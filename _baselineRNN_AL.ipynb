{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# agnews baseline AL pad\n",
    "## no sideInput no mask training\n",
    "### baseline shortcut 多次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### baseline shortcut\n",
    "\n",
    "### 2/04 - valid/test 80%:20%\n",
    "###      - baseline\n",
    "### 2/14 - valid/test 50%:50%\n",
    "#data = \"ag_news\"\n",
    "#for text_len in [25,50,75,100,125,150,175]:\n",
    "### 2/18 - dbpedia\n",
    "data = \"dbpedia_14\"\n",
    "#for text_len in [20,40,60]:\n",
    "### 2/28 - imdb 8:1:1\n",
    "#data = \"imdb\"\n",
    "#for text_len in [100,200,300,400,500]:\n",
    "for test_count in range(5):\n",
    "    #text_len = 500\n",
    "    #text_len = 177\n",
    "    text_len = 80\n",
    "    for model in [\"linearal\",\"lstmal\",\"transformeral\",]:\n",
    "        layer = 5\n",
    "        epoch = 30\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_side.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-size 128 --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fullpath baseline 多次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fullpath baseline\n",
    "import gc\n",
    "### 2/22 - baseline: valid/test with fullpath\n",
    "#data = \"ag_news\"\n",
    "#for text_len in [25,50,75,100,125,150,175]:\n",
    "### 2/26 - dbpedia\n",
    "data = \"dbpedia_14\"\n",
    "#for text_len in [20,40,60]:\n",
    "### 2/28 - imdb 8:1:1\n",
    "### 3/16 - fullpath valid / shortcut+adapt test\n",
    "batch = 256\n",
    "#data = \"imdb\"\n",
    "#for text_len in [100,200,300,400,500]:\n",
    "for test_count in range(5):\n",
    "    #text_len = 500\n",
    "    text_len = 80\n",
    "    #text_len = 177\n",
    "    for model in [\"transformeral\",\"linearal\",\"lstmal\",]:\n",
    "        layer = 5\n",
    "        epoch = 20\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}base{batch}_pad{text_len}/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}base{batch}_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}base{batch}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_base.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-size {batch} --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "    gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adapt 多次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2/04 - valid/test 80%:20%\n",
    "###      - save_path unique for test load\n",
    "###      - \"lstmal\",\"linearal\",\"transformeral\" adapt valid pad save best auc\n",
    "### 2/08 - valid/test 50%:50%\n",
    "#data = \"ag_news\"\n",
    "#for text_len in [25,50,75,100,125,150,175]:\n",
    "#for text_len in [50,75,100,125,150,175]:\n",
    "### 2/18 - dbpedia\n",
    "#data = \"dbpedia_14\"\n",
    "#for text_len in [20,40,60]:\n",
    "data = \"imdb\"\n",
    "for test_count in range(5):\n",
    "    text_len = 500\n",
    "    #text_len = 177\n",
    "    for model in [\"lstmal\",\"linearal\",\"transformeral\"]:\n",
    "        layer = 5\n",
    "        epoch = 30\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}ad_pad{text_len}/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}ad_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_adapt.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-size 128 --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final exp 補跑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"imdb\"\n",
    "for test_count in range(5,10):\n",
    "    text_len = 500\n",
    "\n",
    "    for model in [\"lstmal\",\"linearal\",\"transformeral\"]:\n",
    "        layer = 5\n",
    "        epoch = 20\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_base_side.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-train 256 --batch-test 512 \\\n",
    "        --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"ag_news\"\n",
    "for test_count in range(5,10):\n",
    "    text_len = 177\n",
    "\n",
    "    for model in [\"lstmal\",\"linearal\",\"transformeral\"]:\n",
    "        layer = 5\n",
    "        epoch = 20\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_base_side.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-train 256 --batch-test 512 \\\n",
    "        --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"dbpedia_14\"\n",
    "for test_count in range(5,10):\n",
    "    text_len = 80\n",
    "\n",
    "    for model in [\"transformeral\",\"lstmal\",\"linearal\",]:\n",
    "        layer = 5\n",
    "        epoch = 20\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_base_side.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-train 256 --batch-test 512 \\\n",
    "        --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix lbl train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix lbl test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"imdb\"\n",
    "for test_count in range(1):\n",
    "    text_len = 500\n",
    "\n",
    "    for model in [\"linearal\",\"transformeral\",\"lstmal\",]:\n",
    "        layer = 5\n",
    "        epoch = 50\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_test_rnn_lbl.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-train 256 --batch-test 512 \\\n",
    "        --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"imdb\"\n",
    "for test_count in range(1):\n",
    "    text_len = 500\n",
    "\n",
    "    for model in [\"linearal\",\"transformeral\",\"lstmal\",]:\n",
    "        layer = 5\n",
    "        epoch = 50\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_test_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_test_rnn_lbl.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-train 256 --batch-test 512 \\\n",
    "        --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"ag_news\"\n",
    "for test_count in range(1):\n",
    "    text_len = 177\n",
    "\n",
    "    for model in [\"linearal\",\"transformeral\",\"lstmal\",]:\n",
    "        layer = 5\n",
    "        epoch = 50\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_test_rnn_lbl.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-train 256 --batch-test 512 \\\n",
    "        --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"dbpedia_14\"\n",
    "for test_count in range(1):\n",
    "    text_len = 80\n",
    "\n",
    "    for model in [\"linearal\",\"transformeral\",\"lstmal\",]:\n",
    "        layer = 5\n",
    "        epoch = 50\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_rnn_lbl.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-train 256 --batch-test 512 \\\n",
    "        --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sideinput lbl fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘ckpt/imdb_transformeralside_l4_pad200_fix/’: File exists\n",
      "mkdir: cannot create directory ‘result/imdb_transformeralside_l4_pad200_fix/’: File exists\n",
      "loading glove vocabs...: 100%|██████| 400000/400000 [00:03<00:00, 110056.89it/s]\n",
      "Train 0 | Acc 0.484925 (19397/40000): 100%|███| 157/157 [00:11<00:00, 14.03it/s]\n",
      "Train 1 | Acc 0.488625 (19545/40000): 100%|███| 157/157 [00:10<00:00, 14.51it/s]\n",
      "Train 2 | Acc 0.4885 (19540/40000): 100%|█████| 157/157 [00:10<00:00, 14.50it/s]\n",
      "Train 3 | Acc 0.487675 (19507/40000): 100%|███| 157/157 [00:10<00:00, 14.47it/s]\n",
      "Train 4 | Acc 0.4883 (19532/40000): 100%|█████| 157/157 [00:10<00:00, 14.48it/s]\n",
      "Train 5 | Acc 0.486275 (19451/40000): 100%|███| 157/157 [00:10<00:00, 14.36it/s]\n",
      "Train 6 | Acc 0.486975 (19479/40000): 100%|███| 157/157 [00:10<00:00, 14.48it/s]\n",
      "Train 7 | Acc 0.487475 (19499/40000): 100%|███| 157/157 [00:10<00:00, 14.46it/s]\n",
      "Train 8 | Acc 0.48715 (19486/40000): 100%|████| 157/157 [00:10<00:00, 14.48it/s]\n",
      "Train 9 | Acc 0.487775 (19511/40000): 100%|███| 157/157 [00:10<00:00, 14.38it/s]\n",
      "Train 10 | Acc 0.48835 (19534/40000): 100%|███| 157/157 [00:10<00:00, 14.48it/s]\n",
      "Train 11 | Acc 0.489625 (19585/40000): 100%|██| 157/157 [00:10<00:00, 14.46it/s]\n",
      "Train 12 | Acc 0.490075 (19603/40000): 100%|██| 157/157 [00:10<00:00, 14.49it/s]\n",
      "Train 13 | Acc 0.4895 (19580/40000): 100%|████| 157/157 [00:10<00:00, 14.47it/s]\n",
      "Train 14 | Acc 0.49065 (19626/40000): 100%|███| 157/157 [00:10<00:00, 14.46it/s]\n",
      "Train 15 | Acc 0.49155 (19662/40000): 100%|███| 157/157 [00:10<00:00, 14.43it/s]\n",
      "Train 16 | Acc 0.4916 (19664/40000): 100%|████| 157/157 [00:10<00:00, 14.32it/s]\n",
      "Train 17 | Acc 0.492175 (19687/40000): 100%|██| 157/157 [00:10<00:00, 14.44it/s]\n",
      "Train 18 | Acc 0.493 (19720/40000): 100%|█████| 157/157 [00:10<00:00, 14.43it/s]\n",
      "Train 19 | Acc 0.49305 (19722/40000): 100%|███| 157/157 [00:10<00:00, 14.44it/s]\n",
      "Train 20 | Acc 0.49325 (19730/40000): 100%|███| 157/157 [00:10<00:00, 14.37it/s]\n",
      "Train 21 | Acc 0.493725 (19749/40000): 100%|██| 157/157 [00:10<00:00, 14.44it/s]\n",
      "Train 22 | Acc 0.4941 (19764/40000): 100%|████| 157/157 [00:10<00:00, 14.38it/s]\n",
      "Train 23 | Acc 0.49435 (19774/40000): 100%|███| 157/157 [00:10<00:00, 14.46it/s]\n",
      "Train 24 | Acc 0.494925 (19797/40000): 100%|██| 157/157 [00:10<00:00, 14.43it/s]\n",
      "Train 25 | Acc 0.494775 (19791/40000): 100%|██| 157/157 [00:10<00:00, 14.41it/s]\n"
     ]
    }
   ],
   "source": [
    "data = \"imdb\"\n",
    "for test_count in range(1):\n",
    "    text_len = 200\n",
    "\n",
    "    for model in [\"transformeralside\",\"lstmalside\",]:\n",
    "        layer = 4\n",
    "        epoch = 400\n",
    "        lr = 0.0005\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_rnn_lbl.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-train 256 --batch-test 512 \\\n",
    "        --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --side-dim 50-50-50-50\\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"dbpedia_14\"\n",
    "for test_count in range(1):\n",
    "    text_len = 80\n",
    "\n",
    "    for model in [\"transformeralside\",\"lstmalside\",]:\n",
    "        layer = 4\n",
    "        epoch = 200\n",
    "        lr = 0.0005\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_rnn_lbl.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-train 256 --batch-test 512 \\\n",
    "        --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --side-dim 20-20-20-20\\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"ag_news\"\n",
    "for test_count in range(1):\n",
    "    text_len = 40\n",
    "\n",
    "    for model in [\"transformeralside\",\"lstmalside\",]:\n",
    "        layer = 4\n",
    "        epoch = 400\n",
    "        lr = 0.0005\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_rnn_lbl.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-train 256 --batch-test 512 \\\n",
    "        --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --side-dim 10-10-10-10\\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
