{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# agnews baseline AL pad\n",
    "## no sideInput no mask training\n",
    "### baseline shortcut 多次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### baseline shortcut\n",
    "\n",
    "### 2/04 - valid/test 80%:20%\n",
    "###      - baseline\n",
    "### 2/14 - valid/test 50%:50%\n",
    "#data = \"ag_news\"\n",
    "#for text_len in [25,50,75,100,125,150,175]:\n",
    "### 2/18 - dbpedia\n",
    "data = \"dbpedia_14\"\n",
    "#for text_len in [20,40,60]:\n",
    "### 2/28 - imdb 8:1:1\n",
    "#data = \"imdb\"\n",
    "#for text_len in [100,200,300,400,500]:\n",
    "for test_count in range(5):\n",
    "    #text_len = 500\n",
    "    #text_len = 177\n",
    "    text_len = 80\n",
    "    for model in [\"linearal\",\"lstmal\",\"transformeral\",]:\n",
    "        layer = 5\n",
    "        epoch = 30\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_side.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-size 128 --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fullpath baseline 多次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fullpath baseline\n",
    "import gc\n",
    "### 2/22 - baseline: valid/test with fullpath\n",
    "#data = \"ag_news\"\n",
    "#for text_len in [25,50,75,100,125,150,175]:\n",
    "### 2/26 - dbpedia\n",
    "data = \"dbpedia_14\"\n",
    "#for text_len in [20,40,60]:\n",
    "### 2/28 - imdb 8:1:1\n",
    "### 3/16 - fullpath valid / shortcut+adapt test\n",
    "batch = 256\n",
    "#data = \"imdb\"\n",
    "#for text_len in [100,200,300,400,500]:\n",
    "for test_count in range(5):\n",
    "    #text_len = 500\n",
    "    text_len = 80\n",
    "    #text_len = 177\n",
    "    for model in [\"transformeral\",\"linearal\",\"lstmal\",]:\n",
    "        layer = 5\n",
    "        epoch = 20\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}base{batch}_pad{text_len}/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}base{batch}_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}base{batch}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_base.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-size {batch} --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "    gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adapt 多次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2/04 - valid/test 80%:20%\n",
    "###      - save_path unique for test load\n",
    "###      - \"lstmal\",\"linearal\",\"transformeral\" adapt valid pad save best auc\n",
    "### 2/08 - valid/test 50%:50%\n",
    "#data = \"ag_news\"\n",
    "#for text_len in [25,50,75,100,125,150,175]:\n",
    "#for text_len in [50,75,100,125,150,175]:\n",
    "### 2/18 - dbpedia\n",
    "#data = \"dbpedia_14\"\n",
    "#for text_len in [20,40,60]:\n",
    "data = \"imdb\"\n",
    "for test_count in range(5):\n",
    "    text_len = 500\n",
    "    #text_len = 177\n",
    "    for model in [\"lstmal\",\"linearal\",\"transformeral\"]:\n",
    "        layer = 5\n",
    "        epoch = 30\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}ad_pad{text_len}/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}ad_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_adapt.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-size 128 --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### final exp 補跑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"imdb\"\n",
    "for test_count in range(5,10):\n",
    "    text_len = 500\n",
    "\n",
    "    for model in [\"lstmal\",\"linearal\",\"transformeral\"]:\n",
    "        layer = 5\n",
    "        epoch = 20\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_base_side.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-train 256 --batch-test 512 \\\n",
    "        --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"ag_news\"\n",
    "for test_count in range(5,10):\n",
    "    text_len = 177\n",
    "\n",
    "    for model in [\"lstmal\",\"linearal\",\"transformeral\"]:\n",
    "        layer = 5\n",
    "        epoch = 20\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_base_side.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-train 256 --batch-test 512 \\\n",
    "        --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"dbpedia_14\"\n",
    "for test_count in range(5,10):\n",
    "    text_len = 80\n",
    "\n",
    "    for model in [\"transformeral\",\"lstmal\",\"linearal\",]:\n",
    "        layer = 5\n",
    "        epoch = 20\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_base_side.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-train 256 --batch-test 512 \\\n",
    "        --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fix lbl train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"imdb\"\n",
    "for test_count in range(1):\n",
    "    text_len = 500\n",
    "\n",
    "    for model in [\"linearal\",\"transformeral\",\"lstmal\",]:\n",
    "        layer = 5\n",
    "        epoch = 50\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_test_rnn_lbl.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-train 256 --batch-test 512 \\\n",
    "        --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"imdb\"\n",
    "for test_count in range(1):\n",
    "    text_len = 500\n",
    "\n",
    "    for model in [\"linearal\",\"transformeral\",\"lstmal\",]:\n",
    "        layer = 5\n",
    "        epoch = 50\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_test_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_test_rnn_lbl.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-train 256 --batch-test 512 \\\n",
    "        --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"ag_news\"\n",
    "for test_count in range(1):\n",
    "    text_len = 177\n",
    "\n",
    "    for model in [\"linearal\",\"transformeral\",\"lstmal\",]:\n",
    "        layer = 5\n",
    "        epoch = 50\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_test_rnn_lbl.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-train 256 --batch-test 512 \\\n",
    "        --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"dbpedia_14\"\n",
    "for test_count in range(1):\n",
    "    text_len = 80\n",
    "\n",
    "    for model in [\"linearal\",\"transformeral\",\"lstmal\",]:\n",
    "        layer = 5\n",
    "        epoch = 50\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}_fix/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}_{test_count}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_rnn_lbl.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-train 256 --batch-test 512 \\\n",
    "        --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
