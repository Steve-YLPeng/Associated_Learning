total count words 222751
vocab size 30000
train size 40000, valid size 5000, test size 5000
found 27937 words in glove
model: TransformerALsideText(
  (layers): ModuleList(
    (0): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=2, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=2, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
  (emb_layers): ModuleList(
    (0): Embedding(30000, 300)
    (1): Embedding(30000, 300)
    (2): Embedding(30000, 300)
    (3): Embedding(30000, 300)
    (4): Embedding(30000, 300)
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.multi_headed_attention.linears.0.weight 90000
layers.0.enc.f.multi_headed_attention.linears.0.bias 300
layers.0.enc.f.multi_headed_attention.linears.1.weight 90000
layers.0.enc.f.multi_headed_attention.linears.1.bias 300
layers.0.enc.f.multi_headed_attention.linears.2.weight 90000
layers.0.enc.f.multi_headed_attention.linears.2.bias 300
layers.0.enc.f.multi_headed_attention.linears.3.weight 90000
layers.0.enc.f.multi_headed_attention.linears.3.bias 300
layers.0.enc.f.feed_forward.w_1.weight 90000
layers.0.enc.f.feed_forward.w_1.bias 300
layers.0.enc.f.feed_forward.w_2.weight 90000
layers.0.enc.f.feed_forward.w_2.bias 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.0.enc.f.encoder.norm.a 300
layers.0.enc.f.encoder.norm.b 300
layers.0.ae.g.0.weight 256
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 256
layers.0.ae.h.0.bias 2
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
emb_layers.0.weight 9000000
emb_layers.1.weight 9000000
emb_layers.2.weight 9000000
emb_layers.3.weight 9000000
emb_layers.4.weight 9000000
Total Trainable Params: 50758378
init_time 22.499363382
Start Training
gc 0
Train Epoch0 Acc 0.4996 (19984/40000), AUC 0.5015175342559814
ep0_train_time 23.865408329999998
Test Epoch0 layer0 Acc 0.4998, AUC 0.57851243019104, avg_entr 0.6836191415786743, f1 0.4997999966144562
ep0_l0_test_time 0.307166665000004
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 0
Test Epoch0 layer1 Acc 0.5036, AUC 0.5715059041976929, avg_entr 0.6885996460914612, f1 0.503600001335144
ep0_l1_test_time 0.379539041000001
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 0
Test Epoch0 layer2 Acc 0.5, AUC 0.5498647093772888, avg_entr 0.6823166608810425, f1 0.5
ep0_l2_test_time 0.4882584879999996
Test Epoch0 layer3 Acc 0.5, AUC 0.49831822514533997, avg_entr 0.6868473887443542, f1 0.5
ep0_l3_test_time 0.6396386830000012
Test Epoch0 layer4 Acc 0.5, AUC 0.47838643193244934, avg_entr 0.6860290765762329, f1 0.5
ep0_l4_test_time 0.8317352460000009
gc 0
Train Epoch1 Acc 0.509175 (20367/40000), AUC 0.5126140713691711
ep1_train_time 23.35917124499999
Test Epoch1 layer0 Acc 0.5002, AUC 0.6266311407089233, avg_entr 0.610112190246582, f1 0.5001999735832214
ep1_l0_test_time 0.30665229500000635
Test Epoch1 layer1 Acc 0.5042, AUC 0.6299182772636414, avg_entr 0.60418301820755, f1 0.5041999816894531
ep1_l1_test_time 0.37926275799999587
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 1
Test Epoch1 layer2 Acc 0.5008, AUC 0.5995548367500305, avg_entr 0.6541696190834045, f1 0.5008000135421753
ep1_l2_test_time 0.4872971289999981
Test Epoch1 layer3 Acc 0.5, AUC 0.5381883382797241, avg_entr 0.6489742398262024, f1 0.5
ep1_l3_test_time 0.6367144499999995
Test Epoch1 layer4 Acc 0.5, AUC 0.5163827538490295, avg_entr 0.6626051068305969, f1 0.5
ep1_l4_test_time 0.8310318779999903
gc 0
Train Epoch2 Acc 0.5203 (20812/40000), AUC 0.5295619368553162
ep2_train_time 23.380432029000005
Test Epoch2 layer0 Acc 0.6134, AUC 0.6702142357826233, avg_entr 0.596503496170044, f1 0.6133999824523926
ep2_l0_test_time 0.3061732460000002
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 2
Test Epoch2 layer1 Acc 0.6432, AUC 0.7086602449417114, avg_entr 0.5682952404022217, f1 0.6431999802589417
ep2_l1_test_time 0.3786921680000006
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 2
Test Epoch2 layer2 Acc 0.6516, AUC 0.7110995054244995, avg_entr 0.5934104323387146, f1 0.6516000032424927
ep2_l2_test_time 0.4945350160000004
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 2
Test Epoch2 layer3 Acc 0.6392, AUC 0.7044159173965454, avg_entr 0.6730414628982544, f1 0.63919997215271
ep2_l3_test_time 0.6378094429999948
Test Epoch2 layer4 Acc 0.5, AUC 0.6956765651702881, avg_entr 0.6680780053138733, f1 0.5
ep2_l4_test_time 0.8310027610000077
gc 0
Train Epoch3 Acc 0.569125 (22765/40000), AUC 0.5962162017822266
ep3_train_time 23.367227779000004
Test Epoch3 layer0 Acc 0.6506, AUC 0.725467324256897, avg_entr 0.4824035167694092, f1 0.650600016117096
ep3_l0_test_time 0.3065240440000139
Test Epoch3 layer1 Acc 0.644, AUC 0.7649960517883301, avg_entr 0.3902037739753723, f1 0.6439999938011169
ep3_l1_test_time 0.37978289099999074
Test Epoch3 layer2 Acc 0.6156, AUC 0.7761456370353699, avg_entr 0.31502747535705566, f1 0.6155999898910522
ep3_l2_test_time 0.4909469859999831
Test Epoch3 layer3 Acc 0.6038, AUC 0.774554967880249, avg_entr 0.35760149359703064, f1 0.6037999987602234
ep3_l3_test_time 0.638785323999997
Test Epoch3 layer4 Acc 0.5202, AUC 0.7740703821182251, avg_entr 0.26561111211776733, f1 0.5202000141143799
ep3_l4_test_time 0.8326507249999793
gc 0
Train Epoch4 Acc 0.6517 (26068/40000), AUC 0.7058671712875366
ep4_train_time 23.38417753799999
Test Epoch4 layer0 Acc 0.6806, AUC 0.7527704834938049, avg_entr 0.4621972143650055, f1 0.6805999875068665
ep4_l0_test_time 0.30807582099998854
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
Test Epoch4 layer1 Acc 0.7128, AUC 0.7881051301956177, avg_entr 0.454389363527298, f1 0.7128000259399414
ep4_l1_test_time 0.3787797309999803
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
Test Epoch4 layer2 Acc 0.725, AUC 0.799875020980835, avg_entr 0.47822919487953186, f1 0.7250000238418579
ep4_l2_test_time 0.4870531720000031
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
Test Epoch4 layer3 Acc 0.7258, AUC 0.7998919486999512, avg_entr 0.5184248089790344, f1 0.7257999777793884
ep4_l3_test_time 0.6398554719999936
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
Test Epoch4 layer4 Acc 0.727, AUC 0.7995485067367554, avg_entr 0.5674787163734436, f1 0.7269999980926514
ep4_l4_test_time 0.8314458320000142
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
gc 0
Train Epoch5 Acc 0.715475 (28619/40000), AUC 0.7914013862609863
ep5_train_time 23.398694680999995
Test Epoch5 layer0 Acc 0.6832, AUC 0.7667102217674255, avg_entr 0.36437687277793884, f1 0.6832000017166138
ep5_l0_test_time 0.30629438799999775
Test Epoch5 layer1 Acc 0.6872, AUC 0.8045408129692078, avg_entr 0.299555242061615, f1 0.6872000098228455
ep5_l1_test_time 0.3788777800000105
Test Epoch5 layer2 Acc 0.6836, AUC 0.8164489269256592, avg_entr 0.26478540897369385, f1 0.6836000084877014
ep5_l2_test_time 0.48991305399999874
Test Epoch5 layer3 Acc 0.6674, AUC 0.8154256939888, avg_entr 0.24111242592334747, f1 0.6674000024795532
ep5_l3_test_time 0.6386574150000115
Test Epoch5 layer4 Acc 0.6572, AUC 0.8152294754981995, avg_entr 0.22552183270454407, f1 0.6571999788284302
ep5_l4_test_time 0.834465243000011
gc 0
Train Epoch6 Acc 0.734325 (29373/40000), AUC 0.8090578317642212
ep6_train_time 23.41003096099999
Test Epoch6 layer0 Acc 0.7002, AUC 0.7772886157035828, avg_entr 0.3763747215270996, f1 0.7002000212669373
ep6_l0_test_time 0.3045355229999984
Test Epoch6 layer1 Acc 0.7248, AUC 0.8143365383148193, avg_entr 0.316005140542984, f1 0.7247999906539917
ep6_l1_test_time 0.3808024939999939
Test Epoch6 layer2 Acc 0.7336, AUC 0.8275928497314453, avg_entr 0.297966867685318, f1 0.7335999608039856
ep6_l2_test_time 0.4883547080000028
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer3 Acc 0.727, AUC 0.8286800980567932, avg_entr 0.2912850081920624, f1 0.7269999980926514
ep6_l3_test_time 0.6377711990000137
Test Epoch6 layer4 Acc 0.725, AUC 0.8291327953338623, avg_entr 0.28701120615005493, f1 0.7250000238418579
ep6_l4_test_time 0.8311962009999831
gc 0
Train Epoch7 Acc 0.748825 (29953/40000), AUC 0.8275081515312195
ep7_train_time 23.39215696299999
Test Epoch7 layer0 Acc 0.7068, AUC 0.7842544317245483, avg_entr 0.3449060022830963, f1 0.7067999839782715
ep7_l0_test_time 0.3053953270000136
Test Epoch7 layer1 Acc 0.7364, AUC 0.8223663568496704, avg_entr 0.336992084980011, f1 0.7364000082015991
ep7_l1_test_time 0.37901807500000473
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 7
Test Epoch7 layer2 Acc 0.7522, AUC 0.835513174533844, avg_entr 0.35733723640441895, f1 0.7522000074386597
ep7_l2_test_time 0.4873903220000102
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 7
Test Epoch7 layer3 Acc 0.7554, AUC 0.8371292352676392, avg_entr 0.38705992698669434, f1 0.7554000020027161
ep7_l3_test_time 0.6377131049999889
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 7
Test Epoch7 layer4 Acc 0.7534, AUC 0.8374612927436829, avg_entr 0.41149741411209106, f1 0.7533999681472778
ep7_l4_test_time 0.8302956600000186
gc 0
Train Epoch8 Acc 0.7628 (30512/40000), AUC 0.8432145118713379
ep8_train_time 23.428622785000016
Test Epoch8 layer0 Acc 0.7076, AUC 0.7902073860168457, avg_entr 0.3244956433773041, f1 0.707599937915802
ep8_l0_test_time 0.3069928740000023
Test Epoch8 layer1 Acc 0.7462, AUC 0.8309944868087769, avg_entr 0.29827865958213806, f1 0.7462000250816345
ep8_l1_test_time 0.3811730869999792
Test Epoch8 layer2 Acc 0.7602, AUC 0.8443537950515747, avg_entr 0.3030645549297333, f1 0.7602000832557678
ep8_l2_test_time 0.4904704140000149
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 8
Test Epoch8 layer3 Acc 0.7656, AUC 0.8468478918075562, avg_entr 0.3219599425792694, f1 0.7655999660491943
ep8_l3_test_time 0.6399205210000218
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 8
Test Epoch8 layer4 Acc 0.7644, AUC 0.8468303680419922, avg_entr 0.3344280421733856, f1 0.7644000053405762
ep8_l4_test_time 0.8346969940000122
gc 0
Train Epoch9 Acc 0.792975 (31719/40000), AUC 0.8706633448600769
ep9_train_time 23.481287162
Test Epoch9 layer0 Acc 0.7146, AUC 0.7926544547080994, avg_entr 0.2981656789779663, f1 0.7146000266075134
ep9_l0_test_time 0.3080414930000188
Test Epoch9 layer1 Acc 0.7502, AUC 0.8325610756874084, avg_entr 0.2527409493923187, f1 0.7501999735832214
ep9_l1_test_time 0.38104842299998154
Test Epoch9 layer2 Acc 0.7664, AUC 0.8458824157714844, avg_entr 0.224393829703331, f1 0.7663999199867249
ep9_l2_test_time 0.49044064299999945
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 9
Test Epoch9 layer3 Acc 0.7694, AUC 0.8484029173851013, avg_entr 0.21061986684799194, f1 0.7694000005722046
ep9_l3_test_time 0.638141891000032
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 9
Test Epoch9 layer4 Acc 0.7652, AUC 0.8486777544021606, avg_entr 0.1922045350074768, f1 0.7652000188827515
ep9_l4_test_time 0.8311356429999819
gc 0
Train Epoch10 Acc 0.8193 (32772/40000), AUC 0.8966212272644043
ep10_train_time 23.355921019999982
Test Epoch10 layer0 Acc 0.704, AUC 0.7896239757537842, avg_entr 0.2735379636287689, f1 0.7039999961853027
ep10_l0_test_time 0.3052125699999806
Test Epoch10 layer1 Acc 0.7322, AUC 0.8329925537109375, avg_entr 0.24210859835147858, f1 0.732200026512146
ep10_l1_test_time 0.3785924439999917
Test Epoch10 layer2 Acc 0.7256, AUC 0.8452275991439819, avg_entr 0.22204206883907318, f1 0.7255999445915222
ep10_l2_test_time 0.4895465140000397
Test Epoch10 layer3 Acc 0.7056, AUC 0.8467674255371094, avg_entr 0.2112482637166977, f1 0.7056000232696533
ep10_l3_test_time 0.6383690189999811
Test Epoch10 layer4 Acc 0.6914, AUC 0.8469676971435547, avg_entr 0.1996750831604004, f1 0.6913999915122986
ep10_l4_test_time 0.8317632449999905
gc 0
Train Epoch11 Acc 0.843375 (33735/40000), AUC 0.9194709062576294
ep11_train_time 23.405393548999996
Test Epoch11 layer0 Acc 0.7072, AUC 0.7859211564064026, avg_entr 0.25598543882369995, f1 0.7071999907493591
ep11_l0_test_time 0.3052659589999962
Test Epoch11 layer1 Acc 0.7448, AUC 0.8298614621162415, avg_entr 0.2151203602552414, f1 0.7447999715805054
ep11_l1_test_time 0.3783305819999896
Test Epoch11 layer2 Acc 0.7556, AUC 0.8413605093955994, avg_entr 0.17662984132766724, f1 0.7555999755859375
ep11_l2_test_time 0.48855257500002836
Test Epoch11 layer3 Acc 0.7592, AUC 0.8441052436828613, avg_entr 0.14787788689136505, f1 0.7591999769210815
ep11_l3_test_time 0.6379438949999781
Test Epoch11 layer4 Acc 0.7578, AUC 0.8459856510162354, avg_entr 0.12804856896400452, f1 0.7577999830245972
ep11_l4_test_time 0.831635963999986
gc 0
Train Epoch12 Acc 0.8538 (34152/40000), AUC 0.9264918565750122
ep12_train_time 23.399217145999955
Test Epoch12 layer0 Acc 0.7042, AUC 0.7931389808654785, avg_entr 0.22589819133281708, f1 0.704200029373169
ep12_l0_test_time 0.3053168320000168
Test Epoch12 layer1 Acc 0.7472, AUC 0.8387953042984009, avg_entr 0.20396201312541962, f1 0.747200071811676
ep12_l1_test_time 0.379208766999966
Test Epoch12 layer2 Acc 0.748, AUC 0.8500608205795288, avg_entr 0.14459213614463806, f1 0.7480000257492065
ep12_l2_test_time 0.48963346700003285
Test Epoch12 layer3 Acc 0.749, AUC 0.8541648983955383, avg_entr 0.11703869700431824, f1 0.7490000128746033
ep12_l3_test_time 0.6388456259999771
Test Epoch12 layer4 Acc 0.7466, AUC 0.8540353178977966, avg_entr 0.1092359721660614, f1 0.7465999126434326
ep12_l4_test_time 0.8317862309999668
gc 0
Train Epoch13 Acc 0.87795 (35118/40000), AUC 0.9452568888664246
ep13_train_time 23.39524918500001
Test Epoch13 layer0 Acc 0.7074, AUC 0.7804617881774902, avg_entr 0.23179872334003448, f1 0.7074000239372253
ep13_l0_test_time 0.3086016799999811
Test Epoch13 layer1 Acc 0.7492, AUC 0.8274281024932861, avg_entr 0.18876034021377563, f1 0.7491999864578247
ep13_l1_test_time 0.37969806499995684
Test Epoch13 layer2 Acc 0.7568, AUC 0.8392540812492371, avg_entr 0.12536773085594177, f1 0.7567999958992004
ep13_l2_test_time 0.495981922999988
Test Epoch13 layer3 Acc 0.7602, AUC 0.8448467254638672, avg_entr 0.1114320307970047, f1 0.7602000832557678
ep13_l3_test_time 0.6368494489999534
Test Epoch13 layer4 Acc 0.7612, AUC 0.8455306887626648, avg_entr 0.10678200423717499, f1 0.7612000107765198
ep13_l4_test_time 0.8306104839999762
gc 0
Train Epoch14 Acc 0.884375 (35375/40000), AUC 0.9479316473007202
ep14_train_time 23.44238337600001
Test Epoch14 layer0 Acc 0.6906, AUC 0.7791599035263062, avg_entr 0.22153207659721375, f1 0.6905999779701233
ep14_l0_test_time 0.30588103200000205
Test Epoch14 layer1 Acc 0.7118, AUC 0.8223986625671387, avg_entr 0.18346962332725525, f1 0.7117999792098999
ep14_l1_test_time 0.3797725559999776
Test Epoch14 layer2 Acc 0.7242, AUC 0.8338499069213867, avg_entr 0.12684161961078644, f1 0.7242000699043274
ep14_l2_test_time 0.4891446709999627
Test Epoch14 layer3 Acc 0.7208, AUC 0.8402765989303589, avg_entr 0.1089952141046524, f1 0.7207999229431152
ep14_l3_test_time 0.6384791199999995
Test Epoch14 layer4 Acc 0.721, AUC 0.840000331401825, avg_entr 0.10423808544874191, f1 0.7210000157356262
ep14_l4_test_time 0.8334127020000324
gc 0
Train Epoch15 Acc 0.8974 (35896/40000), AUC 0.9579600691795349
ep15_train_time 23.41319212000002
Test Epoch15 layer0 Acc 0.7058, AUC 0.7793409824371338, avg_entr 0.21363241970539093, f1 0.7057999968528748
ep15_l0_test_time 0.30692204600001105
Test Epoch15 layer1 Acc 0.7332, AUC 0.8225452899932861, avg_entr 0.16627085208892822, f1 0.7332000136375427
ep15_l1_test_time 0.3813987330000259
Test Epoch15 layer2 Acc 0.7442, AUC 0.8362170457839966, avg_entr 0.10725337266921997, f1 0.7441999316215515
ep15_l2_test_time 0.49049234299997124
Test Epoch15 layer3 Acc 0.745, AUC 0.8427928686141968, avg_entr 0.09922856837511063, f1 0.7449999451637268
ep15_l3_test_time 0.6385218140000006
Test Epoch15 layer4 Acc 0.7452, AUC 0.8429426550865173, avg_entr 0.09399205446243286, f1 0.745199978351593
ep15_l4_test_time 0.8330769230000215
gc 0
Train Epoch16 Acc 0.914225 (36569/40000), AUC 0.9687174558639526
ep16_train_time 23.424047223000002
Test Epoch16 layer0 Acc 0.677, AUC 0.7781548500061035, avg_entr 0.18649409711360931, f1 0.6769999861717224
ep16_l0_test_time 0.30839772199999516
Test Epoch16 layer1 Acc 0.6622, AUC 0.8174729943275452, avg_entr 0.11569223552942276, f1 0.6621999740600586
ep16_l1_test_time 0.3800470580000024
Test Epoch16 layer2 Acc 0.6768, AUC 0.8274050951004028, avg_entr 0.08090309053659439, f1 0.676800012588501
ep16_l2_test_time 0.49020194799999217
Test Epoch16 layer3 Acc 0.6752, AUC 0.836005449295044, avg_entr 0.07556081563234329, f1 0.6751999855041504
ep16_l3_test_time 0.63941231900003
Test Epoch16 layer4 Acc 0.6722, AUC 0.8316010236740112, avg_entr 0.07276773452758789, f1 0.6722000241279602
ep16_l4_test_time 0.833662634999996
gc 0
Train Epoch17 Acc 0.93115 (37246/40000), AUC 0.9779728651046753
ep17_train_time 23.410284788000013
Test Epoch17 layer0 Acc 0.6934, AUC 0.7725907564163208, avg_entr 0.19002512097358704, f1 0.6934000253677368
ep17_l0_test_time 0.3052834640000128
Test Epoch17 layer1 Acc 0.7032, AUC 0.8073558807373047, avg_entr 0.10480564087629318, f1 0.7031999826431274
ep17_l1_test_time 0.38070532400001866
Test Epoch17 layer2 Acc 0.7216, AUC 0.8115696310997009, avg_entr 0.06506521999835968, f1 0.7215999960899353
ep17_l2_test_time 0.48956667499999185
Test Epoch17 layer3 Acc 0.723, AUC 0.8266603350639343, avg_entr 0.0594930425286293, f1 0.7229999899864197
ep17_l3_test_time 0.6381804760000023
Test Epoch17 layer4 Acc 0.7222, AUC 0.8248739838600159, avg_entr 0.05681606009602547, f1 0.7222000360488892
ep17_l4_test_time 0.833286003000012
gc 0
Train Epoch18 Acc 0.937625 (37505/40000), AUC 0.9813883304595947
ep18_train_time 23.39446425799997
Test Epoch18 layer0 Acc 0.7014, AUC 0.7687270641326904, avg_entr 0.1913774013519287, f1 0.7013999819755554
ep18_l0_test_time 0.30670485000007375
Test Epoch18 layer1 Acc 0.719, AUC 0.8023537397384644, avg_entr 0.10315178334712982, f1 0.718999981880188
ep18_l1_test_time 0.3785688919999757
Test Epoch18 layer2 Acc 0.7396, AUC 0.8188542127609253, avg_entr 0.07164519280195236, f1 0.7396000027656555
ep18_l2_test_time 0.48732624199999464
Test Epoch18 layer3 Acc 0.741, AUC 0.827054500579834, avg_entr 0.06617172807455063, f1 0.7409999370574951
ep18_l3_test_time 0.6400568289999455
Test Epoch18 layer4 Acc 0.7428, AUC 0.8263239860534668, avg_entr 0.06454942375421524, f1 0.7427999973297119
ep18_l4_test_time 0.834228975999963
gc 0
Train Epoch19 Acc 0.94685 (37874/40000), AUC 0.9861586689949036
ep19_train_time 23.405816456000025
Test Epoch19 layer0 Acc 0.702, AUC 0.7701337337493896, avg_entr 0.1894371062517166, f1 0.7020000219345093
ep19_l0_test_time 0.30649689599999874
Test Epoch19 layer1 Acc 0.719, AUC 0.8021408319473267, avg_entr 0.09435434639453888, f1 0.718999981880188
ep19_l1_test_time 0.37980547899996964
Test Epoch19 layer2 Acc 0.7388, AUC 0.8130350112915039, avg_entr 0.06248030439019203, f1 0.7387999892234802
ep19_l2_test_time 0.48866301999998996
Test Epoch19 layer3 Acc 0.7404, AUC 0.8257578015327454, avg_entr 0.05667951703071594, f1 0.7404000163078308
ep19_l3_test_time 0.638142734999974
Test Epoch19 layer4 Acc 0.7402, AUC 0.8250696659088135, avg_entr 0.054039716720581055, f1 0.7401999831199646
ep19_l4_test_time 0.8315580739999859
gc 0
Train Epoch20 Acc 0.9484 (37936/40000), AUC 0.9863160848617554
ep20_train_time 23.396970892000013
Test Epoch20 layer0 Acc 0.6952, AUC 0.7692309021949768, avg_entr 0.17539992928504944, f1 0.6952000260353088
ep20_l0_test_time 0.3067710330000182
Test Epoch20 layer1 Acc 0.7036, AUC 0.7987315654754639, avg_entr 0.09256185591220856, f1 0.7035999894142151
ep20_l1_test_time 0.3809214159999783
Test Epoch20 layer2 Acc 0.7304, AUC 0.80683434009552, avg_entr 0.0582466796040535, f1 0.7304000854492188
ep20_l2_test_time 0.49161920999995345
Test Epoch20 layer3 Acc 0.7292, AUC 0.822147011756897, avg_entr 0.05176163464784622, f1 0.7291999459266663
ep20_l3_test_time 0.6397358870000289
Test Epoch20 layer4 Acc 0.7308, AUC 0.8192001581192017, avg_entr 0.05018109828233719, f1 0.7307999730110168
ep20_l4_test_time 0.8355711699999802
gc 0
Train Epoch21 Acc 0.958 (38320/40000), AUC 0.9908515214920044
ep21_train_time 23.39509395999994
Test Epoch21 layer0 Acc 0.698, AUC 0.7692874670028687, avg_entr 0.18046756088733673, f1 0.6980000138282776
ep21_l0_test_time 0.3124807240000109
Test Epoch21 layer1 Acc 0.714, AUC 0.8002458810806274, avg_entr 0.08434068411588669, f1 0.7139999866485596
ep21_l1_test_time 0.3787424849999752
Test Epoch21 layer2 Acc 0.7422, AUC 0.8134190440177917, avg_entr 0.05782965570688248, f1 0.7422000169754028
ep21_l2_test_time 0.4901769680000143
Test Epoch21 layer3 Acc 0.7442, AUC 0.828093409538269, avg_entr 0.054377906024456024, f1 0.7441999316215515
ep21_l3_test_time 0.6386430740000151
Test Epoch21 layer4 Acc 0.7448, AUC 0.8268261551856995, avg_entr 0.0522032231092453, f1 0.7447999715805054
ep21_l4_test_time 0.8334425330000386
gc 0
Train Epoch22 Acc 0.95915 (38366/40000), AUC 0.991212785243988
ep22_train_time 23.412029425000014
Test Epoch22 layer0 Acc 0.701, AUC 0.7666910886764526, avg_entr 0.1802273839712143, f1 0.7009999752044678
ep22_l0_test_time 0.30700891899994076
Test Epoch22 layer1 Acc 0.7138, AUC 0.7964951992034912, avg_entr 0.08649102598428726, f1 0.7138000130653381
ep22_l1_test_time 0.3806773119999889
Test Epoch22 layer2 Acc 0.7334, AUC 0.8076796531677246, avg_entr 0.05833259969949722, f1 0.7333999872207642
ep22_l2_test_time 0.4892907290000039
Test Epoch22 layer3 Acc 0.7352, AUC 0.822304368019104, avg_entr 0.0530230775475502, f1 0.7351999282836914
ep22_l3_test_time 0.6375502360000382
Test Epoch22 layer4 Acc 0.7362, AUC 0.8213536739349365, avg_entr 0.05141228064894676, f1 0.7361999750137329
ep22_l4_test_time 0.8308973450000394
gc 0
Train Epoch23 Acc 0.962075 (38483/40000), AUC 0.9915021061897278
ep23_train_time 23.392963030000033
Test Epoch23 layer0 Acc 0.6998, AUC 0.7665970325469971, avg_entr 0.17440514266490936, f1 0.6998000144958496
ep23_l0_test_time 0.30565838400002576
Test Epoch23 layer1 Acc 0.7112, AUC 0.7955516576766968, avg_entr 0.08394870907068253, f1 0.7111999988555908
ep23_l1_test_time 0.378580200999977
Test Epoch23 layer2 Acc 0.7346, AUC 0.8035492897033691, avg_entr 0.05299292504787445, f1 0.7345999479293823
ep23_l2_test_time 0.4879904870000473
Test Epoch23 layer3 Acc 0.7376, AUC 0.820334792137146, avg_entr 0.048616327345371246, f1 0.7376000285148621
ep23_l3_test_time 0.6373666690000164
Test Epoch23 layer4 Acc 0.738, AUC 0.8185825347900391, avg_entr 0.04735248535871506, f1 0.7379999160766602
ep23_l4_test_time 0.8310504879999598
gc 0
Train Epoch24 Acc 0.963825 (38553/40000), AUC 0.9926055669784546
ep24_train_time 23.38061394500005
Test Epoch24 layer0 Acc 0.6976, AUC 0.7645978927612305, avg_entr 0.17414253950119019, f1 0.6976000070571899
ep24_l0_test_time 0.30593031099999735
Test Epoch24 layer1 Acc 0.7036, AUC 0.790039598941803, avg_entr 0.07170728594064713, f1 0.7035999894142151
ep24_l1_test_time 0.3788405850000345
Test Epoch24 layer2 Acc 0.7282, AUC 0.7949163913726807, avg_entr 0.048370346426963806, f1 0.7282000184059143
ep24_l2_test_time 0.48902611400001206
Test Epoch24 layer3 Acc 0.7302, AUC 0.8142460584640503, avg_entr 0.04551704600453377, f1 0.7301999926567078
ep24_l3_test_time 0.6394731709999633
Test Epoch24 layer4 Acc 0.729, AUC 0.8137410879135132, avg_entr 0.043886832892894745, f1 0.7289999723434448
ep24_l4_test_time 0.8313933049998923
gc 0
Train Epoch25 Acc 0.968475 (38739/40000), AUC 0.9944851398468018
ep25_train_time 23.445983950999903
Test Epoch25 layer0 Acc 0.7008, AUC 0.7653576731681824, avg_entr 0.17136642336845398, f1 0.7008000016212463
ep25_l0_test_time 0.30815660899997965
Test Epoch25 layer1 Acc 0.706, AUC 0.7919105291366577, avg_entr 0.07224003970623016, f1 0.7059999704360962
ep25_l1_test_time 0.38191875500001515
Test Epoch25 layer2 Acc 0.7308, AUC 0.796482503414154, avg_entr 0.04999590665102005, f1 0.7307999730110168
ep25_l2_test_time 0.48903925100000833
Test Epoch25 layer3 Acc 0.7332, AUC 0.8154957294464111, avg_entr 0.04485033452510834, f1 0.7332000136375427
ep25_l3_test_time 0.6376506520000476
Test Epoch25 layer4 Acc 0.7354, AUC 0.8142416477203369, avg_entr 0.04295849800109863, f1 0.7354000210762024
ep25_l4_test_time 0.8310424370000646
gc 0
Train Epoch26 Acc 0.9693 (38772/40000), AUC 0.9945876598358154
ep26_train_time 23.397289966000017
Test Epoch26 layer0 Acc 0.7008, AUC 0.7641465067863464, avg_entr 0.17063547670841217, f1 0.7008000016212463
ep26_l0_test_time 0.30668735599999764
Test Epoch26 layer1 Acc 0.71, AUC 0.7924383878707886, avg_entr 0.07480086386203766, f1 0.7099999785423279
ep26_l1_test_time 0.3817459729999655
Test Epoch26 layer2 Acc 0.7328, AUC 0.7935429811477661, avg_entr 0.05097149312496185, f1 0.7327999472618103
ep26_l2_test_time 0.49092323800005033
Test Epoch26 layer3 Acc 0.7354, AUC 0.8156006336212158, avg_entr 0.04361874237656593, f1 0.7354000210762024
ep26_l3_test_time 0.6393200119999847
Test Epoch26 layer4 Acc 0.736, AUC 0.8138231039047241, avg_entr 0.04133611172437668, f1 0.7360000014305115
ep26_l4_test_time 0.8355333480000127
gc 0
Train Epoch27 Acc 0.96925 (38770/40000), AUC 0.9945887327194214
ep27_train_time 23.413939695000067
Test Epoch27 layer0 Acc 0.697, AUC 0.7638975977897644, avg_entr 0.170087993144989, f1 0.6970000267028809
ep27_l0_test_time 0.3049478760000284
Test Epoch27 layer1 Acc 0.7072, AUC 0.7920712232589722, avg_entr 0.0768938809633255, f1 0.7071999907493591
ep27_l1_test_time 0.37815170600003967
Test Epoch27 layer2 Acc 0.7356, AUC 0.7972756624221802, avg_entr 0.048177607357501984, f1 0.7355999946594238
ep27_l2_test_time 0.4884630889999926
Test Epoch27 layer3 Acc 0.7366, AUC 0.8161666989326477, avg_entr 0.044205740094184875, f1 0.7365999817848206
ep27_l3_test_time 0.6378368370000089
Test Epoch27 layer4 Acc 0.7376, AUC 0.8150088787078857, avg_entr 0.04214853048324585, f1 0.7376000285148621
ep27_l4_test_time 0.8318717719999995
gc 0
Train Epoch28 Acc 0.971625 (38865/40000), AUC 0.995074987411499
ep28_train_time 23.420255053999995
Test Epoch28 layer0 Acc 0.6938, AUC 0.7629895210266113, avg_entr 0.17074494063854218, f1 0.6937999725341797
ep28_l0_test_time 0.30662146199995277
Test Epoch28 layer1 Acc 0.7068, AUC 0.7888859510421753, avg_entr 0.07196084409952164, f1 0.7067999839782715
ep28_l1_test_time 0.37975120299995524
Test Epoch28 layer2 Acc 0.7332, AUC 0.7956005334854126, avg_entr 0.04920875281095505, f1 0.7332000136375427
ep28_l2_test_time 0.488900942999976
Test Epoch28 layer3 Acc 0.733, AUC 0.813072681427002, avg_entr 0.04437385872006416, f1 0.7329999804496765
ep28_l3_test_time 0.6378451389999782
Test Epoch28 layer4 Acc 0.735, AUC 0.8133062720298767, avg_entr 0.04258337989449501, f1 0.7350000143051147
ep28_l4_test_time 0.8320500610000181
gc 0
Train Epoch29 Acc 0.9725 (38900/40000), AUC 0.9955304265022278
ep29_train_time 23.404140248999965
Test Epoch29 layer0 Acc 0.6936, AUC 0.762394905090332, avg_entr 0.16915197670459747, f1 0.6935999989509583
ep29_l0_test_time 0.30710499200006325
Test Epoch29 layer1 Acc 0.7032, AUC 0.7878082990646362, avg_entr 0.06901443749666214, f1 0.7031999826431274
ep29_l1_test_time 0.38004158299997925
Test Epoch29 layer2 Acc 0.729, AUC 0.7884121537208557, avg_entr 0.046487122774124146, f1 0.7289999723434448
ep29_l2_test_time 0.4892766649999203
Test Epoch29 layer3 Acc 0.7304, AUC 0.8103200197219849, avg_entr 0.04283558204770088, f1 0.7304000854492188
ep29_l3_test_time 0.6404486469999711
Test Epoch29 layer4 Acc 0.7312, AUC 0.81009441614151, avg_entr 0.041013624519109726, f1 0.7311999797821045
ep29_l4_test_time 0.8334965980000106
gc 0
Train Epoch30 Acc 0.9738 (38952/40000), AUC 0.9955445528030396
ep30_train_time 23.408695016000024
Test Epoch30 layer0 Acc 0.6972, AUC 0.7612936496734619, avg_entr 0.1686927080154419, f1 0.6972000002861023
ep30_l0_test_time 0.3067942119999998
Test Epoch30 layer1 Acc 0.7032, AUC 0.7863603830337524, avg_entr 0.06735923141241074, f1 0.7031999826431274
ep30_l1_test_time 0.3878414769999381
Test Epoch30 layer2 Acc 0.7244, AUC 0.7877695560455322, avg_entr 0.045522257685661316, f1 0.7244000434875488
ep30_l2_test_time 0.49646194099989316
Test Epoch30 layer3 Acc 0.7284, AUC 0.807995080947876, avg_entr 0.03878866136074066, f1 0.7284000515937805
ep30_l3_test_time 0.641657519999967
Test Epoch30 layer4 Acc 0.7292, AUC 0.808239221572876, avg_entr 0.036999575793743134, f1 0.7291999459266663
ep30_l4_test_time 0.8318229459999884
gc 0
Train Epoch31 Acc 0.974775 (38991/40000), AUC 0.9959744215011597
ep31_train_time 23.406061351999938
Test Epoch31 layer0 Acc 0.6906, AUC 0.7614492774009705, avg_entr 0.16627061367034912, f1 0.6905999779701233
ep31_l0_test_time 0.3058334370000466
Test Epoch31 layer1 Acc 0.7032, AUC 0.7866734862327576, avg_entr 0.06602371484041214, f1 0.7031999826431274
ep31_l1_test_time 0.379922507999936
Test Epoch31 layer2 Acc 0.73, AUC 0.7867148518562317, avg_entr 0.047302428632974625, f1 0.7300000190734863
ep31_l2_test_time 0.48908742800006166
Test Epoch31 layer3 Acc 0.7328, AUC 0.808933436870575, avg_entr 0.044165998697280884, f1 0.7327999472618103
ep31_l3_test_time 0.6387623529999473
Test Epoch31 layer4 Acc 0.733, AUC 0.8087277412414551, avg_entr 0.04217246174812317, f1 0.7329999804496765
ep31_l4_test_time 0.8332759899999473
gc 0
Train Epoch32 Acc 0.974625 (38985/40000), AUC 0.9956428408622742
ep32_train_time 23.442953960000068
Test Epoch32 layer0 Acc 0.693, AUC 0.7614715099334717, avg_entr 0.16682876646518707, f1 0.6930000185966492
ep32_l0_test_time 0.3071205239999699
Test Epoch32 layer1 Acc 0.7032, AUC 0.7851221561431885, avg_entr 0.0644134059548378, f1 0.7031999826431274
ep32_l1_test_time 0.3806027370000038
Test Epoch32 layer2 Acc 0.7296, AUC 0.7848677635192871, avg_entr 0.04544755816459656, f1 0.7295999526977539
ep32_l2_test_time 0.4888879159999533
Test Epoch32 layer3 Acc 0.7316, AUC 0.8074078559875488, avg_entr 0.04146865755319595, f1 0.7316000461578369
ep32_l3_test_time 0.638580380999997
Test Epoch32 layer4 Acc 0.7318, AUC 0.8076654672622681, avg_entr 0.039430901408195496, f1 0.7318000197410583
ep32_l4_test_time 0.833747709000022
gc 0
Train Epoch33 Acc 0.976275 (39051/40000), AUC 0.9964942932128906
ep33_train_time 23.409453477999932
Test Epoch33 layer0 Acc 0.6966, AUC 0.7617493867874146, avg_entr 0.16659890115261078, f1 0.6966000199317932
ep33_l0_test_time 0.3074062910000066
Test Epoch33 layer1 Acc 0.7054, AUC 0.7869968414306641, avg_entr 0.0663461983203888, f1 0.7053999900817871
ep33_l1_test_time 0.3814393319998999
Test Epoch33 layer2 Acc 0.7294, AUC 0.788848876953125, avg_entr 0.04613146185874939, f1 0.7293999791145325
ep33_l2_test_time 0.4898154139999633
Test Epoch33 layer3 Acc 0.7338, AUC 0.8098595142364502, avg_entr 0.04166194424033165, f1 0.7338000535964966
ep33_l3_test_time 0.6392384000000675
Test Epoch33 layer4 Acc 0.7332, AUC 0.810108482837677, avg_entr 0.039959464222192764, f1 0.7332000136375427
ep33_l4_test_time 0.8316486109999914
gc 0
Train Epoch34 Acc 0.9742 (38968/40000), AUC 0.9961299896240234
ep34_train_time 23.404156824000097
Test Epoch34 layer0 Acc 0.6938, AUC 0.7615886926651001, avg_entr 0.16497232019901276, f1 0.6937999725341797
ep34_l0_test_time 0.3070748800000729
Test Epoch34 layer1 Acc 0.7062, AUC 0.787244439125061, avg_entr 0.0666501447558403, f1 0.7062000036239624
ep34_l1_test_time 0.3798864789999925
Test Epoch34 layer2 Acc 0.73, AUC 0.7885146141052246, avg_entr 0.046050459146499634, f1 0.7300000190734863
ep34_l2_test_time 0.48925720800002637
Test Epoch34 layer3 Acc 0.7312, AUC 0.8088648319244385, avg_entr 0.040087152272462845, f1 0.7311999797821045
ep34_l3_test_time 0.6380772850000085
Test Epoch34 layer4 Acc 0.732, AUC 0.8089516162872314, avg_entr 0.03820332512259483, f1 0.7319999933242798
ep34_l4_test_time 0.832805533999931
gc 0
Train Epoch35 Acc 0.975925 (39037/40000), AUC 0.9963009357452393
ep35_train_time 23.463380468000082
Test Epoch35 layer0 Acc 0.694, AUC 0.7614915370941162, avg_entr 0.16527709364891052, f1 0.6940000057220459
ep35_l0_test_time 0.3080211210000243
Test Epoch35 layer1 Acc 0.7058, AUC 0.7869974970817566, avg_entr 0.06574124097824097, f1 0.7057999968528748
ep35_l1_test_time 0.38579804100004367
Test Epoch35 layer2 Acc 0.7312, AUC 0.7860002517700195, avg_entr 0.04450976103544235, f1 0.7311999797821045
ep35_l2_test_time 0.4897006449999708
Test Epoch35 layer3 Acc 0.7306, AUC 0.8077169060707092, avg_entr 0.040393929928541183, f1 0.7305999994277954
ep35_l3_test_time 0.640019260000031
Test Epoch35 layer4 Acc 0.7318, AUC 0.8080535531044006, avg_entr 0.037791669368743896, f1 0.7318000197410583
ep35_l4_test_time 0.8331902800000535
gc 0
Train Epoch36 Acc 0.97545 (39018/40000), AUC 0.9958255290985107
ep36_train_time 23.384202108000068
Test Epoch36 layer0 Acc 0.695, AUC 0.7613967657089233, avg_entr 0.1666773557662964, f1 0.6949999928474426
ep36_l0_test_time 0.3057184250000091
Test Epoch36 layer1 Acc 0.7032, AUC 0.7867452502250671, avg_entr 0.06559403985738754, f1 0.7031999826431274
ep36_l1_test_time 0.37992271599989635
Test Epoch36 layer2 Acc 0.7328, AUC 0.788308322429657, avg_entr 0.04342970624566078, f1 0.7327999472618103
ep36_l2_test_time 0.48966687699999056
Test Epoch36 layer3 Acc 0.733, AUC 0.8085774183273315, avg_entr 0.03999464586377144, f1 0.7329999804496765
ep36_l3_test_time 0.6396779579999929
Test Epoch36 layer4 Acc 0.7334, AUC 0.8088266849517822, avg_entr 0.037780601531267166, f1 0.7333999872207642
ep36_l4_test_time 0.8327156189999414
gc 0
Train Epoch37 Acc 0.976425 (39057/40000), AUC 0.9963717460632324
ep37_train_time 23.3917893549999
Test Epoch37 layer0 Acc 0.693, AUC 0.7611352205276489, avg_entr 0.16560298204421997, f1 0.6930000185966492
ep37_l0_test_time 0.30559242399999675
Test Epoch37 layer1 Acc 0.7056, AUC 0.786998987197876, avg_entr 0.06641602516174316, f1 0.7056000232696533
ep37_l1_test_time 0.37988185599999724
Test Epoch37 layer2 Acc 0.7304, AUC 0.7896074652671814, avg_entr 0.04463893920183182, f1 0.7304000854492188
ep37_l2_test_time 0.48861992999991344
Test Epoch37 layer3 Acc 0.7338, AUC 0.8091094493865967, avg_entr 0.04064061492681503, f1 0.7338000535964966
ep37_l3_test_time 0.6386946189999207
Test Epoch37 layer4 Acc 0.7334, AUC 0.8095368146896362, avg_entr 0.03837214782834053, f1 0.7333999872207642
ep37_l4_test_time 0.8318215030000147
gc 0
Train Epoch38 Acc 0.97655 (39062/40000), AUC 0.9963381290435791
ep38_train_time 23.41672705299993
Test Epoch38 layer0 Acc 0.6932, AUC 0.7609966397285461, avg_entr 0.16443946957588196, f1 0.6931999921798706
ep38_l0_test_time 0.30612113100005445
Test Epoch38 layer1 Acc 0.7048, AUC 0.7865089178085327, avg_entr 0.06587384641170502, f1 0.704800009727478
ep38_l1_test_time 0.3794216050000614
Test Epoch38 layer2 Acc 0.7308, AUC 0.7880278825759888, avg_entr 0.04543227702379227, f1 0.7307999730110168
ep38_l2_test_time 0.4888226840000698
Test Epoch38 layer3 Acc 0.7314, AUC 0.8090535402297974, avg_entr 0.041799817234277725, f1 0.7314000129699707
ep38_l3_test_time 0.6398787570001332
Test Epoch38 layer4 Acc 0.7328, AUC 0.8094677329063416, avg_entr 0.03932086005806923, f1 0.7327999472618103
ep38_l4_test_time 0.8331906190001064
gc 0
Train Epoch39 Acc 0.9768 (39072/40000), AUC 0.9964603185653687
ep39_train_time 23.396947156999886
Test Epoch39 layer0 Acc 0.6922, AUC 0.7606830596923828, avg_entr 0.16439910233020782, f1 0.6922000050544739
ep39_l0_test_time 0.30566206999992573
Test Epoch39 layer1 Acc 0.7046, AUC 0.7861381769180298, avg_entr 0.06518606096506119, f1 0.7045999765396118
ep39_l1_test_time 0.3794206799998392
Test Epoch39 layer2 Acc 0.7298, AUC 0.7878180742263794, avg_entr 0.04436449706554413, f1 0.7297999858856201
ep39_l2_test_time 0.48910437800009277
Test Epoch39 layer3 Acc 0.732, AUC 0.8088247776031494, avg_entr 0.04183574393391609, f1 0.7319999933242798
ep39_l3_test_time 0.6384305100000347
Test Epoch39 layer4 Acc 0.7314, AUC 0.809339165687561, avg_entr 0.03926682844758034, f1 0.7314000129699707
ep39_l4_test_time 0.8322560919998523
gc 0
Train Epoch40 Acc 0.97735 (39094/40000), AUC 0.9968479871749878
ep40_train_time 23.42465974200013
Test Epoch40 layer0 Acc 0.6938, AUC 0.7607329487800598, avg_entr 0.16362982988357544, f1 0.6937999725341797
ep40_l0_test_time 0.30534770100007336
Test Epoch40 layer1 Acc 0.704, AUC 0.7857931852340698, avg_entr 0.06450676172971725, f1 0.7039999961853027
ep40_l1_test_time 0.37979783200012207
Test Epoch40 layer2 Acc 0.729, AUC 0.7863216400146484, avg_entr 0.04414115473628044, f1 0.7289999723434448
ep40_l2_test_time 0.4888488190001681
Test Epoch40 layer3 Acc 0.7326, AUC 0.8075861930847168, avg_entr 0.040123213082551956, f1 0.7325999140739441
ep40_l3_test_time 0.6368068829999629
Test Epoch40 layer4 Acc 0.732, AUC 0.8082756996154785, avg_entr 0.03764883428812027, f1 0.7319999933242798
ep40_l4_test_time 0.8321119449999514
gc 0
Train Epoch41 Acc 0.97675 (39070/40000), AUC 0.9964328408241272
ep41_train_time 23.435440488999802
Test Epoch41 layer0 Acc 0.6934, AUC 0.7606319785118103, avg_entr 0.1638137251138687, f1 0.6934000253677368
ep41_l0_test_time 0.30752692300006856
Test Epoch41 layer1 Acc 0.7046, AUC 0.7859548330307007, avg_entr 0.0645771473646164, f1 0.7045999765396118
ep41_l1_test_time 0.38769335099982527
Test Epoch41 layer2 Acc 0.7306, AUC 0.7878822088241577, avg_entr 0.04513527452945709, f1 0.7305999994277954
ep41_l2_test_time 0.4900882970000566
Test Epoch41 layer3 Acc 0.7312, AUC 0.808201253414154, avg_entr 0.04159792885184288, f1 0.7311999797821045
ep41_l3_test_time 0.6389337650000471
Test Epoch41 layer4 Acc 0.7316, AUC 0.8087581396102905, avg_entr 0.03913233429193497, f1 0.7316000461578369
ep41_l4_test_time 0.8321671140001854
gc 0
Train Epoch42 Acc 0.976975 (39079/40000), AUC 0.9963905215263367
ep42_train_time 23.399982292999994
Test Epoch42 layer0 Acc 0.6934, AUC 0.760810136795044, avg_entr 0.16415712237358093, f1 0.6934000253677368
ep42_l0_test_time 0.3065339480001512
Test Epoch42 layer1 Acc 0.7032, AUC 0.7857903242111206, avg_entr 0.06351307034492493, f1 0.7031999826431274
ep42_l1_test_time 0.3788105200001155
Test Epoch42 layer2 Acc 0.7296, AUC 0.7857980728149414, avg_entr 0.043774399906396866, f1 0.7295999526977539
ep42_l2_test_time 0.4887695959998837
Test Epoch42 layer3 Acc 0.731, AUC 0.8069961071014404, avg_entr 0.04009745642542839, f1 0.7310000061988831
ep42_l3_test_time 0.6381580570000551
Test Epoch42 layer4 Acc 0.7312, AUC 0.8077458143234253, avg_entr 0.03772272914648056, f1 0.7311999797821045
ep42_l4_test_time 0.8320516159999443
gc 0
Train Epoch43 Acc 0.977775 (39111/40000), AUC 0.9968417882919312
ep43_train_time 23.42558893599994
Test Epoch43 layer0 Acc 0.6932, AUC 0.7607430219650269, avg_entr 0.16378265619277954, f1 0.6931999921798706
ep43_l0_test_time 0.3063148670000828
Test Epoch43 layer1 Acc 0.7026, AUC 0.785598635673523, avg_entr 0.06334643065929413, f1 0.7026000022888184
ep43_l1_test_time 0.3796916029998556
Test Epoch43 layer2 Acc 0.7296, AUC 0.7865610122680664, avg_entr 0.04274827614426613, f1 0.7295999526977539
ep43_l2_test_time 0.48987185300006786
Test Epoch43 layer3 Acc 0.7312, AUC 0.8073761463165283, avg_entr 0.03988732397556305, f1 0.7311999797821045
ep43_l3_test_time 0.6376228070000707
Test Epoch43 layer4 Acc 0.731, AUC 0.808061420917511, avg_entr 0.03737494349479675, f1 0.7310000061988831
ep43_l4_test_time 0.8314252689999648
gc 0
Train Epoch44 Acc 0.9771 (39084/40000), AUC 0.9964581727981567
ep44_train_time 23.394175962999952
Test Epoch44 layer0 Acc 0.6938, AUC 0.7607446908950806, avg_entr 0.16357283294200897, f1 0.6937999725341797
ep44_l0_test_time 0.31153602099993805
Test Epoch44 layer1 Acc 0.7044, AUC 0.7859139442443848, avg_entr 0.06372767686843872, f1 0.7044000029563904
ep44_l1_test_time 0.3799515359999077
Test Epoch44 layer2 Acc 0.7302, AUC 0.7859125137329102, avg_entr 0.04375586658716202, f1 0.7301999926567078
ep44_l2_test_time 0.48987566400001015
Test Epoch44 layer3 Acc 0.7306, AUC 0.8070765733718872, avg_entr 0.03992370516061783, f1 0.7305999994277954
ep44_l3_test_time 0.6387144210000315
Test Epoch44 layer4 Acc 0.7314, AUC 0.8080707788467407, avg_entr 0.03747912496328354, f1 0.7314000129699707
ep44_l4_test_time 0.8326348129999133
gc 0
Train Epoch45 Acc 0.97745 (39098/40000), AUC 0.9963710308074951
ep45_train_time 23.43643929399991
Test Epoch45 layer0 Acc 0.6942, AUC 0.760751485824585, avg_entr 0.16380280256271362, f1 0.6941999793052673
ep45_l0_test_time 0.30592060100002527
Test Epoch45 layer1 Acc 0.7036, AUC 0.7855898141860962, avg_entr 0.06344860792160034, f1 0.7035999894142151
ep45_l1_test_time 0.378167828000187
Test Epoch45 layer2 Acc 0.7288, AUC 0.7854101657867432, avg_entr 0.04350384324789047, f1 0.7287999987602234
ep45_l2_test_time 0.48781957000005605
Test Epoch45 layer3 Acc 0.7318, AUC 0.8065487742424011, avg_entr 0.039383865892887115, f1 0.7318000197410583
ep45_l3_test_time 0.6377345650000734
Test Epoch45 layer4 Acc 0.7316, AUC 0.8076404333114624, avg_entr 0.03683241456747055, f1 0.7316000461578369
ep45_l4_test_time 0.83388472799993
gc 0
Train Epoch46 Acc 0.97755 (39102/40000), AUC 0.9967472553253174
ep46_train_time 23.406494803999976
Test Epoch46 layer0 Acc 0.6926, AUC 0.7606924772262573, avg_entr 0.16366513073444366, f1 0.6926000118255615
ep46_l0_test_time 0.30663719700010006
Test Epoch46 layer1 Acc 0.704, AUC 0.7856032848358154, avg_entr 0.06292486190795898, f1 0.7039999961853027
ep46_l1_test_time 0.37946603099999265
Test Epoch46 layer2 Acc 0.7298, AUC 0.7857135534286499, avg_entr 0.04319022223353386, f1 0.7297999858856201
ep46_l2_test_time 0.489174420000154
Test Epoch46 layer3 Acc 0.7302, AUC 0.8065880537033081, avg_entr 0.03920069709420204, f1 0.7301999926567078
ep46_l3_test_time 0.6380502409999735
Test Epoch46 layer4 Acc 0.7308, AUC 0.8075158596038818, avg_entr 0.03662834316492081, f1 0.7307999730110168
ep46_l4_test_time 0.8341739120000966
gc 0
Train Epoch47 Acc 0.978225 (39129/40000), AUC 0.9965382218360901
ep47_train_time 23.40172001199994
Test Epoch47 layer0 Acc 0.6936, AUC 0.760716438293457, avg_entr 0.16366371512413025, f1 0.6935999989509583
ep47_l0_test_time 0.3076431719998709
Test Epoch47 layer1 Acc 0.7038, AUC 0.7855623960494995, avg_entr 0.06321925669908524, f1 0.7038000226020813
ep47_l1_test_time 0.3808500749998984
Test Epoch47 layer2 Acc 0.7308, AUC 0.7859760522842407, avg_entr 0.04357055947184563, f1 0.7307999730110168
ep47_l2_test_time 0.48992251399999986
Test Epoch47 layer3 Acc 0.7302, AUC 0.8068897724151611, avg_entr 0.039612483233213425, f1 0.7301999926567078
ep47_l3_test_time 0.6380623560000913
Test Epoch47 layer4 Acc 0.7314, AUC 0.8077691793441772, avg_entr 0.037042614072561264, f1 0.7314000129699707
ep47_l4_test_time 0.8329806799999915
gc 0
Train Epoch48 Acc 0.97805 (39122/40000), AUC 0.9964906573295593
ep48_train_time 23.413887264000095
Test Epoch48 layer0 Acc 0.6948, AUC 0.7606635689735413, avg_entr 0.16391237080097198, f1 0.6948000192642212
ep48_l0_test_time 0.30711733900011495
Test Epoch48 layer1 Acc 0.7032, AUC 0.7856365442276001, avg_entr 0.06387828290462494, f1 0.7031999826431274
ep48_l1_test_time 0.38282708099995943
Test Epoch48 layer2 Acc 0.7306, AUC 0.7862756252288818, avg_entr 0.04409630224108696, f1 0.7305999994277954
ep48_l2_test_time 0.4889874900002269
Test Epoch48 layer3 Acc 0.7318, AUC 0.8066794276237488, avg_entr 0.03977106511592865, f1 0.7318000197410583
ep48_l3_test_time 0.6374218440000732
Test Epoch48 layer4 Acc 0.7334, AUC 0.8078405857086182, avg_entr 0.03743821009993553, f1 0.7333999872207642
ep48_l4_test_time 0.8327154860000974
gc 0
Train Epoch49 Acc 0.9775 (39100/40000), AUC 0.9966736435890198
ep49_train_time 23.40641515099992
Test Epoch49 layer0 Acc 0.6932, AUC 0.7606618404388428, avg_entr 0.16357140243053436, f1 0.6931999921798706
ep49_l0_test_time 0.3078980430000229
Test Epoch49 layer1 Acc 0.7044, AUC 0.7857276201248169, avg_entr 0.06355589628219604, f1 0.7044000029563904
ep49_l1_test_time 0.38150386999996044
Test Epoch49 layer2 Acc 0.7302, AUC 0.7862895131111145, avg_entr 0.043677788227796555, f1 0.7301999926567078
ep49_l2_test_time 0.491073914000026
Test Epoch49 layer3 Acc 0.7312, AUC 0.8068739175796509, avg_entr 0.0397799089550972, f1 0.7311999797821045
ep49_l3_test_time 0.638812173000133
Test Epoch49 layer4 Acc 0.7318, AUC 0.8078588247299194, avg_entr 0.037325598299503326, f1 0.7318000197410583
ep49_l4_test_time 0.8329453590001776
Best AUC tensor(0.7694) 9 3
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
total_train+valid_time 1310.65421021
Start Testing
Load ckpt at ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt
gc 9
Test layer0 Acc 0.7062, AUC 0.7984123826026917, avg_entr 0.295851469039917, f1 0.7062000036239624
l0_test_time 0.3060757390001072
gc 0
Test layer1 Acc 0.7484, AUC 0.8335443735122681, avg_entr 0.25147339701652527, f1 0.7483999729156494
l1_test_time 0.3808317610000813
gc 0
Test layer2 Acc 0.7652, AUC 0.8474426865577698, avg_entr 0.22374780476093292, f1 0.7652000188827515
l2_test_time 0.4905229999999392
gc 0
Test layer3 Acc 0.7642, AUC 0.8495780229568481, avg_entr 0.21179918944835663, f1 0.76419997215271
l3_test_time 0.6397230320001199
gc 0
Test layer4 Acc 0.7658, AUC 0.8505065441131592, avg_entr 0.19374260306358337, f1 0.7657999992370605
l4_test_time 0.8334470629999942
gc 0
Test threshold 0.1 Acc 0.7658, AUC 0.8442749977111816, avg_entr 0.2747463881969452, f1 0.7657999992370605
t0.1_test_time 0.7039149409999936
gc 0
Test threshold 0.2 Acc 0.7644, AUC 0.838085949420929, avg_entr 0.27578458189964294, f1 0.7644000053405762
t0.2_test_time 0.6221051390000412
gc 0
Test threshold 0.3 Acc 0.7642, AUC 0.8333766460418701, avg_entr 0.2818393409252167, f1 0.76419997215271
t0.3_test_time 0.5753798880000431
gc 0
Test threshold 0.4 Acc 0.7628, AUC 0.8310432434082031, avg_entr 0.289210706949234, f1 0.7627999782562256
t0.4_test_time 0.5350990550000461
gc 0
Test threshold 0.5 Acc 0.7614, AUC 0.8246298432350159, avg_entr 0.29998424649238586, f1 0.7613999843597412
t0.5_test_time 0.4995268569998643
gc 0
Test threshold 0.6 Acc 0.7554, AUC 0.8196837902069092, avg_entr 0.31201043725013733, f1 0.7554000020027161
t0.6_test_time 0.46667836599999646
gc 0
Test threshold 0.7 Acc 0.749, AUC 0.8182241916656494, avg_entr 0.32683271169662476, f1 0.7490000128746033
t0.7_test_time 0.436464720999993
gc 0
Test threshold 0.8 Acc 0.7426, AUC 0.8127456903457642, avg_entr 0.344833105802536, f1 0.7426000237464905
t0.8_test_time 0.4099453070000436
gc 0
Test threshold 0.9 Acc 0.7362, AUC 0.8087127208709717, avg_entr 0.3717380464076996, f1 0.7361999750137329
t0.9_test_time 0.38887799999997696
