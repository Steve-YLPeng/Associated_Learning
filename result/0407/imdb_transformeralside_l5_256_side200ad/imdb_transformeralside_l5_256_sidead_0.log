total count words 222751
vocab size 30000
train size 40000, valid size 5000, test size 5000
found 27937 words in glove
model: TransformerALsideText(
  (layers): ModuleList(
    (0): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=2, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=2, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
  (emb_layers): ModuleList(
    (0): Embedding(30000, 300)
    (1): Embedding(30000, 300)
    (2): Embedding(30000, 300)
    (3): Embedding(30000, 300)
    (4): Embedding(30000, 300)
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.multi_headed_attention.linears.0.weight 90000
layers.0.enc.f.multi_headed_attention.linears.0.bias 300
layers.0.enc.f.multi_headed_attention.linears.1.weight 90000
layers.0.enc.f.multi_headed_attention.linears.1.bias 300
layers.0.enc.f.multi_headed_attention.linears.2.weight 90000
layers.0.enc.f.multi_headed_attention.linears.2.bias 300
layers.0.enc.f.multi_headed_attention.linears.3.weight 90000
layers.0.enc.f.multi_headed_attention.linears.3.bias 300
layers.0.enc.f.feed_forward.w_1.weight 90000
layers.0.enc.f.feed_forward.w_1.bias 300
layers.0.enc.f.feed_forward.w_2.weight 90000
layers.0.enc.f.feed_forward.w_2.bias 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.0.enc.f.encoder.norm.a 300
layers.0.enc.f.encoder.norm.b 300
layers.0.ae.g.0.weight 256
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 256
layers.0.ae.h.0.bias 2
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
emb_layers.0.weight 9000000
emb_layers.1.weight 9000000
emb_layers.2.weight 9000000
emb_layers.3.weight 9000000
emb_layers.4.weight 9000000
Total Trainable Params: 50758378
init_time 22.61329197
Start Training
gc 0
Train Epoch0 Acc 0.503025 (20121/40000), AUC 0.5045163631439209
ep0_train_time 23.713784156000003
Test Epoch0 layer0 Acc 0.5594, AUC 0.5790632367134094, avg_entr 0.6917266249656677, f1 0.5594000220298767
ep0_l0_test_time 0.306677901999997
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 0
Test Epoch0 layer1 Acc 0.5104, AUC 0.5085047483444214, avg_entr 0.6941266059875488, f1 0.5103999972343445
ep0_l1_test_time 0.37929247499999974
Test Epoch0 layer2 Acc 0.5144, AUC 0.5320399403572083, avg_entr 0.6965804100036621, f1 0.5144000053405762
ep0_l2_test_time 0.48833230600000377
Test Epoch0 layer3 Acc 0.501, AUC 0.5144174098968506, avg_entr 0.6916484832763672, f1 0.5009999871253967
ep0_l3_test_time 0.6373988110000042
Test Epoch0 layer4 Acc 0.5058, AUC 0.5042279958724976, avg_entr 0.6903652548789978, f1 0.5058000087738037
ep0_l4_test_time 0.8280659699999973
gc 0
Train Epoch1 Acc 0.5115 (20460/40000), AUC 0.5161632299423218
ep1_train_time 23.30630739699999
Test Epoch1 layer0 Acc 0.593, AUC 0.6289103627204895, avg_entr 0.6512119770050049, f1 0.5929999947547913
ep1_l0_test_time 0.3081378199999989
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 1
Test Epoch1 layer1 Acc 0.5766, AUC 0.6341582536697388, avg_entr 0.6806392669677734, f1 0.5766000151634216
ep1_l1_test_time 0.3791877300000124
Test Epoch1 layer2 Acc 0.517, AUC 0.5941017270088196, avg_entr 0.6898382306098938, f1 0.5170000195503235
ep1_l2_test_time 0.4880487109999905
Test Epoch1 layer3 Acc 0.5156, AUC 0.57082200050354, avg_entr 0.6920264363288879, f1 0.5156000256538391
ep1_l3_test_time 0.6378071999999975
Test Epoch1 layer4 Acc 0.4998, AUC 0.4703214168548584, avg_entr 0.6958652138710022, f1 0.4997999966144562
ep1_l4_test_time 0.8298471519999993
gc 0
Train Epoch2 Acc 0.517875 (20715/40000), AUC 0.5260230302810669
ep2_train_time 23.353406092
Test Epoch2 layer0 Acc 0.6306, AUC 0.7094056010246277, avg_entr 0.5270041823387146, f1 0.6305999755859375
ep2_l0_test_time 0.3078556589999977
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 2
Test Epoch2 layer1 Acc 0.6016, AUC 0.7317348718643188, avg_entr 0.41045820713043213, f1 0.6015999913215637
ep2_l1_test_time 0.3909233849999936
Test Epoch2 layer2 Acc 0.585, AUC 0.7321195006370544, avg_entr 0.4165748953819275, f1 0.5849999785423279
ep2_l2_test_time 0.4916640250000057
Test Epoch2 layer3 Acc 0.5886, AUC 0.701850414276123, avg_entr 0.5346271991729736, f1 0.5885999798774719
ep2_l3_test_time 0.6402356920000045
Test Epoch2 layer4 Acc 0.5, AUC 0.6699809432029724, avg_entr 0.6521453857421875, f1 0.5
ep2_l4_test_time 0.831593380000001
gc 0
Train Epoch3 Acc 0.61765 (24706/40000), AUC 0.6621481776237488
ep3_train_time 23.378984593000013
Test Epoch3 layer0 Acc 0.6702, AUC 0.7425609230995178, avg_entr 0.49923384189605713, f1 0.670199990272522
ep3_l0_test_time 0.3068348070000013
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer1 Acc 0.6886, AUC 0.7627602815628052, avg_entr 0.470426470041275, f1 0.6886000037193298
ep3_l1_test_time 0.38034700000000043
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer2 Acc 0.6836, AUC 0.766264796257019, avg_entr 0.46534618735313416, f1 0.6836000084877014
ep3_l2_test_time 0.4893012459999966
Test Epoch3 layer3 Acc 0.6772, AUC 0.7559547424316406, avg_entr 0.4799843728542328, f1 0.6772000193595886
ep3_l3_test_time 0.6382967030000088
Test Epoch3 layer4 Acc 0.6236, AUC 0.7459665536880493, avg_entr 0.4828721582889557, f1 0.6236000061035156
ep3_l4_test_time 0.8303427339999985
gc 0
Train Epoch4 Acc 0.66505 (26602/40000), AUC 0.7225624918937683
ep4_train_time 23.35464752300001
Test Epoch4 layer0 Acc 0.691, AUC 0.7628892660140991, avg_entr 0.4352853000164032, f1 0.6909999847412109
ep4_l0_test_time 0.30884030000001417
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
Test Epoch4 layer1 Acc 0.7024, AUC 0.787145733833313, avg_entr 0.3963945806026459, f1 0.7024000287055969
ep4_l1_test_time 0.3822329780000189
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
Test Epoch4 layer2 Acc 0.711, AUC 0.797737181186676, avg_entr 0.40172791481018066, f1 0.7110000848770142
ep4_l2_test_time 0.49150447700000655
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
Test Epoch4 layer3 Acc 0.708, AUC 0.791048526763916, avg_entr 0.4574882686138153, f1 0.7080000638961792
ep4_l3_test_time 0.6393284259999916
Test Epoch4 layer4 Acc 0.7112, AUC 0.7806473970413208, avg_entr 0.4998437464237213, f1 0.7111999988555908
ep4_l4_test_time 0.8311958310000023
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
gc 0
Train Epoch5 Acc 0.685675 (27427/40000), AUC 0.7486791610717773
ep5_train_time 23.403547886000013
Test Epoch5 layer0 Acc 0.6804, AUC 0.7692582607269287, avg_entr 0.360021710395813, f1 0.680400013923645
ep5_l0_test_time 0.307836175999995
Test Epoch5 layer1 Acc 0.6854, AUC 0.7938889265060425, avg_entr 0.29191383719444275, f1 0.6854000091552734
ep5_l1_test_time 0.37916734199998814
Test Epoch5 layer2 Acc 0.6986, AUC 0.8060806393623352, avg_entr 0.32625365257263184, f1 0.6985999941825867
ep5_l2_test_time 0.48892537999998353
Test Epoch5 layer3 Acc 0.7046, AUC 0.800995409488678, avg_entr 0.37572938203811646, f1 0.7045999765396118
ep5_l3_test_time 0.6388901019999764
Test Epoch5 layer4 Acc 0.7112, AUC 0.7926746606826782, avg_entr 0.4059770107269287, f1 0.7111999988555908
ep5_l4_test_time 0.8312169229999995
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 5
gc 0
Train Epoch6 Acc 0.716325 (28653/40000), AUC 0.7891348600387573
ep6_train_time 23.365340576000023
Test Epoch6 layer0 Acc 0.6802, AUC 0.7768908739089966, avg_entr 0.36747294664382935, f1 0.6801999807357788
ep6_l0_test_time 0.3082273280000152
Test Epoch6 layer1 Acc 0.7164, AUC 0.8066732883453369, avg_entr 0.3364666998386383, f1 0.7164000272750854
ep6_l1_test_time 0.3824568320000026
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer2 Acc 0.7272, AUC 0.8219523429870605, avg_entr 0.31760382652282715, f1 0.7271999716758728
ep6_l2_test_time 0.4903210749999971
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer3 Acc 0.7216, AUC 0.81855309009552, avg_entr 0.3132111132144928, f1 0.7215999960899353
ep6_l3_test_time 0.63957521399999
Test Epoch6 layer4 Acc 0.712, AUC 0.8122721910476685, avg_entr 0.3187786936759949, f1 0.7120000123977661
ep6_l4_test_time 0.8345151720000104
gc 0
Train Epoch7 Acc 0.741775 (29671/40000), AUC 0.8201847672462463
ep7_train_time 23.363921054000002
Test Epoch7 layer0 Acc 0.6904, AUC 0.780131459236145, avg_entr 0.32435837388038635, f1 0.6904000043869019
ep7_l0_test_time 0.30929447899998763
Test Epoch7 layer1 Acc 0.7054, AUC 0.8113098740577698, avg_entr 0.29192057251930237, f1 0.7053999900817871
ep7_l1_test_time 0.38171616799999697
Test Epoch7 layer2 Acc 0.7206, AUC 0.8355949521064758, avg_entr 0.3201178014278412, f1 0.7206000685691833
ep7_l2_test_time 0.4915453110000101
Test Epoch7 layer3 Acc 0.7198, AUC 0.8338228464126587, avg_entr 0.3732268214225769, f1 0.7197999358177185
ep7_l3_test_time 0.6389207889999966
Test Epoch7 layer4 Acc 0.728, AUC 0.8292748928070068, avg_entr 0.443575382232666, f1 0.7279999852180481
ep7_l4_test_time 0.8319206079999901
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 7
gc 0
Train Epoch8 Acc 0.771825 (30873/40000), AUC 0.854347288608551
ep8_train_time 23.390670917000023
Test Epoch8 layer0 Acc 0.7054, AUC 0.7895453572273254, avg_entr 0.32004570960998535, f1 0.7053999900817871
ep8_l0_test_time 0.30846064600001455
Test Epoch8 layer1 Acc 0.7426, AUC 0.8237995505332947, avg_entr 0.27896177768707275, f1 0.7426000237464905
ep8_l1_test_time 0.38046275600004265
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 8
Test Epoch8 layer2 Acc 0.7608, AUC 0.8458216190338135, avg_entr 0.2781704068183899, f1 0.7608000040054321
ep8_l2_test_time 0.4935637820000238
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 8
Test Epoch8 layer3 Acc 0.7604, AUC 0.8460901975631714, avg_entr 0.2830178141593933, f1 0.7603999972343445
ep8_l3_test_time 0.6456855949999749
Test Epoch8 layer4 Acc 0.7576, AUC 0.8450101613998413, avg_entr 0.2832666039466858, f1 0.7576000690460205
ep8_l4_test_time 0.8376250590000041
gc 0
Train Epoch9 Acc 0.7876 (31504/40000), AUC 0.8686070442199707
ep9_train_time 23.400670453999965
Test Epoch9 layer0 Acc 0.7036, AUC 0.7925323843955994, avg_entr 0.307557612657547, f1 0.7035999894142151
ep9_l0_test_time 0.3081628799999976
Test Epoch9 layer1 Acc 0.7258, AUC 0.8222407698631287, avg_entr 0.2621644139289856, f1 0.7257999777793884
ep9_l1_test_time 0.38067242900001474
Test Epoch9 layer2 Acc 0.7442, AUC 0.8457223176956177, avg_entr 0.25311729311943054, f1 0.7441999316215515
ep9_l2_test_time 0.4901380569999674
Test Epoch9 layer3 Acc 0.7388, AUC 0.8462623357772827, avg_entr 0.2496931403875351, f1 0.7387999892234802
ep9_l3_test_time 0.6398875670000166
Test Epoch9 layer4 Acc 0.7326, AUC 0.846384584903717, avg_entr 0.2378058135509491, f1 0.7325999140739441
ep9_l4_test_time 0.831705822999993
gc 0
Train Epoch10 Acc 0.804875 (32195/40000), AUC 0.8856313228607178
ep10_train_time 23.391815263000012
Test Epoch10 layer0 Acc 0.6926, AUC 0.7933499217033386, avg_entr 0.2739658057689667, f1 0.6926000118255615
ep10_l0_test_time 0.3085175260000028
Test Epoch10 layer1 Acc 0.7284, AUC 0.8222852349281311, avg_entr 0.2599477767944336, f1 0.7284000515937805
ep10_l1_test_time 0.380731892999961
Test Epoch10 layer2 Acc 0.7512, AUC 0.8445523977279663, avg_entr 0.23912839591503143, f1 0.7512000203132629
ep10_l2_test_time 0.4901907870000173
Test Epoch10 layer3 Acc 0.7508, AUC 0.8449567556381226, avg_entr 0.20680712163448334, f1 0.7508000135421753
ep10_l3_test_time 0.6401296329999582
Test Epoch10 layer4 Acc 0.751, AUC 0.8450506329536438, avg_entr 0.18500427901744843, f1 0.7509999871253967
ep10_l4_test_time 0.8339660860000322
gc 0
Train Epoch11 Acc 0.820475 (32819/40000), AUC 0.8960570096969604
ep11_train_time 23.392750428
Test Epoch11 layer0 Acc 0.7142, AUC 0.7955505847930908, avg_entr 0.26316529512405396, f1 0.7142000198364258
ep11_l0_test_time 0.31207056099998454
Test Epoch11 layer1 Acc 0.728, AUC 0.8235942125320435, avg_entr 0.2120313048362732, f1 0.7279999852180481
ep11_l1_test_time 0.38243783699999767
Test Epoch11 layer2 Acc 0.745, AUC 0.847956657409668, avg_entr 0.19373507797718048, f1 0.7449999451637268
ep11_l2_test_time 0.4934476399999994
Test Epoch11 layer3 Acc 0.7442, AUC 0.8491889834403992, avg_entr 0.14791887998580933, f1 0.7441999316215515
ep11_l3_test_time 0.6399496610000028
Test Epoch11 layer4 Acc 0.744, AUC 0.8491283655166626, avg_entr 0.12622924149036407, f1 0.7439999580383301
ep11_l4_test_time 0.8332963660000132
gc 0
Train Epoch12 Acc 0.8478 (33912/40000), AUC 0.9216009378433228
ep12_train_time 23.38231824099995
Test Epoch12 layer0 Acc 0.7138, AUC 0.79219651222229, avg_entr 0.24478302896022797, f1 0.7138000130653381
ep12_l0_test_time 0.3093763249999597
Test Epoch12 layer1 Acc 0.7332, AUC 0.8212352395057678, avg_entr 0.20146732032299042, f1 0.7332000136375427
ep12_l1_test_time 0.3804213190000496
Test Epoch12 layer2 Acc 0.757, AUC 0.8474462032318115, avg_entr 0.18157006800174713, f1 0.7570000886917114
ep12_l2_test_time 0.4893185120000112
Test Epoch12 layer3 Acc 0.7606, AUC 0.8501161932945251, avg_entr 0.13642340898513794, f1 0.7605999708175659
ep12_l3_test_time 0.6475697430000196
Test Epoch12 layer4 Acc 0.7634, AUC 0.851384162902832, avg_entr 0.13305450975894928, f1 0.7634000182151794
ep12_l4_test_time 0.8460515639999926
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 12
gc 0
Train Epoch13 Acc 0.8684 (34736/40000), AUC 0.937304675579071
ep13_train_time 23.6759237
Test Epoch13 layer0 Acc 0.7146, AUC 0.7893284559249878, avg_entr 0.24632714688777924, f1 0.7146000266075134
ep13_l0_test_time 0.32490595800004485
Test Epoch13 layer1 Acc 0.7398, AUC 0.8222203850746155, avg_entr 0.20460912585258484, f1 0.7398000359535217
ep13_l1_test_time 0.3887161789999709
Test Epoch13 layer2 Acc 0.7622, AUC 0.846764087677002, avg_entr 0.17778781056404114, f1 0.7621999979019165
ep13_l2_test_time 0.49467677199999116
Test Epoch13 layer3 Acc 0.7644, AUC 0.8501744866371155, avg_entr 0.12814751267433167, f1 0.7644000053405762
ep13_l3_test_time 0.6496973320000166
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 13
Test Epoch13 layer4 Acc 0.7654, AUC 0.8514003157615662, avg_entr 0.12548406422138214, f1 0.7653999924659729
ep13_l4_test_time 0.8377774909999971
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 13
gc 0
Train Epoch14 Acc 0.88475 (35390/40000), AUC 0.9514020681381226
ep14_train_time 23.84588698799996
Test Epoch14 layer0 Acc 0.7074, AUC 0.782694399356842, avg_entr 0.23223139345645905, f1 0.7074000239372253
ep14_l0_test_time 0.31245457299996815
Test Epoch14 layer1 Acc 0.7356, AUC 0.8148547410964966, avg_entr 0.18686574697494507, f1 0.7355999946594238
ep14_l1_test_time 0.3866448189999687
Test Epoch14 layer2 Acc 0.7584, AUC 0.83823561668396, avg_entr 0.1473664790391922, f1 0.758400022983551
ep14_l2_test_time 0.5026986950000492
Test Epoch14 layer3 Acc 0.7612, AUC 0.8441104888916016, avg_entr 0.11089487373828888, f1 0.7612000107765198
ep14_l3_test_time 0.6526184410000155
Test Epoch14 layer4 Acc 0.7622, AUC 0.8453813791275024, avg_entr 0.108195461332798, f1 0.7621999979019165
ep14_l4_test_time 0.848551160999989
gc 0
Train Epoch15 Acc 0.894125 (35765/40000), AUC 0.9534936547279358
ep15_train_time 24.020891894000044
Test Epoch15 layer0 Acc 0.7134, AUC 0.7833573818206787, avg_entr 0.21581852436065674, f1 0.7134000062942505
ep15_l0_test_time 0.31738279299997885
Test Epoch15 layer1 Acc 0.7358, AUC 0.8121256232261658, avg_entr 0.1671004444360733, f1 0.73580002784729
ep15_l1_test_time 0.38777765300000056
Test Epoch15 layer2 Acc 0.7484, AUC 0.8321529030799866, avg_entr 0.11717807501554489, f1 0.7483999729156494
ep15_l2_test_time 0.4981593879999764
Test Epoch15 layer3 Acc 0.754, AUC 0.8380086421966553, avg_entr 0.09814455360174179, f1 0.7540000081062317
ep15_l3_test_time 0.6468566170000258
Test Epoch15 layer4 Acc 0.7526, AUC 0.8396983742713928, avg_entr 0.09608396887779236, f1 0.7526000142097473
ep15_l4_test_time 0.8383333719999655
gc 0
Train Epoch16 Acc 0.908225 (36329/40000), AUC 0.9624228477478027
ep16_train_time 23.795684764000043
Test Epoch16 layer0 Acc 0.7098, AUC 0.7809092998504639, avg_entr 0.2133513242006302, f1 0.7098000049591064
ep16_l0_test_time 0.31396192400001155
Test Epoch16 layer1 Acc 0.7316, AUC 0.8075510263442993, avg_entr 0.16236478090286255, f1 0.7316000461578369
ep16_l1_test_time 0.3956454770000164
Test Epoch16 layer2 Acc 0.7452, AUC 0.824289083480835, avg_entr 0.10330060124397278, f1 0.745199978351593
ep16_l2_test_time 0.49513613100003795
Test Epoch16 layer3 Acc 0.7504, AUC 0.8318338394165039, avg_entr 0.08932626247406006, f1 0.7504000067710876
ep16_l3_test_time 0.6481588789999932
Test Epoch16 layer4 Acc 0.7528, AUC 0.8341618180274963, avg_entr 0.08949470520019531, f1 0.7528000473976135
ep16_l4_test_time 0.8356049559999974
gc 0
Train Epoch17 Acc 0.923275 (36931/40000), AUC 0.9758844971656799
ep17_train_time 23.786027183000044
Test Epoch17 layer0 Acc 0.7066, AUC 0.7788773775100708, avg_entr 0.2008238285779953, f1 0.70660001039505
ep17_l0_test_time 0.31254174899999043
Test Epoch17 layer1 Acc 0.7278, AUC 0.8084919452667236, avg_entr 0.1499052494764328, f1 0.7277999520301819
ep17_l1_test_time 0.38538572900000645
Test Epoch17 layer2 Acc 0.7454, AUC 0.8277063369750977, avg_entr 0.09300237149000168, f1 0.745400071144104
ep17_l2_test_time 0.49608499999999367
Test Epoch17 layer3 Acc 0.7552, AUC 0.8336642980575562, avg_entr 0.07894368469715118, f1 0.7552000284194946
ep17_l3_test_time 0.645601892000002
Test Epoch17 layer4 Acc 0.7552, AUC 0.8367182016372681, avg_entr 0.07885996997356415, f1 0.7552000284194946
ep17_l4_test_time 0.8390605450000521
gc 0
Train Epoch18 Acc 0.92955 (37182/40000), AUC 0.9794209003448486
ep18_train_time 23.57891067700001
Test Epoch18 layer0 Acc 0.7088, AUC 0.7742476463317871, avg_entr 0.1962403953075409, f1 0.7088000178337097
ep18_l0_test_time 0.3264388410000265
Test Epoch18 layer1 Acc 0.7236, AUC 0.8010754585266113, avg_entr 0.12739701569080353, f1 0.7236000299453735
ep18_l1_test_time 0.39462638899999547
Test Epoch18 layer2 Acc 0.7384, AUC 0.8163270950317383, avg_entr 0.07570730894804001, f1 0.7384000420570374
ep18_l2_test_time 0.5024173729999575
Test Epoch18 layer3 Acc 0.7462, AUC 0.8232747912406921, avg_entr 0.06931467354297638, f1 0.7462000250816345
ep18_l3_test_time 0.650039445999937
Test Epoch18 layer4 Acc 0.748, AUC 0.8256304264068604, avg_entr 0.06876935809850693, f1 0.7480000257492065
ep18_l4_test_time 0.842362761000004
gc 0
Train Epoch19 Acc 0.93635 (37454/40000), AUC 0.9810155034065247
ep19_train_time 23.521929329000045
Test Epoch19 layer0 Acc 0.7052, AUC 0.7728219032287598, avg_entr 0.19548247754573822, f1 0.7052000164985657
ep19_l0_test_time 0.32102479900004255
Test Epoch19 layer1 Acc 0.7198, AUC 0.7935671806335449, avg_entr 0.1109631136059761, f1 0.7197999358177185
ep19_l1_test_time 0.38435741700004655
Test Epoch19 layer2 Acc 0.7326, AUC 0.8099062442779541, avg_entr 0.07256106287240982, f1 0.7325999140739441
ep19_l2_test_time 0.4994984249999561
Test Epoch19 layer3 Acc 0.7406, AUC 0.8160542249679565, avg_entr 0.06978011131286621, f1 0.7405999302864075
ep19_l3_test_time 0.6431425289999879
Test Epoch19 layer4 Acc 0.7422, AUC 0.8182992339134216, avg_entr 0.0707261711359024, f1 0.7422000169754028
ep19_l4_test_time 0.8399917010000308
gc 0
Train Epoch20 Acc 0.936925 (37477/40000), AUC 0.9804919362068176
ep20_train_time 23.821815377000007
Test Epoch20 layer0 Acc 0.702, AUC 0.7731930613517761, avg_entr 0.18344329297542572, f1 0.7020000219345093
ep20_l0_test_time 0.3285779970000249
Test Epoch20 layer1 Acc 0.7188, AUC 0.7917834520339966, avg_entr 0.1019798070192337, f1 0.7188000082969666
ep20_l1_test_time 0.39744515699999283
Test Epoch20 layer2 Acc 0.7292, AUC 0.8101305961608887, avg_entr 0.06513575464487076, f1 0.7291999459266663
ep20_l2_test_time 0.49926979800000026
Test Epoch20 layer3 Acc 0.735, AUC 0.8140344023704529, avg_entr 0.05893326550722122, f1 0.7350000143051147
ep20_l3_test_time 0.6446356740000283
Test Epoch20 layer4 Acc 0.735, AUC 0.8182190656661987, avg_entr 0.057726118713617325, f1 0.7350000143051147
ep20_l4_test_time 0.8370596629999909
gc 0
Train Epoch21 Acc 0.945625 (37825/40000), AUC 0.9860272407531738
ep21_train_time 23.890205548999916
Test Epoch21 layer0 Acc 0.7042, AUC 0.7717157602310181, avg_entr 0.18843095004558563, f1 0.704200029373169
ep21_l0_test_time 0.3145453909999105
Test Epoch21 layer1 Acc 0.7118, AUC 0.7866487503051758, avg_entr 0.09495485574007034, f1 0.7117999792098999
ep21_l1_test_time 0.38856623499998477
Test Epoch21 layer2 Acc 0.7262, AUC 0.8060156106948853, avg_entr 0.06253056973218918, f1 0.7261999845504761
ep21_l2_test_time 0.49875345899999957
Test Epoch21 layer3 Acc 0.7346, AUC 0.8107346296310425, avg_entr 0.058402758091688156, f1 0.7345999479293823
ep21_l3_test_time 0.6542721990000473
Test Epoch21 layer4 Acc 0.736, AUC 0.8158636093139648, avg_entr 0.05734467878937721, f1 0.7360000014305115
ep21_l4_test_time 0.8400732380000591
gc 0
Train Epoch22 Acc 0.946925 (37877/40000), AUC 0.9868724346160889
ep22_train_time 23.710059204000004
Test Epoch22 layer0 Acc 0.7, AUC 0.7696976661682129, avg_entr 0.18802227079868317, f1 0.699999988079071
ep22_l0_test_time 0.3115425220000816
Test Epoch22 layer1 Acc 0.7134, AUC 0.7828483581542969, avg_entr 0.08717373758554459, f1 0.7134000062942505
ep22_l1_test_time 0.38743096700000024
Test Epoch22 layer2 Acc 0.7302, AUC 0.8054509162902832, avg_entr 0.0634068101644516, f1 0.7301999926567078
ep22_l2_test_time 0.4950036039999759
Test Epoch22 layer3 Acc 0.7328, AUC 0.8090090751647949, avg_entr 0.06195605546236038, f1 0.7327999472618103
ep22_l3_test_time 0.6456350529999781
Test Epoch22 layer4 Acc 0.734, AUC 0.8130872845649719, avg_entr 0.061456628143787384, f1 0.7339999675750732
ep22_l4_test_time 0.8390165220000654
gc 0
Train Epoch23 Acc 0.949675 (37987/40000), AUC 0.9876131415367126
ep23_train_time 23.770741648000012
Test Epoch23 layer0 Acc 0.6966, AUC 0.7686481475830078, avg_entr 0.18186677992343903, f1 0.6966000199317932
ep23_l0_test_time 0.3154616530000567
Test Epoch23 layer1 Acc 0.7154, AUC 0.7826314568519592, avg_entr 0.08291196823120117, f1 0.715399980545044
ep23_l1_test_time 0.38554841800009854
Test Epoch23 layer2 Acc 0.7302, AUC 0.8039877414703369, avg_entr 0.0609089732170105, f1 0.7301999926567078
ep23_l2_test_time 0.4964297300000453
Test Epoch23 layer3 Acc 0.7362, AUC 0.8098063468933105, avg_entr 0.054979003965854645, f1 0.7361999750137329
ep23_l3_test_time 0.6464506229999643
Test Epoch23 layer4 Acc 0.7366, AUC 0.815755307674408, avg_entr 0.05427231267094612, f1 0.7365999817848206
ep23_l4_test_time 0.8390876000000844
gc 0
Train Epoch24 Acc 0.95355 (38142/40000), AUC 0.9888874292373657
ep24_train_time 23.746887974999936
Test Epoch24 layer0 Acc 0.6976, AUC 0.7674108743667603, avg_entr 0.18003463745117188, f1 0.6976000070571899
ep24_l0_test_time 0.3161074329999565
Test Epoch24 layer1 Acc 0.7134, AUC 0.7799254655838013, avg_entr 0.07604897022247314, f1 0.7134000062942505
ep24_l1_test_time 0.39200746099993466
Test Epoch24 layer2 Acc 0.7302, AUC 0.802890419960022, avg_entr 0.0566902831196785, f1 0.7301999926567078
ep24_l2_test_time 0.4999895180000067
Test Epoch24 layer3 Acc 0.7344, AUC 0.807603657245636, avg_entr 0.05150176212191582, f1 0.7343999147415161
ep24_l3_test_time 0.6482278080000015
Test Epoch24 layer4 Acc 0.734, AUC 0.8126228451728821, avg_entr 0.0498509518802166, f1 0.7339999675750732
ep24_l4_test_time 0.8428867630000241
gc 0
Train Epoch25 Acc 0.955975 (38239/40000), AUC 0.990363359451294
ep25_train_time 23.596391275999963
Test Epoch25 layer0 Acc 0.6964, AUC 0.767419695854187, avg_entr 0.17559383809566498, f1 0.696399986743927
ep25_l0_test_time 0.31315596499996445
Test Epoch25 layer1 Acc 0.7074, AUC 0.7773553133010864, avg_entr 0.07055629789829254, f1 0.7074000239372253
ep25_l1_test_time 0.38523644199995033
Test Epoch25 layer2 Acc 0.7274, AUC 0.7996824979782104, avg_entr 0.052893493324518204, f1 0.7274000644683838
ep25_l2_test_time 0.5074452540000038
Test Epoch25 layer3 Acc 0.734, AUC 0.8046706914901733, avg_entr 0.04838227853178978, f1 0.7339999675750732
ep25_l3_test_time 0.6554717100000289
Test Epoch25 layer4 Acc 0.7342, AUC 0.8106461763381958, avg_entr 0.04674777388572693, f1 0.7342000007629395
ep25_l4_test_time 0.8409923540000364
gc 0
Train Epoch26 Acc 0.955125 (38205/40000), AUC 0.9903216361999512
ep26_train_time 23.971462568999982
Test Epoch26 layer0 Acc 0.6966, AUC 0.7658867835998535, avg_entr 0.17624326050281525, f1 0.6966000199317932
ep26_l0_test_time 0.32189702199991643
Test Epoch26 layer1 Acc 0.7046, AUC 0.776390552520752, avg_entr 0.07034586369991302, f1 0.7045999765396118
ep26_l1_test_time 0.3916453309999497
Test Epoch26 layer2 Acc 0.7228, AUC 0.7995774745941162, avg_entr 0.05718560889363289, f1 0.7227999567985535
ep26_l2_test_time 0.5090249549999726
Test Epoch26 layer3 Acc 0.7322, AUC 0.803985595703125, avg_entr 0.05687861144542694, f1 0.732200026512146
ep26_l3_test_time 0.6464410739999948
Test Epoch26 layer4 Acc 0.7314, AUC 0.8096497058868408, avg_entr 0.05499836429953575, f1 0.7314000129699707
ep26_l4_test_time 0.8491266309999901
gc 0
Train Epoch27 Acc 0.95775 (38310/40000), AUC 0.9909499883651733
ep27_train_time 23.855276904999982
Test Epoch27 layer0 Acc 0.6994, AUC 0.7664107084274292, avg_entr 0.17305202782154083, f1 0.699400007724762
ep27_l0_test_time 0.31244335600001705
Test Epoch27 layer1 Acc 0.7068, AUC 0.7736338973045349, avg_entr 0.06697791814804077, f1 0.7067999839782715
ep27_l1_test_time 0.4044007469999542
Test Epoch27 layer2 Acc 0.7252, AUC 0.7954671382904053, avg_entr 0.05148424208164215, f1 0.7251999974250793
ep27_l2_test_time 0.5219431940000732
Test Epoch27 layer3 Acc 0.7318, AUC 0.8005287647247314, avg_entr 0.04805918037891388, f1 0.7318000197410583
ep27_l3_test_time 0.6475229269999545
Test Epoch27 layer4 Acc 0.7312, AUC 0.8078200817108154, avg_entr 0.04599806293845177, f1 0.7311999797821045
ep27_l4_test_time 0.8410461700000269
gc 0
Train Epoch28 Acc 0.95915 (38366/40000), AUC 0.9905992150306702
ep28_train_time 23.879249712000046
Test Epoch28 layer0 Acc 0.701, AUC 0.766089916229248, avg_entr 0.1751202642917633, f1 0.7009999752044678
ep28_l0_test_time 0.33716373300001123
Test Epoch28 layer1 Acc 0.7036, AUC 0.7720845937728882, avg_entr 0.06524074077606201, f1 0.7035999894142151
ep28_l1_test_time 0.3953218829999514
Test Epoch28 layer2 Acc 0.7266, AUC 0.7969216704368591, avg_entr 0.05364192649722099, f1 0.7265999913215637
ep28_l2_test_time 0.49652636399991934
Test Epoch28 layer3 Acc 0.7322, AUC 0.8018390536308289, avg_entr 0.049400169402360916, f1 0.732200026512146
ep28_l3_test_time 0.6490084130000469
Test Epoch28 layer4 Acc 0.7334, AUC 0.8080661296844482, avg_entr 0.0470087006688118, f1 0.7333999872207642
ep28_l4_test_time 0.8401676219999672
gc 0
Train Epoch29 Acc 0.959625 (38385/40000), AUC 0.9912706613540649
ep29_train_time 23.87477481999997
Test Epoch29 layer0 Acc 0.6918, AUC 0.7646956443786621, avg_entr 0.17452441155910492, f1 0.6917999982833862
ep29_l0_test_time 0.31302962500001286
Test Epoch29 layer1 Acc 0.7036, AUC 0.7713345885276794, avg_entr 0.06449473649263382, f1 0.7035999894142151
ep29_l1_test_time 0.3886443699999518
Test Epoch29 layer2 Acc 0.7262, AUC 0.7944241762161255, avg_entr 0.05069301277399063, f1 0.7261999845504761
ep29_l2_test_time 0.49715104300003077
Test Epoch29 layer3 Acc 0.7302, AUC 0.798728883266449, avg_entr 0.047934193164110184, f1 0.7301999926567078
ep29_l3_test_time 0.6464280590000726
Test Epoch29 layer4 Acc 0.7308, AUC 0.8069467544555664, avg_entr 0.04647830128669739, f1 0.7307999730110168
ep29_l4_test_time 0.852120885999966
gc 0
Train Epoch30 Acc 0.960975 (38439/40000), AUC 0.9913781881332397
ep30_train_time 23.71286273699991
Test Epoch30 layer0 Acc 0.7, AUC 0.7650784254074097, avg_entr 0.17447057366371155, f1 0.699999988079071
ep30_l0_test_time 0.3130115129999922
Test Epoch30 layer1 Acc 0.7054, AUC 0.7724074125289917, avg_entr 0.06428003311157227, f1 0.7053999900817871
ep30_l1_test_time 0.38830111800007217
Test Epoch30 layer2 Acc 0.7274, AUC 0.7967594861984253, avg_entr 0.05166766420006752, f1 0.7274000644683838
ep30_l2_test_time 0.5102072619999944
Test Epoch30 layer3 Acc 0.7344, AUC 0.8013741970062256, avg_entr 0.05031554028391838, f1 0.7343999147415161
ep30_l3_test_time 0.6553945130000329
Test Epoch30 layer4 Acc 0.7338, AUC 0.8073030710220337, avg_entr 0.04871325194835663, f1 0.7338000535964966
ep30_l4_test_time 0.8490214669999432
gc 0
Train Epoch31 Acc 0.961475 (38459/40000), AUC 0.9919649362564087
ep31_train_time 23.602554941999983
Test Epoch31 layer0 Acc 0.6928, AUC 0.7645055055618286, avg_entr 0.17285698652267456, f1 0.692799985408783
ep31_l0_test_time 0.32404993799991644
Test Epoch31 layer1 Acc 0.7052, AUC 0.7716437578201294, avg_entr 0.06247185170650482, f1 0.7052000164985657
ep31_l1_test_time 0.3907246100000066
Test Epoch31 layer2 Acc 0.7244, AUC 0.7939735651016235, avg_entr 0.05117272213101387, f1 0.7244000434875488
ep31_l2_test_time 0.5005233429999407
Test Epoch31 layer3 Acc 0.73, AUC 0.7975181341171265, avg_entr 0.046187590807676315, f1 0.7300000190734863
ep31_l3_test_time 0.6557051380000303
Test Epoch31 layer4 Acc 0.7294, AUC 0.8063504695892334, avg_entr 0.0442521795630455, f1 0.7293999791145325
ep31_l4_test_time 0.8419671149999886
gc 0
Train Epoch32 Acc 0.962575 (38503/40000), AUC 0.9921857118606567
ep32_train_time 23.732044902999974
Test Epoch32 layer0 Acc 0.6942, AUC 0.7646434307098389, avg_entr 0.17216697335243225, f1 0.6941999793052673
ep32_l0_test_time 0.3153168009999945
Test Epoch32 layer1 Acc 0.7052, AUC 0.7715886235237122, avg_entr 0.06185951083898544, f1 0.7052000164985657
ep32_l1_test_time 0.38594345600006363
Test Epoch32 layer2 Acc 0.7228, AUC 0.7946609854698181, avg_entr 0.04994465410709381, f1 0.7227999567985535
ep32_l2_test_time 0.495423030999973
Test Epoch32 layer3 Acc 0.7264, AUC 0.7986786365509033, avg_entr 0.04857683554291725, f1 0.7264000177383423
ep32_l3_test_time 0.6452447770000163
Test Epoch32 layer4 Acc 0.7272, AUC 0.806544303894043, avg_entr 0.047137610614299774, f1 0.7271999716758728
ep32_l4_test_time 0.8484823679999636
gc 0
Train Epoch33 Acc 0.96365 (38546/40000), AUC 0.9926689863204956
ep33_train_time 23.917984047999994
Test Epoch33 layer0 Acc 0.694, AUC 0.7643663883209229, avg_entr 0.17193633317947388, f1 0.6940000057220459
ep33_l0_test_time 0.3208328260000144
Test Epoch33 layer1 Acc 0.7036, AUC 0.76985764503479, avg_entr 0.062143437564373016, f1 0.7035999894142151
ep33_l1_test_time 0.38631235899993044
Test Epoch33 layer2 Acc 0.7244, AUC 0.792729914188385, avg_entr 0.04884135350584984, f1 0.7244000434875488
ep33_l2_test_time 0.4967225740000458
Test Epoch33 layer3 Acc 0.731, AUC 0.7966059446334839, avg_entr 0.04440340772271156, f1 0.7310000061988831
ep33_l3_test_time 0.6473023530001001
Test Epoch33 layer4 Acc 0.7318, AUC 0.8049329519271851, avg_entr 0.04252022132277489, f1 0.7318000197410583
ep33_l4_test_time 0.8436953140000014
gc 0
Train Epoch34 Acc 0.9617 (38468/40000), AUC 0.9925426244735718
ep34_train_time 23.74220285399997
Test Epoch34 layer0 Acc 0.694, AUC 0.7638224363327026, avg_entr 0.17219439148902893, f1 0.6940000057220459
ep34_l0_test_time 0.3129516889999877
Test Epoch34 layer1 Acc 0.7008, AUC 0.7692819833755493, avg_entr 0.06145979091525078, f1 0.7008000016212463
ep34_l1_test_time 0.3841229829999975
Test Epoch34 layer2 Acc 0.7232, AUC 0.7922295331954956, avg_entr 0.04910951480269432, f1 0.7232000827789307
ep34_l2_test_time 0.49526327000000947
Test Epoch34 layer3 Acc 0.7316, AUC 0.7958778738975525, avg_entr 0.045060209929943085, f1 0.7316000461578369
ep34_l3_test_time 0.6464386280000554
Test Epoch34 layer4 Acc 0.7326, AUC 0.8046398758888245, avg_entr 0.04331817105412483, f1 0.7325999140739441
ep34_l4_test_time 0.83859433300006
gc 0
Train Epoch35 Acc 0.96475 (38590/40000), AUC 0.9930053353309631
ep35_train_time 23.849606531000063
Test Epoch35 layer0 Acc 0.6952, AUC 0.7639060616493225, avg_entr 0.17028546333312988, f1 0.6952000260353088
ep35_l0_test_time 0.3165588150000076
Test Epoch35 layer1 Acc 0.702, AUC 0.7683614492416382, avg_entr 0.06077752634882927, f1 0.7020000219345093
ep35_l1_test_time 0.4102415759999758
Test Epoch35 layer2 Acc 0.724, AUC 0.7937785983085632, avg_entr 0.04950189217925072, f1 0.7239999175071716
ep35_l2_test_time 0.505270696000025
Test Epoch35 layer3 Acc 0.7324, AUC 0.7970452904701233, avg_entr 0.048959553241729736, f1 0.7323999404907227
ep35_l3_test_time 0.6458064820000118
Test Epoch35 layer4 Acc 0.7322, AUC 0.8053651452064514, avg_entr 0.04696132615208626, f1 0.732200026512146
ep35_l4_test_time 0.8394381710000971
gc 0
Train Epoch36 Acc 0.962925 (38517/40000), AUC 0.9926040172576904
ep36_train_time 23.89858008300007
Test Epoch36 layer0 Acc 0.6952, AUC 0.7640354633331299, avg_entr 0.1708640158176422, f1 0.6952000260353088
ep36_l0_test_time 0.32456024099997194
Test Epoch36 layer1 Acc 0.7046, AUC 0.7702410817146301, avg_entr 0.06125634163618088, f1 0.7045999765396118
ep36_l1_test_time 0.38259318199993686
Test Epoch36 layer2 Acc 0.726, AUC 0.7940018773078918, avg_entr 0.05023280158638954, f1 0.7260000109672546
ep36_l2_test_time 0.4966789669999798
Test Epoch36 layer3 Acc 0.732, AUC 0.796924889087677, avg_entr 0.04657284542918205, f1 0.7319999933242798
ep36_l3_test_time 0.6406744429999662
Test Epoch36 layer4 Acc 0.7314, AUC 0.8060426712036133, avg_entr 0.045142557471990585, f1 0.7314000129699707
ep36_l4_test_time 0.8365256760000648
gc 0
Train Epoch37 Acc 0.96315 (38526/40000), AUC 0.9927259087562561
ep37_train_time 23.614028345000065
Test Epoch37 layer0 Acc 0.6964, AUC 0.7643157243728638, avg_entr 0.1704872101545334, f1 0.696399986743927
ep37_l0_test_time 0.3083472339999389
Test Epoch37 layer1 Acc 0.7056, AUC 0.7689054608345032, avg_entr 0.06053971126675606, f1 0.7056000232696533
ep37_l1_test_time 0.3805407050001577
Test Epoch37 layer2 Acc 0.7238, AUC 0.7935449481010437, avg_entr 0.04893090948462486, f1 0.723800003528595
ep37_l2_test_time 0.489631670000108
Test Epoch37 layer3 Acc 0.7292, AUC 0.7966029644012451, avg_entr 0.04731963574886322, f1 0.7291999459266663
ep37_l3_test_time 0.6397553269998753
Test Epoch37 layer4 Acc 0.73, AUC 0.8052825927734375, avg_entr 0.045521002262830734, f1 0.7300000190734863
ep37_l4_test_time 0.8337816300002032
gc 0
Train Epoch38 Acc 0.962725 (38509/40000), AUC 0.9929041266441345
ep38_train_time 23.379715072999943
Test Epoch38 layer0 Acc 0.6972, AUC 0.7642166614532471, avg_entr 0.1703769415616989, f1 0.6972000002861023
ep38_l0_test_time 0.3077627059999486
Test Epoch38 layer1 Acc 0.7046, AUC 0.7696657180786133, avg_entr 0.06005279719829559, f1 0.7045999765396118
ep38_l1_test_time 0.38022669199995107
Test Epoch38 layer2 Acc 0.7254, AUC 0.7931356430053711, avg_entr 0.048406291753053665, f1 0.7253999710083008
ep38_l2_test_time 0.48906707700007246
Test Epoch38 layer3 Acc 0.7306, AUC 0.7965779304504395, avg_entr 0.045081689953804016, f1 0.7305999994277954
ep38_l3_test_time 0.6413103459999547
Test Epoch38 layer4 Acc 0.7302, AUC 0.8055610656738281, avg_entr 0.0430002324283123, f1 0.7301999926567078
ep38_l4_test_time 0.8331869629998891
gc 0
Train Epoch39 Acc 0.9641 (38564/40000), AUC 0.9930484294891357
ep39_train_time 23.436621938000144
Test Epoch39 layer0 Acc 0.6958, AUC 0.7638658881187439, avg_entr 0.16998900473117828, f1 0.6958000063896179
ep39_l0_test_time 0.3082492920000277
Test Epoch39 layer1 Acc 0.7036, AUC 0.7688852548599243, avg_entr 0.059907060116529465, f1 0.7035999894142151
ep39_l1_test_time 0.3822151549998125
Test Epoch39 layer2 Acc 0.7244, AUC 0.7922815084457397, avg_entr 0.048649031668901443, f1 0.7244000434875488
ep39_l2_test_time 0.49217909200001486
Test Epoch39 layer3 Acc 0.7304, AUC 0.7954365015029907, avg_entr 0.04486467316746712, f1 0.7304000854492188
ep39_l3_test_time 0.6449966139998651
Test Epoch39 layer4 Acc 0.731, AUC 0.8048554062843323, avg_entr 0.04244855046272278, f1 0.7310000061988831
ep39_l4_test_time 0.8331828650000261
gc 0
Train Epoch40 Acc 0.963175 (38527/40000), AUC 0.993212103843689
ep40_train_time 23.413350020999815
Test Epoch40 layer0 Acc 0.6966, AUC 0.7640550136566162, avg_entr 0.17032045125961304, f1 0.6966000199317932
ep40_l0_test_time 0.30702567999992425
Test Epoch40 layer1 Acc 0.7032, AUC 0.7686998844146729, avg_entr 0.0592946894466877, f1 0.7031999826431274
ep40_l1_test_time 0.3816501100000096
Test Epoch40 layer2 Acc 0.724, AUC 0.7930697202682495, avg_entr 0.04829990863800049, f1 0.7239999175071716
ep40_l2_test_time 0.49092746100018303
Test Epoch40 layer3 Acc 0.7282, AUC 0.7966899275779724, avg_entr 0.046563077718019485, f1 0.7282000184059143
ep40_l3_test_time 0.6411704419999751
Test Epoch40 layer4 Acc 0.729, AUC 0.8051818609237671, avg_entr 0.04440973699092865, f1 0.7289999723434448
ep40_l4_test_time 0.8336128420000932
gc 0
Train Epoch41 Acc 0.964725 (38589/40000), AUC 0.9934346079826355
ep41_train_time 23.54112589700003
Test Epoch41 layer0 Acc 0.696, AUC 0.7640388011932373, avg_entr 0.1696559339761734, f1 0.6959999799728394
ep41_l0_test_time 0.3085055490000741
Test Epoch41 layer1 Acc 0.7042, AUC 0.7688976526260376, avg_entr 0.05916822329163551, f1 0.704200029373169
ep41_l1_test_time 0.38168407600005594
Test Epoch41 layer2 Acc 0.723, AUC 0.7931329011917114, avg_entr 0.048924580216407776, f1 0.7229999899864197
ep41_l2_test_time 0.49095977299998594
Test Epoch41 layer3 Acc 0.7306, AUC 0.7962555289268494, avg_entr 0.04605035483837128, f1 0.7305999994277954
ep41_l3_test_time 0.6380035570000473
Test Epoch41 layer4 Acc 0.7306, AUC 0.8052549362182617, avg_entr 0.0441344678401947, f1 0.7305999994277954
ep41_l4_test_time 0.8315231849999236
gc 0
Train Epoch42 Acc 0.96365 (38546/40000), AUC 0.99308842420578
ep42_train_time 23.444371464999904
Test Epoch42 layer0 Acc 0.6952, AUC 0.7638522982597351, avg_entr 0.17015506327152252, f1 0.6952000260353088
ep42_l0_test_time 0.3087871590000759
Test Epoch42 layer1 Acc 0.7032, AUC 0.7686848640441895, avg_entr 0.059357695281505585, f1 0.7031999826431274
ep42_l1_test_time 0.379615769999873
Test Epoch42 layer2 Acc 0.723, AUC 0.7928289175033569, avg_entr 0.049269918352365494, f1 0.7229999899864197
ep42_l2_test_time 0.48893219299998236
Test Epoch42 layer3 Acc 0.7308, AUC 0.7961162328720093, avg_entr 0.046652235090732574, f1 0.7307999730110168
ep42_l3_test_time 0.6393890939998528
Test Epoch42 layer4 Acc 0.732, AUC 0.8050508499145508, avg_entr 0.04466705396771431, f1 0.7319999933242798
ep42_l4_test_time 0.8308102599999074
gc 0
Train Epoch43 Acc 0.9646 (38584/40000), AUC 0.9930808544158936
ep43_train_time 23.437793892999935
Test Epoch43 layer0 Acc 0.6958, AUC 0.7638141512870789, avg_entr 0.16948296129703522, f1 0.6958000063896179
ep43_l0_test_time 0.311661137000101
Test Epoch43 layer1 Acc 0.704, AUC 0.7683051824569702, avg_entr 0.05907503515481949, f1 0.7039999961853027
ep43_l1_test_time 0.38722825500008184
Test Epoch43 layer2 Acc 0.7226, AUC 0.7925176024436951, avg_entr 0.04797464236617088, f1 0.722599983215332
ep43_l2_test_time 0.49124709299985625
Test Epoch43 layer3 Acc 0.731, AUC 0.7957707047462463, avg_entr 0.04559079557657242, f1 0.7310000061988831
ep43_l3_test_time 0.6411113950000527
Test Epoch43 layer4 Acc 0.732, AUC 0.8045233488082886, avg_entr 0.04355819523334503, f1 0.7319999933242798
ep43_l4_test_time 0.8343405979999261
gc 0
Train Epoch44 Acc 0.964775 (38591/40000), AUC 0.9930554032325745
ep44_train_time 23.451591851000103
Test Epoch44 layer0 Acc 0.6948, AUC 0.7638118267059326, avg_entr 0.1696653813123703, f1 0.6948000192642212
ep44_l0_test_time 0.3076264100000117
Test Epoch44 layer1 Acc 0.7038, AUC 0.7682833671569824, avg_entr 0.0588441900908947, f1 0.7038000226020813
ep44_l1_test_time 0.3862732860000051
Test Epoch44 layer2 Acc 0.7228, AUC 0.7918732166290283, avg_entr 0.04775730520486832, f1 0.7227999567985535
ep44_l2_test_time 0.4921306100000038
Test Epoch44 layer3 Acc 0.7298, AUC 0.7949601411819458, avg_entr 0.04409268870949745, f1 0.7297999858856201
ep44_l3_test_time 0.6391430520000085
Test Epoch44 layer4 Acc 0.731, AUC 0.8042561411857605, avg_entr 0.04193035513162613, f1 0.7310000061988831
ep44_l4_test_time 0.8396904440000981
gc 0
Train Epoch45 Acc 0.964425 (38577/40000), AUC 0.9932581782341003
ep45_train_time 23.41985721800006
Test Epoch45 layer0 Acc 0.6958, AUC 0.7639132738113403, avg_entr 0.1694294959306717, f1 0.6958000063896179
ep45_l0_test_time 0.30664060100002644
Test Epoch45 layer1 Acc 0.7044, AUC 0.7682609558105469, avg_entr 0.05890250205993652, f1 0.7044000029563904
ep45_l1_test_time 0.380657329000087
Test Epoch45 layer2 Acc 0.723, AUC 0.7927225828170776, avg_entr 0.04836329445242882, f1 0.7229999899864197
ep45_l2_test_time 0.4887862650000443
Test Epoch45 layer3 Acc 0.7308, AUC 0.7959798574447632, avg_entr 0.0457908920943737, f1 0.7307999730110168
ep45_l3_test_time 0.6379523209998297
Test Epoch45 layer4 Acc 0.731, AUC 0.8047419786453247, avg_entr 0.04346247389912605, f1 0.7310000061988831
ep45_l4_test_time 0.8325804440000866
gc 0
Train Epoch46 Acc 0.964975 (38599/40000), AUC 0.9934589862823486
ep46_train_time 23.413255859000174
Test Epoch46 layer0 Acc 0.6958, AUC 0.7638829946517944, avg_entr 0.16948124766349792, f1 0.6958000063896179
ep46_l0_test_time 0.3074551510001129
Test Epoch46 layer1 Acc 0.704, AUC 0.7681202292442322, avg_entr 0.058656465262174606, f1 0.7039999961853027
ep46_l1_test_time 0.3797360660000777
Test Epoch46 layer2 Acc 0.7238, AUC 0.7920264601707458, avg_entr 0.047649089246988297, f1 0.723800003528595
ep46_l2_test_time 0.48938311200004136
Test Epoch46 layer3 Acc 0.7308, AUC 0.7954371571540833, avg_entr 0.04500170052051544, f1 0.7307999730110168
ep46_l3_test_time 0.6404119950000222
Test Epoch46 layer4 Acc 0.7306, AUC 0.8044033646583557, avg_entr 0.04264381155371666, f1 0.7305999994277954
ep46_l4_test_time 0.8379691360000834
gc 0
Train Epoch47 Acc 0.964925 (38597/40000), AUC 0.9930485486984253
ep47_train_time 23.41244418300016
Test Epoch47 layer0 Acc 0.6958, AUC 0.763926088809967, avg_entr 0.1690952628850937, f1 0.6958000063896179
ep47_l0_test_time 0.3070278839998082
Test Epoch47 layer1 Acc 0.7038, AUC 0.7680558562278748, avg_entr 0.058420002460479736, f1 0.7038000226020813
ep47_l1_test_time 0.3793482030000632
Test Epoch47 layer2 Acc 0.7238, AUC 0.7919591069221497, avg_entr 0.047776054590940475, f1 0.723800003528595
ep47_l2_test_time 0.48967418000006546
Test Epoch47 layer3 Acc 0.7314, AUC 0.7952695488929749, avg_entr 0.04456210508942604, f1 0.7314000129699707
ep47_l3_test_time 0.6384088380000321
Test Epoch47 layer4 Acc 0.731, AUC 0.8044589757919312, avg_entr 0.04235632345080376, f1 0.7310000061988831
ep47_l4_test_time 0.8328661780001312
gc 0
Train Epoch48 Acc 0.966 (38640/40000), AUC 0.9934419989585876
ep48_train_time 23.43991539800004
Test Epoch48 layer0 Acc 0.6958, AUC 0.7639138698577881, avg_entr 0.16935250163078308, f1 0.6958000063896179
ep48_l0_test_time 0.30850945199995294
Test Epoch48 layer1 Acc 0.7034, AUC 0.7677148580551147, avg_entr 0.058671191334724426, f1 0.7034000158309937
ep48_l1_test_time 0.3816665809999904
Test Epoch48 layer2 Acc 0.7226, AUC 0.7920428514480591, avg_entr 0.047887805849313736, f1 0.722599983215332
ep48_l2_test_time 0.4907106090001889
Test Epoch48 layer3 Acc 0.73, AUC 0.795519232749939, avg_entr 0.04595397785305977, f1 0.7300000190734863
ep48_l3_test_time 0.6392862410000362
Test Epoch48 layer4 Acc 0.7302, AUC 0.8043110370635986, avg_entr 0.04361022263765335, f1 0.7301999926567078
ep48_l4_test_time 0.8336336449999635
gc 0
Train Epoch49 Acc 0.9636 (38544/40000), AUC 0.9931032061576843
ep49_train_time 23.399805302999994
Test Epoch49 layer0 Acc 0.6952, AUC 0.7639074921607971, avg_entr 0.16929098963737488, f1 0.6952000260353088
ep49_l0_test_time 0.30957778000015423
Test Epoch49 layer1 Acc 0.704, AUC 0.7678627967834473, avg_entr 0.05852734297513962, f1 0.7039999961853027
ep49_l1_test_time 0.3816787650000606
Test Epoch49 layer2 Acc 0.7234, AUC 0.7920295000076294, avg_entr 0.048051029443740845, f1 0.7233999967575073
ep49_l2_test_time 0.48858348099997784
Test Epoch49 layer3 Acc 0.7306, AUC 0.79554283618927, avg_entr 0.04567522928118706, f1 0.7305999994277954
ep49_l3_test_time 0.6389877369999795
Test Epoch49 layer4 Acc 0.7322, AUC 0.8044379949569702, avg_entr 0.04335092753171921, f1 0.732200026512146
ep49_l4_test_time 0.8324584000001778
Best AUC tensor(0.7654) 13 4
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
total_train+valid_time 1320.824183027
Start Testing
Load ckpt at ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt
gc 9
Test layer0 Acc 0.705, AUC 0.7849653959274292, avg_entr 0.24398711323738098, f1 0.7049999833106995
l0_test_time 0.30767229999992196
gc 0
Test layer1 Acc 0.7394, AUC 0.8214319944381714, avg_entr 0.2047804445028305, f1 0.7394000291824341
l1_test_time 0.3802558740001132
gc 0
Test layer2 Acc 0.7612, AUC 0.8454984426498413, avg_entr 0.18408381938934326, f1 0.7612000107765198
l2_test_time 0.490719836000153
gc 0
Test layer3 Acc 0.764, AUC 0.8489876985549927, avg_entr 0.13269804418087006, f1 0.7639999985694885
l3_test_time 0.6424832899999728
gc 0
Test layer4 Acc 0.7662, AUC 0.8509161472320557, avg_entr 0.13021604716777802, f1 0.766200065612793
l4_test_time 0.834873411999979
gc 0
Test threshold 0.1 Acc 0.7648, AUC 0.8314394354820251, avg_entr 0.18718321621418, f1 0.764799952507019
t0.1_test_time 0.6179592589999174
gc 0
Test threshold 0.2 Acc 0.761, AUC 0.8252881765365601, avg_entr 0.19348032772541046, f1 0.7610000371932983
t0.2_test_time 0.5552004899998337
gc 0
Test threshold 0.3 Acc 0.7578, AUC 0.8225071430206299, avg_entr 0.2032373547554016, f1 0.7577999830245972
t0.3_test_time 0.5204473899998447
gc 0
Test threshold 0.4 Acc 0.753, AUC 0.816689670085907, avg_entr 0.21572314202785492, f1 0.753000020980835
t0.4_test_time 0.49206780500003333
gc 0
Test threshold 0.5 Acc 0.7478, AUC 0.8122894763946533, avg_entr 0.229599729180336, f1 0.7477999925613403
t0.5_test_time 0.483520684000041
gc 0
Test threshold 0.6 Acc 0.7434, AUC 0.8084530234336853, avg_entr 0.24284541606903076, f1 0.743399977684021
t0.6_test_time 0.44143316500003493
gc 0
Test threshold 0.7 Acc 0.7364, AUC 0.8037600517272949, avg_entr 0.25972065329551697, f1 0.7364000082015991
t0.7_test_time 0.41717165099998965
gc 0
Test threshold 0.8 Acc 0.7304, AUC 0.7984076738357544, avg_entr 0.27947330474853516, f1 0.7304000854492188
t0.8_test_time 0.40109489299993584
gc 0
Test threshold 0.9 Acc 0.7204, AUC 0.7940226793289185, avg_entr 0.30294686555862427, f1 0.7204000353813171
t0.9_test_time 0.38736733499990805
