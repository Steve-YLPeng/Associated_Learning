total count words 222751
vocab size 30000
train size 40000, valid size 5000, test size 5000
found 27937 words in glove
model: TransformerALsideText(
  (layers): ModuleList(
    (0): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=2, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=2, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
  (emb_layers): ModuleList(
    (0): Embedding(30000, 300)
    (1): Embedding(30000, 300)
    (2): Embedding(30000, 300)
    (3): Embedding(30000, 300)
    (4): Embedding(30000, 300)
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.multi_headed_attention.linears.0.weight 90000
layers.0.enc.f.multi_headed_attention.linears.0.bias 300
layers.0.enc.f.multi_headed_attention.linears.1.weight 90000
layers.0.enc.f.multi_headed_attention.linears.1.bias 300
layers.0.enc.f.multi_headed_attention.linears.2.weight 90000
layers.0.enc.f.multi_headed_attention.linears.2.bias 300
layers.0.enc.f.multi_headed_attention.linears.3.weight 90000
layers.0.enc.f.multi_headed_attention.linears.3.bias 300
layers.0.enc.f.feed_forward.w_1.weight 90000
layers.0.enc.f.feed_forward.w_1.bias 300
layers.0.enc.f.feed_forward.w_2.weight 90000
layers.0.enc.f.feed_forward.w_2.bias 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.0.enc.f.encoder.norm.a 300
layers.0.enc.f.encoder.norm.b 300
layers.0.ae.g.0.weight 256
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 256
layers.0.ae.h.0.bias 2
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
emb_layers.0.weight 9000000
emb_layers.1.weight 9000000
emb_layers.2.weight 9000000
emb_layers.3.weight 9000000
emb_layers.4.weight 9000000
Total Trainable Params: 50758378
init_time 20.914560221
Start Training
gc 0
Train Epoch0 Acc 0.496425 (19857/40000), AUC 0.49817121028900146
ep0_train_time 65.822934935
Test Epoch0 layer0 Acc 0.5638, AUC 0.5956649780273438, avg_entr 0.6697909832000732, f1 0.5637999773025513
ep0_l0_test_time 0.6386308689999964
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 0
Test Epoch0 layer1 Acc 0.5178, AUC 0.5431115627288818, avg_entr 0.6903185844421387, f1 0.517799973487854
ep0_l1_test_time 0.8406072319999964
Test Epoch0 layer2 Acc 0.5018, AUC 0.5220972895622253, avg_entr 0.6906172633171082, f1 0.501800000667572
ep0_l2_test_time 1.1518226219999974
Test Epoch0 layer3 Acc 0.4994, AUC 0.48248815536499023, avg_entr 0.6894897222518921, f1 0.49939998984336853
ep0_l3_test_time 1.6350423030000059
Test Epoch0 layer4 Acc 0.5006, AUC 0.5047027468681335, avg_entr 0.6926912069320679, f1 0.5005999803543091
ep0_l4_test_time 2.2702864430000034
gc 0
Train Epoch1 Acc 0.511175 (20447/40000), AUC 0.5138491988182068
ep1_train_time 65.71161951500001
Test Epoch1 layer0 Acc 0.6028, AUC 0.6509852409362793, avg_entr 0.6699920892715454, f1 0.6028000116348267
ep1_l0_test_time 0.6386102380000125
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 1
Test Epoch1 layer1 Acc 0.56, AUC 0.6365355253219604, avg_entr 0.684849202632904, f1 0.5600000023841858
ep1_l1_test_time 0.8421702040000127
Test Epoch1 layer2 Acc 0.5, AUC 0.5578020811080933, avg_entr 0.6828902363777161, f1 0.5
ep1_l2_test_time 1.1531735330000004
Test Epoch1 layer3 Acc 0.5, AUC 0.48247215151786804, avg_entr 0.6838906407356262, f1 0.5
ep1_l3_test_time 1.6458487949999778
Test Epoch1 layer4 Acc 0.5, AUC 0.5573664903640747, avg_entr 0.6875296831130981, f1 0.5
ep1_l4_test_time 2.2681785050000087
gc 0
Train Epoch2 Acc 0.5149 (20596/40000), AUC 0.5217888355255127
ep2_train_time 65.672318469
Test Epoch2 layer0 Acc 0.6312, AUC 0.765020489692688, avg_entr 0.4776536524295807, f1 0.6312000155448914
ep2_l0_test_time 0.6363944379999964
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 2
Test Epoch2 layer1 Acc 0.6068, AUC 0.7691119909286499, avg_entr 0.47157618403434753, f1 0.6068000197410583
ep2_l1_test_time 0.837461664000017
Test Epoch2 layer2 Acc 0.5282, AUC 0.7377122044563293, avg_entr 0.4637819230556488, f1 0.5281999707221985
ep2_l2_test_time 1.153179477000009
Test Epoch2 layer3 Acc 0.5, AUC 0.7475998401641846, avg_entr 0.5563837885856628, f1 0.5
ep2_l3_test_time 1.6364898599999833
Test Epoch2 layer4 Acc 0.5, AUC 0.6623694896697998, avg_entr 0.6580235958099365, f1 0.5
ep2_l4_test_time 2.2693190920000177
gc 0
Train Epoch3 Acc 0.61305 (24522/40000), AUC 0.6588564515113831
ep3_train_time 65.67637183699998
Test Epoch3 layer0 Acc 0.691, AUC 0.8143700361251831, avg_entr 0.40767142176628113, f1 0.6909999847412109
ep3_l0_test_time 0.6379795330000206
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer1 Acc 0.6888, AUC 0.8300656080245972, avg_entr 0.40698927640914917, f1 0.6887999773025513
ep3_l1_test_time 0.8372020410000118
Test Epoch3 layer2 Acc 0.6684, AUC 0.8298741579055786, avg_entr 0.4364786148071289, f1 0.66839998960495
ep3_l2_test_time 1.1653075239999566
Test Epoch3 layer3 Acc 0.6544, AUC 0.8298120498657227, avg_entr 0.4813903272151947, f1 0.6543999910354614
ep3_l3_test_time 1.6365492889999587
Test Epoch3 layer4 Acc 0.5574, AUC 0.8292674422264099, avg_entr 0.5025079250335693, f1 0.5573999881744385
ep3_l4_test_time 2.268185107000022
gc 0
Train Epoch4 Acc 0.71505 (28602/40000), AUC 0.7935436964035034
ep4_train_time 65.713628674
Test Epoch4 layer0 Acc 0.7422, AUC 0.8337061405181885, avg_entr 0.35434654355049133, f1 0.7422000169754028
ep4_l0_test_time 0.6399137919999589
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
Test Epoch4 layer1 Acc 0.7226, AUC 0.8418539762496948, avg_entr 0.3128919303417206, f1 0.722599983215332
ep4_l1_test_time 0.8420610059999944
Test Epoch4 layer2 Acc 0.7, AUC 0.8430927395820618, avg_entr 0.3137665390968323, f1 0.699999988079071
ep4_l2_test_time 1.1621654319999948
Test Epoch4 layer3 Acc 0.6742, AUC 0.8419035077095032, avg_entr 0.31137943267822266, f1 0.6741999983787537
ep4_l3_test_time 1.6372200659999976
Test Epoch4 layer4 Acc 0.6532, AUC 0.842507004737854, avg_entr 0.305680513381958, f1 0.6531999707221985
ep4_l4_test_time 2.2700010670000097
gc 0
Train Epoch5 Acc 0.738525 (29541/40000), AUC 0.8199896812438965
ep5_train_time 65.68789575600005
Test Epoch5 layer0 Acc 0.7512, AUC 0.8456348776817322, avg_entr 0.32122233510017395, f1 0.7512000203132629
ep5_l0_test_time 0.6408984200000418
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 5
Test Epoch5 layer1 Acc 0.759, AUC 0.8597937822341919, avg_entr 0.2878694534301758, f1 0.7589999437332153
ep5_l1_test_time 0.8410529349999933
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 5
Test Epoch5 layer2 Acc 0.759, AUC 0.8609793186187744, avg_entr 0.2686087489128113, f1 0.7589999437332153
ep5_l2_test_time 1.170327871999973
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 5
Test Epoch5 layer3 Acc 0.7544, AUC 0.8610292673110962, avg_entr 0.2641817033290863, f1 0.7544000148773193
ep5_l3_test_time 1.640905733000011
Test Epoch5 layer4 Acc 0.7524, AUC 0.8612367510795593, avg_entr 0.2651618421077728, f1 0.7523999810218811
ep5_l4_test_time 2.26846261999998
gc 0
Train Epoch6 Acc 0.7778 (31112/40000), AUC 0.8586812615394592
ep6_train_time 65.61070157500001
Test Epoch6 layer0 Acc 0.7642, AUC 0.8543571829795837, avg_entr 0.29919493198394775, f1 0.76419997215271
ep6_l0_test_time 0.6644735490000357
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer1 Acc 0.7774, AUC 0.8706521987915039, avg_entr 0.2607874274253845, f1 0.777400016784668
ep6_l1_test_time 0.8827679319999788
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer2 Acc 0.7804, AUC 0.8722642660140991, avg_entr 0.23708781599998474, f1 0.7803999781608582
ep6_l2_test_time 1.1634198310000556
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer3 Acc 0.7792, AUC 0.8722534775733948, avg_entr 0.25326263904571533, f1 0.7791999578475952
ep6_l3_test_time 1.6466463799999929
Test Epoch6 layer4 Acc 0.7792, AUC 0.8723534941673279, avg_entr 0.26503846049308777, f1 0.7791999578475952
ep6_l4_test_time 2.2691602449999664
gc 0
Train Epoch7 Acc 0.80495 (32198/40000), AUC 0.8864705562591553
ep7_train_time 65.58652804400003
Test Epoch7 layer0 Acc 0.7744, AUC 0.8606277108192444, avg_entr 0.27130013704299927, f1 0.7743999361991882
ep7_l0_test_time 0.6376828080000223
Test Epoch7 layer1 Acc 0.7932, AUC 0.8793227672576904, avg_entr 0.24731303751468658, f1 0.7932000160217285
ep7_l1_test_time 0.8297186030000603
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 7
Test Epoch7 layer2 Acc 0.7938, AUC 0.8811383247375488, avg_entr 0.20259927213191986, f1 0.7937999963760376
ep7_l2_test_time 1.1605026390000148
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 7
Test Epoch7 layer3 Acc 0.7946, AUC 0.8815181255340576, avg_entr 0.20330356061458588, f1 0.7946000695228577
ep7_l3_test_time 1.6413856279999663
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 7
Test Epoch7 layer4 Acc 0.7942, AUC 0.8814922571182251, avg_entr 0.21201246976852417, f1 0.7942000031471252
ep7_l4_test_time 2.276722405999976
gc 0
Train Epoch8 Acc 0.818575 (32743/40000), AUC 0.8967902660369873
ep8_train_time 65.76867702799996
Test Epoch8 layer0 Acc 0.7638, AUC 0.8642329573631287, avg_entr 0.24590036273002625, f1 0.7638000249862671
ep8_l0_test_time 0.6371954720000303
Test Epoch8 layer1 Acc 0.7836, AUC 0.8838648796081543, avg_entr 0.2216814011335373, f1 0.7835999727249146
ep8_l1_test_time 0.8303496759999689
Test Epoch8 layer2 Acc 0.7846, AUC 0.8866623640060425, avg_entr 0.15875844657421112, f1 0.784600019454956
ep8_l2_test_time 1.1574853089999806
Test Epoch8 layer3 Acc 0.7844, AUC 0.8857078552246094, avg_entr 0.15757519006729126, f1 0.7843999266624451
ep8_l3_test_time 1.6459054660000447
Test Epoch8 layer4 Acc 0.7838, AUC 0.8852782845497131, avg_entr 0.1586935818195343, f1 0.7838000059127808
ep8_l4_test_time 2.271632173999933
gc 0
Train Epoch9 Acc 0.826675 (33067/40000), AUC 0.9056521654129028
ep9_train_time 65.697895947
Test Epoch9 layer0 Acc 0.774, AUC 0.864928662776947, avg_entr 0.2331169992685318, f1 0.7739999890327454
ep9_l0_test_time 0.640779451999947
Test Epoch9 layer1 Acc 0.7952, AUC 0.8848577737808228, avg_entr 0.1955500990152359, f1 0.7952000498771667
ep9_l1_test_time 0.829933245999996
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 9
Test Epoch9 layer2 Acc 0.8002, AUC 0.8871735334396362, avg_entr 0.1388113647699356, f1 0.8001999855041504
ep9_l2_test_time 1.160323094999967
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 9
Test Epoch9 layer3 Acc 0.8008, AUC 0.8876181840896606, avg_entr 0.13301660120487213, f1 0.8007999658584595
ep9_l3_test_time 1.6477204940000547
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 9
Test Epoch9 layer4 Acc 0.8008, AUC 0.8877718448638916, avg_entr 0.13067427277565002, f1 0.8007999658584595
ep9_l4_test_time 2.2754391380000243
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 9
gc 0
Train Epoch10 Acc 0.84465 (33786/40000), AUC 0.9199774861335754
ep10_train_time 65.759746372
Test Epoch10 layer0 Acc 0.7838, AUC 0.8692249059677124, avg_entr 0.22920136153697968, f1 0.7838000059127808
ep10_l0_test_time 0.6382037019999416
Test Epoch10 layer1 Acc 0.7978, AUC 0.8891828656196594, avg_entr 0.18494121730327606, f1 0.7978000044822693
ep10_l1_test_time 0.8307862550000209
Test Epoch10 layer2 Acc 0.8012, AUC 0.8914756774902344, avg_entr 0.13396470248699188, f1 0.8011999726295471
ep10_l2_test_time 1.1564002590000655
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 10
Test Epoch10 layer3 Acc 0.8016, AUC 0.892430305480957, avg_entr 0.13109031319618225, f1 0.8015999794006348
ep10_l3_test_time 1.644726275000039
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 10
Test Epoch10 layer4 Acc 0.8018, AUC 0.8925817012786865, avg_entr 0.1252022087574005, f1 0.801800012588501
ep10_l4_test_time 2.2792322889999923
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 10
gc 0
Train Epoch11 Acc 0.853575 (34143/40000), AUC 0.9274435043334961
ep11_train_time 65.76662313700001
Test Epoch11 layer0 Acc 0.7824, AUC 0.8716567754745483, avg_entr 0.22580324113368988, f1 0.7824000120162964
ep11_l0_test_time 0.6379017799999929
Test Epoch11 layer1 Acc 0.7862, AUC 0.8885507583618164, avg_entr 0.17331697046756744, f1 0.7861999869346619
ep11_l1_test_time 0.8323421669999789
Test Epoch11 layer2 Acc 0.7916, AUC 0.8906824588775635, avg_entr 0.12531128525733948, f1 0.7915999889373779
ep11_l2_test_time 1.1522248869999885
Test Epoch11 layer3 Acc 0.791, AUC 0.8912440538406372, avg_entr 0.12288530170917511, f1 0.7910000681877136
ep11_l3_test_time 1.6377725979999695
Test Epoch11 layer4 Acc 0.7884, AUC 0.891537070274353, avg_entr 0.12324164062738419, f1 0.7884000539779663
ep11_l4_test_time 2.273786484000084
gc 0
Train Epoch12 Acc 0.86485 (34594/40000), AUC 0.936082124710083
ep12_train_time 65.74746498000002
Test Epoch12 layer0 Acc 0.7582, AUC 0.8692258596420288, avg_entr 0.21538890898227692, f1 0.7582000494003296
ep12_l0_test_time 0.6382617689999961
Test Epoch12 layer1 Acc 0.7618, AUC 0.8892415761947632, avg_entr 0.14734837412834167, f1 0.7618000507354736
ep12_l1_test_time 0.8308759080000527
Test Epoch12 layer2 Acc 0.7588, AUC 0.8918811082839966, avg_entr 0.12028402090072632, f1 0.7588000297546387
ep12_l2_test_time 1.1555943729999854
Test Epoch12 layer3 Acc 0.756, AUC 0.8922613263130188, avg_entr 0.1189998909831047, f1 0.7559999227523804
ep12_l3_test_time 1.6420946079999794
Test Epoch12 layer4 Acc 0.7534, AUC 0.8925908803939819, avg_entr 0.11629494279623032, f1 0.7533999681472778
ep12_l4_test_time 2.2746231470000566
gc 0
Train Epoch13 Acc 0.86645 (34658/40000), AUC 0.9321850538253784
ep13_train_time 65.79555440400009
Test Epoch13 layer0 Acc 0.7868, AUC 0.8685004711151123, avg_entr 0.2190600335597992, f1 0.786799967288971
ep13_l0_test_time 0.6396173610000915
Test Epoch13 layer1 Acc 0.7992, AUC 0.8860732913017273, avg_entr 0.13191021978855133, f1 0.7991999983787537
ep13_l1_test_time 0.8305750679999164
Test Epoch13 layer2 Acc 0.8024, AUC 0.8886408805847168, avg_entr 0.12107145041227341, f1 0.8023999929428101
ep13_l2_test_time 1.1547661970000718
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 13
Test Epoch13 layer3 Acc 0.8038, AUC 0.889220654964447, avg_entr 0.11880064755678177, f1 0.8037999868392944
ep13_l3_test_time 1.6432217499998387
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 13
Test Epoch13 layer4 Acc 0.8032, AUC 0.889275312423706, avg_entr 0.11652059108018875, f1 0.8032000660896301
ep13_l4_test_time 2.2769747429999825
gc 0
Train Epoch14 Acc 0.877025 (35081/40000), AUC 0.9452622532844543
ep14_train_time 65.69090379699992
Test Epoch14 layer0 Acc 0.7768, AUC 0.8695769906044006, avg_entr 0.1968013048171997, f1 0.7768000364303589
ep14_l0_test_time 0.6389242529999137
Test Epoch14 layer1 Acc 0.793, AUC 0.8872250318527222, avg_entr 0.12908081710338593, f1 0.7929999828338623
ep14_l1_test_time 0.8318909469999198
Test Epoch14 layer2 Acc 0.7974, AUC 0.8900010585784912, avg_entr 0.11138954758644104, f1 0.7973999977111816
ep14_l2_test_time 1.1534660180000174
Test Epoch14 layer3 Acc 0.7984, AUC 0.8905413150787354, avg_entr 0.10781306028366089, f1 0.7983999848365784
ep14_l3_test_time 1.6362022999999226
Test Epoch14 layer4 Acc 0.796, AUC 0.8908727169036865, avg_entr 0.10806947201490402, f1 0.796000063419342
ep14_l4_test_time 2.2730576410001504
gc 0
Train Epoch15 Acc 0.8969 (35876/40000), AUC 0.9600444436073303
ep15_train_time 65.78732830100012
Test Epoch15 layer0 Acc 0.7562, AUC 0.8649458885192871, avg_entr 0.172624871134758, f1 0.7561999559402466
ep15_l0_test_time 0.7113662600002044
Test Epoch15 layer1 Acc 0.7732, AUC 0.8802971839904785, avg_entr 0.09071763604879379, f1 0.7731999754905701
ep15_l1_test_time 0.8453440210000736
Test Epoch15 layer2 Acc 0.7736, AUC 0.8863616585731506, avg_entr 0.07991398125886917, f1 0.7735999822616577
ep15_l2_test_time 1.1573140860000422
Test Epoch15 layer3 Acc 0.7744, AUC 0.8860703110694885, avg_entr 0.07627028971910477, f1 0.7743999361991882
ep15_l3_test_time 1.6407207089998792
Test Epoch15 layer4 Acc 0.7758, AUC 0.8856946229934692, avg_entr 0.07677194476127625, f1 0.7758000493049622
ep15_l4_test_time 2.271117559000004
gc 0
Train Epoch16 Acc 0.904925 (36197/40000), AUC 0.9639748930931091
ep16_train_time 66.087395689
Test Epoch16 layer0 Acc 0.7814, AUC 0.861732006072998, avg_entr 0.1838335543870926, f1 0.7814000248908997
ep16_l0_test_time 0.6448359850000998
Test Epoch16 layer1 Acc 0.798, AUC 0.8773394823074341, avg_entr 0.09536195546388626, f1 0.7979999780654907
ep16_l1_test_time 0.8427261730000737
Test Epoch16 layer2 Acc 0.7998, AUC 0.8833515644073486, avg_entr 0.0803646668791771, f1 0.7997999787330627
ep16_l2_test_time 1.1583171240001775
Test Epoch16 layer3 Acc 0.8006, AUC 0.8833793997764587, avg_entr 0.07575558125972748, f1 0.800599992275238
ep16_l3_test_time 1.6434556249998877
Test Epoch16 layer4 Acc 0.801, AUC 0.8836199045181274, avg_entr 0.07416737079620361, f1 0.8010000586509705
ep16_l4_test_time 2.2814854859998377
gc 0
Train Epoch17 Acc 0.915325 (36613/40000), AUC 0.9699910879135132
ep17_train_time 65.64656025900013
Test Epoch17 layer0 Acc 0.7792, AUC 0.8618394136428833, avg_entr 0.1781637817621231, f1 0.7791999578475952
ep17_l0_test_time 0.6356662560001496
Test Epoch17 layer1 Acc 0.7888, AUC 0.8729320764541626, avg_entr 0.08098851144313812, f1 0.7888000011444092
ep17_l1_test_time 0.8313501249999717
Test Epoch17 layer2 Acc 0.7922, AUC 0.8798587322235107, avg_entr 0.0704360157251358, f1 0.7922000288963318
ep17_l2_test_time 1.150230472999965
Test Epoch17 layer3 Acc 0.7928, AUC 0.8790866136550903, avg_entr 0.06814940273761749, f1 0.7928000092506409
ep17_l3_test_time 1.6334292609999466
Test Epoch17 layer4 Acc 0.7928, AUC 0.8791916966438293, avg_entr 0.06695166230201721, f1 0.7928000092506409
ep17_l4_test_time 2.269975922999947
gc 0
Train Epoch18 Acc 0.922875 (36915/40000), AUC 0.9739311337471008
ep18_train_time 65.66405542100006
Test Epoch18 layer0 Acc 0.7782, AUC 0.8579156398773193, avg_entr 0.17754162847995758, f1 0.7781999707221985
ep18_l0_test_time 0.6382419670001127
Test Epoch18 layer1 Acc 0.7888, AUC 0.866869330406189, avg_entr 0.07716456800699234, f1 0.7888000011444092
ep18_l1_test_time 0.8300890839998374
Test Epoch18 layer2 Acc 0.7914, AUC 0.8742296695709229, avg_entr 0.0693189948797226, f1 0.7914000153541565
ep18_l2_test_time 1.1537753200000225
Test Epoch18 layer3 Acc 0.7926, AUC 0.8739486932754517, avg_entr 0.06630808115005493, f1 0.7925999760627747
ep18_l3_test_time 1.6359799379999913
Test Epoch18 layer4 Acc 0.7934, AUC 0.873943567276001, avg_entr 0.06461438536643982, f1 0.79339998960495
ep18_l4_test_time 2.269342748000099
gc 0
Train Epoch19 Acc 0.92795 (37118/40000), AUC 0.9778907299041748
ep19_train_time 65.66481376500019
Test Epoch19 layer0 Acc 0.772, AUC 0.856209397315979, avg_entr 0.17378096282482147, f1 0.7720000147819519
ep19_l0_test_time 0.6395756469999014
Test Epoch19 layer1 Acc 0.7894, AUC 0.8666571974754333, avg_entr 0.07246644049882889, f1 0.7893999814987183
ep19_l1_test_time 0.8464070099998935
Test Epoch19 layer2 Acc 0.7916, AUC 0.8759227991104126, avg_entr 0.06405723094940186, f1 0.7915999889373779
ep19_l2_test_time 1.1537003799999184
Test Epoch19 layer3 Acc 0.7918, AUC 0.8752667903900146, avg_entr 0.06169573962688446, f1 0.7918000221252441
ep19_l3_test_time 1.6358115540001563
Test Epoch19 layer4 Acc 0.7932, AUC 0.8758094906806946, avg_entr 0.061208002269268036, f1 0.7932000160217285
ep19_l4_test_time 2.2778733659999943
gc 0
Train Epoch20 Acc 0.933325 (37333/40000), AUC 0.9802032709121704
ep20_train_time 65.75422727099999
Test Epoch20 layer0 Acc 0.7732, AUC 0.8528096079826355, avg_entr 0.16861769556999207, f1 0.7731999754905701
ep20_l0_test_time 0.6358702259999518
Test Epoch20 layer1 Acc 0.7874, AUC 0.862377405166626, avg_entr 0.07551965117454529, f1 0.7874000072479248
ep20_l1_test_time 0.831181972999957
Test Epoch20 layer2 Acc 0.7868, AUC 0.8719251751899719, avg_entr 0.06536208093166351, f1 0.786799967288971
ep20_l2_test_time 1.1510407200000827
Test Epoch20 layer3 Acc 0.7884, AUC 0.872369647026062, avg_entr 0.06221301853656769, f1 0.7884000539779663
ep20_l3_test_time 1.6343417690000024
Test Epoch20 layer4 Acc 0.7888, AUC 0.8728104829788208, avg_entr 0.06106532737612724, f1 0.7888000011444092
ep20_l4_test_time 2.270175096999992
gc 0
Train Epoch21 Acc 0.938175 (37527/40000), AUC 0.9821169376373291
ep21_train_time 65.75392012800012
Test Epoch21 layer0 Acc 0.7688, AUC 0.8519742488861084, avg_entr 0.1651908904314041, f1 0.7688000202178955
ep21_l0_test_time 0.6359235039999476
Test Epoch21 layer1 Acc 0.7824, AUC 0.8604538440704346, avg_entr 0.06745241582393646, f1 0.7824000120162964
ep21_l1_test_time 0.8288788830000158
Test Epoch21 layer2 Acc 0.7866, AUC 0.8699719309806824, avg_entr 0.05817423015832901, f1 0.7865999937057495
ep21_l2_test_time 1.1534734930000923
Test Epoch21 layer3 Acc 0.79, AUC 0.8695144653320312, avg_entr 0.05632564052939415, f1 0.7900000214576721
ep21_l3_test_time 1.6351339979999011
Test Epoch21 layer4 Acc 0.7892, AUC 0.8697335720062256, avg_entr 0.05505352094769478, f1 0.7892000079154968
ep21_l4_test_time 2.268519320999985
gc 0
Train Epoch22 Acc 0.94205 (37682/40000), AUC 0.9839847087860107
ep22_train_time 65.63339956499999
Test Epoch22 layer0 Acc 0.7682, AUC 0.8514251112937927, avg_entr 0.1644611805677414, f1 0.7681999802589417
ep22_l0_test_time 0.6508831940000164
Test Epoch22 layer1 Acc 0.7838, AUC 0.8604260683059692, avg_entr 0.06493481248617172, f1 0.7838000059127808
ep22_l1_test_time 0.8329493070000353
Test Epoch22 layer2 Acc 0.7884, AUC 0.8700295686721802, avg_entr 0.05508168786764145, f1 0.7884000539779663
ep22_l2_test_time 1.1561027990001094
Test Epoch22 layer3 Acc 0.7892, AUC 0.8693519830703735, avg_entr 0.053085364401340485, f1 0.7892000079154968
ep22_l3_test_time 1.6340126369998416
Test Epoch22 layer4 Acc 0.7892, AUC 0.8701077699661255, avg_entr 0.052394893020391464, f1 0.7892000079154968
ep22_l4_test_time 2.2717632929998217
gc 0
Train Epoch23 Acc 0.944125 (37765/40000), AUC 0.9856902360916138
ep23_train_time 65.62500567500001
Test Epoch23 layer0 Acc 0.7696, AUC 0.8490949273109436, avg_entr 0.16347633302211761, f1 0.769599974155426
ep23_l0_test_time 0.639217527000028
Test Epoch23 layer1 Acc 0.784, AUC 0.8571288585662842, avg_entr 0.06275598704814911, f1 0.7839999794960022
ep23_l1_test_time 0.831869794000113
Test Epoch23 layer2 Acc 0.7876, AUC 0.8682385087013245, avg_entr 0.05397243797779083, f1 0.7875999212265015
ep23_l2_test_time 1.1519486570000481
Test Epoch23 layer3 Acc 0.7882, AUC 0.8676977753639221, avg_entr 0.051591407507658005, f1 0.7882000207901001
ep23_l3_test_time 1.6358776590000161
Test Epoch23 layer4 Acc 0.7884, AUC 0.8682957291603088, avg_entr 0.050832681357860565, f1 0.7884000539779663
ep23_l4_test_time 2.2694455890000427
gc 0
Train Epoch24 Acc 0.94695 (37878/40000), AUC 0.9867374897003174
ep24_train_time 65.70190551499991
Test Epoch24 layer0 Acc 0.7696, AUC 0.84890216588974, avg_entr 0.15873582661151886, f1 0.769599974155426
ep24_l0_test_time 0.6359521820002101
Test Epoch24 layer1 Acc 0.7858, AUC 0.8540682792663574, avg_entr 0.05941417068243027, f1 0.7857999801635742
ep24_l1_test_time 0.828205589999925
Test Epoch24 layer2 Acc 0.7888, AUC 0.8673957586288452, avg_entr 0.050854429602622986, f1 0.7888000011444092
ep24_l2_test_time 1.1533357430000706
Test Epoch24 layer3 Acc 0.7908, AUC 0.868034839630127, avg_entr 0.04804416373372078, f1 0.7907999753952026
ep24_l3_test_time 1.6366703680000683
Test Epoch24 layer4 Acc 0.7906, AUC 0.868690013885498, avg_entr 0.047303639352321625, f1 0.7906000018119812
ep24_l4_test_time 2.2702495060000274
gc 0
Train Epoch25 Acc 0.949275 (37971/40000), AUC 0.9875957369804382
ep25_train_time 65.61276346599993
Test Epoch25 layer0 Acc 0.7682, AUC 0.8477110862731934, avg_entr 0.15944741666316986, f1 0.7681999802589417
ep25_l0_test_time 0.6389259070001572
Test Epoch25 layer1 Acc 0.783, AUC 0.8530973196029663, avg_entr 0.05947491526603699, f1 0.7829999923706055
ep25_l1_test_time 0.8293670450000263
Test Epoch25 layer2 Acc 0.788, AUC 0.865381121635437, avg_entr 0.05056456848978996, f1 0.7879999876022339
ep25_l2_test_time 1.15412470199999
Test Epoch25 layer3 Acc 0.7892, AUC 0.8661453723907471, avg_entr 0.04737789183855057, f1 0.7892000079154968
ep25_l3_test_time 1.635732292999819
Test Epoch25 layer4 Acc 0.7894, AUC 0.8666771054267883, avg_entr 0.04653465747833252, f1 0.7893999814987183
ep25_l4_test_time 2.2706336129999727
gc 0
Train Epoch26 Acc 0.950075 (38003/40000), AUC 0.987842857837677
ep26_train_time 65.601579937
Test Epoch26 layer0 Acc 0.7676, AUC 0.8469974994659424, avg_entr 0.159778892993927, f1 0.7675999402999878
ep26_l0_test_time 0.6353220949999923
Test Epoch26 layer1 Acc 0.7786, AUC 0.8484975099563599, avg_entr 0.05869168043136597, f1 0.7785999774932861
ep26_l1_test_time 0.8305650449999575
Test Epoch26 layer2 Acc 0.7824, AUC 0.8611451387405396, avg_entr 0.05124777927994728, f1 0.7824000120162964
ep26_l2_test_time 1.150254577999931
Test Epoch26 layer3 Acc 0.7828, AUC 0.8631526231765747, avg_entr 0.0480148084461689, f1 0.782800018787384
ep26_l3_test_time 1.6359072420000302
Test Epoch26 layer4 Acc 0.784, AUC 0.8637499213218689, avg_entr 0.0471402183175087, f1 0.7839999794960022
ep26_l4_test_time 2.269774840000082
gc 0
Train Epoch27 Acc 0.95255 (38102/40000), AUC 0.9890730381011963
ep27_train_time 65.63521907199993
Test Epoch27 layer0 Acc 0.7646, AUC 0.846457302570343, avg_entr 0.15609440207481384, f1 0.7645999789237976
ep27_l0_test_time 0.6359052719999454
Test Epoch27 layer1 Acc 0.7808, AUC 0.8475693464279175, avg_entr 0.05829674005508423, f1 0.7808000445365906
ep27_l1_test_time 0.8293005450000237
Test Epoch27 layer2 Acc 0.785, AUC 0.8604494333267212, avg_entr 0.05070292204618454, f1 0.7850000262260437
ep27_l2_test_time 1.1529324420000648
Test Epoch27 layer3 Acc 0.7858, AUC 0.8632408380508423, avg_entr 0.04720555245876312, f1 0.7857999801635742
ep27_l3_test_time 1.6345239639999818
Test Epoch27 layer4 Acc 0.7852, AUC 0.863895833492279, avg_entr 0.046541474759578705, f1 0.7851999998092651
ep27_l4_test_time 2.2689330809998864
gc 0
Train Epoch28 Acc 0.95295 (38118/40000), AUC 0.9886699318885803
ep28_train_time 65.75227787599988
Test Epoch28 layer0 Acc 0.7644, AUC 0.8455928564071655, avg_entr 0.1571229100227356, f1 0.7644000053405762
ep28_l0_test_time 0.6394150840001203
Test Epoch28 layer1 Acc 0.7778, AUC 0.8440540432929993, avg_entr 0.05386390537023544, f1 0.7778000235557556
ep28_l1_test_time 0.8301735869999902
Test Epoch28 layer2 Acc 0.7808, AUC 0.8576875329017639, avg_entr 0.046950921416282654, f1 0.7808000445365906
ep28_l2_test_time 1.163975556999958
Test Epoch28 layer3 Acc 0.7812, AUC 0.8593515157699585, avg_entr 0.04430089890956879, f1 0.7811999917030334
ep28_l3_test_time 1.6357472889999372
Test Epoch28 layer4 Acc 0.7812, AUC 0.8597208261489868, avg_entr 0.04360118880867958, f1 0.7811999917030334
ep28_l4_test_time 2.2700038040002255
gc 0
Train Epoch29 Acc 0.95475 (38190/40000), AUC 0.9896331429481506
ep29_train_time 65.77942765299986
Test Epoch29 layer0 Acc 0.7646, AUC 0.8449004888534546, avg_entr 0.15564095973968506, f1 0.7645999789237976
ep29_l0_test_time 0.6378167100001519
Test Epoch29 layer1 Acc 0.7772, AUC 0.8447336554527283, avg_entr 0.05618738383054733, f1 0.777199923992157
ep29_l1_test_time 0.8335909999996147
Test Epoch29 layer2 Acc 0.7804, AUC 0.8578137159347534, avg_entr 0.04801215976476669, f1 0.7803999781608582
ep29_l2_test_time 1.1545177939997302
Test Epoch29 layer3 Acc 0.7802, AUC 0.8604093194007874, avg_entr 0.044730495661497116, f1 0.7801999449729919
ep29_l3_test_time 1.6351532599996972
Test Epoch29 layer4 Acc 0.7806, AUC 0.8609573841094971, avg_entr 0.04397895187139511, f1 0.7806000113487244
ep29_l4_test_time 2.273918987000343
gc 0
Train Epoch30 Acc 0.954575 (38183/40000), AUC 0.9897059798240662
ep30_train_time 65.64757115300017
Test Epoch30 layer0 Acc 0.7668, AUC 0.8450015187263489, avg_entr 0.15622127056121826, f1 0.7667999863624573
ep30_l0_test_time 0.6454296209999484
Test Epoch30 layer1 Acc 0.784, AUC 0.8482375144958496, avg_entr 0.05845099315047264, f1 0.7839999794960022
ep30_l1_test_time 0.8387362349999421
Test Epoch30 layer2 Acc 0.7838, AUC 0.8616377115249634, avg_entr 0.049508098512887955, f1 0.7838000059127808
ep30_l2_test_time 1.1617428920003476
Test Epoch30 layer3 Acc 0.7844, AUC 0.86435467004776, avg_entr 0.046694524586200714, f1 0.7843999266624451
ep30_l3_test_time 1.641925060000176
Test Epoch30 layer4 Acc 0.7844, AUC 0.864845871925354, avg_entr 0.04631306231021881, f1 0.7843999266624451
ep30_l4_test_time 2.276249108000229
gc 0
Train Epoch31 Acc 0.955825 (38233/40000), AUC 0.9898824095726013
ep31_train_time 65.61543479500006
Test Epoch31 layer0 Acc 0.7668, AUC 0.8441799879074097, avg_entr 0.15631051361560822, f1 0.7667999863624573
ep31_l0_test_time 0.6408396100000573
Test Epoch31 layer1 Acc 0.7788, AUC 0.8455449938774109, avg_entr 0.05747843161225319, f1 0.7788000106811523
ep31_l1_test_time 0.8300243610001417
Test Epoch31 layer2 Acc 0.782, AUC 0.8592637777328491, avg_entr 0.04897308349609375, f1 0.7820000052452087
ep31_l2_test_time 1.1545415639998282
Test Epoch31 layer3 Acc 0.783, AUC 0.86138916015625, avg_entr 0.04629436880350113, f1 0.7829999923706055
ep31_l3_test_time 1.6366444860000229
Test Epoch31 layer4 Acc 0.7826, AUC 0.8619201183319092, avg_entr 0.045685384422540665, f1 0.7825999855995178
ep31_l4_test_time 2.273416419000114
gc 0
Train Epoch32 Acc 0.9568 (38272/40000), AUC 0.9904440641403198
ep32_train_time 65.73513569499983
Test Epoch32 layer0 Acc 0.7644, AUC 0.8442668318748474, avg_entr 0.15483978390693665, f1 0.7644000053405762
ep32_l0_test_time 0.6686926170000334
Test Epoch32 layer1 Acc 0.7756, AUC 0.8457304239273071, avg_entr 0.054812196642160416, f1 0.775600016117096
ep32_l1_test_time 0.8451457689998279
Test Epoch32 layer2 Acc 0.7804, AUC 0.8586488962173462, avg_entr 0.0471622571349144, f1 0.7803999781608582
ep32_l2_test_time 1.1591680559999986
Test Epoch32 layer3 Acc 0.7816, AUC 0.860424816608429, avg_entr 0.044058918952941895, f1 0.7815999984741211
ep32_l3_test_time 1.6418692199999896
Test Epoch32 layer4 Acc 0.7834, AUC 0.861108660697937, avg_entr 0.043098852038383484, f1 0.7833999395370483
ep32_l4_test_time 2.269551768999918
gc 0
Train Epoch33 Acc 0.95795 (38318/40000), AUC 0.9909029006958008
ep33_train_time 65.66320566000013
Test Epoch33 layer0 Acc 0.7652, AUC 0.844413161277771, avg_entr 0.15302087366580963, f1 0.7652000188827515
ep33_l0_test_time 0.6364341270000295
Test Epoch33 layer1 Acc 0.7804, AUC 0.8443444967269897, avg_entr 0.054852839559316635, f1 0.7803999781608582
ep33_l1_test_time 0.82973888000015
Test Epoch33 layer2 Acc 0.7832, AUC 0.8581280708312988, avg_entr 0.04569794610142708, f1 0.7832000851631165
ep33_l2_test_time 1.1728022679999413
Test Epoch33 layer3 Acc 0.7828, AUC 0.8606464862823486, avg_entr 0.04251762479543686, f1 0.782800018787384
ep33_l3_test_time 1.6373941389997526
Test Epoch33 layer4 Acc 0.783, AUC 0.8612499237060547, avg_entr 0.04172227159142494, f1 0.7829999923706055
ep33_l4_test_time 2.267605571999866
gc 0
Train Epoch34 Acc 0.957075 (38283/40000), AUC 0.9907486438751221
ep34_train_time 65.62389022299976
Test Epoch34 layer0 Acc 0.7664, AUC 0.8442144393920898, avg_entr 0.15457455813884735, f1 0.7663999199867249
ep34_l0_test_time 0.6372998859997097
Test Epoch34 layer1 Acc 0.7806, AUC 0.8448359966278076, avg_entr 0.055634308606386185, f1 0.7806000113487244
ep34_l1_test_time 0.8273396249996949
Test Epoch34 layer2 Acc 0.783, AUC 0.858567476272583, avg_entr 0.04583146795630455, f1 0.7829999923706055
ep34_l2_test_time 1.1521776969998427
Test Epoch34 layer3 Acc 0.783, AUC 0.8612963557243347, avg_entr 0.04323199763894081, f1 0.7829999923706055
ep34_l3_test_time 1.6360950919997777
Test Epoch34 layer4 Acc 0.7834, AUC 0.8618545532226562, avg_entr 0.042627155780792236, f1 0.7833999395370483
ep34_l4_test_time 2.2772847669998555
gc 0
Train Epoch35 Acc 0.958225 (38329/40000), AUC 0.9911727905273438
ep35_train_time 65.74086210600035
Test Epoch35 layer0 Acc 0.7658, AUC 0.8440439701080322, avg_entr 0.1537584364414215, f1 0.7657999992370605
ep35_l0_test_time 0.6396488380000847
Test Epoch35 layer1 Acc 0.7756, AUC 0.8438791036605835, avg_entr 0.05376347526907921, f1 0.775600016117096
ep35_l1_test_time 0.8341036000001623
Test Epoch35 layer2 Acc 0.7816, AUC 0.8576127290725708, avg_entr 0.045120954513549805, f1 0.7815999984741211
ep35_l2_test_time 1.1598809940001047
Test Epoch35 layer3 Acc 0.784, AUC 0.8600155711174011, avg_entr 0.041220422834157944, f1 0.7839999794960022
ep35_l3_test_time 1.6417361500002698
Test Epoch35 layer4 Acc 0.7838, AUC 0.8607258796691895, avg_entr 0.04032807797193527, f1 0.7838000059127808
ep35_l4_test_time 2.279508577999877
gc 0
Train Epoch36 Acc 0.958775 (38351/40000), AUC 0.9910449981689453
ep36_train_time 65.64617653599998
Test Epoch36 layer0 Acc 0.765, AUC 0.8441461324691772, avg_entr 0.1528594046831131, f1 0.7649999856948853
ep36_l0_test_time 0.6371553029998722
Test Epoch36 layer1 Acc 0.7778, AUC 0.8434978127479553, avg_entr 0.0537743903696537, f1 0.7778000235557556
ep36_l1_test_time 0.8385916229999566
Test Epoch36 layer2 Acc 0.7806, AUC 0.8576339483261108, avg_entr 0.0447051078081131, f1 0.7806000113487244
ep36_l2_test_time 1.154182149999997
Test Epoch36 layer3 Acc 0.781, AUC 0.8603238463401794, avg_entr 0.04140390083193779, f1 0.781000018119812
ep36_l3_test_time 1.6379454360003365
Test Epoch36 layer4 Acc 0.7812, AUC 0.8609083890914917, avg_entr 0.04066643491387367, f1 0.7811999917030334
ep36_l4_test_time 2.26939888600009
gc 0
Train Epoch37 Acc 0.957625 (38305/40000), AUC 0.991230845451355
ep37_train_time 65.74299863100032
Test Epoch37 layer0 Acc 0.7662, AUC 0.8438200950622559, avg_entr 0.15239576995372772, f1 0.766200065612793
ep37_l0_test_time 0.6384669889998804
Test Epoch37 layer1 Acc 0.7806, AUC 0.8441106081008911, avg_entr 0.054347679018974304, f1 0.7806000113487244
ep37_l1_test_time 0.8291860710000947
Test Epoch37 layer2 Acc 0.7826, AUC 0.8583093881607056, avg_entr 0.045721739530563354, f1 0.7825999855995178
ep37_l2_test_time 1.1530905949998669
Test Epoch37 layer3 Acc 0.7824, AUC 0.860628604888916, avg_entr 0.043090615421533585, f1 0.7824000120162964
ep37_l3_test_time 1.636737902999812
Test Epoch37 layer4 Acc 0.7826, AUC 0.8612244129180908, avg_entr 0.04230447858572006, f1 0.7825999855995178
ep37_l4_test_time 2.2777005880002434
gc 0
Train Epoch38 Acc 0.958175 (38327/40000), AUC 0.9910194277763367
ep38_train_time 65.64628664600014
Test Epoch38 layer0 Acc 0.7664, AUC 0.843722403049469, avg_entr 0.15300309658050537, f1 0.7663999199867249
ep38_l0_test_time 0.6383160479999788
Test Epoch38 layer1 Acc 0.7798, AUC 0.8437970876693726, avg_entr 0.055223118513822556, f1 0.7797999978065491
ep38_l1_test_time 0.832479013000011
Test Epoch38 layer2 Acc 0.781, AUC 0.8580353856086731, avg_entr 0.04580284282565117, f1 0.781000018119812
ep38_l2_test_time 1.1523632100002033
Test Epoch38 layer3 Acc 0.7808, AUC 0.8606699705123901, avg_entr 0.043002042919397354, f1 0.7808000445365906
ep38_l3_test_time 1.6373191269999552
Test Epoch38 layer4 Acc 0.781, AUC 0.8612277507781982, avg_entr 0.04221592843532562, f1 0.781000018119812
ep38_l4_test_time 2.2762914920003823
gc 0
Train Epoch39 Acc 0.958375 (38335/40000), AUC 0.9912559390068054
ep39_train_time 65.83195867299992
Test Epoch39 layer0 Acc 0.7648, AUC 0.8433868885040283, avg_entr 0.1527707725763321, f1 0.764799952507019
ep39_l0_test_time 0.6391955809999672
Test Epoch39 layer1 Acc 0.7784, AUC 0.8439490795135498, avg_entr 0.05338612571358681, f1 0.7784000039100647
ep39_l1_test_time 0.8314065290001054
Test Epoch39 layer2 Acc 0.7804, AUC 0.857654869556427, avg_entr 0.044517576694488525, f1 0.7803999781608582
ep39_l2_test_time 1.1514765420001822
Test Epoch39 layer3 Acc 0.7808, AUC 0.8603006601333618, avg_entr 0.04123339429497719, f1 0.7808000445365906
ep39_l3_test_time 1.6351347069999065
Test Epoch39 layer4 Acc 0.7808, AUC 0.8609180450439453, avg_entr 0.040405262261629105, f1 0.7808000445365906
ep39_l4_test_time 2.26962097500018
gc 0
Train Epoch40 Acc 0.960425 (38417/40000), AUC 0.991622805595398
ep40_train_time 65.64300213200022
Test Epoch40 layer0 Acc 0.7648, AUC 0.8433279991149902, avg_entr 0.15237464010715485, f1 0.764799952507019
ep40_l0_test_time 0.6390719060000265
Test Epoch40 layer1 Acc 0.779, AUC 0.84300297498703, avg_entr 0.05463718995451927, f1 0.7789999842643738
ep40_l1_test_time 0.8315083920001598
Test Epoch40 layer2 Acc 0.781, AUC 0.8568877577781677, avg_entr 0.044699009507894516, f1 0.781000018119812
ep40_l2_test_time 1.155378018999727
Test Epoch40 layer3 Acc 0.7812, AUC 0.8602356910705566, avg_entr 0.04199475049972534, f1 0.7811999917030334
ep40_l3_test_time 1.6370068269998228
Test Epoch40 layer4 Acc 0.7816, AUC 0.8608078956604004, avg_entr 0.04121225327253342, f1 0.7815999984741211
ep40_l4_test_time 2.270906064999963
gc 0
Train Epoch41 Acc 0.9588 (38352/40000), AUC 0.9913209080696106
ep41_train_time 65.666880279
Test Epoch41 layer0 Acc 0.7642, AUC 0.8432617783546448, avg_entr 0.15251240134239197, f1 0.76419997215271
ep41_l0_test_time 0.6449859600002128
Test Epoch41 layer1 Acc 0.7778, AUC 0.8429938554763794, avg_entr 0.0543089285492897, f1 0.7778000235557556
ep41_l1_test_time 0.844070111000292
Test Epoch41 layer2 Acc 0.7802, AUC 0.8567012548446655, avg_entr 0.04492262750864029, f1 0.7801999449729919
ep41_l2_test_time 1.1624159680000048
Test Epoch41 layer3 Acc 0.7804, AUC 0.8596153259277344, avg_entr 0.04199743643403053, f1 0.7803999781608582
ep41_l3_test_time 1.6450001620000876
Test Epoch41 layer4 Acc 0.7804, AUC 0.860221266746521, avg_entr 0.04119797423481941, f1 0.7803999781608582
ep41_l4_test_time 2.278073813999981
gc 0
Train Epoch42 Acc 0.9582 (38328/40000), AUC 0.9913081526756287
ep42_train_time 65.71725793699989
Test Epoch42 layer0 Acc 0.7652, AUC 0.8434569835662842, avg_entr 0.15210698544979095, f1 0.7652000188827515
ep42_l0_test_time 0.6407519419999517
Test Epoch42 layer1 Acc 0.778, AUC 0.8433176875114441, avg_entr 0.053216807544231415, f1 0.777999997138977
ep42_l1_test_time 0.8332820369996625
Test Epoch42 layer2 Acc 0.7798, AUC 0.8567519783973694, avg_entr 0.04420240595936775, f1 0.7797999978065491
ep42_l2_test_time 1.1531469339997784
Test Epoch42 layer3 Acc 0.7802, AUC 0.8595026135444641, avg_entr 0.04106858745217323, f1 0.7801999449729919
ep42_l3_test_time 1.639249765000386
Test Epoch42 layer4 Acc 0.7802, AUC 0.8602346777915955, avg_entr 0.0402664877474308, f1 0.7801999449729919
ep42_l4_test_time 2.272139896999761
gc 0
Train Epoch43 Acc 0.959275 (38371/40000), AUC 0.9917047023773193
ep43_train_time 65.67513043300005
Test Epoch43 layer0 Acc 0.764, AUC 0.8435149192810059, avg_entr 0.15176203846931458, f1 0.7639999985694885
ep43_l0_test_time 0.6462840919998598
Test Epoch43 layer1 Acc 0.7772, AUC 0.8431839346885681, avg_entr 0.05287843197584152, f1 0.777199923992157
ep43_l1_test_time 0.838769265999872
Test Epoch43 layer2 Acc 0.78, AUC 0.8565036058425903, avg_entr 0.04401867091655731, f1 0.7799999117851257
ep43_l2_test_time 1.159007253999789
Test Epoch43 layer3 Acc 0.781, AUC 0.8594361543655396, avg_entr 0.04074681177735329, f1 0.781000018119812
ep43_l3_test_time 1.6357978710002499
Test Epoch43 layer4 Acc 0.7808, AUC 0.8601549863815308, avg_entr 0.03998390957713127, f1 0.7808000445365906
ep43_l4_test_time 2.26980215399999
gc 0
Train Epoch44 Acc 0.959725 (38389/40000), AUC 0.9915868043899536
ep44_train_time 65.65006392799978
Test Epoch44 layer0 Acc 0.7638, AUC 0.8434359431266785, avg_entr 0.1517520695924759, f1 0.7638000249862671
ep44_l0_test_time 0.638488260000031
Test Epoch44 layer1 Acc 0.7766, AUC 0.8433541059494019, avg_entr 0.05237627029418945, f1 0.7766000032424927
ep44_l1_test_time 0.8302225799998268
Test Epoch44 layer2 Acc 0.7786, AUC 0.8564211130142212, avg_entr 0.043949756771326065, f1 0.7785999774932861
ep44_l2_test_time 1.1543379740001
Test Epoch44 layer3 Acc 0.7814, AUC 0.8593899011611938, avg_entr 0.040551185607910156, f1 0.7814000248908997
ep44_l3_test_time 1.6375281290002022
Test Epoch44 layer4 Acc 0.782, AUC 0.860075831413269, avg_entr 0.03968187794089317, f1 0.7820000052452087
ep44_l4_test_time 2.271129028999894
gc 0
Train Epoch45 Acc 0.959475 (38379/40000), AUC 0.991382896900177
ep45_train_time 65.67414535900025
Test Epoch45 layer0 Acc 0.7634, AUC 0.8432955741882324, avg_entr 0.1515367329120636, f1 0.7634000182151794
ep45_l0_test_time 0.6390942159996484
Test Epoch45 layer1 Acc 0.777, AUC 0.8431611061096191, avg_entr 0.052652858197689056, f1 0.7770000100135803
ep45_l1_test_time 0.8390681460000451
Test Epoch45 layer2 Acc 0.7798, AUC 0.8563433289527893, avg_entr 0.04402961581945419, f1 0.7797999978065491
ep45_l2_test_time 1.153981450000174
Test Epoch45 layer3 Acc 0.7818, AUC 0.8592979907989502, avg_entr 0.04067772254347801, f1 0.7817999720573425
ep45_l3_test_time 1.6375803579999229
Test Epoch45 layer4 Acc 0.7816, AUC 0.859987199306488, avg_entr 0.03981317579746246, f1 0.7815999984741211
ep45_l4_test_time 2.27112510500001
gc 0
Train Epoch46 Acc 0.95965 (38386/40000), AUC 0.9917082786560059
ep46_train_time 65.6508462679999
Test Epoch46 layer0 Acc 0.764, AUC 0.8432883024215698, avg_entr 0.1514972299337387, f1 0.7639999985694885
ep46_l0_test_time 0.6384594359997209
Test Epoch46 layer1 Acc 0.7774, AUC 0.8430854678153992, avg_entr 0.05241924896836281, f1 0.777400016784668
ep46_l1_test_time 0.8313143509999463
Test Epoch46 layer2 Acc 0.7794, AUC 0.8562822341918945, avg_entr 0.04380475729703903, f1 0.7794000506401062
ep46_l2_test_time 1.1551926369998
Test Epoch46 layer3 Acc 0.7824, AUC 0.8592911958694458, avg_entr 0.040421053767204285, f1 0.7824000120162964
ep46_l3_test_time 1.6367522020000251
Test Epoch46 layer4 Acc 0.782, AUC 0.8599900007247925, avg_entr 0.039539434015750885, f1 0.7820000052452087
ep46_l4_test_time 2.2700071210001624
gc 0
Train Epoch47 Acc 0.960075 (38403/40000), AUC 0.991457462310791
ep47_train_time 65.65628254500007
Test Epoch47 layer0 Acc 0.7642, AUC 0.8432120680809021, avg_entr 0.15140314400196075, f1 0.76419997215271
ep47_l0_test_time 0.6463208979998853
Test Epoch47 layer1 Acc 0.777, AUC 0.8429174423217773, avg_entr 0.05255012959241867, f1 0.7770000100135803
ep47_l1_test_time 0.8298117279996404
Test Epoch47 layer2 Acc 0.7788, AUC 0.8560590744018555, avg_entr 0.043812334537506104, f1 0.7788000106811523
ep47_l2_test_time 1.156646973000079
Test Epoch47 layer3 Acc 0.7814, AUC 0.8592917919158936, avg_entr 0.040337201207876205, f1 0.7814000248908997
ep47_l3_test_time 1.6366953759998069
Test Epoch47 layer4 Acc 0.7814, AUC 0.8599990606307983, avg_entr 0.039446763694286346, f1 0.7814000248908997
ep47_l4_test_time 2.271476139999777
gc 0
Train Epoch48 Acc 0.9596 (38384/40000), AUC 0.9913167357444763
ep48_train_time 65.80232890399975
Test Epoch48 layer0 Acc 0.763, AUC 0.8431560397148132, avg_entr 0.15158264338970184, f1 0.7630000114440918
ep48_l0_test_time 0.6376521140000477
Test Epoch48 layer1 Acc 0.7786, AUC 0.8430740833282471, avg_entr 0.0533275343477726, f1 0.7785999774932861
ep48_l1_test_time 0.8327308199995969
Test Epoch48 layer2 Acc 0.7804, AUC 0.8563613295555115, avg_entr 0.04404163733124733, f1 0.7803999781608582
ep48_l2_test_time 1.1520223249999617
Test Epoch48 layer3 Acc 0.781, AUC 0.8595498204231262, avg_entr 0.04092417657375336, f1 0.781000018119812
ep48_l3_test_time 1.634697930999664
Test Epoch48 layer4 Acc 0.7812, AUC 0.8602075576782227, avg_entr 0.04011159762740135, f1 0.7811999917030334
ep48_l4_test_time 2.2713844370000515
gc 0
Train Epoch49 Acc 0.9601 (38404/40000), AUC 0.9914852976799011
ep49_train_time 65.63825595400021
Test Epoch49 layer0 Acc 0.7636, AUC 0.8432044982910156, avg_entr 0.15142680704593658, f1 0.7635999917984009
ep49_l0_test_time 0.6362206019998666
Test Epoch49 layer1 Acc 0.777, AUC 0.8431228399276733, avg_entr 0.052411992102861404, f1 0.7770000100135803
ep49_l1_test_time 0.8301148900000044
Test Epoch49 layer2 Acc 0.7794, AUC 0.8563086986541748, avg_entr 0.04394093528389931, f1 0.7794000506401062
ep49_l2_test_time 1.15224230099966
Test Epoch49 layer3 Acc 0.782, AUC 0.8594468832015991, avg_entr 0.04053422063589096, f1 0.7820000052452087
ep49_l3_test_time 1.6355528839999351
Test Epoch49 layer4 Acc 0.7818, AUC 0.8601419925689697, avg_entr 0.03966080769896507, f1 0.7817999720573425
ep49_l4_test_time 2.2684702149999794
Best AUC tensor(0.8038) 13 3
train_as_loss [[8.33310906e+01 5.80495336e+01 5.18785229e+01 5.03866162e+01
  4.98518072e+01 4.96045946e+01 4.94709995e+01 4.93909067e+01
  4.93392161e+01 4.93039764e+01 4.92789139e+01 4.92604790e+01
  4.92465458e+01 4.92357771e+01 4.92272920e+01 4.92204998e+01
  4.92162095e+01 4.92136345e+01 4.92112188e+01 4.92089553e+01
  4.92073446e+01 4.92062886e+01 4.92052325e+01 4.92041810e+01
  4.92033917e+01 4.92028528e+01 4.92022965e+01 4.92017257e+01
  4.92012857e+01 4.92009794e+01 4.92006578e+01 4.92003200e+01
  4.92000551e+01 4.91998702e+01 4.91996739e+01 4.91994611e+01
  4.91992997e+01 4.91991802e+01 4.91990539e+01 4.91989209e+01
  4.91988137e+01 4.91987418e+01 4.91986548e+01 4.91985729e+01
  4.91984979e+01 4.91984529e+01 4.91984037e+01 4.91983348e+01
  4.91982976e+01 4.91982710e+01]
 [1.98840854e+00 2.12632239e-04 1.79770075e-05 4.77715717e-06
  1.93256353e-06 9.44883385e-07 4.96033554e-07 2.99199334e-07
  1.84983143e-07 1.21904231e-07 8.35969804e-08 5.79164570e-08
  4.21874837e-08 3.01009810e-08 2.22145387e-08 7.16014256e-08
  1.48263936e-08 1.11962680e-08 9.89303903e-09 3.53871958e-08
  7.94632514e-09 6.82302507e-09 6.30701644e-09 2.38778935e-08
  5.47544396e-09 5.04108406e-09 4.77935922e-09 1.86152322e-08
  4.40443809e-09 4.19190110e-09 4.07460339e-09 1.56094385e-08
  3.85983209e-09 3.62598803e-09 3.55302698e-09 1.35941108e-08
  3.56921647e-09 3.28252972e-09 3.20693379e-09 1.19408345e-08
  3.48024024e-09 2.99913684e-09 2.90898806e-09 1.04310321e-08
  3.59280281e-09 2.84347360e-09 2.72307906e-09 8.95884803e-09
  3.89862148e-09 2.81568100e-09]
 [1.91763264e+00 2.13490909e-04 1.77553631e-05 4.29312163e-06
  1.76374335e-06 8.54407039e-07 4.23821090e-07 2.64301130e-07
  1.58601799e-07 1.08880527e-07 7.86026208e-08 5.41366186e-08
  4.12196667e-08 2.79079029e-08 2.15000793e-08 2.17306650e-08
  8.18775568e-09 1.08388365e-08 9.16306729e-09 8.86072539e-09
  3.19416663e-09 6.27264783e-09 5.45903278e-09 5.37967081e-09
  1.69516475e-09 4.49932287e-09 4.02610257e-09 4.05097356e-09
  1.20592175e-09 3.65706056e-09 3.39543761e-09 3.29848470e-09
  9.14374231e-10 3.06114126e-09 2.92374732e-09 2.87227452e-09
  7.74653056e-10 2.72671007e-09 2.64831774e-09 2.55835425e-09
  7.15978637e-10 2.44981365e-09 2.40236920e-09 2.33030579e-09
  6.95775382e-10 2.18988282e-09 2.22611957e-09 2.08890862e-09
  7.19082875e-10 2.03590775e-09]
 [1.87587589e+00 2.36147941e-04 2.15272868e-05 5.61681884e-06
  2.41806616e-06 1.22840016e-06 5.43264339e-07 3.62114557e-07
  2.04018907e-07 1.51984477e-07 1.23579642e-07 8.34670087e-08
  6.77424124e-08 4.11995033e-08 3.46148114e-08 8.85672457e-08
  3.05689838e-08 1.36943880e-08 1.28826984e-08 3.74517247e-08
  1.18774141e-08 7.21396014e-09 6.73837178e-09 2.31324380e-08
  6.47837910e-09 4.99117731e-09 4.68688255e-09 1.74385204e-08
  4.84740860e-09 4.04922387e-09 3.83539815e-09 1.42944044e-08
  3.92835383e-09 3.33281645e-09 3.26801286e-09 1.22291503e-08
  3.60118240e-09 3.01122017e-09 2.94326525e-09 1.06113791e-08
  3.57789229e-09 2.78250672e-09 2.69966607e-09 9.30120873e-09
  3.71598798e-09 2.64727310e-09 2.51858496e-09 7.89308721e-09
  3.99770559e-09 2.65681185e-09]
 [2.44369031e+00 6.71081165e-04 2.45949910e-05 6.24081308e-06
  2.84547215e-06 1.59533293e-06 6.28602339e-07 4.82709656e-07
  2.58167902e-07 2.26161468e-07 2.21869011e-07 1.56229319e-07
  1.37389552e-07 8.03163678e-08 7.87502211e-08 1.38386079e-07
  6.46946824e-08 2.12440058e-08 2.24533291e-08 4.89606894e-08
  2.02083985e-08 9.54382107e-09 9.37089868e-09 2.70762525e-08
  9.01293088e-09 6.04299364e-09 5.64406758e-09 1.97071224e-08
  6.15094409e-09 4.69064576e-09 4.34085055e-09 1.57380328e-08
  4.70138241e-09 3.70357970e-09 3.60131239e-09 1.31118370e-08
  4.29259706e-09 3.34786663e-09 3.27716703e-09 1.12377530e-08
  4.29942710e-09 3.11465650e-09 2.94654101e-09 9.83731321e-09
  4.63147205e-09 3.05998793e-09 2.87865380e-09 8.36709391e-09
  5.17553607e-09 3.40699791e-09]]
train_ae_loss [[5.01731281 3.44546601 4.34568152 4.56152884 4.76145581 4.95967681
  4.98999718 5.02927294 5.04986295 5.08003018 4.99553233 4.92680037
  4.84616223 4.8633574  4.70897824 4.5665317  4.23880871 4.03387994
  3.9410275  3.85676755 3.60496412 3.56015303 3.47787968 3.40932702
  3.30731623 3.26644325 3.23694178 3.25332231 3.1794231  3.14931076
  3.14569883 3.13342276 3.1123065  3.09385479 3.0967932  3.08855027
  3.06484159 3.06380429 3.07254542 3.07245905 3.04336551 3.05121478
  3.05495904 3.06309327 3.05690125 3.04636951 3.06119586 3.05833256
  3.07236432 3.0501195 ]
 [3.87686626 3.39119533 4.56939519 4.5948268  4.67114127 4.84604914
  4.79930595 4.74496737 4.72209335 4.73004859 4.56916797 4.43838006
  4.22178676 4.27474812 3.92738029 3.50355984 3.21032932 2.93473919
  2.81570312 2.60454182 2.36792472 2.29126806 2.18785768 2.05540052
  1.96479335 1.89542105 1.86966134 1.85051437 1.79575608 1.75197706
  1.75086708 1.7174803  1.71385308 1.68163617 1.68385195 1.64924183
  1.63543482 1.64305924 1.65760912 1.63931096 1.59021502 1.61811669
  1.62986789 1.62953071 1.62693524 1.60449372 1.62115535 1.61370185
  1.62939391 1.61298441]
 [5.21086299 3.27202071 4.53531144 4.56672603 4.47379806 4.60754701
  4.46073651 4.26093524 4.17873611 4.1551866  3.95035524 3.83808052
  3.68306733 3.80464724 3.48545172 3.10596949 2.91089281 2.54431985
  2.43424578 2.25181017 2.07584471 1.95225687 1.84843572 1.74462763
  1.67461449 1.59283846 1.56388376 1.54861397 1.5098046  1.46231698
  1.45470642 1.42645933 1.42181779 1.38674356 1.3876189  1.35321953
  1.34462449 1.35333095 1.36523807 1.34408501 1.30510464 1.32755464
  1.33573289 1.33438129 1.33234302 1.31106773 1.3241159  1.32157569
  1.33448423 1.32722431]
 [5.18640267 3.3080524  4.77611462 5.08155089 4.71218291 4.84417459
  4.66043614 4.38322108 4.28576002 4.25431819 4.03468454 3.91288029
  3.74228925 3.8902995  3.54880646 3.11190055 2.87158394 2.57497748
  2.46072537 2.25755859 2.07344864 1.96602256 1.85953344 1.74771304
  1.67147576 1.59829683 1.56855926 1.5494314  1.50805437 1.46450222
  1.455972   1.42510067 1.42103886 1.38509495 1.38722759 1.35012009
  1.34215658 1.35321378 1.36340896 1.34173038 1.30130055 1.32338676
  1.33344511 1.33088723 1.3305264  1.30702025 1.31995872 1.31771776
  1.33373451 1.32406898]
 [5.30951796 2.98842966 4.33270032 5.02669779 4.42259222 4.50158135
  4.28917557 3.96724997 3.87363286 3.84399276 3.63644478 3.52997541
  3.36466586 3.55522485 3.20522549 2.77971803 2.57453562 2.30811762
  2.20374256 2.01518909 1.85363626 1.7566285  1.66044771 1.55772914
  1.49142361 1.42355    1.39826709 1.37954758 1.34396362 1.30305658
  1.29763552 1.26904944 1.26493021 1.233083   1.23514544 1.20134647
  1.19445974 1.20380889 1.21339906 1.19404448 1.157205   1.17699358
  1.18710234 1.18441638 1.1837277  1.16286446 1.17404905 1.17216777
  1.18692933 1.17828789]]
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
total_train+valid_time 3620.199224913
Start Testing
Load ckpt at ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt
gc 9
Test layer0 Acc 0.7844, AUC 0.8674886226654053, avg_entr 0.22096726298332214, f1 0.7843999266624451
l0_test_time 0.640739319000204
gc 0
Test layer1 Acc 0.8034, AUC 0.8841607570648193, avg_entr 0.131410613656044, f1 0.8033999800682068
l1_test_time 0.844023580999874
gc 0
Test layer2 Acc 0.8068, AUC 0.8863059282302856, avg_entr 0.12136173248291016, f1 0.8068000078201294
l2_test_time 1.158970180000324
gc 0
Test layer3 Acc 0.8068, AUC 0.8871454000473022, avg_entr 0.11972902715206146, f1 0.8068000078201294
l3_test_time 1.6420106199998372
gc 0
Test layer4 Acc 0.8046, AUC 0.8871579766273499, avg_entr 0.1175394281744957, f1 0.8046000599861145
l4_test_time 2.275867898999877
gc 0
Test threshold 0.1 Acc 0.804, AUC 0.8779563903808594, avg_entr 0.17296797037124634, f1 0.8040000200271606
t0.1_test_time 1.274264101999961
gc 0
Test threshold 0.2 Acc 0.803, AUC 0.8759252429008484, avg_entr 0.18103504180908203, f1 0.8029999732971191
t0.2_test_time 1.1381561180000972
gc 0
Test threshold 0.3 Acc 0.803, AUC 0.8752601146697998, avg_entr 0.18953174352645874, f1 0.8029999732971191
t0.3_test_time 1.0511105929999758
gc 0
Test threshold 0.4 Acc 0.8026, AUC 0.8751341104507446, avg_entr 0.19987766444683075, f1 0.802600085735321
t0.4_test_time 0.9958042210000713
gc 0
Test threshold 0.5 Acc 0.8, AUC 0.8742310404777527, avg_entr 0.21172919869422913, f1 0.8000000715255737
t0.5_test_time 0.9354567860000316
gc 0
Test threshold 0.6 Acc 0.7982, AUC 0.8738426566123962, avg_entr 0.22631151974201202, f1 0.7982000708580017
t0.6_test_time 0.8878831179999906
gc 0
Test threshold 0.7 Acc 0.797, AUC 0.8704973459243774, avg_entr 0.2403699904680252, f1 0.796999990940094
t0.7_test_time 0.8368991919996915
gc 0
Test threshold 0.8 Acc 0.7962, AUC 0.8702312111854553, avg_entr 0.25645387172698975, f1 0.7961999177932739
t0.8_test_time 0.7938809829997808
gc 0
Test threshold 0.9 Acc 0.7922, AUC 0.8688866496086121, avg_entr 0.2776525020599365, f1 0.7922000288963318
t0.9_test_time 0.7720699410001544
