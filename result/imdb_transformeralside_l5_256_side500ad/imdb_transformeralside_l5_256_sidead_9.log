total count words 222751
vocab size 30000
train size 40000, valid size 5000, test size 5000
found 27937 words in glove
model: TransformerALsideText(
  (layers): ModuleList(
    (0): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=2, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=2, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
  (emb_layers): ModuleList(
    (0): Embedding(30000, 300)
    (1): Embedding(30000, 300)
    (2): Embedding(30000, 300)
    (3): Embedding(30000, 300)
    (4): Embedding(30000, 300)
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.multi_headed_attention.linears.0.weight 90000
layers.0.enc.f.multi_headed_attention.linears.0.bias 300
layers.0.enc.f.multi_headed_attention.linears.1.weight 90000
layers.0.enc.f.multi_headed_attention.linears.1.bias 300
layers.0.enc.f.multi_headed_attention.linears.2.weight 90000
layers.0.enc.f.multi_headed_attention.linears.2.bias 300
layers.0.enc.f.multi_headed_attention.linears.3.weight 90000
layers.0.enc.f.multi_headed_attention.linears.3.bias 300
layers.0.enc.f.feed_forward.w_1.weight 90000
layers.0.enc.f.feed_forward.w_1.bias 300
layers.0.enc.f.feed_forward.w_2.weight 90000
layers.0.enc.f.feed_forward.w_2.bias 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.0.enc.f.encoder.norm.a 300
layers.0.enc.f.encoder.norm.b 300
layers.0.ae.g.0.weight 256
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 256
layers.0.ae.h.0.bias 2
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
emb_layers.0.weight 9000000
emb_layers.1.weight 9000000
emb_layers.2.weight 9000000
emb_layers.3.weight 9000000
emb_layers.4.weight 9000000
Total Trainable Params: 50758378
init_time 21.059835019999998
Start Training
gc 0
Train Epoch0 Acc 0.499275 (19971/40000), AUC 0.49928903579711914
ep0_train_time 65.805085514
Test Epoch0 layer0 Acc 0.544, AUC 0.6067284941673279, avg_entr 0.6920894384384155, f1 0.5440000295639038
ep0_l0_test_time 0.619900732000005
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 0
Test Epoch0 layer1 Acc 0.5192, AUC 0.53797447681427, avg_entr 0.6929122805595398, f1 0.5192000269889832
ep0_l1_test_time 0.8218406260000108
Test Epoch0 layer2 Acc 0.5088, AUC 0.5165287256240845, avg_entr 0.6917010545730591, f1 0.5088000297546387
ep0_l2_test_time 1.1355233529999964
Test Epoch0 layer3 Acc 0.4666, AUC 0.456276535987854, avg_entr 0.6917396783828735, f1 0.4666000008583069
ep0_l3_test_time 1.6199557959999993
Test Epoch0 layer4 Acc 0.5118, AUC 0.5006580352783203, avg_entr 0.6944875717163086, f1 0.5117999911308289
ep0_l4_test_time 2.254189070999999
gc 0
Train Epoch1 Acc 0.5091 (20364/40000), AUC 0.5114760994911194
ep1_train_time 65.67668892899998
Test Epoch1 layer0 Acc 0.6148, AUC 0.7160383462905884, avg_entr 0.5962851643562317, f1 0.614799976348877
ep1_l0_test_time 0.620200729000004
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 1
Test Epoch1 layer1 Acc 0.5026, AUC 0.7171751260757446, avg_entr 0.6414362192153931, f1 0.5026000142097473
ep1_l1_test_time 0.8232953849999944
Test Epoch1 layer2 Acc 0.5, AUC 0.6308013200759888, avg_entr 0.6496788859367371, f1 0.5
ep1_l2_test_time 1.1471186679999903
Test Epoch1 layer3 Acc 0.5, AUC 0.39085185527801514, avg_entr 0.6685290336608887, f1 0.5
ep1_l3_test_time 1.621613467000003
Test Epoch1 layer4 Acc 0.5, AUC 0.49254870414733887, avg_entr 0.6760537624359131, f1 0.5
ep1_l4_test_time 2.2558057619999943
gc 0
Train Epoch2 Acc 0.520725 (20829/40000), AUC 0.5300421714782715
ep2_train_time 65.685395914
Test Epoch2 layer0 Acc 0.6916, AUC 0.78224116563797, avg_entr 0.5025712251663208, f1 0.6916000247001648
ep2_l0_test_time 0.6223958639999978
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 2
Test Epoch2 layer1 Acc 0.6728, AUC 0.7875305414199829, avg_entr 0.4954017698764801, f1 0.6728000044822693
ep2_l1_test_time 0.8193628570000158
Test Epoch2 layer2 Acc 0.5926, AUC 0.7869613170623779, avg_entr 0.47540923953056335, f1 0.5925999879837036
ep2_l2_test_time 1.1396751329999972
Test Epoch2 layer3 Acc 0.5194, AUC 0.7828453779220581, avg_entr 0.6239806413650513, f1 0.5194000005722046
ep2_l3_test_time 1.634031397000001
Test Epoch2 layer4 Acc 0.6748, AUC 0.7311798334121704, avg_entr 0.690230131149292, f1 0.6747999787330627
ep2_l4_test_time 2.262100363000002
gc 0
Train Epoch3 Acc 0.6173 (24692/40000), AUC 0.6653287410736084
ep3_train_time 65.568304093
Test Epoch3 layer0 Acc 0.7288, AUC 0.8209242224693298, avg_entr 0.4270683228969574, f1 0.7287999987602234
ep3_l0_test_time 0.621690583999964
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer1 Acc 0.709, AUC 0.8257471919059753, avg_entr 0.4098297357559204, f1 0.7090000510215759
ep3_l1_test_time 0.8252874240000097
Test Epoch3 layer2 Acc 0.6824, AUC 0.8260251879692078, avg_entr 0.4017990231513977, f1 0.6823999881744385
ep3_l2_test_time 1.1417901649999749
Test Epoch3 layer3 Acc 0.6564, AUC 0.8259933590888977, avg_entr 0.4031843841075897, f1 0.6564000248908997
ep3_l3_test_time 1.6267227619999858
Test Epoch3 layer4 Acc 0.6244, AUC 0.8265699744224548, avg_entr 0.46471670269966125, f1 0.6244000196456909
ep3_l4_test_time 2.2617047780000235
gc 0
Train Epoch4 Acc 0.703525 (28141/40000), AUC 0.7758543491363525
ep4_train_time 65.935025768
Test Epoch4 layer0 Acc 0.6698, AUC 0.8379204869270325, avg_entr 0.32954344153404236, f1 0.6697999835014343
ep4_l0_test_time 0.6203235209999889
Test Epoch4 layer1 Acc 0.6154, AUC 0.8431453108787537, avg_entr 0.3111075460910797, f1 0.6154000163078308
ep4_l1_test_time 0.814761357000009
Test Epoch4 layer2 Acc 0.5702, AUC 0.8443315029144287, avg_entr 0.29411444067955017, f1 0.5702000260353088
ep4_l2_test_time 1.1425723269999821
Test Epoch4 layer3 Acc 0.5442, AUC 0.8445159792900085, avg_entr 0.2794223427772522, f1 0.5442000031471252
ep4_l3_test_time 1.62294898600004
Test Epoch4 layer4 Acc 0.5208, AUC 0.8448032140731812, avg_entr 0.25647979974746704, f1 0.520799994468689
ep4_l4_test_time 2.25580392400002
gc 0
Train Epoch5 Acc 0.733825 (29353/40000), AUC 0.8103337287902832
ep5_train_time 65.83569225499997
Test Epoch5 layer0 Acc 0.7464, AUC 0.8487250804901123, avg_entr 0.30833131074905396, f1 0.7463999390602112
ep5_l0_test_time 0.6189245829999663
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 5
Test Epoch5 layer1 Acc 0.7548, AUC 0.8546104431152344, avg_entr 0.29140615463256836, f1 0.754800021648407
ep5_l1_test_time 0.8270698240000343
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 5
Test Epoch5 layer2 Acc 0.7532, AUC 0.8561197519302368, avg_entr 0.2890705168247223, f1 0.7531999945640564
ep5_l2_test_time 1.143728574000022
Test Epoch5 layer3 Acc 0.7518, AUC 0.8558757305145264, avg_entr 0.297477126121521, f1 0.751800000667572
ep5_l3_test_time 1.6247868579999931
Test Epoch5 layer4 Acc 0.7498, AUC 0.8559170365333557, avg_entr 0.29954859614372253, f1 0.7498000264167786
ep5_l4_test_time 2.254541512000003
gc 0
Train Epoch6 Acc 0.770225 (30809/40000), AUC 0.8515713214874268
ep6_train_time 65.52325970300006
Test Epoch6 layer0 Acc 0.7686, AUC 0.8564628958702087, avg_entr 0.2988985478878021, f1 0.7685999870300293
ep6_l0_test_time 0.6211701119999589
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer1 Acc 0.778, AUC 0.8670493364334106, avg_entr 0.29234105348587036, f1 0.777999997138977
ep6_l1_test_time 0.8257688600000392
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer2 Acc 0.7702, AUC 0.8686802387237549, avg_entr 0.2987966537475586, f1 0.7702000141143799
ep6_l2_test_time 1.1432716459999028
Test Epoch6 layer3 Acc 0.7582, AUC 0.8684670925140381, avg_entr 0.30004262924194336, f1 0.7582000494003296
ep6_l3_test_time 1.617732593000028
Test Epoch6 layer4 Acc 0.7442, AUC 0.8686075210571289, avg_entr 0.301987886428833, f1 0.7441999316215515
ep6_l4_test_time 2.250903519000076
gc 0
Train Epoch7 Acc 0.78955 (31582/40000), AUC 0.8712776899337769
ep7_train_time 65.62164205199997
Test Epoch7 layer0 Acc 0.7786, AUC 0.8634066581726074, avg_entr 0.27237454056739807, f1 0.7785999774932861
ep7_l0_test_time 0.6413963180000337
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 7
Test Epoch7 layer1 Acc 0.7844, AUC 0.874030590057373, avg_entr 0.24038834869861603, f1 0.7843999266624451
ep7_l1_test_time 0.8286072250000416
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 7
Test Epoch7 layer2 Acc 0.7864, AUC 0.8763506412506104, avg_entr 0.19806455075740814, f1 0.7864000201225281
ep7_l2_test_time 1.1422258899999633
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 7
Test Epoch7 layer3 Acc 0.7866, AUC 0.8762273788452148, avg_entr 0.1749378740787506, f1 0.7865999937057495
ep7_l3_test_time 1.6256507470000088
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 7
Test Epoch7 layer4 Acc 0.7864, AUC 0.8763283491134644, avg_entr 0.17377468943595886, f1 0.7864000201225281
ep7_l4_test_time 2.2661412230000906
gc 0
Train Epoch8 Acc 0.8069 (32276/40000), AUC 0.8859379291534424
ep8_train_time 65.7441359479999
Test Epoch8 layer0 Acc 0.7728, AUC 0.8683338165283203, avg_entr 0.2622828185558319, f1 0.7728000283241272
ep8_l0_test_time 0.6269003140000677
Test Epoch8 layer1 Acc 0.7844, AUC 0.8839370608329773, avg_entr 0.22027060389518738, f1 0.7843999266624451
ep8_l1_test_time 0.8241823729999851
Test Epoch8 layer2 Acc 0.7852, AUC 0.884258508682251, avg_entr 0.17795391380786896, f1 0.7851999998092651
ep8_l2_test_time 1.1417012530000648
Test Epoch8 layer3 Acc 0.7814, AUC 0.8844467401504517, avg_entr 0.16618235409259796, f1 0.7814000248908997
ep8_l3_test_time 1.6296865589999925
Test Epoch8 layer4 Acc 0.781, AUC 0.884554922580719, avg_entr 0.16157664358615875, f1 0.781000018119812
ep8_l4_test_time 2.265592933999983
gc 0
Train Epoch9 Acc 0.82775 (33110/40000), AUC 0.9059144258499146
ep9_train_time 65.67240566500004
Test Epoch9 layer0 Acc 0.7734, AUC 0.8704140186309814, avg_entr 0.2466675043106079, f1 0.7734000086784363
ep9_l0_test_time 0.6201619319999736
Test Epoch9 layer1 Acc 0.7956, AUC 0.8871638178825378, avg_entr 0.20963484048843384, f1 0.7955999970436096
ep9_l1_test_time 0.8136693010000045
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 9
Test Epoch9 layer2 Acc 0.7984, AUC 0.8883621692657471, avg_entr 0.1654421091079712, f1 0.7983999848365784
ep9_l2_test_time 1.146049392000009
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 9
Test Epoch9 layer3 Acc 0.7982, AUC 0.8887955546379089, avg_entr 0.1645035743713379, f1 0.7982000708580017
ep9_l3_test_time 1.6349949000000379
Test Epoch9 layer4 Acc 0.7982, AUC 0.8889774084091187, avg_entr 0.1627807319164276, f1 0.7982000708580017
ep9_l4_test_time 2.2545168919999696
gc 0
Train Epoch10 Acc 0.83935 (33574/40000), AUC 0.9164288640022278
ep10_train_time 65.65902467300009
Test Epoch10 layer0 Acc 0.7626, AUC 0.8708981275558472, avg_entr 0.231728196144104, f1 0.7626000046730042
ep10_l0_test_time 0.620449520999955
Test Epoch10 layer1 Acc 0.7848, AUC 0.8870533108711243, avg_entr 0.1904374659061432, f1 0.7847999930381775
ep10_l1_test_time 0.8119497019999926
Test Epoch10 layer2 Acc 0.7892, AUC 0.8879748582839966, avg_entr 0.14300964772701263, f1 0.7892000079154968
ep10_l2_test_time 1.1427193770000486
Test Epoch10 layer3 Acc 0.7892, AUC 0.8876433372497559, avg_entr 0.14161556959152222, f1 0.7892000079154968
ep10_l3_test_time 1.6251555329999974
Test Epoch10 layer4 Acc 0.79, AUC 0.8879075050354004, avg_entr 0.1415044665336609, f1 0.7900000214576721
ep10_l4_test_time 2.2575260200000002
gc 0
Train Epoch11 Acc 0.844825 (33793/40000), AUC 0.9192758798599243
ep11_train_time 65.748172447
Test Epoch11 layer0 Acc 0.7872, AUC 0.8705754280090332, avg_entr 0.21733012795448303, f1 0.7871999740600586
ep11_l0_test_time 0.623008370999969
Test Epoch11 layer1 Acc 0.8034, AUC 0.8881019949913025, avg_entr 0.1525726020336151, f1 0.8033999800682068
ep11_l1_test_time 0.813960824999981
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 11
Test Epoch11 layer2 Acc 0.8042, AUC 0.889494776725769, avg_entr 0.12218699604272842, f1 0.8041999936103821
ep11_l2_test_time 1.1565868679999767
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 11
Test Epoch11 layer3 Acc 0.8046, AUC 0.8897510766983032, avg_entr 0.1213885098695755, f1 0.8046000599861145
ep11_l3_test_time 1.6495022859999153
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 11
Test Epoch11 layer4 Acc 0.8054, AUC 0.8897622227668762, avg_entr 0.12032710015773773, f1 0.805400013923645
ep11_l4_test_time 2.277010130000008
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 11
gc 0
Train Epoch12 Acc 0.8629 (34516/40000), AUC 0.933600664138794
ep12_train_time 65.815272209
Test Epoch12 layer0 Acc 0.7678, AUC 0.8696257472038269, avg_entr 0.22005648910999298, f1 0.767799973487854
ep12_l0_test_time 0.6209915850000698
Test Epoch12 layer1 Acc 0.7784, AUC 0.8844634890556335, avg_entr 0.13830195367336273, f1 0.7784000039100647
ep12_l1_test_time 0.8146887699999752
Test Epoch12 layer2 Acc 0.779, AUC 0.8870748281478882, avg_entr 0.1273796558380127, f1 0.7789999842643738
ep12_l2_test_time 1.141417046000015
Test Epoch12 layer3 Acc 0.7778, AUC 0.8868144750595093, avg_entr 0.12927234172821045, f1 0.7778000235557556
ep12_l3_test_time 1.629011544999912
Test Epoch12 layer4 Acc 0.7782, AUC 0.8864259719848633, avg_entr 0.12960641086101532, f1 0.7781999707221985
ep12_l4_test_time 2.2581277150000005
gc 0
Train Epoch13 Acc 0.872025 (34881/40000), AUC 0.9396493434906006
ep13_train_time 65.73327370900006
Test Epoch13 layer0 Acc 0.7776, AUC 0.8718977570533752, avg_entr 0.21810734272003174, f1 0.7775999903678894
ep13_l0_test_time 0.6237580279998838
Test Epoch13 layer1 Acc 0.7988, AUC 0.8887507319450378, avg_entr 0.12007911503314972, f1 0.798799991607666
ep13_l1_test_time 0.816589120000117
Test Epoch13 layer2 Acc 0.797, AUC 0.8883315324783325, avg_entr 0.11084620654582977, f1 0.796999990940094
ep13_l2_test_time 1.138942082000085
Test Epoch13 layer3 Acc 0.7968, AUC 0.888573169708252, avg_entr 0.11019618809223175, f1 0.7968000173568726
ep13_l3_test_time 1.622250238999868
Test Epoch13 layer4 Acc 0.7968, AUC 0.8884604573249817, avg_entr 0.1075119748711586, f1 0.7968000173568726
ep13_l4_test_time 2.259616830999903
gc 0
Train Epoch14 Acc 0.88325 (35330/40000), AUC 0.9486395120620728
ep14_train_time 65.81960406999997
Test Epoch14 layer0 Acc 0.7774, AUC 0.8655426502227783, avg_entr 0.20469340682029724, f1 0.777400016784668
ep14_l0_test_time 0.6238273480000771
Test Epoch14 layer1 Acc 0.794, AUC 0.8825134038925171, avg_entr 0.10924355685710907, f1 0.7940000295639038
ep14_l1_test_time 0.8202411849999862
Test Epoch14 layer2 Acc 0.7918, AUC 0.885343074798584, avg_entr 0.10591211169958115, f1 0.7918000221252441
ep14_l2_test_time 1.1486454920000142
Test Epoch14 layer3 Acc 0.7926, AUC 0.8854139447212219, avg_entr 0.10509411990642548, f1 0.7925999760627747
ep14_l3_test_time 1.6304132069999469
Test Epoch14 layer4 Acc 0.7918, AUC 0.88532954454422, avg_entr 0.10424359142780304, f1 0.7918000221252441
ep14_l4_test_time 2.2667152660001193
gc 0
Train Epoch15 Acc 0.89345 (35738/40000), AUC 0.9551892280578613
ep15_train_time 65.77652690000014
Test Epoch15 layer0 Acc 0.7662, AUC 0.865993320941925, avg_entr 0.1996796578168869, f1 0.766200065612793
ep15_l0_test_time 0.6205461459999242
Test Epoch15 layer1 Acc 0.7832, AUC 0.8792344331741333, avg_entr 0.10802536457777023, f1 0.7832000851631165
ep15_l1_test_time 0.8191842399999132
Test Epoch15 layer2 Acc 0.7792, AUC 0.8827970027923584, avg_entr 0.0984380766749382, f1 0.7791999578475952
ep15_l2_test_time 1.144926046000137
Test Epoch15 layer3 Acc 0.7782, AUC 0.8830935955047607, avg_entr 0.09875001758337021, f1 0.7781999707221985
ep15_l3_test_time 1.6254111359999115
Test Epoch15 layer4 Acc 0.7786, AUC 0.8830277919769287, avg_entr 0.09951789677143097, f1 0.7785999774932861
ep15_l4_test_time 2.2599450459999844
gc 0
Train Epoch16 Acc 0.905725 (36229/40000), AUC 0.9652432203292847
ep16_train_time 65.84068815299997
Test Epoch16 layer0 Acc 0.7682, AUC 0.865811824798584, avg_entr 0.185587540268898, f1 0.7681999802589417
ep16_l0_test_time 0.6223264279999512
Test Epoch16 layer1 Acc 0.783, AUC 0.8818805813789368, avg_entr 0.0983063355088234, f1 0.7829999923706055
ep16_l1_test_time 0.8167237909999585
Test Epoch16 layer2 Acc 0.7908, AUC 0.8860905766487122, avg_entr 0.08619096875190735, f1 0.7907999753952026
ep16_l2_test_time 1.1420354060001046
Test Epoch16 layer3 Acc 0.7906, AUC 0.8870168924331665, avg_entr 0.08401453495025635, f1 0.7906000018119812
ep16_l3_test_time 1.6227948779999224
Test Epoch16 layer4 Acc 0.7896, AUC 0.8865426778793335, avg_entr 0.08205696940422058, f1 0.7896000146865845
ep16_l4_test_time 2.2656056789999184
gc 0
Train Epoch17 Acc 0.912675 (36507/40000), AUC 0.9692567586898804
ep17_train_time 65.8454677310001
Test Epoch17 layer0 Acc 0.776, AUC 0.8562524318695068, avg_entr 0.17550846934318542, f1 0.7759999632835388
ep17_l0_test_time 0.6344566330001271
Test Epoch17 layer1 Acc 0.7924, AUC 0.8683333396911621, avg_entr 0.07774019986391068, f1 0.7923999428749084
ep17_l1_test_time 0.8221248729998933
Test Epoch17 layer2 Acc 0.7912, AUC 0.8740581274032593, avg_entr 0.07315846532583237, f1 0.7911999821662903
ep17_l2_test_time 1.144568530000015
Test Epoch17 layer3 Acc 0.7918, AUC 0.8748151063919067, avg_entr 0.06888758391141891, f1 0.7918000221252441
ep17_l3_test_time 1.6233240620001652
Test Epoch17 layer4 Acc 0.7914, AUC 0.8748608231544495, avg_entr 0.06523280590772629, f1 0.7914000153541565
ep17_l4_test_time 2.2583118049999484
gc 0
Train Epoch18 Acc 0.929525 (37181/40000), AUC 0.9779863953590393
ep18_train_time 65.7253386320001
Test Epoch18 layer0 Acc 0.7782, AUC 0.8568912744522095, avg_entr 0.1717078983783722, f1 0.7781999707221985
ep18_l0_test_time 0.6203390109999418
Test Epoch18 layer1 Acc 0.7862, AUC 0.8675546646118164, avg_entr 0.06589139252901077, f1 0.7861999869346619
ep18_l1_test_time 0.8155059389998769
Test Epoch18 layer2 Acc 0.7868, AUC 0.8729257583618164, avg_entr 0.059079840779304504, f1 0.786799967288971
ep18_l2_test_time 1.1369957709998744
Test Epoch18 layer3 Acc 0.7862, AUC 0.8738113641738892, avg_entr 0.05607620254158974, f1 0.7861999869346619
ep18_l3_test_time 1.627550304000124
Test Epoch18 layer4 Acc 0.7862, AUC 0.8735841512680054, avg_entr 0.05375444516539574, f1 0.7861999869346619
ep18_l4_test_time 2.258115091000036
gc 0
Train Epoch19 Acc 0.9364 (37456/40000), AUC 0.9822781085968018
ep19_train_time 65.78868818700016
Test Epoch19 layer0 Acc 0.7674, AUC 0.851305365562439, avg_entr 0.16511262953281403, f1 0.7673999667167664
ep19_l0_test_time 0.6210846169999513
Test Epoch19 layer1 Acc 0.7764, AUC 0.8580415844917297, avg_entr 0.06307254731655121, f1 0.776400089263916
ep19_l1_test_time 0.8143696790000376
Test Epoch19 layer2 Acc 0.7814, AUC 0.8660642504692078, avg_entr 0.057859472930431366, f1 0.7814000248908997
ep19_l2_test_time 1.1384556210000483
Test Epoch19 layer3 Acc 0.7824, AUC 0.8673114776611328, avg_entr 0.05469483509659767, f1 0.7824000120162964
ep19_l3_test_time 1.621695617000114
Test Epoch19 layer4 Acc 0.7814, AUC 0.8668622970581055, avg_entr 0.052282366901636124, f1 0.7814000248908997
ep19_l4_test_time 2.260125449000043
gc 0
Train Epoch20 Acc 0.943625 (37745/40000), AUC 0.9849890470504761
ep20_train_time 65.84440910700005
Test Epoch20 layer0 Acc 0.766, AUC 0.8490161895751953, avg_entr 0.1651114821434021, f1 0.7659999132156372
ep20_l0_test_time 0.6229879399998026
Test Epoch20 layer1 Acc 0.7792, AUC 0.8588019013404846, avg_entr 0.060731444507837296, f1 0.7791999578475952
ep20_l1_test_time 0.8154661700000361
Test Epoch20 layer2 Acc 0.7812, AUC 0.8660491704940796, avg_entr 0.05557246133685112, f1 0.7811999917030334
ep20_l2_test_time 1.1404932410000583
Test Epoch20 layer3 Acc 0.7808, AUC 0.8679142594337463, avg_entr 0.05356387794017792, f1 0.7808000445365906
ep20_l3_test_time 1.6221405370001776
Test Epoch20 layer4 Acc 0.7804, AUC 0.8677769899368286, avg_entr 0.05183003470301628, f1 0.7803999781608582
ep20_l4_test_time 2.2635407439997834
gc 0
Train Epoch21 Acc 0.946225 (37849/40000), AUC 0.9863409996032715
ep21_train_time 65.84341503799988
Test Epoch21 layer0 Acc 0.7662, AUC 0.8454570174217224, avg_entr 0.1642255187034607, f1 0.766200065612793
ep21_l0_test_time 0.622631561000162
Test Epoch21 layer1 Acc 0.7746, AUC 0.8486955165863037, avg_entr 0.0618940070271492, f1 0.7746000289916992
ep21_l1_test_time 0.8409225309999329
Test Epoch21 layer2 Acc 0.7758, AUC 0.8610864281654358, avg_entr 0.05664220079779625, f1 0.7758000493049622
ep21_l2_test_time 1.1497758369998792
Test Epoch21 layer3 Acc 0.7756, AUC 0.863347053527832, avg_entr 0.05488616228103638, f1 0.775600016117096
ep21_l3_test_time 1.6444636840001294
Test Epoch21 layer4 Acc 0.7752, AUC 0.8630020618438721, avg_entr 0.05279337614774704, f1 0.7752000093460083
ep21_l4_test_time 2.263255817000072
gc 0
Train Epoch22 Acc 0.953425 (38137/40000), AUC 0.9888694882392883
ep22_train_time 65.753499637
Test Epoch22 layer0 Acc 0.7686, AUC 0.8446800112724304, avg_entr 0.15595610439777374, f1 0.7685999870300293
ep22_l0_test_time 0.6281027149998408
Test Epoch22 layer1 Acc 0.78, AUC 0.8440579771995544, avg_entr 0.050571899861097336, f1 0.7799999117851257
ep22_l1_test_time 0.8204592639999646
Test Epoch22 layer2 Acc 0.7802, AUC 0.8573037385940552, avg_entr 0.044519055634737015, f1 0.7801999449729919
ep22_l2_test_time 1.1452882810001483
Test Epoch22 layer3 Acc 0.7808, AUC 0.860611081123352, avg_entr 0.0425170361995697, f1 0.7808000445365906
ep22_l3_test_time 1.62478413000008
Test Epoch22 layer4 Acc 0.7806, AUC 0.8602296113967896, avg_entr 0.04072607308626175, f1 0.7806000113487244
ep22_l4_test_time 2.2590831219999927
gc 0
Train Epoch23 Acc 0.957625 (38305/40000), AUC 0.9904534816741943
ep23_train_time 65.79799268500005
Test Epoch23 layer0 Acc 0.7688, AUC 0.8435839414596558, avg_entr 0.1556495875120163, f1 0.7688000202178955
ep23_l0_test_time 0.6261837449999348
Test Epoch23 layer1 Acc 0.778, AUC 0.8429512977600098, avg_entr 0.049961742013692856, f1 0.777999997138977
ep23_l1_test_time 0.8267785020000247
Test Epoch23 layer2 Acc 0.7778, AUC 0.8559260368347168, avg_entr 0.045832209289073944, f1 0.7778000235557556
ep23_l2_test_time 1.1423723109999173
Test Epoch23 layer3 Acc 0.7776, AUC 0.8596537113189697, avg_entr 0.043708398938179016, f1 0.7775999903678894
ep23_l3_test_time 1.6247638360000565
Test Epoch23 layer4 Acc 0.7782, AUC 0.859449028968811, avg_entr 0.04170346260070801, f1 0.7781999707221985
ep23_l4_test_time 2.2619725090000884
gc 0
Train Epoch24 Acc 0.959975 (38399/40000), AUC 0.9916028380393982
ep24_train_time 65.86439282000015
Test Epoch24 layer0 Acc 0.7702, AUC 0.8438568711280823, avg_entr 0.15347693860530853, f1 0.7702000141143799
ep24_l0_test_time 0.6307754739998472
Test Epoch24 layer1 Acc 0.7788, AUC 0.8466546535491943, avg_entr 0.048421069979667664, f1 0.7788000106811523
ep24_l1_test_time 0.8175821460001771
Test Epoch24 layer2 Acc 0.7808, AUC 0.8556750416755676, avg_entr 0.04525251314043999, f1 0.7808000445365906
ep24_l2_test_time 1.1437234990000889
Test Epoch24 layer3 Acc 0.7818, AUC 0.8601397275924683, avg_entr 0.043269746005535126, f1 0.7817999720573425
ep24_l3_test_time 1.625069498999892
Test Epoch24 layer4 Acc 0.7822, AUC 0.8595970273017883, avg_entr 0.04125625267624855, f1 0.7821999788284302
ep24_l4_test_time 2.2623798810000153
gc 0
Train Epoch25 Acc 0.962975 (38519/40000), AUC 0.9925947189331055
ep25_train_time 65.74983680000014
Test Epoch25 layer0 Acc 0.7632, AUC 0.8412094116210938, avg_entr 0.1559741199016571, f1 0.7631999850273132
ep25_l0_test_time 0.6236657619999733
Test Epoch25 layer1 Acc 0.7694, AUC 0.8345613479614258, avg_entr 0.04818866774439812, f1 0.7694000005722046
ep25_l1_test_time 0.8192371679999724
Test Epoch25 layer2 Acc 0.7736, AUC 0.8498734831809998, avg_entr 0.04353060945868492, f1 0.7735999822616577
ep25_l2_test_time 1.142191715999843
Test Epoch25 layer3 Acc 0.7742, AUC 0.8545207977294922, avg_entr 0.0409318283200264, f1 0.7742000222206116
ep25_l3_test_time 1.6256652950000898
Test Epoch25 layer4 Acc 0.774, AUC 0.853553295135498, avg_entr 0.038706667721271515, f1 0.7739999890327454
ep25_l4_test_time 2.261023330000171
gc 0
Train Epoch26 Acc 0.9644 (38576/40000), AUC 0.9929826259613037
ep26_train_time 65.87302219000003
Test Epoch26 layer0 Acc 0.7632, AUC 0.8396728038787842, avg_entr 0.1514255553483963, f1 0.7631999850273132
ep26_l0_test_time 0.6230640619999122
Test Epoch26 layer1 Acc 0.775, AUC 0.837455689907074, avg_entr 0.04536653310060501, f1 0.7749999761581421
ep26_l1_test_time 0.8321374009999545
Test Epoch26 layer2 Acc 0.777, AUC 0.8519035577774048, avg_entr 0.041981786489486694, f1 0.7770000100135803
ep26_l2_test_time 1.1485889969999334
Test Epoch26 layer3 Acc 0.7776, AUC 0.8559675812721252, avg_entr 0.03955719619989395, f1 0.7775999903678894
ep26_l3_test_time 1.6241527579998092
Test Epoch26 layer4 Acc 0.777, AUC 0.8553617000579834, avg_entr 0.03758176043629646, f1 0.7770000100135803
ep26_l4_test_time 2.258540599000071
gc 0
Train Epoch27 Acc 0.967675 (38707/40000), AUC 0.9939377307891846
ep27_train_time 65.75540279400002
Test Epoch27 layer0 Acc 0.7632, AUC 0.8391681909561157, avg_entr 0.15098576247692108, f1 0.7631999850273132
ep27_l0_test_time 0.6233568100001321
Test Epoch27 layer1 Acc 0.7724, AUC 0.8335817456245422, avg_entr 0.04537628963589668, f1 0.7724000215530396
ep27_l1_test_time 0.8155145690000154
Test Epoch27 layer2 Acc 0.7712, AUC 0.8488214015960693, avg_entr 0.04033653438091278, f1 0.7712000012397766
ep27_l2_test_time 1.1401739059999727
Test Epoch27 layer3 Acc 0.7734, AUC 0.8530001640319824, avg_entr 0.03748831897974014, f1 0.7734000086784363
ep27_l3_test_time 1.6221495139998297
Test Epoch27 layer4 Acc 0.7734, AUC 0.8522230386734009, avg_entr 0.035494364798069, f1 0.7734000086784363
ep27_l4_test_time 2.2603143010001077
gc 0
Train Epoch28 Acc 0.9664 (38656/40000), AUC 0.9938793182373047
ep28_train_time 65.74009514099998
Test Epoch28 layer0 Acc 0.765, AUC 0.8395427465438843, avg_entr 0.14900460839271545, f1 0.7649999856948853
ep28_l0_test_time 0.6220824329998322
Test Epoch28 layer1 Acc 0.7698, AUC 0.8352608680725098, avg_entr 0.042345594614744186, f1 0.7698000073432922
ep28_l1_test_time 0.8179559240002163
Test Epoch28 layer2 Acc 0.7704, AUC 0.8488954305648804, avg_entr 0.03897581249475479, f1 0.7703999280929565
ep28_l2_test_time 1.1391603080001005
Test Epoch28 layer3 Acc 0.7706, AUC 0.8535178899765015, avg_entr 0.03587396815419197, f1 0.7706000208854675
ep28_l3_test_time 1.6253819249996013
Test Epoch28 layer4 Acc 0.7706, AUC 0.8528212904930115, avg_entr 0.03387489542365074, f1 0.7706000208854675
ep28_l4_test_time 2.259570660999998
gc 0
Train Epoch29 Acc 0.968475 (38739/40000), AUC 0.9946321249008179
ep29_train_time 65.76482097200005
Test Epoch29 layer0 Acc 0.7618, AUC 0.8392013311386108, avg_entr 0.14874590933322906, f1 0.7618000507354736
ep29_l0_test_time 0.6327304400001594
Test Epoch29 layer1 Acc 0.7704, AUC 0.8322604894638062, avg_entr 0.043574534356594086, f1 0.7703999280929565
ep29_l1_test_time 0.8152236199998697
Test Epoch29 layer2 Acc 0.7682, AUC 0.8476479649543762, avg_entr 0.040311865508556366, f1 0.7681999802589417
ep29_l2_test_time 1.1444148940004197
Test Epoch29 layer3 Acc 0.77, AUC 0.8529472351074219, avg_entr 0.03705005347728729, f1 0.7699999809265137
ep29_l3_test_time 1.6339826749999702
Test Epoch29 layer4 Acc 0.7696, AUC 0.8524237871170044, avg_entr 0.03511154279112816, f1 0.769599974155426
ep29_l4_test_time 2.2696885080003995
gc 0
Train Epoch30 Acc 0.968325 (38733/40000), AUC 0.9942235350608826
ep30_train_time 65.877102681
Test Epoch30 layer0 Acc 0.7658, AUC 0.8389568328857422, avg_entr 0.14713063836097717, f1 0.7657999992370605
ep30_l0_test_time 0.6240866660000393
Test Epoch30 layer1 Acc 0.7744, AUC 0.8327476978302002, avg_entr 0.039714545011520386, f1 0.7743999361991882
ep30_l1_test_time 0.8164853569996922
Test Epoch30 layer2 Acc 0.7758, AUC 0.8464394807815552, avg_entr 0.03604703024029732, f1 0.7758000493049622
ep30_l2_test_time 1.1461155100000724
Test Epoch30 layer3 Acc 0.7756, AUC 0.852022647857666, avg_entr 0.03364472836256027, f1 0.775600016117096
ep30_l3_test_time 1.6241131039996617
Test Epoch30 layer4 Acc 0.7756, AUC 0.8514323234558105, avg_entr 0.0317952036857605, f1 0.775600016117096
ep30_l4_test_time 2.261487533000036
gc 0
Train Epoch31 Acc 0.97015 (38806/40000), AUC 0.9945536851882935
ep31_train_time 65.8020173660002
Test Epoch31 layer0 Acc 0.762, AUC 0.8377928733825684, avg_entr 0.14767365157604218, f1 0.7619999647140503
ep31_l0_test_time 0.6234892020002007
Test Epoch31 layer1 Acc 0.7698, AUC 0.8285156488418579, avg_entr 0.042697906494140625, f1 0.7698000073432922
ep31_l1_test_time 0.8193078459999015
Test Epoch31 layer2 Acc 0.7706, AUC 0.8448051810264587, avg_entr 0.03739599138498306, f1 0.7706000208854675
ep31_l2_test_time 1.1375108850002107
Test Epoch31 layer3 Acc 0.7714, AUC 0.8505419492721558, avg_entr 0.033700864762067795, f1 0.771399974822998
ep31_l3_test_time 1.6219830579998415
Test Epoch31 layer4 Acc 0.7714, AUC 0.8498132228851318, avg_entr 0.03181708604097366, f1 0.771399974822998
ep31_l4_test_time 2.2571711959999448
gc 0
Train Epoch32 Acc 0.9695 (38780/40000), AUC 0.9948717355728149
ep32_train_time 65.76251767500025
Test Epoch32 layer0 Acc 0.7584, AUC 0.8374247550964355, avg_entr 0.1495886892080307, f1 0.758400022983551
ep32_l0_test_time 0.6225148859998626
Test Epoch32 layer1 Acc 0.7706, AUC 0.8284804821014404, avg_entr 0.04401044547557831, f1 0.7706000208854675
ep32_l1_test_time 0.8190485919999446
Test Epoch32 layer2 Acc 0.77, AUC 0.8445425033569336, avg_entr 0.03954056277871132, f1 0.7699999809265137
ep32_l2_test_time 1.1386743510001907
Test Epoch32 layer3 Acc 0.7716, AUC 0.851862907409668, avg_entr 0.0360603891313076, f1 0.771600067615509
ep32_l3_test_time 1.6330007539995677
Test Epoch32 layer4 Acc 0.7712, AUC 0.8517086505889893, avg_entr 0.034018371254205704, f1 0.7712000012397766
ep32_l4_test_time 2.2695149109999875
gc 0
Train Epoch33 Acc 0.969575 (38783/40000), AUC 0.9946854710578918
ep33_train_time 65.858694217
Test Epoch33 layer0 Acc 0.763, AUC 0.8377960920333862, avg_entr 0.1439121514558792, f1 0.7630000114440918
ep33_l0_test_time 0.6283081269998547
Test Epoch33 layer1 Acc 0.7666, AUC 0.8269788026809692, avg_entr 0.038803573697805405, f1 0.7666000127792358
ep33_l1_test_time 0.8167661529996622
Test Epoch33 layer2 Acc 0.77, AUC 0.844656765460968, avg_entr 0.03361385315656662, f1 0.7699999809265137
ep33_l2_test_time 1.1423501429999305
Test Epoch33 layer3 Acc 0.7708, AUC 0.8498979210853577, avg_entr 0.031206823885440826, f1 0.7707999348640442
ep33_l3_test_time 1.6258558530003029
Test Epoch33 layer4 Acc 0.771, AUC 0.8491207361221313, avg_entr 0.02947065979242325, f1 0.7710000276565552
ep33_l4_test_time 2.2600750520000474
gc 0
Train Epoch34 Acc 0.9709 (38836/40000), AUC 0.9952208995819092
ep34_train_time 65.74904539799991
Test Epoch34 layer0 Acc 0.762, AUC 0.8374729752540588, avg_entr 0.14455170929431915, f1 0.7619999647140503
ep34_l0_test_time 0.6248425020003197
Test Epoch34 layer1 Acc 0.7694, AUC 0.8300905227661133, avg_entr 0.03849994018673897, f1 0.7694000005722046
ep34_l1_test_time 0.8192772520001199
Test Epoch34 layer2 Acc 0.7716, AUC 0.845475435256958, avg_entr 0.03317219018936157, f1 0.771600067615509
ep34_l2_test_time 1.1401120539999283
Test Epoch34 layer3 Acc 0.773, AUC 0.8508353233337402, avg_entr 0.030584922060370445, f1 0.7730000019073486
ep34_l3_test_time 1.623367915000017
Test Epoch34 layer4 Acc 0.7734, AUC 0.8503673076629639, avg_entr 0.02880297601222992, f1 0.7734000086784363
ep34_l4_test_time 2.266164548999768
gc 0
Train Epoch35 Acc 0.9718 (38872/40000), AUC 0.995165228843689
ep35_train_time 65.76451338399966
Test Epoch35 layer0 Acc 0.7608, AUC 0.8371167182922363, avg_entr 0.14510057866573334, f1 0.7608000040054321
ep35_l0_test_time 0.622352865999801
Test Epoch35 layer1 Acc 0.7684, AUC 0.8282666206359863, avg_entr 0.03969631344079971, f1 0.7684000730514526
ep35_l1_test_time 0.8212736409996069
Test Epoch35 layer2 Acc 0.7714, AUC 0.8439559936523438, avg_entr 0.03546023741364479, f1 0.771399974822998
ep35_l2_test_time 1.1469448060001923
Test Epoch35 layer3 Acc 0.7712, AUC 0.8497753739356995, avg_entr 0.03240194171667099, f1 0.7712000012397766
ep35_l3_test_time 1.6247530000000552
Test Epoch35 layer4 Acc 0.771, AUC 0.8493821024894714, avg_entr 0.030682332813739777, f1 0.7710000276565552
ep35_l4_test_time 2.2677236760000596
gc 0
Train Epoch36 Acc 0.97165 (38866/40000), AUC 0.9957872033119202
ep36_train_time 65.76051584800007
Test Epoch36 layer0 Acc 0.7616, AUC 0.8369030952453613, avg_entr 0.1445593684911728, f1 0.7616000771522522
ep36_l0_test_time 0.6235314219998145
Test Epoch36 layer1 Acc 0.7666, AUC 0.8281993865966797, avg_entr 0.03857271745800972, f1 0.7666000127792358
ep36_l1_test_time 0.8156629969998903
Test Epoch36 layer2 Acc 0.7698, AUC 0.8440289497375488, avg_entr 0.03490471839904785, f1 0.7698000073432922
ep36_l2_test_time 1.1401913870004137
Test Epoch36 layer3 Acc 0.7696, AUC 0.8501954078674316, avg_entr 0.03257271647453308, f1 0.769599974155426
ep36_l3_test_time 1.625564046999898
Test Epoch36 layer4 Acc 0.7698, AUC 0.8496226072311401, avg_entr 0.030765648931264877, f1 0.7698000073432922
ep36_l4_test_time 2.267252198999813
gc 0
Train Epoch37 Acc 0.97305 (38922/40000), AUC 0.9956226348876953
ep37_train_time 65.759549934
Test Epoch37 layer0 Acc 0.7618, AUC 0.8364882469177246, avg_entr 0.1447899341583252, f1 0.7618000507354736
ep37_l0_test_time 0.6244124869999723
Test Epoch37 layer1 Acc 0.7684, AUC 0.8284679651260376, avg_entr 0.040036048740148544, f1 0.7684000730514526
ep37_l1_test_time 0.8185906310000064
Test Epoch37 layer2 Acc 0.7704, AUC 0.8439000844955444, avg_entr 0.03571898490190506, f1 0.7703999280929565
ep37_l2_test_time 1.141095401000257
Test Epoch37 layer3 Acc 0.7706, AUC 0.8495544195175171, avg_entr 0.03317675739526749, f1 0.7706000208854675
ep37_l3_test_time 1.622842030999891
Test Epoch37 layer4 Acc 0.7706, AUC 0.8491594195365906, avg_entr 0.03138544782996178, f1 0.7706000208854675
ep37_l4_test_time 2.260047067999949
gc 0
Train Epoch38 Acc 0.9717 (38868/40000), AUC 0.9952839016914368
ep38_train_time 65.74843960299995
Test Epoch38 layer0 Acc 0.7612, AUC 0.8369379043579102, avg_entr 0.1444002240896225, f1 0.7612000107765198
ep38_l0_test_time 0.6215700449997712
Test Epoch38 layer1 Acc 0.7676, AUC 0.8296152949333191, avg_entr 0.03928440436720848, f1 0.7675999402999878
ep38_l1_test_time 0.8187284480000017
Test Epoch38 layer2 Acc 0.7698, AUC 0.8438853025436401, avg_entr 0.03515441343188286, f1 0.7698000073432922
ep38_l2_test_time 1.1375846529999762
Test Epoch38 layer3 Acc 0.77, AUC 0.8498525619506836, avg_entr 0.033107735216617584, f1 0.7699999809265137
ep38_l3_test_time 1.6226339740001094
Test Epoch38 layer4 Acc 0.7706, AUC 0.8493589162826538, avg_entr 0.03139720484614372, f1 0.7706000208854675
ep38_l4_test_time 2.2572016120002445
gc 0
Train Epoch39 Acc 0.97265 (38906/40000), AUC 0.9954758882522583
ep39_train_time 65.73661222500004
Test Epoch39 layer0 Acc 0.7616, AUC 0.8368527889251709, avg_entr 0.14356644451618195, f1 0.7616000771522522
ep39_l0_test_time 0.6221744109998326
Test Epoch39 layer1 Acc 0.7682, AUC 0.829481840133667, avg_entr 0.038549378514289856, f1 0.7681999802589417
ep39_l1_test_time 0.8159975710000253
Test Epoch39 layer2 Acc 0.7714, AUC 0.8446431159973145, avg_entr 0.034664783626794815, f1 0.771399974822998
ep39_l2_test_time 1.1406802630003767
Test Epoch39 layer3 Acc 0.7712, AUC 0.8501714468002319, avg_entr 0.03204893320798874, f1 0.7712000012397766
ep39_l3_test_time 1.6248170419999042
Test Epoch39 layer4 Acc 0.7714, AUC 0.8499186635017395, avg_entr 0.03029494546353817, f1 0.771399974822998
ep39_l4_test_time 2.261149784000281
gc 0
Train Epoch40 Acc 0.972675 (38907/40000), AUC 0.9954609870910645
ep40_train_time 65.74294784499989
Test Epoch40 layer0 Acc 0.7616, AUC 0.8369185924530029, avg_entr 0.14239516854286194, f1 0.7616000771522522
ep40_l0_test_time 0.6226322210000035
Test Epoch40 layer1 Acc 0.7668, AUC 0.8295220136642456, avg_entr 0.03796442598104477, f1 0.7667999863624573
ep40_l1_test_time 0.8140820319999875
Test Epoch40 layer2 Acc 0.7702, AUC 0.8441975116729736, avg_entr 0.03399110585451126, f1 0.7702000141143799
ep40_l2_test_time 1.14029790900031
Test Epoch40 layer3 Acc 0.7704, AUC 0.850059449672699, avg_entr 0.03178362920880318, f1 0.7703999280929565
ep40_l3_test_time 1.6250124580001284
Test Epoch40 layer4 Acc 0.7704, AUC 0.8496949672698975, avg_entr 0.03011086955666542, f1 0.7703999280929565
ep40_l4_test_time 2.2594088659998306
gc 0
Train Epoch41 Acc 0.9722 (38888/40000), AUC 0.9956859946250916
ep41_train_time 65.8375113269999
Test Epoch41 layer0 Acc 0.7606, AUC 0.8365988731384277, avg_entr 0.14333753287792206, f1 0.7605999708175659
ep41_l0_test_time 0.6207714970000779
Test Epoch41 layer1 Acc 0.7704, AUC 0.8266240358352661, avg_entr 0.04001162573695183, f1 0.7703999280929565
ep41_l1_test_time 0.8207216949999747
Test Epoch41 layer2 Acc 0.77, AUC 0.8427125811576843, avg_entr 0.035665299743413925, f1 0.7699999809265137
ep41_l2_test_time 1.1471148890000222
Test Epoch41 layer3 Acc 0.7704, AUC 0.8492348194122314, avg_entr 0.032745301723480225, f1 0.7703999280929565
ep41_l3_test_time 1.636112275999949
Test Epoch41 layer4 Acc 0.7704, AUC 0.8489793539047241, avg_entr 0.030951865017414093, f1 0.7703999280929565
ep41_l4_test_time 2.269050275000154
gc 0
Train Epoch42 Acc 0.9736 (38944/40000), AUC 0.9956759214401245
ep42_train_time 65.80742895799995
Test Epoch42 layer0 Acc 0.762, AUC 0.836633563041687, avg_entr 0.14295166730880737, f1 0.7619999647140503
ep42_l0_test_time 0.6335930239997651
Test Epoch42 layer1 Acc 0.768, AUC 0.8278839588165283, avg_entr 0.038470569998025894, f1 0.7680000066757202
ep42_l1_test_time 0.8191503319999356
Test Epoch42 layer2 Acc 0.7714, AUC 0.8422364592552185, avg_entr 0.03428296372294426, f1 0.771399974822998
ep42_l2_test_time 1.1474579230002746
Test Epoch42 layer3 Acc 0.772, AUC 0.8492072820663452, avg_entr 0.03180313855409622, f1 0.7720000147819519
ep42_l3_test_time 1.6271499650001715
Test Epoch42 layer4 Acc 0.7718, AUC 0.848851203918457, avg_entr 0.030103497207164764, f1 0.7717999815940857
ep42_l4_test_time 2.26002918300037
gc 0
Train Epoch43 Acc 0.972175 (38887/40000), AUC 0.9954233169555664
ep43_train_time 65.77139402400007
Test Epoch43 layer0 Acc 0.7624, AUC 0.8365476131439209, avg_entr 0.1429688185453415, f1 0.7623999714851379
ep43_l0_test_time 0.6234040980002646
Test Epoch43 layer1 Acc 0.7674, AUC 0.8282454013824463, avg_entr 0.03840266168117523, f1 0.7673999667167664
ep43_l1_test_time 0.8139796749997004
Test Epoch43 layer2 Acc 0.7706, AUC 0.8424104452133179, avg_entr 0.03362661227583885, f1 0.7706000208854675
ep43_l2_test_time 1.1506891479998558
Test Epoch43 layer3 Acc 0.771, AUC 0.8492082357406616, avg_entr 0.031121907755732536, f1 0.7710000276565552
ep43_l3_test_time 1.6303435859999809
Test Epoch43 layer4 Acc 0.7714, AUC 0.8487422466278076, avg_entr 0.029400518164038658, f1 0.771399974822998
ep43_l4_test_time 2.267447743000048
gc 0
Train Epoch44 Acc 0.973225 (38929/40000), AUC 0.9960070252418518
ep44_train_time 65.8612073459999
Test Epoch44 layer0 Acc 0.7622, AUC 0.8365976810455322, avg_entr 0.1426520198583603, f1 0.7621999979019165
ep44_l0_test_time 0.6287899330000073
Test Epoch44 layer1 Acc 0.7682, AUC 0.8285276293754578, avg_entr 0.03788602724671364, f1 0.7681999802589417
ep44_l1_test_time 0.8150960160000977
Test Epoch44 layer2 Acc 0.7718, AUC 0.842792272567749, avg_entr 0.03395237401127815, f1 0.7717999815940857
ep44_l2_test_time 1.1393650599998182
Test Epoch44 layer3 Acc 0.7722, AUC 0.8496235013008118, avg_entr 0.03140277788043022, f1 0.7721999287605286
ep44_l3_test_time 1.6216062710000188
Test Epoch44 layer4 Acc 0.7724, AUC 0.8491629362106323, avg_entr 0.02973957546055317, f1 0.7724000215530396
ep44_l4_test_time 2.2675828289998208
gc 0
Train Epoch45 Acc 0.9732 (38928/40000), AUC 0.9959307909011841
ep45_train_time 65.9676393259997
Test Epoch45 layer0 Acc 0.7618, AUC 0.8365705013275146, avg_entr 0.1430211216211319, f1 0.7618000507354736
ep45_l0_test_time 0.6297703019999972
Test Epoch45 layer1 Acc 0.768, AUC 0.827081561088562, avg_entr 0.03943762555718422, f1 0.7680000066757202
ep45_l1_test_time 0.8182212209999307
Test Epoch45 layer2 Acc 0.7712, AUC 0.8421883583068848, avg_entr 0.034825630486011505, f1 0.7712000012397766
ep45_l2_test_time 1.1383596450000368
Test Epoch45 layer3 Acc 0.7716, AUC 0.8491566181182861, avg_entr 0.031969841569662094, f1 0.771600067615509
ep45_l3_test_time 1.6232408339997164
Test Epoch45 layer4 Acc 0.7716, AUC 0.8486980199813843, avg_entr 0.030210791155695915, f1 0.771600067615509
ep45_l4_test_time 2.2691738290000103
gc 0
Train Epoch46 Acc 0.974175 (38967/40000), AUC 0.9957989454269409
ep46_train_time 65.80215181600033
Test Epoch46 layer0 Acc 0.7618, AUC 0.8364840745925903, avg_entr 0.14312925934791565, f1 0.7618000507354736
ep46_l0_test_time 0.6232566399999087
Test Epoch46 layer1 Acc 0.7674, AUC 0.8272711038589478, avg_entr 0.0388837568461895, f1 0.7673999667167664
ep46_l1_test_time 0.8315182400001504
Test Epoch46 layer2 Acc 0.7716, AUC 0.8426414728164673, avg_entr 0.03450522571802139, f1 0.771600067615509
ep46_l2_test_time 1.1485291610001696
Test Epoch46 layer3 Acc 0.7714, AUC 0.8492426872253418, avg_entr 0.03153490647673607, f1 0.771399974822998
ep46_l3_test_time 1.6455669670003772
Test Epoch46 layer4 Acc 0.7714, AUC 0.848859429359436, avg_entr 0.029801413416862488, f1 0.771399974822998
ep46_l4_test_time 2.260370134999903
gc 0
Train Epoch47 Acc 0.972925 (38917/40000), AUC 0.9958431720733643
ep47_train_time 65.90521627399994
Test Epoch47 layer0 Acc 0.7616, AUC 0.8365013599395752, avg_entr 0.14266039431095123, f1 0.7616000771522522
ep47_l0_test_time 0.6219750129998829
Test Epoch47 layer1 Acc 0.768, AUC 0.827910304069519, avg_entr 0.038194019347429276, f1 0.7680000066757202
ep47_l1_test_time 0.8151919050001197
Test Epoch47 layer2 Acc 0.7712, AUC 0.8426361083984375, avg_entr 0.03369864076375961, f1 0.7712000012397766
ep47_l2_test_time 1.142533691999688
Test Epoch47 layer3 Acc 0.7718, AUC 0.8492334485054016, avg_entr 0.031097589060664177, f1 0.7717999815940857
ep47_l3_test_time 1.6249948189997667
Test Epoch47 layer4 Acc 0.7718, AUC 0.8488060235977173, avg_entr 0.029393715783953667, f1 0.7717999815940857
ep47_l4_test_time 2.258835896000164
gc 0
Train Epoch48 Acc 0.973975 (38959/40000), AUC 0.9958092570304871
ep48_train_time 65.75073433000034
Test Epoch48 layer0 Acc 0.7628, AUC 0.8364489078521729, avg_entr 0.1424769163131714, f1 0.7627999782562256
ep48_l0_test_time 0.6239309289999255
Test Epoch48 layer1 Acc 0.7684, AUC 0.8281672596931458, avg_entr 0.037398118525743484, f1 0.7684000730514526
ep48_l1_test_time 0.8163726259999748
Test Epoch48 layer2 Acc 0.7708, AUC 0.8428100347518921, avg_entr 0.03325558826327324, f1 0.7707999348640442
ep48_l2_test_time 1.1402571029998398
Test Epoch48 layer3 Acc 0.7714, AUC 0.8492916822433472, avg_entr 0.03078550100326538, f1 0.771399974822998
ep48_l3_test_time 1.6235841439997785
Test Epoch48 layer4 Acc 0.7716, AUC 0.8488572835922241, avg_entr 0.029148437082767487, f1 0.771600067615509
ep48_l4_test_time 2.2599647089996324
gc 0
Train Epoch49 Acc 0.9736 (38944/40000), AUC 0.9958525896072388
ep49_train_time 65.76104175499995
Test Epoch49 layer0 Acc 0.7612, AUC 0.8363965749740601, avg_entr 0.1427183896303177, f1 0.7612000107765198
ep49_l0_test_time 0.6214209390000178
Test Epoch49 layer1 Acc 0.768, AUC 0.8272714614868164, avg_entr 0.038104504346847534, f1 0.7680000066757202
ep49_l1_test_time 0.8251990939997995
Test Epoch49 layer2 Acc 0.7718, AUC 0.842742919921875, avg_entr 0.03373582288622856, f1 0.7717999815940857
ep49_l2_test_time 1.1388485870002114
Test Epoch49 layer3 Acc 0.7718, AUC 0.8491328954696655, avg_entr 0.030993515625596046, f1 0.7717999815940857
ep49_l3_test_time 1.6223437210001066
Test Epoch49 layer4 Acc 0.772, AUC 0.8487581014633179, avg_entr 0.02926507592201233, f1 0.7720000147819519
ep49_l4_test_time 2.2592136110001775
Best AUC tensor(0.8054) 11 4
train_as_loss [[9.07574537e+01 6.01220579e+01 5.23276305e+01 5.05628187e+01
  4.99463657e+01 4.96639574e+01 4.95118365e+01 4.94207097e+01
  4.93618793e+01 4.93217407e+01 4.92931675e+01 4.92721269e+01
  4.92562088e+01 4.92438884e+01 4.92341703e+01 4.92263854e+01
  4.92200583e+01 4.92148585e+01 4.92115041e+01 4.92094645e+01
  4.92075309e+01 4.92057028e+01 4.92043890e+01 4.92035224e+01
  4.92026516e+01 4.92017802e+01 4.92011241e+01 4.92006741e+01
  4.92002093e+01 4.91997302e+01 4.91993597e+01 4.91990996e+01
  4.91988288e+01 4.91985422e+01 4.91983188e+01 4.91981598e+01
  4.91979923e+01 4.91978139e+01 4.91976742e+01 4.91975698e+01
  4.91974649e+01 4.91973499e+01 4.91972576e+01 4.91971923e+01
  4.91971241e+01 4.91970500e+01 4.91969860e+01 4.91969491e+01
  4.91969052e+01 4.91968507e+01]
 [2.46499186e+00 4.62153161e-04 2.07027579e-05 5.15382669e-06
  2.03961588e-06 1.01511878e-06 5.58745803e-07 4.89778181e-07
  3.35716696e-07 3.04962347e-07 3.85611216e-07 6.77966471e-08
  3.96461798e-07 2.85642650e-07 2.01048914e-07 4.07591918e-07
  1.75890346e-07 5.80178658e-07 9.56713255e-09 8.02059892e-09
  6.71181265e-09 6.02992039e-09 5.27083763e-09 4.99650849e-09
  4.50664967e-09 4.16593689e-09 3.86330494e-09 3.70071701e-09
  3.52998914e-09 3.42507225e-09 3.16805614e-09 3.06918370e-09
  2.97595837e-09 2.86171100e-09 2.75994962e-09 2.69935687e-09
  2.61490451e-09 2.57385732e-09 2.51708363e-09 2.46097018e-09
  2.41493467e-09 2.35838601e-09 2.37809741e-09 2.31266105e-09
  2.24362633e-09 2.20969802e-09 2.28601622e-09 2.24012425e-09
  2.15357348e-09 2.08222140e-09]
 [2.17289121e+00 4.99238971e-04 1.33426991e-05 2.96480562e-06
  1.16859270e-06 6.07671828e-07 3.40869540e-07 1.96839656e-07
  1.37794357e-07 8.23996379e-08 6.34113442e-08 4.64154358e-08
  3.64502399e-08 2.78654594e-08 2.20591803e-08 2.24384706e-08
  4.30019703e-08 4.67843601e-08 6.85523675e-09 5.46740033e-09
  1.68378141e-08 1.38203539e-08 3.53425299e-09 3.15731970e-09
  1.08223639e-08 9.57340694e-09 2.37744416e-09 2.20299045e-09
  8.35020578e-09 7.72602228e-09 1.92507481e-09 1.78853764e-09
  6.87238560e-09 6.44778606e-09 1.60728607e-09 1.54076209e-09
  5.90624680e-09 5.78619739e-09 1.48945582e-09 1.39306106e-09
  5.24712727e-09 5.26340102e-09 1.46989121e-09 1.29616683e-09
  4.64322348e-09 4.84715331e-09 1.53979139e-09 1.25781308e-09
  4.21263250e-09 4.62949139e-09]
 [2.46563922e+00 1.00481035e-03 1.77606263e-05 4.34258088e-06
  1.74428310e-06 8.80427774e-07 4.93279900e-07 2.77489410e-07
  1.97455158e-07 1.07808851e-07 8.84044228e-08 6.98158521e-08
  5.02352212e-08 4.35340448e-08 3.50882829e-08 3.14796482e-08
  5.13485637e-08 4.99394947e-08 1.14557848e-08 7.65629750e-09
  1.76530732e-08 1.46418226e-08 4.78603134e-09 3.68736016e-09
  1.07369566e-08 9.37482591e-09 2.76228988e-09 2.22359261e-09
  8.08706121e-09 7.52399373e-09 2.08390248e-09 1.73757928e-09
  6.46562262e-09 6.08665802e-09 1.62502992e-09 1.45526198e-09
  5.44059256e-09 5.38884674e-09 1.53092624e-09 1.33949878e-09
  4.89398710e-09 4.94705871e-09 1.52127988e-09 1.26303796e-09
  4.40622107e-09 4.70653562e-09 1.65924592e-09 1.31003303e-09
  4.19464966e-09 4.66281542e-09]
 [2.26705617e+00 1.31459083e-03 1.72862555e-05 4.77525340e-06
  2.02423413e-06 1.14047219e-06 6.72585819e-07 3.84724995e-07
  2.97701036e-07 1.36823076e-07 1.42008455e-07 1.27088191e-07
  8.47249060e-08 9.04896974e-08 7.61953189e-08 6.89701623e-08
  7.64760210e-08 6.86750057e-08 2.45699925e-08 1.49553550e-08
  2.21424579e-08 1.85076477e-08 8.72036174e-09 5.34192443e-09
  1.25773828e-08 1.07510182e-08 3.80454121e-09 2.70413673e-09
  9.15595387e-09 8.39325874e-09 2.75042898e-09 2.01274072e-09
  7.22107160e-09 6.74852084e-09 1.94338933e-09 1.65056208e-09
  6.01340959e-09 6.06360465e-09 1.78671103e-09 1.48709042e-09
  5.30775849e-09 5.55276990e-09 1.78444240e-09 1.40421086e-09
  4.75007310e-09 5.25048841e-09 2.02130616e-09 1.47282733e-09
  4.45321027e-09 5.28054531e-09]]
train_ae_loss [[3.84441512 3.05157024 4.00288812 4.34923392 4.62581435 4.77606633
  4.89704547 4.97114472 5.05955807 4.96312658 4.95102305 4.93105895
  4.79327162 4.69532458 4.59399471 4.44061155 4.27554285 4.22554365
  3.72436966 3.52589223 3.41212982 3.3570415  3.10082992 3.03053657
  2.95947018 2.91338041 2.81620727 2.77743108 2.77547245 2.7202924
  2.6717873  2.66151267 2.65073605 2.65508308 2.6124549  2.59708116
  2.61614997 2.58409386 2.59670789 2.5957838  2.57173992 2.57420632
  2.56788968 2.56395552 2.58096055 2.57257823 2.57152407 2.56599773
  2.5791013  2.58011717]
 [4.54738215 3.15442913 4.27641105 4.35967648 4.6144281  4.72417654
  4.75093858 4.73035646 4.72454741 4.52240414 4.43379466 4.36086659
  4.02755651 3.89723929 3.66070222 3.43482414 3.18664761 3.09042672
  2.4520105  2.2123804  2.08146749 2.00476914 1.68525665 1.61202783
  1.52807201 1.45735093 1.35496612 1.30404136 1.31292125 1.26355161
  1.20303386 1.15965416 1.16328685 1.17486283 1.13464999 1.10229078
  1.12920088 1.10802737 1.11092444 1.10409816 1.07936665 1.08727504
  1.08490853 1.06557266 1.08991202 1.08368518 1.08429868 1.07368871
  1.0910895  1.0748805 ]
 [3.9823813  2.88715662 4.13146879 4.08647679 4.26278488 4.34926401
  4.27666313 4.20403516 4.12471329 3.86827021 3.75632308 3.74501938
  3.48626056 3.38150939 3.17378795 2.98150409 2.70975074 2.62214939
  2.10446599 1.88681761 1.74127459 1.67453407 1.40811927 1.34093564
  1.26090969 1.19648401 1.11753534 1.06892875 1.07099643 1.02569447
  0.9768145  0.93025907 0.93552033 0.94760087 0.91989471 0.89271865
  0.90755234 0.8893552  0.89214779 0.88703393 0.8652831  0.87429112
  0.87028252 0.85050154 0.87599644 0.86608407 0.86632263 0.86225861
  0.87680403 0.85944216]
 [5.01733254 3.08627814 4.48948537 4.61912277 4.57976161 4.63167268
  4.45772387 4.33802508 4.23898337 3.95386353 3.83019336 3.81808502
  3.54293925 3.43846736 3.22059887 3.02463886 2.72805402 2.63865763
  2.1170282  1.8931135  1.73994453 1.67261265 1.40638325 1.3380908
  1.25543657 1.1874539  1.10897798 1.05838381 1.06001384 1.01406552
  0.96871939 0.91773874 0.92301951 0.9355524  0.9080351  0.88221646
  0.89653365 0.87688982 0.87921207 0.87511006 0.85345115 0.8646692
  0.85815864 0.8374758  0.86287121 0.85158047 0.85363634 0.85070274
  0.86565066 0.84579813]
 [4.71856413 2.52289183 3.70788681 4.24875662 3.91781799 3.90519896
  3.66149844 3.56044023 3.45603654 3.21111999 3.10103808 3.10073571
  2.86627183 2.78685207 2.60767023 2.45029916 2.19028661 2.12143034
  1.70868095 1.52493372 1.39912141 1.34368508 1.13442884 1.07899523
  1.0098735  0.95453885 0.89384839 0.85223307 0.85291658 0.81592525
  0.78033525 0.73961702 0.74358806 0.75313799 0.73186393 0.7114137
  0.72169138 0.706389   0.70871801 0.70485905 0.68767034 0.69657539
  0.69180361 0.67488137 0.69510714 0.68614061 0.68747395 0.68539623
  0.69713848 0.68120998]]
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
total_train+valid_time 3619.313428161
Start Testing
Load ckpt at ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt
gc 9
Test layer0 Acc 0.79, AUC 0.8743683099746704, avg_entr 0.2195945382118225, f1 0.7900000214576721
l0_test_time 0.6225782780002191
gc 0
Test layer1 Acc 0.8032, AUC 0.8915054798126221, avg_entr 0.15512584149837494, f1 0.8032000660896301
l1_test_time 0.8173707650003053
gc 0
Test layer2 Acc 0.8024, AUC 0.892658531665802, avg_entr 0.12538456916809082, f1 0.8023999929428101
l2_test_time 1.1403886250000141
gc 0
Test layer3 Acc 0.8018, AUC 0.8926606178283691, avg_entr 0.1246701180934906, f1 0.801800012588501
l3_test_time 1.6212791460002336
gc 0
Test layer4 Acc 0.8026, AUC 0.8925090432167053, avg_entr 0.12374299019575119, f1 0.802600085735321
l4_test_time 2.2562272390000544
gc 0
Test threshold 0.1 Acc 0.8024, AUC 0.8885849714279175, avg_entr 0.18187129497528076, f1 0.8023999929428101
t0.1_test_time 1.291880690999733
gc 0
Test threshold 0.2 Acc 0.8036, AUC 0.8858702778816223, avg_entr 0.19139142334461212, f1 0.803600013256073
t0.2_test_time 1.158764637999866
gc 0
Test threshold 0.3 Acc 0.804, AUC 0.8845676183700562, avg_entr 0.20221589505672455, f1 0.8040000200271606
t0.3_test_time 1.0683482619997449
gc 0
Test threshold 0.4 Acc 0.803, AUC 0.8822512030601501, avg_entr 0.21280595660209656, f1 0.8029999732971191
t0.4_test_time 0.9958395160001601
gc 0
Test threshold 0.5 Acc 0.8016, AUC 0.8818238973617554, avg_entr 0.22612248361110687, f1 0.8015999794006348
t0.5_test_time 0.9273406920001435
gc 0
Test threshold 0.6 Acc 0.8002, AUC 0.8810625076293945, avg_entr 0.23759709298610687, f1 0.8001999855041504
t0.6_test_time 0.8902772540000115
gc 0
Test threshold 0.7 Acc 0.7994, AUC 0.8797063827514648, avg_entr 0.2492668479681015, f1 0.7993999123573303
t0.7_test_time 0.8413102849999632
gc 0
Test threshold 0.8 Acc 0.7986, AUC 0.8778561353683472, avg_entr 0.26202794909477234, f1 0.7986000180244446
t0.8_test_time 0.7809455840001647
gc 0
Test threshold 0.9 Acc 0.797, AUC 0.876659631729126, avg_entr 0.2802978754043579, f1 0.796999990940094
t0.9_test_time 0.7253603610001846
