total count words 222751
vocab size 30000
train size 40000, valid size 5000, test size 5000
found 27937 words in glove
model: TransformerALsideText(
  (layers): ModuleList(
    (0): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=2, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=2, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
  (emb_layers): ModuleList(
    (0): Embedding(30000, 300)
    (1): Embedding(30000, 300)
    (2): Embedding(30000, 300)
    (3): Embedding(30000, 300)
    (4): Embedding(30000, 300)
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.multi_headed_attention.linears.0.weight 90000
layers.0.enc.f.multi_headed_attention.linears.0.bias 300
layers.0.enc.f.multi_headed_attention.linears.1.weight 90000
layers.0.enc.f.multi_headed_attention.linears.1.bias 300
layers.0.enc.f.multi_headed_attention.linears.2.weight 90000
layers.0.enc.f.multi_headed_attention.linears.2.bias 300
layers.0.enc.f.multi_headed_attention.linears.3.weight 90000
layers.0.enc.f.multi_headed_attention.linears.3.bias 300
layers.0.enc.f.feed_forward.w_1.weight 90000
layers.0.enc.f.feed_forward.w_1.bias 300
layers.0.enc.f.feed_forward.w_2.weight 90000
layers.0.enc.f.feed_forward.w_2.bias 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.0.enc.f.encoder.norm.a 300
layers.0.enc.f.encoder.norm.b 300
layers.0.ae.g.0.weight 256
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 256
layers.0.ae.h.0.bias 2
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
emb_layers.0.weight 9000000
emb_layers.1.weight 9000000
emb_layers.2.weight 9000000
emb_layers.3.weight 9000000
emb_layers.4.weight 9000000
Total Trainable Params: 50758378
init_time 20.982025656
Start Training
gc 0
Train Epoch0 Acc 0.5013 (20052/40000), AUC 0.49852922558784485
ep0_train_time 65.948234946
Test Epoch0 layer0 Acc 0.5438, AUC 0.6219311356544495, avg_entr 0.6873138546943665, f1 0.5437999963760376
ep0_l0_test_time 0.6319074919999963
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 0
Test Epoch0 layer1 Acc 0.5216, AUC 0.5393068790435791, avg_entr 0.7018513679504395, f1 0.5216000080108643
ep0_l1_test_time 0.8331334519999984
Test Epoch0 layer2 Acc 0.5316, AUC 0.5432969331741333, avg_entr 0.6933589577674866, f1 0.5315999984741211
ep0_l2_test_time 1.147611132999998
Test Epoch0 layer3 Acc 0.5018, AUC 0.5289623141288757, avg_entr 0.6922779679298401, f1 0.501800000667572
ep0_l3_test_time 1.6278018209999914
Test Epoch0 layer4 Acc 0.4952, AUC 0.46254727244377136, avg_entr 0.6935179829597473, f1 0.4952000081539154
ep0_l4_test_time 2.263237402999991
gc 0
Train Epoch1 Acc 0.49935 (19974/40000), AUC 0.4999850392341614
ep1_train_time 65.624544122
Test Epoch1 layer0 Acc 0.63, AUC 0.7160452008247375, avg_entr 0.6152947545051575, f1 0.6299999952316284
ep1_l0_test_time 0.6356830729999956
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 1
Test Epoch1 layer1 Acc 0.5076, AUC 0.704866349697113, avg_entr 0.5663648843765259, f1 0.5076000094413757
ep1_l1_test_time 0.8280215899999916
Test Epoch1 layer2 Acc 0.5, AUC 0.6834744215011597, avg_entr 0.6049191355705261, f1 0.5
ep1_l2_test_time 1.1465549119999991
Test Epoch1 layer3 Acc 0.5, AUC 0.5209764242172241, avg_entr 0.6458569765090942, f1 0.5
ep1_l3_test_time 1.6280146199999876
Test Epoch1 layer4 Acc 0.5, AUC 0.4367150068283081, avg_entr 0.6466162800788879, f1 0.5
ep1_l4_test_time 2.2574671879999926
gc 0
Train Epoch2 Acc 0.52485 (20994/40000), AUC 0.5351579189300537
ep2_train_time 65.529933674
Test Epoch2 layer0 Acc 0.7082, AUC 0.7991117238998413, avg_entr 0.4484505355358124, f1 0.7081999778747559
ep2_l0_test_time 0.6295712320000177
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 2
Test Epoch2 layer1 Acc 0.6992, AUC 0.8000309467315674, avg_entr 0.417891263961792, f1 0.6991999745368958
ep2_l1_test_time 0.8271468470000229
Test Epoch2 layer2 Acc 0.6786, AUC 0.7938315868377686, avg_entr 0.4260362386703491, f1 0.678600013256073
ep2_l2_test_time 1.1425561660000199
Test Epoch2 layer3 Acc 0.6322, AUC 0.7926066517829895, avg_entr 0.5187793374061584, f1 0.6322000026702881
ep2_l3_test_time 1.641940422999994
Test Epoch2 layer4 Acc 0.6588, AUC 0.7856455445289612, avg_entr 0.688607931137085, f1 0.6588000059127808
ep2_l4_test_time 2.270406723999997
gc 0
Train Epoch3 Acc 0.645075 (25803/40000), AUC 0.690670907497406
ep3_train_time 65.667828418
Test Epoch3 layer0 Acc 0.7454, AUC 0.827907919883728, avg_entr 0.4004519581794739, f1 0.745400071144104
ep3_l0_test_time 0.6460607399999958
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer1 Acc 0.7522, AUC 0.8355546593666077, avg_entr 0.39899998903274536, f1 0.7522000074386597
ep3_l1_test_time 0.8553040040000042
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer2 Acc 0.7478, AUC 0.8359400629997253, avg_entr 0.4128586947917938, f1 0.7477999925613403
ep3_l2_test_time 1.1628633079999986
Test Epoch3 layer3 Acc 0.7384, AUC 0.8359737992286682, avg_entr 0.44342225790023804, f1 0.7384000420570374
ep3_l3_test_time 1.6386793780000062
Test Epoch3 layer4 Acc 0.6936, AUC 0.8363303542137146, avg_entr 0.4730738699436188, f1 0.6935999989509583
ep3_l4_test_time 2.2808736549999935
gc 0
Train Epoch4 Acc 0.7086 (28344/40000), AUC 0.7892212271690369
ep4_train_time 65.64219984300001
Test Epoch4 layer0 Acc 0.7608, AUC 0.8424198627471924, avg_entr 0.3404315412044525, f1 0.7608000040054321
ep4_l0_test_time 0.6312912610000012
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
Test Epoch4 layer1 Acc 0.7602, AUC 0.8512464761734009, avg_entr 0.3183354437351227, f1 0.7602000832557678
ep4_l1_test_time 0.8290624850000086
Test Epoch4 layer2 Acc 0.7606, AUC 0.8505127429962158, avg_entr 0.31487414240837097, f1 0.7605999708175659
ep4_l2_test_time 1.1423094969999852
Test Epoch4 layer3 Acc 0.7542, AUC 0.8504161238670349, avg_entr 0.31813833117485046, f1 0.7541999816894531
ep4_l3_test_time 1.6246757810000076
Test Epoch4 layer4 Acc 0.7502, AUC 0.8506252765655518, avg_entr 0.3230978846549988, f1 0.7501999735832214
ep4_l4_test_time 2.25684826600002
gc 0
Train Epoch5 Acc 0.759675 (30387/40000), AUC 0.8418699502944946
ep5_train_time 65.59923698
Test Epoch5 layer0 Acc 0.766, AUC 0.8529250025749207, avg_entr 0.3158101439476013, f1 0.7659999132156372
ep5_l0_test_time 0.6272305109999934
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 5
Test Epoch5 layer1 Acc 0.7826, AUC 0.8658013343811035, avg_entr 0.2880012094974518, f1 0.7825999855995178
ep5_l1_test_time 0.8360709859999815
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 5
Test Epoch5 layer2 Acc 0.7796, AUC 0.865781307220459, avg_entr 0.2690718173980713, f1 0.7796000838279724
ep5_l2_test_time 1.1611826689999702
Test Epoch5 layer3 Acc 0.7796, AUC 0.8656322956085205, avg_entr 0.2665290832519531, f1 0.7796000838279724
ep5_l3_test_time 1.6280797699999994
Test Epoch5 layer4 Acc 0.7786, AUC 0.8657771944999695, avg_entr 0.26562994718551636, f1 0.7785999774932861
ep5_l4_test_time 2.2622952170000303
gc 0
Train Epoch6 Acc 0.783675 (31347/40000), AUC 0.8674834370613098
ep6_train_time 65.57334402899994
Test Epoch6 layer0 Acc 0.7696, AUC 0.8606748580932617, avg_entr 0.27724364399909973, f1 0.769599974155426
ep6_l0_test_time 0.6331597559999409
Test Epoch6 layer1 Acc 0.7862, AUC 0.8746699690818787, avg_entr 0.24704892933368683, f1 0.7861999869346619
ep6_l1_test_time 0.8257266599999866
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer2 Acc 0.7894, AUC 0.8757411241531372, avg_entr 0.21028432250022888, f1 0.7893999814987183
ep6_l2_test_time 1.1528932639999994
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer3 Acc 0.7892, AUC 0.8758304119110107, avg_entr 0.21159274876117706, f1 0.7892000079154968
ep6_l3_test_time 1.6301917030000368
Test Epoch6 layer4 Acc 0.7888, AUC 0.8760656118392944, avg_entr 0.2077447772026062, f1 0.7888000011444092
ep6_l4_test_time 2.2563414139999622
gc 0
Train Epoch7 Acc 0.787025 (31481/40000), AUC 0.8666620850563049
ep7_train_time 65.56992755400006
Test Epoch7 layer0 Acc 0.7784, AUC 0.8669762015342712, avg_entr 0.2657547891139984, f1 0.7784000039100647
ep7_l0_test_time 0.6275235269999939
Test Epoch7 layer1 Acc 0.796, AUC 0.884393036365509, avg_entr 0.2325240969657898, f1 0.796000063419342
ep7_l1_test_time 0.8208917200000769
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 7
Test Epoch7 layer2 Acc 0.7918, AUC 0.8847296833992004, avg_entr 0.20802456140518188, f1 0.7918000221252441
ep7_l2_test_time 1.1596298480000087
Test Epoch7 layer3 Acc 0.7908, AUC 0.884784460067749, avg_entr 0.21999430656433105, f1 0.7907999753952026
ep7_l3_test_time 1.6254017919999342
Test Epoch7 layer4 Acc 0.7924, AUC 0.8849139213562012, avg_entr 0.2374161183834076, f1 0.7923999428749084
ep7_l4_test_time 2.261341870000024
gc 0
Train Epoch8 Acc 0.820325 (32813/40000), AUC 0.8994076251983643
ep8_train_time 65.57114615299997
Test Epoch8 layer0 Acc 0.7682, AUC 0.8704845905303955, avg_entr 0.24869008362293243, f1 0.7681999802589417
ep8_l0_test_time 0.638048432000005
Test Epoch8 layer1 Acc 0.7848, AUC 0.8877444267272949, avg_entr 0.19552814960479736, f1 0.7847999930381775
ep8_l1_test_time 0.8227162850000695
Test Epoch8 layer2 Acc 0.7898, AUC 0.8887197971343994, avg_entr 0.16115176677703857, f1 0.7897999882698059
ep8_l2_test_time 1.147631725999986
Test Epoch8 layer3 Acc 0.7848, AUC 0.8889725208282471, avg_entr 0.15739135444164276, f1 0.7847999930381775
ep8_l3_test_time 1.6349563300000227
Test Epoch8 layer4 Acc 0.7808, AUC 0.889163613319397, avg_entr 0.15499942004680634, f1 0.7808000445365906
ep8_l4_test_time 2.270259225000018
gc 0
Train Epoch9 Acc 0.8235 (32940/40000), AUC 0.9021685123443604
ep9_train_time 65.57473742100001
Test Epoch9 layer0 Acc 0.7604, AUC 0.8756253719329834, avg_entr 0.23334619402885437, f1 0.7603999972343445
ep9_l0_test_time 0.6281324930000665
Test Epoch9 layer1 Acc 0.7796, AUC 0.890891432762146, avg_entr 0.181468665599823, f1 0.7796000838279724
ep9_l1_test_time 0.832469379000031
Test Epoch9 layer2 Acc 0.7808, AUC 0.8926264643669128, avg_entr 0.15157894790172577, f1 0.7808000445365906
ep9_l2_test_time 1.1424446210000951
Test Epoch9 layer3 Acc 0.7804, AUC 0.8929165005683899, avg_entr 0.1463904231786728, f1 0.7803999781608582
ep9_l3_test_time 1.623225019000074
Test Epoch9 layer4 Acc 0.777, AUC 0.8930889368057251, avg_entr 0.14246921241283417, f1 0.7770000100135803
ep9_l4_test_time 2.257680769999979
gc 0
Train Epoch10 Acc 0.83375 (33350/40000), AUC 0.9108509421348572
ep10_train_time 65.54790437499992
Test Epoch10 layer0 Acc 0.7926, AUC 0.8784056901931763, avg_entr 0.22484517097473145, f1 0.7925999760627747
ep10_l0_test_time 0.6294136879999996
Test Epoch10 layer1 Acc 0.8108, AUC 0.8946631550788879, avg_entr 0.1606660932302475, f1 0.8108000159263611
ep10_l1_test_time 0.8221917230000599
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 10
Test Epoch10 layer2 Acc 0.8106, AUC 0.8954952955245972, avg_entr 0.1408490240573883, f1 0.8105999231338501
ep10_l2_test_time 1.1610094400000435
Test Epoch10 layer3 Acc 0.8106, AUC 0.89564049243927, avg_entr 0.13847799599170685, f1 0.8105999231338501
ep10_l3_test_time 1.6368184139998903
Test Epoch10 layer4 Acc 0.8126, AUC 0.8958098888397217, avg_entr 0.13428263366222382, f1 0.8126000165939331
ep10_l4_test_time 2.266335111999979
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 10
gc 0
Train Epoch11 Acc 0.8384 (33536/40000), AUC 0.9147441387176514
ep11_train_time 65.57884851600011
Test Epoch11 layer0 Acc 0.799, AUC 0.8795017004013062, avg_entr 0.21421799063682556, f1 0.7990000247955322
ep11_l0_test_time 0.6281425639999725
Test Epoch11 layer1 Acc 0.8132, AUC 0.8962973356246948, avg_entr 0.14721691608428955, f1 0.8131999969482422
ep11_l1_test_time 0.8211534710000024
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 11
Test Epoch11 layer2 Acc 0.8124, AUC 0.8966882228851318, avg_entr 0.12342783063650131, f1 0.8123999238014221
ep11_l2_test_time 1.1536918289999676
Test Epoch11 layer3 Acc 0.812, AUC 0.8966530561447144, avg_entr 0.12336435914039612, f1 0.8119999766349792
ep11_l3_test_time 1.6238910289999922
Test Epoch11 layer4 Acc 0.8104, AUC 0.8966723680496216, avg_entr 0.12306362390518188, f1 0.8104000091552734
ep11_l4_test_time 2.257857994999995
gc 0
Train Epoch12 Acc 0.85385 (34154/40000), AUC 0.9261107444763184
ep12_train_time 65.54882733500006
Test Epoch12 layer0 Acc 0.7942, AUC 0.8802280426025391, avg_entr 0.20201274752616882, f1 0.7942000031471252
ep12_l0_test_time 0.6271715569999969
Test Epoch12 layer1 Acc 0.8004, AUC 0.8954454064369202, avg_entr 0.11591484397649765, f1 0.8004000186920166
ep12_l1_test_time 0.8211037649999753
Test Epoch12 layer2 Acc 0.7998, AUC 0.8963594436645508, avg_entr 0.10323859006166458, f1 0.7997999787330627
ep12_l2_test_time 1.1437162629999875
Test Epoch12 layer3 Acc 0.8004, AUC 0.8963711261749268, avg_entr 0.09940284490585327, f1 0.8004000186920166
ep12_l3_test_time 1.6223293799999965
Test Epoch12 layer4 Acc 0.797, AUC 0.8962578773498535, avg_entr 0.09705033153295517, f1 0.796999990940094
ep12_l4_test_time 2.2563052430000425
gc 0
Train Epoch13 Acc 0.86675 (34670/40000), AUC 0.937188982963562
ep13_train_time 65.59101495699997
Test Epoch13 layer0 Acc 0.7978, AUC 0.8821709156036377, avg_entr 0.1933886706829071, f1 0.7978000044822693
ep13_l0_test_time 0.6275936370000181
Test Epoch13 layer1 Acc 0.8184, AUC 0.89821457862854, avg_entr 0.12013200670480728, f1 0.8184000253677368
ep13_l1_test_time 0.8314509750000525
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 13
Test Epoch13 layer2 Acc 0.8162, AUC 0.8992722034454346, avg_entr 0.10614748299121857, f1 0.8162000179290771
ep13_l2_test_time 1.1510131649999948
Test Epoch13 layer3 Acc 0.8182, AUC 0.8992308378219604, avg_entr 0.10372170060873032, f1 0.8181999921798706
ep13_l3_test_time 1.6338897690000067
Test Epoch13 layer4 Acc 0.8178, AUC 0.8993003368377686, avg_entr 0.10069939494132996, f1 0.817799985408783
ep13_l4_test_time 2.2625473260000035
gc 0
Train Epoch14 Acc 0.87655 (35062/40000), AUC 0.9438384771347046
ep14_train_time 65.85288439800001
Test Epoch14 layer0 Acc 0.776, AUC 0.8826366066932678, avg_entr 0.17051628232002258, f1 0.7759999632835388
ep14_l0_test_time 0.6253855850000036
Test Epoch14 layer1 Acc 0.7786, AUC 0.897526741027832, avg_entr 0.0986255407333374, f1 0.7785999774932861
ep14_l1_test_time 0.8226262189998579
Test Epoch14 layer2 Acc 0.775, AUC 0.8991374373435974, avg_entr 0.08813325315713882, f1 0.7749999761581421
ep14_l2_test_time 1.1424966549998317
Test Epoch14 layer3 Acc 0.7768, AUC 0.8990287184715271, avg_entr 0.08414076268672943, f1 0.7768000364303589
ep14_l3_test_time 1.62534989400001
Test Epoch14 layer4 Acc 0.7772, AUC 0.8991055488586426, avg_entr 0.08148370683193207, f1 0.777199923992157
ep14_l4_test_time 2.256907303999924
gc 0
Train Epoch15 Acc 0.88775 (35510/40000), AUC 0.951709508895874
ep15_train_time 65.55300181000007
Test Epoch15 layer0 Acc 0.7968, AUC 0.8805737495422363, avg_entr 0.1795378029346466, f1 0.7968000173568726
ep15_l0_test_time 0.6291654379999727
Test Epoch15 layer1 Acc 0.8144, AUC 0.8948304057121277, avg_entr 0.09868866950273514, f1 0.8144000172615051
ep15_l1_test_time 0.8188820510001733
Test Epoch15 layer2 Acc 0.815, AUC 0.8962646722793579, avg_entr 0.0817333459854126, f1 0.8149999976158142
ep15_l2_test_time 1.1413675200001308
Test Epoch15 layer3 Acc 0.8148, AUC 0.8960787057876587, avg_entr 0.07949382066726685, f1 0.8148000240325928
ep15_l3_test_time 1.621213287000046
Test Epoch15 layer4 Acc 0.8132, AUC 0.8962414264678955, avg_entr 0.07799859344959259, f1 0.8131999969482422
ep15_l4_test_time 2.256342557999915
gc 0
Train Epoch16 Acc 0.89335 (35734/40000), AUC 0.9550551176071167
ep16_train_time 65.59163108500002
Test Epoch16 layer0 Acc 0.7934, AUC 0.8781578540802002, avg_entr 0.17236122488975525, f1 0.79339998960495
ep16_l0_test_time 0.6261616599999797
Test Epoch16 layer1 Acc 0.8164, AUC 0.8933621048927307, avg_entr 0.09255048632621765, f1 0.8164000511169434
ep16_l1_test_time 0.82249195899999
Test Epoch16 layer2 Acc 0.8208, AUC 0.8970304727554321, avg_entr 0.07448581606149673, f1 0.8208000063896179
ep16_l2_test_time 1.1404330689999824
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 16
Test Epoch16 layer3 Acc 0.8206, AUC 0.896761417388916, avg_entr 0.07378184795379639, f1 0.8205999732017517
ep16_l3_test_time 1.6293087780002224
Test Epoch16 layer4 Acc 0.8206, AUC 0.8968038558959961, avg_entr 0.07160401344299316, f1 0.8205999732017517
ep16_l4_test_time 2.2553502829998706
gc 0
Train Epoch17 Acc 0.907 (36280/40000), AUC 0.9644488096237183
ep17_train_time 65.64386354699991
Test Epoch17 layer0 Acc 0.7708, AUC 0.8766050338745117, avg_entr 0.1690935641527176, f1 0.7707999348640442
ep17_l0_test_time 0.6278519489999326
Test Epoch17 layer1 Acc 0.8018, AUC 0.8874608278274536, avg_entr 0.08898056298494339, f1 0.801800012588501
ep17_l1_test_time 0.8184188550001181
Test Epoch17 layer2 Acc 0.8008, AUC 0.894668698310852, avg_entr 0.07755222171545029, f1 0.8007999658584595
ep17_l2_test_time 1.141640481999957
Test Epoch17 layer3 Acc 0.8014, AUC 0.894085168838501, avg_entr 0.08008840680122375, f1 0.8014000058174133
ep17_l3_test_time 1.6247694170001523
Test Epoch17 layer4 Acc 0.8028, AUC 0.894790768623352, avg_entr 0.08368950337171555, f1 0.8027999997138977
ep17_l4_test_time 2.2711325699999634
gc 0
Train Epoch18 Acc 0.919975 (36799/40000), AUC 0.9728437662124634
ep18_train_time 65.61271837200002
Test Epoch18 layer0 Acc 0.7944, AUC 0.8765902519226074, avg_entr 0.15691494941711426, f1 0.7943999767303467
ep18_l0_test_time 0.6291428830002133
Test Epoch18 layer1 Acc 0.8094, AUC 0.8850516080856323, avg_entr 0.07124686986207962, f1 0.8094000220298767
ep18_l1_test_time 0.8309379519998856
Test Epoch18 layer2 Acc 0.8096, AUC 0.8916708827018738, avg_entr 0.05947623401880264, f1 0.8095999956130981
ep18_l2_test_time 1.1477957299998707
Test Epoch18 layer3 Acc 0.809, AUC 0.8916558027267456, avg_entr 0.056567560881376266, f1 0.8090000748634338
ep18_l3_test_time 1.6234535629998845
Test Epoch18 layer4 Acc 0.8088, AUC 0.8916528224945068, avg_entr 0.055196210741996765, f1 0.8087999820709229
ep18_l4_test_time 2.256549249000045
gc 0
Train Epoch19 Acc 0.930175 (37207/40000), AUC 0.9788030385971069
ep19_train_time 65.55889118300001
Test Epoch19 layer0 Acc 0.789, AUC 0.8731352090835571, avg_entr 0.15255016088485718, f1 0.7889999747276306
ep19_l0_test_time 0.625689980000061
Test Epoch19 layer1 Acc 0.8082, AUC 0.8840039372444153, avg_entr 0.07083016633987427, f1 0.808199942111969
ep19_l1_test_time 0.8232945610000115
Test Epoch19 layer2 Acc 0.8072, AUC 0.8908599615097046, avg_entr 0.05818377807736397, f1 0.807200014591217
ep19_l2_test_time 1.1417141499998706
Test Epoch19 layer3 Acc 0.8082, AUC 0.8907942771911621, avg_entr 0.056149475276470184, f1 0.808199942111969
ep19_l3_test_time 1.6246547540001757
Test Epoch19 layer4 Acc 0.8086, AUC 0.8913556933403015, avg_entr 0.05526196211576462, f1 0.8086000084877014
ep19_l4_test_time 2.256081043999984
gc 0
Train Epoch20 Acc 0.937675 (37507/40000), AUC 0.9818599224090576
ep20_train_time 65.57030690099987
Test Epoch20 layer0 Acc 0.7912, AUC 0.8702473640441895, avg_entr 0.1529538631439209, f1 0.7911999821662903
ep20_l0_test_time 0.6260455740000452
Test Epoch20 layer1 Acc 0.7974, AUC 0.8711082935333252, avg_entr 0.0651899203658104, f1 0.7973999977111816
ep20_l1_test_time 0.8192995769998106
Test Epoch20 layer2 Acc 0.7948, AUC 0.8817543983459473, avg_entr 0.05541331693530083, f1 0.7947999835014343
ep20_l2_test_time 1.1421698159999778
Test Epoch20 layer3 Acc 0.7938, AUC 0.8815351724624634, avg_entr 0.053551074117422104, f1 0.7937999963760376
ep20_l3_test_time 1.6235350800000106
Test Epoch20 layer4 Acc 0.7924, AUC 0.8823118209838867, avg_entr 0.05396826192736626, f1 0.7923999428749084
ep20_l4_test_time 2.255471140000054
gc 0
Train Epoch21 Acc 0.9428 (37712/40000), AUC 0.9832496643066406
ep21_train_time 65.61442603799992
Test Epoch21 layer0 Acc 0.7788, AUC 0.8676741123199463, avg_entr 0.1492076963186264, f1 0.7788000106811523
ep21_l0_test_time 0.6267216609999195
Test Epoch21 layer1 Acc 0.7924, AUC 0.8752534985542297, avg_entr 0.06194530054926872, f1 0.7923999428749084
ep21_l1_test_time 0.8200692279999657
Test Epoch21 layer2 Acc 0.7948, AUC 0.8841450810432434, avg_entr 0.05232446268200874, f1 0.7947999835014343
ep21_l2_test_time 1.1448622840000553
Test Epoch21 layer3 Acc 0.7956, AUC 0.8838033676147461, avg_entr 0.04990618675947189, f1 0.7955999970436096
ep21_l3_test_time 1.6244577679999566
Test Epoch21 layer4 Acc 0.795, AUC 0.8849030137062073, avg_entr 0.04920089617371559, f1 0.7950000166893005
ep21_l4_test_time 2.2582319279999865
gc 0
Train Epoch22 Acc 0.94795 (37918/40000), AUC 0.9872422218322754
ep22_train_time 65.66352200799997
Test Epoch22 layer0 Acc 0.7852, AUC 0.8659441471099854, avg_entr 0.14715640246868134, f1 0.7851999998092651
ep22_l0_test_time 0.6308912859999509
Test Epoch22 layer1 Acc 0.7966, AUC 0.8651798963546753, avg_entr 0.05770725756883621, f1 0.7965999841690063
ep22_l1_test_time 0.824171478000153
Test Epoch22 layer2 Acc 0.797, AUC 0.8785214424133301, avg_entr 0.04779139533638954, f1 0.796999990940094
ep22_l2_test_time 1.1433907610000915
Test Epoch22 layer3 Acc 0.7986, AUC 0.8789352178573608, avg_entr 0.04540874436497688, f1 0.7986000180244446
ep22_l3_test_time 1.6258022030001484
Test Epoch22 layer4 Acc 0.7968, AUC 0.8792992830276489, avg_entr 0.04512695223093033, f1 0.7968000173568726
ep22_l4_test_time 2.2570794440000554
gc 0
Train Epoch23 Acc 0.953775 (38151/40000), AUC 0.9891456961631775
ep23_train_time 65.68876823200003
Test Epoch23 layer0 Acc 0.7822, AUC 0.8652786016464233, avg_entr 0.14324218034744263, f1 0.7821999788284302
ep23_l0_test_time 0.6406348970001545
Test Epoch23 layer1 Acc 0.7944, AUC 0.8661574125289917, avg_entr 0.05570681020617485, f1 0.7943999767303467
ep23_l1_test_time 0.8226389689998541
Test Epoch23 layer2 Acc 0.7962, AUC 0.8782466650009155, avg_entr 0.04371977970004082, f1 0.7961999177932739
ep23_l2_test_time 1.1446599410001
Test Epoch23 layer3 Acc 0.7966, AUC 0.878282904624939, avg_entr 0.04071608558297157, f1 0.7965999841690063
ep23_l3_test_time 1.6254947550000907
Test Epoch23 layer4 Acc 0.7968, AUC 0.8795682191848755, avg_entr 0.04022914543747902, f1 0.7968000173568726
ep23_l4_test_time 2.2594541769999523
gc 0
Train Epoch24 Acc 0.95755 (38302/40000), AUC 0.9899932742118835
ep24_train_time 65.55889650899985
Test Epoch24 layer0 Acc 0.7842, AUC 0.8621237277984619, avg_entr 0.1429196447134018, f1 0.7842000126838684
ep24_l0_test_time 0.6268327450000015
Test Epoch24 layer1 Acc 0.7936, AUC 0.8622567653656006, avg_entr 0.05455441772937775, f1 0.7936000227928162
ep24_l1_test_time 0.8230871350001507
Test Epoch24 layer2 Acc 0.7966, AUC 0.8729849457740784, avg_entr 0.04752976819872856, f1 0.7965999841690063
ep24_l2_test_time 1.1405095589998382
Test Epoch24 layer3 Acc 0.797, AUC 0.8729267120361328, avg_entr 0.04509136825799942, f1 0.796999990940094
ep24_l3_test_time 1.625063014000034
Test Epoch24 layer4 Acc 0.7972, AUC 0.8744733333587646, avg_entr 0.044871456921100616, f1 0.7971999645233154
ep24_l4_test_time 2.256611661999841
gc 0
Train Epoch25 Acc 0.959625 (38385/40000), AUC 0.9901850819587708
ep25_train_time 65.57611539599998
Test Epoch25 layer0 Acc 0.7828, AUC 0.8605501651763916, avg_entr 0.14223605394363403, f1 0.782800018787384
ep25_l0_test_time 0.627057091999859
Test Epoch25 layer1 Acc 0.795, AUC 0.860425591468811, avg_entr 0.05325661599636078, f1 0.7950000166893005
ep25_l1_test_time 0.8226290370000697
Test Epoch25 layer2 Acc 0.7922, AUC 0.872897744178772, avg_entr 0.04295766353607178, f1 0.7922000288963318
ep25_l2_test_time 1.1436918590000005
Test Epoch25 layer3 Acc 0.7924, AUC 0.8733454346656799, avg_entr 0.04034896939992905, f1 0.7923999428749084
ep25_l3_test_time 1.6246069059998263
Test Epoch25 layer4 Acc 0.7922, AUC 0.8745962977409363, avg_entr 0.03950830176472664, f1 0.7922000288963318
ep25_l4_test_time 2.2604475100001764
gc 0
Train Epoch26 Acc 0.96235 (38494/40000), AUC 0.9921869039535522
ep26_train_time 65.54912131099991
Test Epoch26 layer0 Acc 0.7824, AUC 0.8608704805374146, avg_entr 0.13864970207214355, f1 0.7824000120162964
ep26_l0_test_time 0.6327313150000009
Test Epoch26 layer1 Acc 0.7936, AUC 0.8612927198410034, avg_entr 0.04952678084373474, f1 0.7936000227928162
ep26_l1_test_time 0.8210975780000354
Test Epoch26 layer2 Acc 0.7918, AUC 0.8740007281303406, avg_entr 0.041274718940258026, f1 0.7918000221252441
ep26_l2_test_time 1.142503218999991
Test Epoch26 layer3 Acc 0.7914, AUC 0.8749181032180786, avg_entr 0.03858528286218643, f1 0.7914000153541565
ep26_l3_test_time 1.6229245609999907
Test Epoch26 layer4 Acc 0.7912, AUC 0.8763743042945862, avg_entr 0.03836207091808319, f1 0.7911999821662903
ep26_l4_test_time 2.25744312300003
gc 0
Train Epoch27 Acc 0.964625 (38585/40000), AUC 0.9924651384353638
ep27_train_time 65.60750731899998
Test Epoch27 layer0 Acc 0.7818, AUC 0.8594330549240112, avg_entr 0.1398528665304184, f1 0.7817999720573425
ep27_l0_test_time 0.6266532689999167
Test Epoch27 layer1 Acc 0.7904, AUC 0.8538254499435425, avg_entr 0.04782307147979736, f1 0.7904000282287598
ep27_l1_test_time 0.8246241040001223
Test Epoch27 layer2 Acc 0.7936, AUC 0.869741678237915, avg_entr 0.03917442262172699, f1 0.7936000227928162
ep27_l2_test_time 1.150768276000008
Test Epoch27 layer3 Acc 0.7928, AUC 0.8714381456375122, avg_entr 0.03695002198219299, f1 0.7928000092506409
ep27_l3_test_time 1.633356982999885
Test Epoch27 layer4 Acc 0.7932, AUC 0.8728306889533997, avg_entr 0.0366830974817276, f1 0.7932000160217285
ep27_l4_test_time 2.264452119999987
gc 0
Train Epoch28 Acc 0.966175 (38647/40000), AUC 0.993489682674408
ep28_train_time 65.58375429999978
Test Epoch28 layer0 Acc 0.7818, AUC 0.857678234577179, avg_entr 0.1392764449119568, f1 0.7817999720573425
ep28_l0_test_time 0.6257875590004005
Test Epoch28 layer1 Acc 0.7908, AUC 0.8569002151489258, avg_entr 0.04691223055124283, f1 0.7907999753952026
ep28_l1_test_time 0.8201801929999419
Test Epoch28 layer2 Acc 0.791, AUC 0.8700344562530518, avg_entr 0.0378614142537117, f1 0.7910000681877136
ep28_l2_test_time 1.1431662110003344
Test Epoch28 layer3 Acc 0.7908, AUC 0.87160325050354, avg_entr 0.035659369081258774, f1 0.7907999753952026
ep28_l3_test_time 1.6233000309998715
Test Epoch28 layer4 Acc 0.7908, AUC 0.8728967905044556, avg_entr 0.035678599029779434, f1 0.7907999753952026
ep28_l4_test_time 2.2563416150001103
gc 0
Train Epoch29 Acc 0.96655 (38662/40000), AUC 0.9934998154640198
ep29_train_time 65.54631745799998
Test Epoch29 layer0 Acc 0.7766, AUC 0.8586015105247498, avg_entr 0.13769188523292542, f1 0.7766000032424927
ep29_l0_test_time 0.6270337529999779
Test Epoch29 layer1 Acc 0.787, AUC 0.8538023233413696, avg_entr 0.04515886679291725, f1 0.7870000600814819
ep29_l1_test_time 0.8243815410000934
Test Epoch29 layer2 Acc 0.7878, AUC 0.8691830635070801, avg_entr 0.03556071221828461, f1 0.7877999544143677
ep29_l2_test_time 1.1430131320003056
Test Epoch29 layer3 Acc 0.7872, AUC 0.8711490035057068, avg_entr 0.03330256789922714, f1 0.7871999740600586
ep29_l3_test_time 1.6238877480000156
Test Epoch29 layer4 Acc 0.7874, AUC 0.872633695602417, avg_entr 0.033149126917123795, f1 0.7874000072479248
ep29_l4_test_time 2.2570744679997006
gc 0
Train Epoch30 Acc 0.968 (38720/40000), AUC 0.9942102432250977
ep30_train_time 65.57557712800008
Test Epoch30 layer0 Acc 0.7796, AUC 0.8574001789093018, avg_entr 0.13862641155719757, f1 0.7796000838279724
ep30_l0_test_time 0.6296751990003031
Test Epoch30 layer1 Acc 0.7894, AUC 0.8544367551803589, avg_entr 0.04723823070526123, f1 0.7893999814987183
ep30_l1_test_time 0.824326463000034
Test Epoch30 layer2 Acc 0.7918, AUC 0.8690828084945679, avg_entr 0.039154812693595886, f1 0.7918000221252441
ep30_l2_test_time 1.1440300549998028
Test Epoch30 layer3 Acc 0.7924, AUC 0.8710182309150696, avg_entr 0.03641292825341225, f1 0.7923999428749084
ep30_l3_test_time 1.6247428960000434
Test Epoch30 layer4 Acc 0.7926, AUC 0.872232973575592, avg_entr 0.03634399548172951, f1 0.7925999760627747
ep30_l4_test_time 2.2602229330000227
gc 0
Train Epoch31 Acc 0.9676 (38704/40000), AUC 0.9944462776184082
ep31_train_time 65.55146030500009
Test Epoch31 layer0 Acc 0.7772, AUC 0.8562901616096497, avg_entr 0.13849520683288574, f1 0.777199923992157
ep31_l0_test_time 0.6410841599999912
Test Epoch31 layer1 Acc 0.7914, AUC 0.8503649234771729, avg_entr 0.04527227208018303, f1 0.7914000153541565
ep31_l1_test_time 0.8226855990001241
Test Epoch31 layer2 Acc 0.791, AUC 0.8659603595733643, avg_entr 0.037765707820653915, f1 0.7910000681877136
ep31_l2_test_time 1.146487664000233
Test Epoch31 layer3 Acc 0.7906, AUC 0.8684471845626831, avg_entr 0.035322435200214386, f1 0.7906000018119812
ep31_l3_test_time 1.6230840200000785
Test Epoch31 layer4 Acc 0.7908, AUC 0.8697256445884705, avg_entr 0.03531960770487785, f1 0.7907999753952026
ep31_l4_test_time 2.2657087979996504
gc 0
Train Epoch32 Acc 0.968625 (38745/40000), AUC 0.9945777654647827
ep32_train_time 65.54415872900017
Test Epoch32 layer0 Acc 0.7724, AUC 0.8558242321014404, avg_entr 0.1357744336128235, f1 0.7724000215530396
ep32_l0_test_time 0.6406127049999668
Test Epoch32 layer1 Acc 0.7898, AUC 0.84942626953125, avg_entr 0.04342908412218094, f1 0.7897999882698059
ep32_l1_test_time 0.8361296600000969
Test Epoch32 layer2 Acc 0.7906, AUC 0.8652335405349731, avg_entr 0.034779563546180725, f1 0.7906000018119812
ep32_l2_test_time 1.1510523389997616
Test Epoch32 layer3 Acc 0.79, AUC 0.8681612014770508, avg_entr 0.032228123396635056, f1 0.7900000214576721
ep32_l3_test_time 1.6340371640003468
Test Epoch32 layer4 Acc 0.7902, AUC 0.8695331811904907, avg_entr 0.03220144659280777, f1 0.7901999950408936
ep32_l4_test_time 2.2676200850000896
gc 0
Train Epoch33 Acc 0.969675 (38787/40000), AUC 0.9946014285087585
ep33_train_time 65.57226302400022
Test Epoch33 layer0 Acc 0.7814, AUC 0.85636967420578, avg_entr 0.1375187188386917, f1 0.7814000248908997
ep33_l0_test_time 0.6263536619999286
Test Epoch33 layer1 Acc 0.79, AUC 0.8496462106704712, avg_entr 0.044745560735464096, f1 0.7900000214576721
ep33_l1_test_time 0.8260350730001846
Test Epoch33 layer2 Acc 0.7904, AUC 0.8653447031974792, avg_entr 0.03620581701397896, f1 0.7904000282287598
ep33_l2_test_time 1.1480152560002352
Test Epoch33 layer3 Acc 0.7916, AUC 0.868404746055603, avg_entr 0.033614229410886765, f1 0.7915999889373779
ep33_l3_test_time 1.624730236999767
Test Epoch33 layer4 Acc 0.7914, AUC 0.869793176651001, avg_entr 0.033720921725034714, f1 0.7914000153541565
ep33_l4_test_time 2.2575210149998384
gc 0
Train Epoch34 Acc 0.97015 (38806/40000), AUC 0.9950624108314514
ep34_train_time 65.5404639809999
Test Epoch34 layer0 Acc 0.7798, AUC 0.8548006415367126, avg_entr 0.13890665769577026, f1 0.7797999978065491
ep34_l0_test_time 0.6252684659998522
Test Epoch34 layer1 Acc 0.7894, AUC 0.8492110967636108, avg_entr 0.047132864594459534, f1 0.7893999814987183
ep34_l1_test_time 0.8227458279998245
Test Epoch34 layer2 Acc 0.7888, AUC 0.8643007278442383, avg_entr 0.03905143588781357, f1 0.7888000011444092
ep34_l2_test_time 1.141365998999845
Test Epoch34 layer3 Acc 0.7904, AUC 0.8671635389328003, avg_entr 0.036538708955049515, f1 0.7904000282287598
ep34_l3_test_time 1.6227181150002252
Test Epoch34 layer4 Acc 0.7904, AUC 0.8683682680130005, avg_entr 0.036516811698675156, f1 0.7904000282287598
ep34_l4_test_time 2.2554621120002594
gc 0
Train Epoch35 Acc 0.97095 (38838/40000), AUC 0.9948383569717407
ep35_train_time 65.58864821599991
Test Epoch35 layer0 Acc 0.7796, AUC 0.8551682233810425, avg_entr 0.13622966408729553, f1 0.7796000838279724
ep35_l0_test_time 0.6263216859997556
Test Epoch35 layer1 Acc 0.7904, AUC 0.8494694232940674, avg_entr 0.04402729123830795, f1 0.7904000282287598
ep35_l1_test_time 0.820334050999918
Test Epoch35 layer2 Acc 0.7888, AUC 0.8653044104576111, avg_entr 0.037307579070329666, f1 0.7888000011444092
ep35_l2_test_time 1.1435552879997886
Test Epoch35 layer3 Acc 0.79, AUC 0.8681460618972778, avg_entr 0.03475210443139076, f1 0.7900000214576721
ep35_l3_test_time 1.6231402079997679
Test Epoch35 layer4 Acc 0.79, AUC 0.8694809675216675, avg_entr 0.03463771939277649, f1 0.7900000214576721
ep35_l4_test_time 2.261861250000038
gc 0
Train Epoch36 Acc 0.972675 (38907/40000), AUC 0.9952099323272705
ep36_train_time 65.54937879499994
Test Epoch36 layer0 Acc 0.7784, AUC 0.8548519015312195, avg_entr 0.13592568039894104, f1 0.7784000039100647
ep36_l0_test_time 0.6277318590000505
Test Epoch36 layer1 Acc 0.7904, AUC 0.8485013246536255, avg_entr 0.04419860243797302, f1 0.7904000282287598
ep36_l1_test_time 0.81993485699968
Test Epoch36 layer2 Acc 0.7884, AUC 0.8640660047531128, avg_entr 0.037166763097047806, f1 0.7884000539779663
ep36_l2_test_time 1.1411138369999207
Test Epoch36 layer3 Acc 0.7892, AUC 0.867284893989563, avg_entr 0.03457922488451004, f1 0.7892000079154968
ep36_l3_test_time 1.621692245000304
Test Epoch36 layer4 Acc 0.7882, AUC 0.8685294389724731, avg_entr 0.03442804515361786, f1 0.7882000207901001
ep36_l4_test_time 2.2556759569997666
gc 0
Train Epoch37 Acc 0.972275 (38891/40000), AUC 0.9947378635406494
ep37_train_time 65.53122857700009
Test Epoch37 layer0 Acc 0.7782, AUC 0.8543945550918579, avg_entr 0.13639584183692932, f1 0.7781999707221985
ep37_l0_test_time 0.6269301809998069
Test Epoch37 layer1 Acc 0.7884, AUC 0.8486849665641785, avg_entr 0.043879829347133636, f1 0.7884000539779663
ep37_l1_test_time 0.821836378000171
Test Epoch37 layer2 Acc 0.7868, AUC 0.8634916543960571, avg_entr 0.03664059564471245, f1 0.786799967288971
ep37_l2_test_time 1.1399631969998154
Test Epoch37 layer3 Acc 0.7888, AUC 0.8670761585235596, avg_entr 0.03420482948422432, f1 0.7888000011444092
ep37_l3_test_time 1.6208879660002822
Test Epoch37 layer4 Acc 0.7884, AUC 0.8682908415794373, avg_entr 0.03400280326604843, f1 0.7884000539779663
ep37_l4_test_time 2.255861227999958
gc 0
Train Epoch38 Acc 0.973075 (38923/40000), AUC 0.995484471321106
ep38_train_time 65.6056385249999
Test Epoch38 layer0 Acc 0.777, AUC 0.8542707562446594, avg_entr 0.1366548389196396, f1 0.7770000100135803
ep38_l0_test_time 0.6383240259997365
Test Epoch38 layer1 Acc 0.7886, AUC 0.8476905822753906, avg_entr 0.043284785002470016, f1 0.7886000275611877
ep38_l1_test_time 0.821844295000119
Test Epoch38 layer2 Acc 0.7886, AUC 0.8632084131240845, avg_entr 0.035452477633953094, f1 0.7886000275611877
ep38_l2_test_time 1.1467127230002916
Test Epoch38 layer3 Acc 0.7878, AUC 0.8670244216918945, avg_entr 0.032475829124450684, f1 0.7877999544143677
ep38_l3_test_time 1.62849530099993
Test Epoch38 layer4 Acc 0.7882, AUC 0.8680788278579712, avg_entr 0.032221000641584396, f1 0.7882000207901001
ep38_l4_test_time 2.262471278999783
gc 0
Train Epoch39 Acc 0.97165 (38866/40000), AUC 0.9953398704528809
ep39_train_time 65.60274441000001
Test Epoch39 layer0 Acc 0.7728, AUC 0.8540047407150269, avg_entr 0.13451585173606873, f1 0.7728000283241272
ep39_l0_test_time 0.627608015000078
Test Epoch39 layer1 Acc 0.7854, AUC 0.8469460010528564, avg_entr 0.041757967323064804, f1 0.7853999733924866
ep39_l1_test_time 0.8225402030002442
Test Epoch39 layer2 Acc 0.7874, AUC 0.8628613948822021, avg_entr 0.03348911926150322, f1 0.7874000072479248
ep39_l2_test_time 1.1411216189999323
Test Epoch39 layer3 Acc 0.7874, AUC 0.8670178651809692, avg_entr 0.030747754499316216, f1 0.7874000072479248
ep39_l3_test_time 1.622181060999992
Test Epoch39 layer4 Acc 0.7874, AUC 0.8679782152175903, avg_entr 0.03058549202978611, f1 0.7874000072479248
ep39_l4_test_time 2.256549291999818
gc 0
Train Epoch40 Acc 0.973225 (38929/40000), AUC 0.9954415559768677
ep40_train_time 65.56503383500012
Test Epoch40 layer0 Acc 0.7768, AUC 0.8546609878540039, avg_entr 0.13497470319271088, f1 0.7768000364303589
ep40_l0_test_time 0.6252675410000847
Test Epoch40 layer1 Acc 0.7896, AUC 0.8471559286117554, avg_entr 0.04281138256192207, f1 0.7896000146865845
ep40_l1_test_time 0.8183523809998405
Test Epoch40 layer2 Acc 0.788, AUC 0.8632012605667114, avg_entr 0.03588872402906418, f1 0.7879999876022339
ep40_l2_test_time 1.1430114330000833
Test Epoch40 layer3 Acc 0.7876, AUC 0.8669902086257935, avg_entr 0.03312770277261734, f1 0.7875999212265015
ep40_l3_test_time 1.6230177399997956
Test Epoch40 layer4 Acc 0.7884, AUC 0.8681265115737915, avg_entr 0.0330965593457222, f1 0.7884000539779663
ep40_l4_test_time 2.256285374000072
gc 0
Train Epoch41 Acc 0.972375 (38895/40000), AUC 0.9952989220619202
ep41_train_time 65.5652267989999
Test Epoch41 layer0 Acc 0.7764, AUC 0.8540853261947632, avg_entr 0.13534881174564362, f1 0.776400089263916
ep41_l0_test_time 0.6302777549999519
Test Epoch41 layer1 Acc 0.7884, AUC 0.8454312682151794, avg_entr 0.04313451424241066, f1 0.7884000539779663
ep41_l1_test_time 0.8208124029997634
Test Epoch41 layer2 Acc 0.7866, AUC 0.862335205078125, avg_entr 0.03622141480445862, f1 0.7865999937057495
ep41_l2_test_time 1.1432157350000125
Test Epoch41 layer3 Acc 0.788, AUC 0.8661755323410034, avg_entr 0.03361425921320915, f1 0.7879999876022339
ep41_l3_test_time 1.625338893999924
Test Epoch41 layer4 Acc 0.7876, AUC 0.8672835826873779, avg_entr 0.0335540696978569, f1 0.7875999212265015
ep41_l4_test_time 2.260402168999917
gc 0
Train Epoch42 Acc 0.972025 (38881/40000), AUC 0.995416522026062
ep42_train_time 65.77574711699981
Test Epoch42 layer0 Acc 0.7728, AUC 0.8539798259735107, avg_entr 0.13435189425945282, f1 0.7728000283241272
ep42_l0_test_time 0.6254809710003428
Test Epoch42 layer1 Acc 0.787, AUC 0.8467487096786499, avg_entr 0.04220641404390335, f1 0.7870000600814819
ep42_l1_test_time 0.8272423429998526
Test Epoch42 layer2 Acc 0.7882, AUC 0.8628847599029541, avg_entr 0.0345512256026268, f1 0.7882000207901001
ep42_l2_test_time 1.1537440439997226
Test Epoch42 layer3 Acc 0.7882, AUC 0.8668676614761353, avg_entr 0.03187570348381996, f1 0.7882000207901001
ep42_l3_test_time 1.6236966070000562
Test Epoch42 layer4 Acc 0.7882, AUC 0.8679686784744263, avg_entr 0.031806398183107376, f1 0.7882000207901001
ep42_l4_test_time 2.2557469560001664
gc 0
Train Epoch43 Acc 0.972925 (38917/40000), AUC 0.995646595954895
ep43_train_time 65.69583240799966
Test Epoch43 layer0 Acc 0.7742, AUC 0.853759765625, avg_entr 0.13425619900226593, f1 0.7742000222206116
ep43_l0_test_time 0.6266902719999052
Test Epoch43 layer1 Acc 0.7874, AUC 0.846954345703125, avg_entr 0.04155480116605759, f1 0.7874000072479248
ep43_l1_test_time 0.8195851959999345
Test Epoch43 layer2 Acc 0.7884, AUC 0.8626258373260498, avg_entr 0.033638183027505875, f1 0.7884000539779663
ep43_l2_test_time 1.1431565190000583
Test Epoch43 layer3 Acc 0.7876, AUC 0.866837203502655, avg_entr 0.030712638050317764, f1 0.7875999212265015
ep43_l3_test_time 1.6246214679999866
Test Epoch43 layer4 Acc 0.7878, AUC 0.8679207563400269, avg_entr 0.03075535036623478, f1 0.7877999544143677
ep43_l4_test_time 2.2582320569999865
gc 0
Train Epoch44 Acc 0.97325 (38930/40000), AUC 0.9957835078239441
ep44_train_time 65.68194112899982
Test Epoch44 layer0 Acc 0.7766, AUC 0.8541941046714783, avg_entr 0.1343211829662323, f1 0.7766000032424927
ep44_l0_test_time 0.6290192890000981
Test Epoch44 layer1 Acc 0.7886, AUC 0.8463589549064636, avg_entr 0.04170302674174309, f1 0.7886000275611877
ep44_l1_test_time 0.8313346599998113
Test Epoch44 layer2 Acc 0.7866, AUC 0.8623720407485962, avg_entr 0.03481220826506615, f1 0.7865999937057495
ep44_l2_test_time 1.1535238729998127
Test Epoch44 layer3 Acc 0.7864, AUC 0.8665417432785034, avg_entr 0.032170768827199936, f1 0.7864000201225281
ep44_l3_test_time 1.6219487869998375
Test Epoch44 layer4 Acc 0.7872, AUC 0.8676508665084839, avg_entr 0.03200247511267662, f1 0.7871999740600586
ep44_l4_test_time 2.2571661540000605
gc 0
Train Epoch45 Acc 0.9727 (38908/40000), AUC 0.9957050681114197
ep45_train_time 65.55551623599968
Test Epoch45 layer0 Acc 0.7754, AUC 0.8539278507232666, avg_entr 0.13443948328495026, f1 0.775399923324585
ep45_l0_test_time 0.6257017369998721
Test Epoch45 layer1 Acc 0.789, AUC 0.8466609716415405, avg_entr 0.04181646555662155, f1 0.7889999747276306
ep45_l1_test_time 0.8222213660001216
Test Epoch45 layer2 Acc 0.7862, AUC 0.8620187044143677, avg_entr 0.035234235227108, f1 0.7861999869346619
ep45_l2_test_time 1.1406719339997835
Test Epoch45 layer3 Acc 0.7864, AUC 0.8662671446800232, avg_entr 0.032590366899967194, f1 0.7864000201225281
ep45_l3_test_time 1.624796759000219
Test Epoch45 layer4 Acc 0.7864, AUC 0.8673791885375977, avg_entr 0.03250747174024582, f1 0.7864000201225281
ep45_l4_test_time 2.2571486449996883
gc 0
Train Epoch46 Acc 0.973025 (38921/40000), AUC 0.9959303140640259
ep46_train_time 65.54132022700014
Test Epoch46 layer0 Acc 0.775, AUC 0.8536777496337891, avg_entr 0.13422855734825134, f1 0.7749999761581421
ep46_l0_test_time 0.6286102789999859
Test Epoch46 layer1 Acc 0.788, AUC 0.8465962409973145, avg_entr 0.04194461554288864, f1 0.7879999876022339
ep46_l1_test_time 0.8197808359996088
Test Epoch46 layer2 Acc 0.7858, AUC 0.8619222640991211, avg_entr 0.03506268560886383, f1 0.7857999801635742
ep46_l2_test_time 1.1424713699998392
Test Epoch46 layer3 Acc 0.7856, AUC 0.8662409782409668, avg_entr 0.03228969871997833, f1 0.7856000065803528
ep46_l3_test_time 1.6280838120001135
Test Epoch46 layer4 Acc 0.7866, AUC 0.8673397302627563, avg_entr 0.03215422108769417, f1 0.7865999937057495
ep46_l4_test_time 2.2620565839997653
gc 0
Train Epoch47 Acc 0.972625 (38905/40000), AUC 0.9954315423965454
ep47_train_time 65.56442466699991
Test Epoch47 layer0 Acc 0.775, AUC 0.8536808490753174, avg_entr 0.13403154909610748, f1 0.7749999761581421
ep47_l0_test_time 0.6260879280002882
Test Epoch47 layer1 Acc 0.7874, AUC 0.8464453816413879, avg_entr 0.04164954274892807, f1 0.7874000072479248
ep47_l1_test_time 0.8228336789998139
Test Epoch47 layer2 Acc 0.7876, AUC 0.8620171546936035, avg_entr 0.0345112569630146, f1 0.7875999212265015
ep47_l2_test_time 1.141675010000199
Test Epoch47 layer3 Acc 0.7868, AUC 0.8662979602813721, avg_entr 0.03176316246390343, f1 0.786799967288971
ep47_l3_test_time 1.624754228999791
Test Epoch47 layer4 Acc 0.7864, AUC 0.8674047589302063, avg_entr 0.0317455492913723, f1 0.7864000201225281
ep47_l4_test_time 2.2617261299997153
gc 0
Train Epoch48 Acc 0.97265 (38906/40000), AUC 0.9957653284072876
ep48_train_time 65.57150676099991
Test Epoch48 layer0 Acc 0.7768, AUC 0.8538269996643066, avg_entr 0.1346985250711441, f1 0.7768000364303589
ep48_l0_test_time 0.6273943040000631
Test Epoch48 layer1 Acc 0.7896, AUC 0.8465206623077393, avg_entr 0.042210258543491364, f1 0.7896000146865845
ep48_l1_test_time 0.8212867540000843
Test Epoch48 layer2 Acc 0.786, AUC 0.8619785904884338, avg_entr 0.03565549477934837, f1 0.7860000133514404
ep48_l2_test_time 1.1432578009998906
Test Epoch48 layer3 Acc 0.787, AUC 0.8662793636322021, avg_entr 0.033148881047964096, f1 0.7870000600814819
ep48_l3_test_time 1.623964235999665
Test Epoch48 layer4 Acc 0.7868, AUC 0.8673508167266846, avg_entr 0.03303370624780655, f1 0.786799967288971
ep48_l4_test_time 2.256960311000057
gc 0
Train Epoch49 Acc 0.972775 (38911/40000), AUC 0.9956774711608887
ep49_train_time 65.58841186300015
Test Epoch49 layer0 Acc 0.7752, AUC 0.8537688255310059, avg_entr 0.13442236185073853, f1 0.7752000093460083
ep49_l0_test_time 0.6382394089996524
Test Epoch49 layer1 Acc 0.7882, AUC 0.8468030691146851, avg_entr 0.04177951067686081, f1 0.7882000207901001
ep49_l1_test_time 0.8208761119999508
Test Epoch49 layer2 Acc 0.7874, AUC 0.8621886968612671, avg_entr 0.035035859793424606, f1 0.7874000072479248
ep49_l2_test_time 1.1429112499999974
Test Epoch49 layer3 Acc 0.7872, AUC 0.8664467334747314, avg_entr 0.03251001983880997, f1 0.7871999740600586
ep49_l3_test_time 1.6224491510001826
Test Epoch49 layer4 Acc 0.7876, AUC 0.8675409555435181, avg_entr 0.03249043598771095, f1 0.7875999212265015
ep49_l4_test_time 2.2582833410001513
Best AUC tensor(0.8208) 16 2
train_as_loss [[8.44108759e+01 5.79450655e+01 5.17717684e+01 5.03358138e+01
  4.98240664e+01 4.95876158e+01 4.94597203e+01 4.93829690e+01
  4.93333827e+01 4.92995508e+01 4.92754672e+01 4.92577404e+01
  4.92443320e+01 4.92339600e+01 4.92257839e+01 4.92192356e+01
  4.92139166e+01 4.92095456e+01 4.92059154e+01 4.92035581e+01
  4.92021152e+01 4.92007426e+01 4.91994401e+01 4.91985023e+01
  4.91978820e+01 4.91972582e+01 4.91966322e+01 4.91961600e+01
  4.91958357e+01 4.91954998e+01 4.91951562e+01 4.91948879e+01
  4.91947002e+01 4.91945032e+01 4.91942973e+01 4.91941324e+01
  4.91940196e+01 4.91939008e+01 4.91937696e+01 4.91936665e+01
  4.91935928e+01 4.91935156e+01 4.91934305e+01 4.91933666e+01
  4.91933263e+01 4.91932673e+01 4.91932147e+01 4.91931795e+01
  4.91931460e+01 4.91931071e+01]
 [2.19154217e+00 2.67072313e-04 1.58543166e-05 4.33119433e-06
  1.62602580e-06 7.78907911e-07 4.17132034e-07 2.45701200e-07
  1.48456081e-07 9.52473856e-08 6.42025632e-08 4.34158261e-08
  3.31272519e-08 2.29918104e-08 1.75862932e-08 1.29023647e-08
  2.01693751e-07 3.77569270e-07 2.64988197e-08 5.93080296e-09
  4.39544277e-09 3.88842990e-09 1.31190437e-08 3.28045665e-09
  2.66478471e-09 2.48905431e-09 9.50469999e-09 2.27189961e-09
  2.08382060e-09 1.98552102e-09 7.61650686e-09 1.85876145e-09
  1.70193102e-09 1.75206526e-09 6.68450809e-09 1.63963779e-09
  1.52248442e-09 1.52371362e-09 5.79985955e-09 1.50130512e-09
  1.40296642e-09 1.39978194e-09 5.28217869e-09 1.48530050e-09
  1.31927273e-09 1.29871431e-09 4.76934278e-09 1.56924678e-09
  1.29363248e-09 1.25680018e-09]
 [2.65577159e+00 3.62089598e-04 1.64310615e-05 4.51327760e-06
  1.63080512e-06 8.02949791e-07 4.39994037e-07 2.62487337e-07
  1.62344346e-07 1.02744599e-07 7.16998250e-08 4.71247271e-08
  3.93988291e-08 2.63120831e-08 2.13352023e-08 1.53261948e-08
  3.27797875e-07 6.33554094e-07 3.03938294e-08 8.61031431e-09
  4.94754812e-09 4.12103392e-09 1.22661303e-08 4.01682887e-09
  2.50070999e-09 2.27464877e-09 8.50656392e-09 2.41840714e-09
  1.89221498e-09 1.76735534e-09 6.50586994e-09 1.76672471e-09
  1.42206124e-09 1.55271236e-09 5.60798461e-09 1.48827551e-09
  1.26210693e-09 1.28308371e-09 4.71508537e-09 1.32588919e-09
  1.16163319e-09 1.15824789e-09 4.29495466e-09 1.29229257e-09
  1.11515183e-09 1.09476634e-09 3.93815246e-09 1.41453951e-09
  1.11626897e-09 1.09147022e-09]
 [2.15107612e+00 3.40555905e-04 1.42202764e-05 4.17400736e-06
  1.42270630e-06 7.50289335e-07 4.30783201e-07 2.58184067e-07
  1.80805587e-07 1.06263035e-07 8.45269227e-08 5.38910987e-08
  5.59156684e-08 3.71245666e-08 3.43575714e-08 2.58571950e-08
  3.04761612e-07 5.94465292e-07 4.61983704e-08 1.81030840e-08
  7.54595417e-09 5.74560283e-09 1.16899264e-08 6.21789078e-09
  2.42160220e-09 2.07338746e-09 7.28067171e-09 3.03121373e-09
  1.76787581e-09 1.51829061e-09 4.90466012e-09 1.77015331e-09
  1.03787504e-09 1.30142752e-09 4.08757306e-09 1.30215877e-09
  9.41682047e-10 9.58786647e-10 3.25406744e-09 1.01370378e-09
  8.32621273e-10 8.10143115e-10 2.88344362e-09 1.01188271e-09
  7.83219899e-10 7.64282221e-10 2.64645130e-09 1.09419516e-09
  8.19518287e-10 7.76979198e-10]
 [1.91180257e+00 8.94742779e-04 1.91178814e-05 6.29599351e-06
  2.18648358e-06 1.20789864e-06 7.52279994e-07 4.49309650e-07
  3.55689525e-07 1.97282525e-07 1.66538709e-07 1.06333325e-07
  1.40432911e-07 9.20633397e-08 9.44054550e-08 7.47357649e-08
  2.97662826e-07 5.62478497e-07 1.11671421e-07 5.07647731e-08
  1.90275241e-08 1.55246601e-08 2.11912073e-08 1.37838396e-08
  4.33317052e-09 3.56504347e-09 1.12768901e-08 5.71248812e-09
  2.91211935e-09 2.36208527e-09 6.85110911e-09 2.76614507e-09
  1.45394437e-09 1.90317392e-09 5.55969214e-09 1.89830436e-09
  1.28201277e-09 1.32989268e-09 4.27031346e-09 1.42818775e-09
  1.11367916e-09 1.08432721e-09 3.72578487e-09 1.39469106e-09
  1.01946520e-09 1.01957506e-09 3.36438047e-09 1.52989757e-09
  1.08309599e-09 1.03220007e-09]]
train_ae_loss [[4.27864819 3.18333973 3.95107198 4.29208417 4.56766449 4.68638438
  4.79433827 4.93297146 4.86846991 4.96872025 4.94526664 4.96176584
  4.87691554 4.73146164 4.65218732 4.5217715  4.44042735 4.22416415
  4.05494635 3.67887215 3.50818559 3.44723312 3.32071878 3.09089892
  3.02721692 2.95372257 2.91896528 2.81042314 2.7729095  2.74950142
  2.73193824 2.66271103 2.64817046 2.65175386 2.63560721 2.61150204
  2.61906516 2.58592549 2.58059635 2.57498265 2.588582   2.58962962
  2.58791486 2.56596755 2.56066945 2.57084888 2.56748478 2.55699185
  2.57172588 2.56062435]
 [4.41222449 3.49754485 4.17112477 4.31850675 4.48969902 4.50323916
  4.51607151 4.64279842 4.3882461  4.44609446 4.33400619 4.30711332
  4.12375953 3.88302259 3.74195076 3.55133265 3.43134942 3.1318678
  2.77148191 2.41506143 2.22207355 2.13081517 1.92213874 1.69105769
  1.6292378  1.55362481 1.48499511 1.37390427 1.34214227 1.31862791
  1.26629115 1.21065389 1.20631201 1.202614   1.18362376 1.15569179
  1.16159818 1.13189922 1.09813225 1.11022917 1.12304489 1.10966848
  1.12771407 1.09290065 1.08300292 1.08433191 1.10301744 1.08922
  1.09350774 1.10307256]
 [3.82643157 3.35811923 4.62281124 4.54069481 4.62839684 4.5710499
  4.50769089 4.65326005 4.28456462 4.37103557 4.24302687 4.23457165
  4.03232921 3.78220187 3.62843049 3.43358358 3.32999667 2.99615524
  2.62693831 2.28250102 2.08630038 2.00492337 1.78884488 1.55748034
  1.50144799 1.42986576 1.35545757 1.24163011 1.21261167 1.19251295
  1.14233319 1.08482992 1.08276889 1.0748147  1.05761522 1.02785009
  1.03699383 1.00692425 0.9694011  0.98802058 0.99425544 0.97815901
  1.00354032 0.9652744  0.95681671 0.95944131 0.97203155 0.96764749
  0.9654643  0.98287221]
 [4.15867455 3.17598985 4.65600718 4.64318112 4.55774185 4.43811085
  4.36000361 4.5240766  4.10818372 4.19361114 4.06837367 4.0629409
  3.86357453 3.61586282 3.46453132 3.28037534 3.19029284 2.85545366
  2.48875077 2.16543053 1.97957079 1.90567819 1.69109819 1.47193545
  1.41923331 1.35166495 1.27785014 1.16804968 1.14311991 1.12449005
  1.07450537 1.01996171 1.01788652 1.00865002 0.99509973 0.96512461
  0.97400652 0.94673944 0.9076341  0.92746875 0.93338307 0.91590321
  0.94358876 0.9058778  0.89771473 0.90214974 0.91089623 0.90822088
  0.904767   0.92172293]
 [4.44126309 2.94673722 4.3914023  4.80315879 4.42703301 4.2202796
  4.0976287  4.28910969 3.8231368  3.90618852 3.78361576 3.77779554
  3.58449784 3.34732487 3.19936143 3.03092666 2.95480197 2.63007873
  2.28041381 1.98548768 1.81473216 1.74929662 1.54877404 1.34713709
  1.30096904 1.23849625 1.16837868 1.06744829 1.04488797 1.02743506
  0.98139473 0.93197884 0.92986221 0.9214098  0.90862011 0.8810016
  0.88871838 0.86444535 0.82829659 0.8464775  0.85188564 0.83647966
  0.86080722 0.82655171 0.8188439  0.82307424 0.83098679 0.82854586
  0.82550359 0.84143908]]
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
total_train+valid_time 3610.5871552549997
Start Testing
Load ckpt at ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt
gc 9
Test layer0 Acc 0.7934, AUC 0.8711282014846802, avg_entr 0.17343375086784363, f1 0.79339998960495
l0_test_time 0.6319104389999666
gc 0
Test layer1 Acc 0.8002, AUC 0.8875123262405396, avg_entr 0.09602710604667664, f1 0.8001999855041504
l1_test_time 0.8287396539999463
gc 0
Test layer2 Acc 0.7998, AUC 0.8898761868476868, avg_entr 0.08018525689840317, f1 0.7997999787330627
l2_test_time 1.145547605000047
gc 0
Test layer3 Acc 0.7996, AUC 0.8901517391204834, avg_entr 0.079751156270504, f1 0.7996000051498413
l3_test_time 1.626196555000206
gc 0
Test layer4 Acc 0.7998, AUC 0.8898404836654663, avg_entr 0.0776013508439064, f1 0.7997999787330627
l4_test_time 2.2589965850002045
gc 0
Test threshold 0.1 Acc 0.7994, AUC 0.8782809972763062, avg_entr 0.11960291862487793, f1 0.7993999123573303
t0.1_test_time 1.0910285909999402
gc 0
Test threshold 0.2 Acc 0.7988, AUC 0.87919020652771, avg_entr 0.1295054852962494, f1 0.798799991607666
t0.2_test_time 1.002244607999728
gc 0
Test threshold 0.3 Acc 0.7994, AUC 0.8780103921890259, avg_entr 0.13789613544940948, f1 0.7993999123573303
t0.3_test_time 0.9438539719999426
gc 0
Test threshold 0.4 Acc 0.7992, AUC 0.8775554895401001, avg_entr 0.14763271808624268, f1 0.7991999983787537
t0.4_test_time 0.8891078340002423
gc 0
Test threshold 0.5 Acc 0.7996, AUC 0.8772232532501221, avg_entr 0.1556171327829361, f1 0.7996000051498413
t0.5_test_time 0.8461417499997879
gc 0
Test threshold 0.6 Acc 0.799, AUC 0.8770307302474976, avg_entr 0.1644362360239029, f1 0.7990000247955322
t0.6_test_time 0.8114351059998626
gc 0
Test threshold 0.7 Acc 0.7982, AUC 0.8753699064254761, avg_entr 0.17645280063152313, f1 0.7982000708580017
t0.7_test_time 0.7713989060002859
gc 0
Test threshold 0.8 Acc 0.7968, AUC 0.8735367059707642, avg_entr 0.19059933722019196, f1 0.7968000173568726
t0.8_test_time 0.7401642400000128
gc 0
Test threshold 0.9 Acc 0.7954, AUC 0.8709326982498169, avg_entr 0.20871075987815857, f1 0.795400083065033
t0.9_test_time 0.708771496999816
