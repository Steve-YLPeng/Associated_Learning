total count words 222751
vocab size 30000
train size 40000, valid size 5000, test size 5000
found 27937 words in glove
model: TransformerALsideText(
  (layers): ModuleList(
    (0): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=2, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=2, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
  (emb_layers): ModuleList(
    (0): Embedding(30000, 300)
    (1): Embedding(30000, 300)
    (2): Embedding(30000, 300)
    (3): Embedding(30000, 300)
    (4): Embedding(30000, 300)
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.multi_headed_attention.linears.0.weight 90000
layers.0.enc.f.multi_headed_attention.linears.0.bias 300
layers.0.enc.f.multi_headed_attention.linears.1.weight 90000
layers.0.enc.f.multi_headed_attention.linears.1.bias 300
layers.0.enc.f.multi_headed_attention.linears.2.weight 90000
layers.0.enc.f.multi_headed_attention.linears.2.bias 300
layers.0.enc.f.multi_headed_attention.linears.3.weight 90000
layers.0.enc.f.multi_headed_attention.linears.3.bias 300
layers.0.enc.f.feed_forward.w_1.weight 90000
layers.0.enc.f.feed_forward.w_1.bias 300
layers.0.enc.f.feed_forward.w_2.weight 90000
layers.0.enc.f.feed_forward.w_2.bias 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.0.enc.f.encoder.norm.a 300
layers.0.enc.f.encoder.norm.b 300
layers.0.ae.g.0.weight 256
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 256
layers.0.ae.h.0.bias 2
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
emb_layers.0.weight 9000000
emb_layers.1.weight 9000000
emb_layers.2.weight 9000000
emb_layers.3.weight 9000000
emb_layers.4.weight 9000000
Total Trainable Params: 50758378
init_time 20.934534355
Start Training
gc 0
Train Epoch0 Acc 0.50165 (20066/40000), AUC 0.5007637143135071
ep0_train_time 65.948282968
Test Epoch0 layer0 Acc 0.5864, AUC 0.6228693723678589, avg_entr 0.6929706931114197, f1 0.5863999724388123
ep0_l0_test_time 0.6263541779999997
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 0
Test Epoch0 layer1 Acc 0.5192, AUC 0.5692307353019714, avg_entr 0.6907985210418701, f1 0.5192000269889832
ep0_l1_test_time 0.8300177210000044
Test Epoch0 layer2 Acc 0.5062, AUC 0.5448563694953918, avg_entr 0.6926702260971069, f1 0.5062000155448914
ep0_l2_test_time 1.1440228910000059
Test Epoch0 layer3 Acc 0.498, AUC 0.501682460308075, avg_entr 0.6948793530464172, f1 0.49799999594688416
ep0_l3_test_time 1.626747691999995
Test Epoch0 layer4 Acc 0.5, AUC 0.4964926242828369, avg_entr 0.6891544461250305, f1 0.5
ep0_l4_test_time 2.265054714999991
gc 0
Train Epoch1 Acc 0.510025 (20401/40000), AUC 0.5139859318733215
ep1_train_time 65.75014094299999
Test Epoch1 layer0 Acc 0.6828, AUC 0.7595693469047546, avg_entr 0.5941962599754333, f1 0.6827999949455261
ep1_l0_test_time 0.6276513220000197
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 1
Test Epoch1 layer1 Acc 0.6682, AUC 0.7484655380249023, avg_entr 0.6349818110466003, f1 0.6682000160217285
ep1_l1_test_time 0.82902378
Test Epoch1 layer2 Acc 0.607, AUC 0.7171474099159241, avg_entr 0.6913080215454102, f1 0.6069999933242798
ep1_l2_test_time 1.1408711759999903
Test Epoch1 layer3 Acc 0.5914, AUC 0.6792579889297485, avg_entr 0.6927114129066467, f1 0.5914000272750854
ep1_l3_test_time 1.623626994999995
Test Epoch1 layer4 Acc 0.5006, AUC 0.5851531028747559, avg_entr 0.6837947964668274, f1 0.5005999803543091
ep1_l4_test_time 2.2573563440000157
gc 0
Train Epoch2 Acc 0.5505 (22020/40000), AUC 0.5754508972167969
ep2_train_time 65.626322623
Test Epoch2 layer0 Acc 0.6962, AUC 0.8161414861679077, avg_entr 0.4224739670753479, f1 0.6962000131607056
ep2_l0_test_time 0.6335440070000118
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 2
Test Epoch2 layer1 Acc 0.672, AUC 0.8241328001022339, avg_entr 0.3841429650783539, f1 0.671999990940094
ep2_l1_test_time 0.836894022999985
Test Epoch2 layer2 Acc 0.6326, AUC 0.8205840587615967, avg_entr 0.36953404545783997, f1 0.6326000094413757
ep2_l2_test_time 1.1540148130000034
Test Epoch2 layer3 Acc 0.5346, AUC 0.818265974521637, avg_entr 0.26959747076034546, f1 0.534600019454956
ep2_l3_test_time 1.6359369889999869
Test Epoch2 layer4 Acc 0.5006, AUC 0.8199462890625, avg_entr 0.4895654320716858, f1 0.5005999803543091
ep2_l4_test_time 2.2714114300000006
gc 0
Train Epoch3 Acc 0.635625 (25425/40000), AUC 0.684892475605011
ep3_train_time 65.73572814200003
Test Epoch3 layer0 Acc 0.7494, AUC 0.8355836868286133, avg_entr 0.40370941162109375, f1 0.7494000196456909
ep3_l0_test_time 0.62992118599999
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer1 Acc 0.7514, AUC 0.8464838266372681, avg_entr 0.40983033180236816, f1 0.7513999938964844
ep3_l1_test_time 0.8264618530000121
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer2 Acc 0.7524, AUC 0.846503496170044, avg_entr 0.44173821806907654, f1 0.7523999810218811
ep3_l2_test_time 1.1480314890000045
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer3 Acc 0.7556, AUC 0.8460862636566162, avg_entr 0.4877387583255768, f1 0.7555999755859375
ep3_l3_test_time 1.6308884419999572
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer4 Acc 0.7632, AUC 0.8460692167282104, avg_entr 0.5484809279441833, f1 0.7631999850273132
ep3_l4_test_time 2.2682305080000447
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.735025 (29401/40000), AUC 0.8134980797767639
ep4_train_time 65.69068985299998
Test Epoch4 layer0 Acc 0.7254, AUC 0.8499089479446411, avg_entr 0.318342000246048, f1 0.7253999710083008
ep4_l0_test_time 0.6259124160000056
Test Epoch4 layer1 Acc 0.694, AUC 0.8594617247581482, avg_entr 0.2604805529117584, f1 0.6940000057220459
ep4_l1_test_time 0.8207898449999789
Test Epoch4 layer2 Acc 0.6682, AUC 0.8600024580955505, avg_entr 0.2314731925725937, f1 0.6682000160217285
ep4_l2_test_time 1.1431530099999918
Test Epoch4 layer3 Acc 0.6362, AUC 0.8598067760467529, avg_entr 0.21026918292045593, f1 0.6362000107765198
ep4_l3_test_time 1.6266572840000322
Test Epoch4 layer4 Acc 0.6212, AUC 0.8592566251754761, avg_entr 0.2012886255979538, f1 0.6212000250816345
ep4_l4_test_time 2.2633249209999917
gc 0
Train Epoch5 Acc 0.76465 (30586/40000), AUC 0.8461675047874451
ep5_train_time 65.62945792400001
Test Epoch5 layer0 Acc 0.7776, AUC 0.8569650650024414, avg_entr 0.33701571822166443, f1 0.7775999903678894
ep5_l0_test_time 0.6281073399999855
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 5
Test Epoch5 layer1 Acc 0.7736, AUC 0.8666837215423584, avg_entr 0.3206239342689514, f1 0.7735999822616577
ep5_l1_test_time 0.8375610530000017
Test Epoch5 layer2 Acc 0.7646, AUC 0.8670302033424377, avg_entr 0.32554906606674194, f1 0.7645999789237976
ep5_l2_test_time 1.1451044730000035
Test Epoch5 layer3 Acc 0.752, AUC 0.8667296767234802, avg_entr 0.3254331946372986, f1 0.7519999742507935
ep5_l3_test_time 1.6274755530000107
Test Epoch5 layer4 Acc 0.741, AUC 0.8667098879814148, avg_entr 0.3359314203262329, f1 0.7409999370574951
ep5_l4_test_time 2.264491841999984
gc 0
Train Epoch6 Acc 0.781775 (31271/40000), AUC 0.8632638454437256
ep6_train_time 65.66331495399993
Test Epoch6 layer0 Acc 0.7786, AUC 0.8641669750213623, avg_entr 0.2919437885284424, f1 0.7785999774932861
ep6_l0_test_time 0.6303938060000291
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer1 Acc 0.7942, AUC 0.8775241374969482, avg_entr 0.26940399408340454, f1 0.7942000031471252
ep6_l1_test_time 0.8338123279999081
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer2 Acc 0.7938, AUC 0.8789212703704834, avg_entr 0.2617923617362976, f1 0.7937999963760376
ep6_l2_test_time 1.1490882870000405
Test Epoch6 layer3 Acc 0.7982, AUC 0.8796447515487671, avg_entr 0.262455552816391, f1 0.7982000708580017
ep6_l3_test_time 1.624538432999998
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer4 Acc 0.7994, AUC 0.8797885775566101, avg_entr 0.2638075351715088, f1 0.7993999123573303
ep6_l4_test_time 2.270520198999975
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
gc 0
Train Epoch7 Acc 0.79505 (31802/40000), AUC 0.8768250346183777
ep7_train_time 65.60149444800004
Test Epoch7 layer0 Acc 0.7612, AUC 0.868962287902832, avg_entr 0.251225084066391, f1 0.7612000107765198
ep7_l0_test_time 0.6294558549999465
Test Epoch7 layer1 Acc 0.752, AUC 0.882379949092865, avg_entr 0.2010759711265564, f1 0.7519999742507935
ep7_l1_test_time 0.8189100710000048
Test Epoch7 layer2 Acc 0.7462, AUC 0.8839830756187439, avg_entr 0.16631917655467987, f1 0.7462000250816345
ep7_l2_test_time 1.1426926119999052
Test Epoch7 layer3 Acc 0.741, AUC 0.8842339515686035, avg_entr 0.15548546612262726, f1 0.7409999370574951
ep7_l3_test_time 1.6273461009999437
Test Epoch7 layer4 Acc 0.7354, AUC 0.8842732906341553, avg_entr 0.15040795505046844, f1 0.7354000210762024
ep7_l4_test_time 2.266296050000051
gc 0
Train Epoch8 Acc 0.814275 (32571/40000), AUC 0.8922135829925537
ep8_train_time 65.63565570899993
Test Epoch8 layer0 Acc 0.7812, AUC 0.870741069316864, avg_entr 0.26569899916648865, f1 0.7811999917030334
ep8_l0_test_time 0.6280994910000572
Test Epoch8 layer1 Acc 0.795, AUC 0.8857043981552124, avg_entr 0.2159351110458374, f1 0.7950000166893005
ep8_l1_test_time 0.8213619130000325
Test Epoch8 layer2 Acc 0.7964, AUC 0.8877747058868408, avg_entr 0.18458108603954315, f1 0.7964000105857849
ep8_l2_test_time 1.1464880489999132
Test Epoch8 layer3 Acc 0.7986, AUC 0.8876994848251343, avg_entr 0.19088239967823029, f1 0.7986000180244446
ep8_l3_test_time 1.6313616400000228
Test Epoch8 layer4 Acc 0.799, AUC 0.8878173828125, avg_entr 0.1944565623998642, f1 0.7990000247955322
ep8_l4_test_time 2.2634987879999926
gc 0
Train Epoch9 Acc 0.828325 (33133/40000), AUC 0.9065543413162231
ep9_train_time 65.75137603600001
Test Epoch9 layer0 Acc 0.7984, AUC 0.8773042559623718, avg_entr 0.2402326911687851, f1 0.7983999848365784
ep9_l0_test_time 0.6318905389999827
Test Epoch9 layer1 Acc 0.8136, AUC 0.8926620483398438, avg_entr 0.1616721898317337, f1 0.8136000037193298
ep9_l1_test_time 0.8271489590000556
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 9
Test Epoch9 layer2 Acc 0.813, AUC 0.894758939743042, avg_entr 0.1498708873987198, f1 0.8130000233650208
ep9_l2_test_time 1.1539750299999696
Test Epoch9 layer3 Acc 0.8142, AUC 0.8949423432350159, avg_entr 0.14936037361621857, f1 0.8141999840736389
ep9_l3_test_time 1.6251438079999616
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 9
Test Epoch9 layer4 Acc 0.813, AUC 0.8950859308242798, avg_entr 0.15316054224967957, f1 0.8130000233650208
ep9_l4_test_time 2.265508974999989
gc 0
Train Epoch10 Acc 0.832575 (33303/40000), AUC 0.9075394868850708
ep10_train_time 65.605674195
Test Epoch10 layer0 Acc 0.7752, AUC 0.8797324895858765, avg_entr 0.2297777533531189, f1 0.7752000093460083
ep10_l0_test_time 0.629303223000079
Test Epoch10 layer1 Acc 0.7856, AUC 0.8940600156784058, avg_entr 0.15602539479732513, f1 0.7856000065803528
ep10_l1_test_time 0.8254997239999966
Test Epoch10 layer2 Acc 0.7834, AUC 0.8955774903297424, avg_entr 0.1429336816072464, f1 0.7833999395370483
ep10_l2_test_time 1.1441974069999787
Test Epoch10 layer3 Acc 0.7822, AUC 0.8961887955665588, avg_entr 0.1413416713476181, f1 0.7821999788284302
ep10_l3_test_time 1.629568010000071
Test Epoch10 layer4 Acc 0.7822, AUC 0.8962682485580444, avg_entr 0.13805365562438965, f1 0.7821999788284302
ep10_l4_test_time 2.264421342999981
gc 0
Train Epoch11 Acc 0.845575 (33823/40000), AUC 0.9211423397064209
ep11_train_time 65.74335083400001
Test Epoch11 layer0 Acc 0.7976, AUC 0.8785080909729004, avg_entr 0.20992755889892578, f1 0.7976000308990479
ep11_l0_test_time 0.6293578480000406
Test Epoch11 layer1 Acc 0.8114, AUC 0.8922778964042664, avg_entr 0.13346299529075623, f1 0.8113999962806702
ep11_l1_test_time 0.8345797989999255
Test Epoch11 layer2 Acc 0.8118, AUC 0.8937849998474121, avg_entr 0.11940274387598038, f1 0.8118000030517578
ep11_l2_test_time 1.1469022859999995
Test Epoch11 layer3 Acc 0.8102, AUC 0.894097089767456, avg_entr 0.11754690110683441, f1 0.8101999759674072
ep11_l3_test_time 1.6284432480000532
Test Epoch11 layer4 Acc 0.8074, AUC 0.894302248954773, avg_entr 0.11731463670730591, f1 0.8073999881744385
ep11_l4_test_time 2.265065261000018
gc 0
Train Epoch12 Acc 0.8586 (34344/40000), AUC 0.9317560195922852
ep12_train_time 65.68451377999997
Test Epoch12 layer0 Acc 0.7946, AUC 0.8791832327842712, avg_entr 0.20740532875061035, f1 0.7946000695228577
ep12_l0_test_time 0.6320907140000145
Test Epoch12 layer1 Acc 0.8138, AUC 0.8923401236534119, avg_entr 0.13674625754356384, f1 0.8137999773025513
ep12_l1_test_time 0.822133258000008
Test Epoch12 layer2 Acc 0.8152, AUC 0.8956142067909241, avg_entr 0.11965290457010269, f1 0.8152000308036804
ep12_l2_test_time 1.1472393599999577
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 12
Test Epoch12 layer3 Acc 0.8148, AUC 0.8958128690719604, avg_entr 0.11965429782867432, f1 0.8148000240325928
ep12_l3_test_time 1.6301072630000135
Test Epoch12 layer4 Acc 0.8156, AUC 0.8959943056106567, avg_entr 0.11903742700815201, f1 0.8155999779701233
ep12_l4_test_time 2.254079843999989
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 12
gc 0
Train Epoch13 Acc 0.8661 (34644/40000), AUC 0.9350623488426208
ep13_train_time 65.52784174399994
Test Epoch13 layer0 Acc 0.793, AUC 0.8785686492919922, avg_entr 0.1885722279548645, f1 0.7929999828338623
ep13_l0_test_time 0.6283614689998558
Test Epoch13 layer1 Acc 0.796, AUC 0.8914812207221985, avg_entr 0.11882621049880981, f1 0.796000063419342
ep13_l1_test_time 0.8185720160001893
Test Epoch13 layer2 Acc 0.7954, AUC 0.8943778872489929, avg_entr 0.10446830093860626, f1 0.795400083065033
ep13_l2_test_time 1.1419791579999128
Test Epoch13 layer3 Acc 0.7956, AUC 0.8939683437347412, avg_entr 0.10548888146877289, f1 0.7955999970436096
ep13_l3_test_time 1.6236050150000665
Test Epoch13 layer4 Acc 0.795, AUC 0.8939666748046875, avg_entr 0.10425695776939392, f1 0.7950000166893005
ep13_l4_test_time 2.2585167830000046
gc 0
Train Epoch14 Acc 0.872075 (34883/40000), AUC 0.9415951371192932
ep14_train_time 65.52913955100007
Test Epoch14 layer0 Acc 0.8046, AUC 0.8816800117492676, avg_entr 0.18474936485290527, f1 0.8046000599861145
ep14_l0_test_time 0.625348841999994
Test Epoch14 layer1 Acc 0.8154, AUC 0.894692063331604, avg_entr 0.10812540352344513, f1 0.8154000043869019
ep14_l1_test_time 0.8215510159998303
Test Epoch14 layer2 Acc 0.8152, AUC 0.8969012498855591, avg_entr 0.09563727676868439, f1 0.8152000308036804
ep14_l2_test_time 1.1451651150000544
Test Epoch14 layer3 Acc 0.8158, AUC 0.8970910310745239, avg_entr 0.09503256529569626, f1 0.8158000111579895
ep14_l3_test_time 1.6251267560000997
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 14
Test Epoch14 layer4 Acc 0.8154, AUC 0.8972159624099731, avg_entr 0.09521006792783737, f1 0.8154000043869019
ep14_l4_test_time 2.2640682270000525
gc 0
Train Epoch15 Acc 0.880325 (35213/40000), AUC 0.9449660778045654
ep15_train_time 65.7401784990002
Test Epoch15 layer0 Acc 0.7936, AUC 0.8809616565704346, avg_entr 0.1775164008140564, f1 0.7936000227928162
ep15_l0_test_time 0.624549567000031
Test Epoch15 layer1 Acc 0.7946, AUC 0.8939980268478394, avg_entr 0.09446322172880173, f1 0.7946000695228577
ep15_l1_test_time 0.8185144470000978
Test Epoch15 layer2 Acc 0.793, AUC 0.8968725800514221, avg_entr 0.08219170570373535, f1 0.7929999828338623
ep15_l2_test_time 1.1450960969998505
Test Epoch15 layer3 Acc 0.7924, AUC 0.8961895704269409, avg_entr 0.08048854768276215, f1 0.7923999428749084
ep15_l3_test_time 1.634484268000051
Test Epoch15 layer4 Acc 0.7874, AUC 0.8963813781738281, avg_entr 0.07772859185934067, f1 0.7874000072479248
ep15_l4_test_time 2.2606899740001154
gc 0
Train Epoch16 Acc 0.883 (35320/40000), AUC 0.9471621513366699
ep16_train_time 65.6765336410001
Test Epoch16 layer0 Acc 0.7716, AUC 0.8783332109451294, avg_entr 0.18469387292861938, f1 0.771600067615509
ep16_l0_test_time 0.629794942999979
Test Epoch16 layer1 Acc 0.7694, AUC 0.8894041776657104, avg_entr 0.10294710844755173, f1 0.7694000005722046
ep16_l1_test_time 0.8190545279999242
Test Epoch16 layer2 Acc 0.7616, AUC 0.8906723260879517, avg_entr 0.0907997339963913, f1 0.7616000771522522
ep16_l2_test_time 1.1422111680001308
Test Epoch16 layer3 Acc 0.7546, AUC 0.8914991617202759, avg_entr 0.09095372259616852, f1 0.7546000480651855
ep16_l3_test_time 1.6245270480001182
Test Epoch16 layer4 Acc 0.7542, AUC 0.8918901681900024, avg_entr 0.08982671052217484, f1 0.7541999816894531
ep16_l4_test_time 2.262468080999952
gc 0
Train Epoch17 Acc 0.892125 (35685/40000), AUC 0.9529080390930176
ep17_train_time 65.603523816
Test Epoch17 layer0 Acc 0.7708, AUC 0.877883791923523, avg_entr 0.18102265894412994, f1 0.7707999348640442
ep17_l0_test_time 0.6272253180000007
Test Epoch17 layer1 Acc 0.7808, AUC 0.8866530060768127, avg_entr 0.09864103049039841, f1 0.7808000445365906
ep17_l1_test_time 0.8212806970000202
Test Epoch17 layer2 Acc 0.7824, AUC 0.892006516456604, avg_entr 0.09239180386066437, f1 0.7824000120162964
ep17_l2_test_time 1.148468763999972
Test Epoch17 layer3 Acc 0.7796, AUC 0.8922401666641235, avg_entr 0.09231910109519958, f1 0.7796000838279724
ep17_l3_test_time 1.6253865930000302
Test Epoch17 layer4 Acc 0.778, AUC 0.8920899629592896, avg_entr 0.09288528561592102, f1 0.777999997138977
ep17_l4_test_time 2.261606077999886
gc 0
Train Epoch18 Acc 0.903875 (36155/40000), AUC 0.9627516865730286
ep18_train_time 65.79372215700005
Test Epoch18 layer0 Acc 0.7932, AUC 0.8757736682891846, avg_entr 0.15448838472366333, f1 0.7932000160217285
ep18_l0_test_time 0.6252173360001052
Test Epoch18 layer1 Acc 0.8104, AUC 0.8870217800140381, avg_entr 0.07650422304868698, f1 0.8104000091552734
ep18_l1_test_time 0.8194651220001106
Test Epoch18 layer2 Acc 0.8116, AUC 0.8929443359375, avg_entr 0.06598913669586182, f1 0.8116000294685364
ep18_l2_test_time 1.1427817040000718
Test Epoch18 layer3 Acc 0.8112, AUC 0.8929233551025391, avg_entr 0.06362348794937134, f1 0.8112000226974487
ep18_l3_test_time 1.6252657019999788
Test Epoch18 layer4 Acc 0.811, AUC 0.8933446407318115, avg_entr 0.0630287453532219, f1 0.8109999895095825
ep18_l4_test_time 2.2582038119999197
gc 0
Train Epoch19 Acc 0.9196 (36784/40000), AUC 0.9736649990081787
ep19_train_time 65.56370761700009
Test Epoch19 layer0 Acc 0.7972, AUC 0.8739991188049316, avg_entr 0.15482136607170105, f1 0.7971999645233154
ep19_l0_test_time 0.632060822000085
Test Epoch19 layer1 Acc 0.8062, AUC 0.8796231746673584, avg_entr 0.07034686952829361, f1 0.8062000274658203
ep19_l1_test_time 0.821490747000098
Test Epoch19 layer2 Acc 0.8076, AUC 0.8885537385940552, avg_entr 0.0621231384575367, f1 0.8076000213623047
ep19_l2_test_time 1.1443422019999616
Test Epoch19 layer3 Acc 0.8078, AUC 0.8886767625808716, avg_entr 0.06094292551279068, f1 0.8077999353408813
ep19_l3_test_time 1.6230476339999313
Test Epoch19 layer4 Acc 0.808, AUC 0.8890533447265625, avg_entr 0.06052279844880104, f1 0.8080000281333923
ep19_l4_test_time 2.2657636200001434
gc 0
Train Epoch20 Acc 0.927125 (37085/40000), AUC 0.9763360023498535
ep20_train_time 65.56167519700011
Test Epoch20 layer0 Acc 0.7896, AUC 0.8722450137138367, avg_entr 0.15779198706150055, f1 0.7896000146865845
ep20_l0_test_time 0.6272605730000578
Test Epoch20 layer1 Acc 0.803, AUC 0.8741597533226013, avg_entr 0.06743751466274261, f1 0.8029999732971191
ep20_l1_test_time 0.8217091520000395
Test Epoch20 layer2 Acc 0.805, AUC 0.8868268728256226, avg_entr 0.059043705463409424, f1 0.8050000667572021
ep20_l2_test_time 1.1411966829998619
Test Epoch20 layer3 Acc 0.805, AUC 0.8867719173431396, avg_entr 0.05683936923742294, f1 0.8050000667572021
ep20_l3_test_time 1.6299347549997947
Test Epoch20 layer4 Acc 0.805, AUC 0.8874564170837402, avg_entr 0.05579327419400215, f1 0.8050000667572021
ep20_l4_test_time 2.263922307999792
gc 0
Train Epoch21 Acc 0.932375 (37295/40000), AUC 0.9790807366371155
ep21_train_time 65.6870170919999
Test Epoch21 layer0 Acc 0.7896, AUC 0.8698936700820923, avg_entr 0.14467988908290863, f1 0.7896000146865845
ep21_l0_test_time 0.6265750579998439
Test Epoch21 layer1 Acc 0.7972, AUC 0.8724583387374878, avg_entr 0.06241956353187561, f1 0.7971999645233154
ep21_l1_test_time 0.8218256400000428
Test Epoch21 layer2 Acc 0.7998, AUC 0.8826848864555359, avg_entr 0.0531974658370018, f1 0.7997999787330627
ep21_l2_test_time 1.1432124100001602
Test Epoch21 layer3 Acc 0.7992, AUC 0.8827176690101624, avg_entr 0.05060327425599098, f1 0.7991999983787537
ep21_l3_test_time 1.624555841000074
Test Epoch21 layer4 Acc 0.8, AUC 0.8834048509597778, avg_entr 0.04976692795753479, f1 0.8000000715255737
ep21_l4_test_time 2.2590767409999444
gc 0
Train Epoch22 Acc 0.9364 (37456/40000), AUC 0.9808412194252014
ep22_train_time 65.70347441599984
Test Epoch22 layer0 Acc 0.7856, AUC 0.8690415024757385, avg_entr 0.14461246132850647, f1 0.7856000065803528
ep22_l0_test_time 0.6527015140000003
Test Epoch22 layer1 Acc 0.795, AUC 0.8702971935272217, avg_entr 0.05921953171491623, f1 0.7950000166893005
ep22_l1_test_time 0.8294835369999873
Test Epoch22 layer2 Acc 0.797, AUC 0.8836507797241211, avg_entr 0.05066336691379547, f1 0.796999990940094
ep22_l2_test_time 1.147987546000195
Test Epoch22 layer3 Acc 0.7968, AUC 0.8832191228866577, avg_entr 0.04964618757367134, f1 0.7968000173568726
ep22_l3_test_time 1.6257877640000515
Test Epoch22 layer4 Acc 0.7968, AUC 0.8844448924064636, avg_entr 0.04990098997950554, f1 0.7968000173568726
ep22_l4_test_time 2.2612151490000088
gc 0
Train Epoch23 Acc 0.942475 (37699/40000), AUC 0.9851060509681702
ep23_train_time 65.75547394800014
Test Epoch23 layer0 Acc 0.7902, AUC 0.8663501739501953, avg_entr 0.14914071559906006, f1 0.7901999950408936
ep23_l0_test_time 0.626918422000017
Test Epoch23 layer1 Acc 0.796, AUC 0.8716232776641846, avg_entr 0.06332861632108688, f1 0.796000063419342
ep23_l1_test_time 0.8219800609999766
Test Epoch23 layer2 Acc 0.7984, AUC 0.8809233903884888, avg_entr 0.05876299366354942, f1 0.7983999848365784
ep23_l2_test_time 1.1427834270000403
Test Epoch23 layer3 Acc 0.7988, AUC 0.8812112212181091, avg_entr 0.057219572365283966, f1 0.798799991607666
ep23_l3_test_time 1.6262329660000887
Test Epoch23 layer4 Acc 0.7984, AUC 0.8821679353713989, avg_entr 0.05681232735514641, f1 0.7983999848365784
ep23_l4_test_time 2.259379620000118
gc 0
Train Epoch24 Acc 0.945375 (37815/40000), AUC 0.98508220911026
ep24_train_time 65.55948421599987
Test Epoch24 layer0 Acc 0.7874, AUC 0.8664301037788391, avg_entr 0.14020338654518127, f1 0.7874000072479248
ep24_l0_test_time 0.6277154839999639
Test Epoch24 layer1 Acc 0.7942, AUC 0.8658269643783569, avg_entr 0.055612269788980484, f1 0.7942000031471252
ep24_l1_test_time 0.820084640999994
Test Epoch24 layer2 Acc 0.7954, AUC 0.8799965977668762, avg_entr 0.049521539360284805, f1 0.795400083065033
ep24_l2_test_time 1.1436246729999766
Test Epoch24 layer3 Acc 0.7974, AUC 0.8802386522293091, avg_entr 0.04742592200636864, f1 0.7973999977111816
ep24_l3_test_time 1.6329690289999235
Test Epoch24 layer4 Acc 0.798, AUC 0.8814656734466553, avg_entr 0.04671647027134895, f1 0.7979999780654907
ep24_l4_test_time 2.2597034420000455
gc 0
Train Epoch25 Acc 0.94915 (37966/40000), AUC 0.9873961210250854
ep25_train_time 65.5830302249999
Test Epoch25 layer0 Acc 0.7844, AUC 0.8631926774978638, avg_entr 0.14000169932842255, f1 0.7843999266624451
ep25_l0_test_time 0.625162113999977
Test Epoch25 layer1 Acc 0.7882, AUC 0.8640755414962769, avg_entr 0.05493289977312088, f1 0.7882000207901001
ep25_l1_test_time 0.821479712999917
Test Epoch25 layer2 Acc 0.793, AUC 0.8773614764213562, avg_entr 0.04748683422803879, f1 0.7929999828338623
ep25_l2_test_time 1.1436845949999679
Test Epoch25 layer3 Acc 0.7928, AUC 0.8778838515281677, avg_entr 0.045471739023923874, f1 0.7928000092506409
ep25_l3_test_time 1.6245997940000052
Test Epoch25 layer4 Acc 0.792, AUC 0.8791826367378235, avg_entr 0.045010026544332504, f1 0.7920000553131104
ep25_l4_test_time 2.2627989140000864
gc 0
Train Epoch26 Acc 0.9506 (38024/40000), AUC 0.9878947734832764
ep26_train_time 65.73713907199999
Test Epoch26 layer0 Acc 0.785, AUC 0.863861083984375, avg_entr 0.14454419910907745, f1 0.7850000262260437
ep26_l0_test_time 0.6261537739999312
Test Epoch26 layer1 Acc 0.8, AUC 0.8654032945632935, avg_entr 0.053776081651449203, f1 0.8000000715255737
ep26_l1_test_time 0.8225359000000481
Test Epoch26 layer2 Acc 0.8006, AUC 0.8802331686019897, avg_entr 0.048458077013492584, f1 0.800599992275238
ep26_l2_test_time 1.1417654370000037
Test Epoch26 layer3 Acc 0.8022, AUC 0.8806920051574707, avg_entr 0.04594150558114052, f1 0.8022000193595886
ep26_l3_test_time 1.625802781999937
Test Epoch26 layer4 Acc 0.8022, AUC 0.8817270398139954, avg_entr 0.045645538717508316, f1 0.8022000193595886
ep26_l4_test_time 2.2587118289998216
gc 0
Train Epoch27 Acc 0.953975 (38159/40000), AUC 0.9895492196083069
ep27_train_time 65.57416091000005
Test Epoch27 layer0 Acc 0.787, AUC 0.862635612487793, avg_entr 0.1410556137561798, f1 0.7870000600814819
ep27_l0_test_time 0.6288202819998787
Test Epoch27 layer1 Acc 0.7942, AUC 0.8604227304458618, avg_entr 0.050532110035419464, f1 0.7942000031471252
ep27_l1_test_time 0.8190326500000538
Test Epoch27 layer2 Acc 0.796, AUC 0.8769668340682983, avg_entr 0.04385026544332504, f1 0.796000063419342
ep27_l2_test_time 1.143727710000121
Test Epoch27 layer3 Acc 0.797, AUC 0.8776036500930786, avg_entr 0.041305262595415115, f1 0.796999990940094
ep27_l3_test_time 1.625188363999996
Test Epoch27 layer4 Acc 0.7978, AUC 0.8791086673736572, avg_entr 0.04115070030093193, f1 0.7978000044822693
ep27_l4_test_time 2.2587992230000964
gc 0
Train Epoch28 Acc 0.9551 (38204/40000), AUC 0.9901644587516785
ep28_train_time 65.57423624800003
Test Epoch28 layer0 Acc 0.786, AUC 0.8623478412628174, avg_entr 0.13707849383354187, f1 0.7860000133514404
ep28_l0_test_time 0.6320586439996987
Test Epoch28 layer1 Acc 0.7966, AUC 0.8591171503067017, avg_entr 0.047738537192344666, f1 0.7965999841690063
ep28_l1_test_time 0.8277895530000023
Test Epoch28 layer2 Acc 0.7974, AUC 0.8771702647209167, avg_entr 0.041805021464824677, f1 0.7973999977111816
ep28_l2_test_time 1.1414342670000224
Test Epoch28 layer3 Acc 0.799, AUC 0.8779232501983643, avg_entr 0.03948375955224037, f1 0.7990000247955322
ep28_l3_test_time 1.6248043370001142
Test Epoch28 layer4 Acc 0.8, AUC 0.8795113563537598, avg_entr 0.039032649248838425, f1 0.8000000715255737
ep28_l4_test_time 2.2604724719999467
gc 0
Train Epoch29 Acc 0.95635 (38254/40000), AUC 0.9907276630401611
ep29_train_time 65.73599802099989
Test Epoch29 layer0 Acc 0.7888, AUC 0.8621894121170044, avg_entr 0.13873834908008575, f1 0.7888000011444092
ep29_l0_test_time 0.6275498420000076
Test Epoch29 layer1 Acc 0.7964, AUC 0.8588100671768188, avg_entr 0.04826497286558151, f1 0.7964000105857849
ep29_l1_test_time 0.8193484019998323
Test Epoch29 layer2 Acc 0.7984, AUC 0.8763927817344666, avg_entr 0.042058080434799194, f1 0.7983999848365784
ep29_l2_test_time 1.1543136549998962
Test Epoch29 layer3 Acc 0.7986, AUC 0.8769077062606812, avg_entr 0.03971729427576065, f1 0.7986000180244446
ep29_l3_test_time 1.627256449000015
Test Epoch29 layer4 Acc 0.7984, AUC 0.8786681890487671, avg_entr 0.038750529289245605, f1 0.7983999848365784
ep29_l4_test_time 2.260194690999924
gc 0
Train Epoch30 Acc 0.957075 (38283/40000), AUC 0.9903976917266846
ep30_train_time 65.67495668499987
Test Epoch30 layer0 Acc 0.7826, AUC 0.861212968826294, avg_entr 0.13576030731201172, f1 0.7825999855995178
ep30_l0_test_time 0.6366804939998474
Test Epoch30 layer1 Acc 0.7928, AUC 0.856744647026062, avg_entr 0.04740689694881439, f1 0.7928000092506409
ep30_l1_test_time 0.8190982930000246
Test Epoch30 layer2 Acc 0.794, AUC 0.8742939829826355, avg_entr 0.040415097028017044, f1 0.7940000295639038
ep30_l2_test_time 1.1446579789999305
Test Epoch30 layer3 Acc 0.7944, AUC 0.8750772476196289, avg_entr 0.0382382795214653, f1 0.7943999767303467
ep30_l3_test_time 1.6232032469997648
Test Epoch30 layer4 Acc 0.7954, AUC 0.8768417835235596, avg_entr 0.03767252340912819, f1 0.795400083065033
ep30_l4_test_time 2.261380448000182
gc 0
Train Epoch31 Acc 0.9597 (38388/40000), AUC 0.9916671514511108
ep31_train_time 65.5768996669999
Test Epoch31 layer0 Acc 0.7862, AUC 0.8611350059509277, avg_entr 0.13845038414001465, f1 0.7861999869346619
ep31_l0_test_time 0.6270370410002215
Test Epoch31 layer1 Acc 0.7948, AUC 0.8544900417327881, avg_entr 0.04506664350628853, f1 0.7947999835014343
ep31_l1_test_time 0.8220702480002728
Test Epoch31 layer2 Acc 0.7986, AUC 0.872970700263977, avg_entr 0.03872368484735489, f1 0.7986000180244446
ep31_l2_test_time 1.1411919910001416
Test Epoch31 layer3 Acc 0.7992, AUC 0.8753133416175842, avg_entr 0.03665181249380112, f1 0.7991999983787537
ep31_l3_test_time 1.627902479000113
Test Epoch31 layer4 Acc 0.7998, AUC 0.8768442869186401, avg_entr 0.036391425877809525, f1 0.7997999787330627
ep31_l4_test_time 2.2641547920002267
gc 0
Train Epoch32 Acc 0.959575 (38383/40000), AUC 0.991243302822113
ep32_train_time 65.67476490300032
Test Epoch32 layer0 Acc 0.7848, AUC 0.8603474497795105, avg_entr 0.13749131560325623, f1 0.7847999930381775
ep32_l0_test_time 0.629537105000054
Test Epoch32 layer1 Acc 0.7938, AUC 0.8555152416229248, avg_entr 0.04503529518842697, f1 0.7937999963760376
ep32_l1_test_time 0.8213151110003309
Test Epoch32 layer2 Acc 0.7996, AUC 0.8725004196166992, avg_entr 0.03850214183330536, f1 0.7996000051498413
ep32_l2_test_time 1.145534661000056
Test Epoch32 layer3 Acc 0.799, AUC 0.8741225004196167, avg_entr 0.03650761768221855, f1 0.7990000247955322
ep32_l3_test_time 1.6266092739997475
Test Epoch32 layer4 Acc 0.7992, AUC 0.8758620023727417, avg_entr 0.03588080033659935, f1 0.7991999983787537
ep32_l4_test_time 2.262307754000176
gc 0
Train Epoch33 Acc 0.961725 (38469/40000), AUC 0.9922850728034973
ep33_train_time 65.56588238599988
Test Epoch33 layer0 Acc 0.785, AUC 0.8599904775619507, avg_entr 0.13720999658107758, f1 0.7850000262260437
ep33_l0_test_time 0.629346655000063
Test Epoch33 layer1 Acc 0.7936, AUC 0.8554126024246216, avg_entr 0.045202936977148056, f1 0.7936000227928162
ep33_l1_test_time 0.8207221509996998
Test Epoch33 layer2 Acc 0.7946, AUC 0.8712685108184814, avg_entr 0.03875485062599182, f1 0.7946000695228577
ep33_l2_test_time 1.1443605399999797
Test Epoch33 layer3 Acc 0.7944, AUC 0.87279212474823, avg_entr 0.03639145940542221, f1 0.7943999767303467
ep33_l3_test_time 1.626570984999944
Test Epoch33 layer4 Acc 0.7956, AUC 0.8744566440582275, avg_entr 0.035732023417949677, f1 0.7955999970436096
ep33_l4_test_time 2.2595788020003056
gc 0
Train Epoch34 Acc 0.9617 (38468/40000), AUC 0.992300271987915
ep34_train_time 65.74334328399982
Test Epoch34 layer0 Acc 0.7858, AUC 0.8600314259529114, avg_entr 0.13602633774280548, f1 0.7857999801635742
ep34_l0_test_time 0.6380239929999334
Test Epoch34 layer1 Acc 0.7932, AUC 0.8534621000289917, avg_entr 0.04630446434020996, f1 0.7932000160217285
ep34_l1_test_time 0.8272174670000823
Test Epoch34 layer2 Acc 0.797, AUC 0.8714622259140015, avg_entr 0.04016948118805885, f1 0.796999990940094
ep34_l2_test_time 1.148489488999985
Test Epoch34 layer3 Acc 0.7976, AUC 0.8730355501174927, avg_entr 0.03791941702365875, f1 0.7976000308990479
ep34_l3_test_time 1.6261775459997807
Test Epoch34 layer4 Acc 0.798, AUC 0.8747419118881226, avg_entr 0.037515655159950256, f1 0.7979999780654907
ep34_l4_test_time 2.2608879610002077
gc 0
Train Epoch35 Acc 0.9617 (38468/40000), AUC 0.9925704002380371
ep35_train_time 65.68148894299975
Test Epoch35 layer0 Acc 0.785, AUC 0.8590431213378906, avg_entr 0.1360236406326294, f1 0.7850000262260437
ep35_l0_test_time 0.6267385220003234
Test Epoch35 layer1 Acc 0.7922, AUC 0.853184700012207, avg_entr 0.04579032585024834, f1 0.7922000288963318
ep35_l1_test_time 0.825013872999989
Test Epoch35 layer2 Acc 0.797, AUC 0.871170163154602, avg_entr 0.03930896148085594, f1 0.796999990940094
ep35_l2_test_time 1.1593728299999384
Test Epoch35 layer3 Acc 0.7966, AUC 0.8730182647705078, avg_entr 0.037133317440748215, f1 0.7965999841690063
ep35_l3_test_time 1.6398826740000914
Test Epoch35 layer4 Acc 0.7968, AUC 0.8746967315673828, avg_entr 0.03683437034487724, f1 0.7968000173568726
ep35_l4_test_time 2.2684169889998884
gc 0
Train Epoch36 Acc 0.962075 (38483/40000), AUC 0.9926719665527344
ep36_train_time 65.71188710800016
Test Epoch36 layer0 Acc 0.7866, AUC 0.8592144250869751, avg_entr 0.13429100811481476, f1 0.7865999937057495
ep36_l0_test_time 0.6301061420003862
Test Epoch36 layer1 Acc 0.791, AUC 0.8532500267028809, avg_entr 0.044926442205905914, f1 0.7910000681877136
ep36_l1_test_time 0.8206417040000815
Test Epoch36 layer2 Acc 0.7958, AUC 0.8710280060768127, avg_entr 0.03930560126900673, f1 0.7958000302314758
ep36_l2_test_time 1.1440187700000024
Test Epoch36 layer3 Acc 0.7954, AUC 0.8729838132858276, avg_entr 0.037335388362407684, f1 0.795400083065033
ep36_l3_test_time 1.62496615200007
Test Epoch36 layer4 Acc 0.7954, AUC 0.8747252225875854, avg_entr 0.03679008036851883, f1 0.795400083065033
ep36_l4_test_time 2.260246427000311
gc 0
Train Epoch37 Acc 0.962675 (38507/40000), AUC 0.992777943611145
ep37_train_time 65.61527898299983
Test Epoch37 layer0 Acc 0.7848, AUC 0.8589081764221191, avg_entr 0.13498178124427795, f1 0.7847999930381775
ep37_l0_test_time 0.6260561349999989
Test Epoch37 layer1 Acc 0.791, AUC 0.851835310459137, avg_entr 0.04482226073741913, f1 0.7910000681877136
ep37_l1_test_time 0.8213697340002
Test Epoch37 layer2 Acc 0.7946, AUC 0.8699878454208374, avg_entr 0.03838016092777252, f1 0.7946000695228577
ep37_l2_test_time 1.1417154310001933
Test Epoch37 layer3 Acc 0.7944, AUC 0.8723939061164856, avg_entr 0.036287400871515274, f1 0.7943999767303467
ep37_l3_test_time 1.6243339490001745
Test Epoch37 layer4 Acc 0.7946, AUC 0.8741176724433899, avg_entr 0.035639286041259766, f1 0.7946000695228577
ep37_l4_test_time 2.2621100690003004
gc 0
Train Epoch38 Acc 0.96295 (38518/40000), AUC 0.9931408166885376
ep38_train_time 65.61280606199989
Test Epoch38 layer0 Acc 0.783, AUC 0.8587993383407593, avg_entr 0.13436180353164673, f1 0.7829999923706055
ep38_l0_test_time 0.6290369859998464
Test Epoch38 layer1 Acc 0.7936, AUC 0.8538272380828857, avg_entr 0.04518738016486168, f1 0.7936000227928162
ep38_l1_test_time 0.8192020609999418
Test Epoch38 layer2 Acc 0.7952, AUC 0.8714358806610107, avg_entr 0.03880351409316063, f1 0.7952000498771667
ep38_l2_test_time 1.1497947459997704
Test Epoch38 layer3 Acc 0.7968, AUC 0.8738396167755127, avg_entr 0.03669210895895958, f1 0.7968000173568726
ep38_l3_test_time 1.6296563720002268
Test Epoch38 layer4 Acc 0.7958, AUC 0.8754830360412598, avg_entr 0.036181364208459854, f1 0.7958000302314758
ep38_l4_test_time 2.2673221320001176
gc 0
Train Epoch39 Acc 0.964325 (38573/40000), AUC 0.9931801557540894
ep39_train_time 65.61681614300005
Test Epoch39 layer0 Acc 0.7858, AUC 0.8587816953659058, avg_entr 0.13478441536426544, f1 0.7857999801635742
ep39_l0_test_time 0.6258987870000965
Test Epoch39 layer1 Acc 0.793, AUC 0.8527084589004517, avg_entr 0.04411744326353073, f1 0.7929999828338623
ep39_l1_test_time 0.8253250699999626
Test Epoch39 layer2 Acc 0.7964, AUC 0.8711906671524048, avg_entr 0.03789300471544266, f1 0.7964000105857849
ep39_l2_test_time 1.1407956280004328
Test Epoch39 layer3 Acc 0.7968, AUC 0.8736010789871216, avg_entr 0.03573145717382431, f1 0.7968000173568726
ep39_l3_test_time 1.6237072029998671
Test Epoch39 layer4 Acc 0.797, AUC 0.8753830194473267, avg_entr 0.035166334360837936, f1 0.796999990940094
ep39_l4_test_time 2.260546675000114
gc 0
Train Epoch40 Acc 0.9649 (38596/40000), AUC 0.9931473135948181
ep40_train_time 65.57662451600027
Test Epoch40 layer0 Acc 0.785, AUC 0.8589169979095459, avg_entr 0.13406045734882355, f1 0.7850000262260437
ep40_l0_test_time 0.6289696579997326
Test Epoch40 layer1 Acc 0.7926, AUC 0.8529008030891418, avg_entr 0.04450027644634247, f1 0.7925999760627747
ep40_l1_test_time 0.8241565200000878
Test Epoch40 layer2 Acc 0.7944, AUC 0.8710300326347351, avg_entr 0.03809734806418419, f1 0.7943999767303467
ep40_l2_test_time 1.143152538999857
Test Epoch40 layer3 Acc 0.7956, AUC 0.873054027557373, avg_entr 0.03585699945688248, f1 0.7955999970436096
ep40_l3_test_time 1.6256547849998242
Test Epoch40 layer4 Acc 0.796, AUC 0.8749389052391052, avg_entr 0.035238441079854965, f1 0.796000063419342
ep40_l4_test_time 2.259678920999704
gc 0
Train Epoch41 Acc 0.9638 (38552/40000), AUC 0.9930663108825684
ep41_train_time 65.65769039599991
Test Epoch41 layer0 Acc 0.7858, AUC 0.8586732745170593, avg_entr 0.1346767544746399, f1 0.7857999801635742
ep41_l0_test_time 0.6290704989996811
Test Epoch41 layer1 Acc 0.7922, AUC 0.8524247407913208, avg_entr 0.044347457587718964, f1 0.7922000288963318
ep41_l1_test_time 0.8241549939998549
Test Epoch41 layer2 Acc 0.7946, AUC 0.870400071144104, avg_entr 0.03842639550566673, f1 0.7946000695228577
ep41_l2_test_time 1.147714446000009
Test Epoch41 layer3 Acc 0.7948, AUC 0.8727112412452698, avg_entr 0.03636644035577774, f1 0.7947999835014343
ep41_l3_test_time 1.628028340000128
Test Epoch41 layer4 Acc 0.795, AUC 0.8745596408843994, avg_entr 0.03582165390253067, f1 0.7950000166893005
ep41_l4_test_time 2.2697401880000143
gc 0
Train Epoch42 Acc 0.964375 (38575/40000), AUC 0.993108868598938
ep42_train_time 65.63373505000027
Test Epoch42 layer0 Acc 0.7854, AUC 0.85858154296875, avg_entr 0.13392537832260132, f1 0.7853999733924866
ep42_l0_test_time 0.6272373780002454
Test Epoch42 layer1 Acc 0.7934, AUC 0.8517586588859558, avg_entr 0.0439787320792675, f1 0.79339998960495
ep42_l1_test_time 0.8250219669998842
Test Epoch42 layer2 Acc 0.7954, AUC 0.8699698448181152, avg_entr 0.03743109852075577, f1 0.795400083065033
ep42_l2_test_time 1.1438009889998284
Test Epoch42 layer3 Acc 0.7954, AUC 0.8724496364593506, avg_entr 0.03537098318338394, f1 0.795400083065033
ep42_l3_test_time 1.6285796220004158
Test Epoch42 layer4 Acc 0.7956, AUC 0.8742855787277222, avg_entr 0.034848056733608246, f1 0.7955999970436096
ep42_l4_test_time 2.2640677320000577
gc 0
Train Epoch43 Acc 0.964075 (38563/40000), AUC 0.9931195974349976
ep43_train_time 65.60842664500024
Test Epoch43 layer0 Acc 0.7844, AUC 0.8586957454681396, avg_entr 0.1338365525007248, f1 0.7843999266624451
ep43_l0_test_time 0.6265599490002387
Test Epoch43 layer1 Acc 0.7932, AUC 0.8517277240753174, avg_entr 0.043653275817632675, f1 0.7932000160217285
ep43_l1_test_time 0.8214254389999951
Test Epoch43 layer2 Acc 0.7948, AUC 0.8698704838752747, avg_entr 0.03708299994468689, f1 0.7947999835014343
ep43_l2_test_time 1.1430203209997671
Test Epoch43 layer3 Acc 0.7958, AUC 0.8722284436225891, avg_entr 0.03499893844127655, f1 0.7958000302314758
ep43_l3_test_time 1.6262963419999323
Test Epoch43 layer4 Acc 0.7968, AUC 0.874103307723999, avg_entr 0.03442889079451561, f1 0.7968000173568726
ep43_l4_test_time 2.2618475230001422
gc 0
Train Epoch44 Acc 0.965425 (38617/40000), AUC 0.9935239553451538
ep44_train_time 65.59091715199975
Test Epoch44 layer0 Acc 0.786, AUC 0.8585630655288696, avg_entr 0.1343611627817154, f1 0.7860000133514404
ep44_l0_test_time 0.6283433260000493
Test Epoch44 layer1 Acc 0.792, AUC 0.8519381284713745, avg_entr 0.04377482831478119, f1 0.7920000553131104
ep44_l1_test_time 0.8238269490002494
Test Epoch44 layer2 Acc 0.795, AUC 0.8701905012130737, avg_entr 0.03726758435368538, f1 0.7950000166893005
ep44_l2_test_time 1.1430525859996123
Test Epoch44 layer3 Acc 0.795, AUC 0.8726770877838135, avg_entr 0.03536108508706093, f1 0.7950000166893005
ep44_l3_test_time 1.624437491000208
Test Epoch44 layer4 Acc 0.7958, AUC 0.8744819164276123, avg_entr 0.034821391105651855, f1 0.7958000302314758
ep44_l4_test_time 2.2598992599996564
gc 0
Train Epoch45 Acc 0.964275 (38571/40000), AUC 0.9934037923812866
ep45_train_time 65.57384085600006
Test Epoch45 layer0 Acc 0.7852, AUC 0.8585309982299805, avg_entr 0.13373273611068726, f1 0.7851999998092651
ep45_l0_test_time 0.6262322999996286
Test Epoch45 layer1 Acc 0.7932, AUC 0.8519562482833862, avg_entr 0.04373088479042053, f1 0.7932000160217285
ep45_l1_test_time 0.8219907979996606
Test Epoch45 layer2 Acc 0.796, AUC 0.8699702024459839, avg_entr 0.03735407814383507, f1 0.796000063419342
ep45_l2_test_time 1.1416889389997777
Test Epoch45 layer3 Acc 0.7964, AUC 0.8723605871200562, avg_entr 0.035410694777965546, f1 0.7964000105857849
ep45_l3_test_time 1.624816667000232
Test Epoch45 layer4 Acc 0.7958, AUC 0.8742614984512329, avg_entr 0.03495835140347481, f1 0.7958000302314758
ep45_l4_test_time 2.2586393339997812
gc 0
Train Epoch46 Acc 0.964725 (38589/40000), AUC 0.9934236407279968
ep46_train_time 65.66482766499985
Test Epoch46 layer0 Acc 0.7864, AUC 0.8584482073783875, avg_entr 0.13370347023010254, f1 0.7864000201225281
ep46_l0_test_time 0.6254444130004231
Test Epoch46 layer1 Acc 0.7928, AUC 0.8517802953720093, avg_entr 0.04356374964118004, f1 0.7928000092506409
ep46_l1_test_time 0.8186551280000458
Test Epoch46 layer2 Acc 0.796, AUC 0.8698805570602417, avg_entr 0.03727905824780464, f1 0.796000063419342
ep46_l2_test_time 1.1434135569998034
Test Epoch46 layer3 Acc 0.7968, AUC 0.8722161054611206, avg_entr 0.03539414331316948, f1 0.7968000173568726
ep46_l3_test_time 1.6253801269999713
Test Epoch46 layer4 Acc 0.7956, AUC 0.8740987181663513, avg_entr 0.03489314392209053, f1 0.7955999970436096
ep46_l4_test_time 2.2599591640000654
gc 0
Train Epoch47 Acc 0.96525 (38610/40000), AUC 0.9933079481124878
ep47_train_time 65.6801460239999
Test Epoch47 layer0 Acc 0.785, AUC 0.8584578037261963, avg_entr 0.1336798220872879, f1 0.7850000262260437
ep47_l0_test_time 0.6286718800001836
Test Epoch47 layer1 Acc 0.7928, AUC 0.8515468835830688, avg_entr 0.04374966770410538, f1 0.7928000092506409
ep47_l1_test_time 0.8194704449997516
Test Epoch47 layer2 Acc 0.7946, AUC 0.8698339462280273, avg_entr 0.03745127096772194, f1 0.7946000695228577
ep47_l2_test_time 1.1452547799999593
Test Epoch47 layer3 Acc 0.7952, AUC 0.8722133636474609, avg_entr 0.03550482168793678, f1 0.7952000498771667
ep47_l3_test_time 1.6241550600002483
Test Epoch47 layer4 Acc 0.7956, AUC 0.8740991950035095, avg_entr 0.03500410541892052, f1 0.7955999970436096
ep47_l4_test_time 2.2588547370000924
gc 0
Train Epoch48 Acc 0.964825 (38593/40000), AUC 0.9932832717895508
ep48_train_time 65.77350463699986
Test Epoch48 layer0 Acc 0.785, AUC 0.8584927320480347, avg_entr 0.13367098569869995, f1 0.7850000262260437
ep48_l0_test_time 0.6269437169999037
Test Epoch48 layer1 Acc 0.7928, AUC 0.8514903783798218, avg_entr 0.04397419095039368, f1 0.7928000092506409
ep48_l1_test_time 0.8224811270001737
Test Epoch48 layer2 Acc 0.7956, AUC 0.869806170463562, avg_entr 0.03759557381272316, f1 0.7955999970436096
ep48_l2_test_time 1.143792982999912
Test Epoch48 layer3 Acc 0.7962, AUC 0.8721449375152588, avg_entr 0.03556060045957565, f1 0.7961999177932739
ep48_l3_test_time 1.6270044419998158
Test Epoch48 layer4 Acc 0.7962, AUC 0.8740599155426025, avg_entr 0.03510921448469162, f1 0.7961999177932739
ep48_l4_test_time 2.2618686330001765
gc 0
Train Epoch49 Acc 0.9656 (38624/40000), AUC 0.9934367537498474
ep49_train_time 65.57209778600009
Test Epoch49 layer0 Acc 0.7848, AUC 0.8585559129714966, avg_entr 0.13346447050571442, f1 0.7847999930381775
ep49_l0_test_time 0.6660519430001841
Test Epoch49 layer1 Acc 0.7934, AUC 0.85162353515625, avg_entr 0.04383746534585953, f1 0.79339998960495
ep49_l1_test_time 0.9066977709999264
Test Epoch49 layer2 Acc 0.7962, AUC 0.8698598742485046, avg_entr 0.03765472397208214, f1 0.7961999177932739
ep49_l2_test_time 1.1674209479997444
Test Epoch49 layer3 Acc 0.796, AUC 0.8722274899482727, avg_entr 0.03566030412912369, f1 0.796000063419342
ep49_l3_test_time 1.636977176000073
Test Epoch49 layer4 Acc 0.7968, AUC 0.8741166591644287, avg_entr 0.03522927686572075, f1 0.7968000173568726
ep49_l4_test_time 2.265366548000202
Best AUC tensor(0.8158) 14 3
train_as_loss [[8.65664056e+01 5.90406559e+01 5.22394779e+01 5.05570665e+01
  4.99469250e+01 4.96636282e+01 4.95103962e+01 4.94185959e+01
  4.93594573e+01 4.93192337e+01 4.92906978e+01 4.92697637e+01
  4.92539836e+01 4.92418194e+01 4.92322605e+01 4.92246272e+01
  4.92184469e+01 4.92133814e+01 4.92091848e+01 4.92064677e+01
  4.92048075e+01 4.92032288e+01 4.92017328e+01 4.92006566e+01
  4.91999457e+01 4.91992310e+01 4.91985141e+01 4.91979751e+01
  4.91976033e+01 4.91972212e+01 4.91968266e+01 4.91965218e+01
  4.91963074e+01 4.91960833e+01 4.91958496e+01 4.91956631e+01
  4.91955327e+01 4.91953947e+01 4.91952471e+01 4.91951303e+01
  4.91950485e+01 4.91949592e+01 4.91948650e+01 4.91947890e+01
  4.91947369e+01 4.91946792e+01 4.91946173e+01 4.91945667e+01
  4.91945337e+01 4.91944969e+01]
 [2.54072953e+00 4.62115415e-04 2.06107815e-05 5.77194041e-06
  2.54552886e-06 1.31518900e-06 7.50658405e-07 4.68478287e-07
  2.87185696e-07 1.88918682e-07 1.29907553e-07 9.10073948e-08
  6.20915944e-08 5.21985392e-08 9.80714773e-08 2.78055758e-07
  8.57709123e-07 2.26398589e-06 2.80040406e-06 1.29761244e-08
  6.57797681e-09 5.82252695e-09 4.95443700e-09 4.32073059e-09
  3.93605668e-09 3.63157960e-09 3.33793242e-09 2.99260350e-09
  2.81674498e-09 2.73911825e-09 2.59168082e-09 2.41900595e-09
  2.32345897e-09 2.23366515e-09 2.15758596e-09 2.07821309e-09
  2.01043004e-09 1.98014383e-09 1.92664645e-09 1.87537036e-09
  1.81593283e-09 1.77645901e-09 1.72005394e-09 1.68554402e-09
  1.65208988e-09 1.61449296e-09 1.54685552e-09 1.56766909e-09
  1.51085299e-09 1.45532940e-09]
 [2.45901071e+00 3.48250170e-04 1.61012312e-05 4.46741399e-06
  2.05190344e-06 1.08783843e-06 6.44655307e-07 4.13570604e-07
  2.55216627e-07 1.69954198e-07 1.22108283e-07 8.96449629e-08
  6.09550526e-08 5.50064871e-08 1.20905025e-07 3.29236340e-07
  9.29142169e-07 2.14848962e-06 2.75559702e-06 1.63345673e-08
  6.51172967e-09 5.93586518e-09 5.09231752e-09 4.14867015e-09
  3.83479972e-09 3.56931797e-09 3.22713513e-09 2.78104223e-09
  2.57493643e-09 2.52773498e-09 2.42097202e-09 2.21433308e-09
  2.14228947e-09 2.03790294e-09 1.97119135e-09 1.86384375e-09
  1.82310575e-09 1.78873867e-09 1.75832592e-09 1.69148813e-09
  1.65719269e-09 1.59867536e-09 1.57233959e-09 1.53919758e-09
  1.49002546e-09 1.44413802e-09 1.40946436e-09 1.44979583e-09
  1.39540736e-09 1.33382398e-09]
 [2.02948834e+00 5.39993449e-04 1.73609649e-05 5.22276053e-06
  2.56494248e-06 1.39728658e-06 8.56863402e-07 5.66778471e-07
  3.45827394e-07 2.32403881e-07 1.82172850e-07 1.39555112e-07
  9.25302278e-08 7.56266031e-08 1.41846230e-07 3.55633922e-07
  1.00540870e-06 2.47666803e-06 3.31543174e-06 2.73733674e-08
  9.35759889e-09 8.92180166e-09 7.95032650e-09 5.50640085e-09
  5.19583897e-09 4.96359418e-09 4.30292047e-09 3.34143799e-09
  3.00392941e-09 3.04419321e-09 2.94121089e-09 2.58779991e-09
  2.53126575e-09 2.35355266e-09 2.29294404e-09 2.13899345e-09
  2.08491789e-09 2.05556243e-09 2.01623317e-09 1.93329720e-09
  1.86244828e-09 1.81414047e-09 1.78341148e-09 1.72765202e-09
  1.69639000e-09 1.64710379e-09 1.57186259e-09 1.60095214e-09
  1.56025473e-09 1.51460425e-09]
 [2.20121800e+00 7.77091173e-04 2.44660525e-05 7.29948004e-06
  3.60748001e-06 1.93671409e-06 1.21342763e-06 8.69625031e-07
  5.00412324e-07 3.55783915e-07 3.19196839e-07 2.60146477e-07
  1.77661831e-07 1.35494420e-07 2.27703291e-07 4.96088108e-07
  1.31540424e-06 3.21868262e-06 4.29378131e-06 9.06629507e-08
  1.63366781e-08 1.70830642e-08 1.84871852e-08 8.51838964e-09
  7.90802402e-09 8.23485438e-09 6.92357768e-09 4.26339967e-09
  3.61111212e-09 3.86459161e-09 3.71135035e-09 3.08190407e-09
  2.97545524e-09 2.75808754e-09 2.71042909e-09 2.45140791e-09
  2.40107144e-09 2.34891869e-09 2.33834010e-09 2.19130181e-09
  2.12543911e-09 2.07691516e-09 2.05843462e-09 1.93916229e-09
  1.90462421e-09 1.87727109e-09 1.80829658e-09 1.84617337e-09
  1.78115632e-09 1.73337279e-09]]
train_ae_loss [[4.23248261 3.05801468 3.7683766  4.13726823 4.32916363 4.53097652
  4.68296655 4.79918114 4.81538554 4.83216793 4.89973932 4.81750489
  4.75936881 4.75871373 4.68833495 4.62940712 4.62428419 4.53323421
  4.30987753 3.91973893 3.81710678 3.67894461 3.60477086 3.4159391
  3.36730422 3.28276319 3.22902623 3.13854124 3.09561474 3.06158587
  3.05656214 2.98462176 2.98186473 2.97333997 2.94371623 2.94252832
  2.92193359 2.91002557 2.91695457 2.89827438 2.90101935 2.90082877
  2.86986698 2.88234048 2.87329282 2.87643704 2.85980028 2.86170388
  2.89102981 2.87495827]
 [4.23891159 3.08078329 3.75487988 3.94727223 3.98284035 4.13856171
  4.22726648 4.27493601 4.1995302  4.0560104  4.0903625  3.91366393
  3.73884007 3.71954186 3.60885188 3.50867815 3.49319778 3.33761756
  3.03350773 2.55169362 2.42169524 2.2552527  2.17037068 1.94709391
  1.88124669 1.77367966 1.71825319 1.59228132 1.55061563 1.51234975
  1.50198248 1.43652375 1.43214399 1.42428492 1.38876323 1.37709963
  1.35952488 1.34948165 1.34361079 1.33369823 1.33084769 1.31921709
  1.28803753 1.29369584 1.30297595 1.28692726 1.28383674 1.28224229
  1.31221407 1.29835517]
 [4.35916503 2.84549712 3.68925019 3.74700741 3.64358511 3.75646405
  3.82380606 3.80484675 3.68250073 3.53560925 3.58659802 3.41108165
  3.23793904 3.22416833 3.11432389 3.02923616 3.02049041 2.88367724
  2.58587024 2.14746195 2.03267687 1.88466044 1.81352166 1.60996192
  1.55629515 1.46217271 1.41050977 1.29153512 1.25515027 1.22677874
  1.21188768 1.15744216 1.15144652 1.14225874 1.11616802 1.10018718
  1.08923112 1.07922924 1.07551994 1.06485373 1.06021325 1.04809954
  1.02130098 1.02141457 1.03918031 1.02110372 1.01975749 1.01852285
  1.04324885 1.03245814]
 [5.34150515 2.81840267 3.91551536 4.08996901 3.77331149 3.85382209
  3.92013526 3.86483594 3.74066547 3.57363893 3.64423118 3.45516659
  3.26610085 3.26185315 3.14512653 3.0690806  3.05992838 2.92869982
  2.6081533  2.15249244 2.03688461 1.88864496 1.81681782 1.61070117
  1.55740828 1.4585556  1.40827618 1.28555712 1.24825001 1.22163229
  1.20522901 1.14942337 1.14422878 1.13355323 1.10788057 1.09132059
  1.08149046 1.0709766  1.06735497 1.05572571 1.05054931 1.03824877
  1.01163138 1.01196479 1.0295628  1.01248262 1.01151533 1.00758158
  1.0329192  1.02248329]
 [4.60554341 2.78540097 3.95965981 4.56941775 3.88496266 3.84448575
  3.89299677 3.80800404 3.67136425 3.47553507 3.56087562 3.36102775
  3.16154158 3.16048616 3.04336209 2.98057319 2.96920226 2.8477101
  2.51673694 2.06438896 1.95272843 1.81300349 1.74425592 1.54245383
  1.49256413 1.39546251 1.34761468 1.22730507 1.19075518 1.16661071
  1.15067184 1.09742155 1.09116718 1.08026594 1.05647735 1.03988012
  1.03055389 1.02069137 1.01622079 1.00480355 0.9997794  0.98829777
  0.96258141 0.96429122 0.98083598 0.96391827 0.96222528 0.95837047
  0.98277729 0.97312001]]
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
total_train+valid_time 3613.965137156
Start Testing
Load ckpt at ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt
gc 9
Test layer0 Acc 0.7966, AUC 0.8804618120193481, avg_entr 0.18656174838542938, f1 0.7965999841690063
l0_test_time 0.6253511810000418
gc 0
Test layer1 Acc 0.8168, AUC 0.8961710929870605, avg_entr 0.10700009763240814, f1 0.8167999982833862
l1_test_time 0.8226684639998894
gc 0
Test layer2 Acc 0.817, AUC 0.8991546630859375, avg_entr 0.0943261906504631, f1 0.8169999718666077
l2_test_time 1.144139055999858
gc 0
Test layer3 Acc 0.8176, AUC 0.8993329405784607, avg_entr 0.09399504214525223, f1 0.8176000118255615
l3_test_time 1.6261183510000592
gc 0
Test layer4 Acc 0.8176, AUC 0.8992506265640259, avg_entr 0.09412024170160294, f1 0.8176000118255615
l4_test_time 2.2614557419997254
gc 0
Test threshold 0.1 Acc 0.817, AUC 0.8925336003303528, avg_entr 0.13975879549980164, f1 0.8169999718666077
t0.1_test_time 1.149901821000185
gc 0
Test threshold 0.2 Acc 0.817, AUC 0.8903928399085999, avg_entr 0.1500551700592041, f1 0.8169999718666077
t0.2_test_time 1.0419649969999227
gc 0
Test threshold 0.3 Acc 0.816, AUC 0.8900128602981567, avg_entr 0.16012509167194366, f1 0.8160000443458557
t0.3_test_time 0.9706801730003463
gc 0
Test threshold 0.4 Acc 0.815, AUC 0.8883059024810791, avg_entr 0.16946323215961456, f1 0.8149999976158142
t0.4_test_time 0.9145356110002467
gc 0
Test threshold 0.5 Acc 0.813, AUC 0.8859752416610718, avg_entr 0.1796598583459854, f1 0.8130000233650208
t0.5_test_time 0.8752488170002835
gc 0
Test threshold 0.6 Acc 0.812, AUC 0.8856298923492432, avg_entr 0.19039370119571686, f1 0.8119999766349792
t0.6_test_time 0.8455526709999504
gc 0
Test threshold 0.7 Acc 0.8112, AUC 0.8849400281906128, avg_entr 0.20193547010421753, f1 0.8112000226974487
t0.7_test_time 0.8093007590000525
gc 0
Test threshold 0.8 Acc 0.809, AUC 0.884118914604187, avg_entr 0.21555602550506592, f1 0.8090000748634338
t0.8_test_time 0.759513412999695
gc 0
Test threshold 0.9 Acc 0.8066, AUC 0.8827341794967651, avg_entr 0.2317153811454773, f1 0.8065999746322632
t0.9_test_time 0.7229725600000165
