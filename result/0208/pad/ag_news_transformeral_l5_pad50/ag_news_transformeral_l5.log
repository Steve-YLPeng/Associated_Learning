total count words 102019
vocab size 30000
found 26754 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13672292
Start Training
gc 0
Train Epoch0 Acc 0.64385 (77262/120000), AUC 0.8652437329292297
ep0_train_time 28.45541524887085
Test Epoch0 layer0 Acc 0.9113486842105263, AUC 0.9776655435562134, avg_entr 0.21829597651958466
ep0_l0_test_time 0.09886908531188965
Save ckpt to ckpt/ag_news_transformeral_l5_pad50//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9090460526315789, AUC 0.9787004590034485, avg_entr 0.15935231745243073
ep0_l1_test_time 0.15663719177246094
Save ckpt to ckpt/ag_news_transformeral_l5_pad50//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.9100328947368421, AUC 0.9783316850662231, avg_entr 0.15530088543891907
ep0_l2_test_time 0.21627283096313477
Test Epoch0 layer3 Acc 0.909375, AUC 0.9784586429595947, avg_entr 0.15100526809692383
ep0_l3_test_time 0.2723879814147949
Test Epoch0 layer4 Acc 0.9103618421052632, AUC 0.978635847568512, avg_entr 0.14933572709560394
ep0_l4_test_time 0.33103084564208984
gc 0
Train Epoch1 Acc 0.9268916666666667 (111227/120000), AUC 0.9839187860488892
ep1_train_time 28.740925312042236
Test Epoch1 layer0 Acc 0.9149671052631579, AUC 0.9799062013626099, avg_entr 0.13439811766147614
ep1_l0_test_time 0.09636044502258301
Save ckpt to ckpt/ag_news_transformeral_l5_pad50//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.9175986842105263, AUC 0.981876015663147, avg_entr 0.0853475034236908
ep1_l1_test_time 0.15776515007019043
Save ckpt to ckpt/ag_news_transformeral_l5_pad50//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.9172697368421052, AUC 0.9814197421073914, avg_entr 0.07091165333986282
ep1_l2_test_time 0.21630263328552246
Test Epoch1 layer3 Acc 0.9171052631578948, AUC 0.981217086315155, avg_entr 0.06585587561130524
ep1_l3_test_time 0.272477388381958
Test Epoch1 layer4 Acc 0.9185855263157895, AUC 0.981301486492157, avg_entr 0.0653776004910469
ep1_l4_test_time 0.3315088748931885
gc 0
Train Epoch2 Acc 0.93995 (112794/120000), AUC 0.9886088371276855
ep2_train_time 28.175997734069824
Test Epoch2 layer0 Acc 0.9141447368421053, AUC 0.980465292930603, avg_entr 0.10683947056531906
ep2_l0_test_time 0.09719991683959961
Test Epoch2 layer1 Acc 0.9171052631578948, AUC 0.9825930595397949, avg_entr 0.04942619055509567
ep2_l1_test_time 0.15526676177978516
Save ckpt to ckpt/ag_news_transformeral_l5_pad50//ag_news_transformeral_l5.pt  ,ep 2
Test Epoch2 layer2 Acc 0.9171052631578948, AUC 0.9820234775543213, avg_entr 0.03868093341588974
ep2_l2_test_time 0.21631288528442383
Test Epoch2 layer3 Acc 0.9167763157894737, AUC 0.9812873005867004, avg_entr 0.03574744611978531
ep2_l3_test_time 0.2731821537017822
Test Epoch2 layer4 Acc 0.9167763157894737, AUC 0.9819941520690918, avg_entr 0.034273453056812286
ep2_l4_test_time 0.33211278915405273
gc 0
Train Epoch3 Acc 0.9470916666666667 (113651/120000), AUC 0.9907064437866211
ep3_train_time 28.168104887008667
Test Epoch3 layer0 Acc 0.9148026315789474, AUC 0.9802805185317993, avg_entr 0.0902319923043251
ep3_l0_test_time 0.09670352935791016
Test Epoch3 layer1 Acc 0.9157894736842105, AUC 0.980312705039978, avg_entr 0.035789038985967636
ep3_l1_test_time 0.15503263473510742
Test Epoch3 layer2 Acc 0.915625, AUC 0.9814205169677734, avg_entr 0.02962704934179783
ep3_l2_test_time 0.21382641792297363
Test Epoch3 layer3 Acc 0.9159539473684211, AUC 0.9815189838409424, avg_entr 0.02760598622262478
ep3_l3_test_time 0.27303552627563477
Test Epoch3 layer4 Acc 0.9162828947368421, AUC 0.982172966003418, avg_entr 0.026445647701621056
ep3_l4_test_time 0.3317849636077881
gc 0
Train Epoch4 Acc 0.9525666666666667 (114308/120000), AUC 0.9914262294769287
ep4_train_time 28.522435188293457
Test Epoch4 layer0 Acc 0.9159539473684211, AUC 0.9801090955734253, avg_entr 0.0818086788058281
ep4_l0_test_time 0.09762430191040039
Test Epoch4 layer1 Acc 0.9100328947368421, AUC 0.9789940714836121, avg_entr 0.030540408566594124
ep4_l1_test_time 0.15470409393310547
Test Epoch4 layer2 Acc 0.9115131578947369, AUC 0.9804622530937195, avg_entr 0.02499731257557869
ep4_l2_test_time 0.21400976181030273
Test Epoch4 layer3 Acc 0.9103618421052632, AUC 0.9809039831161499, avg_entr 0.023024991154670715
ep4_l3_test_time 0.2730708122253418
Test Epoch4 layer4 Acc 0.9110197368421052, AUC 0.9813413619995117, avg_entr 0.020688438788056374
ep4_l4_test_time 0.33228421211242676
gc 0
Train Epoch5 Acc 0.9563583333333333 (114763/120000), AUC 0.9922559261322021
ep5_train_time 28.200117826461792
Test Epoch5 layer0 Acc 0.915625, AUC 0.9801192283630371, avg_entr 0.07372908294200897
ep5_l0_test_time 0.09668469429016113
Test Epoch5 layer1 Acc 0.9116776315789473, AUC 0.9792391061782837, avg_entr 0.026457391679286957
ep5_l1_test_time 0.15564775466918945
Test Epoch5 layer2 Acc 0.9115131578947369, AUC 0.9802778959274292, avg_entr 0.020330708473920822
ep5_l2_test_time 0.21491789817810059
Test Epoch5 layer3 Acc 0.9118421052631579, AUC 0.980688214302063, avg_entr 0.019018098711967468
ep5_l3_test_time 0.27347540855407715
Test Epoch5 layer4 Acc 0.9111842105263158, AUC 0.9806621074676514, avg_entr 0.01757064461708069
ep5_l4_test_time 0.33223795890808105
gc 0
Train Epoch6 Acc 0.9590916666666667 (115091/120000), AUC 0.9930111169815063
ep6_train_time 28.14801025390625
Test Epoch6 layer0 Acc 0.9148026315789474, AUC 0.9800395965576172, avg_entr 0.07070692628622055
ep6_l0_test_time 0.09755134582519531
Test Epoch6 layer1 Acc 0.9120065789473685, AUC 0.9785379767417908, avg_entr 0.02434460073709488
ep6_l1_test_time 0.15528559684753418
Test Epoch6 layer2 Acc 0.9116776315789473, AUC 0.9796321988105774, avg_entr 0.0183109063655138
ep6_l2_test_time 0.21436762809753418
Test Epoch6 layer3 Acc 0.9111842105263158, AUC 0.9806167483329773, avg_entr 0.016634928062558174
ep6_l3_test_time 0.2733280658721924
Test Epoch6 layer4 Acc 0.9108552631578948, AUC 0.9814399480819702, avg_entr 0.014605117030441761
ep6_l4_test_time 0.33211255073547363
gc 0
Train Epoch7 Acc 0.9637916666666667 (115655/120000), AUC 0.9943364262580872
ep7_train_time 28.52609395980835
Test Epoch7 layer0 Acc 0.9141447368421053, AUC 0.9799224734306335, avg_entr 0.06728297472000122
ep7_l0_test_time 0.09684467315673828
Test Epoch7 layer1 Acc 0.9106907894736842, AUC 0.9763813614845276, avg_entr 0.02451561950147152
ep7_l1_test_time 0.15523195266723633
Test Epoch7 layer2 Acc 0.9116776315789473, AUC 0.9774941205978394, avg_entr 0.018104538321495056
ep7_l2_test_time 0.21376395225524902
Test Epoch7 layer3 Acc 0.9110197368421052, AUC 0.9771684408187866, avg_entr 0.0161146093159914
ep7_l3_test_time 0.27254557609558105
Test Epoch7 layer4 Acc 0.9098684210526315, AUC 0.9765570163726807, avg_entr 0.014106347225606441
ep7_l4_test_time 0.3316640853881836
gc 0
Train Epoch8 Acc 0.9652083333333333 (115825/120000), AUC 0.9946154952049255
ep8_train_time 28.94620704650879
Test Epoch8 layer0 Acc 0.9120065789473685, AUC 0.9796349406242371, avg_entr 0.0636133924126625
ep8_l0_test_time 0.09714245796203613
Test Epoch8 layer1 Acc 0.909375, AUC 0.9751701354980469, avg_entr 0.0223851278424263
ep8_l1_test_time 0.15540504455566406
Test Epoch8 layer2 Acc 0.9083881578947368, AUC 0.975884199142456, avg_entr 0.01620539277791977
ep8_l2_test_time 0.2142658233642578
Test Epoch8 layer3 Acc 0.9069078947368421, AUC 0.9770228266716003, avg_entr 0.014437184669077396
ep8_l3_test_time 0.27318382263183594
Test Epoch8 layer4 Acc 0.9074013157894737, AUC 0.9761244058609009, avg_entr 0.012582272291183472
ep8_l4_test_time 0.3320138454437256
gc 0
Train Epoch9 Acc 0.9665583333333333 (115987/120000), AUC 0.9948787689208984
ep9_train_time 28.355273246765137
Test Epoch9 layer0 Acc 0.9116776315789473, AUC 0.9794735312461853, avg_entr 0.06204817816615105
ep9_l0_test_time 0.09659051895141602
Test Epoch9 layer1 Acc 0.9098684210526315, AUC 0.9746758937835693, avg_entr 0.02163897268474102
ep9_l1_test_time 0.15503430366516113
Test Epoch9 layer2 Acc 0.909375, AUC 0.9770269989967346, avg_entr 0.015809213742613792
ep9_l2_test_time 0.21440601348876953
Test Epoch9 layer3 Acc 0.9100328947368421, AUC 0.978539228439331, avg_entr 0.014053703285753727
ep9_l3_test_time 0.2731132507324219
Test Epoch9 layer4 Acc 0.9090460526315789, AUC 0.9778589010238647, avg_entr 0.012393558397889137
ep9_l4_test_time 0.3323550224304199
gc 0
Train Epoch10 Acc 0.9672583333333333 (116071/120000), AUC 0.9951053261756897
ep10_train_time 28.377317667007446
Test Epoch10 layer0 Acc 0.9116776315789473, AUC 0.9794790148735046, avg_entr 0.058527544140815735
ep10_l0_test_time 0.09696555137634277
Test Epoch10 layer1 Acc 0.9085526315789474, AUC 0.9744489192962646, avg_entr 0.02068062126636505
ep10_l1_test_time 0.1546487808227539
Test Epoch10 layer2 Acc 0.9075657894736842, AUC 0.9744183421134949, avg_entr 0.014726830646395683
ep10_l2_test_time 0.21315836906433105
Test Epoch10 layer3 Acc 0.9074013157894737, AUC 0.9763147830963135, avg_entr 0.012895028106868267
ep10_l3_test_time 0.27222418785095215
Test Epoch10 layer4 Acc 0.9072368421052631, AUC 0.9759595394134521, avg_entr 0.011263477616012096
ep10_l4_test_time 0.3315556049346924
gc 0
Train Epoch11 Acc 0.9697666666666667 (116372/120000), AUC 0.9956644773483276
ep11_train_time 28.05671525001526
Test Epoch11 layer0 Acc 0.9121710526315789, AUC 0.9792775511741638, avg_entr 0.057211704552173615
ep11_l0_test_time 0.09747982025146484
Test Epoch11 layer1 Acc 0.9085526315789474, AUC 0.9738134145736694, avg_entr 0.019906088709831238
ep11_l1_test_time 0.15575814247131348
Test Epoch11 layer2 Acc 0.9074013157894737, AUC 0.9753357768058777, avg_entr 0.014043203555047512
ep11_l2_test_time 0.21481108665466309
Test Epoch11 layer3 Acc 0.9080592105263158, AUC 0.9773558974266052, avg_entr 0.012620918452739716
ep11_l3_test_time 0.2731893062591553
Test Epoch11 layer4 Acc 0.9080592105263158, AUC 0.976455569267273, avg_entr 0.01117986161261797
ep11_l4_test_time 0.332444429397583
gc 0
Train Epoch12 Acc 0.970575 (116469/120000), AUC 0.9957563281059265
ep12_train_time 28.340911388397217
Test Epoch12 layer0 Acc 0.9120065789473685, AUC 0.9792463779449463, avg_entr 0.055144280195236206
ep12_l0_test_time 0.09879899024963379
Test Epoch12 layer1 Acc 0.9077302631578947, AUC 0.9722095727920532, avg_entr 0.019215205684304237
ep12_l1_test_time 0.15752077102661133
Test Epoch12 layer2 Acc 0.9085526315789474, AUC 0.9706066250801086, avg_entr 0.01379092875868082
ep12_l2_test_time 0.21614909172058105
Test Epoch12 layer3 Acc 0.9077302631578947, AUC 0.9715721607208252, avg_entr 0.012060502544045448
ep12_l3_test_time 0.27518558502197266
Test Epoch12 layer4 Acc 0.9078947368421053, AUC 0.9719440937042236, avg_entr 0.010480089113116264
ep12_l4_test_time 0.33447766304016113
gc 0
Train Epoch13 Acc 0.9710833333333333 (116530/120000), AUC 0.9958796501159668
ep13_train_time 28.28371000289917
Test Epoch13 layer0 Acc 0.9106907894736842, AUC 0.9791045188903809, avg_entr 0.05302439257502556
ep13_l0_test_time 0.09657907485961914
Test Epoch13 layer1 Acc 0.9074013157894737, AUC 0.9726498126983643, avg_entr 0.0189806055277586
ep13_l1_test_time 0.15494084358215332
Test Epoch13 layer2 Acc 0.9070723684210527, AUC 0.9731208086013794, avg_entr 0.013131878338754177
ep13_l2_test_time 0.2140965461730957
Test Epoch13 layer3 Acc 0.9064144736842106, AUC 0.9746423959732056, avg_entr 0.01114543154835701
ep13_l3_test_time 0.27281951904296875
Test Epoch13 layer4 Acc 0.905921052631579, AUC 0.9747629165649414, avg_entr 0.009648212231695652
ep13_l4_test_time 0.33217859268188477
gc 0
Train Epoch14 Acc 0.9715833333333334 (116590/120000), AUC 0.9959495663642883
ep14_train_time 28.35440492630005
Test Epoch14 layer0 Acc 0.9092105263157895, AUC 0.9789435267448425, avg_entr 0.05131612718105316
ep14_l0_test_time 0.09701085090637207
Test Epoch14 layer1 Acc 0.906578947368421, AUC 0.9728146195411682, avg_entr 0.01803562603890896
ep14_l1_test_time 0.15553689002990723
Test Epoch14 layer2 Acc 0.9054276315789473, AUC 0.9734579920768738, avg_entr 0.01272327359765768
ep14_l2_test_time 0.21403837203979492
Test Epoch14 layer3 Acc 0.905921052631579, AUC 0.9732120037078857, avg_entr 0.0112135149538517
ep14_l3_test_time 0.27361583709716797
Test Epoch14 layer4 Acc 0.9055921052631579, AUC 0.9738218784332275, avg_entr 0.009906835854053497
ep14_l4_test_time 0.33227109909057617
gc 0
Train Epoch15 Acc 0.97285 (116742/120000), AUC 0.9962238669395447
ep15_train_time 28.426629304885864
Test Epoch15 layer0 Acc 0.9105263157894737, AUC 0.9790170788764954, avg_entr 0.050146061927080154
ep15_l0_test_time 0.09673881530761719
Test Epoch15 layer1 Acc 0.905921052631579, AUC 0.9725115299224854, avg_entr 0.018054882064461708
ep15_l1_test_time 0.15516185760498047
Test Epoch15 layer2 Acc 0.9047697368421053, AUC 0.9722006320953369, avg_entr 0.012628493830561638
ep15_l2_test_time 0.21439456939697266
Test Epoch15 layer3 Acc 0.9032894736842105, AUC 0.9731005430221558, avg_entr 0.011072132736444473
ep15_l3_test_time 0.2731809616088867
Test Epoch15 layer4 Acc 0.9034539473684211, AUC 0.972658634185791, avg_entr 0.009725827723741531
ep15_l4_test_time 0.33302760124206543
gc 0
Train Epoch16 Acc 0.97315 (116778/120000), AUC 0.9962830543518066
ep16_train_time 28.914177656173706
Test Epoch16 layer0 Acc 0.9101973684210526, AUC 0.9790351390838623, avg_entr 0.048558857291936874
ep16_l0_test_time 0.09713554382324219
Test Epoch16 layer1 Acc 0.905921052631579, AUC 0.9720062613487244, avg_entr 0.01790004037320614
ep16_l1_test_time 0.15460443496704102
Test Epoch16 layer2 Acc 0.9034539473684211, AUC 0.9717347025871277, avg_entr 0.012421278282999992
ep16_l2_test_time 0.2134537696838379
Test Epoch16 layer3 Acc 0.903125, AUC 0.9728825092315674, avg_entr 0.010787352919578552
ep16_l3_test_time 0.2724146842956543
Test Epoch16 layer4 Acc 0.903125, AUC 0.9734358191490173, avg_entr 0.009262768551707268
ep16_l4_test_time 0.3317606449127197
gc 0
Train Epoch17 Acc 0.9737333333333333 (116848/120000), AUC 0.9963936805725098
ep17_train_time 28.83469247817993
Test Epoch17 layer0 Acc 0.9108552631578948, AUC 0.97904372215271, avg_entr 0.04704771190881729
ep17_l0_test_time 0.09835648536682129
Test Epoch17 layer1 Acc 0.9055921052631579, AUC 0.972320556640625, avg_entr 0.017377400770783424
ep17_l1_test_time 0.15747475624084473
Test Epoch17 layer2 Acc 0.9042763157894737, AUC 0.9717893600463867, avg_entr 0.011994928121566772
ep17_l2_test_time 0.21683716773986816
Test Epoch17 layer3 Acc 0.9041118421052632, AUC 0.9722483158111572, avg_entr 0.010527047328650951
ep17_l3_test_time 0.27622485160827637
Test Epoch17 layer4 Acc 0.9042763157894737, AUC 0.9721563458442688, avg_entr 0.009329337626695633
ep17_l4_test_time 0.3355436325073242
gc 0
Train Epoch18 Acc 0.9738083333333334 (116857/120000), AUC 0.9963492751121521
ep18_train_time 28.314106464385986
Test Epoch18 layer0 Acc 0.9100328947368421, AUC 0.9789327383041382, avg_entr 0.04559781774878502
ep18_l0_test_time 0.0966486930847168
Test Epoch18 layer1 Acc 0.9054276315789473, AUC 0.9714570641517639, avg_entr 0.01618877425789833
ep18_l1_test_time 0.1547253131866455
Test Epoch18 layer2 Acc 0.9054276315789473, AUC 0.9706730842590332, avg_entr 0.010754024609923363
ep18_l2_test_time 0.21395063400268555
Test Epoch18 layer3 Acc 0.9055921052631579, AUC 0.9712398052215576, avg_entr 0.009431197308003902
ep18_l3_test_time 0.2724933624267578
Test Epoch18 layer4 Acc 0.9047697368421053, AUC 0.9699341058731079, avg_entr 0.008578385226428509
ep18_l4_test_time 0.331859827041626
gc 0
Train Epoch19 Acc 0.9744583333333333 (116935/120000), AUC 0.996555745601654
ep19_train_time 28.432023763656616
Test Epoch19 layer0 Acc 0.9100328947368421, AUC 0.9788851737976074, avg_entr 0.045215025544166565
ep19_l0_test_time 0.09912943840026855
Test Epoch19 layer1 Acc 0.9057565789473684, AUC 0.9715563058853149, avg_entr 0.01685580052435398
ep19_l1_test_time 0.1595144271850586
Test Epoch19 layer2 Acc 0.9046052631578947, AUC 0.970243513584137, avg_entr 0.01135096326470375
ep19_l2_test_time 0.21973299980163574
Test Epoch19 layer3 Acc 0.9041118421052632, AUC 0.9710662364959717, avg_entr 0.009795326739549637
ep19_l3_test_time 0.2798185348510742
Test Epoch19 layer4 Acc 0.9039473684210526, AUC 0.9701312780380249, avg_entr 0.008599398657679558
ep19_l4_test_time 0.3398599624633789
gc 0
Train Epoch20 Acc 0.9748916666666667 (116987/120000), AUC 0.9965450763702393
ep20_train_time 28.56792378425598
Test Epoch20 layer0 Acc 0.9098684210526315, AUC 0.9789198637008667, avg_entr 0.0440811961889267
ep20_l0_test_time 0.09724760055541992
Test Epoch20 layer1 Acc 0.9052631578947369, AUC 0.9712034463882446, avg_entr 0.016385063529014587
ep20_l1_test_time 0.15512967109680176
Test Epoch20 layer2 Acc 0.9029605263157895, AUC 0.9702239632606506, avg_entr 0.011055602692067623
ep20_l2_test_time 0.21365904808044434
Test Epoch20 layer3 Acc 0.9029605263157895, AUC 0.9697815179824829, avg_entr 0.009668562561273575
ep20_l3_test_time 0.27252840995788574
Test Epoch20 layer4 Acc 0.9034539473684211, AUC 0.9693946838378906, avg_entr 0.008391962386667728
ep20_l4_test_time 0.33130502700805664
gc 0
Train Epoch21 Acc 0.974975 (116997/120000), AUC 0.9965643286705017
ep21_train_time 28.64809560775757
Test Epoch21 layer0 Acc 0.9105263157894737, AUC 0.9789707660675049, avg_entr 0.042626019567251205
ep21_l0_test_time 0.0970468521118164
Test Epoch21 layer1 Acc 0.9054276315789473, AUC 0.9713651537895203, avg_entr 0.015716157853603363
ep21_l1_test_time 0.15523600578308105
Test Epoch21 layer2 Acc 0.9041118421052632, AUC 0.9698652625083923, avg_entr 0.010611383244395256
ep21_l2_test_time 0.21397733688354492
Test Epoch21 layer3 Acc 0.9039473684210526, AUC 0.9684407711029053, avg_entr 0.009246599860489368
ep21_l3_test_time 0.2728891372680664
Test Epoch21 layer4 Acc 0.9041118421052632, AUC 0.9669666290283203, avg_entr 0.008270366117358208
ep21_l4_test_time 0.3315749168395996
gc 0
Train Epoch22 Acc 0.9749833333333333 (116998/120000), AUC 0.9964486360549927
ep22_train_time 28.190359592437744
Test Epoch22 layer0 Acc 0.9106907894736842, AUC 0.9789592027664185, avg_entr 0.04168621823191643
ep22_l0_test_time 0.09714150428771973
Test Epoch22 layer1 Acc 0.9054276315789473, AUC 0.9712203145027161, avg_entr 0.01549001969397068
ep22_l1_test_time 0.15517187118530273
Test Epoch22 layer2 Acc 0.9046052631578947, AUC 0.9699826836585999, avg_entr 0.010165493935346603
ep22_l2_test_time 0.2145674228668213
Test Epoch22 layer3 Acc 0.9041118421052632, AUC 0.9687965512275696, avg_entr 0.008873441256582737
ep22_l3_test_time 0.2725999355316162
Test Epoch22 layer4 Acc 0.9042763157894737, AUC 0.9672479629516602, avg_entr 0.007803390733897686
ep22_l4_test_time 0.33174586296081543
gc 0
Train Epoch23 Acc 0.9756916666666666 (117083/120000), AUC 0.9966433048248291
ep23_train_time 28.50729465484619
Test Epoch23 layer0 Acc 0.9103618421052632, AUC 0.978969931602478, avg_entr 0.04139045253396034
ep23_l0_test_time 0.09714770317077637
Test Epoch23 layer1 Acc 0.9052631578947369, AUC 0.9712409973144531, avg_entr 0.015574591234326363
ep23_l1_test_time 0.15505456924438477
Test Epoch23 layer2 Acc 0.903125, AUC 0.9703083038330078, avg_entr 0.010301603935658932
ep23_l2_test_time 0.21445298194885254
Test Epoch23 layer3 Acc 0.9027960526315789, AUC 0.9694220423698425, avg_entr 0.008785109966993332
ep23_l3_test_time 0.2730519771575928
Test Epoch23 layer4 Acc 0.9029605263157895, AUC 0.967937707901001, avg_entr 0.007678444962948561
ep23_l4_test_time 0.33233213424682617
gc 0
Train Epoch24 Acc 0.9753916666666667 (117047/120000), AUC 0.9965861439704895
ep24_train_time 28.492666959762573
Test Epoch24 layer0 Acc 0.9100328947368421, AUC 0.9789309501647949, avg_entr 0.040963418781757355
ep24_l0_test_time 0.09625554084777832
Test Epoch24 layer1 Acc 0.905921052631579, AUC 0.971132218837738, avg_entr 0.015261544845998287
ep24_l1_test_time 0.15459203720092773
Test Epoch24 layer2 Acc 0.9050986842105263, AUC 0.9701833128929138, avg_entr 0.010088862851262093
ep24_l2_test_time 0.21347832679748535
Test Epoch24 layer3 Acc 0.9047697368421053, AUC 0.969068706035614, avg_entr 0.00870059709995985
ep24_l3_test_time 0.27245092391967773
Test Epoch24 layer4 Acc 0.9046052631578947, AUC 0.9675142765045166, avg_entr 0.007467528805136681
ep24_l4_test_time 0.3319237232208252
gc 0
Train Epoch25 Acc 0.9756416666666666 (117077/120000), AUC 0.9965752363204956
ep25_train_time 28.38033652305603
Test Epoch25 layer0 Acc 0.9105263157894737, AUC 0.9789252281188965, avg_entr 0.0405920073390007
ep25_l0_test_time 0.09691452980041504
Test Epoch25 layer1 Acc 0.905921052631579, AUC 0.9711947441101074, avg_entr 0.015251599252223969
ep25_l1_test_time 0.15532159805297852
Test Epoch25 layer2 Acc 0.9039473684210526, AUC 0.9703055620193481, avg_entr 0.010051499120891094
ep25_l2_test_time 0.21416950225830078
Test Epoch25 layer3 Acc 0.9039473684210526, AUC 0.9698112607002258, avg_entr 0.008673272095620632
ep25_l3_test_time 0.2730116844177246
Test Epoch25 layer4 Acc 0.9039473684210526, AUC 0.968988299369812, avg_entr 0.007456084247678518
ep25_l4_test_time 0.33167552947998047
gc 0
Train Epoch26 Acc 0.9756916666666666 (117083/120000), AUC 0.9966317415237427
ep26_train_time 28.38753914833069
Test Epoch26 layer0 Acc 0.9105263157894737, AUC 0.9789341688156128, avg_entr 0.04035645350813866
ep26_l0_test_time 0.09684467315673828
Test Epoch26 layer1 Acc 0.9055921052631579, AUC 0.9712088108062744, avg_entr 0.01518324762582779
ep26_l1_test_time 0.1550886631011963
Test Epoch26 layer2 Acc 0.9037828947368421, AUC 0.9697491526603699, avg_entr 0.010024162009358406
ep26_l2_test_time 0.21396493911743164
Test Epoch26 layer3 Acc 0.9034539473684211, AUC 0.9686855673789978, avg_entr 0.00879896990954876
ep26_l3_test_time 0.27245664596557617
Test Epoch26 layer4 Acc 0.9036184210526316, AUC 0.9675259590148926, avg_entr 0.007615228649228811
ep26_l4_test_time 0.3320643901824951
gc 0
Train Epoch27 Acc 0.9757916666666666 (117095/120000), AUC 0.9966540932655334
ep27_train_time 28.293557167053223
Test Epoch27 layer0 Acc 0.9103618421052632, AUC 0.9789302945137024, avg_entr 0.04008838161826134
ep27_l0_test_time 0.09713006019592285
Test Epoch27 layer1 Acc 0.9055921052631579, AUC 0.9712877869606018, avg_entr 0.01501461211591959
ep27_l1_test_time 0.15524530410766602
Test Epoch27 layer2 Acc 0.9042763157894737, AUC 0.9703827500343323, avg_entr 0.009920704178512096
ep27_l2_test_time 0.21367740631103516
Test Epoch27 layer3 Acc 0.9046052631578947, AUC 0.9696453213691711, avg_entr 0.008575384505093098
ep27_l3_test_time 0.2732264995574951
Test Epoch27 layer4 Acc 0.9039473684210526, AUC 0.9680895805358887, avg_entr 0.0073742736130952835
ep27_l4_test_time 0.33142876625061035
gc 0
Train Epoch28 Acc 0.9756583333333333 (117079/120000), AUC 0.996705174446106
ep28_train_time 28.43707013130188
Test Epoch28 layer0 Acc 0.9101973684210526, AUC 0.9789297580718994, avg_entr 0.039972301572561264
ep28_l0_test_time 0.09604692459106445
Test Epoch28 layer1 Acc 0.9057565789473684, AUC 0.9713078141212463, avg_entr 0.014844382181763649
ep28_l1_test_time 0.15512585639953613
Test Epoch28 layer2 Acc 0.9042763157894737, AUC 0.9703398942947388, avg_entr 0.009840196929872036
ep28_l2_test_time 0.21428728103637695
Test Epoch28 layer3 Acc 0.9039473684210526, AUC 0.96952885389328, avg_entr 0.008566834032535553
ep28_l3_test_time 0.2728445529937744
Test Epoch28 layer4 Acc 0.9041118421052632, AUC 0.9686963558197021, avg_entr 0.007523995358496904
ep28_l4_test_time 0.3318777084350586
gc 0
Train Epoch29 Acc 0.975825 (117099/120000), AUC 0.9966449737548828
ep29_train_time 28.23990273475647
Test Epoch29 layer0 Acc 0.9103618421052632, AUC 0.9789323806762695, avg_entr 0.039739519357681274
ep29_l0_test_time 0.09664320945739746
Test Epoch29 layer1 Acc 0.9055921052631579, AUC 0.9710966944694519, avg_entr 0.014929934404790401
ep29_l1_test_time 0.1550450325012207
Test Epoch29 layer2 Acc 0.9029605263157895, AUC 0.969672679901123, avg_entr 0.009794855490326881
ep29_l2_test_time 0.21394038200378418
Test Epoch29 layer3 Acc 0.9029605263157895, AUC 0.9684884548187256, avg_entr 0.00849097315222025
ep29_l3_test_time 0.2722914218902588
Test Epoch29 layer4 Acc 0.9027960526315789, AUC 0.9671421051025391, avg_entr 0.007440355606377125
ep29_l4_test_time 0.3317549228668213
gc 0
Train Epoch30 Acc 0.9759166666666667 (117110/120000), AUC 0.9965530633926392
ep30_train_time 28.128740072250366
Test Epoch30 layer0 Acc 0.9101973684210526, AUC 0.9789272546768188, avg_entr 0.039705295115709305
ep30_l0_test_time 0.0975961685180664
Test Epoch30 layer1 Acc 0.9060855263157894, AUC 0.9711239337921143, avg_entr 0.014785140752792358
ep30_l1_test_time 0.15513229370117188
Test Epoch30 layer2 Acc 0.9036184210526316, AUC 0.9700479507446289, avg_entr 0.009738404303789139
ep30_l2_test_time 0.21442627906799316
Test Epoch30 layer3 Acc 0.9034539473684211, AUC 0.969157338142395, avg_entr 0.008461466990411282
ep30_l3_test_time 0.27376699447631836
Test Epoch30 layer4 Acc 0.9032894736842105, AUC 0.9680062532424927, avg_entr 0.007385685574263334
ep30_l4_test_time 0.33225512504577637
gc 0
Train Epoch31 Acc 0.9762 (117144/120000), AUC 0.9966784715652466
ep31_train_time 28.65606379508972
Test Epoch31 layer0 Acc 0.9101973684210526, AUC 0.9789068698883057, avg_entr 0.03962048143148422
ep31_l0_test_time 0.096649169921875
Test Epoch31 layer1 Acc 0.905921052631579, AUC 0.9710930585861206, avg_entr 0.014626892283558846
ep31_l1_test_time 0.15458154678344727
Test Epoch31 layer2 Acc 0.9050986842105263, AUC 0.9701294898986816, avg_entr 0.00971846841275692
ep31_l2_test_time 0.21381020545959473
Test Epoch31 layer3 Acc 0.9050986842105263, AUC 0.9686042666435242, avg_entr 0.008457436226308346
ep31_l3_test_time 0.2732970714569092
Test Epoch31 layer4 Acc 0.9046052631578947, AUC 0.9671568870544434, avg_entr 0.007315283175557852
ep31_l4_test_time 0.33231234550476074
gc 0
Train Epoch32 Acc 0.9760083333333334 (117121/120000), AUC 0.9967491030693054
ep32_train_time 28.348779439926147
Test Epoch32 layer0 Acc 0.9105263157894737, AUC 0.9789203405380249, avg_entr 0.03949625790119171
ep32_l0_test_time 0.10152053833007812
Test Epoch32 layer1 Acc 0.9060855263157894, AUC 0.9710439443588257, avg_entr 0.01478059682995081
ep32_l1_test_time 0.1598191261291504
Test Epoch32 layer2 Acc 0.9039473684210526, AUC 0.9696727395057678, avg_entr 0.009687925688922405
ep32_l2_test_time 0.22113680839538574
Test Epoch32 layer3 Acc 0.9036184210526316, AUC 0.9685474038124084, avg_entr 0.008422493934631348
ep32_l3_test_time 0.2792825698852539
Test Epoch32 layer4 Acc 0.9034539473684211, AUC 0.9670330286026001, avg_entr 0.007287260610610247
ep32_l4_test_time 0.33757615089416504
gc 0
Train Epoch33 Acc 0.9761666666666666 (117140/120000), AUC 0.9966984391212463
ep33_train_time 28.54297399520874
Test Epoch33 layer0 Acc 0.9103618421052632, AUC 0.9789035320281982, avg_entr 0.03949867933988571
ep33_l0_test_time 0.12760138511657715
Test Epoch33 layer1 Acc 0.9060855263157894, AUC 0.9710806012153625, avg_entr 0.014718261547386646
ep33_l1_test_time 0.1906416416168213
Test Epoch33 layer2 Acc 0.9044407894736842, AUC 0.9700246453285217, avg_entr 0.009655145928263664
ep33_l2_test_time 0.25340867042541504
Test Epoch33 layer3 Acc 0.9039473684210526, AUC 0.9690366983413696, avg_entr 0.008387597277760506
ep33_l3_test_time 0.31574034690856934
Test Epoch33 layer4 Acc 0.9042763157894737, AUC 0.9675389528274536, avg_entr 0.007288552355021238
ep33_l4_test_time 0.3788120746612549
gc 0
Train Epoch34 Acc 0.9759833333333333 (117118/120000), AUC 0.9967235922813416
ep34_train_time 30.94764280319214
Test Epoch34 layer0 Acc 0.9103618421052632, AUC 0.9789093732833862, avg_entr 0.03943941369652748
ep34_l0_test_time 0.12558555603027344
Test Epoch34 layer1 Acc 0.9057565789473684, AUC 0.9711177349090576, avg_entr 0.01478305272758007
ep34_l1_test_time 0.18941783905029297
Test Epoch34 layer2 Acc 0.9041118421052632, AUC 0.9698724746704102, avg_entr 0.009642518125474453
ep34_l2_test_time 0.25280213356018066
Test Epoch34 layer3 Acc 0.9036184210526316, AUC 0.9692248702049255, avg_entr 0.008338159881532192
ep34_l3_test_time 0.31456947326660156
Test Epoch34 layer4 Acc 0.9036184210526316, AUC 0.9680476784706116, avg_entr 0.007235855329781771
ep34_l4_test_time 0.377025842666626
gc 0
Train Epoch35 Acc 0.976075 (117129/120000), AUC 0.996645450592041
ep35_train_time 30.140744924545288
Test Epoch35 layer0 Acc 0.9105263157894737, AUC 0.9789081811904907, avg_entr 0.03941652923822403
ep35_l0_test_time 0.19379329681396484
Test Epoch35 layer1 Acc 0.9060855263157894, AUC 0.9710923433303833, avg_entr 0.014727802015841007
ep35_l1_test_time 0.1852879524230957
Test Epoch35 layer2 Acc 0.9044407894736842, AUC 0.9699108600616455, avg_entr 0.009622403420507908
ep35_l2_test_time 0.24643898010253906
Test Epoch35 layer3 Acc 0.9039473684210526, AUC 0.9686537981033325, avg_entr 0.008337563835084438
ep35_l3_test_time 0.30875420570373535
Test Epoch35 layer4 Acc 0.9041118421052632, AUC 0.9674099683761597, avg_entr 0.007264018524438143
ep35_l4_test_time 0.3693063259124756
gc 0
Train Epoch36 Acc 0.9761583333333334 (117139/120000), AUC 0.9967283606529236
ep36_train_time 29.568292379379272
Test Epoch36 layer0 Acc 0.9103618421052632, AUC 0.9789018630981445, avg_entr 0.03934964910149574
ep36_l0_test_time 0.1250166893005371
Test Epoch36 layer1 Acc 0.9060855263157894, AUC 0.9710496664047241, avg_entr 0.014701290987432003
ep36_l1_test_time 0.18860626220703125
Test Epoch36 layer2 Acc 0.9041118421052632, AUC 0.9698548913002014, avg_entr 0.009618544951081276
ep36_l2_test_time 0.2516140937805176
Test Epoch36 layer3 Acc 0.9039473684210526, AUC 0.9688857197761536, avg_entr 0.008337615989148617
ep36_l3_test_time 0.31277894973754883
Test Epoch36 layer4 Acc 0.9039473684210526, AUC 0.9675859808921814, avg_entr 0.0072806295938789845
ep36_l4_test_time 0.3767366409301758
gc 0
Train Epoch37 Acc 0.9763666666666667 (117164/120000), AUC 0.9967408776283264
ep37_train_time 30.06781029701233
Test Epoch37 layer0 Acc 0.9100328947368421, AUC 0.9788968563079834, avg_entr 0.039381444454193115
ep37_l0_test_time 0.12774372100830078
Test Epoch37 layer1 Acc 0.9057565789473684, AUC 0.9709886312484741, avg_entr 0.01470281183719635
ep37_l1_test_time 0.1894989013671875
Test Epoch37 layer2 Acc 0.9046052631578947, AUC 0.9699904918670654, avg_entr 0.009612500667572021
ep37_l2_test_time 0.25161266326904297
Test Epoch37 layer3 Acc 0.9044407894736842, AUC 0.9689249992370605, avg_entr 0.008294754661619663
ep37_l3_test_time 0.31435561180114746
Test Epoch37 layer4 Acc 0.9042763157894737, AUC 0.9677425622940063, avg_entr 0.007210880983620882
ep37_l4_test_time 0.3763706684112549
gc 0
Train Epoch38 Acc 0.9761833333333333 (117142/120000), AUC 0.9966999292373657
ep38_train_time 29.72448754310608
Test Epoch38 layer0 Acc 0.9103618421052632, AUC 0.9789007902145386, avg_entr 0.039343904703855515
ep38_l0_test_time 0.1884915828704834
Test Epoch38 layer1 Acc 0.905921052631579, AUC 0.9710498452186584, avg_entr 0.014693956822156906
ep38_l1_test_time 0.18905949592590332
Test Epoch38 layer2 Acc 0.9046052631578947, AUC 0.9697754979133606, avg_entr 0.009593198075890541
ep38_l2_test_time 0.25113821029663086
Test Epoch38 layer3 Acc 0.9042763157894737, AUC 0.9688606262207031, avg_entr 0.008286346681416035
ep38_l3_test_time 0.3131072521209717
Test Epoch38 layer4 Acc 0.9041118421052632, AUC 0.967563271522522, avg_entr 0.007202341221272945
ep38_l4_test_time 0.37546467781066895
gc 0
Train Epoch39 Acc 0.9760583333333334 (117127/120000), AUC 0.9966518878936768
ep39_train_time 31.01278328895569
Test Epoch39 layer0 Acc 0.9103618421052632, AUC 0.9788947105407715, avg_entr 0.03928299620747566
ep39_l0_test_time 0.1330242156982422
Test Epoch39 layer1 Acc 0.9060855263157894, AUC 0.9710630774497986, avg_entr 0.01467289961874485
ep39_l1_test_time 0.18936467170715332
Test Epoch39 layer2 Acc 0.9046052631578947, AUC 0.9698201417922974, avg_entr 0.009585562162101269
ep39_l2_test_time 0.2590949535369873
Test Epoch39 layer3 Acc 0.9044407894736842, AUC 0.9688777327537537, avg_entr 0.008287946693599224
ep39_l3_test_time 0.32193589210510254
Test Epoch39 layer4 Acc 0.9041118421052632, AUC 0.9674645662307739, avg_entr 0.007211573421955109
ep39_l4_test_time 0.3838479518890381
gc 0
Train Epoch40 Acc 0.97615 (117138/120000), AUC 0.9967010021209717
ep40_train_time 29.268842935562134
Test Epoch40 layer0 Acc 0.9105263157894737, AUC 0.9788941144943237, avg_entr 0.039277348667383194
ep40_l0_test_time 0.1253795623779297
Test Epoch40 layer1 Acc 0.9060855263157894, AUC 0.9710090160369873, avg_entr 0.014667907729744911
ep40_l1_test_time 0.18876004219055176
Test Epoch40 layer2 Acc 0.9046052631578947, AUC 0.9698799252510071, avg_entr 0.009591001085937023
ep40_l2_test_time 0.25197362899780273
Test Epoch40 layer3 Acc 0.9044407894736842, AUC 0.968782901763916, avg_entr 0.008290558122098446
ep40_l3_test_time 0.31458020210266113
Test Epoch40 layer4 Acc 0.9041118421052632, AUC 0.9674512147903442, avg_entr 0.007213090546429157
ep40_l4_test_time 0.3760371208190918
gc 0
Train Epoch41 Acc 0.9760416666666667 (117125/120000), AUC 0.9967219829559326
ep41_train_time 30.175665616989136
Test Epoch41 layer0 Acc 0.9105263157894737, AUC 0.9788939356803894, avg_entr 0.0392669253051281
ep41_l0_test_time 0.12913870811462402
Test Epoch41 layer1 Acc 0.9060855263157894, AUC 0.9710504412651062, avg_entr 0.014678239822387695
ep41_l1_test_time 0.19669246673583984
Test Epoch41 layer2 Acc 0.9046052631578947, AUC 0.9698525071144104, avg_entr 0.009586005471646786
ep41_l2_test_time 0.2582075595855713
Test Epoch41 layer3 Acc 0.9044407894736842, AUC 0.9688517451286316, avg_entr 0.008288503624498844
ep41_l3_test_time 0.32042908668518066
Test Epoch41 layer4 Acc 0.9041118421052632, AUC 0.9675358533859253, avg_entr 0.007216339465230703
ep41_l4_test_time 0.38271284103393555
gc 0
Train Epoch42 Acc 0.9763 (117156/120000), AUC 0.9966995716094971
ep42_train_time 30.227070093154907
Test Epoch42 layer0 Acc 0.9105263157894737, AUC 0.9789013266563416, avg_entr 0.03926752135157585
ep42_l0_test_time 0.1268310546875
Test Epoch42 layer1 Acc 0.9057565789473684, AUC 0.9710224270820618, avg_entr 0.014681209810078144
ep42_l1_test_time 0.21535634994506836
Test Epoch42 layer2 Acc 0.9046052631578947, AUC 0.9698714017868042, avg_entr 0.009584330022335052
ep42_l2_test_time 0.2790088653564453
Test Epoch42 layer3 Acc 0.9042763157894737, AUC 0.9689347743988037, avg_entr 0.008285246789455414
ep42_l3_test_time 0.3413259983062744
Test Epoch42 layer4 Acc 0.9041118421052632, AUC 0.9676523208618164, avg_entr 0.007212858647108078
ep42_l4_test_time 0.40419840812683105
gc 0
Train Epoch43 Acc 0.9760333333333333 (117124/120000), AUC 0.9966706037521362
ep43_train_time 30.01021957397461
Test Epoch43 layer0 Acc 0.9105263157894737, AUC 0.9789007306098938, avg_entr 0.039246298372745514
ep43_l0_test_time 0.13381385803222656
Test Epoch43 layer1 Acc 0.905921052631579, AUC 0.9710183143615723, avg_entr 0.014666329137980938
ep43_l1_test_time 0.19362115859985352
Test Epoch43 layer2 Acc 0.9046052631578947, AUC 0.9698527455329895, avg_entr 0.00957810040563345
ep43_l2_test_time 0.2588639259338379
Test Epoch43 layer3 Acc 0.9044407894736842, AUC 0.968921422958374, avg_entr 0.00828581117093563
ep43_l3_test_time 0.3209981918334961
Test Epoch43 layer4 Acc 0.9041118421052632, AUC 0.9675774574279785, avg_entr 0.007226395420730114
ep43_l4_test_time 0.3828279972076416
gc 0
Train Epoch44 Acc 0.9763083333333333 (117157/120000), AUC 0.9966559410095215
ep44_train_time 29.609355449676514
Test Epoch44 layer0 Acc 0.9105263157894737, AUC 0.9788993000984192, avg_entr 0.03924524411559105
ep44_l0_test_time 0.12546157836914062
Test Epoch44 layer1 Acc 0.9057565789473684, AUC 0.9709947109222412, avg_entr 0.014671005308628082
ep44_l1_test_time 0.18943142890930176
Test Epoch44 layer2 Acc 0.9046052631578947, AUC 0.9698610901832581, avg_entr 0.009574523195624352
ep44_l2_test_time 0.27197933197021484
Test Epoch44 layer3 Acc 0.9042763157894737, AUC 0.9688302278518677, avg_entr 0.008279022760689259
ep44_l3_test_time 0.38724184036254883
Test Epoch44 layer4 Acc 0.9039473684210526, AUC 0.9674832224845886, avg_entr 0.007218745071440935
ep44_l4_test_time 0.4500577449798584
gc 0
Train Epoch45 Acc 0.9760833333333333 (117130/120000), AUC 0.9967095255851746
ep45_train_time 32.34622287750244
Test Epoch45 layer0 Acc 0.9103618421052632, AUC 0.9788991808891296, avg_entr 0.039238158613443375
ep45_l0_test_time 0.12570452690124512
Test Epoch45 layer1 Acc 0.9057565789473684, AUC 0.9710232615470886, avg_entr 0.014667492359876633
ep45_l1_test_time 0.18033933639526367
Test Epoch45 layer2 Acc 0.9046052631578947, AUC 0.9698470234870911, avg_entr 0.00957356858998537
ep45_l2_test_time 0.2592902183532715
Test Epoch45 layer3 Acc 0.9041118421052632, AUC 0.9688757658004761, avg_entr 0.008283795788884163
ep45_l3_test_time 0.3710472583770752
Test Epoch45 layer4 Acc 0.9039473684210526, AUC 0.9675110578536987, avg_entr 0.007227886468172073
ep45_l4_test_time 0.3764524459838867
gc 0
Train Epoch46 Acc 0.9760083333333334 (117121/120000), AUC 0.9966945052146912
ep46_train_time 29.55686068534851
Test Epoch46 layer0 Acc 0.9105263157894737, AUC 0.978900134563446, avg_entr 0.03923128917813301
ep46_l0_test_time 0.1264193058013916
Test Epoch46 layer1 Acc 0.9057565789473684, AUC 0.9710274934768677, avg_entr 0.014659241773188114
ep46_l1_test_time 0.21591687202453613
Test Epoch46 layer2 Acc 0.9046052631578947, AUC 0.969814658164978, avg_entr 0.009565536864101887
ep46_l2_test_time 0.27991533279418945
Test Epoch46 layer3 Acc 0.9044407894736842, AUC 0.9688730239868164, avg_entr 0.008267974480986595
ep46_l3_test_time 0.34229278564453125
Test Epoch46 layer4 Acc 0.9041118421052632, AUC 0.9674851894378662, avg_entr 0.007208177819848061
ep46_l4_test_time 0.40473508834838867
gc 0
Train Epoch47 Acc 0.9762333333333333 (117148/120000), AUC 0.996709942817688
ep47_train_time 30.634493589401245
Test Epoch47 layer0 Acc 0.9105263157894737, AUC 0.9788900017738342, avg_entr 0.03922518342733383
ep47_l0_test_time 0.125227689743042
Test Epoch47 layer1 Acc 0.9057565789473684, AUC 0.9710203409194946, avg_entr 0.014656617306172848
ep47_l1_test_time 0.18853545188903809
Test Epoch47 layer2 Acc 0.9046052631578947, AUC 0.9698296189308167, avg_entr 0.009564713574945927
ep47_l2_test_time 0.2512474060058594
Test Epoch47 layer3 Acc 0.9044407894736842, AUC 0.9688518643379211, avg_entr 0.00826864130795002
ep47_l3_test_time 0.31310105323791504
Test Epoch47 layer4 Acc 0.9041118421052632, AUC 0.9674341678619385, avg_entr 0.007212604396045208
ep47_l4_test_time 0.37488889694213867
gc 0
Train Epoch48 Acc 0.9761833333333333 (117142/120000), AUC 0.9966946840286255
ep48_train_time 30.82136583328247
Test Epoch48 layer0 Acc 0.9105263157894737, AUC 0.9788901209831238, avg_entr 0.03922639414668083
ep48_l0_test_time 0.12498092651367188
Test Epoch48 layer1 Acc 0.9057565789473684, AUC 0.9710026979446411, avg_entr 0.014657258987426758
ep48_l1_test_time 0.18821287155151367
Test Epoch48 layer2 Acc 0.9046052631578947, AUC 0.9698276519775391, avg_entr 0.009562903083860874
ep48_l2_test_time 0.2503187656402588
Test Epoch48 layer3 Acc 0.9044407894736842, AUC 0.9688478708267212, avg_entr 0.008265769109129906
ep48_l3_test_time 0.31215882301330566
Test Epoch48 layer4 Acc 0.9041118421052632, AUC 0.9674273133277893, avg_entr 0.007209030445665121
ep48_l4_test_time 0.3742861747741699
gc 0
Train Epoch49 Acc 0.9761166666666666 (117134/120000), AUC 0.9967527389526367
ep49_train_time 29.879175186157227
Test Epoch49 layer0 Acc 0.9105263157894737, AUC 0.9788902997970581, avg_entr 0.039223235100507736
ep49_l0_test_time 0.12224578857421875
Test Epoch49 layer1 Acc 0.9057565789473684, AUC 0.9709972739219666, avg_entr 0.014656552113592625
ep49_l1_test_time 0.18364763259887695
Test Epoch49 layer2 Acc 0.9046052631578947, AUC 0.9698265790939331, avg_entr 0.009563629515469074
ep49_l2_test_time 0.24632930755615234
Test Epoch49 layer3 Acc 0.9042763157894737, AUC 0.9688472151756287, avg_entr 0.008265732787549496
ep49_l3_test_time 0.307450532913208
Test Epoch49 layer4 Acc 0.9041118421052632, AUC 0.9674158096313477, avg_entr 0.007209583185613155
ep49_l4_test_time 0.3685595989227295
Best AUC 0.9825930595397949
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_transformeral_l5_pad50//ag_news_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.9269736842105263, AUC 0.9866469502449036, avg_entr 0.10938546061515808
ep49_l0_test_time 0.03300595283508301
Test Epoch49 layer1 Acc 0.9296052631578947, AUC 0.9874044060707092, avg_entr 0.05111890658736229
ep49_l1_test_time 0.04800844192504883
Test Epoch49 layer2 Acc 0.9296052631578947, AUC 0.9878716468811035, avg_entr 0.04013402387499809
ep49_l2_test_time 0.06349396705627441
Test Epoch49 layer3 Acc 0.9282894736842106, AUC 0.9877987504005432, avg_entr 0.036887601017951965
ep49_l3_test_time 0.07894539833068848
Test Epoch49 layer4 Acc 0.9289473684210526, AUC 0.987666130065918, avg_entr 0.035732612013816833
ep49_l4_test_time 0.09427523612976074
