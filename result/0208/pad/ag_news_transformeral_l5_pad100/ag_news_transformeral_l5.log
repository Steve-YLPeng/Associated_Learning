total count words 102019
vocab size 30000
found 26754 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13672292
Start Training
gc 0
Train Epoch0 Acc 0.6265833333333334 (75190/120000), AUC 0.8560295701026917
ep0_train_time 48.09804940223694
Test Epoch0 layer0 Acc 0.9075657894736842, AUC 0.9761558175086975, avg_entr 0.23196187615394592
ep0_l0_test_time 0.16180014610290527
Save ckpt to ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9085526315789474, AUC 0.9780347347259521, avg_entr 0.1602315455675125
ep0_l1_test_time 0.27625346183776855
Save ckpt to ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.9085526315789474, AUC 0.9780933260917664, avg_entr 0.15617233514785767
ep0_l2_test_time 0.3945491313934326
Save ckpt to ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer3 Acc 0.9087171052631579, AUC 0.9782906770706177, avg_entr 0.15069197118282318
ep0_l3_test_time 0.5083153247833252
Save ckpt to ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer4 Acc 0.9083881578947368, AUC 0.9783009886741638, avg_entr 0.15047051012516022
ep0_l4_test_time 0.6192703247070312
Save ckpt to ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.9242333333333334 (110908/120000), AUC 0.9828187823295593
ep1_train_time 47.74187517166138
Test Epoch1 layer0 Acc 0.9110197368421052, AUC 0.9790912866592407, avg_entr 0.1387377828359604
ep1_l0_test_time 0.16055965423583984
Save ckpt to ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.915296052631579, AUC 0.9805620908737183, avg_entr 0.08393792808055878
ep1_l1_test_time 0.2771120071411133
Save ckpt to ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.9159539473684211, AUC 0.9801412224769592, avg_entr 0.06865350157022476
ep1_l2_test_time 0.39292335510253906
Test Epoch1 layer3 Acc 0.9154605263157894, AUC 0.9805288314819336, avg_entr 0.06371529400348663
ep1_l3_test_time 0.5042352676391602
Test Epoch1 layer4 Acc 0.9148026315789474, AUC 0.9801069498062134, avg_entr 0.06352831423282623
ep1_l4_test_time 0.6175942420959473
gc 0
Train Epoch2 Acc 0.9374583333333333 (112495/120000), AUC 0.9871846437454224
ep2_train_time 47.74462556838989
Test Epoch2 layer0 Acc 0.9146381578947368, AUC 0.9801855683326721, avg_entr 0.1129426434636116
ep2_l0_test_time 0.160447359085083
Test Epoch2 layer1 Acc 0.9167763157894737, AUC 0.9806234836578369, avg_entr 0.047524772584438324
ep2_l1_test_time 0.2756688594818115
Save ckpt to ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt  ,ep 2
Test Epoch2 layer2 Acc 0.9167763157894737, AUC 0.9814703464508057, avg_entr 0.03944845125079155
ep2_l2_test_time 0.3954436779022217
Save ckpt to ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt  ,ep 2
Test Epoch2 layer3 Acc 0.9167763157894737, AUC 0.9815223217010498, avg_entr 0.038020145148038864
ep2_l3_test_time 0.5073492527008057
Save ckpt to ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt  ,ep 2
Test Epoch2 layer4 Acc 0.9164473684210527, AUC 0.9813516139984131, avg_entr 0.03665415197610855
ep2_l4_test_time 0.6208860874176025
gc 0
Train Epoch3 Acc 0.9451333333333334 (113416/120000), AUC 0.9895910620689392
ep3_train_time 47.77363967895508
Test Epoch3 layer0 Acc 0.9154605263157894, AUC 0.9807068109512329, avg_entr 0.09036482870578766
ep3_l0_test_time 0.1604018211364746
Test Epoch3 layer1 Acc 0.9159539473684211, AUC 0.978567361831665, avg_entr 0.03350437805056572
ep3_l1_test_time 0.2758057117462158
Test Epoch3 layer2 Acc 0.9161184210526315, AUC 0.9795579314231873, avg_entr 0.026912840083241463
ep3_l2_test_time 0.3914468288421631
Test Epoch3 layer3 Acc 0.9167763157894737, AUC 0.9788787364959717, avg_entr 0.02499583177268505
ep3_l3_test_time 0.5051522254943848
Test Epoch3 layer4 Acc 0.9166118421052631, AUC 0.9794603586196899, avg_entr 0.02313242293894291
ep3_l4_test_time 0.6177592277526855
gc 0
Train Epoch4 Acc 0.950675 (114081/120000), AUC 0.9910743236541748
ep4_train_time 47.73690748214722
Test Epoch4 layer0 Acc 0.9129934210526316, AUC 0.9807379245758057, avg_entr 0.08149770647287369
ep4_l0_test_time 0.15984177589416504
Test Epoch4 layer1 Acc 0.9151315789473684, AUC 0.9784702062606812, avg_entr 0.029647264629602432
ep4_l1_test_time 0.2761554718017578
Test Epoch4 layer2 Acc 0.9139802631578947, AUC 0.979649543762207, avg_entr 0.024744747206568718
ep4_l2_test_time 0.39205169677734375
Test Epoch4 layer3 Acc 0.9138157894736842, AUC 0.9795422554016113, avg_entr 0.023213684558868408
ep4_l3_test_time 0.5041086673736572
Test Epoch4 layer4 Acc 0.9136513157894737, AUC 0.9806084632873535, avg_entr 0.021698473021388054
ep4_l4_test_time 0.6180827617645264
gc 0
Train Epoch5 Acc 0.9540333333333333 (114484/120000), AUC 0.9922062158584595
ep5_train_time 47.865395069122314
Test Epoch5 layer0 Acc 0.9164473684210527, AUC 0.9806760549545288, avg_entr 0.07576780021190643
ep5_l0_test_time 0.15942716598510742
Test Epoch5 layer1 Acc 0.9136513157894737, AUC 0.9770193099975586, avg_entr 0.02620851621031761
ep5_l1_test_time 0.27546238899230957
Test Epoch5 layer2 Acc 0.9126644736842106, AUC 0.9799553155899048, avg_entr 0.021026551723480225
ep5_l2_test_time 0.3910939693450928
Test Epoch5 layer3 Acc 0.912828947368421, AUC 0.9805825352668762, avg_entr 0.019925573840737343
ep5_l3_test_time 0.5043690204620361
Test Epoch5 layer4 Acc 0.9133223684210526, AUC 0.9801200032234192, avg_entr 0.018373310565948486
ep5_l4_test_time 0.6167213916778564
gc 0
Train Epoch6 Acc 0.957675 (114921/120000), AUC 0.9930537939071655
ep6_train_time 48.724175453186035
Test Epoch6 layer0 Acc 0.9164473684210527, AUC 0.9803218841552734, avg_entr 0.06803257763385773
ep6_l0_test_time 0.19518232345581055
Test Epoch6 layer1 Acc 0.9116776315789473, AUC 0.9754968881607056, avg_entr 0.02322136051952839
ep6_l1_test_time 0.31694793701171875
Test Epoch6 layer2 Acc 0.9110197368421052, AUC 0.978611946105957, avg_entr 0.017440682277083397
ep6_l2_test_time 0.4364044666290283
Test Epoch6 layer3 Acc 0.9115131578947369, AUC 0.9789267778396606, avg_entr 0.016074106097221375
ep6_l3_test_time 0.5559110641479492
Test Epoch6 layer4 Acc 0.9116776315789473, AUC 0.9790716767311096, avg_entr 0.014771209098398685
ep6_l4_test_time 0.6684677600860596
gc 0
Train Epoch7 Acc 0.9596916666666667 (115163/120000), AUC 0.9936034679412842
ep7_train_time 49.25028896331787
Test Epoch7 layer0 Acc 0.9141447368421053, AUC 0.9801058769226074, avg_entr 0.06400332599878311
ep7_l0_test_time 0.19431138038635254
Test Epoch7 layer1 Acc 0.9125, AUC 0.9758825898170471, avg_entr 0.0212703924626112
ep7_l1_test_time 0.40343189239501953
Test Epoch7 layer2 Acc 0.9133223684210526, AUC 0.9785350561141968, avg_entr 0.015820488333702087
ep7_l2_test_time 0.436596155166626
Test Epoch7 layer3 Acc 0.9133223684210526, AUC 0.9790126085281372, avg_entr 0.014736001379787922
ep7_l3_test_time 0.5558140277862549
Test Epoch7 layer4 Acc 0.9131578947368421, AUC 0.9797082543373108, avg_entr 0.013268908485770226
ep7_l4_test_time 0.6686818599700928
gc 0
Train Epoch8 Acc 0.9628583333333334 (115543/120000), AUC 0.9943656325340271
ep8_train_time 49.29784822463989
Test Epoch8 layer0 Acc 0.9138157894736842, AUC 0.9801057577133179, avg_entr 0.06147891655564308
ep8_l0_test_time 0.25764966011047363
Test Epoch8 layer1 Acc 0.9126644736842106, AUC 0.9724566340446472, avg_entr 0.02199608087539673
ep8_l1_test_time 0.3752148151397705
Test Epoch8 layer2 Acc 0.9121710526315789, AUC 0.9739735126495361, avg_entr 0.016492631286382675
ep8_l2_test_time 0.5035598278045654
Test Epoch8 layer3 Acc 0.9120065789473685, AUC 0.9750424027442932, avg_entr 0.015263809822499752
ep8_l3_test_time 0.6161034107208252
Test Epoch8 layer4 Acc 0.9115131578947369, AUC 0.9755148887634277, avg_entr 0.013743902556598186
ep8_l4_test_time 0.7383041381835938
gc 0
Train Epoch9 Acc 0.9642833333333334 (115714/120000), AUC 0.9946765899658203
ep9_train_time 50.60008192062378
Test Epoch9 layer0 Acc 0.9146381578947368, AUC 0.9800529479980469, avg_entr 0.059532277286052704
ep9_l0_test_time 0.19449114799499512
Test Epoch9 layer1 Acc 0.9103618421052632, AUC 0.9730277061462402, avg_entr 0.020827511325478554
ep9_l1_test_time 0.3160994052886963
Test Epoch9 layer2 Acc 0.9095394736842105, AUC 0.9759758114814758, avg_entr 0.015243728645145893
ep9_l2_test_time 0.43576860427856445
Test Epoch9 layer3 Acc 0.9085526315789474, AUC 0.9770899415016174, avg_entr 0.013928767293691635
ep9_l3_test_time 0.5535483360290527
Test Epoch9 layer4 Acc 0.9090460526315789, AUC 0.9772432446479797, avg_entr 0.012348286807537079
ep9_l4_test_time 0.6674678325653076
gc 0
Train Epoch10 Acc 0.965725 (115887/120000), AUC 0.9951575994491577
ep10_train_time 49.33856725692749
Test Epoch10 layer0 Acc 0.9138157894736842, AUC 0.9799476861953735, avg_entr 0.05603982135653496
ep10_l0_test_time 0.1952650547027588
Test Epoch10 layer1 Acc 0.9108552631578948, AUC 0.9717482328414917, avg_entr 0.019351080060005188
ep10_l1_test_time 0.31622314453125
Test Epoch10 layer2 Acc 0.9108552631578948, AUC 0.9746550917625427, avg_entr 0.013631408102810383
ep10_l2_test_time 0.43630075454711914
Test Epoch10 layer3 Acc 0.9108552631578948, AUC 0.9760380983352661, avg_entr 0.012249399907886982
ep10_l3_test_time 0.5555875301361084
Test Epoch10 layer4 Acc 0.9110197368421052, AUC 0.9764756560325623, avg_entr 0.011240768246352673
ep10_l4_test_time 0.6702046394348145
gc 0
Train Epoch11 Acc 0.9666333333333333 (115996/120000), AUC 0.9951937198638916
ep11_train_time 49.062499046325684
Test Epoch11 layer0 Acc 0.9133223684210526, AUC 0.9798181653022766, avg_entr 0.05428985878825188
ep11_l0_test_time 0.29548001289367676
Test Epoch11 layer1 Acc 0.9101973684210526, AUC 0.9709657430648804, avg_entr 0.017920715734362602
ep11_l1_test_time 0.4050590991973877
Test Epoch11 layer2 Acc 0.9098684210526315, AUC 0.9730085134506226, avg_entr 0.012142166495323181
ep11_l2_test_time 0.5224428176879883
Test Epoch11 layer3 Acc 0.9100328947368421, AUC 0.9745009541511536, avg_entr 0.010644646361470222
ep11_l3_test_time 0.5553319454193115
Test Epoch11 layer4 Acc 0.9100328947368421, AUC 0.9754788875579834, avg_entr 0.00943605788052082
ep11_l4_test_time 0.7604472637176514
gc 0
Train Epoch12 Acc 0.9679833333333333 (116158/120000), AUC 0.9956444501876831
ep12_train_time 50.80505919456482
Test Epoch12 layer0 Acc 0.912828947368421, AUC 0.9796968102455139, avg_entr 0.052818167954683304
ep12_l0_test_time 0.2893409729003906
Test Epoch12 layer1 Acc 0.9116776315789473, AUC 0.9711045026779175, avg_entr 0.018420686945319176
ep12_l1_test_time 0.40521955490112305
Test Epoch12 layer2 Acc 0.9098684210526315, AUC 0.9723577499389648, avg_entr 0.013167093507945538
ep12_l2_test_time 0.5211019515991211
Test Epoch12 layer3 Acc 0.9095394736842105, AUC 0.9733821153640747, avg_entr 0.01194838434457779
ep12_l3_test_time 0.6414697170257568
Test Epoch12 layer4 Acc 0.9097039473684211, AUC 0.9747018814086914, avg_entr 0.010553873144090176
ep12_l4_test_time 0.761235237121582
gc 0
Train Epoch13 Acc 0.9688333333333333 (116260/120000), AUC 0.9956477284431458
ep13_train_time 51.774285078048706
Test Epoch13 layer0 Acc 0.9125, AUC 0.9796822667121887, avg_entr 0.05132053792476654
ep13_l0_test_time 0.1953723430633545
Test Epoch13 layer1 Acc 0.9100328947368421, AUC 0.9710354804992676, avg_entr 0.017886120826005936
ep13_l1_test_time 0.3179490566253662
Test Epoch13 layer2 Acc 0.9100328947368421, AUC 0.9718227386474609, avg_entr 0.012783201411366463
ep13_l2_test_time 0.4817068576812744
Test Epoch13 layer3 Acc 0.9092105263157895, AUC 0.9726360440254211, avg_entr 0.011146031320095062
ep13_l3_test_time 0.657170295715332
Test Epoch13 layer4 Acc 0.9088815789473684, AUC 0.972920835018158, avg_entr 0.009957537055015564
ep13_l4_test_time 0.7064411640167236
gc 0
Train Epoch14 Acc 0.9693833333333334 (116326/120000), AUC 0.9958508610725403
ep14_train_time 50.129918336868286
Test Epoch14 layer0 Acc 0.9123355263157895, AUC 0.9795644283294678, avg_entr 0.04953461512923241
ep14_l0_test_time 0.19372272491455078
Test Epoch14 layer1 Acc 0.909375, AUC 0.9707497954368591, avg_entr 0.016668202355504036
ep14_l1_test_time 0.3168814182281494
Test Epoch14 layer2 Acc 0.9097039473684211, AUC 0.971641480922699, avg_entr 0.011606721207499504
ep14_l2_test_time 0.43851280212402344
Test Epoch14 layer3 Acc 0.909375, AUC 0.9725030660629272, avg_entr 0.010258156806230545
ep14_l3_test_time 0.5577974319458008
Test Epoch14 layer4 Acc 0.9097039473684211, AUC 0.9731714725494385, avg_entr 0.009188110940158367
ep14_l4_test_time 0.6710114479064941
gc 0
Train Epoch15 Acc 0.9700166666666666 (116402/120000), AUC 0.9960222244262695
ep15_train_time 49.47335743904114
Test Epoch15 layer0 Acc 0.9126644736842106, AUC 0.9795259237289429, avg_entr 0.04815848916769028
ep15_l0_test_time 0.19550514221191406
Test Epoch15 layer1 Acc 0.9092105263157895, AUC 0.9702497124671936, avg_entr 0.016706494614481926
ep15_l1_test_time 0.31727170944213867
Test Epoch15 layer2 Acc 0.9098684210526315, AUC 0.970970630645752, avg_entr 0.011328690685331821
ep15_l2_test_time 0.5070664882659912
Test Epoch15 layer3 Acc 0.9097039473684211, AUC 0.9718427658081055, avg_entr 0.01004045456647873
ep15_l3_test_time 0.6226706504821777
Test Epoch15 layer4 Acc 0.9098684210526315, AUC 0.972092866897583, avg_entr 0.008969261310994625
ep15_l4_test_time 0.7500734329223633
gc 0
Train Epoch16 Acc 0.970625 (116475/120000), AUC 0.9962087273597717
ep16_train_time 50.03217697143555
Test Epoch16 layer0 Acc 0.9115131578947369, AUC 0.9795163869857788, avg_entr 0.046762410551309586
ep16_l0_test_time 0.19385337829589844
Test Epoch16 layer1 Acc 0.9095394736842105, AUC 0.969254195690155, avg_entr 0.01609073579311371
ep16_l1_test_time 0.31598663330078125
Test Epoch16 layer2 Acc 0.909375, AUC 0.969627320766449, avg_entr 0.010790296830236912
ep16_l2_test_time 0.4345226287841797
Test Epoch16 layer3 Acc 0.9088815789473684, AUC 0.9711432456970215, avg_entr 0.009459009394049644
ep16_l3_test_time 0.5554733276367188
Test Epoch16 layer4 Acc 0.9090460526315789, AUC 0.9724434018135071, avg_entr 0.008326458744704723
ep16_l4_test_time 0.6686689853668213
gc 0
Train Epoch17 Acc 0.9710916666666667 (116531/120000), AUC 0.9961927533149719
ep17_train_time 49.62770915031433
Test Epoch17 layer0 Acc 0.9129934210526316, AUC 0.9795679450035095, avg_entr 0.04527515172958374
ep17_l0_test_time 0.26563334465026855
Test Epoch17 layer1 Acc 0.9092105263157895, AUC 0.9696579575538635, avg_entr 0.015346769243478775
ep17_l1_test_time 0.374356746673584
Test Epoch17 layer2 Acc 0.9095394736842105, AUC 0.9693121910095215, avg_entr 0.009741839952766895
ep17_l2_test_time 0.4672713279724121
Test Epoch17 layer3 Acc 0.9090460526315789, AUC 0.9701975584030151, avg_entr 0.008263916708528996
ep17_l3_test_time 0.5557243824005127
Test Epoch17 layer4 Acc 0.9090460526315789, AUC 0.9701040983200073, avg_entr 0.007594303693622351
ep17_l4_test_time 0.6726527214050293
gc 0
Train Epoch18 Acc 0.9714416666666666 (116573/120000), AUC 0.9961848258972168
ep18_train_time 49.093233823776245
Test Epoch18 layer0 Acc 0.9116776315789473, AUC 0.9794990420341492, avg_entr 0.044292740523815155
ep18_l0_test_time 0.19489431381225586
Test Epoch18 layer1 Acc 0.9083881578947368, AUC 0.9686674475669861, avg_entr 0.015267728827893734
ep18_l1_test_time 0.3171651363372803
Test Epoch18 layer2 Acc 0.9090460526315789, AUC 0.9673323631286621, avg_entr 0.010038674809038639
ep18_l2_test_time 0.43697619438171387
Test Epoch18 layer3 Acc 0.9090460526315789, AUC 0.9686042070388794, avg_entr 0.008899866603314877
ep18_l3_test_time 0.55570387840271
Test Epoch18 layer4 Acc 0.9095394736842105, AUC 0.9695212841033936, avg_entr 0.007986227050423622
ep18_l4_test_time 0.6698513031005859
gc 0
Train Epoch19 Acc 0.9716333333333333 (116596/120000), AUC 0.9963368773460388
ep19_train_time 49.845977544784546
Test Epoch19 layer0 Acc 0.9123355263157895, AUC 0.9795596599578857, avg_entr 0.04320058226585388
ep19_l0_test_time 0.1941359043121338
Test Epoch19 layer1 Acc 0.909375, AUC 0.9696482419967651, avg_entr 0.014744860120117664
ep19_l1_test_time 0.31583213806152344
Test Epoch19 layer2 Acc 0.9095394736842105, AUC 0.9689380526542664, avg_entr 0.009448446333408356
ep19_l2_test_time 0.4364027976989746
Test Epoch19 layer3 Acc 0.9090460526315789, AUC 0.9689206480979919, avg_entr 0.00816836953163147
ep19_l3_test_time 0.6090312004089355
Test Epoch19 layer4 Acc 0.9095394736842105, AUC 0.9680853486061096, avg_entr 0.007596269249916077
ep19_l4_test_time 0.762446403503418
gc 0
Train Epoch20 Acc 0.972 (116640/120000), AUC 0.9963812828063965
ep20_train_time 50.122631549835205
Test Epoch20 layer0 Acc 0.9116776315789473, AUC 0.9795317649841309, avg_entr 0.04234692454338074
ep20_l0_test_time 0.1935408115386963
Test Epoch20 layer1 Acc 0.9087171052631579, AUC 0.9695378541946411, avg_entr 0.014797531068325043
ep20_l1_test_time 0.31575584411621094
Test Epoch20 layer2 Acc 0.9085526315789474, AUC 0.9691051840782166, avg_entr 0.010083078406751156
ep20_l2_test_time 0.43424510955810547
Test Epoch20 layer3 Acc 0.9078947368421053, AUC 0.9689383506774902, avg_entr 0.008809690363705158
ep20_l3_test_time 0.555591344833374
Test Epoch20 layer4 Acc 0.9082236842105263, AUC 0.9680519104003906, avg_entr 0.008048700168728828
ep20_l4_test_time 0.6664125919342041
gc 0
Train Epoch21 Acc 0.9720166666666666 (116642/120000), AUC 0.9963078498840332
ep21_train_time 49.15030765533447
Test Epoch21 layer0 Acc 0.9110197368421052, AUC 0.9795058965682983, avg_entr 0.04134511575102806
ep21_l0_test_time 0.19388365745544434
Test Epoch21 layer1 Acc 0.9083881578947368, AUC 0.9685028791427612, avg_entr 0.014387921430170536
ep21_l1_test_time 0.3161201477050781
Test Epoch21 layer2 Acc 0.9088815789473684, AUC 0.9680905938148499, avg_entr 0.009501575492322445
ep21_l2_test_time 0.4388084411621094
Test Epoch21 layer3 Acc 0.9087171052631579, AUC 0.9681450128555298, avg_entr 0.008424530737102032
ep21_l3_test_time 0.5580599308013916
Test Epoch21 layer4 Acc 0.9083881578947368, AUC 0.9681814908981323, avg_entr 0.007624445483088493
ep21_l4_test_time 0.6707437038421631
gc 0
Train Epoch22 Acc 0.9723166666666667 (116678/120000), AUC 0.9963508248329163
ep22_train_time 50.26964831352234
Test Epoch22 layer0 Acc 0.9111842105263158, AUC 0.9794995188713074, avg_entr 0.040693704038858414
ep22_l0_test_time 0.29476189613342285
Test Epoch22 layer1 Acc 0.9088815789473684, AUC 0.9688364267349243, avg_entr 0.014006657525897026
ep22_l1_test_time 0.40526628494262695
Test Epoch22 layer2 Acc 0.9088815789473684, AUC 0.9683587551116943, avg_entr 0.009194775484502316
ep22_l2_test_time 0.5237672328948975
Test Epoch22 layer3 Acc 0.9087171052631579, AUC 0.9682736396789551, avg_entr 0.00808306410908699
ep22_l3_test_time 0.5336513519287109
Test Epoch22 layer4 Acc 0.9088815789473684, AUC 0.9676421284675598, avg_entr 0.007356871385127306
ep22_l4_test_time 0.7731273174285889
gc 0
Train Epoch23 Acc 0.9723833333333334 (116686/120000), AUC 0.9964951276779175
ep23_train_time 50.68775153160095
Test Epoch23 layer0 Acc 0.9116776315789473, AUC 0.9795188307762146, avg_entr 0.040127791464328766
ep23_l0_test_time 0.1931908130645752
Test Epoch23 layer1 Acc 0.9083881578947368, AUC 0.9689275026321411, avg_entr 0.013736453838646412
ep23_l1_test_time 0.31514477729797363
Test Epoch23 layer2 Acc 0.9090460526315789, AUC 0.9682060480117798, avg_entr 0.009008965454995632
ep23_l2_test_time 0.4352397918701172
Test Epoch23 layer3 Acc 0.9088815789473684, AUC 0.9680453538894653, avg_entr 0.007931298576295376
ep23_l3_test_time 0.5553138256072998
Test Epoch23 layer4 Acc 0.9088815789473684, AUC 0.967018187046051, avg_entr 0.00719002541154623
ep23_l4_test_time 0.6693968772888184
gc 0
Train Epoch24 Acc 0.972725 (116727/120000), AUC 0.9965448379516602
ep24_train_time 50.08704400062561
Test Epoch24 layer0 Acc 0.912828947368421, AUC 0.9795259833335876, avg_entr 0.039666060358285904
ep24_l0_test_time 0.19382286071777344
Test Epoch24 layer1 Acc 0.9090460526315789, AUC 0.9690213203430176, avg_entr 0.013684779405593872
ep24_l1_test_time 0.31510472297668457
Test Epoch24 layer2 Acc 0.9095394736842105, AUC 0.9684299826622009, avg_entr 0.009237902238965034
ep24_l2_test_time 0.43444323539733887
Test Epoch24 layer3 Acc 0.9088815789473684, AUC 0.9681774973869324, avg_entr 0.008104060776531696
ep24_l3_test_time 0.5544192790985107
Test Epoch24 layer4 Acc 0.9092105263157895, AUC 0.9673944711685181, avg_entr 0.00733661325648427
ep24_l4_test_time 0.6678910255432129
gc 0
Train Epoch25 Acc 0.972775 (116733/120000), AUC 0.9965031743049622
ep25_train_time 49.75890874862671
Test Epoch25 layer0 Acc 0.9116776315789473, AUC 0.9795043468475342, avg_entr 0.03939766064286232
ep25_l0_test_time 0.2608041763305664
Test Epoch25 layer1 Acc 0.9090460526315789, AUC 0.9686205983161926, avg_entr 0.013492736965417862
ep25_l1_test_time 0.40856337547302246
Test Epoch25 layer2 Acc 0.9088815789473684, AUC 0.967961311340332, avg_entr 0.008955604396760464
ep25_l2_test_time 0.5235035419464111
Test Epoch25 layer3 Acc 0.9090460526315789, AUC 0.9678745269775391, avg_entr 0.0077933273278176785
ep25_l3_test_time 0.6436042785644531
Test Epoch25 layer4 Acc 0.9088815789473684, AUC 0.966707170009613, avg_entr 0.006988750770688057
ep25_l4_test_time 0.7643246650695801
gc 0
Train Epoch26 Acc 0.972675 (116721/120000), AUC 0.9965882301330566
ep26_train_time 50.537980794906616
Test Epoch26 layer0 Acc 0.9113486842105263, AUC 0.9794982075691223, avg_entr 0.03919729217886925
ep26_l0_test_time 0.19249749183654785
Test Epoch26 layer1 Acc 0.9087171052631579, AUC 0.9687932133674622, avg_entr 0.013377930037677288
ep26_l1_test_time 0.3142681121826172
Test Epoch26 layer2 Acc 0.9085526315789474, AUC 0.9679814577102661, avg_entr 0.009005138650536537
ep26_l2_test_time 0.43512916564941406
Test Epoch26 layer3 Acc 0.9083881578947368, AUC 0.9681208729743958, avg_entr 0.007793206721544266
ep26_l3_test_time 0.552819013595581
Test Epoch26 layer4 Acc 0.9082236842105263, AUC 0.9672034978866577, avg_entr 0.007002055644989014
ep26_l4_test_time 0.6661117076873779
gc 0
Train Epoch27 Acc 0.9729166666666667 (116750/120000), AUC 0.9966074228286743
ep27_train_time 50.93824911117554
Test Epoch27 layer0 Acc 0.9113486842105263, AUC 0.9795026183128357, avg_entr 0.03890836611390114
ep27_l0_test_time 0.19358277320861816
Test Epoch27 layer1 Acc 0.9085526315789474, AUC 0.9685739278793335, avg_entr 0.01326104998588562
ep27_l1_test_time 0.31467103958129883
Test Epoch27 layer2 Acc 0.9090460526315789, AUC 0.9678605198860168, avg_entr 0.00895547866821289
ep27_l2_test_time 0.4351508617401123
Test Epoch27 layer3 Acc 0.9087171052631579, AUC 0.9677175283432007, avg_entr 0.007810237351804972
ep27_l3_test_time 0.6324737071990967
Test Epoch27 layer4 Acc 0.9085526315789474, AUC 0.966697096824646, avg_entr 0.0070725735276937485
ep27_l4_test_time 0.7607042789459229
gc 0
Train Epoch28 Acc 0.9726916666666666 (116723/120000), AUC 0.9965717792510986
ep28_train_time 49.66179919242859
Test Epoch28 layer0 Acc 0.9120065789473685, AUC 0.9795050621032715, avg_entr 0.0386589840054512
ep28_l0_test_time 0.1956169605255127
Test Epoch28 layer1 Acc 0.9085526315789474, AUC 0.9684981107711792, avg_entr 0.013171643950045109
ep28_l1_test_time 0.3176083564758301
Test Epoch28 layer2 Acc 0.9085526315789474, AUC 0.9676700830459595, avg_entr 0.00878582987934351
ep28_l2_test_time 0.43757009506225586
Test Epoch28 layer3 Acc 0.9087171052631579, AUC 0.9676331281661987, avg_entr 0.0076307510025799274
ep28_l3_test_time 0.5563364028930664
Test Epoch28 layer4 Acc 0.9085526315789474, AUC 0.9667183756828308, avg_entr 0.006856891792267561
ep28_l4_test_time 0.6697268486022949
gc 0
Train Epoch29 Acc 0.973075 (116769/120000), AUC 0.9966477155685425
ep29_train_time 49.19329214096069
Test Epoch29 layer0 Acc 0.9118421052631579, AUC 0.9794949889183044, avg_entr 0.038638606667518616
ep29_l0_test_time 0.1957540512084961
Test Epoch29 layer1 Acc 0.9090460526315789, AUC 0.9688376188278198, avg_entr 0.013103560544550419
ep29_l1_test_time 0.3180656433105469
Test Epoch29 layer2 Acc 0.9082236842105263, AUC 0.9682161808013916, avg_entr 0.00879369955509901
ep29_l2_test_time 0.5141186714172363
Test Epoch29 layer3 Acc 0.9087171052631579, AUC 0.9680010676383972, avg_entr 0.0076327212154865265
ep29_l3_test_time 0.641160249710083
Test Epoch29 layer4 Acc 0.9085526315789474, AUC 0.9670105576515198, avg_entr 0.006795489229261875
ep29_l4_test_time 0.7597084045410156
gc 0
Train Epoch30 Acc 0.9729833333333333 (116758/120000), AUC 0.9966222643852234
ep30_train_time 50.62604904174805
Test Epoch30 layer0 Acc 0.9120065789473685, AUC 0.9794998168945312, avg_entr 0.03861016407608986
ep30_l0_test_time 0.19409489631652832
Test Epoch30 layer1 Acc 0.9090460526315789, AUC 0.9686676263809204, avg_entr 0.013073314912617207
ep30_l1_test_time 0.3158376216888428
Test Epoch30 layer2 Acc 0.9090460526315789, AUC 0.9681109189987183, avg_entr 0.00881616584956646
ep30_l2_test_time 0.4378030300140381
Test Epoch30 layer3 Acc 0.9087171052631579, AUC 0.9678530693054199, avg_entr 0.007748809643089771
ep30_l3_test_time 0.5551700592041016
Test Epoch30 layer4 Acc 0.9085526315789474, AUC 0.966632604598999, avg_entr 0.006968044210225344
ep30_l4_test_time 0.669104814529419
gc 0
Train Epoch31 Acc 0.97285 (116742/120000), AUC 0.9965776205062866
ep31_train_time 49.492918252944946
Test Epoch31 layer0 Acc 0.9116776315789473, AUC 0.9794893264770508, avg_entr 0.0384724996984005
ep31_l0_test_time 0.19273114204406738
Test Epoch31 layer1 Acc 0.9092105263157895, AUC 0.9686523079872131, avg_entr 0.013089700601994991
ep31_l1_test_time 0.31546926498413086
Test Epoch31 layer2 Acc 0.9088815789473684, AUC 0.967844545841217, avg_entr 0.00890609435737133
ep31_l2_test_time 0.4338500499725342
Test Epoch31 layer3 Acc 0.9087171052631579, AUC 0.9676467776298523, avg_entr 0.007787408772855997
ep31_l3_test_time 0.5539035797119141
Test Epoch31 layer4 Acc 0.9083881578947368, AUC 0.9665573835372925, avg_entr 0.006981843616813421
ep31_l4_test_time 0.7157723903656006
gc 0
Train Epoch32 Acc 0.9728416666666667 (116741/120000), AUC 0.9966423511505127
ep32_train_time 49.02044439315796
Test Epoch32 layer0 Acc 0.9118421052631579, AUC 0.9794929027557373, avg_entr 0.038463249802589417
ep32_l0_test_time 0.19416475296020508
Test Epoch32 layer1 Acc 0.9092105263157895, AUC 0.9686150550842285, avg_entr 0.013051632791757584
ep32_l1_test_time 0.3143289089202881
Test Epoch32 layer2 Acc 0.9088815789473684, AUC 0.9678996205329895, avg_entr 0.008863183669745922
ep32_l2_test_time 0.4358816146850586
Test Epoch32 layer3 Acc 0.9085526315789474, AUC 0.9677203297615051, avg_entr 0.00773038063198328
ep32_l3_test_time 0.5540833473205566
Test Epoch32 layer4 Acc 0.9082236842105263, AUC 0.9667669534683228, avg_entr 0.006910072639584541
ep32_l4_test_time 0.667158842086792
gc 0
Train Epoch33 Acc 0.973 (116760/120000), AUC 0.9965667724609375
ep33_train_time 50.2925386428833
Test Epoch33 layer0 Acc 0.9120065789473685, AUC 0.9794889688491821, avg_entr 0.03841273486614227
ep33_l0_test_time 0.1931743621826172
Test Epoch33 layer1 Acc 0.909375, AUC 0.9686846137046814, avg_entr 0.013031450100243092
ep33_l1_test_time 0.3159768581390381
Test Epoch33 layer2 Acc 0.9092105263157895, AUC 0.9679186344146729, avg_entr 0.008883140049874783
ep33_l2_test_time 0.4352288246154785
Test Epoch33 layer3 Acc 0.9087171052631579, AUC 0.9676364064216614, avg_entr 0.007783781737089157
ep33_l3_test_time 0.55348801612854
Test Epoch33 layer4 Acc 0.9083881578947368, AUC 0.9665223360061646, avg_entr 0.006956505589187145
ep33_l4_test_time 0.6680049896240234
gc 0
Train Epoch34 Acc 0.9729916666666667 (116759/120000), AUC 0.9966301321983337
ep34_train_time 49.67463541030884
Test Epoch34 layer0 Acc 0.9125, AUC 0.9794986248016357, avg_entr 0.03841298073530197
ep34_l0_test_time 0.1951284408569336
Test Epoch34 layer1 Acc 0.9090460526315789, AUC 0.9684364795684814, avg_entr 0.013031929731369019
ep34_l1_test_time 0.3178107738494873
Test Epoch34 layer2 Acc 0.9090460526315789, AUC 0.9678166508674622, avg_entr 0.008919917978346348
ep34_l2_test_time 0.4373586177825928
Test Epoch34 layer3 Acc 0.9088815789473684, AUC 0.9675033092498779, avg_entr 0.00786354299634695
ep34_l3_test_time 0.5576629638671875
Test Epoch34 layer4 Acc 0.9085526315789474, AUC 0.9664735794067383, avg_entr 0.007101177703589201
ep34_l4_test_time 0.6706991195678711
gc 0
Train Epoch35 Acc 0.9729083333333334 (116749/120000), AUC 0.9965366721153259
ep35_train_time 49.52929377555847
Test Epoch35 layer0 Acc 0.9120065789473685, AUC 0.9794968366622925, avg_entr 0.03832198306918144
ep35_l0_test_time 0.1948995590209961
Test Epoch35 layer1 Acc 0.9092105263157895, AUC 0.9684958457946777, avg_entr 0.012985066510736942
ep35_l1_test_time 0.3156578540802002
Test Epoch35 layer2 Acc 0.9090460526315789, AUC 0.9678149223327637, avg_entr 0.00886500347405672
ep35_l2_test_time 0.4351224899291992
Test Epoch35 layer3 Acc 0.9088815789473684, AUC 0.9674851894378662, avg_entr 0.007783281151205301
ep35_l3_test_time 0.5549745559692383
Test Epoch35 layer4 Acc 0.9083881578947368, AUC 0.9664080739021301, avg_entr 0.006982850842177868
ep35_l4_test_time 0.6701819896697998
gc 0
Train Epoch36 Acc 0.973 (116760/120000), AUC 0.9965560436248779
ep36_train_time 49.39547514915466
Test Epoch36 layer0 Acc 0.9123355263157895, AUC 0.9794981479644775, avg_entr 0.03836600482463837
ep36_l0_test_time 0.2544381618499756
Test Epoch36 layer1 Acc 0.9090460526315789, AUC 0.968410849571228, avg_entr 0.012968861497938633
ep36_l1_test_time 0.33406758308410645
Test Epoch36 layer2 Acc 0.9092105263157895, AUC 0.9676687121391296, avg_entr 0.008849472738802433
ep36_l2_test_time 0.4372243881225586
Test Epoch36 layer3 Acc 0.9087171052631579, AUC 0.9673057198524475, avg_entr 0.007799067068845034
ep36_l3_test_time 0.5563647747039795
Test Epoch36 layer4 Acc 0.9085526315789474, AUC 0.966414213180542, avg_entr 0.007005891762673855
ep36_l4_test_time 0.6687815189361572
gc 0
Train Epoch37 Acc 0.9732333333333333 (116788/120000), AUC 0.996484100818634
ep37_train_time 50.563873052597046
Test Epoch37 layer0 Acc 0.9116776315789473, AUC 0.979491114616394, avg_entr 0.03835521265864372
ep37_l0_test_time 0.19353580474853516
Test Epoch37 layer1 Acc 0.9090460526315789, AUC 0.9683647751808167, avg_entr 0.012976322323083878
ep37_l1_test_time 0.3151865005493164
Test Epoch37 layer2 Acc 0.9087171052631579, AUC 0.9676917791366577, avg_entr 0.00886455923318863
ep37_l2_test_time 0.43493080139160156
Test Epoch37 layer3 Acc 0.9085526315789474, AUC 0.9674296379089355, avg_entr 0.007810176815837622
ep37_l3_test_time 0.5552458763122559
Test Epoch37 layer4 Acc 0.9085526315789474, AUC 0.9663265347480774, avg_entr 0.007037912495434284
ep37_l4_test_time 0.6695337295532227
gc 0
Train Epoch38 Acc 0.9732833333333333 (116794/120000), AUC 0.996630072593689
ep38_train_time 49.12469530105591
Test Epoch38 layer0 Acc 0.9120065789473685, AUC 0.9794891476631165, avg_entr 0.038253236562013626
ep38_l0_test_time 0.18726277351379395
Test Epoch38 layer1 Acc 0.9090460526315789, AUC 0.9684494733810425, avg_entr 0.0129461120814085
ep38_l1_test_time 0.2800016403198242
Test Epoch38 layer2 Acc 0.9090460526315789, AUC 0.9677056074142456, avg_entr 0.008796936832368374
ep38_l2_test_time 0.3973727226257324
Test Epoch38 layer3 Acc 0.9087171052631579, AUC 0.9674845337867737, avg_entr 0.0077164554968476295
ep38_l3_test_time 0.5083925724029541
Test Epoch38 layer4 Acc 0.9083881578947368, AUC 0.9662906527519226, avg_entr 0.0069035920314490795
ep38_l4_test_time 0.6213512420654297
gc 0
Train Epoch39 Acc 0.9731583333333333 (116779/120000), AUC 0.9965709447860718
ep39_train_time 50.21801543235779
Test Epoch39 layer0 Acc 0.9120065789473685, AUC 0.9794912934303284, avg_entr 0.03831718489527702
ep39_l0_test_time 0.16100835800170898
Test Epoch39 layer1 Acc 0.9092105263157895, AUC 0.9684978127479553, avg_entr 0.012948819436132908
ep39_l1_test_time 0.2765219211578369
Test Epoch39 layer2 Acc 0.9090460526315789, AUC 0.9677201509475708, avg_entr 0.00881898496299982
ep39_l2_test_time 0.39251017570495605
Test Epoch39 layer3 Acc 0.9088815789473684, AUC 0.9674937129020691, avg_entr 0.007745762355625629
ep39_l3_test_time 0.5054340362548828
Test Epoch39 layer4 Acc 0.9083881578947368, AUC 0.9663124084472656, avg_entr 0.006947043817490339
ep39_l4_test_time 0.6174287796020508
gc 0
Train Epoch40 Acc 0.9731333333333333 (116776/120000), AUC 0.9966020584106445
ep40_train_time 47.89724683761597
Test Epoch40 layer0 Acc 0.9121710526315789, AUC 0.9794909358024597, avg_entr 0.038337886333465576
ep40_l0_test_time 0.16034150123596191
Test Epoch40 layer1 Acc 0.9092105263157895, AUC 0.9684932231903076, avg_entr 0.012956824153661728
ep40_l1_test_time 0.275773286819458
Test Epoch40 layer2 Acc 0.9087171052631579, AUC 0.9677466154098511, avg_entr 0.008842761628329754
ep40_l2_test_time 0.3921959400177002
Test Epoch40 layer3 Acc 0.9088815789473684, AUC 0.9674322605133057, avg_entr 0.007766245398670435
ep40_l3_test_time 0.5034265518188477
Test Epoch40 layer4 Acc 0.9085526315789474, AUC 0.9663070440292358, avg_entr 0.006974699441343546
ep40_l4_test_time 0.6176176071166992
gc 0
Train Epoch41 Acc 0.9733333333333334 (116800/120000), AUC 0.9965869188308716
ep41_train_time 47.99182891845703
Test Epoch41 layer0 Acc 0.9120065789473685, AUC 0.9794904589653015, avg_entr 0.03827846050262451
ep41_l0_test_time 0.1608715057373047
Test Epoch41 layer1 Acc 0.9092105263157895, AUC 0.968487560749054, avg_entr 0.012949563562870026
ep41_l1_test_time 0.2757987976074219
Test Epoch41 layer2 Acc 0.9088815789473684, AUC 0.9677485227584839, avg_entr 0.00884766224771738
ep41_l2_test_time 0.39202189445495605
Test Epoch41 layer3 Acc 0.9088815789473684, AUC 0.9674586057662964, avg_entr 0.007780617102980614
ep41_l3_test_time 0.5055561065673828
Test Epoch41 layer4 Acc 0.9085526315789474, AUC 0.9662778377532959, avg_entr 0.0069875577464699745
ep41_l4_test_time 0.6179804801940918
gc 0
Train Epoch42 Acc 0.9729083333333334 (116749/120000), AUC 0.9966602921485901
ep42_train_time 47.96476101875305
Test Epoch42 layer0 Acc 0.9118421052631579, AUC 0.9794890880584717, avg_entr 0.038285404443740845
ep42_l0_test_time 0.16034340858459473
Test Epoch42 layer1 Acc 0.9092105263157895, AUC 0.968478262424469, avg_entr 0.012942486442625523
ep42_l1_test_time 0.2763051986694336
Test Epoch42 layer2 Acc 0.9087171052631579, AUC 0.967754602432251, avg_entr 0.008839989081025124
ep42_l2_test_time 0.39137983322143555
Test Epoch42 layer3 Acc 0.9088815789473684, AUC 0.9675168991088867, avg_entr 0.007766799069941044
ep42_l3_test_time 0.5037555694580078
Test Epoch42 layer4 Acc 0.9085526315789474, AUC 0.9663523435592651, avg_entr 0.0069745187647640705
ep42_l4_test_time 0.6181750297546387
gc 0
Train Epoch43 Acc 0.973175 (116781/120000), AUC 0.9966722726821899
ep43_train_time 47.93243861198425
Test Epoch43 layer0 Acc 0.9120065789473685, AUC 0.9794892072677612, avg_entr 0.03824380040168762
ep43_l0_test_time 0.16049981117248535
Test Epoch43 layer1 Acc 0.9092105263157895, AUC 0.9685007929801941, avg_entr 0.012935196980834007
ep43_l1_test_time 0.275653600692749
Test Epoch43 layer2 Acc 0.9087171052631579, AUC 0.9677311182022095, avg_entr 0.008825067430734634
ep43_l2_test_time 0.391660213470459
Test Epoch43 layer3 Acc 0.9088815789473684, AUC 0.9675019383430481, avg_entr 0.007747529540210962
ep43_l3_test_time 0.5041091442108154
Test Epoch43 layer4 Acc 0.9083881578947368, AUC 0.9664053916931152, avg_entr 0.006940748076885939
ep43_l4_test_time 0.6167540550231934
gc 0
Train Epoch44 Acc 0.9730166666666666 (116762/120000), AUC 0.9966318607330322
ep44_train_time 47.977168798446655
Test Epoch44 layer0 Acc 0.9120065789473685, AUC 0.9794890880584717, avg_entr 0.03826696053147316
ep44_l0_test_time 0.1603407859802246
Test Epoch44 layer1 Acc 0.9092105263157895, AUC 0.9684717655181885, avg_entr 0.012939453125
ep44_l1_test_time 0.27642345428466797
Test Epoch44 layer2 Acc 0.9087171052631579, AUC 0.9677435159683228, avg_entr 0.008838752284646034
ep44_l2_test_time 0.39214515686035156
Test Epoch44 layer3 Acc 0.9088815789473684, AUC 0.9674766659736633, avg_entr 0.007763714529573917
ep44_l3_test_time 0.5047097206115723
Test Epoch44 layer4 Acc 0.9083881578947368, AUC 0.9663299918174744, avg_entr 0.0069627948105335236
ep44_l4_test_time 0.6174192428588867
gc 0
Train Epoch45 Acc 0.973275 (116793/120000), AUC 0.9966806769371033
ep45_train_time 48.046592473983765
Test Epoch45 layer0 Acc 0.9120065789473685, AUC 0.9794874787330627, avg_entr 0.0382542610168457
ep45_l0_test_time 0.16451430320739746
Test Epoch45 layer1 Acc 0.9092105263157895, AUC 0.968469500541687, avg_entr 0.012932335957884789
ep45_l1_test_time 0.27755022048950195
Test Epoch45 layer2 Acc 0.9087171052631579, AUC 0.9677252173423767, avg_entr 0.00883276853710413
ep45_l2_test_time 0.3931112289428711
Test Epoch45 layer3 Acc 0.9088815789473684, AUC 0.9674628376960754, avg_entr 0.007753318641334772
ep45_l3_test_time 0.5050556659698486
Test Epoch45 layer4 Acc 0.9083881578947368, AUC 0.9663103222846985, avg_entr 0.006953348405659199
ep45_l4_test_time 0.617992639541626
gc 0
Train Epoch46 Acc 0.9731083333333334 (116773/120000), AUC 0.9966176152229309
ep46_train_time 48.03584027290344
Test Epoch46 layer0 Acc 0.9120065789473685, AUC 0.9794875383377075, avg_entr 0.03825124725699425
ep46_l0_test_time 0.16241812705993652
Test Epoch46 layer1 Acc 0.9092105263157895, AUC 0.9684769511222839, avg_entr 0.01293138787150383
ep46_l1_test_time 0.2767810821533203
Test Epoch46 layer2 Acc 0.9087171052631579, AUC 0.9676897525787354, avg_entr 0.008826589211821556
ep46_l2_test_time 0.392470121383667
Test Epoch46 layer3 Acc 0.9088815789473684, AUC 0.9674492478370667, avg_entr 0.007748930715024471
ep46_l3_test_time 0.5050928592681885
Test Epoch46 layer4 Acc 0.9083881578947368, AUC 0.966299295425415, avg_entr 0.006943935994058847
ep46_l4_test_time 0.6185579299926758
gc 0
Train Epoch47 Acc 0.9731083333333334 (116773/120000), AUC 0.996652364730835
ep47_train_time 48.108715295791626
Test Epoch47 layer0 Acc 0.9118421052631579, AUC 0.9794826507568359, avg_entr 0.03827836737036705
ep47_l0_test_time 0.1615278720855713
Test Epoch47 layer1 Acc 0.9092105263157895, AUC 0.9684624671936035, avg_entr 0.012933934107422829
ep47_l1_test_time 0.2766690254211426
Test Epoch47 layer2 Acc 0.9087171052631579, AUC 0.9677243828773499, avg_entr 0.00883506890386343
ep47_l2_test_time 0.392009973526001
Test Epoch47 layer3 Acc 0.9088815789473684, AUC 0.9674268960952759, avg_entr 0.007759802509099245
ep47_l3_test_time 0.5046489238739014
Test Epoch47 layer4 Acc 0.9085526315789474, AUC 0.9662953019142151, avg_entr 0.006966448854655027
ep47_l4_test_time 0.6178102493286133
gc 0
Train Epoch48 Acc 0.973125 (116775/120000), AUC 0.9966006278991699
ep48_train_time 49.68439483642578
Test Epoch48 layer0 Acc 0.9120065789473685, AUC 0.9794872403144836, avg_entr 0.0382525771856308
ep48_l0_test_time 0.2024517059326172
Test Epoch48 layer1 Acc 0.9092105263157895, AUC 0.9684609770774841, avg_entr 0.012931480072438717
ep48_l1_test_time 0.32671260833740234
Test Epoch48 layer2 Acc 0.9087171052631579, AUC 0.9677038192749023, avg_entr 0.008833414874970913
ep48_l2_test_time 0.4465060234069824
Test Epoch48 layer3 Acc 0.9088815789473684, AUC 0.9674191474914551, avg_entr 0.007759710308164358
ep48_l3_test_time 0.5666594505310059
Test Epoch48 layer4 Acc 0.9085526315789474, AUC 0.9662905931472778, avg_entr 0.006964479573071003
ep48_l4_test_time 0.6798884868621826
gc 0
Train Epoch49 Acc 0.9731166666666666 (116774/120000), AUC 0.9967122673988342
ep49_train_time 50.24410581588745
Test Epoch49 layer0 Acc 0.9120065789473685, AUC 0.9794868230819702, avg_entr 0.03824857994914055
ep49_l0_test_time 0.30355310440063477
Test Epoch49 layer1 Acc 0.9092105263157895, AUC 0.9684619307518005, avg_entr 0.012931638397276402
ep49_l1_test_time 0.40692901611328125
Test Epoch49 layer2 Acc 0.9087171052631579, AUC 0.9677340984344482, avg_entr 0.008832553401589394
ep49_l2_test_time 0.5370733737945557
Test Epoch49 layer3 Acc 0.9088815789473684, AUC 0.9674229621887207, avg_entr 0.007757602725178003
ep49_l3_test_time 0.6517717838287354
Test Epoch49 layer4 Acc 0.9083881578947368, AUC 0.966289758682251, avg_entr 0.006960756611078978
ep49_l4_test_time 0.6826014518737793
Best AUC 0.9815223217010498
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.925, AUC 0.9860648512840271, avg_entr 0.11769669502973557
ep49_l0_test_time 0.053069353103637695
Test Epoch49 layer1 Acc 0.925, AUC 0.9858888983726501, avg_entr 0.04645780846476555
ep49_l1_test_time 0.08365988731384277
Test Epoch49 layer2 Acc 0.9236842105263158, AUC 0.9867424368858337, avg_entr 0.0360051654279232
ep49_l2_test_time 0.11359286308288574
Test Epoch49 layer3 Acc 0.9236842105263158, AUC 0.9861539602279663, avg_entr 0.034122735261917114
ep49_l3_test_time 0.14358091354370117
Test Epoch49 layer4 Acc 0.9236842105263158, AUC 0.9861854314804077, avg_entr 0.03297821804881096
ep49_l4_test_time 0.1727433204650879
