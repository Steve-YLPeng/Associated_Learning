total count words 102019
vocab size 30000
found 26754 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13672292
Start Training
gc 0
Train Epoch0 Acc 0.606875 (72825/120000), AUC 0.8398609757423401
ep0_train_time 18.208520650863647
Test Epoch0 layer0 Acc 0.9105263157894737, AUC 0.9791966676712036, avg_entr 0.2086874544620514
ep0_l0_test_time 0.0700216293334961
Save ckpt to ckpt/ag_news_transformeral_l5_pad25//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9100328947368421, AUC 0.9780145883560181, avg_entr 0.16616778075695038
ep0_l1_test_time 0.09974122047424316
Test Epoch0 layer2 Acc 0.9083881578947368, AUC 0.9782015681266785, avg_entr 0.16772760450839996
ep0_l2_test_time 0.13103723526000977
Test Epoch0 layer3 Acc 0.9083881578947368, AUC 0.9782360196113586, avg_entr 0.16668373346328735
ep0_l3_test_time 0.16373467445373535
Test Epoch0 layer4 Acc 0.9069078947368421, AUC 0.9785832166671753, avg_entr 0.17206606268882751
ep0_l4_test_time 0.19569110870361328
gc 0
Train Epoch1 Acc 0.9272 (111264/120000), AUC 0.9836664199829102
ep1_train_time 17.950658321380615
Test Epoch1 layer0 Acc 0.9126644736842106, AUC 0.9809496998786926, avg_entr 0.13174904882907867
ep1_l0_test_time 0.06769657135009766
Save ckpt to ckpt/ag_news_transformeral_l5_pad25//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.9169407894736842, AUC 0.9808225035667419, avg_entr 0.08663593977689743
ep1_l1_test_time 0.10174918174743652
Test Epoch1 layer2 Acc 0.9149671052631579, AUC 0.9806784391403198, avg_entr 0.07812955975532532
ep1_l2_test_time 0.1315629482269287
Test Epoch1 layer3 Acc 0.9138157894736842, AUC 0.9810631275177002, avg_entr 0.07031175494194031
ep1_l3_test_time 0.16400933265686035
Save ckpt to ckpt/ag_news_transformeral_l5_pad25//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer4 Acc 0.9123355263157895, AUC 0.9811108112335205, avg_entr 0.06790335476398468
ep1_l4_test_time 0.19897150993347168
Save ckpt to ckpt/ag_news_transformeral_l5_pad25//ag_news_transformeral_l5.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.9406083333333334 (112873/120000), AUC 0.9885950088500977
ep2_train_time 18.644647121429443
Test Epoch2 layer0 Acc 0.9148026315789474, AUC 0.9811604619026184, avg_entr 0.10370159149169922
ep2_l0_test_time 0.0852811336517334
Save ckpt to ckpt/ag_news_transformeral_l5_pad25//ag_news_transformeral_l5.pt  ,ep 2
Test Epoch2 layer1 Acc 0.9159539473684211, AUC 0.9809763431549072, avg_entr 0.046167463064193726
ep2_l1_test_time 0.12158751487731934
Test Epoch2 layer2 Acc 0.9167763157894737, AUC 0.9807127714157104, avg_entr 0.03777982294559479
ep2_l2_test_time 0.15481162071228027
Test Epoch2 layer3 Acc 0.9166118421052631, AUC 0.9806825518608093, avg_entr 0.03453627973794937
ep2_l3_test_time 0.1886587142944336
Test Epoch2 layer4 Acc 0.9167763157894737, AUC 0.9811691045761108, avg_entr 0.03251277655363083
ep2_l4_test_time 0.22238659858703613
Save ckpt to ckpt/ag_news_transformeral_l5_pad25//ag_news_transformeral_l5.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.9477583333333334 (113731/120000), AUC 0.9900320768356323
ep3_train_time 19.638007402420044
Test Epoch3 layer0 Acc 0.9139802631578947, AUC 0.9808392524719238, avg_entr 0.09213738888502121
ep3_l0_test_time 0.08541584014892578
Test Epoch3 layer1 Acc 0.9171052631578948, AUC 0.9789125919342041, avg_entr 0.03527209535241127
ep3_l1_test_time 0.1208043098449707
Test Epoch3 layer2 Acc 0.9182565789473685, AUC 0.9812682271003723, avg_entr 0.028506005182862282
ep3_l2_test_time 0.15514564514160156
Save ckpt to ckpt/ag_news_transformeral_l5_pad25//ag_news_transformeral_l5.pt  ,ep 3
Test Epoch3 layer3 Acc 0.9179276315789474, AUC 0.9814894199371338, avg_entr 0.026501033455133438
ep3_l3_test_time 0.18979859352111816
Save ckpt to ckpt/ag_news_transformeral_l5_pad25//ag_news_transformeral_l5.pt  ,ep 3
Test Epoch3 layer4 Acc 0.9174342105263158, AUC 0.9810961484909058, avg_entr 0.025733724236488342
ep3_l4_test_time 0.2240290641784668
gc 0
Train Epoch4 Acc 0.95275 (114330/120000), AUC 0.9911344051361084
ep4_train_time 21.562345266342163
Test Epoch4 layer0 Acc 0.9121710526315789, AUC 0.9804421067237854, avg_entr 0.08118680864572525
ep4_l0_test_time 0.08584189414978027
Test Epoch4 layer1 Acc 0.9151315789473684, AUC 0.977728545665741, avg_entr 0.030308911576867104
ep4_l1_test_time 0.12058615684509277
Test Epoch4 layer2 Acc 0.9159539473684211, AUC 0.9805103540420532, avg_entr 0.023988939821720123
ep4_l2_test_time 0.15474939346313477
Test Epoch4 layer3 Acc 0.9161184210526315, AUC 0.9806154370307922, avg_entr 0.021999793127179146
ep4_l3_test_time 0.18857288360595703
Test Epoch4 layer4 Acc 0.9164473684210527, AUC 0.9808348417282104, avg_entr 0.020865442231297493
ep4_l4_test_time 0.3241102695465088
gc 0
Train Epoch5 Acc 0.9567916666666667 (114815/120000), AUC 0.9918734431266785
ep5_train_time 19.752031803131104
Test Epoch5 layer0 Acc 0.9136513157894737, AUC 0.9805039167404175, avg_entr 0.07416127622127533
ep5_l0_test_time 0.08552432060241699
Test Epoch5 layer1 Acc 0.9133223684210526, AUC 0.9787786602973938, avg_entr 0.025939736515283585
ep5_l1_test_time 0.1201484203338623
Test Epoch5 layer2 Acc 0.9136513157894737, AUC 0.9811307191848755, avg_entr 0.019826939329504967
ep5_l2_test_time 0.1539292335510254
Test Epoch5 layer3 Acc 0.9138157894736842, AUC 0.9811298847198486, avg_entr 0.018135394901037216
ep5_l3_test_time 0.18776607513427734
Test Epoch5 layer4 Acc 0.9134868421052632, AUC 0.9805037975311279, avg_entr 0.016888046637177467
ep5_l4_test_time 0.22214746475219727
gc 0
Train Epoch6 Acc 0.95885 (115062/120000), AUC 0.9931811690330505
ep6_train_time 20.531975984573364
Test Epoch6 layer0 Acc 0.9120065789473685, AUC 0.9800635576248169, avg_entr 0.07026826590299606
ep6_l0_test_time 0.0859975814819336
Test Epoch6 layer1 Acc 0.9129934210526316, AUC 0.9772575497627258, avg_entr 0.024556973949074745
ep6_l1_test_time 0.12048745155334473
Test Epoch6 layer2 Acc 0.9139802631578947, AUC 0.9797101616859436, avg_entr 0.01879928447306156
ep6_l2_test_time 0.15449881553649902
Test Epoch6 layer3 Acc 0.9138157894736842, AUC 0.9808590412139893, avg_entr 0.016981007531285286
ep6_l3_test_time 0.1886892318725586
Test Epoch6 layer4 Acc 0.9138157894736842, AUC 0.9807908535003662, avg_entr 0.015587607398629189
ep6_l4_test_time 0.22247838973999023
gc 0
Train Epoch7 Acc 0.9636916666666666 (115643/120000), AUC 0.9940446615219116
ep7_train_time 22.390535593032837
Test Epoch7 layer0 Acc 0.9120065789473685, AUC 0.9799826741218567, avg_entr 0.06610910594463348
ep7_l0_test_time 0.08632802963256836
Test Epoch7 layer1 Acc 0.9101973684210526, AUC 0.9762794971466064, avg_entr 0.023489080369472504
ep7_l1_test_time 0.12108325958251953
Test Epoch7 layer2 Acc 0.9103618421052632, AUC 0.9794317483901978, avg_entr 0.01716463454067707
ep7_l2_test_time 0.15485048294067383
Test Epoch7 layer3 Acc 0.9098684210526315, AUC 0.9798206090927124, avg_entr 0.015780009329319
ep7_l3_test_time 0.18909358978271484
Test Epoch7 layer4 Acc 0.9098684210526315, AUC 0.9799202680587769, avg_entr 0.014353521168231964
ep7_l4_test_time 0.2228705883026123
gc 0
Train Epoch8 Acc 0.9651416666666667 (115817/120000), AUC 0.9943830966949463
ep8_train_time 23.21925711631775
Test Epoch8 layer0 Acc 0.9100328947368421, AUC 0.9795414209365845, avg_entr 0.06390544772148132
ep8_l0_test_time 0.08772897720336914
Test Epoch8 layer1 Acc 0.9100328947368421, AUC 0.9749632477760315, avg_entr 0.022513430565595627
ep8_l1_test_time 0.12258696556091309
Test Epoch8 layer2 Acc 0.9100328947368421, AUC 0.9774566888809204, avg_entr 0.016680216416716576
ep8_l2_test_time 0.15810251235961914
Test Epoch8 layer3 Acc 0.9098684210526315, AUC 0.977766752243042, avg_entr 0.01531093381345272
ep8_l3_test_time 0.19226789474487305
Test Epoch8 layer4 Acc 0.9101973684210526, AUC 0.9777709245681763, avg_entr 0.014140959829092026
ep8_l4_test_time 0.22545313835144043
gc 0
Train Epoch9 Acc 0.9665 (115980/120000), AUC 0.9948191046714783
ep9_train_time 19.533040285110474
Test Epoch9 layer0 Acc 0.9101973684210526, AUC 0.9794148206710815, avg_entr 0.060587964951992035
ep9_l0_test_time 0.08850693702697754
Test Epoch9 layer1 Acc 0.9087171052631579, AUC 0.9746238589286804, avg_entr 0.021433543413877487
ep9_l1_test_time 0.1235201358795166
Test Epoch9 layer2 Acc 0.9090460526315789, AUC 0.9781720042228699, avg_entr 0.01545559149235487
ep9_l2_test_time 0.15671849250793457
Test Epoch9 layer3 Acc 0.909375, AUC 0.9788751006126404, avg_entr 0.0141834681853652
ep9_l3_test_time 0.19062495231628418
Test Epoch9 layer4 Acc 0.909375, AUC 0.9794163703918457, avg_entr 0.012700352817773819
ep9_l4_test_time 0.27429842948913574
gc 0
Train Epoch10 Acc 0.9677833333333333 (116134/120000), AUC 0.994983434677124
ep10_train_time 20.021090745925903
Test Epoch10 layer0 Acc 0.9110197368421052, AUC 0.9791901707649231, avg_entr 0.057159412652254105
ep10_l0_test_time 0.08577847480773926
Test Epoch10 layer1 Acc 0.9105263157894737, AUC 0.9728963375091553, avg_entr 0.019520625472068787
ep10_l1_test_time 0.12059187889099121
Test Epoch10 layer2 Acc 0.9105263157894737, AUC 0.9771658182144165, avg_entr 0.01367364451289177
ep10_l2_test_time 0.15439629554748535
Test Epoch10 layer3 Acc 0.9111842105263158, AUC 0.9777933359146118, avg_entr 0.012343017384409904
ep10_l3_test_time 0.18843817710876465
Test Epoch10 layer4 Acc 0.9113486842105263, AUC 0.9776304960250854, avg_entr 0.011090756393969059
ep10_l4_test_time 0.22268342971801758
gc 0
Train Epoch11 Acc 0.9702 (116424/120000), AUC 0.9956309199333191
ep11_train_time 19.445629596710205
Test Epoch11 layer0 Acc 0.9098684210526315, AUC 0.9790197014808655, avg_entr 0.05625545233488083
ep11_l0_test_time 0.08587002754211426
Test Epoch11 layer1 Acc 0.9090460526315789, AUC 0.9718669652938843, avg_entr 0.019650844857096672
ep11_l1_test_time 0.12072944641113281
Test Epoch11 layer2 Acc 0.9078947368421053, AUC 0.9715776443481445, avg_entr 0.01335080061107874
ep11_l2_test_time 0.15572142601013184
Test Epoch11 layer3 Acc 0.9082236842105263, AUC 0.9729753732681274, avg_entr 0.011550657451152802
ep11_l3_test_time 0.18944096565246582
Test Epoch11 layer4 Acc 0.9082236842105263, AUC 0.9745194911956787, avg_entr 0.010093546472489834
ep11_l4_test_time 0.22311830520629883
gc 0
Train Epoch12 Acc 0.9707 (116484/120000), AUC 0.9956380724906921
ep12_train_time 20.82587718963623
Test Epoch12 layer0 Acc 0.9098684210526315, AUC 0.9789374470710754, avg_entr 0.05541878566145897
ep12_l0_test_time 0.08742690086364746
Test Epoch12 layer1 Acc 0.9080592105263158, AUC 0.9725687503814697, avg_entr 0.019765475764870644
ep12_l1_test_time 0.12223410606384277
Test Epoch12 layer2 Acc 0.9082236842105263, AUC 0.973956823348999, avg_entr 0.01361505314707756
ep12_l2_test_time 0.1569666862487793
Test Epoch12 layer3 Acc 0.9078947368421053, AUC 0.973681628704071, avg_entr 0.011883546598255634
ep12_l3_test_time 0.19107484817504883
Test Epoch12 layer4 Acc 0.9083881578947368, AUC 0.973828911781311, avg_entr 0.010232873260974884
ep12_l4_test_time 0.2248685359954834
gc 0
Train Epoch13 Acc 0.9718583333333334 (116623/120000), AUC 0.9958463311195374
ep13_train_time 19.043377161026
Test Epoch13 layer0 Acc 0.9100328947368421, AUC 0.9787856936454773, avg_entr 0.05240656062960625
ep13_l0_test_time 0.08583903312683105
Test Epoch13 layer1 Acc 0.9095394736842105, AUC 0.9723608493804932, avg_entr 0.01855490170419216
ep13_l1_test_time 0.12088441848754883
Test Epoch13 layer2 Acc 0.9082236842105263, AUC 0.9740934371948242, avg_entr 0.012390244752168655
ep13_l2_test_time 0.1552281379699707
Test Epoch13 layer3 Acc 0.9080592105263158, AUC 0.9736579060554504, avg_entr 0.010657592676579952
ep13_l3_test_time 0.18932271003723145
Test Epoch13 layer4 Acc 0.9082236842105263, AUC 0.9731658697128296, avg_entr 0.009406838566064835
ep13_l4_test_time 0.2230391502380371
gc 0
Train Epoch14 Acc 0.9721 (116652/120000), AUC 0.9959530234336853
ep14_train_time 19.000438451766968
Test Epoch14 layer0 Acc 0.909375, AUC 0.9787264466285706, avg_entr 0.05078927055001259
ep14_l0_test_time 0.08727335929870605
Test Epoch14 layer1 Acc 0.9080592105263158, AUC 0.9713987112045288, avg_entr 0.01815159246325493
ep14_l1_test_time 0.12230825424194336
Test Epoch14 layer2 Acc 0.906578947368421, AUC 0.9741064310073853, avg_entr 0.011897427029907703
ep14_l2_test_time 0.15711474418640137
Test Epoch14 layer3 Acc 0.9067434210526316, AUC 0.9733540415763855, avg_entr 0.010231595486402512
ep14_l3_test_time 0.19108939170837402
Test Epoch14 layer4 Acc 0.9070723684210527, AUC 0.9734365344047546, avg_entr 0.008979304693639278
ep14_l4_test_time 0.22576069831848145
gc 0
Train Epoch15 Acc 0.9736333333333334 (116836/120000), AUC 0.9962906241416931
ep15_train_time 20.529499530792236
Test Epoch15 layer0 Acc 0.9100328947368421, AUC 0.9786363840103149, avg_entr 0.04918094351887703
ep15_l0_test_time 0.08672118186950684
Test Epoch15 layer1 Acc 0.9088815789473684, AUC 0.9708818793296814, avg_entr 0.017625439912080765
ep15_l1_test_time 0.1227719783782959
Test Epoch15 layer2 Acc 0.9078947368421053, AUC 0.9739376306533813, avg_entr 0.01178735587745905
ep15_l2_test_time 0.15767884254455566
Test Epoch15 layer3 Acc 0.9080592105263158, AUC 0.9724963903427124, avg_entr 0.010101156309247017
ep15_l3_test_time 0.19220256805419922
Test Epoch15 layer4 Acc 0.9083881578947368, AUC 0.972648561000824, avg_entr 0.008965116925537586
ep15_l4_test_time 0.2271568775177002
gc 0
Train Epoch16 Acc 0.9737333333333333 (116848/120000), AUC 0.9963175654411316
ep16_train_time 23.045339584350586
Test Epoch16 layer0 Acc 0.9110197368421052, AUC 0.9786412715911865, avg_entr 0.04810906574130058
ep16_l0_test_time 0.11512351036071777
Test Epoch16 layer1 Acc 0.909375, AUC 0.9711855053901672, avg_entr 0.01749265566468239
ep16_l1_test_time 0.1482996940612793
Test Epoch16 layer2 Acc 0.9075657894736842, AUC 0.9737138152122498, avg_entr 0.011545553803443909
ep16_l2_test_time 0.1813526153564453
Test Epoch16 layer3 Acc 0.9067434210526316, AUC 0.9727800488471985, avg_entr 0.010062653571367264
ep16_l3_test_time 0.21625375747680664
Test Epoch16 layer4 Acc 0.9067434210526316, AUC 0.9726594090461731, avg_entr 0.00904112495481968
ep16_l4_test_time 0.249114990234375
gc 0
Train Epoch17 Acc 0.974 (116880/120000), AUC 0.9961625337600708
ep17_train_time 20.128589630126953
Test Epoch17 layer0 Acc 0.9101973684210526, AUC 0.9786020517349243, avg_entr 0.04664405435323715
ep17_l0_test_time 0.08670806884765625
Test Epoch17 layer1 Acc 0.9082236842105263, AUC 0.9703436493873596, avg_entr 0.016811026260256767
ep17_l1_test_time 0.18561697006225586
Test Epoch17 layer2 Acc 0.9078947368421053, AUC 0.972848653793335, avg_entr 0.010912689380347729
ep17_l2_test_time 0.24829840660095215
Test Epoch17 layer3 Acc 0.9077302631578947, AUC 0.9715659618377686, avg_entr 0.009307204745709896
ep17_l3_test_time 0.2962515354156494
Test Epoch17 layer4 Acc 0.9080592105263158, AUC 0.9719240069389343, avg_entr 0.008439740166068077
ep17_l4_test_time 0.34409213066101074
gc 0
Train Epoch18 Acc 0.9744166666666667 (116930/120000), AUC 0.9963931441307068
ep18_train_time 19.591556549072266
Test Epoch18 layer0 Acc 0.9111842105263158, AUC 0.978556215763092, avg_entr 0.044991351664066315
ep18_l0_test_time 0.14128398895263672
Test Epoch18 layer1 Acc 0.9080592105263158, AUC 0.9702851176261902, avg_entr 0.016682568937540054
ep18_l1_test_time 0.19824481010437012
Test Epoch18 layer2 Acc 0.906578947368421, AUC 0.9717711806297302, avg_entr 0.01084752194583416
ep18_l2_test_time 0.24724674224853516
Test Epoch18 layer3 Acc 0.9067434210526316, AUC 0.9703975915908813, avg_entr 0.009250972419977188
ep18_l3_test_time 0.29360222816467285
Test Epoch18 layer4 Acc 0.9074013157894737, AUC 0.9704433679580688, avg_entr 0.008129552006721497
ep18_l4_test_time 0.34259605407714844
gc 0
Train Epoch19 Acc 0.9747333333333333 (116968/120000), AUC 0.9964603185653687
ep19_train_time 20.42847442626953
Test Epoch19 layer0 Acc 0.9110197368421052, AUC 0.9785205721855164, avg_entr 0.04431575536727905
ep19_l0_test_time 0.14446234703063965
Test Epoch19 layer1 Acc 0.9072368421052631, AUC 0.9703141450881958, avg_entr 0.016622887924313545
ep19_l1_test_time 0.19864845275878906
Test Epoch19 layer2 Acc 0.90625, AUC 0.9716196060180664, avg_entr 0.010817354544997215
ep19_l2_test_time 0.22207999229431152
Test Epoch19 layer3 Acc 0.905921052631579, AUC 0.9706463813781738, avg_entr 0.009272679686546326
ep19_l3_test_time 0.1894550323486328
Test Epoch19 layer4 Acc 0.905921052631579, AUC 0.9709488749504089, avg_entr 0.008236007764935493
ep19_l4_test_time 0.2232656478881836
gc 0
Train Epoch20 Acc 0.9751083333333334 (117013/120000), AUC 0.9965037107467651
ep20_train_time 21.933388233184814
Test Epoch20 layer0 Acc 0.9103618421052632, AUC 0.978502631187439, avg_entr 0.043307334184646606
ep20_l0_test_time 0.08685994148254395
Test Epoch20 layer1 Acc 0.9077302631578947, AUC 0.9697505235671997, avg_entr 0.01621546968817711
ep20_l1_test_time 0.12097454071044922
Test Epoch20 layer2 Acc 0.9069078947368421, AUC 0.9717000126838684, avg_entr 0.010604266077280045
ep20_l2_test_time 0.15463948249816895
Test Epoch20 layer3 Acc 0.906578947368421, AUC 0.9706391096115112, avg_entr 0.008833512663841248
ep20_l3_test_time 0.18850421905517578
Test Epoch20 layer4 Acc 0.9067434210526316, AUC 0.9697372317314148, avg_entr 0.007767908275127411
ep20_l4_test_time 0.22242021560668945
gc 0
Train Epoch21 Acc 0.9752583333333333 (117031/120000), AUC 0.9964639544487
ep21_train_time 20.05633568763733
Test Epoch21 layer0 Acc 0.9103618421052632, AUC 0.9785118103027344, avg_entr 0.04230353608727455
ep21_l0_test_time 0.08588576316833496
Test Epoch21 layer1 Acc 0.9075657894736842, AUC 0.9701893329620361, avg_entr 0.015904901549220085
ep21_l1_test_time 0.12073993682861328
Test Epoch21 layer2 Acc 0.9070723684210527, AUC 0.9714877009391785, avg_entr 0.010158374905586243
ep21_l2_test_time 0.15478205680847168
Test Epoch21 layer3 Acc 0.906578947368421, AUC 0.9689500331878662, avg_entr 0.008485010825097561
ep21_l3_test_time 0.18895769119262695
Test Epoch21 layer4 Acc 0.906578947368421, AUC 0.9686801433563232, avg_entr 0.007481795735657215
ep21_l4_test_time 0.27597618103027344
gc 0
Train Epoch22 Acc 0.9755833333333334 (117070/120000), AUC 0.9964694976806641
ep22_train_time 19.455341577529907
Test Epoch22 layer0 Acc 0.9105263157894737, AUC 0.9784805774688721, avg_entr 0.041100841015577316
ep22_l0_test_time 0.14371681213378906
Test Epoch22 layer1 Acc 0.9075657894736842, AUC 0.9703078269958496, avg_entr 0.01577509380877018
ep22_l1_test_time 0.1982285976409912
Test Epoch22 layer2 Acc 0.9067434210526316, AUC 0.9723634719848633, avg_entr 0.010350584983825684
ep22_l2_test_time 0.245652437210083
Test Epoch22 layer3 Acc 0.9064144736842106, AUC 0.9704338908195496, avg_entr 0.008733125403523445
ep22_l3_test_time 0.1885063648223877
Test Epoch22 layer4 Acc 0.90625, AUC 0.9692665338516235, avg_entr 0.007699670735746622
ep22_l4_test_time 0.22215962409973145
gc 0
Train Epoch23 Acc 0.9759833333333333 (117118/120000), AUC 0.9966588020324707
ep23_train_time 19.163009881973267
Test Epoch23 layer0 Acc 0.9105263157894737, AUC 0.9784680604934692, avg_entr 0.04058277979493141
ep23_l0_test_time 0.08590269088745117
Test Epoch23 layer1 Acc 0.9070723684210527, AUC 0.9699918031692505, avg_entr 0.015440517105162144
ep23_l1_test_time 0.12087321281433105
Test Epoch23 layer2 Acc 0.9060855263157894, AUC 0.971129834651947, avg_entr 0.010074924677610397
ep23_l2_test_time 0.15508198738098145
Test Epoch23 layer3 Acc 0.90625, AUC 0.9688128232955933, avg_entr 0.008495064452290535
ep23_l3_test_time 0.18940448760986328
Test Epoch23 layer4 Acc 0.906578947368421, AUC 0.9680347442626953, avg_entr 0.007422391790896654
ep23_l4_test_time 0.2235269546508789
gc 0
Train Epoch24 Acc 0.9760416666666667 (117125/120000), AUC 0.9966181516647339
ep24_train_time 20.64976143836975
Test Epoch24 layer0 Acc 0.9100328947368421, AUC 0.9784332513809204, avg_entr 0.04016955941915512
ep24_l0_test_time 0.08527612686157227
Test Epoch24 layer1 Acc 0.9070723684210527, AUC 0.9701652526855469, avg_entr 0.01542910560965538
ep24_l1_test_time 0.12005734443664551
Test Epoch24 layer2 Acc 0.90625, AUC 0.9716643691062927, avg_entr 0.009852034039795399
ep24_l2_test_time 0.154587984085083
Test Epoch24 layer3 Acc 0.906578947368421, AUC 0.9692409634590149, avg_entr 0.008181119337677956
ep24_l3_test_time 0.1883983612060547
Test Epoch24 layer4 Acc 0.906578947368421, AUC 0.9688639640808105, avg_entr 0.00725515466183424
ep24_l4_test_time 0.2222881317138672
gc 0
Train Epoch25 Acc 0.97635 (117162/120000), AUC 0.9965860843658447
ep25_train_time 21.78185772895813
Test Epoch25 layer0 Acc 0.9098684210526315, AUC 0.9784399271011353, avg_entr 0.03976510092616081
ep25_l0_test_time 0.08543825149536133
Test Epoch25 layer1 Acc 0.9067434210526316, AUC 0.9700606465339661, avg_entr 0.015239633619785309
ep25_l1_test_time 0.12029623985290527
Test Epoch25 layer2 Acc 0.90625, AUC 0.9711937308311462, avg_entr 0.009998328983783722
ep25_l2_test_time 0.15392017364501953
Test Epoch25 layer3 Acc 0.9060855263157894, AUC 0.968691349029541, avg_entr 0.008378499187529087
ep25_l3_test_time 0.18792152404785156
Test Epoch25 layer4 Acc 0.9064144736842106, AUC 0.9684503078460693, avg_entr 0.007325004320591688
ep25_l4_test_time 0.22254061698913574
gc 0
Train Epoch26 Acc 0.9762916666666667 (117155/120000), AUC 0.9965506792068481
ep26_train_time 18.991692543029785
Test Epoch26 layer0 Acc 0.9101973684210526, AUC 0.9784208536148071, avg_entr 0.03939574211835861
ep26_l0_test_time 0.11416840553283691
Test Epoch26 layer1 Acc 0.9067434210526316, AUC 0.9699982404708862, avg_entr 0.015088270418345928
ep26_l1_test_time 0.14780974388122559
Test Epoch26 layer2 Acc 0.90625, AUC 0.9710144996643066, avg_entr 0.009806785732507706
ep26_l2_test_time 0.18291449546813965
Test Epoch26 layer3 Acc 0.9064144736842106, AUC 0.9684724807739258, avg_entr 0.008103976957499981
ep26_l3_test_time 0.2156991958618164
Test Epoch26 layer4 Acc 0.9060855263157894, AUC 0.9677976369857788, avg_entr 0.007108144462108612
ep26_l4_test_time 0.24990248680114746
gc 0
Train Epoch27 Acc 0.9763 (117156/120000), AUC 0.9966386556625366
ep27_train_time 22.45672345161438
Test Epoch27 layer0 Acc 0.9103618421052632, AUC 0.9784094095230103, avg_entr 0.03910359740257263
ep27_l0_test_time 0.08554649353027344
Test Epoch27 layer1 Acc 0.906578947368421, AUC 0.9697960615158081, avg_entr 0.014979413710534573
ep27_l1_test_time 0.1201772689819336
Test Epoch27 layer2 Acc 0.9057565789473684, AUC 0.9698782563209534, avg_entr 0.00976457167416811
ep27_l2_test_time 0.15398812294006348
Test Epoch27 layer3 Acc 0.905921052631579, AUC 0.9670552015304565, avg_entr 0.008129343390464783
ep27_l3_test_time 0.18796396255493164
Test Epoch27 layer4 Acc 0.9060855263157894, AUC 0.9683532118797302, avg_entr 0.007216872647404671
ep27_l4_test_time 0.22293686866760254
gc 0
Train Epoch28 Acc 0.9764166666666667 (117170/120000), AUC 0.9966545104980469
ep28_train_time 21.470689296722412
Test Epoch28 layer0 Acc 0.9101973684210526, AUC 0.9783952236175537, avg_entr 0.03901536762714386
ep28_l0_test_time 0.08584332466125488
Test Epoch28 layer1 Acc 0.9067434210526316, AUC 0.9699450135231018, avg_entr 0.015004191547632217
ep28_l1_test_time 0.1203620433807373
Test Epoch28 layer2 Acc 0.9050986842105263, AUC 0.9710354208946228, avg_entr 0.010120079852640629
ep28_l2_test_time 0.1541576385498047
Test Epoch28 layer3 Acc 0.9057565789473684, AUC 0.9684252738952637, avg_entr 0.008642975240945816
ep28_l3_test_time 0.18804216384887695
Test Epoch28 layer4 Acc 0.9052631578947369, AUC 0.9679653644561768, avg_entr 0.007380930241197348
ep28_l4_test_time 0.22184109687805176
gc 0
Train Epoch29 Acc 0.9763416666666667 (117161/120000), AUC 0.9965787529945374
ep29_train_time 18.942618370056152
Test Epoch29 layer0 Acc 0.9100328947368421, AUC 0.9783948659896851, avg_entr 0.03880888968706131
ep29_l0_test_time 0.06812167167663574
Test Epoch29 layer1 Acc 0.9064144736842106, AUC 0.9699423313140869, avg_entr 0.01490363571792841
ep29_l1_test_time 0.09897780418395996
Test Epoch29 layer2 Acc 0.9050986842105263, AUC 0.9710140824317932, avg_entr 0.009910119697451591
ep29_l2_test_time 0.13088679313659668
Test Epoch29 layer3 Acc 0.9052631578947369, AUC 0.9681446552276611, avg_entr 0.00832662358880043
ep29_l3_test_time 0.16319680213928223
Test Epoch29 layer4 Acc 0.9052631578947369, AUC 0.968073844909668, avg_entr 0.0072378176264464855
ep29_l4_test_time 0.1962299346923828
gc 0
Train Epoch30 Acc 0.976525 (117183/120000), AUC 0.9966883659362793
ep30_train_time 17.609798908233643
Test Epoch30 layer0 Acc 0.9103618421052632, AUC 0.9783861041069031, avg_entr 0.03871068358421326
ep30_l0_test_time 0.06842565536499023
Test Epoch30 layer1 Acc 0.9064144736842106, AUC 0.9697616696357727, avg_entr 0.014841806143522263
ep30_l1_test_time 0.0988454818725586
Test Epoch30 layer2 Acc 0.9049342105263158, AUC 0.970962405204773, avg_entr 0.009999976493418217
ep30_l2_test_time 0.1307072639465332
Test Epoch30 layer3 Acc 0.9052631578947369, AUC 0.9678032994270325, avg_entr 0.008506706915795803
ep30_l3_test_time 0.16378378868103027
Test Epoch30 layer4 Acc 0.9055921052631579, AUC 0.9682412147521973, avg_entr 0.007443138863891363
ep30_l4_test_time 0.1959991455078125
gc 0
Train Epoch31 Acc 0.9766333333333334 (117196/120000), AUC 0.9966603517532349
ep31_train_time 17.874880075454712
Test Epoch31 layer0 Acc 0.9103618421052632, AUC 0.9783865213394165, avg_entr 0.03861129283905029
ep31_l0_test_time 0.06869077682495117
Test Epoch31 layer1 Acc 0.90625, AUC 0.9698836803436279, avg_entr 0.014805711805820465
ep31_l1_test_time 0.0986175537109375
Test Epoch31 layer2 Acc 0.9046052631578947, AUC 0.970970630645752, avg_entr 0.00991221982985735
ep31_l2_test_time 0.13082647323608398
Test Epoch31 layer3 Acc 0.9049342105263158, AUC 0.9677968621253967, avg_entr 0.008401243947446346
ep31_l3_test_time 0.1632521152496338
Test Epoch31 layer4 Acc 0.9050986842105263, AUC 0.9682394862174988, avg_entr 0.007366476114839315
ep31_l4_test_time 0.19579839706420898
gc 0
Train Epoch32 Acc 0.9766583333333333 (117199/120000), AUC 0.9966790676116943
ep32_train_time 17.967063903808594
Test Epoch32 layer0 Acc 0.9101973684210526, AUC 0.9783803820610046, avg_entr 0.038538314402103424
ep32_l0_test_time 0.06748723983764648
Test Epoch32 layer1 Acc 0.9064144736842106, AUC 0.9697870016098022, avg_entr 0.014782417565584183
ep32_l1_test_time 0.09843301773071289
Test Epoch32 layer2 Acc 0.9047697368421053, AUC 0.9707836508750916, avg_entr 0.009946511127054691
ep32_l2_test_time 0.1309506893157959
Test Epoch32 layer3 Acc 0.9052631578947369, AUC 0.9678362607955933, avg_entr 0.008403145708143711
ep32_l3_test_time 0.16367554664611816
Test Epoch32 layer4 Acc 0.9052631578947369, AUC 0.9679917693138123, avg_entr 0.007289318833500147
ep32_l4_test_time 0.19632291793823242
gc 0
Train Epoch33 Acc 0.9765916666666666 (117191/120000), AUC 0.9967589378356934
ep33_train_time 18.496320009231567
Test Epoch33 layer0 Acc 0.9100328947368421, AUC 0.9783792495727539, avg_entr 0.0384814478456974
ep33_l0_test_time 0.08812284469604492
Test Epoch33 layer1 Acc 0.9070723684210527, AUC 0.9698521494865417, avg_entr 0.014750235714018345
ep33_l1_test_time 0.12302565574645996
Test Epoch33 layer2 Acc 0.9055921052631579, AUC 0.9708483219146729, avg_entr 0.009835670702159405
ep33_l2_test_time 0.15587639808654785
Test Epoch33 layer3 Acc 0.9057565789473684, AUC 0.9678677320480347, avg_entr 0.008225949481129646
ep33_l3_test_time 0.1900467872619629
Test Epoch33 layer4 Acc 0.9049342105263158, AUC 0.9677222967147827, avg_entr 0.007099749520421028
ep33_l4_test_time 0.22429728507995605
gc 0
Train Epoch34 Acc 0.9767583333333333 (117211/120000), AUC 0.9967681765556335
ep34_train_time 20.456329107284546
Test Epoch34 layer0 Acc 0.9101973684210526, AUC 0.978375256061554, avg_entr 0.0384252592921257
ep34_l0_test_time 0.0851900577545166
Test Epoch34 layer1 Acc 0.9067434210526316, AUC 0.9697304964065552, avg_entr 0.014692401513457298
ep34_l1_test_time 0.12021422386169434
Test Epoch34 layer2 Acc 0.9047697368421053, AUC 0.9703970551490784, avg_entr 0.00983449723571539
ep34_l2_test_time 0.15399861335754395
Test Epoch34 layer3 Acc 0.9052631578947369, AUC 0.9673081636428833, avg_entr 0.00830603577196598
ep34_l3_test_time 0.18837738037109375
Test Epoch34 layer4 Acc 0.9050986842105263, AUC 0.9675936698913574, avg_entr 0.007180986925959587
ep34_l4_test_time 0.2224593162536621
gc 0
Train Epoch35 Acc 0.976775 (117213/120000), AUC 0.9967055320739746
ep35_train_time 19.642499923706055
Test Epoch35 layer0 Acc 0.9101973684210526, AUC 0.978369951248169, avg_entr 0.038393285125494
ep35_l0_test_time 0.06842422485351562
Test Epoch35 layer1 Acc 0.9067434210526316, AUC 0.9698383212089539, avg_entr 0.014715318568050861
ep35_l1_test_time 0.09854388236999512
Test Epoch35 layer2 Acc 0.9049342105263158, AUC 0.9708350300788879, avg_entr 0.009895892813801765
ep35_l2_test_time 0.13090896606445312
Test Epoch35 layer3 Acc 0.9054276315789473, AUC 0.9679313898086548, avg_entr 0.008369437418878078
ep35_l3_test_time 0.16356563568115234
Test Epoch35 layer4 Acc 0.9050986842105263, AUC 0.9678127765655518, avg_entr 0.007232699077576399
ep35_l4_test_time 0.19626402854919434
gc 0
Train Epoch36 Acc 0.97675 (117210/120000), AUC 0.9966601133346558
ep36_train_time 17.90088963508606
Test Epoch36 layer0 Acc 0.9101973684210526, AUC 0.978367269039154, avg_entr 0.03836563602089882
ep36_l0_test_time 0.06819772720336914
Test Epoch36 layer1 Acc 0.90625, AUC 0.9697070121765137, avg_entr 0.014676869846880436
ep36_l1_test_time 0.09901881217956543
Test Epoch36 layer2 Acc 0.9046052631578947, AUC 0.9705833196640015, avg_entr 0.009832305833697319
ep36_l2_test_time 0.1309797763824463
Test Epoch36 layer3 Acc 0.9050986842105263, AUC 0.9674659967422485, avg_entr 0.008317074738442898
ep36_l3_test_time 0.16379404067993164
Test Epoch36 layer4 Acc 0.9057565789473684, AUC 0.968023955821991, avg_entr 0.007282156031578779
ep36_l4_test_time 0.1961979866027832
gc 0
Train Epoch37 Acc 0.97675 (117210/120000), AUC 0.9967421293258667
ep37_train_time 18.017018795013428
Test Epoch37 layer0 Acc 0.9100328947368421, AUC 0.9783675670623779, avg_entr 0.03833020478487015
ep37_l0_test_time 0.06787729263305664
Test Epoch37 layer1 Acc 0.9060855263157894, AUC 0.9697643518447876, avg_entr 0.014670242555439472
ep37_l1_test_time 0.09869647026062012
Test Epoch37 layer2 Acc 0.9046052631578947, AUC 0.9706696271896362, avg_entr 0.00982092134654522
ep37_l2_test_time 0.13051939010620117
Test Epoch37 layer3 Acc 0.9052631578947369, AUC 0.9676142930984497, avg_entr 0.00831947848200798
ep37_l3_test_time 0.16393494606018066
Test Epoch37 layer4 Acc 0.9054276315789473, AUC 0.9680898785591125, avg_entr 0.007314721588045359
ep37_l4_test_time 0.1972198486328125
gc 0
Train Epoch38 Acc 0.9767833333333333 (117214/120000), AUC 0.9966550469398499
ep38_train_time 18.830026626586914
Test Epoch38 layer0 Acc 0.9100328947368421, AUC 0.978364884853363, avg_entr 0.03831062465906143
ep38_l0_test_time 0.0673210620880127
Test Epoch38 layer1 Acc 0.905921052631579, AUC 0.9697918891906738, avg_entr 0.014658356085419655
ep38_l1_test_time 0.09838676452636719
Test Epoch38 layer2 Acc 0.9044407894736842, AUC 0.970674455165863, avg_entr 0.009841338731348515
ep38_l2_test_time 0.13118886947631836
Test Epoch38 layer3 Acc 0.9049342105263158, AUC 0.9675114154815674, avg_entr 0.008398533798754215
ep38_l3_test_time 0.16382694244384766
Test Epoch38 layer4 Acc 0.9050986842105263, AUC 0.9678647518157959, avg_entr 0.007360755931586027
ep38_l4_test_time 0.1958463191986084
gc 0
Train Epoch39 Acc 0.976825 (117219/120000), AUC 0.9966500997543335
ep39_train_time 18.04387855529785
Test Epoch39 layer0 Acc 0.9100328947368421, AUC 0.9783605337142944, avg_entr 0.03830163925886154
ep39_l0_test_time 0.06821417808532715
Test Epoch39 layer1 Acc 0.9064144736842106, AUC 0.9697688817977905, avg_entr 0.014654395170509815
ep39_l1_test_time 0.09913849830627441
Test Epoch39 layer2 Acc 0.9046052631578947, AUC 0.9707465171813965, avg_entr 0.009873831644654274
ep39_l2_test_time 0.13079023361206055
Test Epoch39 layer3 Acc 0.9049342105263158, AUC 0.9676977396011353, avg_entr 0.008393257856369019
ep39_l3_test_time 0.16337275505065918
Test Epoch39 layer4 Acc 0.9050986842105263, AUC 0.967870831489563, avg_entr 0.0072818356566131115
ep39_l4_test_time 0.19609904289245605
gc 0
Train Epoch40 Acc 0.9769166666666667 (117230/120000), AUC 0.9967237114906311
ep40_train_time 20.640723943710327
Test Epoch40 layer0 Acc 0.9100328947368421, AUC 0.9783601760864258, avg_entr 0.038286492228507996
ep40_l0_test_time 0.12416481971740723
Test Epoch40 layer1 Acc 0.9060855263157894, AUC 0.9697345495223999, avg_entr 0.014648541808128357
ep40_l1_test_time 0.20174384117126465
Test Epoch40 layer2 Acc 0.9044407894736842, AUC 0.970732569694519, avg_entr 0.00985417328774929
ep40_l2_test_time 0.24889779090881348
Test Epoch40 layer3 Acc 0.9049342105263158, AUC 0.9676761627197266, avg_entr 0.00838402472436428
ep40_l3_test_time 0.2977924346923828
Test Epoch40 layer4 Acc 0.9049342105263158, AUC 0.9679239988327026, avg_entr 0.007300152909010649
ep40_l4_test_time 0.34644031524658203
gc 0
Train Epoch41 Acc 0.9769 (117228/120000), AUC 0.9968389272689819
ep41_train_time 19.487709283828735
Test Epoch41 layer0 Acc 0.9100328947368421, AUC 0.9783582091331482, avg_entr 0.03827453777194023
ep41_l0_test_time 0.06771016120910645
Test Epoch41 layer1 Acc 0.9064144736842106, AUC 0.9697247743606567, avg_entr 0.014640052802860737
ep41_l1_test_time 0.09972882270812988
Test Epoch41 layer2 Acc 0.9047697368421053, AUC 0.9707647562026978, avg_entr 0.009870185516774654
ep41_l2_test_time 0.13118839263916016
Test Epoch41 layer3 Acc 0.9047697368421053, AUC 0.9676659107208252, avg_entr 0.008393190801143646
ep41_l3_test_time 0.1637580394744873
Test Epoch41 layer4 Acc 0.9050986842105263, AUC 0.9678831696510315, avg_entr 0.007283075712621212
ep41_l4_test_time 0.1967911720275879
gc 0
Train Epoch42 Acc 0.9768416666666667 (117221/120000), AUC 0.9966181516647339
ep42_train_time 18.02540874481201
Test Epoch42 layer0 Acc 0.9101973684210526, AUC 0.9783576726913452, avg_entr 0.0382610522210598
ep42_l0_test_time 0.06850528717041016
Test Epoch42 layer1 Acc 0.9060855263157894, AUC 0.9697363376617432, avg_entr 0.014636905863881111
ep42_l1_test_time 0.09883618354797363
Test Epoch42 layer2 Acc 0.9044407894736842, AUC 0.9707027077674866, avg_entr 0.009836195968091488
ep42_l2_test_time 0.13098740577697754
Test Epoch42 layer3 Acc 0.9049342105263158, AUC 0.967585563659668, avg_entr 0.008351416327059269
ep42_l3_test_time 0.16368913650512695
Test Epoch42 layer4 Acc 0.9049342105263158, AUC 0.9678704738616943, avg_entr 0.007283215876668692
ep42_l4_test_time 0.19563603401184082
gc 0
Train Epoch43 Acc 0.9769166666666667 (117230/120000), AUC 0.9966765642166138
ep43_train_time 18.440226078033447
Test Epoch43 layer0 Acc 0.9101973684210526, AUC 0.9783564805984497, avg_entr 0.03825495392084122
ep43_l0_test_time 0.06789898872375488
Test Epoch43 layer1 Acc 0.9060855263157894, AUC 0.9697308540344238, avg_entr 0.014634225517511368
ep43_l1_test_time 0.09848284721374512
Test Epoch43 layer2 Acc 0.9044407894736842, AUC 0.9706730842590332, avg_entr 0.009839283302426338
ep43_l2_test_time 0.13106822967529297
Test Epoch43 layer3 Acc 0.9049342105263158, AUC 0.9675495028495789, avg_entr 0.00835287757217884
ep43_l3_test_time 0.16337132453918457
Test Epoch43 layer4 Acc 0.9049342105263158, AUC 0.9678646326065063, avg_entr 0.0072788032703101635
ep43_l4_test_time 0.19570064544677734
gc 0
Train Epoch44 Acc 0.9769666666666666 (117236/120000), AUC 0.9966863393783569
ep44_train_time 18.30031681060791
Test Epoch44 layer0 Acc 0.9101973684210526, AUC 0.9783563017845154, avg_entr 0.03825049474835396
ep44_l0_test_time 0.06750845909118652
Test Epoch44 layer1 Acc 0.90625, AUC 0.9697608947753906, avg_entr 0.014633030630648136
ep44_l1_test_time 0.09871840476989746
Test Epoch44 layer2 Acc 0.9044407894736842, AUC 0.9706618189811707, avg_entr 0.0098508195951581
ep44_l2_test_time 0.13111424446105957
Test Epoch44 layer3 Acc 0.9050986842105263, AUC 0.9676072597503662, avg_entr 0.008379523642361164
ep44_l3_test_time 0.16362881660461426
Test Epoch44 layer4 Acc 0.9049342105263158, AUC 0.967860996723175, avg_entr 0.007283165585249662
ep44_l4_test_time 0.1958158016204834
gc 0
Train Epoch45 Acc 0.9768583333333334 (117223/120000), AUC 0.9967691898345947
ep45_train_time 17.946531057357788
Test Epoch45 layer0 Acc 0.9101973684210526, AUC 0.9783554077148438, avg_entr 0.03824720159173012
ep45_l0_test_time 0.06834864616394043
Test Epoch45 layer1 Acc 0.9064144736842106, AUC 0.9697645902633667, avg_entr 0.014633714221417904
ep45_l1_test_time 0.09942293167114258
Test Epoch45 layer2 Acc 0.9049342105263158, AUC 0.9707783460617065, avg_entr 0.00987499300390482
ep45_l2_test_time 0.13099384307861328
Test Epoch45 layer3 Acc 0.9049342105263158, AUC 0.9676753282546997, avg_entr 0.008409269154071808
ep45_l3_test_time 0.16365623474121094
Test Epoch45 layer4 Acc 0.9049342105263158, AUC 0.9678480625152588, avg_entr 0.007284276653081179
ep45_l4_test_time 0.196793794631958
gc 0
Train Epoch46 Acc 0.9769 (117228/120000), AUC 0.9966915249824524
ep46_train_time 18.394071578979492
Test Epoch46 layer0 Acc 0.9101973684210526, AUC 0.9783531427383423, avg_entr 0.038241032510995865
ep46_l0_test_time 0.06839346885681152
Test Epoch46 layer1 Acc 0.9064144736842106, AUC 0.9697469472885132, avg_entr 0.014632628299295902
ep46_l1_test_time 0.09893012046813965
Test Epoch46 layer2 Acc 0.9049342105263158, AUC 0.9706516861915588, avg_entr 0.009874117560684681
ep46_l2_test_time 0.13129901885986328
Test Epoch46 layer3 Acc 0.9049342105263158, AUC 0.9676015377044678, avg_entr 0.008400947786867619
ep46_l3_test_time 0.16468334197998047
Test Epoch46 layer4 Acc 0.9049342105263158, AUC 0.9678226709365845, avg_entr 0.0072777955792844296
ep46_l4_test_time 0.19646358489990234
gc 0
Train Epoch47 Acc 0.9769083333333334 (117229/120000), AUC 0.9967666268348694
ep47_train_time 17.97256302833557
Test Epoch47 layer0 Acc 0.9101973684210526, AUC 0.978354275226593, avg_entr 0.038237135857343674
ep47_l0_test_time 0.06781840324401855
Test Epoch47 layer1 Acc 0.9064144736842106, AUC 0.9697600603103638, avg_entr 0.01463339477777481
ep47_l1_test_time 0.09882473945617676
Test Epoch47 layer2 Acc 0.9047697368421053, AUC 0.9706597328186035, avg_entr 0.009867765940725803
ep47_l2_test_time 0.13124823570251465
Test Epoch47 layer3 Acc 0.9049342105263158, AUC 0.9676414132118225, avg_entr 0.008392482064664364
ep47_l3_test_time 0.1634056568145752
Test Epoch47 layer4 Acc 0.9047697368421053, AUC 0.96783447265625, avg_entr 0.007282941602170467
ep47_l4_test_time 0.19600415229797363
gc 0
Train Epoch48 Acc 0.9767583333333333 (117211/120000), AUC 0.9967072010040283
ep48_train_time 18.716504335403442
Test Epoch48 layer0 Acc 0.9101973684210526, AUC 0.9783532023429871, avg_entr 0.03823366016149521
ep48_l0_test_time 0.06873679161071777
Test Epoch48 layer1 Acc 0.9064144736842106, AUC 0.9697641730308533, avg_entr 0.01463401596993208
ep48_l1_test_time 0.09925270080566406
Test Epoch48 layer2 Acc 0.9049342105263158, AUC 0.9706978797912598, avg_entr 0.009874624200165272
ep48_l2_test_time 0.1307816505432129
Test Epoch48 layer3 Acc 0.9049342105263158, AUC 0.967659056186676, avg_entr 0.008401338942348957
ep48_l3_test_time 0.16314148902893066
Test Epoch48 layer4 Acc 0.9047697368421053, AUC 0.9678569436073303, avg_entr 0.007284426596015692
ep48_l4_test_time 0.19560742378234863
gc 0
Train Epoch49 Acc 0.9769666666666666 (117236/120000), AUC 0.9966989755630493
ep49_train_time 18.446874380111694
Test Epoch49 layer0 Acc 0.9101973684210526, AUC 0.97835373878479, avg_entr 0.03823108598589897
ep49_l0_test_time 0.06809782981872559
Test Epoch49 layer1 Acc 0.9064144736842106, AUC 0.9697670340538025, avg_entr 0.014631164260208607
ep49_l1_test_time 0.0988619327545166
Test Epoch49 layer2 Acc 0.9049342105263158, AUC 0.9706758260726929, avg_entr 0.009871852584183216
ep49_l2_test_time 0.13068795204162598
Test Epoch49 layer3 Acc 0.9049342105263158, AUC 0.9676517248153687, avg_entr 0.008402744308114052
ep49_l3_test_time 0.16312766075134277
Test Epoch49 layer4 Acc 0.9049342105263158, AUC 0.9678661227226257, avg_entr 0.0072855097241699696
ep49_l4_test_time 0.19620990753173828
Best AUC 0.9814894199371338
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_transformeral_l5_pad25//ag_news_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.9223684210526316, AUC 0.9860010147094727, avg_entr 0.09825393557548523
ep49_l0_test_time 0.018129348754882812
Test Epoch49 layer1 Acc 0.9243421052631579, AUC 0.9856746792793274, avg_entr 0.041327349841594696
ep49_l1_test_time 0.025005102157592773
Test Epoch49 layer2 Acc 0.9256578947368421, AUC 0.9871391654014587, avg_entr 0.03256066143512726
ep49_l2_test_time 0.03276968002319336
Test Epoch49 layer3 Acc 0.9243421052631579, AUC 0.987067699432373, avg_entr 0.03076024539768696
ep49_l3_test_time 0.040970802307128906
Test Epoch49 layer4 Acc 0.9230263157894737, AUC 0.986579179763794, avg_entr 0.029955143108963966
ep49_l4_test_time 0.04913020133972168
