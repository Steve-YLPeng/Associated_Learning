total count words 102019
vocab size 30000
found 26754 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13672292
Start Training
gc 0
Train Epoch0 Acc 0.615325 (73839/120000), AUC 0.8487653732299805
ep0_train_time 71.53850197792053
Test Epoch0 layer0 Acc 0.9018092105263158, AUC 0.97464919090271, avg_entr 0.2433261126279831
ep0_l0_test_time 0.21967720985412598
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9060855263157894, AUC 0.9767136573791504, avg_entr 0.16472244262695312
ep0_l1_test_time 0.401700496673584
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.9078947368421053, AUC 0.9770994186401367, avg_entr 0.1564636528491974
ep0_l2_test_time 0.5869719982147217
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer3 Acc 0.9072368421052631, AUC 0.9771609902381897, avg_entr 0.1582389622926712
ep0_l3_test_time 0.76424241065979
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer4 Acc 0.9026315789473685, AUC 0.9771409034729004, avg_entr 0.1646628975868225
ep0_l4_test_time 0.9451205730438232
gc 0
Train Epoch1 Acc 0.919825 (110379/120000), AUC 0.9812646508216858
ep1_train_time 71.3238627910614
Test Epoch1 layer0 Acc 0.9118421052631579, AUC 0.9782143831253052, avg_entr 0.14280693233013153
ep1_l0_test_time 0.21712493896484375
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.9146381578947368, AUC 0.9801167845726013, avg_entr 0.08487791568040848
ep1_l1_test_time 0.4033689498901367
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.9136513157894737, AUC 0.9800158739089966, avg_entr 0.07059185951948166
ep1_l2_test_time 0.5871834754943848
Test Epoch1 layer3 Acc 0.9138157894736842, AUC 0.9799857139587402, avg_entr 0.06535147875547409
ep1_l3_test_time 0.7619092464447021
Test Epoch1 layer4 Acc 0.9138157894736842, AUC 0.9800167083740234, avg_entr 0.060804542154073715
ep1_l4_test_time 0.9422938823699951
gc 0
Train Epoch2 Acc 0.9339833333333334 (112078/120000), AUC 0.9865382313728333
ep2_train_time 71.20545029640198
Test Epoch2 layer0 Acc 0.9149671052631579, AUC 0.9797452688217163, avg_entr 0.10924039036035538
ep2_l0_test_time 0.21651554107666016
Test Epoch2 layer1 Acc 0.9174342105263158, AUC 0.9824614524841309, avg_entr 0.04601462557911873
ep2_l1_test_time 0.40024709701538086
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 2
Test Epoch2 layer2 Acc 0.9166118421052631, AUC 0.9817898273468018, avg_entr 0.03955329209566116
ep2_l2_test_time 0.584601640701294
Test Epoch2 layer3 Acc 0.9159539473684211, AUC 0.9818006753921509, avg_entr 0.03661654517054558
ep2_l3_test_time 0.7612447738647461
Test Epoch2 layer4 Acc 0.9166118421052631, AUC 0.9819486141204834, avg_entr 0.03475514054298401
ep2_l4_test_time 0.9416241645812988
gc 0
Train Epoch3 Acc 0.94205 (113046/120000), AUC 0.9888519644737244
ep3_train_time 71.2059862613678
Test Epoch3 layer0 Acc 0.9171052631578948, AUC 0.9805030822753906, avg_entr 0.09332403540611267
ep3_l0_test_time 0.2170875072479248
Test Epoch3 layer1 Acc 0.9164473684210527, AUC 0.979515790939331, avg_entr 0.03481568396091461
ep3_l1_test_time 0.4012582302093506
Test Epoch3 layer2 Acc 0.9172697368421052, AUC 0.9794542789459229, avg_entr 0.03032897599041462
ep3_l2_test_time 0.5824525356292725
Test Epoch3 layer3 Acc 0.9175986842105263, AUC 0.9801766872406006, avg_entr 0.02837030217051506
ep3_l3_test_time 0.7619073390960693
Test Epoch3 layer4 Acc 0.9166118421052631, AUC 0.9804239273071289, avg_entr 0.02710122987627983
ep3_l4_test_time 0.9424939155578613
gc 0
Train Epoch4 Acc 0.9481916666666667 (113783/120000), AUC 0.9902219772338867
ep4_train_time 71.17825865745544
Test Epoch4 layer0 Acc 0.9144736842105263, AUC 0.9806081056594849, avg_entr 0.08120556175708771
ep4_l0_test_time 0.21725940704345703
Test Epoch4 layer1 Acc 0.9151315789473684, AUC 0.9789499640464783, avg_entr 0.03058292530477047
ep4_l1_test_time 0.4003019332885742
Test Epoch4 layer2 Acc 0.9161184210526315, AUC 0.9787254333496094, avg_entr 0.02670152299106121
ep4_l2_test_time 0.5829706192016602
Test Epoch4 layer3 Acc 0.9166118421052631, AUC 0.9800182580947876, avg_entr 0.025232011452317238
ep4_l3_test_time 0.7615249156951904
Test Epoch4 layer4 Acc 0.9162828947368421, AUC 0.9800029993057251, avg_entr 0.02310427650809288
ep4_l4_test_time 0.9421916007995605
gc 0
Train Epoch5 Acc 0.9521416666666667 (114257/120000), AUC 0.9912965297698975
ep5_train_time 71.3104600906372
Test Epoch5 layer0 Acc 0.9126644736842106, AUC 0.980755627155304, avg_entr 0.07411526888608932
ep5_l0_test_time 0.2171189785003662
Test Epoch5 layer1 Acc 0.9151315789473684, AUC 0.9774823188781738, avg_entr 0.026074597612023354
ep5_l1_test_time 0.4009859561920166
Test Epoch5 layer2 Acc 0.915296052631579, AUC 0.9772030115127563, avg_entr 0.021755941212177277
ep5_l2_test_time 0.5829246044158936
Test Epoch5 layer3 Acc 0.915296052631579, AUC 0.9794174432754517, avg_entr 0.02072324976325035
ep5_l3_test_time 0.7612230777740479
Test Epoch5 layer4 Acc 0.9148026315789474, AUC 0.979425311088562, avg_entr 0.018674559891223907
ep5_l4_test_time 0.9418473243713379
gc 0
Train Epoch6 Acc 0.95505 (114606/120000), AUC 0.9922199249267578
ep6_train_time 71.28281855583191
Test Epoch6 layer0 Acc 0.912828947368421, AUC 0.9806195497512817, avg_entr 0.07099922746419907
ep6_l0_test_time 0.2166738510131836
Test Epoch6 layer1 Acc 0.9101973684210526, AUC 0.9792027473449707, avg_entr 0.02477968856692314
ep6_l1_test_time 0.4012033939361572
Test Epoch6 layer2 Acc 0.9110197368421052, AUC 0.9794090986251831, avg_entr 0.02086627297103405
ep6_l2_test_time 0.5836179256439209
Test Epoch6 layer3 Acc 0.9100328947368421, AUC 0.9797991514205933, avg_entr 0.019737256690859795
ep6_l3_test_time 0.7620131969451904
Test Epoch6 layer4 Acc 0.9097039473684211, AUC 0.9801414608955383, avg_entr 0.01805879920721054
ep6_l4_test_time 0.9415841102600098
gc 0
Train Epoch7 Acc 0.9581083333333333 (114973/120000), AUC 0.9930806756019592
ep7_train_time 71.21345353126526
Test Epoch7 layer0 Acc 0.915625, AUC 0.9806708097457886, avg_entr 0.06256790459156036
ep7_l0_test_time 0.2165982723236084
Test Epoch7 layer1 Acc 0.9103618421052632, AUC 0.97770094871521, avg_entr 0.02225619927048683
ep7_l1_test_time 0.400235652923584
Test Epoch7 layer2 Acc 0.9115131578947369, AUC 0.9779120087623596, avg_entr 0.017456967383623123
ep7_l2_test_time 0.5821835994720459
Test Epoch7 layer3 Acc 0.9111842105263158, AUC 0.9792572259902954, avg_entr 0.015669843181967735
ep7_l3_test_time 0.7603006362915039
Test Epoch7 layer4 Acc 0.9118421052631579, AUC 0.9794529676437378, avg_entr 0.014276081696152687
ep7_l4_test_time 0.9408044815063477
gc 0
Train Epoch8 Acc 0.959925 (115191/120000), AUC 0.9936502575874329
ep8_train_time 71.22869372367859
Test Epoch8 layer0 Acc 0.9136513157894737, AUC 0.980576753616333, avg_entr 0.059328366070985794
ep8_l0_test_time 0.21768403053283691
Test Epoch8 layer1 Acc 0.9092105263157895, AUC 0.9770756959915161, avg_entr 0.020829636603593826
ep8_l1_test_time 0.4005262851715088
Test Epoch8 layer2 Acc 0.9105263157894737, AUC 0.9774500727653503, avg_entr 0.016531065106391907
ep8_l2_test_time 0.5831618309020996
Test Epoch8 layer3 Acc 0.9100328947368421, AUC 0.978759765625, avg_entr 0.015115795657038689
ep8_l3_test_time 0.7599000930786133
Test Epoch8 layer4 Acc 0.9100328947368421, AUC 0.9792770147323608, avg_entr 0.013737264089286327
ep8_l4_test_time 0.9413232803344727
gc 0
Train Epoch9 Acc 0.9615333333333334 (115384/120000), AUC 0.9938511848449707
ep9_train_time 71.20129346847534
Test Epoch9 layer0 Acc 0.9151315789473684, AUC 0.9803186655044556, avg_entr 0.05539728328585625
ep9_l0_test_time 0.22007369995117188
Test Epoch9 layer1 Acc 0.9097039473684211, AUC 0.9754650592803955, avg_entr 0.019260134547948837
ep9_l1_test_time 0.4007906913757324
Test Epoch9 layer2 Acc 0.9101973684210526, AUC 0.9776484370231628, avg_entr 0.014658256433904171
ep9_l2_test_time 0.5827338695526123
Test Epoch9 layer3 Acc 0.9105263157894737, AUC 0.9792871475219727, avg_entr 0.013211325742304325
ep9_l3_test_time 0.7613346576690674
Test Epoch9 layer4 Acc 0.9095394736842105, AUC 0.9785648584365845, avg_entr 0.011854605749249458
ep9_l4_test_time 0.9414980411529541
gc 0
Train Epoch10 Acc 0.9644083333333333 (115729/120000), AUC 0.9946532249450684
ep10_train_time 71.20746946334839
Test Epoch10 layer0 Acc 0.9161184210526315, AUC 0.9802465438842773, avg_entr 0.05416838079690933
ep10_l0_test_time 0.2171037197113037
Test Epoch10 layer1 Acc 0.9095394736842105, AUC 0.9736864566802979, avg_entr 0.01898600161075592
ep10_l1_test_time 0.40076184272766113
Test Epoch10 layer2 Acc 0.9085526315789474, AUC 0.9747660160064697, avg_entr 0.014389106072485447
ep10_l2_test_time 0.5828416347503662
Test Epoch10 layer3 Acc 0.9088815789473684, AUC 0.9754842519760132, avg_entr 0.012778660282492638
ep10_l3_test_time 0.7618446350097656
Test Epoch10 layer4 Acc 0.9090460526315789, AUC 0.9740179181098938, avg_entr 0.01136417593806982
ep10_l4_test_time 0.9415202140808105
gc 0
Train Epoch11 Acc 0.965625 (115875/120000), AUC 0.9951350688934326
ep11_train_time 71.26843070983887
Test Epoch11 layer0 Acc 0.9154605263157894, AUC 0.9800750613212585, avg_entr 0.052499160170555115
ep11_l0_test_time 0.22002744674682617
Test Epoch11 layer1 Acc 0.9087171052631579, AUC 0.9731934070587158, avg_entr 0.018444957211613655
ep11_l1_test_time 0.401165246963501
Test Epoch11 layer2 Acc 0.9080592105263158, AUC 0.9749009609222412, avg_entr 0.01390767376869917
ep11_l2_test_time 0.5833451747894287
Test Epoch11 layer3 Acc 0.9075657894736842, AUC 0.9750624895095825, avg_entr 0.01238154899328947
ep11_l3_test_time 0.7616522312164307
Test Epoch11 layer4 Acc 0.9077302631578947, AUC 0.9742082357406616, avg_entr 0.01109375711530447
ep11_l4_test_time 0.9425556659698486
gc 0
Train Epoch12 Acc 0.9663166666666667 (115958/120000), AUC 0.9950980544090271
ep12_train_time 71.22997570037842
Test Epoch12 layer0 Acc 0.9154605263157894, AUC 0.9799883365631104, avg_entr 0.05029977113008499
ep12_l0_test_time 0.21693634986877441
Test Epoch12 layer1 Acc 0.9080592105263158, AUC 0.9732486009597778, avg_entr 0.01764640212059021
ep12_l1_test_time 0.40030360221862793
Test Epoch12 layer2 Acc 0.9082236842105263, AUC 0.9744211435317993, avg_entr 0.01328456774353981
ep12_l2_test_time 0.58243727684021
Test Epoch12 layer3 Acc 0.9085526315789474, AUC 0.9747034311294556, avg_entr 0.011685820296406746
ep12_l3_test_time 0.7613394260406494
Test Epoch12 layer4 Acc 0.9083881578947368, AUC 0.9735662341117859, avg_entr 0.01053120568394661
ep12_l4_test_time 0.9422533512115479
gc 0
Train Epoch13 Acc 0.9672333333333333 (116068/120000), AUC 0.9954416751861572
ep13_train_time 71.27800559997559
Test Epoch13 layer0 Acc 0.9144736842105263, AUC 0.9799028635025024, avg_entr 0.04826568812131882
ep13_l0_test_time 0.21785831451416016
Test Epoch13 layer1 Acc 0.9080592105263158, AUC 0.9726255536079407, avg_entr 0.017265761271119118
ep13_l1_test_time 0.40059614181518555
Test Epoch13 layer2 Acc 0.9070723684210527, AUC 0.9734327793121338, avg_entr 0.01311515923589468
ep13_l2_test_time 0.5826911926269531
Test Epoch13 layer3 Acc 0.90625, AUC 0.9749711751937866, avg_entr 0.011605298146605492
ep13_l3_test_time 0.7614185810089111
Test Epoch13 layer4 Acc 0.9069078947368421, AUC 0.9755154252052307, avg_entr 0.010668681003153324
ep13_l4_test_time 0.9414675235748291
gc 0
Train Epoch14 Acc 0.9686583333333333 (116239/120000), AUC 0.9956604838371277
ep14_train_time 71.25006365776062
Test Epoch14 layer0 Acc 0.9148026315789474, AUC 0.9799133539199829, avg_entr 0.04724167659878731
ep14_l0_test_time 0.21691608428955078
Test Epoch14 layer1 Acc 0.9072368421052631, AUC 0.9715584516525269, avg_entr 0.017740879207849503
ep14_l1_test_time 0.40085792541503906
Test Epoch14 layer2 Acc 0.9060855263157894, AUC 0.971398115158081, avg_entr 0.013067340478301048
ep14_l2_test_time 0.5830538272857666
Test Epoch14 layer3 Acc 0.9060855263157894, AUC 0.9719148278236389, avg_entr 0.010958396829664707
ep14_l3_test_time 0.7613894939422607
Test Epoch14 layer4 Acc 0.9054276315789473, AUC 0.9723218083381653, avg_entr 0.009649962186813354
ep14_l4_test_time 0.9414563179016113
gc 0
Train Epoch15 Acc 0.969425 (116331/120000), AUC 0.9959551692008972
ep15_train_time 71.29828238487244
Test Epoch15 layer0 Acc 0.9143092105263158, AUC 0.9798314571380615, avg_entr 0.04636333882808685
ep15_l0_test_time 0.21703577041625977
Test Epoch15 layer1 Acc 0.9069078947368421, AUC 0.9718657732009888, avg_entr 0.016909245401620865
ep15_l1_test_time 0.4009511470794678
Test Epoch15 layer2 Acc 0.9064144736842106, AUC 0.9716268181800842, avg_entr 0.01231903862208128
ep15_l2_test_time 0.5836191177368164
Test Epoch15 layer3 Acc 0.906578947368421, AUC 0.9729772806167603, avg_entr 0.010596925392746925
ep15_l3_test_time 0.761246919631958
Test Epoch15 layer4 Acc 0.9064144736842106, AUC 0.9728907346725464, avg_entr 0.009550592862069607
ep15_l4_test_time 0.9420278072357178
gc 0
Train Epoch16 Acc 0.9697583333333334 (116371/120000), AUC 0.9959088563919067
ep16_train_time 71.29924750328064
Test Epoch16 layer0 Acc 0.9134868421052632, AUC 0.9797906279563904, avg_entr 0.04472752660512924
ep16_l0_test_time 0.21653485298156738
Test Epoch16 layer1 Acc 0.9087171052631579, AUC 0.9721185564994812, avg_entr 0.01616089604794979
ep16_l1_test_time 0.40081071853637695
Test Epoch16 layer2 Acc 0.9067434210526316, AUC 0.972111701965332, avg_entr 0.011882424354553223
ep16_l2_test_time 0.5833468437194824
Test Epoch16 layer3 Acc 0.9069078947368421, AUC 0.9731789231300354, avg_entr 0.010258729569613934
ep16_l3_test_time 0.7614281177520752
Test Epoch16 layer4 Acc 0.906578947368421, AUC 0.973119854927063, avg_entr 0.009312882088124752
ep16_l4_test_time 0.9420809745788574
gc 0
Train Epoch17 Acc 0.9699333333333333 (116392/120000), AUC 0.9958732724189758
ep17_train_time 71.29395365715027
Test Epoch17 layer0 Acc 0.9129934210526316, AUC 0.9797974824905396, avg_entr 0.043469447642564774
ep17_l0_test_time 0.21762371063232422
Test Epoch17 layer1 Acc 0.9078947368421053, AUC 0.9716852903366089, avg_entr 0.016282618045806885
ep17_l1_test_time 0.4004995822906494
Test Epoch17 layer2 Acc 0.905921052631579, AUC 0.9725881814956665, avg_entr 0.011891329661011696
ep17_l2_test_time 0.5836811065673828
Test Epoch17 layer3 Acc 0.90625, AUC 0.9736682176589966, avg_entr 0.010173955000936985
ep17_l3_test_time 0.7605557441711426
Test Epoch17 layer4 Acc 0.9055921052631579, AUC 0.9726606607437134, avg_entr 0.009288232773542404
ep17_l4_test_time 0.94095778465271
gc 0
Train Epoch18 Acc 0.9704 (116448/120000), AUC 0.9960389733314514
ep18_train_time 71.26819133758545
Test Epoch18 layer0 Acc 0.9131578947368421, AUC 0.9797710180282593, avg_entr 0.04249347001314163
ep18_l0_test_time 0.2169194221496582
Test Epoch18 layer1 Acc 0.9077302631578947, AUC 0.9709259271621704, avg_entr 0.01533817034214735
ep18_l1_test_time 0.4000058174133301
Test Epoch18 layer2 Acc 0.9064144736842106, AUC 0.9716922044754028, avg_entr 0.010932756587862968
ep18_l2_test_time 0.5819242000579834
Test Epoch18 layer3 Acc 0.905921052631579, AUC 0.9713250398635864, avg_entr 0.009088684804737568
ep18_l3_test_time 0.7599334716796875
Test Epoch18 layer4 Acc 0.9060855263157894, AUC 0.9704514145851135, avg_entr 0.008153549395501614
ep18_l4_test_time 0.9412028789520264
gc 0
Train Epoch19 Acc 0.970925 (116511/120000), AUC 0.9961425065994263
ep19_train_time 71.31359672546387
Test Epoch19 layer0 Acc 0.9129934210526316, AUC 0.979777455329895, avg_entr 0.04121445119380951
ep19_l0_test_time 0.21866750717163086
Test Epoch19 layer1 Acc 0.9080592105263158, AUC 0.9709099531173706, avg_entr 0.015253305435180664
ep19_l1_test_time 0.40211939811706543
Test Epoch19 layer2 Acc 0.9060855263157894, AUC 0.9709783792495728, avg_entr 0.011000065132975578
ep19_l2_test_time 0.5849952697753906
Test Epoch19 layer3 Acc 0.906578947368421, AUC 0.9701327085494995, avg_entr 0.009329942986369133
ep19_l3_test_time 0.7620632648468018
Test Epoch19 layer4 Acc 0.9057565789473684, AUC 0.9686535596847534, avg_entr 0.008417547680437565
ep19_l4_test_time 0.9424686431884766
gc 0
Train Epoch20 Acc 0.97125 (116550/120000), AUC 0.996130108833313
ep20_train_time 71.27442669868469
Test Epoch20 layer0 Acc 0.9134868421052632, AUC 0.9797621965408325, avg_entr 0.04030294716358185
ep20_l0_test_time 0.21816396713256836
Test Epoch20 layer1 Acc 0.9070723684210527, AUC 0.9708373546600342, avg_entr 0.015002107247710228
ep20_l1_test_time 0.4016427993774414
Test Epoch20 layer2 Acc 0.905921052631579, AUC 0.97076416015625, avg_entr 0.010905282571911812
ep20_l2_test_time 0.5843939781188965
Test Epoch20 layer3 Acc 0.905921052631579, AUC 0.9698404669761658, avg_entr 0.009260263293981552
ep20_l3_test_time 0.7614898681640625
Test Epoch20 layer4 Acc 0.9054276315789473, AUC 0.9684824347496033, avg_entr 0.008365066722035408
ep20_l4_test_time 0.942152738571167
gc 0
Train Epoch21 Acc 0.97135 (116562/120000), AUC 0.996218740940094
ep21_train_time 71.30989289283752
Test Epoch21 layer0 Acc 0.9126644736842106, AUC 0.9797248244285583, avg_entr 0.03968692198395729
ep21_l0_test_time 0.21763920783996582
Test Epoch21 layer1 Acc 0.9072368421052631, AUC 0.9708003401756287, avg_entr 0.014739297330379486
ep21_l1_test_time 0.401339054107666
Test Epoch21 layer2 Acc 0.905921052631579, AUC 0.9708247780799866, avg_entr 0.010463492944836617
ep21_l2_test_time 0.5841279029846191
Test Epoch21 layer3 Acc 0.905921052631579, AUC 0.9696439504623413, avg_entr 0.008875276893377304
ep21_l3_test_time 0.7613840103149414
Test Epoch21 layer4 Acc 0.9057565789473684, AUC 0.9679058790206909, avg_entr 0.008009309880435467
ep21_l4_test_time 0.9445605278015137
gc 0
Train Epoch22 Acc 0.9718916666666667 (116627/120000), AUC 0.9963453412055969
ep22_train_time 71.29710078239441
Test Epoch22 layer0 Acc 0.912828947368421, AUC 0.9797334671020508, avg_entr 0.03964630141854286
ep22_l0_test_time 0.21643900871276855
Test Epoch22 layer1 Acc 0.9072368421052631, AUC 0.9707671999931335, avg_entr 0.015047102235257626
ep22_l1_test_time 0.40102267265319824
Test Epoch22 layer2 Acc 0.9039473684210526, AUC 0.9707383513450623, avg_entr 0.01104762777686119
ep22_l2_test_time 0.5828578472137451
Test Epoch22 layer3 Acc 0.9041118421052632, AUC 0.9696558713912964, avg_entr 0.009440591558814049
ep22_l3_test_time 0.761436939239502
Test Epoch22 layer4 Acc 0.9039473684210526, AUC 0.9684263467788696, avg_entr 0.008528109639883041
ep22_l4_test_time 0.9421815872192383
gc 0
Train Epoch23 Acc 0.9721416666666667 (116657/120000), AUC 0.9964221715927124
ep23_train_time 71.36720633506775
Test Epoch23 layer0 Acc 0.912828947368421, AUC 0.9797129034996033, avg_entr 0.03898169845342636
ep23_l0_test_time 0.2168571949005127
Test Epoch23 layer1 Acc 0.9074013157894737, AUC 0.9704937934875488, avg_entr 0.014707474038004875
ep23_l1_test_time 0.40129709243774414
Test Epoch23 layer2 Acc 0.905921052631579, AUC 0.96986323595047, avg_entr 0.01070877630263567
ep23_l2_test_time 0.5837397575378418
Test Epoch23 layer3 Acc 0.9060855263157894, AUC 0.9684065580368042, avg_entr 0.009194969199597836
ep23_l3_test_time 0.7619080543518066
Test Epoch23 layer4 Acc 0.9055921052631579, AUC 0.966727614402771, avg_entr 0.008328607305884361
ep23_l4_test_time 0.9417612552642822
gc 0
Train Epoch24 Acc 0.9721333333333333 (116656/120000), AUC 0.99626225233078
ep24_train_time 71.22632169723511
Test Epoch24 layer0 Acc 0.912828947368421, AUC 0.9797036051750183, avg_entr 0.03886066749691963
ep24_l0_test_time 0.21725034713745117
Test Epoch24 layer1 Acc 0.9075657894736842, AUC 0.9705557823181152, avg_entr 0.014452568255364895
ep24_l1_test_time 0.4013042449951172
Test Epoch24 layer2 Acc 0.905921052631579, AUC 0.9706454277038574, avg_entr 0.010415979661047459
ep24_l2_test_time 0.5833652019500732
Test Epoch24 layer3 Acc 0.9055921052631579, AUC 0.9693663120269775, avg_entr 0.008912785910069942
ep24_l3_test_time 0.7622919082641602
Test Epoch24 layer4 Acc 0.9054276315789473, AUC 0.9679806232452393, avg_entr 0.008138530887663364
ep24_l4_test_time 0.9424505233764648
gc 0
Train Epoch25 Acc 0.9722083333333333 (116665/120000), AUC 0.9963694214820862
ep25_train_time 71.33216047286987
Test Epoch25 layer0 Acc 0.9123355263157895, AUC 0.9796937704086304, avg_entr 0.03843982145190239
ep25_l0_test_time 0.22150015830993652
Test Epoch25 layer1 Acc 0.9075657894736842, AUC 0.9706493020057678, avg_entr 0.014232187531888485
ep25_l1_test_time 0.40146565437316895
Test Epoch25 layer2 Acc 0.905921052631579, AUC 0.9707714915275574, avg_entr 0.01019308902323246
ep25_l2_test_time 0.5831735134124756
Test Epoch25 layer3 Acc 0.9060855263157894, AUC 0.9692949652671814, avg_entr 0.008661591447889805
ep25_l3_test_time 0.7615540027618408
Test Epoch25 layer4 Acc 0.905921052631579, AUC 0.967288076877594, avg_entr 0.00781610794365406
ep25_l4_test_time 0.9425218105316162
gc 0
Train Epoch26 Acc 0.9724166666666667 (116690/120000), AUC 0.9964212775230408
ep26_train_time 71.35942792892456
Test Epoch26 layer0 Acc 0.9129934210526316, AUC 0.9797120690345764, avg_entr 0.03825586661696434
ep26_l0_test_time 0.2171015739440918
Test Epoch26 layer1 Acc 0.9075657894736842, AUC 0.9706878662109375, avg_entr 0.01430354081094265
ep26_l1_test_time 0.4000582695007324
Test Epoch26 layer2 Acc 0.9060855263157894, AUC 0.9705145359039307, avg_entr 0.010233472101390362
ep26_l2_test_time 0.5825250148773193
Test Epoch26 layer3 Acc 0.906578947368421, AUC 0.9691448211669922, avg_entr 0.008696191944181919
ep26_l3_test_time 0.7609615325927734
Test Epoch26 layer4 Acc 0.9060855263157894, AUC 0.9670119881629944, avg_entr 0.007925646379590034
ep26_l4_test_time 0.9409265518188477
gc 0
Train Epoch27 Acc 0.97245 (116694/120000), AUC 0.9963688850402832
ep27_train_time 71.28059434890747
Test Epoch27 layer0 Acc 0.9125, AUC 0.9796964526176453, avg_entr 0.03812621906399727
ep27_l0_test_time 0.21924567222595215
Test Epoch27 layer1 Acc 0.9077302631578947, AUC 0.9707556962966919, avg_entr 0.01433017011731863
ep27_l1_test_time 0.40049219131469727
Test Epoch27 layer2 Acc 0.9050986842105263, AUC 0.9711250066757202, avg_entr 0.01037472952157259
ep27_l2_test_time 0.5828394889831543
Test Epoch27 layer3 Acc 0.9049342105263158, AUC 0.9698545932769775, avg_entr 0.008857857435941696
ep27_l3_test_time 0.7611100673675537
Test Epoch27 layer4 Acc 0.9042763157894737, AUC 0.9679744839668274, avg_entr 0.007956760935485363
ep27_l4_test_time 0.9417622089385986
gc 0
Train Epoch28 Acc 0.972425 (116691/120000), AUC 0.996509313583374
ep28_train_time 71.30062508583069
Test Epoch28 layer0 Acc 0.912828947368421, AUC 0.9797018766403198, avg_entr 0.03785211592912674
ep28_l0_test_time 0.2170426845550537
Test Epoch28 layer1 Acc 0.9080592105263158, AUC 0.9705237150192261, avg_entr 0.01419797446578741
ep28_l1_test_time 0.40032505989074707
Test Epoch28 layer2 Acc 0.9055921052631579, AUC 0.9702527523040771, avg_entr 0.010149666108191013
ep28_l2_test_time 0.5830564498901367
Test Epoch28 layer3 Acc 0.9060855263157894, AUC 0.968360185623169, avg_entr 0.00864906795322895
ep28_l3_test_time 0.7612087726593018
Test Epoch28 layer4 Acc 0.9054276315789473, AUC 0.9661335945129395, avg_entr 0.007787644863128662
ep28_l4_test_time 0.942166805267334
gc 0
Train Epoch29 Acc 0.9725083333333333 (116701/120000), AUC 0.9964866638183594
ep29_train_time 71.30027842521667
Test Epoch29 layer0 Acc 0.9125, AUC 0.9796836972236633, avg_entr 0.03784539923071861
ep29_l0_test_time 0.2172091007232666
Test Epoch29 layer1 Acc 0.9072368421052631, AUC 0.9707802534103394, avg_entr 0.014345739036798477
ep29_l1_test_time 0.4006469249725342
Test Epoch29 layer2 Acc 0.9046052631578947, AUC 0.9709910750389099, avg_entr 0.010564208962023258
ep29_l2_test_time 0.582526683807373
Test Epoch29 layer3 Acc 0.9047697368421053, AUC 0.9694884419441223, avg_entr 0.009072995744645596
ep29_l3_test_time 0.7609410285949707
Test Epoch29 layer4 Acc 0.9042763157894737, AUC 0.9677932262420654, avg_entr 0.008202108554542065
ep29_l4_test_time 0.9413506984710693
gc 0
Train Epoch30 Acc 0.97265 (116718/120000), AUC 0.9965019226074219
ep30_train_time 71.36095380783081
Test Epoch30 layer0 Acc 0.9125, AUC 0.9796923398971558, avg_entr 0.0377957783639431
ep30_l0_test_time 0.21660637855529785
Test Epoch30 layer1 Acc 0.9075657894736842, AUC 0.9704865217208862, avg_entr 0.014215751551091671
ep30_l1_test_time 0.4005122184753418
Test Epoch30 layer2 Acc 0.9050986842105263, AUC 0.9704095125198364, avg_entr 0.010246394202113152
ep30_l2_test_time 0.5825998783111572
Test Epoch30 layer3 Acc 0.9057565789473684, AUC 0.9686131477355957, avg_entr 0.008702611550688744
ep30_l3_test_time 0.7606775760650635
Test Epoch30 layer4 Acc 0.9054276315789473, AUC 0.966509222984314, avg_entr 0.007871358655393124
ep30_l4_test_time 0.9445598125457764
gc 0
Train Epoch31 Acc 0.9723333333333334 (116680/120000), AUC 0.9964770078659058
ep31_train_time 71.35337400436401
Test Epoch31 layer0 Acc 0.9126644736842106, AUC 0.9796876907348633, avg_entr 0.037820685654878616
ep31_l0_test_time 0.22042012214660645
Test Epoch31 layer1 Acc 0.9075657894736842, AUC 0.9705590605735779, avg_entr 0.014276238158345222
ep31_l1_test_time 0.4041328430175781
Test Epoch31 layer2 Acc 0.9046052631578947, AUC 0.9706034660339355, avg_entr 0.010491865687072277
ep31_l2_test_time 0.5863611698150635
Test Epoch31 layer3 Acc 0.9044407894736842, AUC 0.9689115881919861, avg_entr 0.008968564681708813
ep31_l3_test_time 0.7643702030181885
Test Epoch31 layer4 Acc 0.9037828947368421, AUC 0.9668540954589844, avg_entr 0.008114878088235855
ep31_l4_test_time 0.9451863765716553
gc 0
Train Epoch32 Acc 0.9726666666666667 (116720/120000), AUC 0.9963885545730591
ep32_train_time 71.33398032188416
Test Epoch32 layer0 Acc 0.9125, AUC 0.9796832203865051, avg_entr 0.03787074610590935
ep32_l0_test_time 0.21584272384643555
Test Epoch32 layer1 Acc 0.9078947368421053, AUC 0.9705984592437744, avg_entr 0.01422008965164423
ep32_l1_test_time 0.40018177032470703
Test Epoch32 layer2 Acc 0.9047697368421053, AUC 0.9706190228462219, avg_entr 0.010386472567915916
ep32_l2_test_time 0.5824582576751709
Test Epoch32 layer3 Acc 0.9046052631578947, AUC 0.9689846038818359, avg_entr 0.008859524503350258
ep32_l3_test_time 0.7609882354736328
Test Epoch32 layer4 Acc 0.9042763157894737, AUC 0.966846764087677, avg_entr 0.00805220939218998
ep32_l4_test_time 0.9418132305145264
gc 0
Train Epoch33 Acc 0.9729 (116748/120000), AUC 0.9964128732681274
ep33_train_time 71.29260873794556
Test Epoch33 layer0 Acc 0.9125, AUC 0.9796854257583618, avg_entr 0.03767318278551102
ep33_l0_test_time 0.21729826927185059
Test Epoch33 layer1 Acc 0.9075657894736842, AUC 0.9705474376678467, avg_entr 0.014193331822752953
ep33_l1_test_time 0.4006843566894531
Test Epoch33 layer2 Acc 0.9046052631578947, AUC 0.9705285429954529, avg_entr 0.01027088426053524
ep33_l2_test_time 0.5832185745239258
Test Epoch33 layer3 Acc 0.9047697368421053, AUC 0.968734622001648, avg_entr 0.008730598725378513
ep33_l3_test_time 0.7612361907958984
Test Epoch33 layer4 Acc 0.9037828947368421, AUC 0.9666324257850647, avg_entr 0.007840409874916077
ep33_l4_test_time 0.9417035579681396
gc 0
Train Epoch34 Acc 0.9725916666666666 (116711/120000), AUC 0.996500551700592
ep34_train_time 71.33443427085876
Test Epoch34 layer0 Acc 0.9125, AUC 0.9796810150146484, avg_entr 0.037557460367679596
ep34_l0_test_time 0.21807384490966797
Test Epoch34 layer1 Acc 0.9077302631578947, AUC 0.9705656170845032, avg_entr 0.014181067235767841
ep34_l1_test_time 0.40160274505615234
Test Epoch34 layer2 Acc 0.9049342105263158, AUC 0.9706141352653503, avg_entr 0.010235288180410862
ep34_l2_test_time 0.5842170715332031
Test Epoch34 layer3 Acc 0.9049342105263158, AUC 0.9689500331878662, avg_entr 0.008715253323316574
ep34_l3_test_time 0.7617850303649902
Test Epoch34 layer4 Acc 0.9042763157894737, AUC 0.9667454957962036, avg_entr 0.007835905067622662
ep34_l4_test_time 0.9424154758453369
gc 0
Train Epoch35 Acc 0.97245 (116694/120000), AUC 0.9964115619659424
ep35_train_time 71.36134123802185
Test Epoch35 layer0 Acc 0.912828947368421, AUC 0.9796768426895142, avg_entr 0.0375082828104496
ep35_l0_test_time 0.22020339965820312
Test Epoch35 layer1 Acc 0.9077302631578947, AUC 0.9705400466918945, avg_entr 0.014199577271938324
ep35_l1_test_time 0.40137314796447754
Test Epoch35 layer2 Acc 0.9046052631578947, AUC 0.9706531763076782, avg_entr 0.010320994071662426
ep35_l2_test_time 0.5838782787322998
Test Epoch35 layer3 Acc 0.9046052631578947, AUC 0.9689905047416687, avg_entr 0.008807646110653877
ep35_l3_test_time 0.7619738578796387
Test Epoch35 layer4 Acc 0.9039473684210526, AUC 0.9669743180274963, avg_entr 0.007965859025716782
ep35_l4_test_time 0.9424839019775391
gc 0
Train Epoch36 Acc 0.972825 (116739/120000), AUC 0.9963367581367493
ep36_train_time 71.3398208618164
Test Epoch36 layer0 Acc 0.9125, AUC 0.9796720743179321, avg_entr 0.03747912868857384
ep36_l0_test_time 0.21701383590698242
Test Epoch36 layer1 Acc 0.9075657894736842, AUC 0.9704843759536743, avg_entr 0.014158939942717552
ep36_l1_test_time 0.40070486068725586
Test Epoch36 layer2 Acc 0.9046052631578947, AUC 0.9705684185028076, avg_entr 0.010242264717817307
ep36_l2_test_time 0.5835962295532227
Test Epoch36 layer3 Acc 0.9044407894736842, AUC 0.9688868522644043, avg_entr 0.008734236471354961
ep36_l3_test_time 0.7611434459686279
Test Epoch36 layer4 Acc 0.9039473684210526, AUC 0.9667536616325378, avg_entr 0.00790424644947052
ep36_l4_test_time 0.9419877529144287
gc 0
Train Epoch37 Acc 0.9727083333333333 (116725/120000), AUC 0.9964668154716492
ep37_train_time 71.34239983558655
Test Epoch37 layer0 Acc 0.9123355263157895, AUC 0.9796833395957947, avg_entr 0.03748032823204994
ep37_l0_test_time 0.21658825874328613
Test Epoch37 layer1 Acc 0.9077302631578947, AUC 0.9705110788345337, avg_entr 0.014153577387332916
ep37_l1_test_time 0.40041232109069824
Test Epoch37 layer2 Acc 0.9047697368421053, AUC 0.9706903696060181, avg_entr 0.010235733352601528
ep37_l2_test_time 0.5836524963378906
Test Epoch37 layer3 Acc 0.9042763157894737, AUC 0.9690778851509094, avg_entr 0.008728613145649433
ep37_l3_test_time 0.7626676559448242
Test Epoch37 layer4 Acc 0.9039473684210526, AUC 0.9670222401618958, avg_entr 0.007902491837739944
ep37_l4_test_time 0.9432199001312256
gc 0
Train Epoch38 Acc 0.97305 (116766/120000), AUC 0.9965773820877075
ep38_train_time 71.3925142288208
Test Epoch38 layer0 Acc 0.9126644736842106, AUC 0.9796792268753052, avg_entr 0.037462763488292694
ep38_l0_test_time 0.21783185005187988
Test Epoch38 layer1 Acc 0.9078947368421053, AUC 0.9705317616462708, avg_entr 0.014173431321978569
ep38_l1_test_time 0.40180349349975586
Test Epoch38 layer2 Acc 0.9047697368421053, AUC 0.970676600933075, avg_entr 0.010336847975850105
ep38_l2_test_time 0.5842185020446777
Test Epoch38 layer3 Acc 0.9044407894736842, AUC 0.9690945744514465, avg_entr 0.00883955042809248
ep38_l3_test_time 0.7626044750213623
Test Epoch38 layer4 Acc 0.9041118421052632, AUC 0.9671109318733215, avg_entr 0.007998459041118622
ep38_l4_test_time 0.9428901672363281
gc 0
Train Epoch39 Acc 0.9727583333333333 (116731/120000), AUC 0.9965372681617737
ep39_train_time 71.34113693237305
Test Epoch39 layer0 Acc 0.9121710526315789, AUC 0.9796848297119141, avg_entr 0.03749281167984009
ep39_l0_test_time 0.21680712699890137
Test Epoch39 layer1 Acc 0.9077302631578947, AUC 0.9705083966255188, avg_entr 0.01416050922125578
ep39_l1_test_time 0.4002218246459961
Test Epoch39 layer2 Acc 0.9046052631578947, AUC 0.9706519246101379, avg_entr 0.01028925646096468
ep39_l2_test_time 0.58298659324646
Test Epoch39 layer3 Acc 0.9044407894736842, AUC 0.9689642786979675, avg_entr 0.008779414929449558
ep39_l3_test_time 0.7626137733459473
Test Epoch39 layer4 Acc 0.9039473684210526, AUC 0.9668269753456116, avg_entr 0.007927201688289642
ep39_l4_test_time 0.9417920112609863
gc 0
Train Epoch40 Acc 0.9725583333333333 (116707/120000), AUC 0.9964879751205444
ep40_train_time 71.36150741577148
Test Epoch40 layer0 Acc 0.9121710526315789, AUC 0.9796843528747559, avg_entr 0.03748657554388046
ep40_l0_test_time 0.2176053524017334
Test Epoch40 layer1 Acc 0.9077302631578947, AUC 0.9705162048339844, avg_entr 0.014141766354441643
ep40_l1_test_time 0.4004170894622803
Test Epoch40 layer2 Acc 0.9046052631578947, AUC 0.9705881476402283, avg_entr 0.010232886299490929
ep40_l2_test_time 0.5832548141479492
Test Epoch40 layer3 Acc 0.9042763157894737, AUC 0.9688589572906494, avg_entr 0.008716629818081856
ep40_l3_test_time 0.7606828212738037
Test Epoch40 layer4 Acc 0.9037828947368421, AUC 0.9665733575820923, avg_entr 0.007854001596570015
ep40_l4_test_time 0.9418766498565674
gc 0
Train Epoch41 Acc 0.9725333333333334 (116704/120000), AUC 0.9964751601219177
ep41_train_time 71.29914164543152
Test Epoch41 layer0 Acc 0.9123355263157895, AUC 0.97967129945755, avg_entr 0.037422485649585724
ep41_l0_test_time 0.21640968322753906
Test Epoch41 layer1 Acc 0.9077302631578947, AUC 0.9705169200897217, avg_entr 0.01413170900195837
ep41_l1_test_time 0.40010714530944824
Test Epoch41 layer2 Acc 0.9047697368421053, AUC 0.9705760478973389, avg_entr 0.010209492407739162
ep41_l2_test_time 0.5828695297241211
Test Epoch41 layer3 Acc 0.9042763157894737, AUC 0.9689025282859802, avg_entr 0.008701973594725132
ep41_l3_test_time 0.7618184089660645
Test Epoch41 layer4 Acc 0.9039473684210526, AUC 0.9667454957962036, avg_entr 0.007869578897953033
ep41_l4_test_time 0.9418418407440186
gc 0
Train Epoch42 Acc 0.972825 (116739/120000), AUC 0.9965195059776306
ep42_train_time 71.34115958213806
Test Epoch42 layer0 Acc 0.9126644736842106, AUC 0.9796679019927979, avg_entr 0.03743559867143631
ep42_l0_test_time 0.21722841262817383
Test Epoch42 layer1 Acc 0.9077302631578947, AUC 0.9705086350440979, avg_entr 0.014146482571959496
ep42_l1_test_time 0.40143537521362305
Test Epoch42 layer2 Acc 0.9047697368421053, AUC 0.9705830216407776, avg_entr 0.010262382216751575
ep42_l2_test_time 0.5829665660858154
Test Epoch42 layer3 Acc 0.9046052631578947, AUC 0.9688981175422668, avg_entr 0.008765905164182186
ep42_l3_test_time 0.7617418766021729
Test Epoch42 layer4 Acc 0.9039473684210526, AUC 0.9666944146156311, avg_entr 0.007930181920528412
ep42_l4_test_time 0.9425468444824219
gc 0
Train Epoch43 Acc 0.97295 (116754/120000), AUC 0.9965367913246155
ep43_train_time 71.35883712768555
Test Epoch43 layer0 Acc 0.9125, AUC 0.9796693325042725, avg_entr 0.037375807762145996
ep43_l0_test_time 0.21601223945617676
Test Epoch43 layer1 Acc 0.9077302631578947, AUC 0.9705148339271545, avg_entr 0.014153491705656052
ep43_l1_test_time 0.3998401165008545
Test Epoch43 layer2 Acc 0.9046052631578947, AUC 0.9706058502197266, avg_entr 0.010281204245984554
ep43_l2_test_time 0.5826263427734375
Test Epoch43 layer3 Acc 0.9046052631578947, AUC 0.9689128398895264, avg_entr 0.008785279467701912
ep43_l3_test_time 0.7602615356445312
Test Epoch43 layer4 Acc 0.9039473684210526, AUC 0.9667472839355469, avg_entr 0.007949410006403923
ep43_l4_test_time 0.9414272308349609
gc 0
Train Epoch44 Acc 0.9729583333333334 (116755/120000), AUC 0.9965106248855591
ep44_train_time 71.34736275672913
Test Epoch44 layer0 Acc 0.9123355263157895, AUC 0.9796805381774902, avg_entr 0.0374036580324173
ep44_l0_test_time 0.21674084663391113
Test Epoch44 layer1 Acc 0.9077302631578947, AUC 0.9704939126968384, avg_entr 0.014140566810965538
ep44_l1_test_time 0.4001190662384033
Test Epoch44 layer2 Acc 0.9046052631578947, AUC 0.9705910682678223, avg_entr 0.0102387685328722
ep44_l2_test_time 0.583380937576294
Test Epoch44 layer3 Acc 0.9042763157894737, AUC 0.9689029455184937, avg_entr 0.008731935173273087
ep44_l3_test_time 0.7613363265991211
Test Epoch44 layer4 Acc 0.9037828947368421, AUC 0.9667537212371826, avg_entr 0.007888225838541985
ep44_l4_test_time 0.9416208267211914
gc 0
Train Epoch45 Acc 0.9728416666666667 (116741/120000), AUC 0.9964359402656555
ep45_train_time 71.43174314498901
Test Epoch45 layer0 Acc 0.9126644736842106, AUC 0.9796690940856934, avg_entr 0.03740992024540901
ep45_l0_test_time 0.21721482276916504
Test Epoch45 layer1 Acc 0.9077302631578947, AUC 0.970492959022522, avg_entr 0.01415150798857212
ep45_l1_test_time 0.4015638828277588
Test Epoch45 layer2 Acc 0.9046052631578947, AUC 0.9706422686576843, avg_entr 0.010268927551805973
ep45_l2_test_time 0.5832431316375732
Test Epoch45 layer3 Acc 0.9044407894736842, AUC 0.9689494371414185, avg_entr 0.00876876711845398
ep45_l3_test_time 0.7613630294799805
Test Epoch45 layer4 Acc 0.9039473684210526, AUC 0.9668021202087402, avg_entr 0.007923471741378307
ep45_l4_test_time 0.9420690536499023
gc 0
Train Epoch46 Acc 0.9729333333333333 (116752/120000), AUC 0.9964205622673035
ep46_train_time 71.35430335998535
Test Epoch46 layer0 Acc 0.9125, AUC 0.9796661138534546, avg_entr 0.03740471228957176
ep46_l0_test_time 0.21764659881591797
Test Epoch46 layer1 Acc 0.9077302631578947, AUC 0.9705259203910828, avg_entr 0.014149838127195835
ep46_l1_test_time 0.4005711078643799
Test Epoch46 layer2 Acc 0.9046052631578947, AUC 0.9706461429595947, avg_entr 0.01027682051062584
ep46_l2_test_time 0.5826756954193115
Test Epoch46 layer3 Acc 0.9044407894736842, AUC 0.9689837694168091, avg_entr 0.008781921118497849
ep46_l3_test_time 0.7616417407989502
Test Epoch46 layer4 Acc 0.9039473684210526, AUC 0.966880202293396, avg_entr 0.007948079146444798
ep46_l4_test_time 0.9421594142913818
gc 0
Train Epoch47 Acc 0.9728083333333334 (116737/120000), AUC 0.996519148349762
ep47_train_time 71.39791512489319
Test Epoch47 layer0 Acc 0.9126644736842106, AUC 0.9796675443649292, avg_entr 0.0373925119638443
ep47_l0_test_time 0.21709251403808594
Test Epoch47 layer1 Acc 0.9077302631578947, AUC 0.9705260992050171, avg_entr 0.014150564558804035
ep47_l1_test_time 0.4011075496673584
Test Epoch47 layer2 Acc 0.9046052631578947, AUC 0.9706472158432007, avg_entr 0.010274282656610012
ep47_l2_test_time 0.583655595779419
Test Epoch47 layer3 Acc 0.9044407894736842, AUC 0.968986451625824, avg_entr 0.008777451701462269
ep47_l3_test_time 0.761415958404541
Test Epoch47 layer4 Acc 0.9039473684210526, AUC 0.9667911529541016, avg_entr 0.007934008724987507
ep47_l4_test_time 0.9422147274017334
gc 0
Train Epoch48 Acc 0.9730916666666667 (116771/120000), AUC 0.9965169429779053
ep48_train_time 71.34319376945496
Test Epoch48 layer0 Acc 0.9125, AUC 0.979665994644165, avg_entr 0.03740265220403671
ep48_l0_test_time 0.21700739860534668
Test Epoch48 layer1 Acc 0.9077302631578947, AUC 0.9705043435096741, avg_entr 0.014150289818644524
ep48_l1_test_time 0.4013550281524658
Test Epoch48 layer2 Acc 0.9046052631578947, AUC 0.9706422686576843, avg_entr 0.010273853316903114
ep48_l2_test_time 0.5835456848144531
Test Epoch48 layer3 Acc 0.9044407894736842, AUC 0.9689713716506958, avg_entr 0.00877627357840538
ep48_l3_test_time 0.7619516849517822
Test Epoch48 layer4 Acc 0.9039473684210526, AUC 0.9667736291885376, avg_entr 0.007933465763926506
ep48_l4_test_time 0.9425125122070312
gc 0
Train Epoch49 Acc 0.97275 (116730/120000), AUC 0.996539294719696
ep49_train_time 71.37439441680908
Test Epoch49 layer0 Acc 0.9126644736842106, AUC 0.9796673059463501, avg_entr 0.03738304227590561
ep49_l0_test_time 0.21757221221923828
Test Epoch49 layer1 Acc 0.9077302631578947, AUC 0.9704984426498413, avg_entr 0.014145947992801666
ep49_l1_test_time 0.4001047611236572
Test Epoch49 layer2 Acc 0.9046052631578947, AUC 0.970638632774353, avg_entr 0.0102663803845644
ep49_l2_test_time 0.5829086303710938
Test Epoch49 layer3 Acc 0.9044407894736842, AUC 0.9689479470252991, avg_entr 0.008766940794885159
ep49_l3_test_time 0.7613275051116943
Test Epoch49 layer4 Acc 0.9039473684210526, AUC 0.9667977094650269, avg_entr 0.007928173989057541
ep49_l4_test_time 0.9426610469818115
Best AUC 0.9824614524841309
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.925, AUC 0.986065685749054, avg_entr 0.11478157341480255
ep49_l0_test_time 0.05560016632080078
Test Epoch49 layer1 Acc 0.9302631578947368, AUC 0.9872429370880127, avg_entr 0.04748916998505592
ep49_l1_test_time 0.10072994232177734
Test Epoch49 layer2 Acc 0.9276315789473685, AUC 0.9859108328819275, avg_entr 0.040323060005903244
ep49_l2_test_time 0.14649105072021484
Test Epoch49 layer3 Acc 0.9282894736842106, AUC 0.9860600829124451, avg_entr 0.037987880408763885
ep49_l3_test_time 0.19164586067199707
Test Epoch49 layer4 Acc 0.9269736842105263, AUC 0.9857703447341919, avg_entr 0.03634294494986534
ep49_l4_test_time 0.23583745956420898
