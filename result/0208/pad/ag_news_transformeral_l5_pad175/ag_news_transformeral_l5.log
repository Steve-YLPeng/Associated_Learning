total count words 102019
vocab size 30000
found 26754 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13672292
Start Training
gc 0
Train Epoch0 Acc 0.6426083333333333 (77113/120000), AUC 0.865339457988739
ep0_train_time 80.37724423408508
Test Epoch0 layer0 Acc 0.9001644736842105, AUC 0.9743568897247314, avg_entr 0.24785180389881134
ep0_l0_test_time 0.2497243881225586
Save ckpt to ckpt/ag_news_transformeral_l5_pad175//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9050986842105263, AUC 0.9774759411811829, avg_entr 0.16576898097991943
ep0_l1_test_time 0.45679187774658203
Save ckpt to ckpt/ag_news_transformeral_l5_pad175//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.9044407894736842, AUC 0.9777013659477234, avg_entr 0.15703372657299042
ep0_l2_test_time 0.6663212776184082
Save ckpt to ckpt/ag_news_transformeral_l5_pad175//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer3 Acc 0.9036184210526316, AUC 0.9776777029037476, avg_entr 0.1566130518913269
ep0_l3_test_time 0.8675007820129395
Test Epoch0 layer4 Acc 0.9011513157894737, AUC 0.9780255556106567, avg_entr 0.15684722363948822
ep0_l4_test_time 1.0583548545837402
Save ckpt to ckpt/ag_news_transformeral_l5_pad175//ag_news_transformeral_l5.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.9201333333333334 (110416/120000), AUC 0.9817097187042236
ep1_train_time 80.0198814868927
Test Epoch1 layer0 Acc 0.9129934210526316, AUC 0.9780077934265137, avg_entr 0.14318007230758667
ep1_l0_test_time 0.24671673774719238
Test Epoch1 layer1 Acc 0.915296052631579, AUC 0.9810754060745239, avg_entr 0.0768081545829773
ep1_l1_test_time 0.45557260513305664
Save ckpt to ckpt/ag_news_transformeral_l5_pad175//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.9148026315789474, AUC 0.9806907176971436, avg_entr 0.06818286329507828
ep1_l2_test_time 0.6690142154693604
Test Epoch1 layer3 Acc 0.9136513157894737, AUC 0.9804290533065796, avg_entr 0.06035664305090904
ep1_l3_test_time 0.8662889003753662
Test Epoch1 layer4 Acc 0.9139802631578947, AUC 0.980444073677063, avg_entr 0.05942844599485397
ep1_l4_test_time 1.0597798824310303
gc 0
Train Epoch2 Acc 0.9354083333333333 (112249/120000), AUC 0.9869980812072754
ep2_train_time 80.00392198562622
Test Epoch2 layer0 Acc 0.9149671052631579, AUC 0.9795372486114502, avg_entr 0.10958224534988403
ep2_l0_test_time 0.2515993118286133
Test Epoch2 layer1 Acc 0.9182565789473685, AUC 0.9825029373168945, avg_entr 0.043083421885967255
ep2_l1_test_time 0.4570002555847168
Save ckpt to ckpt/ag_news_transformeral_l5_pad175//ag_news_transformeral_l5.pt  ,ep 2
Test Epoch2 layer2 Acc 0.9177631578947368, AUC 0.9819352626800537, avg_entr 0.037641704082489014
ep2_l2_test_time 0.6657297611236572
Test Epoch2 layer3 Acc 0.9171052631578948, AUC 0.9818129539489746, avg_entr 0.03393951803445816
ep2_l3_test_time 0.8659794330596924
Test Epoch2 layer4 Acc 0.9172697368421052, AUC 0.9820030331611633, avg_entr 0.03277822956442833
ep2_l4_test_time 1.0581779479980469
gc 0
Train Epoch3 Acc 0.942375 (113085/120000), AUC 0.9889456629753113
ep3_train_time 80.22039556503296
Test Epoch3 layer0 Acc 0.9174342105263158, AUC 0.9804520010948181, avg_entr 0.09439340978860855
ep3_l0_test_time 0.2470386028289795
Test Epoch3 layer1 Acc 0.9167763157894737, AUC 0.9798786044120789, avg_entr 0.03432704135775566
ep3_l1_test_time 0.4556574821472168
Test Epoch3 layer2 Acc 0.9162828947368421, AUC 0.9794374108314514, avg_entr 0.028875242918729782
ep3_l2_test_time 0.6626553535461426
Test Epoch3 layer3 Acc 0.9162828947368421, AUC 0.9812808632850647, avg_entr 0.025975875556468964
ep3_l3_test_time 0.8654088973999023
Test Epoch3 layer4 Acc 0.9157894736842105, AUC 0.9807642102241516, avg_entr 0.024982500821352005
ep3_l4_test_time 1.0594151020050049
gc 0
Train Epoch4 Acc 0.9483916666666666 (113807/120000), AUC 0.9901324510574341
ep4_train_time 80.02472257614136
Test Epoch4 layer0 Acc 0.9177631578947368, AUC 0.9806617498397827, avg_entr 0.08072078973054886
ep4_l0_test_time 0.2469158172607422
Test Epoch4 layer1 Acc 0.915296052631579, AUC 0.9772500991821289, avg_entr 0.028549056500196457
ep4_l1_test_time 0.4559767246246338
Test Epoch4 layer2 Acc 0.9151315789473684, AUC 0.9774556756019592, avg_entr 0.023395372554659843
ep4_l2_test_time 0.6622321605682373
Test Epoch4 layer3 Acc 0.9151315789473684, AUC 0.9781904816627502, avg_entr 0.021208221092820168
ep4_l3_test_time 0.8643596172332764
Test Epoch4 layer4 Acc 0.915296052631579, AUC 0.978184163570404, avg_entr 0.019772036001086235
ep4_l4_test_time 1.059384822845459
gc 0
Train Epoch5 Acc 0.9527 (114324/120000), AUC 0.9912464618682861
ep5_train_time 79.99700236320496
Test Epoch5 layer0 Acc 0.9144736842105263, AUC 0.9808058738708496, avg_entr 0.07396511733531952
ep5_l0_test_time 0.2476944923400879
Test Epoch5 layer1 Acc 0.9146381578947368, AUC 0.9787403345108032, avg_entr 0.02625662088394165
ep5_l1_test_time 0.4546842575073242
Test Epoch5 layer2 Acc 0.9134868421052632, AUC 0.9790854454040527, avg_entr 0.021377352997660637
ep5_l2_test_time 0.6622493267059326
Test Epoch5 layer3 Acc 0.9136513157894737, AUC 0.9804741144180298, avg_entr 0.019160015508532524
ep5_l3_test_time 0.8646013736724854
Test Epoch5 layer4 Acc 0.9129934210526316, AUC 0.9799864888191223, avg_entr 0.017964811995625496
ep5_l4_test_time 1.0582330226898193
gc 0
Train Epoch6 Acc 0.9557583333333334 (114691/120000), AUC 0.9921635389328003
ep6_train_time 79.99873065948486
Test Epoch6 layer0 Acc 0.9154605263157894, AUC 0.9808709621429443, avg_entr 0.0684899166226387
ep6_l0_test_time 0.24724745750427246
Test Epoch6 layer1 Acc 0.9133223684210526, AUC 0.9772661924362183, avg_entr 0.02361884154379368
ep6_l1_test_time 0.45568013191223145
Test Epoch6 layer2 Acc 0.9143092105263158, AUC 0.9782671928405762, avg_entr 0.018184227868914604
ep6_l2_test_time 0.6621565818786621
Test Epoch6 layer3 Acc 0.9141447368421053, AUC 0.9791209101676941, avg_entr 0.01605170965194702
ep6_l3_test_time 0.8646073341369629
Test Epoch6 layer4 Acc 0.9146381578947368, AUC 0.9787807464599609, avg_entr 0.014842232689261436
ep6_l4_test_time 1.0582973957061768
gc 0
Train Epoch7 Acc 0.95865 (115038/120000), AUC 0.9932769536972046
ep7_train_time 80.03564524650574
Test Epoch7 layer0 Acc 0.9154605263157894, AUC 0.980760931968689, avg_entr 0.06316296756267548
ep7_l0_test_time 0.24593234062194824
Test Epoch7 layer1 Acc 0.9126644736842106, AUC 0.9744356870651245, avg_entr 0.020722821354866028
ep7_l1_test_time 0.4544222354888916
Test Epoch7 layer2 Acc 0.9120065789473685, AUC 0.976608157157898, avg_entr 0.015133656561374664
ep7_l2_test_time 0.6611998081207275
Test Epoch7 layer3 Acc 0.9126644736842106, AUC 0.9773769974708557, avg_entr 0.01328417006880045
ep7_l3_test_time 0.8643691539764404
Test Epoch7 layer4 Acc 0.9133223684210526, AUC 0.978836715221405, avg_entr 0.012191764079034328
ep7_l4_test_time 1.0571260452270508
gc 0
Train Epoch8 Acc 0.9602916666666667 (115235/120000), AUC 0.9935809969902039
ep8_train_time 79.97093486785889
Test Epoch8 layer0 Acc 0.9118421052631579, AUC 0.9806976914405823, avg_entr 0.061615679413080215
ep8_l0_test_time 0.2473604679107666
Test Epoch8 layer1 Acc 0.9120065789473685, AUC 0.9747028350830078, avg_entr 0.02035912126302719
ep8_l1_test_time 0.45522189140319824
Test Epoch8 layer2 Acc 0.9125, AUC 0.9764673709869385, avg_entr 0.01499494630843401
ep8_l2_test_time 0.6626632213592529
Test Epoch8 layer3 Acc 0.9116776315789473, AUC 0.97699373960495, avg_entr 0.013201766647398472
ep8_l3_test_time 0.864283561706543
Test Epoch8 layer4 Acc 0.9120065789473685, AUC 0.976051926612854, avg_entr 0.012068724259734154
ep8_l4_test_time 1.058532476425171
gc 0
Train Epoch9 Acc 0.9623333333333334 (115480/120000), AUC 0.9940938949584961
ep9_train_time 80.03579878807068
Test Epoch9 layer0 Acc 0.9148026315789474, AUC 0.9805125594139099, avg_entr 0.05541396513581276
ep9_l0_test_time 0.24608707427978516
Test Epoch9 layer1 Acc 0.9129934210526316, AUC 0.9749323129653931, avg_entr 0.018590014427900314
ep9_l1_test_time 0.4545457363128662
Test Epoch9 layer2 Acc 0.9133223684210526, AUC 0.9768842458724976, avg_entr 0.014037366025149822
ep9_l2_test_time 0.6626105308532715
Test Epoch9 layer3 Acc 0.9136513157894737, AUC 0.9775192141532898, avg_entr 0.012631773017346859
ep9_l3_test_time 0.8662619590759277
Test Epoch9 layer4 Acc 0.9131578947368421, AUC 0.9770227074623108, avg_entr 0.011580871418118477
ep9_l4_test_time 1.0581519603729248
gc 0
Train Epoch10 Acc 0.9649666666666666 (115796/120000), AUC 0.9948592185974121
ep10_train_time 80.07677793502808
Test Epoch10 layer0 Acc 0.9139802631578947, AUC 0.9805022478103638, avg_entr 0.054187171161174774
ep10_l0_test_time 0.24664688110351562
Test Epoch10 layer1 Acc 0.9106907894736842, AUC 0.9737496972084045, avg_entr 0.017771892249584198
ep10_l1_test_time 0.45542216300964355
Test Epoch10 layer2 Acc 0.9100328947368421, AUC 0.9760125875473022, avg_entr 0.01332713384181261
ep10_l2_test_time 0.6621825695037842
Test Epoch10 layer3 Acc 0.9105263157894737, AUC 0.9767284393310547, avg_entr 0.011754913255572319
ep10_l3_test_time 0.8641138076782227
Test Epoch10 layer4 Acc 0.9101973684210526, AUC 0.9765299558639526, avg_entr 0.010885875672101974
ep10_l4_test_time 1.0579586029052734
gc 0
Train Epoch11 Acc 0.9658833333333333 (115906/120000), AUC 0.995413064956665
ep11_train_time 80.08202314376831
Test Epoch11 layer0 Acc 0.9149671052631579, AUC 0.9803471565246582, avg_entr 0.05282740667462349
ep11_l0_test_time 0.2468554973602295
Test Epoch11 layer1 Acc 0.9118421052631579, AUC 0.9718486070632935, avg_entr 0.01728913001716137
ep11_l1_test_time 0.45475196838378906
Test Epoch11 layer2 Acc 0.9115131578947369, AUC 0.9733157753944397, avg_entr 0.01230548694729805
ep11_l2_test_time 0.6618852615356445
Test Epoch11 layer3 Acc 0.9113486842105263, AUC 0.9739190340042114, avg_entr 0.01081599947065115
ep11_l3_test_time 0.8651721477508545
Test Epoch11 layer4 Acc 0.9113486842105263, AUC 0.9746479392051697, avg_entr 0.00981807243078947
ep11_l4_test_time 1.0576567649841309
gc 0
Train Epoch12 Acc 0.9668333333333333 (116020/120000), AUC 0.9954870343208313
ep12_train_time 80.0833694934845
Test Epoch12 layer0 Acc 0.9151315789473684, AUC 0.9803151488304138, avg_entr 0.05045421048998833
ep12_l0_test_time 0.24732065200805664
Test Epoch12 layer1 Acc 0.9105263157894737, AUC 0.972391664981842, avg_entr 0.016750438138842583
ep12_l1_test_time 0.4562537670135498
Test Epoch12 layer2 Acc 0.9098684210526315, AUC 0.9739078283309937, avg_entr 0.01220810879021883
ep12_l2_test_time 0.663524866104126
Test Epoch12 layer3 Acc 0.9097039473684211, AUC 0.9742270112037659, avg_entr 0.010564003139734268
ep12_l3_test_time 0.865182638168335
Test Epoch12 layer4 Acc 0.9097039473684211, AUC 0.975074291229248, avg_entr 0.009500699117779732
ep12_l4_test_time 1.0590283870697021
gc 0
Train Epoch13 Acc 0.9675416666666666 (116105/120000), AUC 0.9955785274505615
ep13_train_time 80.0514235496521
Test Epoch13 layer0 Acc 0.9146381578947368, AUC 0.9801544547080994, avg_entr 0.04815513268113136
ep13_l0_test_time 0.24747371673583984
Test Epoch13 layer1 Acc 0.9116776315789473, AUC 0.9725759625434875, avg_entr 0.016843868419528008
ep13_l1_test_time 0.45525527000427246
Test Epoch13 layer2 Acc 0.9110197368421052, AUC 0.97429358959198, avg_entr 0.012115340679883957
ep13_l2_test_time 0.6628482341766357
Test Epoch13 layer3 Acc 0.9110197368421052, AUC 0.9746038317680359, avg_entr 0.010779966600239277
ep13_l3_test_time 0.8648607730865479
Test Epoch13 layer4 Acc 0.9108552631578948, AUC 0.9755231142044067, avg_entr 0.009816331788897514
ep13_l4_test_time 1.0577855110168457
gc 0
Train Epoch14 Acc 0.9689333333333333 (116272/120000), AUC 0.9958919286727905
ep14_train_time 80.01395440101624
Test Epoch14 layer0 Acc 0.9151315789473684, AUC 0.9801382422447205, avg_entr 0.04680429771542549
ep14_l0_test_time 0.2474043369293213
Test Epoch14 layer1 Acc 0.9106907894736842, AUC 0.9712202548980713, avg_entr 0.0158405601978302
ep14_l1_test_time 0.45580029487609863
Test Epoch14 layer2 Acc 0.9100328947368421, AUC 0.9731279015541077, avg_entr 0.011404621414840221
ep14_l2_test_time 0.6626198291778564
Test Epoch14 layer3 Acc 0.9100328947368421, AUC 0.9730053544044495, avg_entr 0.009912624023854733
ep14_l3_test_time 0.86501145362854
Test Epoch14 layer4 Acc 0.9100328947368421, AUC 0.9738094210624695, avg_entr 0.0088987210765481
ep14_l4_test_time 1.0604000091552734
gc 0
Train Epoch15 Acc 0.9696416666666666 (116357/120000), AUC 0.996107280254364
ep15_train_time 80.02666473388672
Test Epoch15 layer0 Acc 0.9144736842105263, AUC 0.9800492525100708, avg_entr 0.0458558164536953
ep15_l0_test_time 0.24824261665344238
Test Epoch15 layer1 Acc 0.9100328947368421, AUC 0.9716649651527405, avg_entr 0.015835830941796303
ep15_l1_test_time 0.4553689956665039
Test Epoch15 layer2 Acc 0.9092105263157895, AUC 0.9735252857208252, avg_entr 0.01135993655771017
ep15_l2_test_time 0.6623067855834961
Test Epoch15 layer3 Acc 0.9092105263157895, AUC 0.9729945659637451, avg_entr 0.009618346579372883
ep15_l3_test_time 0.8659229278564453
Test Epoch15 layer4 Acc 0.9095394736842105, AUC 0.9724061489105225, avg_entr 0.008577132597565651
ep15_l4_test_time 1.0595815181732178
gc 0
Train Epoch16 Acc 0.9700833333333333 (116410/120000), AUC 0.9961425065994263
ep16_train_time 80.0688009262085
Test Epoch16 layer0 Acc 0.9138157894736842, AUC 0.9800412058830261, avg_entr 0.0451907217502594
ep16_l0_test_time 0.24734711647033691
Test Epoch16 layer1 Acc 0.9108552631578948, AUC 0.9711887240409851, avg_entr 0.01533404178917408
ep16_l1_test_time 0.4550490379333496
Test Epoch16 layer2 Acc 0.9113486842105263, AUC 0.972694993019104, avg_entr 0.01109202392399311
ep16_l2_test_time 0.6639435291290283
Test Epoch16 layer3 Acc 0.9116776315789473, AUC 0.9718536138534546, avg_entr 0.009397764690220356
ep16_l3_test_time 0.8690998554229736
Test Epoch16 layer4 Acc 0.9105263157894737, AUC 0.9727993011474609, avg_entr 0.008429656736552715
ep16_l4_test_time 1.062053918838501
gc 0
Train Epoch17 Acc 0.9704 (116448/120000), AUC 0.9962020516395569
ep17_train_time 80.0957715511322
Test Epoch17 layer0 Acc 0.9143092105263158, AUC 0.9800246953964233, avg_entr 0.043162260204553604
ep17_l0_test_time 0.2473008632659912
Test Epoch17 layer1 Acc 0.9095394736842105, AUC 0.9709880352020264, avg_entr 0.015156676061451435
ep17_l1_test_time 0.45519042015075684
Test Epoch17 layer2 Acc 0.9100328947368421, AUC 0.9725146889686584, avg_entr 0.01113742496818304
ep17_l2_test_time 0.6618063449859619
Test Epoch17 layer3 Acc 0.9098684210526315, AUC 0.9721265435218811, avg_entr 0.009491357952356339
ep17_l3_test_time 0.8651037216186523
Test Epoch17 layer4 Acc 0.9101973684210526, AUC 0.9718999862670898, avg_entr 0.008391182869672775
ep17_l4_test_time 1.0575671195983887
gc 0
Train Epoch18 Acc 0.9709166666666667 (116510/120000), AUC 0.9963948130607605
ep18_train_time 80.03306269645691
Test Epoch18 layer0 Acc 0.9149671052631579, AUC 0.9799966812133789, avg_entr 0.042277511209249496
ep18_l0_test_time 0.24727892875671387
Test Epoch18 layer1 Acc 0.9100328947368421, AUC 0.9708783626556396, avg_entr 0.014894395135343075
ep18_l1_test_time 0.45479488372802734
Test Epoch18 layer2 Acc 0.9082236842105263, AUC 0.9720776677131653, avg_entr 0.010806821286678314
ep18_l2_test_time 0.6621859073638916
Test Epoch18 layer3 Acc 0.9087171052631579, AUC 0.9712558388710022, avg_entr 0.00919135008007288
ep18_l3_test_time 0.8636064529418945
Test Epoch18 layer4 Acc 0.9087171052631579, AUC 0.9701838493347168, avg_entr 0.008136446587741375
ep18_l4_test_time 1.0589094161987305
gc 0
Train Epoch19 Acc 0.97155 (116586/120000), AUC 0.996446967124939
ep19_train_time 80.0251944065094
Test Epoch19 layer0 Acc 0.9139802631578947, AUC 0.9800117611885071, avg_entr 0.04153549298644066
ep19_l0_test_time 0.24820876121520996
Test Epoch19 layer1 Acc 0.9103618421052632, AUC 0.971323549747467, avg_entr 0.014667966403067112
ep19_l1_test_time 0.4560418128967285
Test Epoch19 layer2 Acc 0.9100328947368421, AUC 0.9722057580947876, avg_entr 0.01004316471517086
ep19_l2_test_time 0.6623220443725586
Test Epoch19 layer3 Acc 0.9095394736842105, AUC 0.9712299704551697, avg_entr 0.008308349177241325
ep19_l3_test_time 0.866424560546875
Test Epoch19 layer4 Acc 0.9092105263157895, AUC 0.970707893371582, avg_entr 0.007495892699807882
ep19_l4_test_time 1.059293270111084
gc 0
Train Epoch20 Acc 0.9715416666666666 (116585/120000), AUC 0.9964917898178101
ep20_train_time 80.19750022888184
Test Epoch20 layer0 Acc 0.9139802631578947, AUC 0.9799718856811523, avg_entr 0.040365900844335556
ep20_l0_test_time 0.24880385398864746
Test Epoch20 layer1 Acc 0.9097039473684211, AUC 0.9707251191139221, avg_entr 0.014310562051832676
ep20_l1_test_time 0.4550199508666992
Test Epoch20 layer2 Acc 0.909375, AUC 0.9713713526725769, avg_entr 0.010163686238229275
ep20_l2_test_time 0.6620159149169922
Test Epoch20 layer3 Acc 0.9092105263157895, AUC 0.9693936109542847, avg_entr 0.008620841428637505
ep20_l3_test_time 0.8637897968292236
Test Epoch20 layer4 Acc 0.9092105263157895, AUC 0.9684637784957886, avg_entr 0.007621414493769407
ep20_l4_test_time 1.0577616691589355
gc 0
Train Epoch21 Acc 0.971725 (116607/120000), AUC 0.9965333342552185
ep21_train_time 80.10809445381165
Test Epoch21 layer0 Acc 0.9133223684210526, AUC 0.9799582362174988, avg_entr 0.03995569050312042
ep21_l0_test_time 0.24661970138549805
Test Epoch21 layer1 Acc 0.9100328947368421, AUC 0.9712615609169006, avg_entr 0.013815086334943771
ep21_l1_test_time 0.45566511154174805
Test Epoch21 layer2 Acc 0.9106907894736842, AUC 0.9730966091156006, avg_entr 0.009652762673795223
ep21_l2_test_time 0.6624424457550049
Test Epoch21 layer3 Acc 0.9101973684210526, AUC 0.9715611934661865, avg_entr 0.007835173979401588
ep21_l3_test_time 0.8644380569458008
Test Epoch21 layer4 Acc 0.9103618421052632, AUC 0.9717262983322144, avg_entr 0.006942710839211941
ep21_l4_test_time 1.058279275894165
gc 0
Train Epoch22 Acc 0.9720583333333334 (116647/120000), AUC 0.9965240359306335
ep22_train_time 80.09703516960144
Test Epoch22 layer0 Acc 0.9138157894736842, AUC 0.9799736142158508, avg_entr 0.03937189280986786
ep22_l0_test_time 0.25083374977111816
Test Epoch22 layer1 Acc 0.9098684210526315, AUC 0.9710138440132141, avg_entr 0.013814453035593033
ep22_l1_test_time 0.4568765163421631
Test Epoch22 layer2 Acc 0.9105263157894737, AUC 0.9728776812553406, avg_entr 0.009722094051539898
ep22_l2_test_time 0.6629102230072021
Test Epoch22 layer3 Acc 0.9098684210526315, AUC 0.9710829257965088, avg_entr 0.007956813089549541
ep22_l3_test_time 0.8648483753204346
Test Epoch22 layer4 Acc 0.9100328947368421, AUC 0.9707094430923462, avg_entr 0.0070698680356144905
ep22_l4_test_time 1.0586068630218506
gc 0
Train Epoch23 Acc 0.9721833333333333 (116662/120000), AUC 0.9965471625328064
ep23_train_time 80.03593802452087
Test Epoch23 layer0 Acc 0.9136513157894737, AUC 0.979938268661499, avg_entr 0.03937261179089546
ep23_l0_test_time 0.24685883522033691
Test Epoch23 layer1 Acc 0.9097039473684211, AUC 0.9707506895065308, avg_entr 0.013552103191614151
ep23_l1_test_time 0.4535672664642334
Test Epoch23 layer2 Acc 0.9100328947368421, AUC 0.972184956073761, avg_entr 0.00946530606597662
ep23_l2_test_time 0.6625316143035889
Test Epoch23 layer3 Acc 0.9097039473684211, AUC 0.9700971841812134, avg_entr 0.007676574867218733
ep23_l3_test_time 0.8635449409484863
Test Epoch23 layer4 Acc 0.9097039473684211, AUC 0.9692003726959229, avg_entr 0.006762096658349037
ep23_l4_test_time 1.058621883392334
gc 0
Train Epoch24 Acc 0.9724666666666667 (116696/120000), AUC 0.9966129064559937
ep24_train_time 80.14928793907166
Test Epoch24 layer0 Acc 0.9138157894736842, AUC 0.9799357652664185, avg_entr 0.03889638930559158
ep24_l0_test_time 0.24667739868164062
Test Epoch24 layer1 Acc 0.9098684210526315, AUC 0.9706389904022217, avg_entr 0.01376293320208788
ep24_l1_test_time 0.45510149002075195
Test Epoch24 layer2 Acc 0.9097039473684211, AUC 0.9724146127700806, avg_entr 0.009793927893042564
ep24_l2_test_time 0.6624548435211182
Test Epoch24 layer3 Acc 0.9097039473684211, AUC 0.9709392189979553, avg_entr 0.00826400425285101
ep24_l3_test_time 0.864253044128418
Test Epoch24 layer4 Acc 0.9090460526315789, AUC 0.9702436923980713, avg_entr 0.0074626365676522255
ep24_l4_test_time 1.0589706897735596
gc 0
Train Epoch25 Acc 0.9722666666666666 (116672/120000), AUC 0.9966539144515991
ep25_train_time 80.22942614555359
Test Epoch25 layer0 Acc 0.9139802631578947, AUC 0.9799227714538574, avg_entr 0.03822542354464531
ep25_l0_test_time 0.24683570861816406
Test Epoch25 layer1 Acc 0.909375, AUC 0.9708248376846313, avg_entr 0.013439217582345009
ep25_l1_test_time 0.4563472270965576
Test Epoch25 layer2 Acc 0.9100328947368421, AUC 0.972615122795105, avg_entr 0.009211720898747444
ep25_l2_test_time 0.6620030403137207
Test Epoch25 layer3 Acc 0.909375, AUC 0.9706063270568848, avg_entr 0.007605765480548143
ep25_l3_test_time 0.8637762069702148
Test Epoch25 layer4 Acc 0.9098684210526315, AUC 0.9700033664703369, avg_entr 0.006757806520909071
ep25_l4_test_time 1.0580241680145264
gc 0
Train Epoch26 Acc 0.9725583333333333 (116707/120000), AUC 0.9966738224029541
ep26_train_time 80.19781851768494
Test Epoch26 layer0 Acc 0.9134868421052632, AUC 0.979909360408783, avg_entr 0.03826777637004852
ep26_l0_test_time 0.2461986541748047
Test Epoch26 layer1 Acc 0.9095394736842105, AUC 0.9705708622932434, avg_entr 0.013390823267400265
ep26_l1_test_time 0.4550647735595703
Test Epoch26 layer2 Acc 0.9103618421052632, AUC 0.9723842144012451, avg_entr 0.009282107464969158
ep26_l2_test_time 0.66170334815979
Test Epoch26 layer3 Acc 0.9097039473684211, AUC 0.9705530405044556, avg_entr 0.007725169882178307
ep26_l3_test_time 0.8636586666107178
Test Epoch26 layer4 Acc 0.9098684210526315, AUC 0.9699320793151855, avg_entr 0.006864068564027548
ep26_l4_test_time 1.0575981140136719
gc 0
Train Epoch27 Acc 0.9726916666666666 (116723/120000), AUC 0.9966115951538086
ep27_train_time 80.1736216545105
Test Epoch27 layer0 Acc 0.9138157894736842, AUC 0.9799051880836487, avg_entr 0.03834696114063263
ep27_l0_test_time 0.24842381477355957
Test Epoch27 layer1 Acc 0.9097039473684211, AUC 0.9705852270126343, avg_entr 0.013312846422195435
ep27_l1_test_time 0.45541977882385254
Test Epoch27 layer2 Acc 0.9095394736842105, AUC 0.9723469614982605, avg_entr 0.009203217923641205
ep27_l2_test_time 0.6631639003753662
Test Epoch27 layer3 Acc 0.9095394736842105, AUC 0.9703453183174133, avg_entr 0.007633760571479797
ep27_l3_test_time 0.8637824058532715
Test Epoch27 layer4 Acc 0.909375, AUC 0.9693166613578796, avg_entr 0.006712743081152439
ep27_l4_test_time 1.0589332580566406
gc 0
Train Epoch28 Acc 0.9731 (116772/120000), AUC 0.9967685341835022
ep28_train_time 80.15278434753418
Test Epoch28 layer0 Acc 0.9129934210526316, AUC 0.979904294013977, avg_entr 0.0382721833884716
ep28_l0_test_time 0.25151991844177246
Test Epoch28 layer1 Acc 0.909375, AUC 0.9706720113754272, avg_entr 0.013248778879642487
ep28_l1_test_time 0.4551718235015869
Test Epoch28 layer2 Acc 0.9101973684210526, AUC 0.9722772836685181, avg_entr 0.00900338776409626
ep28_l2_test_time 0.6623311042785645
Test Epoch28 layer3 Acc 0.909375, AUC 0.9706071615219116, avg_entr 0.007432800717651844
ep28_l3_test_time 0.8645429611206055
Test Epoch28 layer4 Acc 0.9097039473684211, AUC 0.9697113037109375, avg_entr 0.006611079443246126
ep28_l4_test_time 1.0580534934997559
gc 0
Train Epoch29 Acc 0.9728166666666667 (116738/120000), AUC 0.9967564344406128
ep29_train_time 80.19416689872742
Test Epoch29 layer0 Acc 0.9139802631578947, AUC 0.979895830154419, avg_entr 0.037924185395240784
ep29_l0_test_time 0.24712681770324707
Test Epoch29 layer1 Acc 0.9097039473684211, AUC 0.970591127872467, avg_entr 0.013313638977706432
ep29_l1_test_time 0.45501279830932617
Test Epoch29 layer2 Acc 0.9088815789473684, AUC 0.9721074104309082, avg_entr 0.009224992245435715
ep29_l2_test_time 0.6620175838470459
Test Epoch29 layer3 Acc 0.909375, AUC 0.970565915107727, avg_entr 0.007680975832045078
ep29_l3_test_time 0.8641152381896973
Test Epoch29 layer4 Acc 0.9088815789473684, AUC 0.9697931408882141, avg_entr 0.006934643257409334
ep29_l4_test_time 1.0592107772827148
gc 0
Train Epoch30 Acc 0.9727833333333333 (116734/120000), AUC 0.9966898560523987
ep30_train_time 80.08859539031982
Test Epoch30 layer0 Acc 0.9141447368421053, AUC 0.9798794984817505, avg_entr 0.037812553346157074
ep30_l0_test_time 0.24716734886169434
Test Epoch30 layer1 Acc 0.9100328947368421, AUC 0.9707101583480835, avg_entr 0.013123407028615475
ep30_l1_test_time 0.4554262161254883
Test Epoch30 layer2 Acc 0.9095394736842105, AUC 0.9724708199501038, avg_entr 0.008835062384605408
ep30_l2_test_time 0.6619715690612793
Test Epoch30 layer3 Acc 0.909375, AUC 0.9706670045852661, avg_entr 0.007175244856625795
ep30_l3_test_time 0.8644742965698242
Test Epoch30 layer4 Acc 0.9097039473684211, AUC 0.9698836803436279, avg_entr 0.00639022421091795
ep30_l4_test_time 1.057849407196045
gc 0
Train Epoch31 Acc 0.9729666666666666 (116756/120000), AUC 0.9967124462127686
ep31_train_time 80.07570576667786
Test Epoch31 layer0 Acc 0.9143092105263158, AUC 0.979888379573822, avg_entr 0.03781585022807121
ep31_l0_test_time 0.24578022956848145
Test Epoch31 layer1 Acc 0.9095394736842105, AUC 0.9704777598381042, avg_entr 0.013132857158780098
ep31_l1_test_time 0.454967737197876
Test Epoch31 layer2 Acc 0.909375, AUC 0.9720730781555176, avg_entr 0.008884323760867119
ep31_l2_test_time 0.661290168762207
Test Epoch31 layer3 Acc 0.9095394736842105, AUC 0.9701255559921265, avg_entr 0.00731096463277936
ep31_l3_test_time 0.8647935390472412
Test Epoch31 layer4 Acc 0.9092105263157895, AUC 0.9694586992263794, avg_entr 0.006466986611485481
ep31_l4_test_time 1.0574586391448975
gc 0
Train Epoch32 Acc 0.9732083333333333 (116785/120000), AUC 0.9967446327209473
ep32_train_time 80.10575652122498
Test Epoch32 layer0 Acc 0.9141447368421053, AUC 0.9798855781555176, avg_entr 0.03783303126692772
ep32_l0_test_time 0.24742889404296875
Test Epoch32 layer1 Acc 0.9095394736842105, AUC 0.9704838991165161, avg_entr 0.013122262433171272
ep32_l1_test_time 0.4549825191497803
Test Epoch32 layer2 Acc 0.9095394736842105, AUC 0.9721277356147766, avg_entr 0.008878754451870918
ep32_l2_test_time 0.6620914936065674
Test Epoch32 layer3 Acc 0.9092105263157895, AUC 0.9703078269958496, avg_entr 0.007330909371376038
ep32_l3_test_time 0.8636863231658936
Test Epoch32 layer4 Acc 0.9092105263157895, AUC 0.9695794582366943, avg_entr 0.006535752210766077
ep32_l4_test_time 1.0601873397827148
gc 0
Train Epoch33 Acc 0.9726333333333333 (116716/120000), AUC 0.9967530965805054
ep33_train_time 80.12257075309753
Test Epoch33 layer0 Acc 0.9136513157894737, AUC 0.9798862934112549, avg_entr 0.03771602362394333
ep33_l0_test_time 0.24788141250610352
Test Epoch33 layer1 Acc 0.9097039473684211, AUC 0.9705761671066284, avg_entr 0.013106731697916985
ep33_l1_test_time 0.45506715774536133
Test Epoch33 layer2 Acc 0.9092105263157895, AUC 0.9722555875778198, avg_entr 0.00883522443473339
ep33_l2_test_time 0.6625127792358398
Test Epoch33 layer3 Acc 0.9092105263157895, AUC 0.9704393148422241, avg_entr 0.007287011481821537
ep33_l3_test_time 0.8650579452514648
Test Epoch33 layer4 Acc 0.909375, AUC 0.969660758972168, avg_entr 0.006520488299429417
ep33_l4_test_time 1.0592310428619385
gc 0
Train Epoch34 Acc 0.973225 (116787/120000), AUC 0.9967036843299866
ep34_train_time 80.20926928520203
Test Epoch34 layer0 Acc 0.9139802631578947, AUC 0.9798728227615356, avg_entr 0.0378275066614151
ep34_l0_test_time 0.24999260902404785
Test Epoch34 layer1 Acc 0.9095394736842105, AUC 0.9704166054725647, avg_entr 0.013110640458762646
ep34_l1_test_time 0.45525360107421875
Test Epoch34 layer2 Acc 0.9100328947368421, AUC 0.9720766544342041, avg_entr 0.008831404149532318
ep34_l2_test_time 0.6621963977813721
Test Epoch34 layer3 Acc 0.909375, AUC 0.9704288244247437, avg_entr 0.00722764665260911
ep34_l3_test_time 0.8640804290771484
Test Epoch34 layer4 Acc 0.909375, AUC 0.9695039987564087, avg_entr 0.006499568931758404
ep34_l4_test_time 1.0575273036956787
gc 0
Train Epoch35 Acc 0.97275 (116730/120000), AUC 0.9968137741088867
ep35_train_time 80.08900284767151
Test Epoch35 layer0 Acc 0.9136513157894737, AUC 0.9798797369003296, avg_entr 0.03766455501317978
ep35_l0_test_time 0.24775981903076172
Test Epoch35 layer1 Acc 0.909375, AUC 0.9703916311264038, avg_entr 0.013087518513202667
ep35_l1_test_time 0.4556288719177246
Test Epoch35 layer2 Acc 0.9097039473684211, AUC 0.9720550179481506, avg_entr 0.008784612640738487
ep35_l2_test_time 0.6617164611816406
Test Epoch35 layer3 Acc 0.9090460526315789, AUC 0.9700311422348022, avg_entr 0.007214495912194252
ep35_l3_test_time 0.864325761795044
Test Epoch35 layer4 Acc 0.9092105263157895, AUC 0.9691927433013916, avg_entr 0.006407602224498987
ep35_l4_test_time 1.0586779117584229
gc 0
Train Epoch36 Acc 0.9732166666666666 (116786/120000), AUC 0.9966256618499756
ep36_train_time 80.13291716575623
Test Epoch36 layer0 Acc 0.9138157894736842, AUC 0.979880690574646, avg_entr 0.03775761276483536
ep36_l0_test_time 0.24790501594543457
Test Epoch36 layer1 Acc 0.909375, AUC 0.970405101776123, avg_entr 0.013072899542748928
ep36_l1_test_time 0.4554154872894287
Test Epoch36 layer2 Acc 0.9097039473684211, AUC 0.9720502495765686, avg_entr 0.00877506285905838
ep36_l2_test_time 0.6626780033111572
Test Epoch36 layer3 Acc 0.9088815789473684, AUC 0.9700574278831482, avg_entr 0.0072115338407456875
ep36_l3_test_time 0.8649160861968994
Test Epoch36 layer4 Acc 0.909375, AUC 0.9690679907798767, avg_entr 0.006425132043659687
ep36_l4_test_time 1.0586376190185547
gc 0
Train Epoch37 Acc 0.9731333333333333 (116776/120000), AUC 0.9966862201690674
ep37_train_time 80.09578824043274
Test Epoch37 layer0 Acc 0.9136513157894737, AUC 0.9798727035522461, avg_entr 0.03767096996307373
ep37_l0_test_time 0.2509310245513916
Test Epoch37 layer1 Acc 0.9092105263157895, AUC 0.9704543948173523, avg_entr 0.01308872178196907
ep37_l1_test_time 0.4554600715637207
Test Epoch37 layer2 Acc 0.9098684210526315, AUC 0.9719918966293335, avg_entr 0.00879705511033535
ep37_l2_test_time 0.661778450012207
Test Epoch37 layer3 Acc 0.9088815789473684, AUC 0.97010338306427, avg_entr 0.007210779003798962
ep37_l3_test_time 0.8641266822814941
Test Epoch37 layer4 Acc 0.9090460526315789, AUC 0.9691733717918396, avg_entr 0.006446135696023703
ep37_l4_test_time 1.0601317882537842
gc 0
Train Epoch38 Acc 0.9731166666666666 (116774/120000), AUC 0.9966920018196106
ep38_train_time 80.14689350128174
Test Epoch38 layer0 Acc 0.9141447368421053, AUC 0.9798809885978699, avg_entr 0.03762675076723099
ep38_l0_test_time 0.24674081802368164
Test Epoch38 layer1 Acc 0.9095394736842105, AUC 0.9705190658569336, avg_entr 0.013065988197922707
ep38_l1_test_time 0.4559028148651123
Test Epoch38 layer2 Acc 0.9095394736842105, AUC 0.9722182750701904, avg_entr 0.008778943680226803
ep38_l2_test_time 0.6621613502502441
Test Epoch38 layer3 Acc 0.9092105263157895, AUC 0.970356822013855, avg_entr 0.007161334156990051
ep38_l3_test_time 0.8652067184448242
Test Epoch38 layer4 Acc 0.909375, AUC 0.9696012139320374, avg_entr 0.0064279441721737385
ep38_l4_test_time 1.0590181350708008
gc 0
Train Epoch39 Acc 0.973225 (116787/120000), AUC 0.9968254566192627
ep39_train_time 80.06871151924133
Test Epoch39 layer0 Acc 0.9138157894736842, AUC 0.9798773527145386, avg_entr 0.037615567445755005
ep39_l0_test_time 0.2508659362792969
Test Epoch39 layer1 Acc 0.9092105263157895, AUC 0.9704532027244568, avg_entr 0.01305327657610178
ep39_l1_test_time 0.4559352397918701
Test Epoch39 layer2 Acc 0.9095394736842105, AUC 0.9720718860626221, avg_entr 0.008756499737501144
ep39_l2_test_time 0.6628763675689697
Test Epoch39 layer3 Acc 0.9090460526315789, AUC 0.9702498912811279, avg_entr 0.007154388353228569
ep39_l3_test_time 0.8646330833435059
Test Epoch39 layer4 Acc 0.9092105263157895, AUC 0.9694900512695312, avg_entr 0.006390648894011974
ep39_l4_test_time 1.0590624809265137
gc 0
Train Epoch40 Acc 0.973125 (116775/120000), AUC 0.9966837167739868
ep40_train_time 80.1052176952362
Test Epoch40 layer0 Acc 0.9141447368421053, AUC 0.9798687100410461, avg_entr 0.03762722387909889
ep40_l0_test_time 0.2479233741760254
Test Epoch40 layer1 Acc 0.909375, AUC 0.970427393913269, avg_entr 0.013045407831668854
ep40_l1_test_time 0.4553654193878174
Test Epoch40 layer2 Acc 0.909375, AUC 0.9721555113792419, avg_entr 0.00873618759214878
ep40_l2_test_time 0.6633403301239014
Test Epoch40 layer3 Acc 0.9090460526315789, AUC 0.970279335975647, avg_entr 0.007156160194426775
ep40_l3_test_time 0.8648324012756348
Test Epoch40 layer4 Acc 0.9092105263157895, AUC 0.9694381952285767, avg_entr 0.006352460943162441
ep40_l4_test_time 1.0585885047912598
gc 0
Train Epoch41 Acc 0.973075 (116769/120000), AUC 0.9966776371002197
ep41_train_time 80.15887022018433
Test Epoch41 layer0 Acc 0.9136513157894737, AUC 0.9798765182495117, avg_entr 0.03764547407627106
ep41_l0_test_time 0.2460639476776123
Test Epoch41 layer1 Acc 0.9092105263157895, AUC 0.9704331159591675, avg_entr 0.013046618551015854
ep41_l1_test_time 0.4550058841705322
Test Epoch41 layer2 Acc 0.909375, AUC 0.9720242023468018, avg_entr 0.008744463324546814
ep41_l2_test_time 0.661261796951294
Test Epoch41 layer3 Acc 0.9090460526315789, AUC 0.9701179265975952, avg_entr 0.007170335855334997
ep41_l3_test_time 0.8631126880645752
Test Epoch41 layer4 Acc 0.909375, AUC 0.9693295955657959, avg_entr 0.0063766855746507645
ep41_l4_test_time 1.058053970336914
gc 0
Train Epoch42 Acc 0.9730083333333334 (116761/120000), AUC 0.9967576265335083
ep42_train_time 80.07298755645752
Test Epoch42 layer0 Acc 0.9138157894736842, AUC 0.9798710346221924, avg_entr 0.03758973628282547
ep42_l0_test_time 0.2467365264892578
Test Epoch42 layer1 Acc 0.9092105263157895, AUC 0.9704184532165527, avg_entr 0.01303916610777378
ep42_l1_test_time 0.4546205997467041
Test Epoch42 layer2 Acc 0.9092105263157895, AUC 0.972110390663147, avg_entr 0.008729158900678158
ep42_l2_test_time 0.661992073059082
Test Epoch42 layer3 Acc 0.9088815789473684, AUC 0.9701589345932007, avg_entr 0.007140621542930603
ep42_l3_test_time 0.8641138076782227
Test Epoch42 layer4 Acc 0.9092105263157895, AUC 0.9694877862930298, avg_entr 0.006348961964249611
ep42_l4_test_time 1.0572078227996826
gc 0
Train Epoch43 Acc 0.973325 (116799/120000), AUC 0.9968108534812927
ep43_train_time 80.15114712715149
Test Epoch43 layer0 Acc 0.9139802631578947, AUC 0.9798762798309326, avg_entr 0.03761504963040352
ep43_l0_test_time 0.24570655822753906
Test Epoch43 layer1 Acc 0.9092105263157895, AUC 0.970428466796875, avg_entr 0.013047119602560997
ep43_l1_test_time 0.4553952217102051
Test Epoch43 layer2 Acc 0.9095394736842105, AUC 0.9720833897590637, avg_entr 0.00873936340212822
ep43_l2_test_time 0.6618931293487549
Test Epoch43 layer3 Acc 0.9087171052631579, AUC 0.9701893925666809, avg_entr 0.007159047294408083
ep43_l3_test_time 0.8636617660522461
Test Epoch43 layer4 Acc 0.9090460526315789, AUC 0.9693752527236938, avg_entr 0.006368760019540787
ep43_l4_test_time 1.0571630001068115
gc 0
Train Epoch44 Acc 0.97315 (116778/120000), AUC 0.9967409372329712
ep44_train_time 80.08289504051208
Test Epoch44 layer0 Acc 0.9136513157894737, AUC 0.979876697063446, avg_entr 0.037647444754838943
ep44_l0_test_time 0.2478790283203125
Test Epoch44 layer1 Acc 0.9092105263157895, AUC 0.9704312682151794, avg_entr 0.013046864420175552
ep44_l1_test_time 0.4556083679199219
Test Epoch44 layer2 Acc 0.9092105263157895, AUC 0.9720529317855835, avg_entr 0.008741814643144608
ep44_l2_test_time 0.6624624729156494
Test Epoch44 layer3 Acc 0.9088815789473684, AUC 0.9701874852180481, avg_entr 0.007160424720495939
ep44_l3_test_time 0.864001989364624
Test Epoch44 layer4 Acc 0.9092105263157895, AUC 0.9694221019744873, avg_entr 0.0063791521824896336
ep44_l4_test_time 1.05853271484375
gc 0
Train Epoch45 Acc 0.9731583333333333 (116779/120000), AUC 0.9967519044876099
ep45_train_time 80.09461665153503
Test Epoch45 layer0 Acc 0.9136513157894737, AUC 0.9798753261566162, avg_entr 0.037632737308740616
ep45_l0_test_time 0.24651074409484863
Test Epoch45 layer1 Acc 0.9092105263157895, AUC 0.9704257845878601, avg_entr 0.013041508384048939
ep45_l1_test_time 0.4545872211456299
Test Epoch45 layer2 Acc 0.909375, AUC 0.9720465540885925, avg_entr 0.008729259483516216
ep45_l2_test_time 0.6618638038635254
Test Epoch45 layer3 Acc 0.9088815789473684, AUC 0.9701182246208191, avg_entr 0.007151471450924873
ep45_l3_test_time 0.8645503520965576
Test Epoch45 layer4 Acc 0.9092105263157895, AUC 0.9693214297294617, avg_entr 0.006349462084472179
ep45_l4_test_time 1.0567841529846191
gc 0
Train Epoch46 Acc 0.9731333333333333 (116776/120000), AUC 0.996845006942749
ep46_train_time 80.06909680366516
Test Epoch46 layer0 Acc 0.9138157894736842, AUC 0.9798697829246521, avg_entr 0.03760712221264839
ep46_l0_test_time 0.24530482292175293
Test Epoch46 layer1 Acc 0.9092105263157895, AUC 0.9704149961471558, avg_entr 0.013040680438280106
ep46_l1_test_time 0.4545478820800781
Test Epoch46 layer2 Acc 0.9095394736842105, AUC 0.9720895290374756, avg_entr 0.008725374937057495
ep46_l2_test_time 0.6616721153259277
Test Epoch46 layer3 Acc 0.9088815789473684, AUC 0.9701510071754456, avg_entr 0.007136867381632328
ep46_l3_test_time 0.8630404472351074
Test Epoch46 layer4 Acc 0.9090460526315789, AUC 0.9694200754165649, avg_entr 0.0063516139052808285
ep46_l4_test_time 1.057328462600708
gc 0
Train Epoch47 Acc 0.9733916666666667 (116807/120000), AUC 0.9967973828315735
ep47_train_time 80.10211610794067
Test Epoch47 layer0 Acc 0.9138157894736842, AUC 0.979869544506073, avg_entr 0.037575382739305496
ep47_l0_test_time 0.24676203727722168
Test Epoch47 layer1 Acc 0.9092105263157895, AUC 0.9704174995422363, avg_entr 0.01303964015096426
ep47_l1_test_time 0.4552493095397949
Test Epoch47 layer2 Acc 0.909375, AUC 0.9721056818962097, avg_entr 0.00872461311519146
ep47_l2_test_time 0.6632914543151855
Test Epoch47 layer3 Acc 0.9088815789473684, AUC 0.9701546430587769, avg_entr 0.00713859498500824
ep47_l3_test_time 0.8659660816192627
Test Epoch47 layer4 Acc 0.9090460526315789, AUC 0.9694006443023682, avg_entr 0.006352621130645275
ep47_l4_test_time 1.0588185787200928
gc 0
Train Epoch48 Acc 0.9734333333333334 (116812/120000), AUC 0.9967347979545593
ep48_train_time 80.18899989128113
Test Epoch48 layer0 Acc 0.9141447368421053, AUC 0.9798684120178223, avg_entr 0.03760520741343498
ep48_l0_test_time 0.24624300003051758
Test Epoch48 layer1 Acc 0.9092105263157895, AUC 0.9704168438911438, avg_entr 0.01303788460791111
ep48_l1_test_time 0.4541513919830322
Test Epoch48 layer2 Acc 0.909375, AUC 0.9720721244812012, avg_entr 0.008723162114620209
ep48_l2_test_time 0.6613705158233643
Test Epoch48 layer3 Acc 0.9088815789473684, AUC 0.9701578617095947, avg_entr 0.007137612905353308
ep48_l3_test_time 0.8635976314544678
Test Epoch48 layer4 Acc 0.9090460526315789, AUC 0.9693809747695923, avg_entr 0.006352745927870274
ep48_l4_test_time 1.0572962760925293
gc 0
Train Epoch49 Acc 0.9729833333333333 (116758/120000), AUC 0.9966843128204346
ep49_train_time 80.15361189842224
Test Epoch49 layer0 Acc 0.9139802631578947, AUC 0.9798663258552551, avg_entr 0.03761756792664528
ep49_l0_test_time 0.247206449508667
Test Epoch49 layer1 Acc 0.9090460526315789, AUC 0.9704189300537109, avg_entr 0.013038359582424164
ep49_l1_test_time 0.4554433822631836
Test Epoch49 layer2 Acc 0.9095394736842105, AUC 0.9720772504806519, avg_entr 0.00871958862990141
ep49_l2_test_time 0.6629388332366943
Test Epoch49 layer3 Acc 0.9088815789473684, AUC 0.9701611995697021, avg_entr 0.007131117861717939
ep49_l3_test_time 0.86492919921875
Test Epoch49 layer4 Acc 0.9090460526315789, AUC 0.9694118499755859, avg_entr 0.006346854381263256
ep49_l4_test_time 1.059100866317749
Best AUC 0.9825029373168945
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_transformeral_l5_pad175//ag_news_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.925, AUC 0.9862343668937683, avg_entr 0.11778626590967178
ep49_l0_test_time 0.06274986267089844
Test Epoch49 layer1 Acc 0.9282894736842106, AUC 0.9868165850639343, avg_entr 0.04302160441875458
ep49_l1_test_time 0.1146841049194336
Test Epoch49 layer2 Acc 0.9282894736842106, AUC 0.9867867231369019, avg_entr 0.03734084963798523
ep49_l2_test_time 0.1673450469970703
Test Epoch49 layer3 Acc 0.9269736842105263, AUC 0.9862603545188904, avg_entr 0.03370020166039467
ep49_l3_test_time 0.21865606307983398
Test Epoch49 layer4 Acc 0.9269736842105263, AUC 0.9863831996917725, avg_entr 0.03243982046842575
ep49_l4_test_time 0.26644086837768555
