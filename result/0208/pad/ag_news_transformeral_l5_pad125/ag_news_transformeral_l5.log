total count words 102019
vocab size 30000
found 26754 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13672292
Start Training
gc 0
Train Epoch0 Acc 0.6159583333333334 (73915/120000), AUC 0.852074146270752
ep0_train_time 66.26583099365234
Test Epoch0 layer0 Acc 0.9036184210526316, AUC 0.9748392105102539, avg_entr 0.24152489006519318
ep0_l0_test_time 0.33385396003723145
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9042763157894737, AUC 0.9769852161407471, avg_entr 0.1648547500371933
ep0_l1_test_time 0.47230982780456543
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.905921052631579, AUC 0.9771040081977844, avg_entr 0.15569928288459778
ep0_l2_test_time 0.6604464054107666
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer3 Acc 0.9074013157894737, AUC 0.9771037697792053, avg_entr 0.15487973392009735
ep0_l3_test_time 0.7891278266906738
Test Epoch0 layer4 Acc 0.905921052631579, AUC 0.9772356748580933, avg_entr 0.15797516703605652
ep0_l4_test_time 0.751899003982544
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.922425 (110691/120000), AUC 0.9821455478668213
ep1_train_time 56.912702560424805
Test Epoch1 layer0 Acc 0.9125, AUC 0.97849041223526, avg_entr 0.14047393202781677
ep1_l0_test_time 0.1892411708831787
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.9151315789473684, AUC 0.9799273610115051, avg_entr 0.08384574204683304
ep1_l1_test_time 0.3323557376861572
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.9159539473684211, AUC 0.9799861907958984, avg_entr 0.06976111978292465
ep1_l2_test_time 0.4729907512664795
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer3 Acc 0.9172697368421052, AUC 0.9796625971794128, avg_entr 0.06088521331548691
ep1_l3_test_time 0.6120553016662598
Test Epoch1 layer4 Acc 0.9162828947368421, AUC 0.9798905849456787, avg_entr 0.058691658079624176
ep1_l4_test_time 0.7417550086975098
gc 0
Train Epoch2 Acc 0.9361583333333333 (112339/120000), AUC 0.9870796203613281
ep2_train_time 57.03089690208435
Test Epoch2 layer0 Acc 0.9126644736842106, AUC 0.9798477292060852, avg_entr 0.1114019900560379
ep2_l0_test_time 0.18830299377441406
Test Epoch2 layer1 Acc 0.9171052631578948, AUC 0.9806079268455505, avg_entr 0.04508659616112709
ep2_l1_test_time 0.3296322822570801
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 2
Test Epoch2 layer2 Acc 0.9174342105263158, AUC 0.9806532263755798, avg_entr 0.0388631634414196
ep2_l2_test_time 0.4732232093811035
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 2
Test Epoch2 layer3 Acc 0.9175986842105263, AUC 0.9813005924224854, avg_entr 0.03579775243997574
ep2_l3_test_time 0.6095969676971436
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 2
Test Epoch2 layer4 Acc 0.9177631578947368, AUC 0.9806442260742188, avg_entr 0.03525326028466225
ep2_l4_test_time 0.7440600395202637
gc 0
Train Epoch3 Acc 0.9443416666666666 (113321/120000), AUC 0.9893022775650024
ep3_train_time 56.92888522148132
Test Epoch3 layer0 Acc 0.9151315789473684, AUC 0.9802938103675842, avg_entr 0.0908469557762146
ep3_l0_test_time 0.18920326232910156
Test Epoch3 layer1 Acc 0.9162828947368421, AUC 0.9799514412879944, avg_entr 0.03306420147418976
ep3_l1_test_time 0.3298828601837158
Test Epoch3 layer2 Acc 0.9164473684210527, AUC 0.9819911122322083, avg_entr 0.027819819748401642
ep3_l2_test_time 0.47095823287963867
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 3
Test Epoch3 layer3 Acc 0.9164473684210527, AUC 0.9823986291885376, avg_entr 0.026091864332556725
ep3_l3_test_time 0.6113948822021484
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 3
Test Epoch3 layer4 Acc 0.9164473684210527, AUC 0.9825010895729065, avg_entr 0.024975458160042763
ep3_l4_test_time 0.7423036098480225
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.9493416666666666 (113921/120000), AUC 0.9908772706985474
ep4_train_time 57.02401518821716
Test Epoch4 layer0 Acc 0.9144736842105263, AUC 0.9805178642272949, avg_entr 0.08201147615909576
ep4_l0_test_time 0.18896245956420898
Test Epoch4 layer1 Acc 0.915296052631579, AUC 0.9777239561080933, avg_entr 0.031270429491996765
ep4_l1_test_time 0.3304564952850342
Test Epoch4 layer2 Acc 0.9148026315789474, AUC 0.9781513810157776, avg_entr 0.026988204568624496
ep4_l2_test_time 0.47123193740844727
Test Epoch4 layer3 Acc 0.9149671052631579, AUC 0.9794632196426392, avg_entr 0.025295032188296318
ep4_l3_test_time 0.6090381145477295
Test Epoch4 layer4 Acc 0.9159539473684211, AUC 0.9784708619117737, avg_entr 0.024686308577656746
ep4_l4_test_time 0.7403802871704102
gc 0
Train Epoch5 Acc 0.9537083333333334 (114445/120000), AUC 0.9917441606521606
ep5_train_time 57.02996253967285
Test Epoch5 layer0 Acc 0.9166118421052631, AUC 0.9806056022644043, avg_entr 0.07362973690032959
ep5_l0_test_time 0.18962478637695312
Test Epoch5 layer1 Acc 0.9111842105263158, AUC 0.9780946373939514, avg_entr 0.026371775195002556
ep5_l1_test_time 0.33105945587158203
Test Epoch5 layer2 Acc 0.9111842105263158, AUC 0.9796460270881653, avg_entr 0.02069450542330742
ep5_l2_test_time 0.47199368476867676
Test Epoch5 layer3 Acc 0.9126644736842106, AUC 0.9806116819381714, avg_entr 0.018986999988555908
ep5_l3_test_time 0.6100099086761475
Test Epoch5 layer4 Acc 0.9121710526315789, AUC 0.9810003042221069, avg_entr 0.018266700208187103
ep5_l4_test_time 0.7412853240966797
gc 0
Train Epoch6 Acc 0.9568916666666667 (114827/120000), AUC 0.9928797483444214
ep6_train_time 56.959147930145264
Test Epoch6 layer0 Acc 0.9174342105263158, AUC 0.9805572032928467, avg_entr 0.06889941543340683
ep6_l0_test_time 0.18902111053466797
Test Epoch6 layer1 Acc 0.912828947368421, AUC 0.9759040474891663, avg_entr 0.02417212352156639
ep6_l1_test_time 0.32967519760131836
Test Epoch6 layer2 Acc 0.9120065789473685, AUC 0.9793878197669983, avg_entr 0.01901955157518387
ep6_l2_test_time 0.47034239768981934
Test Epoch6 layer3 Acc 0.9111842105263158, AUC 0.9795322418212891, avg_entr 0.017359184101223946
ep6_l3_test_time 0.6071152687072754
Test Epoch6 layer4 Acc 0.9116776315789473, AUC 0.9801427125930786, avg_entr 0.01665641926229
ep6_l4_test_time 0.7402338981628418
gc 0
Train Epoch7 Acc 0.9601583333333333 (115219/120000), AUC 0.9935864806175232
ep7_train_time 57.046618700027466
Test Epoch7 layer0 Acc 0.9151315789473684, AUC 0.9803787469863892, avg_entr 0.06420084089040756
ep7_l0_test_time 0.18892312049865723
Test Epoch7 layer1 Acc 0.9141447368421053, AUC 0.9758520126342773, avg_entr 0.0217968188226223
ep7_l1_test_time 0.3314399719238281
Test Epoch7 layer2 Acc 0.9136513157894737, AUC 0.9783642292022705, avg_entr 0.016264183446764946
ep7_l2_test_time 0.4736294746398926
Test Epoch7 layer3 Acc 0.9129934210526316, AUC 0.9804872870445251, avg_entr 0.01451333612203598
ep7_l3_test_time 0.6112048625946045
Test Epoch7 layer4 Acc 0.9125, AUC 0.9796440005302429, avg_entr 0.013651053421199322
ep7_l4_test_time 0.7442080974578857
gc 0
Train Epoch8 Acc 0.9617666666666667 (115412/120000), AUC 0.994294285774231
ep8_train_time 56.928866386413574
Test Epoch8 layer0 Acc 0.9131578947368421, AUC 0.9802652597427368, avg_entr 0.06045166403055191
ep8_l0_test_time 0.18878579139709473
Test Epoch8 layer1 Acc 0.912828947368421, AUC 0.9747468829154968, avg_entr 0.020459067076444626
ep8_l1_test_time 0.32981014251708984
Test Epoch8 layer2 Acc 0.9111842105263158, AUC 0.9783480167388916, avg_entr 0.015209970064461231
ep8_l2_test_time 0.4715869426727295
Test Epoch8 layer3 Acc 0.9110197368421052, AUC 0.9800596237182617, avg_entr 0.013747871853411198
ep8_l3_test_time 0.6085009574890137
Test Epoch8 layer4 Acc 0.9106907894736842, AUC 0.9802213311195374, avg_entr 0.01296196598559618
ep8_l4_test_time 0.7398815155029297
gc 0
Train Epoch9 Acc 0.9647416666666667 (115769/120000), AUC 0.9949803948402405
ep9_train_time 56.95033621788025
Test Epoch9 layer0 Acc 0.9134868421052632, AUC 0.9800127148628235, avg_entr 0.059329476207494736
ep9_l0_test_time 0.18861794471740723
Test Epoch9 layer1 Acc 0.9121710526315789, AUC 0.9728938341140747, avg_entr 0.020280320197343826
ep9_l1_test_time 0.32943129539489746
Test Epoch9 layer2 Acc 0.9100328947368421, AUC 0.9753627777099609, avg_entr 0.014926676638424397
ep9_l2_test_time 0.4711635112762451
Test Epoch9 layer3 Acc 0.9098684210526315, AUC 0.9763531684875488, avg_entr 0.013631426729261875
ep9_l3_test_time 0.6079099178314209
Test Epoch9 layer4 Acc 0.9100328947368421, AUC 0.9768007397651672, avg_entr 0.012500463984906673
ep9_l4_test_time 0.7401010990142822
gc 0
Train Epoch10 Acc 0.9662833333333334 (115954/120000), AUC 0.9949624538421631
ep10_train_time 56.934770345687866
Test Epoch10 layer0 Acc 0.9141447368421053, AUC 0.9799425005912781, avg_entr 0.05597105622291565
ep10_l0_test_time 0.18966150283813477
Test Epoch10 layer1 Acc 0.9105263157894737, AUC 0.9736955761909485, avg_entr 0.02047821506857872
ep10_l1_test_time 0.3296225070953369
Test Epoch10 layer2 Acc 0.909375, AUC 0.9752357006072998, avg_entr 0.015502345748245716
ep10_l2_test_time 0.47116684913635254
Test Epoch10 layer3 Acc 0.9103618421052632, AUC 0.9753556251525879, avg_entr 0.014157707802951336
ep10_l3_test_time 0.6106171607971191
Test Epoch10 layer4 Acc 0.9108552631578948, AUC 0.9767148494720459, avg_entr 0.013240919448435307
ep10_l4_test_time 0.7412796020507812
gc 0
Train Epoch11 Acc 0.967175 (116061/120000), AUC 0.9952732920646667
ep11_train_time 57.038315296173096
Test Epoch11 layer0 Acc 0.915296052631579, AUC 0.9798898100852966, avg_entr 0.05348562076687813
ep11_l0_test_time 0.18922734260559082
Test Epoch11 layer1 Acc 0.9106907894736842, AUC 0.9721630811691284, avg_entr 0.01804163306951523
ep11_l1_test_time 0.3301990032196045
Test Epoch11 layer2 Acc 0.9098684210526315, AUC 0.9750506281852722, avg_entr 0.012180717661976814
ep11_l2_test_time 0.4709126949310303
Test Epoch11 layer3 Acc 0.9101973684210526, AUC 0.9778556227684021, avg_entr 0.010756191797554493
ep11_l3_test_time 0.607311487197876
Test Epoch11 layer4 Acc 0.9103618421052632, AUC 0.9765950441360474, avg_entr 0.009877646341919899
ep11_l4_test_time 0.7402076721191406
gc 0
Train Epoch12 Acc 0.9680916666666667 (116171/120000), AUC 0.9956161975860596
ep12_train_time 56.985273599624634
Test Epoch12 layer0 Acc 0.9125, AUC 0.9798414707183838, avg_entr 0.051683392375707626
ep12_l0_test_time 0.18883538246154785
Test Epoch12 layer1 Acc 0.9105263157894737, AUC 0.9721183180809021, avg_entr 0.018888695165514946
ep12_l1_test_time 0.3296067714691162
Test Epoch12 layer2 Acc 0.9092105263157895, AUC 0.974929690361023, avg_entr 0.013822643086314201
ep12_l2_test_time 0.47097349166870117
Test Epoch12 layer3 Acc 0.9090460526315789, AUC 0.9762445688247681, avg_entr 0.012273374013602734
ep12_l3_test_time 0.6065547466278076
Test Epoch12 layer4 Acc 0.9090460526315789, AUC 0.9758954644203186, avg_entr 0.011353600770235062
ep12_l4_test_time 0.7403481006622314
gc 0
Train Epoch13 Acc 0.9696 (116352/120000), AUC 0.9958224296569824
ep13_train_time 57.04277229309082
Test Epoch13 layer0 Acc 0.9139802631578947, AUC 0.9797513484954834, avg_entr 0.04987220838665962
ep13_l0_test_time 0.19068622589111328
Test Epoch13 layer1 Acc 0.9098684210526315, AUC 0.9704400897026062, avg_entr 0.01718643680214882
ep13_l1_test_time 0.3308877944946289
Test Epoch13 layer2 Acc 0.9103618421052632, AUC 0.971866250038147, avg_entr 0.011776241473853588
ep13_l2_test_time 0.4743781089782715
Test Epoch13 layer3 Acc 0.9097039473684211, AUC 0.9740051627159119, avg_entr 0.010298063978552818
ep13_l3_test_time 0.6119780540466309
Test Epoch13 layer4 Acc 0.9101973684210526, AUC 0.9726080894470215, avg_entr 0.009590690955519676
ep13_l4_test_time 0.7424347400665283
gc 0
Train Epoch14 Acc 0.96995 (116394/120000), AUC 0.9959007501602173
ep14_train_time 57.0379958152771
Test Epoch14 layer0 Acc 0.9125, AUC 0.9796124696731567, avg_entr 0.04891432076692581
ep14_l0_test_time 0.18976402282714844
Test Epoch14 layer1 Acc 0.9098684210526315, AUC 0.9714581966400146, avg_entr 0.017016390338540077
ep14_l1_test_time 0.32992124557495117
Test Epoch14 layer2 Acc 0.9087171052631579, AUC 0.9751056432723999, avg_entr 0.011418354697525501
ep14_l2_test_time 0.4704890251159668
Test Epoch14 layer3 Acc 0.9095394736842105, AUC 0.975972056388855, avg_entr 0.009914025664329529
ep14_l3_test_time 0.6078414916992188
Test Epoch14 layer4 Acc 0.9092105263157895, AUC 0.9753421545028687, avg_entr 0.00914075504988432
ep14_l4_test_time 0.740558385848999
gc 0
Train Epoch15 Acc 0.9709083333333334 (116509/120000), AUC 0.9959956407546997
ep15_train_time 57.03221106529236
Test Epoch15 layer0 Acc 0.912828947368421, AUC 0.979617714881897, avg_entr 0.04725205898284912
ep15_l0_test_time 0.18999099731445312
Test Epoch15 layer1 Acc 0.9101973684210526, AUC 0.9705419540405273, avg_entr 0.017042674124240875
ep15_l1_test_time 0.3305642604827881
Test Epoch15 layer2 Acc 0.9083881578947368, AUC 0.972898542881012, avg_entr 0.012369795702397823
ep15_l2_test_time 0.47173595428466797
Test Epoch15 layer3 Acc 0.9082236842105263, AUC 0.9732213616371155, avg_entr 0.010992682538926601
ep15_l3_test_time 0.608269214630127
Test Epoch15 layer4 Acc 0.9075657894736842, AUC 0.972556471824646, avg_entr 0.010387517511844635
ep15_l4_test_time 0.7408380508422852
gc 0
Train Epoch16 Acc 0.97115 (116538/120000), AUC 0.9961135387420654
ep16_train_time 57.0743362903595
Test Epoch16 layer0 Acc 0.9125, AUC 0.979583203792572, avg_entr 0.045540496706962585
ep16_l0_test_time 0.18880367279052734
Test Epoch16 layer1 Acc 0.9100328947368421, AUC 0.9707062244415283, avg_entr 0.01608974300324917
ep16_l1_test_time 0.32982826232910156
Test Epoch16 layer2 Acc 0.9078947368421053, AUC 0.9722349643707275, avg_entr 0.010651440359652042
ep16_l2_test_time 0.47086548805236816
Test Epoch16 layer3 Acc 0.9078947368421053, AUC 0.9751113057136536, avg_entr 0.008950447663664818
ep16_l3_test_time 0.6082470417022705
Test Epoch16 layer4 Acc 0.9077302631578947, AUC 0.9736548066139221, avg_entr 0.00823703221976757
ep16_l4_test_time 0.7406980991363525
gc 0
Train Epoch17 Acc 0.971825 (116619/120000), AUC 0.9962708353996277
ep17_train_time 57.01876521110535
Test Epoch17 layer0 Acc 0.9125, AUC 0.979572057723999, avg_entr 0.0441615991294384
ep17_l0_test_time 0.18915867805480957
Test Epoch17 layer1 Acc 0.9101973684210526, AUC 0.9701294898986816, avg_entr 0.016009360551834106
ep17_l1_test_time 0.32979559898376465
Test Epoch17 layer2 Acc 0.9087171052631579, AUC 0.9727364182472229, avg_entr 0.01119960006326437
ep17_l2_test_time 0.47054576873779297
Test Epoch17 layer3 Acc 0.9088815789473684, AUC 0.9742863774299622, avg_entr 0.00969632901251316
ep17_l3_test_time 0.6079671382904053
Test Epoch17 layer4 Acc 0.9085526315789474, AUC 0.9727054834365845, avg_entr 0.008931792341172695
ep17_l4_test_time 0.7404751777648926
gc 0
Train Epoch18 Acc 0.9723083333333333 (116677/120000), AUC 0.996338427066803
ep18_train_time 56.99387240409851
Test Epoch18 layer0 Acc 0.9116776315789473, AUC 0.9795489311218262, avg_entr 0.04370497539639473
ep18_l0_test_time 0.1897892951965332
Test Epoch18 layer1 Acc 0.9101973684210526, AUC 0.9704686403274536, avg_entr 0.016271183267235756
ep18_l1_test_time 0.32997751235961914
Test Epoch18 layer2 Acc 0.9080592105263158, AUC 0.9728907346725464, avg_entr 0.011559125036001205
ep18_l2_test_time 0.4706099033355713
Test Epoch18 layer3 Acc 0.9083881578947368, AUC 0.9732697606086731, avg_entr 0.01017669402062893
ep18_l3_test_time 0.6078667640686035
Test Epoch18 layer4 Acc 0.9082236842105263, AUC 0.9711395502090454, avg_entr 0.009449332021176815
ep18_l4_test_time 0.7403368949890137
gc 0
Train Epoch19 Acc 0.972425 (116691/120000), AUC 0.9962944984436035
ep19_train_time 57.08488440513611
Test Epoch19 layer0 Acc 0.9125, AUC 0.9795555472373962, avg_entr 0.04229891300201416
ep19_l0_test_time 0.18978595733642578
Test Epoch19 layer1 Acc 0.9105263157894737, AUC 0.970209002494812, avg_entr 0.015900779515504837
ep19_l1_test_time 0.33061671257019043
Test Epoch19 layer2 Acc 0.9088815789473684, AUC 0.9729870557785034, avg_entr 0.011567577719688416
ep19_l2_test_time 0.4721558094024658
Test Epoch19 layer3 Acc 0.9088815789473684, AUC 0.9732348322868347, avg_entr 0.010147240944206715
ep19_l3_test_time 0.6066863536834717
Test Epoch19 layer4 Acc 0.9087171052631579, AUC 0.9717954993247986, avg_entr 0.00960766151547432
ep19_l4_test_time 0.7416436672210693
gc 0
Train Epoch20 Acc 0.9725333333333334 (116704/120000), AUC 0.9963312745094299
ep20_train_time 57.167412757873535
Test Epoch20 layer0 Acc 0.9121710526315789, AUC 0.979577898979187, avg_entr 0.041405875235795975
ep20_l0_test_time 0.18875694274902344
Test Epoch20 layer1 Acc 0.9103618421052632, AUC 0.9706316590309143, avg_entr 0.015655094757676125
ep20_l1_test_time 0.33033084869384766
Test Epoch20 layer2 Acc 0.9087171052631579, AUC 0.9726799130439758, avg_entr 0.010746062733232975
ep20_l2_test_time 0.4709327220916748
Test Epoch20 layer3 Acc 0.9085526315789474, AUC 0.972680926322937, avg_entr 0.009188580326735973
ep20_l3_test_time 0.6093959808349609
Test Epoch20 layer4 Acc 0.9085526315789474, AUC 0.9701048135757446, avg_entr 0.008399766869843006
ep20_l4_test_time 0.7395217418670654
gc 0
Train Epoch21 Acc 0.9732333333333333 (116788/120000), AUC 0.9964078664779663
ep21_train_time 57.038928508758545
Test Epoch21 layer0 Acc 0.9125, AUC 0.9795656800270081, avg_entr 0.040325827896595
ep21_l0_test_time 0.1902143955230713
Test Epoch21 layer1 Acc 0.9108552631578948, AUC 0.9704652428627014, avg_entr 0.015089619904756546
ep21_l1_test_time 0.3307454586029053
Test Epoch21 layer2 Acc 0.9077302631578947, AUC 0.9730848073959351, avg_entr 0.010465107858181
ep21_l2_test_time 0.47160911560058594
Test Epoch21 layer3 Acc 0.9077302631578947, AUC 0.9734960198402405, avg_entr 0.008882959373295307
ep21_l3_test_time 0.6081984043121338
Test Epoch21 layer4 Acc 0.9083881578947368, AUC 0.9710071086883545, avg_entr 0.008166045881807804
ep21_l4_test_time 0.741255521774292
gc 0
Train Epoch22 Acc 0.9731583333333333 (116779/120000), AUC 0.9964277744293213
ep22_train_time 57.04722452163696
Test Epoch22 layer0 Acc 0.9118421052631579, AUC 0.9795612096786499, avg_entr 0.03997544199228287
ep22_l0_test_time 0.1897411346435547
Test Epoch22 layer1 Acc 0.9101973684210526, AUC 0.9700432419776917, avg_entr 0.01497140433639288
ep22_l1_test_time 0.3301100730895996
Test Epoch22 layer2 Acc 0.9077302631578947, AUC 0.9721986055374146, avg_entr 0.010271428152918816
ep22_l2_test_time 0.4706254005432129
Test Epoch22 layer3 Acc 0.9072368421052631, AUC 0.971979022026062, avg_entr 0.008747346699237823
ep22_l3_test_time 0.6092772483825684
Test Epoch22 layer4 Acc 0.9072368421052631, AUC 0.9693809151649475, avg_entr 0.00810172501951456
ep22_l4_test_time 0.7397599220275879
gc 0
Train Epoch23 Acc 0.9732083333333333 (116785/120000), AUC 0.9964299201965332
ep23_train_time 57.04887342453003
Test Epoch23 layer0 Acc 0.9133223684210526, AUC 0.9795451164245605, avg_entr 0.03906122222542763
ep23_l0_test_time 0.18934011459350586
Test Epoch23 layer1 Acc 0.9100328947368421, AUC 0.9701149463653564, avg_entr 0.014334231615066528
ep23_l1_test_time 0.3292090892791748
Test Epoch23 layer2 Acc 0.9077302631578947, AUC 0.9719521999359131, avg_entr 0.0094155790284276
ep23_l2_test_time 0.469602108001709
Test Epoch23 layer3 Acc 0.9080592105263158, AUC 0.9725030660629272, avg_entr 0.007869007997214794
ep23_l3_test_time 0.6067900657653809
Test Epoch23 layer4 Acc 0.9078947368421053, AUC 0.9703532457351685, avg_entr 0.00726894848048687
ep23_l4_test_time 0.7398548126220703
gc 0
Train Epoch24 Acc 0.9734333333333334 (116812/120000), AUC 0.9966316223144531
ep24_train_time 57.180415868759155
Test Epoch24 layer0 Acc 0.9116776315789473, AUC 0.9795427918434143, avg_entr 0.03877940773963928
ep24_l0_test_time 0.19176959991455078
Test Epoch24 layer1 Acc 0.9105263157894737, AUC 0.970032274723053, avg_entr 0.014752243645489216
ep24_l1_test_time 0.3299064636230469
Test Epoch24 layer2 Acc 0.9069078947368421, AUC 0.9730079174041748, avg_entr 0.010035223327577114
ep24_l2_test_time 0.47074246406555176
Test Epoch24 layer3 Acc 0.906578947368421, AUC 0.9730693101882935, avg_entr 0.008529768325388432
ep24_l3_test_time 0.6086769104003906
Test Epoch24 layer4 Acc 0.906578947368421, AUC 0.970964252948761, avg_entr 0.007966774515807629
ep24_l4_test_time 0.7409014701843262
gc 0
Train Epoch25 Acc 0.9736916666666666 (116843/120000), AUC 0.9965007305145264
ep25_train_time 57.069260358810425
Test Epoch25 layer0 Acc 0.9116776315789473, AUC 0.9795315265655518, avg_entr 0.03895837813615799
ep25_l0_test_time 0.18938159942626953
Test Epoch25 layer1 Acc 0.9105263157894737, AUC 0.9702913761138916, avg_entr 0.015040391124784946
ep25_l1_test_time 0.3292880058288574
Test Epoch25 layer2 Acc 0.9082236842105263, AUC 0.973126232624054, avg_entr 0.010244758799672127
ep25_l2_test_time 0.47112417221069336
Test Epoch25 layer3 Acc 0.9078947368421053, AUC 0.9727397561073303, avg_entr 0.008684645406901836
ep25_l3_test_time 0.608675479888916
Test Epoch25 layer4 Acc 0.9080592105263158, AUC 0.9706394076347351, avg_entr 0.008046846836805344
ep25_l4_test_time 0.7403018474578857
gc 0
Train Epoch26 Acc 0.973525 (116823/120000), AUC 0.9967222213745117
ep26_train_time 57.056241035461426
Test Epoch26 layer0 Acc 0.9126644736842106, AUC 0.9795438051223755, avg_entr 0.03837098926305771
ep26_l0_test_time 0.1896369457244873
Test Epoch26 layer1 Acc 0.9110197368421052, AUC 0.9701031446456909, avg_entr 0.014594167470932007
ep26_l1_test_time 0.3301408290863037
Test Epoch26 layer2 Acc 0.9070723684210527, AUC 0.9725968837738037, avg_entr 0.009709591045975685
ep26_l2_test_time 0.470928430557251
Test Epoch26 layer3 Acc 0.9069078947368421, AUC 0.9727581739425659, avg_entr 0.008180628530681133
ep26_l3_test_time 0.6085610389709473
Test Epoch26 layer4 Acc 0.9069078947368421, AUC 0.9703713059425354, avg_entr 0.007742618210613728
ep26_l4_test_time 0.7396237850189209
gc 0
Train Epoch27 Acc 0.9735666666666667 (116828/120000), AUC 0.9966293573379517
ep27_train_time 57.05126595497131
Test Epoch27 layer0 Acc 0.9120065789473685, AUC 0.979534387588501, avg_entr 0.038382481783628464
ep27_l0_test_time 0.1886882781982422
Test Epoch27 layer1 Acc 0.9101973684210526, AUC 0.9698642492294312, avg_entr 0.014731419272720814
ep27_l1_test_time 0.329789400100708
Test Epoch27 layer2 Acc 0.9069078947368421, AUC 0.9724138379096985, avg_entr 0.009828681126236916
ep27_l2_test_time 0.47122645378112793
Test Epoch27 layer3 Acc 0.906578947368421, AUC 0.9727427959442139, avg_entr 0.008323343470692635
ep27_l3_test_time 0.6087837219238281
Test Epoch27 layer4 Acc 0.9067434210526316, AUC 0.9701331853866577, avg_entr 0.007782602217048407
ep27_l4_test_time 0.7408502101898193
gc 0
Train Epoch28 Acc 0.9738666666666667 (116864/120000), AUC 0.9966856241226196
ep28_train_time 57.08694911003113
Test Epoch28 layer0 Acc 0.9116776315789473, AUC 0.9795228242874146, avg_entr 0.03809548169374466
ep28_l0_test_time 0.1895599365234375
Test Epoch28 layer1 Acc 0.9098684210526315, AUC 0.9703029990196228, avg_entr 0.014533005654811859
ep28_l1_test_time 0.3312509059906006
Test Epoch28 layer2 Acc 0.9067434210526316, AUC 0.9728306531906128, avg_entr 0.00991053320467472
ep28_l2_test_time 0.47194671630859375
Test Epoch28 layer3 Acc 0.9072368421052631, AUC 0.9732789397239685, avg_entr 0.008207054808735847
ep28_l3_test_time 0.6078131198883057
Test Epoch28 layer4 Acc 0.9077302631578947, AUC 0.9711119532585144, avg_entr 0.007623444311320782
ep28_l4_test_time 0.7410256862640381
gc 0
Train Epoch29 Acc 0.9738 (116856/120000), AUC 0.9967128038406372
ep29_train_time 57.17668128013611
Test Epoch29 layer0 Acc 0.9120065789473685, AUC 0.9795202016830444, avg_entr 0.038006823509931564
ep29_l0_test_time 0.19008374214172363
Test Epoch29 layer1 Acc 0.9105263157894737, AUC 0.9700974822044373, avg_entr 0.014594040811061859
ep29_l1_test_time 0.33054018020629883
Test Epoch29 layer2 Acc 0.906578947368421, AUC 0.9727420806884766, avg_entr 0.009654571302235126
ep29_l2_test_time 0.4718172550201416
Test Epoch29 layer3 Acc 0.9069078947368421, AUC 0.9724082946777344, avg_entr 0.008067122660577297
ep29_l3_test_time 0.6097147464752197
Test Epoch29 layer4 Acc 0.906578947368421, AUC 0.9705958962440491, avg_entr 0.007616275921463966
ep29_l4_test_time 0.7415549755096436
gc 0
Train Epoch30 Acc 0.9738916666666667 (116867/120000), AUC 0.9966679811477661
ep30_train_time 57.134854316711426
Test Epoch30 layer0 Acc 0.9116776315789473, AUC 0.9795184135437012, avg_entr 0.03801584988832474
ep30_l0_test_time 0.18970322608947754
Test Epoch30 layer1 Acc 0.9100328947368421, AUC 0.9702513217926025, avg_entr 0.014492043294012547
ep30_l1_test_time 0.3306114673614502
Test Epoch30 layer2 Acc 0.9069078947368421, AUC 0.9729217290878296, avg_entr 0.009624305181205273
ep30_l2_test_time 0.47107863426208496
Test Epoch30 layer3 Acc 0.9069078947368421, AUC 0.9731869101524353, avg_entr 0.008016579784452915
ep30_l3_test_time 0.6077687740325928
Test Epoch30 layer4 Acc 0.9069078947368421, AUC 0.9707861542701721, avg_entr 0.00757663743570447
ep30_l4_test_time 0.7413091659545898
gc 0
Train Epoch31 Acc 0.9740583333333334 (116887/120000), AUC 0.9967391490936279
ep31_train_time 57.17131066322327
Test Epoch31 layer0 Acc 0.9116776315789473, AUC 0.9795172214508057, avg_entr 0.03793147951364517
ep31_l0_test_time 0.18997931480407715
Test Epoch31 layer1 Acc 0.9098684210526315, AUC 0.9700033068656921, avg_entr 0.01456187292933464
ep31_l1_test_time 0.3296506404876709
Test Epoch31 layer2 Acc 0.9064144736842106, AUC 0.9727323055267334, avg_entr 0.009772866033017635
ep31_l2_test_time 0.47112464904785156
Test Epoch31 layer3 Acc 0.9069078947368421, AUC 0.9726424813270569, avg_entr 0.00816779863089323
ep31_l3_test_time 0.6094732284545898
Test Epoch31 layer4 Acc 0.9070723684210527, AUC 0.9702186584472656, avg_entr 0.007587789092212915
ep31_l4_test_time 0.7405998706817627
gc 0
Train Epoch32 Acc 0.9739166666666667 (116870/120000), AUC 0.9967178106307983
ep32_train_time 57.11992430686951
Test Epoch32 layer0 Acc 0.9125, AUC 0.9795308113098145, avg_entr 0.03774948790669441
ep32_l0_test_time 0.19167590141296387
Test Epoch32 layer1 Acc 0.9100328947368421, AUC 0.9701694250106812, avg_entr 0.014446858316659927
ep32_l1_test_time 0.3299436569213867
Test Epoch32 layer2 Acc 0.906578947368421, AUC 0.9729629755020142, avg_entr 0.009668920189142227
ep32_l2_test_time 0.47103261947631836
Test Epoch32 layer3 Acc 0.90625, AUC 0.9731879234313965, avg_entr 0.008019817993044853
ep32_l3_test_time 0.6081032752990723
Test Epoch32 layer4 Acc 0.9067434210526316, AUC 0.9709950685501099, avg_entr 0.007539077661931515
ep32_l4_test_time 0.741013765335083
gc 0
Train Epoch33 Acc 0.974025 (116883/120000), AUC 0.9967138171195984
ep33_train_time 57.212464570999146
Test Epoch33 layer0 Acc 0.9115131578947369, AUC 0.979517936706543, avg_entr 0.037817370146512985
ep33_l0_test_time 0.18926382064819336
Test Epoch33 layer1 Acc 0.9097039473684211, AUC 0.9699897170066833, avg_entr 0.014477873221039772
ep33_l1_test_time 0.33113598823547363
Test Epoch33 layer2 Acc 0.90625, AUC 0.9727346301078796, avg_entr 0.009637818671762943
ep33_l2_test_time 0.47222113609313965
Test Epoch33 layer3 Acc 0.906578947368421, AUC 0.9728108644485474, avg_entr 0.007992549799382687
ep33_l3_test_time 0.6099348068237305
Test Epoch33 layer4 Acc 0.9067434210526316, AUC 0.9705921411514282, avg_entr 0.007509509101510048
ep33_l4_test_time 0.7415816783905029
gc 0
Train Epoch34 Acc 0.9742583333333333 (116911/120000), AUC 0.9966723918914795
ep34_train_time 57.11137771606445
Test Epoch34 layer0 Acc 0.9118421052631579, AUC 0.979516863822937, avg_entr 0.03774823248386383
ep34_l0_test_time 0.18909335136413574
Test Epoch34 layer1 Acc 0.9095394736842105, AUC 0.9700430631637573, avg_entr 0.014455491676926613
ep34_l1_test_time 0.3297605514526367
Test Epoch34 layer2 Acc 0.906578947368421, AUC 0.972752571105957, avg_entr 0.009748199954628944
ep34_l2_test_time 0.47060441970825195
Test Epoch34 layer3 Acc 0.90625, AUC 0.9730088710784912, avg_entr 0.00810442864894867
ep34_l3_test_time 0.6075689792633057
Test Epoch34 layer4 Acc 0.9067434210526316, AUC 0.970720648765564, avg_entr 0.0075502535328269005
ep34_l4_test_time 0.7415726184844971
gc 0
Train Epoch35 Acc 0.9741833333333333 (116902/120000), AUC 0.9967106580734253
ep35_train_time 57.16050934791565
Test Epoch35 layer0 Acc 0.9123355263157895, AUC 0.9795151948928833, avg_entr 0.03764905035495758
ep35_l0_test_time 0.18925738334655762
Test Epoch35 layer1 Acc 0.9095394736842105, AUC 0.9700548648834229, avg_entr 0.014463959261775017
ep35_l1_test_time 0.3300926685333252
Test Epoch35 layer2 Acc 0.90625, AUC 0.9727473258972168, avg_entr 0.009625316597521305
ep35_l2_test_time 0.47151851654052734
Test Epoch35 layer3 Acc 0.9067434210526316, AUC 0.9726336598396301, avg_entr 0.007978912442922592
ep35_l3_test_time 0.6109025478363037
Test Epoch35 layer4 Acc 0.9067434210526316, AUC 0.9703331589698792, avg_entr 0.0074892910197377205
ep35_l4_test_time 0.7422788143157959
gc 0
Train Epoch36 Acc 0.97435 (116922/120000), AUC 0.9968433380126953
ep36_train_time 57.11636400222778
Test Epoch36 layer0 Acc 0.9121710526315789, AUC 0.9795136451721191, avg_entr 0.03760075941681862
ep36_l0_test_time 0.18986201286315918
Test Epoch36 layer1 Acc 0.909375, AUC 0.9700557589530945, avg_entr 0.014430771581828594
ep36_l1_test_time 0.330153226852417
Test Epoch36 layer2 Acc 0.90625, AUC 0.9726444482803345, avg_entr 0.009607549756765366
ep36_l2_test_time 0.47069430351257324
Test Epoch36 layer3 Acc 0.9064144736842106, AUC 0.9726479649543762, avg_entr 0.007949447259306908
ep36_l3_test_time 0.6077420711517334
Test Epoch36 layer4 Acc 0.9067434210526316, AUC 0.9704548120498657, avg_entr 0.007487392518669367
ep36_l4_test_time 0.7406163215637207
gc 0
Train Epoch37 Acc 0.9743083333333333 (116917/120000), AUC 0.9968371391296387
ep37_train_time 57.18992614746094
Test Epoch37 layer0 Acc 0.9120065789473685, AUC 0.9795126914978027, avg_entr 0.0376163013279438
ep37_l0_test_time 0.1895158290863037
Test Epoch37 layer1 Acc 0.9101973684210526, AUC 0.9699697494506836, avg_entr 0.014506560750305653
ep37_l1_test_time 0.32996654510498047
Test Epoch37 layer2 Acc 0.906578947368421, AUC 0.9727230072021484, avg_entr 0.009584556333720684
ep37_l2_test_time 0.4702022075653076
Test Epoch37 layer3 Acc 0.9067434210526316, AUC 0.9726345539093018, avg_entr 0.007952360436320305
ep37_l3_test_time 0.608600378036499
Test Epoch37 layer4 Acc 0.906578947368421, AUC 0.9705765247344971, avg_entr 0.0074734617955982685
ep37_l4_test_time 0.7398490905761719
gc 0
Train Epoch38 Acc 0.974125 (116895/120000), AUC 0.9967122673988342
ep38_train_time 57.15450191497803
Test Epoch38 layer0 Acc 0.9121710526315789, AUC 0.979511559009552, avg_entr 0.03758292272686958
ep38_l0_test_time 0.19397997856140137
Test Epoch38 layer1 Acc 0.9097039473684211, AUC 0.9700102806091309, avg_entr 0.014478740282356739
ep38_l1_test_time 0.33087158203125
Test Epoch38 layer2 Acc 0.906578947368421, AUC 0.9726830720901489, avg_entr 0.009585322812199593
ep38_l2_test_time 0.47115492820739746
Test Epoch38 layer3 Acc 0.9067434210526316, AUC 0.9726320505142212, avg_entr 0.007941673509776592
ep38_l3_test_time 0.6088919639587402
Test Epoch38 layer4 Acc 0.906578947368421, AUC 0.9704670310020447, avg_entr 0.007463666144758463
ep38_l4_test_time 0.7404675483703613
gc 0
Train Epoch39 Acc 0.9744 (116928/120000), AUC 0.9967448115348816
ep39_train_time 57.29204058647156
Test Epoch39 layer0 Acc 0.9126644736842106, AUC 0.9795166850090027, avg_entr 0.03755863010883331
ep39_l0_test_time 0.19331598281860352
Test Epoch39 layer1 Acc 0.9097039473684211, AUC 0.970045804977417, avg_entr 0.014474540017545223
ep39_l1_test_time 0.3307976722717285
Test Epoch39 layer2 Acc 0.9064144736842106, AUC 0.9728406667709351, avg_entr 0.009572776965796947
ep39_l2_test_time 0.4714992046356201
Test Epoch39 layer3 Acc 0.9067434210526316, AUC 0.9726258516311646, avg_entr 0.007908971980214119
ep39_l3_test_time 0.6088485717773438
Test Epoch39 layer4 Acc 0.9067434210526316, AUC 0.9704904556274414, avg_entr 0.007418899796903133
ep39_l4_test_time 0.7411131858825684
gc 0
Train Epoch40 Acc 0.9741333333333333 (116896/120000), AUC 0.9967859983444214
ep40_train_time 57.184560775756836
Test Epoch40 layer0 Acc 0.9120065789473685, AUC 0.9795109033584595, avg_entr 0.0375545434653759
ep40_l0_test_time 0.18937015533447266
Test Epoch40 layer1 Acc 0.9098684210526315, AUC 0.9699830412864685, avg_entr 0.014493674971163273
ep40_l1_test_time 0.33068323135375977
Test Epoch40 layer2 Acc 0.9067434210526316, AUC 0.97271329164505, avg_entr 0.009558537974953651
ep40_l2_test_time 0.471024751663208
Test Epoch40 layer3 Acc 0.9067434210526316, AUC 0.9726194739341736, avg_entr 0.00793623086065054
ep40_l3_test_time 0.6076133251190186
Test Epoch40 layer4 Acc 0.906578947368421, AUC 0.9705722332000732, avg_entr 0.0074432622641325
ep40_l4_test_time 0.7411341667175293
gc 0
Train Epoch41 Acc 0.9743583333333333 (116923/120000), AUC 0.996803343296051
ep41_train_time 57.25460386276245
Test Epoch41 layer0 Acc 0.9118421052631579, AUC 0.9795124530792236, avg_entr 0.037584539502859116
ep41_l0_test_time 0.1889972686767578
Test Epoch41 layer1 Acc 0.9095394736842105, AUC 0.9699987173080444, avg_entr 0.014452219009399414
ep41_l1_test_time 0.3298196792602539
Test Epoch41 layer2 Acc 0.9060855263157894, AUC 0.9726485013961792, avg_entr 0.009571163915097713
ep41_l2_test_time 0.4710257053375244
Test Epoch41 layer3 Acc 0.906578947368421, AUC 0.9726249575614929, avg_entr 0.007921542041003704
ep41_l3_test_time 0.6086733341217041
Test Epoch41 layer4 Acc 0.9067434210526316, AUC 0.9704380631446838, avg_entr 0.007435482926666737
ep41_l4_test_time 0.7404260635375977
gc 0
Train Epoch42 Acc 0.9740833333333333 (116890/120000), AUC 0.9967271685600281
ep42_train_time 57.199676513671875
Test Epoch42 layer0 Acc 0.9115131578947369, AUC 0.9795114994049072, avg_entr 0.03760838136076927
ep42_l0_test_time 0.1893625259399414
Test Epoch42 layer1 Acc 0.9095394736842105, AUC 0.9699993133544922, avg_entr 0.014438376761972904
ep42_l1_test_time 0.3295252323150635
Test Epoch42 layer2 Acc 0.90625, AUC 0.9726523756980896, avg_entr 0.009569082409143448
ep42_l2_test_time 0.4728837013244629
Test Epoch42 layer3 Acc 0.9067434210526316, AUC 0.9726738929748535, avg_entr 0.007909956388175488
ep42_l3_test_time 0.6088292598724365
Test Epoch42 layer4 Acc 0.9069078947368421, AUC 0.9704744815826416, avg_entr 0.007426014635711908
ep42_l4_test_time 0.7392830848693848
gc 0
Train Epoch43 Acc 0.9743166666666667 (116918/120000), AUC 0.996745228767395
ep43_train_time 57.17522478103638
Test Epoch43 layer0 Acc 0.9118421052631579, AUC 0.9795105457305908, avg_entr 0.037595171481370926
ep43_l0_test_time 0.18979930877685547
Test Epoch43 layer1 Acc 0.9095394736842105, AUC 0.9699794054031372, avg_entr 0.014448215253651142
ep43_l1_test_time 0.32984185218811035
Test Epoch43 layer2 Acc 0.9060855263157894, AUC 0.9726265668869019, avg_entr 0.00956457294523716
ep43_l2_test_time 0.4721713066101074
Test Epoch43 layer3 Acc 0.906578947368421, AUC 0.9726478457450867, avg_entr 0.007913828827440739
ep43_l3_test_time 0.6088597774505615
Test Epoch43 layer4 Acc 0.9067434210526316, AUC 0.9704611301422119, avg_entr 0.007429624907672405
ep43_l4_test_time 0.7406704425811768
gc 0
Train Epoch44 Acc 0.9742583333333333 (116911/120000), AUC 0.9968264102935791
ep44_train_time 57.23330593109131
Test Epoch44 layer0 Acc 0.9116776315789473, AUC 0.9795095920562744, avg_entr 0.03760909661650658
ep44_l0_test_time 0.18978357315063477
Test Epoch44 layer1 Acc 0.9095394736842105, AUC 0.9699898958206177, avg_entr 0.014447405003011227
ep44_l1_test_time 0.3301832675933838
Test Epoch44 layer2 Acc 0.9060855263157894, AUC 0.9726486802101135, avg_entr 0.009557546116411686
ep44_l2_test_time 0.4714326858520508
Test Epoch44 layer3 Acc 0.906578947368421, AUC 0.972640872001648, avg_entr 0.007908140309154987
ep44_l3_test_time 0.6096494197845459
Test Epoch44 layer4 Acc 0.9067434210526316, AUC 0.9704868793487549, avg_entr 0.007427986245602369
ep44_l4_test_time 0.7413082122802734
gc 0
Train Epoch45 Acc 0.9742833333333333 (116914/120000), AUC 0.9967443943023682
ep45_train_time 57.19871950149536
Test Epoch45 layer0 Acc 0.9118421052631579, AUC 0.9795101881027222, avg_entr 0.03757323697209358
ep45_l0_test_time 0.19399213790893555
Test Epoch45 layer1 Acc 0.9095394736842105, AUC 0.9699969291687012, avg_entr 0.01444062776863575
ep45_l1_test_time 0.3308103084564209
Test Epoch45 layer2 Acc 0.9060855263157894, AUC 0.9726681113243103, avg_entr 0.009555955417454243
ep45_l2_test_time 0.4720947742462158
Test Epoch45 layer3 Acc 0.906578947368421, AUC 0.9726579189300537, avg_entr 0.007905278354883194
ep45_l3_test_time 0.6103520393371582
Test Epoch45 layer4 Acc 0.9067434210526316, AUC 0.9705067873001099, avg_entr 0.0074269431643188
ep45_l4_test_time 0.7411789894104004
gc 0
Train Epoch46 Acc 0.97445 (116934/120000), AUC 0.9967950582504272
ep46_train_time 57.215418338775635
Test Epoch46 layer0 Acc 0.9116776315789473, AUC 0.9795089364051819, avg_entr 0.0375739187002182
ep46_l0_test_time 0.1889019012451172
Test Epoch46 layer1 Acc 0.9095394736842105, AUC 0.9699850082397461, avg_entr 0.014430555514991283
ep46_l1_test_time 0.33022356033325195
Test Epoch46 layer2 Acc 0.9060855263157894, AUC 0.9726560115814209, avg_entr 0.009564308449625969
ep46_l2_test_time 0.47110438346862793
Test Epoch46 layer3 Acc 0.9067434210526316, AUC 0.9726759195327759, avg_entr 0.007911056280136108
ep46_l3_test_time 0.6102151870727539
Test Epoch46 layer4 Acc 0.9069078947368421, AUC 0.9705513715744019, avg_entr 0.007428336888551712
ep46_l4_test_time 0.7411773204803467
gc 0
Train Epoch47 Acc 0.97435 (116922/120000), AUC 0.9968026876449585
ep47_train_time 57.14582681655884
Test Epoch47 layer0 Acc 0.9116776315789473, AUC 0.9795098304748535, avg_entr 0.03758903965353966
ep47_l0_test_time 0.18995070457458496
Test Epoch47 layer1 Acc 0.9095394736842105, AUC 0.9699898958206177, avg_entr 0.014435024000704288
ep47_l1_test_time 0.3303821086883545
Test Epoch47 layer2 Acc 0.9060855263157894, AUC 0.9726632237434387, avg_entr 0.009561390615999699
ep47_l2_test_time 0.4715099334716797
Test Epoch47 layer3 Acc 0.9067434210526316, AUC 0.9726536273956299, avg_entr 0.007909185253083706
ep47_l3_test_time 0.6095321178436279
Test Epoch47 layer4 Acc 0.9067434210526316, AUC 0.9705078601837158, avg_entr 0.007423737086355686
ep47_l4_test_time 0.7410900592803955
gc 0
Train Epoch48 Acc 0.9741916666666667 (116903/120000), AUC 0.9968159198760986
ep48_train_time 57.29555416107178
Test Epoch48 layer0 Acc 0.9116776315789473, AUC 0.9795099496841431, avg_entr 0.03755439072847366
ep48_l0_test_time 0.1892848014831543
Test Epoch48 layer1 Acc 0.9095394736842105, AUC 0.9699936509132385, avg_entr 0.014435878954827785
ep48_l1_test_time 0.3303825855255127
Test Epoch48 layer2 Acc 0.9060855263157894, AUC 0.9726724028587341, avg_entr 0.009550744667649269
ep48_l2_test_time 0.47110962867736816
Test Epoch48 layer3 Acc 0.9067434210526316, AUC 0.9726543426513672, avg_entr 0.007896791212260723
ep48_l3_test_time 0.6097571849822998
Test Epoch48 layer4 Acc 0.9067434210526316, AUC 0.9705172777175903, avg_entr 0.007417517714202404
ep48_l4_test_time 0.740607500076294
gc 0
Train Epoch49 Acc 0.9745416666666666 (116945/120000), AUC 0.9967034459114075
ep49_train_time 57.17959403991699
Test Epoch49 layer0 Acc 0.9118421052631579, AUC 0.9795088768005371, avg_entr 0.03756712004542351
ep49_l0_test_time 0.18925976753234863
Test Epoch49 layer1 Acc 0.9095394736842105, AUC 0.9699932336807251, avg_entr 0.014433755539357662
ep49_l1_test_time 0.3309180736541748
Test Epoch49 layer2 Acc 0.9060855263157894, AUC 0.97267746925354, avg_entr 0.009556030854582787
ep49_l2_test_time 0.4717996120452881
Test Epoch49 layer3 Acc 0.9067434210526316, AUC 0.9726584553718567, avg_entr 0.007901700213551521
ep49_l3_test_time 0.6093060970306396
Test Epoch49 layer4 Acc 0.9067434210526316, AUC 0.970521092414856, avg_entr 0.0074187880381941795
ep49_l4_test_time 0.7417645454406738
Best AUC 0.9825010895729065
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.9256578947368421, AUC 0.9862248301506042, avg_entr 0.09493009001016617
ep49_l0_test_time 0.0482022762298584
Test Epoch49 layer1 Acc 0.9276315789473685, AUC 0.9849992990493774, avg_entr 0.03334469348192215
ep49_l1_test_time 0.08307433128356934
Test Epoch49 layer2 Acc 0.9302631578947368, AUC 0.9866106510162354, avg_entr 0.02708735130727291
ep49_l2_test_time 0.11780691146850586
Test Epoch49 layer3 Acc 0.9289473684210526, AUC 0.9858497977256775, avg_entr 0.02424779161810875
ep49_l3_test_time 0.15375733375549316
Test Epoch49 layer4 Acc 0.9282894736842106, AUC 0.9866602420806885, avg_entr 0.0231146402657032
ep49_l4_test_time 0.18615055084228516
