total count words 102019
vocab size 30000
found 26754 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13672292
Start Training
gc 0
Train Epoch0 Acc 0.618375 (74205/120000), AUC 0.8552089929580688
ep0_train_time 41.828513860702515
Test Epoch0 layer0 Acc 0.9070723684210527, AUC 0.9763696193695068, avg_entr 0.23161210119724274
ep0_l0_test_time 0.1941664218902588
Save ckpt to ckpt/ag_news_transformeral_l5_pad75//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.906578947368421, AUC 0.9774708151817322, avg_entr 0.16454347968101501
ep0_l1_test_time 0.33405113220214844
Save ckpt to ckpt/ag_news_transformeral_l5_pad75//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.9042763157894737, AUC 0.9769824147224426, avg_entr 0.16513648629188538
ep0_l2_test_time 0.3303196430206299
Test Epoch0 layer3 Acc 0.9029605263157895, AUC 0.9771162271499634, avg_entr 0.16295357048511505
ep0_l3_test_time 0.533026933670044
Test Epoch0 layer4 Acc 0.9009868421052631, AUC 0.9765397906303406, avg_entr 0.1677219718694687
ep0_l4_test_time 0.6175339221954346
gc 0
Train Epoch1 Acc 0.9248333333333333 (110980/120000), AUC 0.982609748840332
ep1_train_time 40.411499977111816
Test Epoch1 layer0 Acc 0.9157894736842105, AUC 0.9797288179397583, avg_entr 0.13740362226963043
ep1_l0_test_time 0.20788335800170898
Save ckpt to ckpt/ag_news_transformeral_l5_pad75//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.9180921052631579, AUC 0.9815751314163208, avg_entr 0.08398072421550751
ep1_l1_test_time 0.28113293647766113
Save ckpt to ckpt/ag_news_transformeral_l5_pad75//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.9190789473684211, AUC 0.9813871383666992, avg_entr 0.06947468966245651
ep1_l2_test_time 0.36960363388061523
Test Epoch1 layer3 Acc 0.9192434210526316, AUC 0.9814339280128479, avg_entr 0.05844983085989952
ep1_l3_test_time 0.4511451721191406
Test Epoch1 layer4 Acc 0.9194078947368421, AUC 0.9815940260887146, avg_entr 0.05654735490679741
ep1_l4_test_time 0.532867431640625
Save ckpt to ckpt/ag_news_transformeral_l5_pad75//ag_news_transformeral_l5.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.9378916666666667 (112547/120000), AUC 0.9875197410583496
ep2_train_time 40.312161684036255
Test Epoch2 layer0 Acc 0.9144736842105263, AUC 0.9803737998008728, avg_entr 0.10802427679300308
ep2_l0_test_time 0.18300676345825195
Test Epoch2 layer1 Acc 0.9172697368421052, AUC 0.9809088110923767, avg_entr 0.04559499770402908
ep2_l1_test_time 0.274336576461792
Test Epoch2 layer2 Acc 0.9169407894736842, AUC 0.9799675941467285, avg_entr 0.03823528066277504
ep2_l2_test_time 0.36812281608581543
Test Epoch2 layer3 Acc 0.9177631578947368, AUC 0.9795072674751282, avg_entr 0.03347380459308624
ep2_l3_test_time 0.45572757720947266
Test Epoch2 layer4 Acc 0.9175986842105263, AUC 0.9796146154403687, avg_entr 0.031415075063705444
ep2_l4_test_time 0.5461220741271973
gc 0
Train Epoch3 Acc 0.9460416666666667 (113525/120000), AUC 0.9895744323730469
ep3_train_time 40.965872049331665
Test Epoch3 layer0 Acc 0.9149671052631579, AUC 0.9805277585983276, avg_entr 0.09394575655460358
ep3_l0_test_time 0.1815652847290039
Test Epoch3 layer1 Acc 0.9171052631578948, AUC 0.9802206158638, avg_entr 0.03477172553539276
ep3_l1_test_time 0.27351951599121094
Test Epoch3 layer2 Acc 0.9157894736842105, AUC 0.9815126657485962, avg_entr 0.029514649882912636
ep3_l2_test_time 0.3629608154296875
Test Epoch3 layer3 Acc 0.9151315789473684, AUC 0.9818931818008423, avg_entr 0.025700563564896584
ep3_l3_test_time 0.4637136459350586
Save ckpt to ckpt/ag_news_transformeral_l5_pad75//ag_news_transformeral_l5.pt  ,ep 3
Test Epoch3 layer4 Acc 0.9149671052631579, AUC 0.9823310375213623, avg_entr 0.024603407829999924
ep3_l4_test_time 0.563058614730835
Save ckpt to ckpt/ag_news_transformeral_l5_pad75//ag_news_transformeral_l5.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.9509416666666667 (114113/120000), AUC 0.9908896684646606
ep4_train_time 41.33866596221924
Test Epoch4 layer0 Acc 0.9126644736842106, AUC 0.9802513718605042, avg_entr 0.08388010412454605
ep4_l0_test_time 0.26506972312927246
Test Epoch4 layer1 Acc 0.9161184210526315, AUC 0.9785057306289673, avg_entr 0.03093264251947403
ep4_l1_test_time 0.3530442714691162
Test Epoch4 layer2 Acc 0.9159539473684211, AUC 0.9808348417282104, avg_entr 0.025083180516958237
ep4_l2_test_time 0.4359579086303711
Test Epoch4 layer3 Acc 0.9167763157894737, AUC 0.981929361820221, avg_entr 0.022229880094528198
ep4_l3_test_time 0.5233218669891357
Test Epoch4 layer4 Acc 0.9154605263157894, AUC 0.9823048710823059, avg_entr 0.021199673414230347
ep4_l4_test_time 0.5112714767456055
gc 0
Train Epoch5 Acc 0.9551166666666666 (114614/120000), AUC 0.991866946220398
ep5_train_time 40.77329444885254
Test Epoch5 layer0 Acc 0.9138157894736842, AUC 0.9801990985870361, avg_entr 0.07347510755062103
ep5_l0_test_time 0.2716231346130371
Test Epoch5 layer1 Acc 0.9139802631578947, AUC 0.976299524307251, avg_entr 0.027407679706811905
ep5_l1_test_time 0.25072360038757324
Test Epoch5 layer2 Acc 0.9139802631578947, AUC 0.9769190549850464, avg_entr 0.02191336266696453
ep5_l2_test_time 0.3527648448944092
Test Epoch5 layer3 Acc 0.9139802631578947, AUC 0.9772543907165527, avg_entr 0.018946899101138115
ep5_l3_test_time 0.5226175785064697
Test Epoch5 layer4 Acc 0.9136513157894737, AUC 0.9775916337966919, avg_entr 0.0175155159085989
ep5_l4_test_time 0.6083920001983643
gc 0
Train Epoch6 Acc 0.9581 (114972/120000), AUC 0.992887020111084
ep6_train_time 40.060336112976074
Test Epoch6 layer0 Acc 0.9146381578947368, AUC 0.9799909591674805, avg_entr 0.06861403584480286
ep6_l0_test_time 0.1796882152557373
Test Epoch6 layer1 Acc 0.9123355263157895, AUC 0.9766045808792114, avg_entr 0.026077445596456528
ep6_l1_test_time 0.27022314071655273
Test Epoch6 layer2 Acc 0.9125, AUC 0.9761662483215332, avg_entr 0.02044430561363697
ep6_l2_test_time 0.36179518699645996
Test Epoch6 layer3 Acc 0.9125, AUC 0.9764354228973389, avg_entr 0.018263109028339386
ep6_l3_test_time 0.4411003589630127
Test Epoch6 layer4 Acc 0.9116776315789473, AUC 0.9759641885757446, avg_entr 0.017433833330869675
ep6_l4_test_time 0.5475428104400635
gc 0
Train Epoch7 Acc 0.9601333333333333 (115216/120000), AUC 0.9934177994728088
ep7_train_time 39.90493631362915
Test Epoch7 layer0 Acc 0.9095394736842105, AUC 0.9796573519706726, avg_entr 0.06716441363096237
ep7_l0_test_time 0.18323111534118652
Test Epoch7 layer1 Acc 0.9126644736842106, AUC 0.9748127460479736, avg_entr 0.023314788937568665
ep7_l1_test_time 0.27457547187805176
Test Epoch7 layer2 Acc 0.9111842105263158, AUC 0.9754001498222351, avg_entr 0.018762003630399704
ep7_l2_test_time 0.36542248725891113
Test Epoch7 layer3 Acc 0.9120065789473685, AUC 0.9761068224906921, avg_entr 0.01722382940351963
ep7_l3_test_time 0.45772385597229004
Test Epoch7 layer4 Acc 0.9108552631578948, AUC 0.9764292240142822, avg_entr 0.01665109023451805
ep7_l4_test_time 0.5994558334350586
gc 0
Train Epoch8 Acc 0.9635083333333333 (115621/120000), AUC 0.9944522380828857
ep8_train_time 40.859912633895874
Test Epoch8 layer0 Acc 0.9115131578947369, AUC 0.9797425866127014, avg_entr 0.06285613030195236
ep8_l0_test_time 0.18088865280151367
Test Epoch8 layer1 Acc 0.9100328947368421, AUC 0.9745817184448242, avg_entr 0.02254399284720421
ep8_l1_test_time 0.2730708122253418
Test Epoch8 layer2 Acc 0.9088815789473684, AUC 0.9753849506378174, avg_entr 0.016491346061229706
ep8_l2_test_time 0.36067819595336914
Test Epoch8 layer3 Acc 0.9087171052631579, AUC 0.97748863697052, avg_entr 0.014557020738720894
ep8_l3_test_time 0.5306177139282227
Test Epoch8 layer4 Acc 0.9090460526315789, AUC 0.9790181517601013, avg_entr 0.013807560317218304
ep8_l4_test_time 0.6183257102966309
gc 0
Train Epoch9 Acc 0.9647916666666667 (115775/120000), AUC 0.9947757124900818
ep9_train_time 40.89189124107361
Test Epoch9 layer0 Acc 0.9126644736842106, AUC 0.9796469807624817, avg_entr 0.05943753942847252
ep9_l0_test_time 0.17889809608459473
Test Epoch9 layer1 Acc 0.9123355263157895, AUC 0.9731927514076233, avg_entr 0.020912358537316322
ep9_l1_test_time 0.26473522186279297
Test Epoch9 layer2 Acc 0.9111842105263158, AUC 0.9741564989089966, avg_entr 0.014749288558959961
ep9_l2_test_time 0.3619670867919922
Test Epoch9 layer3 Acc 0.9113486842105263, AUC 0.9756501913070679, avg_entr 0.013146322220563889
ep9_l3_test_time 0.44951415061950684
Test Epoch9 layer4 Acc 0.9118421052631579, AUC 0.9762148261070251, avg_entr 0.012044780887663364
ep9_l4_test_time 0.5405819416046143
gc 0
Train Epoch10 Acc 0.966375 (115965/120000), AUC 0.9951575994491577
ep10_train_time 40.482426404953
Test Epoch10 layer0 Acc 0.9108552631578948, AUC 0.979503870010376, avg_entr 0.057275138795375824
ep10_l0_test_time 0.17503142356872559
Test Epoch10 layer1 Acc 0.9105263157894737, AUC 0.9730675220489502, avg_entr 0.02109033241868019
ep10_l1_test_time 0.26660990715026855
Test Epoch10 layer2 Acc 0.9080592105263158, AUC 0.9726822376251221, avg_entr 0.015740584582090378
ep10_l2_test_time 0.3549046516418457
Test Epoch10 layer3 Acc 0.9083881578947368, AUC 0.9744746685028076, avg_entr 0.013404055498540401
ep10_l3_test_time 0.44879961013793945
Test Epoch10 layer4 Acc 0.9080592105263158, AUC 0.9748921394348145, avg_entr 0.01212974451482296
ep10_l4_test_time 0.5274217128753662
gc 0
Train Epoch11 Acc 0.9672583333333333 (116071/120000), AUC 0.9951961040496826
ep11_train_time 40.10308027267456
Test Epoch11 layer0 Acc 0.9133223684210526, AUC 0.9794033169746399, avg_entr 0.05514911189675331
ep11_l0_test_time 0.1806190013885498
Test Epoch11 layer1 Acc 0.9116776315789473, AUC 0.972476065158844, avg_entr 0.019694095477461815
ep11_l1_test_time 0.2742338180541992
Test Epoch11 layer2 Acc 0.9106907894736842, AUC 0.9711940884590149, avg_entr 0.01379154622554779
ep11_l2_test_time 0.4198629856109619
Test Epoch11 layer3 Acc 0.9105263157894737, AUC 0.9706277251243591, avg_entr 0.012198560871183872
ep11_l3_test_time 0.45490288734436035
Test Epoch11 layer4 Acc 0.9101973684210526, AUC 0.971217155456543, avg_entr 0.011219212785363197
ep11_l4_test_time 0.5446348190307617
gc 0
Train Epoch12 Acc 0.9687083333333333 (116245/120000), AUC 0.9956626892089844
ep12_train_time 40.69638514518738
Test Epoch12 layer0 Acc 0.9111842105263158, AUC 0.9792308807373047, avg_entr 0.05329028144478798
ep12_l0_test_time 0.26616477966308594
Test Epoch12 layer1 Acc 0.9110197368421052, AUC 0.9725353717803955, avg_entr 0.018917804583907127
ep12_l1_test_time 0.27489638328552246
Test Epoch12 layer2 Acc 0.9097039473684211, AUC 0.972265362739563, avg_entr 0.012864643707871437
ep12_l2_test_time 0.392925500869751
Test Epoch12 layer3 Acc 0.909375, AUC 0.9718965291976929, avg_entr 0.010832952335476875
ep12_l3_test_time 0.46996569633483887
Test Epoch12 layer4 Acc 0.9097039473684211, AUC 0.973469614982605, avg_entr 0.010085836052894592
ep12_l4_test_time 0.5589139461517334
gc 0
Train Epoch13 Acc 0.9693833333333334 (116326/120000), AUC 0.9958361983299255
ep13_train_time 40.53305745124817
Test Epoch13 layer0 Acc 0.9111842105263158, AUC 0.979159414768219, avg_entr 0.05177801102399826
ep13_l0_test_time 0.1796588897705078
Test Epoch13 layer1 Acc 0.9105263157894737, AUC 0.9715871810913086, avg_entr 0.01858917437493801
ep13_l1_test_time 0.27222609519958496
Test Epoch13 layer2 Acc 0.909375, AUC 0.970483660697937, avg_entr 0.013278242200613022
ep13_l2_test_time 0.4267411231994629
Test Epoch13 layer3 Acc 0.9085526315789474, AUC 0.9705005884170532, avg_entr 0.011459183879196644
ep13_l3_test_time 0.5289750099182129
Test Epoch13 layer4 Acc 0.9085526315789474, AUC 0.9715145826339722, avg_entr 0.010531602427363396
ep13_l4_test_time 0.6188418865203857
gc 0
Train Epoch14 Acc 0.9701416666666667 (116417/120000), AUC 0.995865523815155
ep14_train_time 40.22178244590759
Test Epoch14 layer0 Acc 0.9097039473684211, AUC 0.9791105389595032, avg_entr 0.05111363157629967
ep14_l0_test_time 0.1832120418548584
Test Epoch14 layer1 Acc 0.9088815789473684, AUC 0.9717723727226257, avg_entr 0.018299255520105362
ep14_l1_test_time 0.27518415451049805
Test Epoch14 layer2 Acc 0.9077302631578947, AUC 0.9723554849624634, avg_entr 0.013498899526894093
ep14_l2_test_time 0.36716532707214355
Test Epoch14 layer3 Acc 0.9067434210526316, AUC 0.9745528697967529, avg_entr 0.011743136681616306
ep14_l3_test_time 0.4562525749206543
Test Epoch14 layer4 Acc 0.90625, AUC 0.974675178527832, avg_entr 0.010807705111801624
ep14_l4_test_time 0.5436153411865234
gc 0
Train Epoch15 Acc 0.970625 (116475/120000), AUC 0.995999813079834
ep15_train_time 41.67812919616699
Test Epoch15 layer0 Acc 0.9105263157894737, AUC 0.9790681600570679, avg_entr 0.04827912896871567
ep15_l0_test_time 0.20339393615722656
Test Epoch15 layer1 Acc 0.909375, AUC 0.9712702631950378, avg_entr 0.01766902208328247
ep15_l1_test_time 0.29329419136047363
Test Epoch15 layer2 Acc 0.9078947368421053, AUC 0.9694851040840149, avg_entr 0.012587804347276688
ep15_l2_test_time 0.3857254981994629
Test Epoch15 layer3 Acc 0.9077302631578947, AUC 0.969035267829895, avg_entr 0.010744011029601097
ep15_l3_test_time 0.4740753173828125
Test Epoch15 layer4 Acc 0.9087171052631579, AUC 0.9713013172149658, avg_entr 0.009843425825238228
ep15_l4_test_time 0.5757088661193848
gc 0
Train Epoch16 Acc 0.9713833333333334 (116566/120000), AUC 0.9962803721427917
ep16_train_time 40.39263963699341
Test Epoch16 layer0 Acc 0.9105263157894737, AUC 0.9790534377098083, avg_entr 0.04747476428747177
ep16_l0_test_time 0.1838550567626953
Test Epoch16 layer1 Acc 0.9087171052631579, AUC 0.9721360802650452, avg_entr 0.017256081104278564
ep16_l1_test_time 0.27502870559692383
Test Epoch16 layer2 Acc 0.9083881578947368, AUC 0.9724171161651611, avg_entr 0.012406129390001297
ep16_l2_test_time 0.36721301078796387
Test Epoch16 layer3 Acc 0.9078947368421053, AUC 0.9733988642692566, avg_entr 0.01089970301836729
ep16_l3_test_time 0.45708370208740234
Test Epoch16 layer4 Acc 0.9075657894736842, AUC 0.9746471643447876, avg_entr 0.010143421590328217
ep16_l4_test_time 0.545316219329834
gc 0
Train Epoch17 Acc 0.9715083333333333 (116581/120000), AUC 0.9963135719299316
ep17_train_time 40.69762063026428
Test Epoch17 layer0 Acc 0.9103618421052632, AUC 0.9789981245994568, avg_entr 0.04636745899915695
ep17_l0_test_time 0.17249369621276855
Test Epoch17 layer1 Acc 0.909375, AUC 0.970822274684906, avg_entr 0.01702841743826866
ep17_l1_test_time 0.26762962341308594
Test Epoch17 layer2 Acc 0.9082236842105263, AUC 0.9696856737136841, avg_entr 0.012274976819753647
ep17_l2_test_time 0.35915088653564453
Test Epoch17 layer3 Acc 0.9075657894736842, AUC 0.9705357551574707, avg_entr 0.010672851465642452
ep17_l3_test_time 0.44643402099609375
Test Epoch17 layer4 Acc 0.9074013157894737, AUC 0.9714751243591309, avg_entr 0.009854041039943695
ep17_l4_test_time 0.5383949279785156
gc 0
Train Epoch18 Acc 0.9718666666666667 (116624/120000), AUC 0.9962730407714844
ep18_train_time 40.899978160858154
Test Epoch18 layer0 Acc 0.9101973684210526, AUC 0.9790122509002686, avg_entr 0.044993333518505096
ep18_l0_test_time 0.1733074188232422
Test Epoch18 layer1 Acc 0.9090460526315789, AUC 0.9705187082290649, avg_entr 0.016451042145490646
ep18_l1_test_time 0.26839327812194824
Test Epoch18 layer2 Acc 0.9072368421052631, AUC 0.9699676036834717, avg_entr 0.011716731823980808
ep18_l2_test_time 0.358384370803833
Test Epoch18 layer3 Acc 0.9069078947368421, AUC 0.9705755114555359, avg_entr 0.01024116575717926
ep18_l3_test_time 0.4704127311706543
Test Epoch18 layer4 Acc 0.9064144736842106, AUC 0.971511721611023, avg_entr 0.009438486769795418
ep18_l4_test_time 0.618675947189331
gc 0
Train Epoch19 Acc 0.9721666666666666 (116660/120000), AUC 0.9963852763175964
ep19_train_time 41.24422788619995
Test Epoch19 layer0 Acc 0.9100328947368421, AUC 0.978994607925415, avg_entr 0.043438199907541275
ep19_l0_test_time 0.16936826705932617
Test Epoch19 layer1 Acc 0.9090460526315789, AUC 0.9704161286354065, avg_entr 0.016331011429429054
ep19_l1_test_time 0.25885772705078125
Test Epoch19 layer2 Acc 0.9069078947368421, AUC 0.9693734645843506, avg_entr 0.012085593305528164
ep19_l2_test_time 0.3500382900238037
Test Epoch19 layer3 Acc 0.9067434210526316, AUC 0.9690638780593872, avg_entr 0.010141939856112003
ep19_l3_test_time 0.43796706199645996
Test Epoch19 layer4 Acc 0.9067434210526316, AUC 0.9709503054618835, avg_entr 0.009171996265649796
ep19_l4_test_time 0.5031836032867432
gc 0
Train Epoch20 Acc 0.9725 (116700/120000), AUC 0.9965025186538696
ep20_train_time 40.55911207199097
Test Epoch20 layer0 Acc 0.9103618421052632, AUC 0.9790095090866089, avg_entr 0.04267570748925209
ep20_l0_test_time 0.18321967124938965
Test Epoch20 layer1 Acc 0.9087171052631579, AUC 0.9703062772750854, avg_entr 0.01592533476650715
ep20_l1_test_time 0.27352428436279297
Test Epoch20 layer2 Acc 0.9069078947368421, AUC 0.9688650369644165, avg_entr 0.011350705288350582
ep20_l2_test_time 0.3669266700744629
Test Epoch20 layer3 Acc 0.9067434210526316, AUC 0.9678529500961304, avg_entr 0.00979589018970728
ep20_l3_test_time 0.4570155143737793
Test Epoch20 layer4 Acc 0.9064144736842106, AUC 0.9689576029777527, avg_entr 0.008996197022497654
ep20_l4_test_time 0.5454294681549072
gc 0
Train Epoch21 Acc 0.9727333333333333 (116728/120000), AUC 0.9965401887893677
ep21_train_time 40.091249227523804
Test Epoch21 layer0 Acc 0.9106907894736842, AUC 0.9790290594100952, avg_entr 0.04147682338953018
ep21_l0_test_time 0.2712857723236084
Test Epoch21 layer1 Acc 0.9082236842105263, AUC 0.9704898595809937, avg_entr 0.015652164816856384
ep21_l1_test_time 0.30695676803588867
Test Epoch21 layer2 Acc 0.90625, AUC 0.9681947827339172, avg_entr 0.011104796081781387
ep21_l2_test_time 0.36606359481811523
Test Epoch21 layer3 Acc 0.905921052631579, AUC 0.9663662910461426, avg_entr 0.009553944692015648
ep21_l3_test_time 0.45447325706481934
Test Epoch21 layer4 Acc 0.90625, AUC 0.9680181741714478, avg_entr 0.00873146764934063
ep21_l4_test_time 0.5446491241455078
gc 0
Train Epoch22 Acc 0.9728666666666667 (116744/120000), AUC 0.9965565800666809
ep22_train_time 39.8226752281189
Test Epoch22 layer0 Acc 0.9101973684210526, AUC 0.97901850938797, avg_entr 0.0406905896961689
ep22_l0_test_time 0.17791056632995605
Test Epoch22 layer1 Acc 0.9088815789473684, AUC 0.9705148339271545, avg_entr 0.015382588841021061
ep22_l1_test_time 0.2748439311981201
Test Epoch22 layer2 Acc 0.9067434210526316, AUC 0.968703031539917, avg_entr 0.010930205695331097
ep22_l2_test_time 0.383730411529541
Test Epoch22 layer3 Acc 0.906578947368421, AUC 0.9673192501068115, avg_entr 0.009305489249527454
ep22_l3_test_time 0.47553133964538574
Test Epoch22 layer4 Acc 0.906578947368421, AUC 0.968565046787262, avg_entr 0.008563396520912647
ep22_l4_test_time 0.5504570007324219
gc 0
Train Epoch23 Acc 0.973075 (116769/120000), AUC 0.9964401125907898
ep23_train_time 42.17217493057251
Test Epoch23 layer0 Acc 0.9108552631578948, AUC 0.9790298938751221, avg_entr 0.039913736283779144
ep23_l0_test_time 0.2671952247619629
Test Epoch23 layer1 Acc 0.9085526315789474, AUC 0.9703191518783569, avg_entr 0.015258867293596268
ep23_l1_test_time 0.349137544631958
Test Epoch23 layer2 Acc 0.9067434210526316, AUC 0.9689735770225525, avg_entr 0.010893587954342365
ep23_l2_test_time 0.4278242588043213
Test Epoch23 layer3 Acc 0.90625, AUC 0.9681987762451172, avg_entr 0.009245416149497032
ep23_l3_test_time 0.5158941745758057
Test Epoch23 layer4 Acc 0.90625, AUC 0.9700344800949097, avg_entr 0.008466491475701332
ep23_l4_test_time 0.608220100402832
gc 0
Train Epoch24 Acc 0.9735583333333333 (116827/120000), AUC 0.9966220855712891
ep24_train_time 41.21148943901062
Test Epoch24 layer0 Acc 0.9105263157894737, AUC 0.9790340065956116, avg_entr 0.03979557007551193
ep24_l0_test_time 0.1799154281616211
Test Epoch24 layer1 Acc 0.9085526315789474, AUC 0.9703019857406616, avg_entr 0.015180094167590141
ep24_l1_test_time 0.2720048427581787
Test Epoch24 layer2 Acc 0.9060855263157894, AUC 0.968393087387085, avg_entr 0.010867049917578697
ep24_l2_test_time 0.3635215759277344
Test Epoch24 layer3 Acc 0.9055921052631579, AUC 0.9668717384338379, avg_entr 0.00915632676333189
ep24_l3_test_time 0.4527275562286377
Test Epoch24 layer4 Acc 0.9055921052631579, AUC 0.968386709690094, avg_entr 0.008381121791899204
ep24_l4_test_time 0.5412342548370361
gc 0
Train Epoch25 Acc 0.973525 (116823/120000), AUC 0.9966479539871216
ep25_train_time 40.71716904640198
Test Epoch25 layer0 Acc 0.9110197368421052, AUC 0.9790457487106323, avg_entr 0.03942481055855751
ep25_l0_test_time 0.17797207832336426
Test Epoch25 layer1 Acc 0.9078947368421053, AUC 0.970197319984436, avg_entr 0.01487767044454813
ep25_l1_test_time 0.27442145347595215
Test Epoch25 layer2 Acc 0.9052631578947369, AUC 0.9680885076522827, avg_entr 0.010251057334244251
ep25_l2_test_time 0.3635866641998291
Test Epoch25 layer3 Acc 0.9055921052631579, AUC 0.9669613242149353, avg_entr 0.008654782548546791
ep25_l3_test_time 0.4547255039215088
Test Epoch25 layer4 Acc 0.9054276315789473, AUC 0.967686116695404, avg_entr 0.00790052767843008
ep25_l4_test_time 0.5457170009613037
gc 0
Train Epoch26 Acc 0.9736583333333333 (116839/120000), AUC 0.996617317199707
ep26_train_time 41.25515103340149
Test Epoch26 layer0 Acc 0.9103618421052632, AUC 0.9790218472480774, avg_entr 0.03914126753807068
ep26_l0_test_time 0.16802120208740234
Test Epoch26 layer1 Acc 0.9082236842105263, AUC 0.9701888561248779, avg_entr 0.01476934552192688
ep26_l1_test_time 0.2595953941345215
Test Epoch26 layer2 Acc 0.90625, AUC 0.9684878587722778, avg_entr 0.01022801548242569
ep26_l2_test_time 0.3504312038421631
Test Epoch26 layer3 Acc 0.90625, AUC 0.9675767421722412, avg_entr 0.008643114008009434
ep26_l3_test_time 0.4402158260345459
Test Epoch26 layer4 Acc 0.905921052631579, AUC 0.9678323864936829, avg_entr 0.007887233980000019
ep26_l4_test_time 0.52913498878479
gc 0
Train Epoch27 Acc 0.9735 (116820/120000), AUC 0.9966808557510376
ep27_train_time 40.177002906799316
Test Epoch27 layer0 Acc 0.9098684210526315, AUC 0.979010283946991, avg_entr 0.03910987451672554
ep27_l0_test_time 0.2651233673095703
Test Epoch27 layer1 Acc 0.9090460526315789, AUC 0.9701773524284363, avg_entr 0.014998283237218857
ep27_l1_test_time 0.3547229766845703
Test Epoch27 layer2 Acc 0.9057565789473684, AUC 0.9685410261154175, avg_entr 0.010779987089335918
ep27_l2_test_time 0.4412393569946289
Test Epoch27 layer3 Acc 0.9055921052631579, AUC 0.9667978286743164, avg_entr 0.009057087823748589
ep27_l3_test_time 0.5317530632019043
Test Epoch27 layer4 Acc 0.905921052631579, AUC 0.9683014154434204, avg_entr 0.008283687755465508
ep27_l4_test_time 0.6190054416656494
gc 0
Train Epoch28 Acc 0.9739416666666667 (116873/120000), AUC 0.9967678189277649
ep28_train_time 42.150660276412964
Test Epoch28 layer0 Acc 0.9100328947368421, AUC 0.9790175557136536, avg_entr 0.0389614962041378
ep28_l0_test_time 0.2635538578033447
Test Epoch28 layer1 Acc 0.9083881578947368, AUC 0.9702120423316956, avg_entr 0.014721295796334743
ep28_l1_test_time 0.34603357315063477
Test Epoch28 layer2 Acc 0.9060855263157894, AUC 0.9691991209983826, avg_entr 0.010293019004166126
ep28_l2_test_time 0.409043550491333
Test Epoch28 layer3 Acc 0.905921052631579, AUC 0.9679865837097168, avg_entr 0.008631076663732529
ep28_l3_test_time 0.45024800300598145
Test Epoch28 layer4 Acc 0.9057565789473684, AUC 0.9689450860023499, avg_entr 0.0078525859862566
ep28_l4_test_time 0.5455217361450195
gc 0
Train Epoch29 Acc 0.9738916666666667 (116867/120000), AUC 0.9967672824859619
ep29_train_time 39.40275168418884
Test Epoch29 layer0 Acc 0.9098684210526315, AUC 0.9790118932723999, avg_entr 0.03882221505045891
ep29_l0_test_time 0.252239465713501
Test Epoch29 layer1 Acc 0.9088815789473684, AUC 0.9700446128845215, avg_entr 0.014872146770358086
ep29_l1_test_time 0.33818650245666504
Test Epoch29 layer2 Acc 0.9055921052631579, AUC 0.9685137271881104, avg_entr 0.010575931519269943
ep29_l2_test_time 0.42719507217407227
Test Epoch29 layer3 Acc 0.9057565789473684, AUC 0.9668192863464355, avg_entr 0.008804853074252605
ep29_l3_test_time 0.5178396701812744
Test Epoch29 layer4 Acc 0.9057565789473684, AUC 0.9679721593856812, avg_entr 0.008046827279031277
ep29_l4_test_time 0.6065421104431152
gc 0
Train Epoch30 Acc 0.9735916666666666 (116831/120000), AUC 0.9966673851013184
ep30_train_time 40.02773666381836
Test Epoch30 layer0 Acc 0.9105263157894737, AUC 0.9790263175964355, avg_entr 0.0386713370680809
ep30_l0_test_time 0.16322088241577148
Test Epoch30 layer1 Acc 0.9092105263157895, AUC 0.9700536727905273, avg_entr 0.014863021671772003
ep30_l1_test_time 0.2538447380065918
Test Epoch30 layer2 Acc 0.905921052631579, AUC 0.9683049917221069, avg_entr 0.010553265921771526
ep30_l2_test_time 0.41935300827026367
Test Epoch30 layer3 Acc 0.9050986842105263, AUC 0.9669137597084045, avg_entr 0.008803287521004677
ep30_l3_test_time 0.5085976123809814
Test Epoch30 layer4 Acc 0.9060855263157894, AUC 0.9676666259765625, avg_entr 0.008075169287621975
ep30_l4_test_time 0.598919153213501
gc 0
Train Epoch31 Acc 0.9736833333333333 (116842/120000), AUC 0.9967223405838013
ep31_train_time 40.35714793205261
Test Epoch31 layer0 Acc 0.9106907894736842, AUC 0.97902512550354, avg_entr 0.03854309394955635
ep31_l0_test_time 0.1688551902770996
Test Epoch31 layer1 Acc 0.9090460526315789, AUC 0.9700978994369507, avg_entr 0.014827576465904713
ep31_l1_test_time 0.26116085052490234
Test Epoch31 layer2 Acc 0.9054276315789473, AUC 0.9682329893112183, avg_entr 0.010523581877350807
ep31_l2_test_time 0.35297417640686035
Test Epoch31 layer3 Acc 0.9054276315789473, AUC 0.966852068901062, avg_entr 0.008761114440858364
ep31_l3_test_time 0.4431755542755127
Test Epoch31 layer4 Acc 0.9057565789473684, AUC 0.9679754972457886, avg_entr 0.00805540569126606
ep31_l4_test_time 0.5327291488647461
gc 0
Train Epoch32 Acc 0.9737916666666667 (116855/120000), AUC 0.9967445135116577
ep32_train_time 39.296016216278076
Test Epoch32 layer0 Acc 0.9105263157894737, AUC 0.9790234565734863, avg_entr 0.038546886295080185
ep32_l0_test_time 0.16198134422302246
Test Epoch32 layer1 Acc 0.9085526315789474, AUC 0.9701095819473267, avg_entr 0.014751597307622433
ep32_l1_test_time 0.33020925521850586
Test Epoch32 layer2 Acc 0.9057565789473684, AUC 0.9684558510780334, avg_entr 0.010430228896439075
ep32_l2_test_time 0.41680026054382324
Test Epoch32 layer3 Acc 0.9054276315789473, AUC 0.9669307470321655, avg_entr 0.008694262243807316
ep32_l3_test_time 0.5117125511169434
Test Epoch32 layer4 Acc 0.9055921052631579, AUC 0.9680237174034119, avg_entr 0.007992255501449108
ep32_l4_test_time 0.599116325378418
gc 0
Train Epoch33 Acc 0.9740666666666666 (116888/120000), AUC 0.9968487024307251
ep33_train_time 40.1858549118042
Test Epoch33 layer0 Acc 0.9100328947368421, AUC 0.9790129661560059, avg_entr 0.03853433579206467
ep33_l0_test_time 0.17171597480773926
Test Epoch33 layer1 Acc 0.9085526315789474, AUC 0.9701496362686157, avg_entr 0.014733185060322285
ep33_l1_test_time 0.289747953414917
Test Epoch33 layer2 Acc 0.905921052631579, AUC 0.9686382412910461, avg_entr 0.01036494318395853
ep33_l2_test_time 0.35019803047180176
Test Epoch33 layer3 Acc 0.9054276315789473, AUC 0.9671730995178223, avg_entr 0.00864646676927805
ep33_l3_test_time 0.4408571720123291
Test Epoch33 layer4 Acc 0.9060855263157894, AUC 0.9682701230049133, avg_entr 0.007914042100310326
ep33_l4_test_time 0.5299627780914307
gc 0
Train Epoch34 Acc 0.9739666666666666 (116876/120000), AUC 0.9967549443244934
ep34_train_time 41.1043758392334
Test Epoch34 layer0 Acc 0.9105263157894737, AUC 0.9790213704109192, avg_entr 0.03843177482485771
ep34_l0_test_time 0.3196260929107666
Test Epoch34 layer1 Acc 0.9085526315789474, AUC 0.9701384902000427, avg_entr 0.01473025418817997
ep34_l1_test_time 0.36829376220703125
Test Epoch34 layer2 Acc 0.9057565789473684, AUC 0.9685910940170288, avg_entr 0.010363957844674587
ep34_l2_test_time 0.46713805198669434
Test Epoch34 layer3 Acc 0.9052631578947369, AUC 0.9672031402587891, avg_entr 0.008633757010102272
ep34_l3_test_time 0.5897877216339111
Test Epoch34 layer4 Acc 0.9060855263157894, AUC 0.9681704044342041, avg_entr 0.007905234582722187
ep34_l4_test_time 0.6332476139068604
gc 0
Train Epoch35 Acc 0.9739666666666666 (116876/120000), AUC 0.9967730045318604
ep35_train_time 44.383116006851196
Test Epoch35 layer0 Acc 0.9100328947368421, AUC 0.9790164828300476, avg_entr 0.03841405734419823
ep35_l0_test_time 0.13077664375305176
Test Epoch35 layer1 Acc 0.9085526315789474, AUC 0.9701384902000427, avg_entr 0.014707044698297977
ep35_l1_test_time 0.21569323539733887
Test Epoch35 layer2 Acc 0.9055921052631579, AUC 0.9687590599060059, avg_entr 0.010373511351644993
ep35_l2_test_time 0.3024871349334717
Test Epoch35 layer3 Acc 0.9050986842105263, AUC 0.9671856164932251, avg_entr 0.008621341548860073
ep35_l3_test_time 0.38932275772094727
Test Epoch35 layer4 Acc 0.9060855263157894, AUC 0.9682731628417969, avg_entr 0.007926435209810734
ep35_l4_test_time 0.4754784107208252
gc 0
Train Epoch36 Acc 0.9739166666666667 (116870/120000), AUC 0.9968284964561462
ep36_train_time 40.684765338897705
Test Epoch36 layer0 Acc 0.9101973684210526, AUC 0.9790141582489014, avg_entr 0.03843178600072861
ep36_l0_test_time 0.12856411933898926
Test Epoch36 layer1 Acc 0.9083881578947368, AUC 0.9701318740844727, avg_entr 0.014692699536681175
ep36_l1_test_time 0.21407675743103027
Test Epoch36 layer2 Acc 0.905921052631579, AUC 0.96886146068573, avg_entr 0.010332905687391758
ep36_l2_test_time 0.2997255325317383
Test Epoch36 layer3 Acc 0.9054276315789473, AUC 0.9673560261726379, avg_entr 0.008579693734645844
ep36_l3_test_time 0.38549208641052246
Test Epoch36 layer4 Acc 0.9060855263157894, AUC 0.9684611558914185, avg_entr 0.007867968641221523
ep36_l4_test_time 0.46732020378112793
gc 0
Train Epoch37 Acc 0.97375 (116850/120000), AUC 0.9967885613441467
ep37_train_time 37.5314736366272
Test Epoch37 layer0 Acc 0.9105263157894737, AUC 0.9790197610855103, avg_entr 0.03828355297446251
ep37_l0_test_time 0.12906765937805176
Test Epoch37 layer1 Acc 0.9085526315789474, AUC 0.9699831604957581, avg_entr 0.014735694043338299
ep37_l1_test_time 0.21350884437561035
Test Epoch37 layer2 Acc 0.9055921052631579, AUC 0.9685425162315369, avg_entr 0.010390078648924828
ep37_l2_test_time 0.3008296489715576
Test Epoch37 layer3 Acc 0.9052631578947369, AUC 0.9671719074249268, avg_entr 0.008617798797786236
ep37_l3_test_time 0.38344883918762207
Test Epoch37 layer4 Acc 0.9055921052631579, AUC 0.9679393768310547, avg_entr 0.007966436445713043
ep37_l4_test_time 0.4685842990875244
gc 0
Train Epoch38 Acc 0.973875 (116865/120000), AUC 0.9967467188835144
ep38_train_time 37.47221636772156
Test Epoch38 layer0 Acc 0.9106907894736842, AUC 0.9790185689926147, avg_entr 0.038315922021865845
ep38_l0_test_time 0.12894916534423828
Test Epoch38 layer1 Acc 0.9085526315789474, AUC 0.9700533151626587, avg_entr 0.014725467190146446
ep38_l1_test_time 0.21383166313171387
Test Epoch38 layer2 Acc 0.9054276315789473, AUC 0.9685779809951782, avg_entr 0.010383195243775845
ep38_l2_test_time 0.3001120090484619
Test Epoch38 layer3 Acc 0.9052631578947369, AUC 0.9670929908752441, avg_entr 0.00861747469753027
ep38_l3_test_time 0.38744378089904785
Test Epoch38 layer4 Acc 0.9057565789473684, AUC 0.9680570960044861, avg_entr 0.007953362539410591
ep38_l4_test_time 0.4703712463378906
gc 0
Train Epoch39 Acc 0.9740666666666666 (116888/120000), AUC 0.9968339204788208
ep39_train_time 37.61084532737732
Test Epoch39 layer0 Acc 0.9100328947368421, AUC 0.9790115356445312, avg_entr 0.03836163878440857
ep39_l0_test_time 0.12886643409729004
Test Epoch39 layer1 Acc 0.9083881578947368, AUC 0.9700739979743958, avg_entr 0.014704531989991665
ep39_l1_test_time 0.21388673782348633
Test Epoch39 layer2 Acc 0.9057565789473684, AUC 0.968751847743988, avg_entr 0.010334568098187447
ep39_l2_test_time 0.30025458335876465
Test Epoch39 layer3 Acc 0.9052631578947369, AUC 0.9672074913978577, avg_entr 0.008579986169934273
ep39_l3_test_time 0.38623690605163574
Test Epoch39 layer4 Acc 0.905921052631579, AUC 0.968332827091217, avg_entr 0.007875778712332249
ep39_l4_test_time 0.4683413505554199
gc 0
Train Epoch40 Acc 0.973875 (116865/120000), AUC 0.9968240261077881
ep40_train_time 37.59125852584839
Test Epoch40 layer0 Acc 0.9105263157894737, AUC 0.97901451587677, avg_entr 0.03834683448076248
ep40_l0_test_time 0.12952375411987305
Test Epoch40 layer1 Acc 0.9085526315789474, AUC 0.9700831174850464, avg_entr 0.014721794053912163
ep40_l1_test_time 0.21422076225280762
Test Epoch40 layer2 Acc 0.9055921052631579, AUC 0.968718409538269, avg_entr 0.01035336498171091
ep40_l2_test_time 0.3011167049407959
Test Epoch40 layer3 Acc 0.9050986842105263, AUC 0.9671723246574402, avg_entr 0.008597570471465588
ep40_l3_test_time 0.38710594177246094
Test Epoch40 layer4 Acc 0.9055921052631579, AUC 0.9682527184486389, avg_entr 0.007914211601018906
ep40_l4_test_time 0.4679882526397705
gc 0
Train Epoch41 Acc 0.9740416666666667 (116885/120000), AUC 0.9967809915542603
ep41_train_time 37.46704459190369
Test Epoch41 layer0 Acc 0.9103618421052632, AUC 0.9790157079696655, avg_entr 0.03830008581280708
ep41_l0_test_time 0.13001537322998047
Test Epoch41 layer1 Acc 0.9087171052631579, AUC 0.9700657725334167, avg_entr 0.0147329680621624
ep41_l1_test_time 0.2165510654449463
Test Epoch41 layer2 Acc 0.9054276315789473, AUC 0.9686771035194397, avg_entr 0.010379082523286343
ep41_l2_test_time 0.30367422103881836
Test Epoch41 layer3 Acc 0.9049342105263158, AUC 0.967117965221405, avg_entr 0.008612118661403656
ep41_l3_test_time 0.3867619037628174
Test Epoch41 layer4 Acc 0.9054276315789473, AUC 0.9681396484375, avg_entr 0.007958080619573593
ep41_l4_test_time 0.4673783779144287
gc 0
Train Epoch42 Acc 0.97405 (116886/120000), AUC 0.9966914057731628
ep42_train_time 37.58601760864258
Test Epoch42 layer0 Acc 0.9105263157894737, AUC 0.97901451587677, avg_entr 0.038287729024887085
ep42_l0_test_time 0.13261723518371582
Test Epoch42 layer1 Acc 0.9087171052631579, AUC 0.9700306057929993, avg_entr 0.014734678901731968
ep42_l1_test_time 0.21744012832641602
Test Epoch42 layer2 Acc 0.9050986842105263, AUC 0.968622624874115, avg_entr 0.010378921404480934
ep42_l2_test_time 0.30385899543762207
Test Epoch42 layer3 Acc 0.9049342105263158, AUC 0.9670898914337158, avg_entr 0.008603515103459358
ep42_l3_test_time 0.38889551162719727
Test Epoch42 layer4 Acc 0.9052631578947369, AUC 0.9681391716003418, avg_entr 0.007953334599733353
ep42_l4_test_time 0.47138190269470215
gc 0
Train Epoch43 Acc 0.9739916666666667 (116879/120000), AUC 0.9967585206031799
ep43_train_time 37.49613642692566
Test Epoch43 layer0 Acc 0.9105263157894737, AUC 0.9790128469467163, avg_entr 0.038293082267045975
ep43_l0_test_time 0.1283550262451172
Test Epoch43 layer1 Acc 0.9085526315789474, AUC 0.9700953364372253, avg_entr 0.014722662046551704
ep43_l1_test_time 0.21427297592163086
Test Epoch43 layer2 Acc 0.9054276315789473, AUC 0.9687581658363342, avg_entr 0.01036309264600277
ep43_l2_test_time 0.30101847648620605
Test Epoch43 layer3 Acc 0.9049342105263158, AUC 0.9672077298164368, avg_entr 0.008599119260907173
ep43_l3_test_time 0.3838648796081543
Test Epoch43 layer4 Acc 0.9055921052631579, AUC 0.9682964086532593, avg_entr 0.007926339283585548
ep43_l4_test_time 0.46962594985961914
gc 0
Train Epoch44 Acc 0.9738916666666667 (116867/120000), AUC 0.9968084096908569
ep44_train_time 37.5117552280426
Test Epoch44 layer0 Acc 0.9105263157894737, AUC 0.9790118336677551, avg_entr 0.038291893899440765
ep44_l0_test_time 0.12849879264831543
Test Epoch44 layer1 Acc 0.9085526315789474, AUC 0.9700598120689392, avg_entr 0.014711864292621613
ep44_l1_test_time 0.21409916877746582
Test Epoch44 layer2 Acc 0.9052631578947369, AUC 0.9687337875366211, avg_entr 0.010351653210818768
ep44_l2_test_time 0.2998170852661133
Test Epoch44 layer3 Acc 0.9049342105263158, AUC 0.9672051668167114, avg_entr 0.008588988333940506
ep44_l3_test_time 0.381943941116333
Test Epoch44 layer4 Acc 0.9055921052631579, AUC 0.9683108925819397, avg_entr 0.007916693575680256
ep44_l4_test_time 0.46610069274902344
gc 0
Train Epoch45 Acc 0.9739916666666667 (116879/120000), AUC 0.9968034625053406
ep45_train_time 37.500675439834595
Test Epoch45 layer0 Acc 0.9103618421052632, AUC 0.9790133833885193, avg_entr 0.03828774765133858
ep45_l0_test_time 0.13194680213928223
Test Epoch45 layer1 Acc 0.9083881578947368, AUC 0.9700886607170105, avg_entr 0.014727432280778885
ep45_l1_test_time 0.2155005931854248
Test Epoch45 layer2 Acc 0.9052631578947369, AUC 0.9687303900718689, avg_entr 0.010369016788899899
ep45_l2_test_time 0.30008816719055176
Test Epoch45 layer3 Acc 0.9049342105263158, AUC 0.9671485424041748, avg_entr 0.008602293208241463
ep45_l3_test_time 0.382312536239624
Test Epoch45 layer4 Acc 0.9055921052631579, AUC 0.9681751132011414, avg_entr 0.007948813028633595
ep45_l4_test_time 0.46598219871520996
gc 0
Train Epoch46 Acc 0.9741833333333333 (116902/120000), AUC 0.996761679649353
ep46_train_time 37.529035568237305
Test Epoch46 layer0 Acc 0.9103618421052632, AUC 0.9790111184120178, avg_entr 0.03828565776348114
ep46_l0_test_time 0.12934160232543945
Test Epoch46 layer1 Acc 0.9083881578947368, AUC 0.9700843691825867, avg_entr 0.014720494858920574
ep46_l1_test_time 0.21359038352966309
Test Epoch46 layer2 Acc 0.9050986842105263, AUC 0.9687525629997253, avg_entr 0.010359100066125393
ep46_l2_test_time 0.29961371421813965
Test Epoch46 layer3 Acc 0.9049342105263158, AUC 0.967164158821106, avg_entr 0.008591377176344395
ep46_l3_test_time 0.38572192192077637
Test Epoch46 layer4 Acc 0.9055921052631579, AUC 0.9681993722915649, avg_entr 0.007933113723993301
ep46_l4_test_time 0.46724867820739746
gc 0
Train Epoch47 Acc 0.9738416666666667 (116861/120000), AUC 0.9967813491821289
ep47_train_time 37.565077781677246
Test Epoch47 layer0 Acc 0.9103618421052632, AUC 0.9790144562721252, avg_entr 0.03828543797135353
ep47_l0_test_time 0.12863636016845703
Test Epoch47 layer1 Acc 0.9083881578947368, AUC 0.9701052308082581, avg_entr 0.014720959588885307
ep47_l1_test_time 0.21355438232421875
Test Epoch47 layer2 Acc 0.9052631578947369, AUC 0.9687067866325378, avg_entr 0.01036020740866661
ep47_l2_test_time 0.29965853691101074
Test Epoch47 layer3 Acc 0.9049342105263158, AUC 0.9671199917793274, avg_entr 0.008592239581048489
ep47_l3_test_time 0.38356566429138184
Test Epoch47 layer4 Acc 0.9055921052631579, AUC 0.9681375026702881, avg_entr 0.007940021343529224
ep47_l4_test_time 0.4661524295806885
gc 0
Train Epoch48 Acc 0.9739583333333334 (116875/120000), AUC 0.9968899488449097
ep48_train_time 37.44308638572693
Test Epoch48 layer0 Acc 0.9103618421052632, AUC 0.9790124893188477, avg_entr 0.038282595574855804
ep48_l0_test_time 0.1362745761871338
Test Epoch48 layer1 Acc 0.9083881578947368, AUC 0.9701006412506104, avg_entr 0.01471616979688406
ep48_l1_test_time 0.21355819702148438
Test Epoch48 layer2 Acc 0.9052631578947369, AUC 0.9687125086784363, avg_entr 0.010355912148952484
ep48_l2_test_time 0.29952239990234375
Test Epoch48 layer3 Acc 0.9049342105263158, AUC 0.9671406149864197, avg_entr 0.008589903824031353
ep48_l3_test_time 0.386150598526001
Test Epoch48 layer4 Acc 0.9055921052631579, AUC 0.9681689143180847, avg_entr 0.0079328129068017
ep48_l4_test_time 0.46789097785949707
gc 0
Train Epoch49 Acc 0.974025 (116883/120000), AUC 0.9968457818031311
ep49_train_time 37.44255447387695
Test Epoch49 layer0 Acc 0.9103618421052632, AUC 0.9790130853652954, avg_entr 0.03828234598040581
ep49_l0_test_time 0.12885594367980957
Test Epoch49 layer1 Acc 0.9083881578947368, AUC 0.9701026082038879, avg_entr 0.014718824997544289
ep49_l1_test_time 0.21358513832092285
Test Epoch49 layer2 Acc 0.9052631578947369, AUC 0.9687137603759766, avg_entr 0.01036058273166418
ep49_l2_test_time 0.30049824714660645
Test Epoch49 layer3 Acc 0.9049342105263158, AUC 0.9671231508255005, avg_entr 0.008591759018599987
ep49_l3_test_time 0.38579463958740234
Test Epoch49 layer4 Acc 0.9055921052631579, AUC 0.9681563973426819, avg_entr 0.007939279079437256
ep49_l4_test_time 0.4669780731201172
Best AUC 0.9823310375213623
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_transformeral_l5_pad75//ag_news_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.925, AUC 0.9862931370735168, avg_entr 0.09784631431102753
ep49_l0_test_time 0.03315615653991699
Test Epoch49 layer1 Acc 0.9282894736842106, AUC 0.9853326082229614, avg_entr 0.03721194714307785
ep49_l1_test_time 0.05357098579406738
Test Epoch49 layer2 Acc 0.9282894736842106, AUC 0.9870630502700806, avg_entr 0.03117126226425171
ep49_l2_test_time 0.07492542266845703
Test Epoch49 layer3 Acc 0.9282894736842106, AUC 0.9871541261672974, avg_entr 0.028106097131967545
ep49_l3_test_time 0.09649324417114258
Test Epoch49 layer4 Acc 0.9282894736842106, AUC 0.9876964092254639, avg_entr 0.027708282694220543
ep49_l4_test_time 0.11745333671569824
