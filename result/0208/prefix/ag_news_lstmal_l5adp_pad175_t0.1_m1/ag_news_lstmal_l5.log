total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.134825 (16179/120000), AUC 0.37405210733413696
ep0_train_time 46.508965730667114
Test Epoch0 threshold 0.1 Acc 0.9004934210526315, AUC 0.9737399816513062, avg_entr 0.18111251294612885
ep0_t0.1_test_time 0.27579236030578613
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.07543333333333334 (9052/120000), AUC 0.3186802864074707
ep1_train_time 46.92993211746216
Test Epoch1 threshold 0.1 Acc 0.9108552631578948, AUC 0.9778823852539062, avg_entr 0.10665769875049591
ep1_t0.1_test_time 0.25218915939331055
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.077625 (9315/120000), AUC 0.31149017810821533
ep2_train_time 46.959497690200806
Test Epoch2 threshold 0.1 Acc 0.9111842105263158, AUC 0.9793579578399658, avg_entr 0.08315713703632355
ep2_t0.1_test_time 0.2516334056854248
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.0839 (10068/120000), AUC 0.30975541472435
ep3_train_time 46.90169072151184
Test Epoch3 threshold 0.1 Acc 0.9139802631578947, AUC 0.9800688624382019, avg_entr 0.06769124418497086
ep3_t0.1_test_time 0.2511024475097656
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.09293333333333334 (11152/120000), AUC 0.30943039059638977
ep4_train_time 46.84538435935974
Test Epoch4 threshold 0.1 Acc 0.9123355263157895, AUC 0.9806825518608093, avg_entr 0.06031065806746483
ep4_t0.1_test_time 0.2525200843811035
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 4
gc 0
Train Epoch5 Acc 0.10354166666666667 (12425/120000), AUC 0.3099757730960846
ep5_train_time 46.92263579368591
Test Epoch5 threshold 0.1 Acc 0.9180921052631579, AUC 0.9807340502738953, avg_entr 0.054802022874355316
ep5_t0.1_test_time 0.2503201961517334
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 5
gc 0
Train Epoch6 Acc 0.11454166666666667 (13745/120000), AUC 0.31082531809806824
ep6_train_time 46.84082317352295
Test Epoch6 threshold 0.1 Acc 0.9149671052631579, AUC 0.9805969595909119, avg_entr 0.04882975295186043
ep6_t0.1_test_time 0.2510993480682373
gc 0
Train Epoch7 Acc 0.12469166666666667 (14963/120000), AUC 0.31106072664260864
ep7_train_time 46.82266116142273
Test Epoch7 threshold 0.1 Acc 0.9189144736842105, AUC 0.9807204008102417, avg_entr 0.04524386674165726
ep7_t0.1_test_time 0.25032782554626465
gc 0
Train Epoch8 Acc 0.13663333333333333 (16396/120000), AUC 0.3119511902332306
ep8_train_time 46.863300800323486
Test Epoch8 threshold 0.1 Acc 0.9126644736842106, AUC 0.9805067777633667, avg_entr 0.04321417957544327
ep8_t0.1_test_time 0.25014472007751465
gc 0
Train Epoch9 Acc 0.14385833333333334 (17263/120000), AUC 0.3118710517883301
ep9_train_time 46.91454458236694
Test Epoch9 threshold 0.1 Acc 0.9174342105263158, AUC 0.980437159538269, avg_entr 0.04058965668082237
ep9_t0.1_test_time 0.2504770755767822
Best AUC 0.9807340502738953
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adp_pad175_t0.1_m1//ag_news_lstmal_l5_prefix.pt
[[1381   50   66   35]
 [  16 1477    3   11]
 [  41   11 1325  123]
 [  42   13   87 1399]]
Figure(640x480)
tensor([0.0534, 0.0005, 0.0204,  ..., 0.0008, 0.0037, 0.0349])
[[   3 1097   72  360]
 [  43 1324   14  126]
 [   0 1022  191  287]
 [   2 1194   21  324]]
Figure(640x480)
tensor([1.0764, 1.2179, 1.1262,  ..., 1.2018, 1.1222, 1.1487])
[[ 507  587   25  413]
 [1284  156   50   17]
 [ 871  240   54  335]
 [1210  199   72   60]]
Figure(640x480)
tensor([1.4399, 1.4400, 1.4422,  ..., 1.3287, 1.4313, 1.4400])
[[1513   13    0    6]
 [1482    1    0   24]
 [1338    1    0  161]
 [1482    8    0   51]]
Figure(640x480)
tensor([1.3865, 1.3194, 1.3326,  ..., 1.3388, 1.3858, 1.3567])
[[ 625    0    0  907]
 [ 478    0    0 1029]
 [1234    0    0  266]
 [1444    0    0   97]]
Figure(640x480)
tensor([1.3990, 1.3834, 1.3940,  ..., 1.3708, 1.4092, 1.3675])
