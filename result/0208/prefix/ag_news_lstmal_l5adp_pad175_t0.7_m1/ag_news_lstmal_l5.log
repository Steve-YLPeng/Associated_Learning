total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.254 (30480/120000), AUC 0.6264103651046753
ep0_train_time 46.98215126991272
Test Epoch0 threshold 0.7 Acc 0.8970394736842106, AUC 0.9739899039268494, avg_entr 0.1811559796333313
ep0_t0.7_test_time 0.25191426277160645
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.7_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.258625 (31035/120000), AUC 0.7111685276031494
ep1_train_time 47.008049726486206
Test Epoch1 threshold 0.7 Acc 0.9125, AUC 0.977737307548523, avg_entr 0.10579293221235275
ep1_t0.7_test_time 0.25074267387390137
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.7_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.2593666666666667 (31124/120000), AUC 0.7181488871574402
ep2_train_time 47.066595792770386
Test Epoch2 threshold 0.7 Acc 0.9121710526315789, AUC 0.9794255495071411, avg_entr 0.08022133260965347
ep2_t0.7_test_time 0.2516770362854004
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.7_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.2602333333333333 (31228/120000), AUC 0.7201202511787415
ep3_train_time 47.072049617767334
Test Epoch3 threshold 0.7 Acc 0.9164473684210527, AUC 0.9804168939590454, avg_entr 0.06668240576982498
ep3_t0.7_test_time 0.25061607360839844
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.7_m1//ag_news_lstmal_l5_prefix.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.26150833333333334 (31381/120000), AUC 0.7199887037277222
ep4_train_time 47.07455492019653
Test Epoch4 threshold 0.7 Acc 0.9175986842105263, AUC 0.9807204604148865, avg_entr 0.058784399181604385
ep4_t0.7_test_time 0.2510406970977783
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.7_m1//ag_news_lstmal_l5_prefix.pt  ,ep 4
gc 0
Train Epoch5 Acc 0.26319166666666666 (31583/120000), AUC 0.7194055914878845
ep5_train_time 47.16942477226257
Test Epoch5 threshold 0.7 Acc 0.9161184210526315, AUC 0.980858564376831, avg_entr 0.05305197834968567
ep5_t0.7_test_time 0.2513420581817627
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.7_m1//ag_news_lstmal_l5_prefix.pt  ,ep 5
gc 0
Train Epoch6 Acc 0.26493333333333335 (31792/120000), AUC 0.7183112502098083
ep6_train_time 47.11221671104431
Test Epoch6 threshold 0.7 Acc 0.9167763157894737, AUC 0.9807512164115906, avg_entr 0.04833536222577095
ep6_t0.7_test_time 0.2512032985687256
gc 0
Train Epoch7 Acc 0.2665 (31980/120000), AUC 0.7167688608169556
ep7_train_time 47.053935050964355
Test Epoch7 threshold 0.7 Acc 0.9177631578947368, AUC 0.9807764291763306, avg_entr 0.04577235132455826
ep7_t0.7_test_time 0.2509164810180664
gc 0
Train Epoch8 Acc 0.26865 (32238/120000), AUC 0.7155145406723022
ep8_train_time 47.08964276313782
Test Epoch8 threshold 0.7 Acc 0.9166118421052631, AUC 0.9807004928588867, avg_entr 0.04198431223630905
ep8_t0.7_test_time 0.2501182556152344
gc 0
Train Epoch9 Acc 0.2712333333333333 (32548/120000), AUC 0.7139606475830078
ep9_train_time 47.104185342788696
Test Epoch9 threshold 0.7 Acc 0.9159539473684211, AUC 0.9805161356925964, avg_entr 0.040519244968891144
ep9_t0.7_test_time 0.25165534019470215
Best AUC 0.980858564376831
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adp_pad175_t0.7_m1//ag_news_lstmal_l5_prefix.pt
[[335   7  14  12]
 [  0 389   3   1]
 [  5   6 356  33]
 [  5   0  24 330]]
Figure(640x480)
tensor([0.0174, 0.0420, 0.2084,  ..., 0.0515, 0.0014, 0.0466])
[[  1 308  26  33]
 [  0 309  20  64]
 [  0 247 111  42]
 [  0 285  53  21]]
Figure(640x480)
tensor([1.2494, 1.2244, 1.0167,  ..., 1.1506, 1.1633, 0.8287])
[[ 43   9   7 309]
 [ 17  70  41 265]
 [ 59 119  19 203]
 [ 98  43  20 198]]
Figure(640x480)
tensor([1.4045, 1.3516, 1.3880,  ..., 1.3304, 1.4344, 1.3716])
[[ 15 218 132   3]
 [  5 330  58   0]
 [ 12 354  32   2]
 [  9 250 100   0]]
Figure(640x480)
tensor([1.4088, 1.3984, 1.3923,  ..., 1.4190, 1.3714, 1.4284])
[[  0 368   0   0]
 [  0 393   0   0]
 [  0 398   0   2]
 [  0 336   0  23]]
Figure(640x480)
tensor([1.4355, 1.4282, 1.4220,  ..., 1.4181, 1.4266, 1.4153])
