total count words 102019
vocab size 30000
found 26754 words in glove
Load ckpt from ckpt/ag_news_linearal_l5adp_pad175_t0.5_m3//ag_news_linearal_l5_prefix.pt
model: LinearModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.0.weight 90000
layers.1.enc.f.0.bias 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.0.weight 90000
layers.2.enc.f.0.bias 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.0.weight 90000
layers.3.enc.f.0.bias 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.0.weight 90000
layers.4.enc.f.0.bias 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 9687092
Start Training
train_mask {0, 1, 2, 3}
gc 9
Train Epoch0 Acc 0.08490833333333334 (10189/120000), AUC 0.474209725856781
ep0_train_time 9.878832340240479
Test Epoch0 threshold 0.5 Acc 0.9167763157894737, AUC 0.980522096157074, avg_entr 0.026668796315789223
ep0_t0.5_test_time 0.2559380531311035
Save ckpt to ckpt/ag_news_linearal_l5adp_pad175_t0.5_m4//ag_news_linearal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.10926666666666666 (13112/120000), AUC 0.43716761469841003
ep1_train_time 9.581177234649658
Test Epoch1 threshold 0.5 Acc 0.9164473684210527, AUC 0.980458676815033, avg_entr 0.02586844563484192
ep1_t0.5_test_time 0.25029611587524414
gc 0
Train Epoch2 Acc 0.241475 (28977/120000), AUC 0.42283350229263306
ep2_train_time 9.456449031829834
Test Epoch2 threshold 0.5 Acc 0.9115131578947369, AUC 0.9801105856895447, avg_entr 0.026346638798713684
ep2_t0.5_test_time 0.250016450881958
gc 0
Train Epoch3 Acc 0.2591833333333333 (31102/120000), AUC 0.4254119098186493
ep3_train_time 9.444377899169922
Test Epoch3 threshold 0.5 Acc 0.9125, AUC 0.9801025986671448, avg_entr 0.0257822647690773
ep3_t0.5_test_time 0.25028562545776367
gc 0
Train Epoch4 Acc 0.20905 (25086/120000), AUC 0.43170619010925293
ep4_train_time 9.47614312171936
Test Epoch4 threshold 0.5 Acc 0.9118421052631579, AUC 0.9800106287002563, avg_entr 0.026384491473436356
ep4_t0.5_test_time 0.251354455947876
gc 0
Train Epoch5 Acc 0.19605 (23526/120000), AUC 0.43145552277565
ep5_train_time 9.393061637878418
Test Epoch5 threshold 0.5 Acc 0.9148026315789474, AUC 0.9800138473510742, avg_entr 0.02577412687242031
ep5_t0.5_test_time 0.25008702278137207
gc 0
Train Epoch6 Acc 0.20399166666666665 (24479/120000), AUC 0.43254202604293823
ep6_train_time 9.483609199523926
Test Epoch6 threshold 0.5 Acc 0.9136513157894737, AUC 0.979764997959137, avg_entr 0.02625388279557228
ep6_t0.5_test_time 0.24972891807556152
gc 0
Train Epoch7 Acc 0.20858333333333334 (25030/120000), AUC 0.43722373247146606
ep7_train_time 9.672012567520142
Test Epoch7 threshold 0.5 Acc 0.9141447368421053, AUC 0.9796273708343506, avg_entr 0.026003308594226837
ep7_t0.5_test_time 0.2503633499145508
gc 0
Train Epoch8 Acc 0.20578333333333335 (24694/120000), AUC 0.44467371702194214
ep8_train_time 9.47977590560913
Test Epoch8 threshold 0.5 Acc 0.9129934210526316, AUC 0.979535698890686, avg_entr 0.026544788852334023
ep8_t0.5_test_time 0.24929261207580566
gc 0
Train Epoch9 Acc 0.20593333333333333 (24712/120000), AUC 0.4512312114238739
ep9_train_time 9.488393068313599
Test Epoch9 threshold 0.5 Acc 0.9125, AUC 0.9794455170631409, avg_entr 0.026027774438261986
ep9_t0.5_test_time 0.25156116485595703
Best AUC 0.980522096157074
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_linearal_l5adp_pad175_t0.5_m4//ag_news_linearal_l5_prefix.pt
[[1382   50   65   35]
 [  18 1471    6   12]
 [  39   12 1322  127]
 [  39   12   94 1396]]
Figure(640x480)
tensor([5.4567e-03, 3.2274e-08, 6.8152e-05,  ..., 5.1915e-08, 2.4125e-06,
        3.0195e-04])
[[1380   50   68   34]
 [  17 1471    7   12]
 [  39   11 1323  127]
 [  40   13   90 1398]]
Figure(640x480)
tensor([2.4136e-03, 1.9876e-07, 6.3058e-05,  ..., 9.6463e-08, 3.1385e-06,
        9.1150e-04])
[[1388   50   61   33]
 [  18 1471    6   12]
 [  41   11 1313  135]
 [  40   11   87 1403]]
Figure(640x480)
tensor([2.4884e-03, 7.9651e-08, 3.1917e-05,  ..., 1.0037e-07, 1.2230e-06,
        1.0196e-03])
[[1382   50   61   39]
 [  19 1471    5   12]
 [  39   11 1309  141]
 [  40   12   83 1406]]
Figure(640x480)
tensor([3.3788e-03, 8.5652e-08, 1.6550e-05,  ..., 1.2920e-07, 1.6971e-06,
        5.7349e-04])
[[  44 1145    0  343]
 [   1    4    0 1502]
 [1148  297    0   55]
 [ 939   22    0  580]]
Figure(640x480)
tensor([0.6085, 0.4770, 0.8793,  ..., 0.1048, 0.8604, 0.6068])
