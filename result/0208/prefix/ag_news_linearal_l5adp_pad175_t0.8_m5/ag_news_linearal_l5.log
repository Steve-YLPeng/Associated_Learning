total count words 102019
vocab size 30000
found 26754 words in glove
Load ckpt from ckpt/ag_news_linearal_l5adp_pad175_t0.8_m4//ag_news_linearal_l5_prefix.pt
model: LinearModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.0.weight 90000
layers.1.enc.f.0.bias 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.0.weight 90000
layers.2.enc.f.0.bias 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.0.weight 90000
layers.3.enc.f.0.bias 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.0.weight 90000
layers.4.enc.f.0.bias 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 9687092
Start Training
train_mask {0, 1, 2, 3, 4}
gc 9
Train Epoch0 Acc 0.916175 (109941/120000), AUC 0.9840205907821655
ep0_train_time 10.63531756401062
Test Epoch0 threshold 0.8 Acc 0.915296052631579, AUC 0.9806157350540161, avg_entr 0.025729870423674583
ep0_t0.8_test_time 0.25731563568115234
Save ckpt to ckpt/ag_news_linearal_l5adp_pad175_t0.8_m5//ag_news_linearal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.9489666666666666 (113876/120000), AUC 0.993006706237793
ep1_train_time 10.219689846038818
Test Epoch1 threshold 0.8 Acc 0.9133223684210526, AUC 0.9806222319602966, avg_entr 0.026049435138702393
ep1_t0.8_test_time 0.2548389434814453
Save ckpt to ckpt/ag_news_linearal_l5adp_pad175_t0.8_m5//ag_news_linearal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.9509333333333333 (114112/120000), AUC 0.9933247566223145
ep2_train_time 10.10322880744934
Test Epoch2 threshold 0.8 Acc 0.9131578947368421, AUC 0.9803081154823303, avg_entr 0.025594551116228104
ep2_t0.8_test_time 0.25484180450439453
gc 0
Train Epoch3 Acc 0.9517083333333334 (114205/120000), AUC 0.9933496117591858
ep3_train_time 10.168083667755127
Test Epoch3 threshold 0.8 Acc 0.9148026315789474, AUC 0.980249285697937, avg_entr 0.024981902912259102
ep3_t0.8_test_time 0.2548348903656006
gc 0
Train Epoch4 Acc 0.9528 (114336/120000), AUC 0.9936925172805786
ep4_train_time 10.135172843933105
Test Epoch4 threshold 0.8 Acc 0.9136513157894737, AUC 0.9800419807434082, avg_entr 0.026166792958974838
ep4_t0.8_test_time 0.255204439163208
gc 0
Train Epoch5 Acc 0.954675 (114561/120000), AUC 0.9944930076599121
ep5_train_time 10.017213582992554
Test Epoch5 threshold 0.8 Acc 0.9143092105263158, AUC 0.9799554944038391, avg_entr 0.026483766734600067
ep5_t0.8_test_time 0.25488829612731934
gc 0
Train Epoch6 Acc 0.9553 (114636/120000), AUC 0.9946179986000061
ep6_train_time 10.214215755462646
Test Epoch6 threshold 0.8 Acc 0.9134868421052632, AUC 0.9798194169998169, avg_entr 0.025868268683552742
ep6_t0.8_test_time 0.2540934085845947
gc 0
Train Epoch7 Acc 0.955525 (114663/120000), AUC 0.9947259426116943
ep7_train_time 10.208620548248291
Test Epoch7 threshold 0.8 Acc 0.9134868421052632, AUC 0.9796768426895142, avg_entr 0.026337364688515663
ep7_t0.8_test_time 0.2549412250518799
gc 0
Train Epoch8 Acc 0.9561 (114732/120000), AUC 0.9949367642402649
ep8_train_time 10.163819551467896
Test Epoch8 threshold 0.8 Acc 0.9133223684210526, AUC 0.979560911655426, avg_entr 0.026906533166766167
ep8_t0.8_test_time 0.25589823722839355
gc 0
Train Epoch9 Acc 0.9572166666666667 (114866/120000), AUC 0.995130717754364
ep9_train_time 10.29450535774231
Test Epoch9 threshold 0.8 Acc 0.9123355263157895, AUC 0.9795396327972412, avg_entr 0.026752809062600136
ep9_t0.8_test_time 0.25529980659484863
Best AUC 0.9806222319602966
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_linearal_l5adp_pad175_t0.8_m5//ag_news_linearal_l5_prefix.pt
[[329   6  18  15]
 [  0 388   4   1]
 [  6   4 367  23]
 [  4   1  34 320]]
Figure(640x480)
tensor([1.4124e-03, 6.9802e-03, 3.6800e-01,  ..., 7.7441e-02, 3.8450e-08,
        7.9917e-05])
[[331   5  19  13]
 [  0 388   4   1]
 [  6   4 367  23]
 [  4   1  33 321]]
Figure(640x480)
tensor([4.7887e-04, 3.5796e-03, 2.5584e-01,  ..., 7.9433e-02, 6.4302e-08,
        7.3276e-05])
[[332   6  16  14]
 [  0 388   4   1]
 [  7   4 366  23]
 [  3   1  35 320]]
Figure(640x480)
tensor([4.1585e-04, 2.2519e-03, 2.5264e-01,  ..., 1.7324e-02, 3.2782e-08,
        6.8543e-05])
[[333   5  14  16]
 [  0 388   4   1]
 [  8   4 365  23]
 [  4   1  34 320]]
Figure(640x480)
tensor([6.3512e-05, 2.9223e-04, 9.6474e-02,  ..., 6.3259e-03, 1.8245e-08,
        1.6739e-05])
[[334   4  14  16]
 [  0 388   4   1]
 [  8   4 365  23]
 [  3   1  36 319]]
Figure(640x480)
tensor([2.1443e-05, 6.5772e-05, 5.0537e-02,  ..., 4.1812e-03, 1.4789e-08,
        4.6629e-06])
