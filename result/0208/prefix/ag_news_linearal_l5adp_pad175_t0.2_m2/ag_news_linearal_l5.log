total count words 102019
vocab size 30000
found 26754 words in glove
Load ckpt from ckpt/ag_news_linearal_l5adp_pad175_t0.2_m1//ag_news_linearal_l5_prefix.pt
model: LinearModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.0.weight 90000
layers.1.enc.f.0.bias 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.0.weight 90000
layers.2.enc.f.0.bias 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.0.weight 90000
layers.3.enc.f.0.bias 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.0.weight 90000
layers.4.enc.f.0.bias 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 9687092
Start Training
train_mask {0, 1}
gc 9
Train Epoch0 Acc 0.26238333333333336 (31486/120000), AUC 0.5315420627593994
ep0_train_time 9.153067588806152
Test Epoch0 threshold 0.2 Acc 0.9157894736842105, AUC 0.9806215763092041, avg_entr 0.026173969730734825
ep0_t0.2_test_time 0.2641572952270508
Save ckpt to ckpt/ag_news_linearal_l5adp_pad175_t0.2_m2//ag_news_linearal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.24918333333333334 (29902/120000), AUC 0.5953695774078369
ep1_train_time 8.641021251678467
Test Epoch1 threshold 0.2 Acc 0.9136513157894737, AUC 0.9807607531547546, avg_entr 0.02589477226138115
ep1_t0.2_test_time 0.26233553886413574
Save ckpt to ckpt/ag_news_linearal_l5adp_pad175_t0.2_m2//ag_news_linearal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.24915 (29898/120000), AUC 0.5838800668716431
ep2_train_time 8.523505687713623
Test Epoch2 threshold 0.2 Acc 0.915296052631579, AUC 0.980549693107605, avg_entr 0.02508983202278614
ep2_t0.2_test_time 0.25893616676330566
gc 0
Train Epoch3 Acc 0.249275 (29913/120000), AUC 0.5842071175575256
ep3_train_time 8.495296001434326
Test Epoch3 threshold 0.2 Acc 0.9161184210526315, AUC 0.9803441762924194, avg_entr 0.025648491457104683
ep3_t0.2_test_time 0.2604544162750244
gc 0
Train Epoch4 Acc 0.249175 (29901/120000), AUC 0.5854578614234924
ep4_train_time 8.549385786056519
Test Epoch4 threshold 0.2 Acc 0.9159539473684211, AUC 0.9803601503372192, avg_entr 0.02571321837604046
ep4_t0.2_test_time 0.2570209503173828
gc 0
Train Epoch5 Acc 0.24950833333333333 (29941/120000), AUC 0.5861635208129883
ep5_train_time 8.577714204788208
Test Epoch5 threshold 0.2 Acc 0.9159539473684211, AUC 0.9801532626152039, avg_entr 0.02442525513470173
ep5_t0.2_test_time 0.2581944465637207
gc 0
Train Epoch6 Acc 0.24949166666666667 (29939/120000), AUC 0.5862360000610352
ep6_train_time 8.620374202728271
Test Epoch6 threshold 0.2 Acc 0.9143092105263158, AUC 0.979954183101654, avg_entr 0.0259799025952816
ep6_t0.2_test_time 0.25862860679626465
gc 0
Train Epoch7 Acc 0.249525 (29943/120000), AUC 0.5860447287559509
ep7_train_time 8.572667837142944
Test Epoch7 threshold 0.2 Acc 0.9151315789473684, AUC 0.9799236059188843, avg_entr 0.02594653144478798
ep7_t0.2_test_time 0.2576327323913574
gc 0
Train Epoch8 Acc 0.24955 (29946/120000), AUC 0.5860073566436768
ep8_train_time 8.49057674407959
Test Epoch8 threshold 0.2 Acc 0.9148026315789474, AUC 0.9799350500106812, avg_entr 0.025031305849552155
ep8_t0.2_test_time 0.25816988945007324
gc 0
Train Epoch9 Acc 0.24958333333333332 (29950/120000), AUC 0.585894763469696
ep9_train_time 8.557446479797363
Test Epoch9 threshold 0.2 Acc 0.9121710526315789, AUC 0.9797250032424927, avg_entr 0.024751819670200348
ep9_t0.2_test_time 0.2577323913574219
Best AUC 0.9807607531547546
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_linearal_l5adp_pad175_t0.2_m2//ag_news_linearal_l5_prefix.pt
[[1383   50   68   31]
 [  16 1479    7    5]
 [  39   14 1342  105]
 [  49   17  124 1351]]
Figure(640x480)
tensor([8.0907e-03, 6.6087e-07, 1.0774e-03,  ..., 4.1534e-07, 1.3006e-05,
        1.4951e-04])
[[1380   50   72   30]
 [  16 1481    5    5]
 [  37   12 1346  105]
 [  46   18  122 1355]]
Figure(640x480)
tensor([5.0506e-03, 5.3785e-06, 6.7324e-04,  ..., 5.2592e-07, 2.2603e-05,
        4.1068e-04])
[[   0 1236    0  296]
 [   0   20    0 1487]
 [   1 1480    0   19]
 [   1 1044    0  496]]
Figure(640x480)
tensor([1.0535, 1.2514, 1.2584,  ..., 0.9922, 1.2822, 1.0481])
[[   0   72    0 1460]
 [   0    0    0 1507]
 [   0    0    0 1500]
 [   0   12    0 1529]]
Figure(640x480)
tensor([1.0630, 0.9889, 0.9997,  ..., 0.7413, 1.0356, 1.0741])
[[   0 1139    0  393]
 [   0   22    0 1485]
 [   0 1211    0  289]
 [   0   36    0 1505]]
Figure(640x480)
tensor([0.8695, 0.7002, 0.8976,  ..., 0.9864, 0.9161, 0.8699])
