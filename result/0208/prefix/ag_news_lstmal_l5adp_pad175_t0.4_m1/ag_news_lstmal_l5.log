total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.24283333333333335 (29140/120000), AUC 0.551513135433197
ep0_train_time 46.9716374874115
Test Epoch0 threshold 0.4 Acc 0.8978618421052632, AUC 0.9743249416351318, avg_entr 0.17850865423679352
ep0_t0.4_test_time 0.25542187690734863
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.24084166666666668 (28901/120000), AUC 0.5858545899391174
ep1_train_time 47.18262219429016
Test Epoch1 threshold 0.4 Acc 0.9097039473684211, AUC 0.9781554341316223, avg_entr 0.10536986589431763
ep1_t0.4_test_time 0.2530369758605957
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.24055833333333335 (28867/120000), AUC 0.5851159691810608
ep2_train_time 47.19037842750549
Test Epoch2 threshold 0.4 Acc 0.9123355263157895, AUC 0.9796578884124756, avg_entr 0.07838793843984604
ep2_t0.4_test_time 0.25345492362976074
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.23991666666666667 (28790/120000), AUC 0.5830300450325012
ep3_train_time 47.27954697608948
Test Epoch3 threshold 0.4 Acc 0.9149671052631579, AUC 0.9802149534225464, avg_entr 0.06572462618350983
ep3_t0.4_test_time 0.2526867389678955
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.23923333333333333 (28708/120000), AUC 0.5797199606895447
ep4_train_time 47.0918824672699
Test Epoch4 threshold 0.4 Acc 0.9151315789473684, AUC 0.9807374477386475, avg_entr 0.058241963386535645
ep4_t0.4_test_time 0.2532343864440918
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 4
gc 0
Train Epoch5 Acc 0.23895833333333333 (28675/120000), AUC 0.5769132971763611
ep5_train_time 47.07774043083191
Test Epoch5 threshold 0.4 Acc 0.9139802631578947, AUC 0.9806951880455017, avg_entr 0.05523140728473663
ep5_t0.4_test_time 0.25421977043151855
gc 0
Train Epoch6 Acc 0.23865833333333333 (28639/120000), AUC 0.5740110874176025
ep6_train_time 47.10680437088013
Test Epoch6 threshold 0.4 Acc 0.9146381578947368, AUC 0.9808248281478882, avg_entr 0.0491282120347023
ep6_t0.4_test_time 0.25316333770751953
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 6
gc 0
Train Epoch7 Acc 0.238725 (28647/120000), AUC 0.5716581344604492
ep7_train_time 47.134358406066895
Test Epoch7 threshold 0.4 Acc 0.9154605263157894, AUC 0.9806541800498962, avg_entr 0.045546650886535645
ep7_t0.4_test_time 0.25310587882995605
gc 0
Train Epoch8 Acc 0.238875 (28665/120000), AUC 0.5690550804138184
ep8_train_time 47.08125162124634
Test Epoch8 threshold 0.4 Acc 0.9138157894736842, AUC 0.9806085824966431, avg_entr 0.043970782309770584
ep8_t0.4_test_time 0.25832128524780273
gc 0
Train Epoch9 Acc 0.239025 (28683/120000), AUC 0.5679360032081604
ep9_train_time 47.01995539665222
Test Epoch9 threshold 0.4 Acc 0.9159539473684211, AUC 0.9805417656898499, avg_entr 0.04096834734082222
ep9_t0.4_test_time 0.253314733505249
Best AUC 0.9808248281478882
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adp_pad175_t0.4_m1//ag_news_lstmal_l5_prefix.pt
[[1378   50   72   32]
 [  20 1474    3   10]
 [  39   12 1332  117]
 [  44   12  108 1377]]
Figure(640x480)
tensor([0.0651, 0.0004, 0.0118,  ..., 0.0004, 0.0031, 0.0187])
[[ 807   20   15  690]
 [1219   95   44  149]
 [1221   12   36  231]
 [1411   23    4  103]]
Figure(640x480)
tensor([1.2169, 1.1267, 1.1614,  ..., 1.4127, 1.2683, 1.3154])
[[   1  612    0  919]
 [   5  568    0  934]
 [   1  161    0 1338]
 [   0  117    0 1424]]
Figure(640x480)
tensor([1.3008, 1.2382, 1.2696,  ..., 1.2938, 1.1885, 1.1922])
[[1012  351   85   84]
 [1119  367    0   21]
 [1228  226    6   40]
 [1449   78    1   13]]
Figure(640x480)
tensor([1.4630, 1.4250, 1.4386,  ..., 1.3860, 1.3918, 1.4118])
[[  20 1467   30   15]
 [  91 1376   27   13]
 [   1 1473   22    4]
 [   3 1515    5   18]]
Figure(640x480)
tensor([1.4383, 1.4396, 1.4382,  ..., 1.4456, 1.4228, 1.4347])
