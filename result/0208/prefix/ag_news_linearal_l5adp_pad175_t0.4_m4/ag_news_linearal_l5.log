total count words 102019
vocab size 30000
found 26754 words in glove
Load ckpt from ckpt/ag_news_linearal_l5adp_pad175_t0.4_m3//ag_news_linearal_l5_prefix.pt
model: LinearModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.0.weight 90000
layers.1.enc.f.0.bias 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.0.weight 90000
layers.2.enc.f.0.bias 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.0.weight 90000
layers.3.enc.f.0.bias 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.0.weight 90000
layers.4.enc.f.0.bias 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 9687092
Start Training
train_mask {0, 1, 2, 3}
gc 9
Train Epoch0 Acc 0.03228333333333333 (3874/120000), AUC 0.4246070981025696
ep0_train_time 9.959952354431152
Test Epoch0 threshold 0.4 Acc 0.915296052631579, AUC 0.9805185198783875, avg_entr 0.025519849732518196
ep0_t0.4_test_time 0.2585723400115967
Save ckpt to ckpt/ag_news_linearal_l5adp_pad175_t0.4_m4//ag_news_linearal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.03771666666666667 (4526/120000), AUC 0.41539865732192993
ep1_train_time 11.29143762588501
Test Epoch1 threshold 0.4 Acc 0.9154605263157894, AUC 0.9802846908569336, avg_entr 0.02577056549489498
ep1_t0.4_test_time 0.322345495223999
gc 0
Train Epoch2 Acc 0.13013333333333332 (15616/120000), AUC 0.4266713559627533
ep2_train_time 9.813988208770752
Test Epoch2 threshold 0.4 Acc 0.9151315789473684, AUC 0.9800862073898315, avg_entr 0.02545449323952198
ep2_t0.4_test_time 0.25829529762268066
gc 0
Train Epoch3 Acc 0.223325 (26799/120000), AUC 0.43515652418136597
ep3_train_time 11.536043167114258
Test Epoch3 threshold 0.4 Acc 0.9144736842105263, AUC 0.9800657629966736, avg_entr 0.025459418073296547
ep3_t0.4_test_time 0.3181803226470947
gc 0
Train Epoch4 Acc 0.2814583333333333 (33775/120000), AUC 0.4541016221046448
ep4_train_time 13.917465209960938
Test Epoch4 threshold 0.4 Acc 0.9144736842105263, AUC 0.9799491167068481, avg_entr 0.02573966793715954
ep4_t0.4_test_time 0.43193721771240234
gc 0
Train Epoch5 Acc 0.29568333333333335 (35482/120000), AUC 0.4642106294631958
ep5_train_time 13.155345439910889
Test Epoch5 threshold 0.4 Acc 0.9139802631578947, AUC 0.9798364639282227, avg_entr 0.024982493370771408
ep5_t0.4_test_time 0.31226372718811035
gc 0
Train Epoch6 Acc 0.310575 (37269/120000), AUC 0.4682612717151642
ep6_train_time 11.477377891540527
Test Epoch6 threshold 0.4 Acc 0.912828947368421, AUC 0.9796587228775024, avg_entr 0.02578711323440075
ep6_t0.4_test_time 0.3077411651611328
gc 0
Train Epoch7 Acc 0.32959166666666667 (39551/120000), AUC 0.47143009305000305
ep7_train_time 11.747133016586304
Test Epoch7 threshold 0.4 Acc 0.9126644736842106, AUC 0.9795839786529541, avg_entr 0.02557799220085144
ep7_t0.4_test_time 0.3841524124145508
gc 0
Train Epoch8 Acc 0.3579 (42948/120000), AUC 0.47468286752700806
ep8_train_time 15.300374746322632
Test Epoch8 threshold 0.4 Acc 0.9121710526315789, AUC 0.9795226454734802, avg_entr 0.025634491816163063
ep8_t0.4_test_time 0.38278746604919434
gc 0
Train Epoch9 Acc 0.3844 (46128/120000), AUC 0.4774567186832428
ep9_train_time 15.040124654769897
Test Epoch9 threshold 0.4 Acc 0.9126644736842106, AUC 0.9794257283210754, avg_entr 0.02529490552842617
ep9_t0.4_test_time 0.37831926345825195
Best AUC 0.9805185198783875
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_linearal_l5adp_pad175_t0.4_m4//ag_news_linearal_l5_prefix.pt
[[1373   50   76   33]
 [  13 1477    9    8]
 [  35   12 1340  113]
 [  39   12  114 1376]]
Figure(640x480)
tensor([8.9616e-04, 5.1947e-08, 2.1057e-04,  ..., 2.8815e-08, 7.5073e-06,
        5.9099e-05])
[[1375   50   75   32]
 [  13 1477    9    8]
 [  35   12 1341  112]
 [  38   15  114 1374]]
Figure(640x480)
tensor([1.1247e-03, 4.1242e-07, 2.6206e-04,  ..., 3.6232e-08, 8.4023e-06,
        2.3575e-04])
[[1376   50   75   31]
 [  14 1476    9    8]
 [  36   13 1337  114]
 [  39   15  112 1375]]
Figure(640x480)
tensor([6.7142e-04, 7.1527e-07, 9.8118e-05,  ..., 2.4903e-08, 3.6562e-06,
        1.4795e-04])
[[1378   50   72   32]
 [  13 1477    9    8]
 [  37   14 1337  112]
 [  36   14  115 1376]]
Figure(640x480)
tensor([6.5494e-04, 5.2936e-07, 7.6318e-05,  ..., 3.0576e-08, 3.3781e-06,
        5.6176e-05])
[[  58 1445   29    0]
 [ 200  212 1095    0]
 [1318  177    5    0]
 [ 119 1400   22    0]]
Figure(640x480)
tensor([0.7539, 0.8745, 0.7853,  ..., 0.5882, 0.6737, 0.4539])
