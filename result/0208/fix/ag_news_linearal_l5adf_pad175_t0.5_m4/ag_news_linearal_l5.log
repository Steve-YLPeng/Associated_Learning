total count words 102019
vocab size 30000
found 26754 words in glove
Load ckpt from ckpt/ag_news_linearal_l5adf_pad175_t0.5_m3//ag_news_linearal_l5_prefix.pt
model: LinearModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.0.weight 90000
layers.1.enc.f.0.bias 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.0.weight 90000
layers.2.enc.f.0.bias 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.0.weight 90000
layers.3.enc.f.0.bias 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.0.weight 90000
layers.4.enc.f.0.bias 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 9687092
Start Training
train_mask {0, 1, 2, 3}
gc 9
Train Epoch0 Acc 0.03249166666666667 (3899/120000), AUC 0.22954061627388
ep0_train_time 9.938017129898071
Test Epoch0 threshold 0.5 Acc 0.9144736842105263, AUC 0.9806569814682007, avg_entr 0.025950906798243523
ep0_t0.5_test_time 0.25870800018310547
Save ckpt to ckpt/ag_news_linearal_l5adf_pad175_t0.5_m4//ag_news_linearal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.031641666666666665 (3797/120000), AUC 0.1666363775730133
ep1_train_time 9.695180177688599
Test Epoch1 threshold 0.5 Acc 0.9166118421052631, AUC 0.9805969595909119, avg_entr 0.02677036263048649
ep1_t0.5_test_time 0.2576565742492676
gc 0
Train Epoch2 Acc 0.03244166666666667 (3893/120000), AUC 0.16160383820533752
ep2_train_time 9.592432975769043
Test Epoch2 threshold 0.5 Acc 0.9138157894736842, AUC 0.9802996516227722, avg_entr 0.02690787799656391
ep2_t0.5_test_time 0.2577342987060547
gc 0
Train Epoch3 Acc 0.030025 (3603/120000), AUC 0.15371523797512054
ep3_train_time 9.524354696273804
Test Epoch3 threshold 0.5 Acc 0.9133223684210526, AUC 0.9802496433258057, avg_entr 0.026106176897883415
ep3_t0.5_test_time 0.2557373046875
gc 0
Train Epoch4 Acc 0.026475 (3177/120000), AUC 0.1641659140586853
ep4_train_time 9.433599472045898
Test Epoch4 threshold 0.5 Acc 0.9157894736842105, AUC 0.9799513816833496, avg_entr 0.026121802628040314
ep4_t0.5_test_time 0.25762343406677246
gc 0
Train Epoch5 Acc 0.026566666666666666 (3188/120000), AUC 0.18028303980827332
ep5_train_time 9.83621883392334
Test Epoch5 threshold 0.5 Acc 0.9139802631578947, AUC 0.9799131155014038, avg_entr 0.02612624689936638
ep5_t0.5_test_time 0.2570977210998535
gc 0
Train Epoch6 Acc 0.030808333333333333 (3697/120000), AUC 0.1842239499092102
ep6_train_time 9.672689199447632
Test Epoch6 threshold 0.5 Acc 0.9139802631578947, AUC 0.9798334836959839, avg_entr 0.02548673003911972
ep6_t0.5_test_time 0.2587306499481201
gc 0
Train Epoch7 Acc 0.032933333333333335 (3952/120000), AUC 0.18441182374954224
ep7_train_time 9.667514324188232
Test Epoch7 threshold 0.5 Acc 0.9133223684210526, AUC 0.9797420501708984, avg_entr 0.02644192986190319
ep7_t0.5_test_time 0.2584195137023926
gc 0
Train Epoch8 Acc 0.030933333333333334 (3712/120000), AUC 0.1822025179862976
ep8_train_time 9.570367574691772
Test Epoch8 threshold 0.5 Acc 0.9125, AUC 0.9796114563941956, avg_entr 0.02665039524435997
ep8_t0.5_test_time 0.2592153549194336
gc 0
Train Epoch9 Acc 0.029558333333333332 (3547/120000), AUC 0.1801438331604004
ep9_train_time 9.590530157089233
Test Epoch9 threshold 0.5 Acc 0.9129934210526316, AUC 0.9795421361923218, avg_entr 0.026068182662129402
ep9_t0.5_test_time 0.25644612312316895
Best AUC 0.9806569814682007
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_linearal_l5adf_pad175_t0.5_m4//ag_news_linearal_l5_prefix.pt
[[1388   50   63   31]
 [  18 1480    3    6]
 [  42   16 1333  109]
 [  49   20  111 1361]]
Figure(640x480)
tensor([3.6609e-03, 1.6088e-07, 8.4897e-04,  ..., 3.6319e-08, 1.2631e-05,
        8.3431e-05])
[[1380   51   70   31]
 [  17 1481    4    5]
 [  40   14 1334  112]
 [  51   19  108 1363]]
Figure(640x480)
tensor([3.0783e-03, 1.1106e-06, 6.8088e-04,  ..., 5.4309e-08, 6.7223e-06,
        3.6437e-05])
[[1389   51   61   31]
 [  16 1482    3    6]
 [  41   17 1334  108]
 [  51   20  110 1360]]
Figure(640x480)
tensor([3.1933e-03, 9.9288e-07, 7.0352e-04,  ..., 4.9410e-08, 7.9557e-06,
        2.2062e-05])
[[1389   51   61   31]
 [  16 1482    3    6]
 [  41   16 1333  110]
 [  52   20  107 1362]]
Figure(640x480)
tensor([3.6406e-03, 3.4678e-07, 5.5145e-04,  ..., 3.5592e-08, 4.7583e-06,
        3.1040e-05])
[[   0    0 1356  176]
 [   0    1   13 1493]
 [   0    0  194 1306]
 [   0    0 1462   79]]
Figure(640x480)
tensor([0.4044, 0.6791, 0.6332,  ..., 0.3970, 0.4528, 0.3749])
