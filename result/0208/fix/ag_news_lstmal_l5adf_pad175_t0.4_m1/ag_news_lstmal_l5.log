total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.25001666666666666 (30002/120000), AUC 0.4816892147064209
ep0_train_time 47.01482033729553
Test Epoch0 threshold 0.4 Acc 0.8995065789473684, AUC 0.9740291237831116, avg_entr 0.18161387741565704
ep0_t0.4_test_time 0.256026029586792
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.25 (30000/120000), AUC 0.46894699335098267
ep1_train_time 47.12930512428284
Test Epoch1 threshold 0.4 Acc 0.9115131578947369, AUC 0.9779794216156006, avg_entr 0.10409236699342728
ep1_t0.4_test_time 0.25323486328125
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.25 (30000/120000), AUC 0.4662039577960968
ep2_train_time 47.051151514053345
Test Epoch2 threshold 0.4 Acc 0.9146381578947368, AUC 0.9794521927833557, avg_entr 0.07994052022695541
ep2_t0.4_test_time 0.25479888916015625
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.25 (30000/120000), AUC 0.4655693471431732
ep3_train_time 47.12690091133118
Test Epoch3 threshold 0.4 Acc 0.9166118421052631, AUC 0.9802384376525879, avg_entr 0.06706959754228592
ep3_t0.4_test_time 0.25337958335876465
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.25 (30000/120000), AUC 0.4658335745334625
ep4_train_time 47.048293113708496
Test Epoch4 threshold 0.4 Acc 0.9161184210526315, AUC 0.9806499481201172, avg_entr 0.059263039380311966
ep4_t0.4_test_time 0.25481724739074707
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 4
gc 0
Train Epoch5 Acc 0.25 (30000/120000), AUC 0.4672243595123291
ep5_train_time 47.151957750320435
Test Epoch5 threshold 0.4 Acc 0.9164473684210527, AUC 0.9808269739151001, avg_entr 0.05212140455842018
ep5_t0.4_test_time 0.25336623191833496
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 5
gc 0
Train Epoch6 Acc 0.25 (30000/120000), AUC 0.4684683680534363
ep6_train_time 47.108885526657104
Test Epoch6 threshold 0.4 Acc 0.9144736842105263, AUC 0.980750322341919, avg_entr 0.04952361807227135
ep6_t0.4_test_time 0.2560563087463379
gc 0
Train Epoch7 Acc 0.25 (30000/120000), AUC 0.4698382616043091
ep7_train_time 47.02893257141113
Test Epoch7 threshold 0.4 Acc 0.9136513157894737, AUC 0.9807209968566895, avg_entr 0.044954441487789154
ep7_t0.4_test_time 0.2532169818878174
gc 0
Train Epoch8 Acc 0.25 (30000/120000), AUC 0.4713071584701538
ep8_train_time 47.147377014160156
Test Epoch8 threshold 0.4 Acc 0.9166118421052631, AUC 0.9805637001991272, avg_entr 0.04278396815061569
ep8_t0.4_test_time 0.2535703182220459
gc 0
Train Epoch9 Acc 0.25 (30000/120000), AUC 0.47319212555885315
ep9_train_time 47.16308236122131
Test Epoch9 threshold 0.4 Acc 0.9161184210526315, AUC 0.9803271293640137, avg_entr 0.03979000821709633
ep9_t0.4_test_time 0.25446081161499023
Best AUC 0.9808269739151001
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad175_t0.4_m1//ag_news_lstmal_l5_prefix.pt
[[1357   55   80   40]
 [   6 1485    6   10]
 [  32   15 1340  113]
 [  31   16  104 1390]]
Figure(640x480)
tensor([0.0331, 0.0008, 0.0243,  ..., 0.0007, 0.0019, 0.0351])
[[ 918  202  358   54]
 [1250  115   78   64]
 [ 822  474  178   26]
 [1152  143  188   58]]
Figure(640x480)
tensor([1.4052, 1.4174, 1.4219,  ..., 1.2243, 1.3198, 1.3454])
[[ 146   71  303 1012]
 [  40   78  365 1024]
 [ 428  111  172  789]
 [ 217   17  267 1040]]
Figure(640x480)
tensor([1.4262, 1.3609, 1.4420,  ..., 1.4084, 1.3712, 1.4184])
[[ 105    0 1397   30]
 [ 293    0 1214    0]
 [ 403    0 1080   17]
 [ 183    1 1353    4]]
Figure(640x480)
tensor([1.4234, 1.3618, 1.4451,  ..., 1.3779, 1.4001, 1.3855])
[[   0    0 1532    0]
 [   0    0 1507    0]
 [   0    0 1500    0]
 [   0    0 1541    0]]
Figure(640x480)
tensor([1.3392, 1.2990, 1.3048,  ..., 1.2944, 1.3055, 1.3333])
