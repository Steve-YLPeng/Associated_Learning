total count words 102019
vocab size 30000
found 26754 words in glove
Load ckpt from ckpt/ag_news_linearal_l5adf_pad175_t0.1_m3//ag_news_linearal_l5_prefix.pt
model: LinearModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.0.weight 90000
layers.1.enc.f.0.bias 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.0.weight 90000
layers.2.enc.f.0.bias 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.0.weight 90000
layers.3.enc.f.0.bias 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.0.weight 90000
layers.4.enc.f.0.bias 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 9687092
Start Training
train_mask {0, 1, 2, 3}
gc 9
Train Epoch0 Acc 0.27800833333333336 (33361/120000), AUC 0.6508363485336304
ep0_train_time 9.800479650497437
Test Epoch0 threshold 0.1 Acc 0.9166118421052631, AUC 0.9807093739509583, avg_entr 0.023159684613347054
ep0_t0.1_test_time 0.27363014221191406
Save ckpt to ckpt/ag_news_linearal_l5adf_pad175_t0.1_m4//ag_news_linearal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.3103166666666667 (37238/120000), AUC 0.6043840050697327
ep1_train_time 9.411929845809937
Test Epoch1 threshold 0.1 Acc 0.9159539473684211, AUC 0.9807012677192688, avg_entr 0.022532088682055473
ep1_t0.1_test_time 0.2739260196685791
gc 0
Train Epoch2 Acc 0.321175 (38541/120000), AUC 0.629484236240387
ep2_train_time 9.428248167037964
Test Epoch2 threshold 0.1 Acc 0.9136513157894737, AUC 0.9805289506912231, avg_entr 0.019084317609667778
ep2_t0.1_test_time 0.27216482162475586
gc 0
Train Epoch3 Acc 0.18246666666666667 (21896/120000), AUC 0.708304226398468
ep3_train_time 9.464194536209106
Test Epoch3 threshold 0.1 Acc 0.9149671052631579, AUC 0.980409562587738, avg_entr 0.016652047634124756
ep3_t0.1_test_time 0.2720654010772705
gc 0
Train Epoch4 Acc 0.10095833333333333 (12115/120000), AUC 0.747933030128479
ep4_train_time 9.430161714553833
Test Epoch4 threshold 0.1 Acc 0.9123355263157895, AUC 0.9800845384597778, avg_entr 0.012778673321008682
ep4_t0.1_test_time 0.27214813232421875
gc 0
Train Epoch5 Acc 0.07135 (8562/120000), AUC 0.7388888597488403
ep5_train_time 9.467756509780884
Test Epoch5 threshold 0.1 Acc 0.9115131578947369, AUC 0.9800490736961365, avg_entr 0.013599514029920101
ep5_t0.1_test_time 0.27283811569213867
gc 0
Train Epoch6 Acc 0.0565 (6780/120000), AUC 0.7228191494941711
ep6_train_time 9.419189214706421
Test Epoch6 threshold 0.1 Acc 0.9120065789473685, AUC 0.9798483848571777, avg_entr 0.012492557987570763
ep6_t0.1_test_time 0.27181553840637207
gc 0
Train Epoch7 Acc 0.04488333333333333 (5386/120000), AUC 0.7043102383613586
ep7_train_time 9.373089075088501
Test Epoch7 threshold 0.1 Acc 0.9116776315789473, AUC 0.9796335697174072, avg_entr 0.01184587087482214
ep7_t0.1_test_time 0.27239251136779785
gc 0
Train Epoch8 Acc 0.03896666666666666 (4676/120000), AUC 0.6879225969314575
ep8_train_time 9.43119502067566
Test Epoch8 threshold 0.1 Acc 0.9110197368421052, AUC 0.979577898979187, avg_entr 0.012589182704687119
ep8_t0.1_test_time 0.272205114364624
gc 0
Train Epoch9 Acc 0.036525 (4383/120000), AUC 0.6776323914527893
ep9_train_time 9.512195587158203
Test Epoch9 threshold 0.1 Acc 0.9126644736842106, AUC 0.9795635342597961, avg_entr 0.011459281668066978
ep9_t0.1_test_time 0.2719290256500244
Best AUC 0.9807093739509583
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_linearal_l5adf_pad175_t0.1_m4//ag_news_linearal_l5_prefix.pt
[[1367   55   74   36]
 [   9 1484    7    7]
 [  35   17 1332  116]
 [  34   19   98 1390]]
Figure(640x480)
tensor([1.5152e-03, 1.6409e-07, 4.6430e-04,  ..., 3.9750e-08, 1.8810e-06,
        1.9126e-04])
[[1371   54   73   34]
 [  10 1480    8    9]
 [  36   18 1328  118]
 [  37   18  100 1386]]
Figure(640x480)
tensor([2.8094e-03, 1.1017e-06, 5.4469e-04,  ..., 6.5919e-08, 2.2660e-06,
        3.3647e-04])
[[1371   56   71   34]
 [   9 1478    8   12]
 [  36   17 1322  125]
 [  36   14   93 1398]]
Figure(640x480)
tensor([1.6353e-03, 6.9901e-07, 2.1879e-04,  ..., 6.5599e-08, 1.6826e-06,
        2.0692e-04])
[[1370   55   69   38]
 [   9 1482    4   12]
 [  41   17 1317  125]
 [  34   13   96 1398]]
Figure(640x480)
tensor([2.5735e-03, 1.7508e-06, 2.2805e-04,  ..., 7.3789e-08, 2.0067e-06,
        1.3334e-04])
[[1456   43    0   33]
 [1189  318    0    0]
 [  84 1307    0  109]
 [ 797  733    1   10]]
Figure(640x480)
tensor([1.2898, 1.0427, 1.2548,  ..., 0.9598, 1.2825, 0.7289])
