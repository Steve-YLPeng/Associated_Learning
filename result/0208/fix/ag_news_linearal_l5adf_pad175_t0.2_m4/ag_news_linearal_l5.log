total count words 102019
vocab size 30000
found 26754 words in glove
Load ckpt from ckpt/ag_news_linearal_l5adf_pad175_t0.2_m3//ag_news_linearal_l5_prefix.pt
model: LinearModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.0.weight 90000
layers.1.enc.f.0.bias 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.0.weight 90000
layers.2.enc.f.0.bias 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.0.weight 90000
layers.3.enc.f.0.bias 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.0.weight 90000
layers.4.enc.f.0.bias 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 9687092
Start Training
train_mask {0, 1, 2, 3}
gc 9
Train Epoch0 Acc 0.29505 (35406/120000), AUC 0.57035893201828
ep0_train_time 9.891236782073975
Test Epoch0 threshold 0.2 Acc 0.9159539473684211, AUC 0.9807336330413818, avg_entr 0.024142857640981674
ep0_t0.2_test_time 0.27525782585144043
Save ckpt to ckpt/ag_news_linearal_l5adf_pad175_t0.2_m4//ag_news_linearal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.29459166666666664 (35351/120000), AUC 0.6008832454681396
ep1_train_time 9.542813062667847
Test Epoch1 threshold 0.2 Acc 0.9169407894736842, AUC 0.9806914329528809, avg_entr 0.022720281034708023
ep1_t0.2_test_time 0.27437305450439453
gc 0
Train Epoch2 Acc 0.22886666666666666 (27464/120000), AUC 0.5784400105476379
ep2_train_time 9.489337682723999
Test Epoch2 threshold 0.2 Acc 0.9151315789473684, AUC 0.9804591536521912, avg_entr 0.020456792786717415
ep2_t0.2_test_time 0.2737162113189697
gc 0
Train Epoch3 Acc 0.14531666666666668 (17438/120000), AUC 0.5196828842163086
ep3_train_time 9.435076713562012
Test Epoch3 threshold 0.2 Acc 0.9133223684210526, AUC 0.9801937341690063, avg_entr 0.019309988245368004
ep3_t0.2_test_time 0.27309679985046387
gc 0
Train Epoch4 Acc 0.17771666666666666 (21326/120000), AUC 0.4931842088699341
ep4_train_time 9.35263204574585
Test Epoch4 threshold 0.2 Acc 0.9154605263157894, AUC 0.9802194237709045, avg_entr 0.01843114197254181
ep4_t0.2_test_time 0.2731027603149414
gc 0
Train Epoch5 Acc 0.20788333333333334 (24946/120000), AUC 0.4894651174545288
ep5_train_time 9.349061012268066
Test Epoch5 threshold 0.2 Acc 0.9141447368421053, AUC 0.9800899624824524, avg_entr 0.018095089122653008
ep5_t0.2_test_time 0.27231431007385254
gc 0
Train Epoch6 Acc 0.2386 (28632/120000), AUC 0.48784592747688293
ep6_train_time 9.450790643692017
Test Epoch6 threshold 0.2 Acc 0.9143092105263158, AUC 0.9799206256866455, avg_entr 0.019054165109992027
ep6_t0.2_test_time 0.2729012966156006
gc 0
Train Epoch7 Acc 0.2667083333333333 (32005/120000), AUC 0.4848414659500122
ep7_train_time 9.51025652885437
Test Epoch7 threshold 0.2 Acc 0.9146381578947368, AUC 0.9798648357391357, avg_entr 0.017712946981191635
ep7_t0.2_test_time 0.2724919319152832
gc 0
Train Epoch8 Acc 0.286175 (34341/120000), AUC 0.4830707907676697
ep8_train_time 9.44987416267395
Test Epoch8 threshold 0.2 Acc 0.9123355263157895, AUC 0.9796569347381592, avg_entr 0.01789012923836708
ep8_t0.2_test_time 0.27222752571105957
gc 0
Train Epoch9 Acc 0.29304166666666664 (35165/120000), AUC 0.4818000793457031
ep9_train_time 9.485283613204956
Test Epoch9 threshold 0.2 Acc 0.9141447368421053, AUC 0.9796482920646667, avg_entr 0.018169771879911423
ep9_t0.2_test_time 0.27205395698547363
Best AUC 0.9807336330413818
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_linearal_l5adf_pad175_t0.2_m4//ag_news_linearal_l5_prefix.pt
[[1382   50   68   32]
 [  14 1479    6    8]
 [  37   16 1331  116]
 [  41   19  100 1381]]
Figure(640x480)
tensor([1.8039e-03, 1.0927e-07, 2.4671e-04,  ..., 3.7125e-08, 4.6501e-06,
        2.1132e-04])
[[1380   50   69   33]
 [  14 1478    6    9]
 [  38   13 1332  117]
 [  37   18  101 1385]]
Figure(640x480)
tensor([1.6421e-03, 3.4647e-07, 3.1208e-04,  ..., 5.6136e-08, 8.0405e-06,
        4.9552e-04])
[[1384   50   65   33]
 [  15 1476    6   10]
 [  39   15 1321  125]
 [  41   18   93 1389]]
Figure(640x480)
tensor([1.2964e-03, 4.5242e-07, 1.5040e-04,  ..., 5.9013e-08, 6.1039e-06,
        5.5794e-04])
[[1384   50   65   33]
 [  13 1479    6    9]
 [  42   15 1317  126]
 [  38   18   90 1395]]
Figure(640x480)
tensor([1.2897e-03, 1.6862e-07, 1.0979e-04,  ..., 6.0240e-08, 5.2526e-06,
        3.3549e-04])
[[   1   90   22 1419]
 [   0 1466   32    9]
 [   9    9  157 1325]
 [  81   24 1197  239]]
Figure(640x480)
tensor([0.7979, 0.6957, 1.0965,  ..., 0.4026, 0.9583, 0.2522])
