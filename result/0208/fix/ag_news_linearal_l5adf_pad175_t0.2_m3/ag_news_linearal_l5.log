total count words 102019
vocab size 30000
found 26754 words in glove
Load ckpt from ckpt/ag_news_linearal_l5adf_pad175_t0.2_m2//ag_news_linearal_l5_prefix.pt
model: LinearModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.0.weight 90000
layers.1.enc.f.0.bias 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.0.weight 90000
layers.2.enc.f.0.bias 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.0.weight 90000
layers.3.enc.f.0.bias 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.0.weight 90000
layers.4.enc.f.0.bias 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 9687092
Start Training
train_mask {0, 1, 2}
gc 9
Train Epoch0 Acc 0.18395833333333333 (22075/120000), AUC 0.40217655897140503
ep0_train_time 9.408638000488281
Test Epoch0 threshold 0.2 Acc 0.9154605263157894, AUC 0.9809380769729614, avg_entr 0.02431885525584221
ep0_t0.2_test_time 0.26672792434692383
Save ckpt to ckpt/ag_news_linearal_l5adf_pad175_t0.2_m3//ag_news_linearal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.18691666666666668 (22430/120000), AUC 0.41395819187164307
ep1_train_time 9.088189363479614
Test Epoch1 threshold 0.2 Acc 0.9139802631578947, AUC 0.980765163898468, avg_entr 0.024388320744037628
ep1_t0.2_test_time 0.26619839668273926
gc 0
Train Epoch2 Acc 0.16720833333333332 (20065/120000), AUC 0.455091655254364
ep2_train_time 8.894922971725464
Test Epoch2 threshold 0.2 Acc 0.9171052631578948, AUC 0.9805420637130737, avg_entr 0.024908071383833885
ep2_t0.2_test_time 0.27987146377563477
gc 0
Train Epoch3 Acc 0.16651666666666667 (19982/120000), AUC 0.5062301754951477
ep3_train_time 8.922008037567139
Test Epoch3 threshold 0.2 Acc 0.9146381578947368, AUC 0.9803422093391418, avg_entr 0.024030685424804688
ep3_t0.2_test_time 0.2651255130767822
gc 0
Train Epoch4 Acc 0.21771666666666667 (26126/120000), AUC 0.5321172475814819
ep4_train_time 9.044784545898438
Test Epoch4 threshold 0.2 Acc 0.9149671052631579, AUC 0.9802669286727905, avg_entr 0.023471491411328316
ep4_t0.2_test_time 0.26500940322875977
gc 0
Train Epoch5 Acc 0.27224166666666666 (32669/120000), AUC 0.5489387512207031
ep5_train_time 8.930201530456543
Test Epoch5 threshold 0.2 Acc 0.9134868421052632, AUC 0.9801549911499023, avg_entr 0.022259842604398727
ep5_t0.2_test_time 0.264904260635376
gc 0
Train Epoch6 Acc 0.2999583333333333 (35995/120000), AUC 0.5598772168159485
ep6_train_time 9.111592292785645
Test Epoch6 threshold 0.2 Acc 0.9136513157894737, AUC 0.9800510406494141, avg_entr 0.022503526881337166
ep6_t0.2_test_time 0.2647264003753662
gc 0
Train Epoch7 Acc 0.322275 (38673/120000), AUC 0.5664365291595459
ep7_train_time 8.915786743164062
Test Epoch7 threshold 0.2 Acc 0.9141447368421053, AUC 0.9800119400024414, avg_entr 0.021719150245189667
ep7_t0.2_test_time 0.26448726654052734
gc 0
Train Epoch8 Acc 0.3334083333333333 (40009/120000), AUC 0.5659247040748596
ep8_train_time 8.940124273300171
Test Epoch8 threshold 0.2 Acc 0.9141447368421053, AUC 0.980054497718811, avg_entr 0.021504973992705345
ep8_t0.2_test_time 0.2646300792694092
gc 0
Train Epoch9 Acc 0.33689166666666664 (40427/120000), AUC 0.5652412176132202
ep9_train_time 9.125193119049072
Test Epoch9 threshold 0.2 Acc 0.9143092105263158, AUC 0.9798372387886047, avg_entr 0.020816192030906677
ep9_t0.2_test_time 0.26517271995544434
Best AUC 0.9809380769729614
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_linearal_l5adf_pad175_t0.2_m3//ag_news_linearal_l5_prefix.pt
[[1363   55   81   33]
 [   8 1480    9   10]
 [  32   12 1348  108]
 [  34   17  117 1373]]
Figure(640x480)
tensor([5.4587e-04, 2.3090e-07, 4.4433e-04,  ..., 1.1986e-07, 8.5583e-06,
        1.1982e-04])
[[1366   51   83   32]
 [  11 1479    7   10]
 [  32   12 1349  107]
 [  34   16  115 1376]]
Figure(640x480)
tensor([5.9942e-04, 7.0876e-07, 5.3512e-04,  ..., 2.0204e-07, 3.1968e-05,
        4.5296e-04])
[[1368   51   79   34]
 [  11 1479    7   10]
 [  33   12 1346  109]
 [  35   15  112 1379]]
Figure(640x480)
tensor([4.0223e-04, 1.1678e-06, 3.3704e-04,  ..., 3.1946e-07, 4.3113e-05,
        5.7220e-04])
[[1509    5   18    0]
 [ 799    0  708    0]
 [1396   48   56    0]
 [ 288  290  963    0]]
Figure(640x480)
tensor([0.4257, 0.5295, 0.8416,  ..., 0.8022, 0.8068, 0.4216])
[[  71    0    0 1461]
 [   0    2   23 1482]
 [1168    0    0  332]
 [ 384   23    0 1134]]
Figure(640x480)
tensor([0.9493, 1.0750, 1.2732,  ..., 0.6990, 0.9991, 0.7367])
