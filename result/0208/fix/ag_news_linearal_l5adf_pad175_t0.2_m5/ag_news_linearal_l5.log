total count words 102019
vocab size 30000
found 26754 words in glove
Load ckpt from ckpt/ag_news_linearal_l5adf_pad175_t0.2_m4//ag_news_linearal_l5_prefix.pt
model: LinearModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.0.weight 90000
layers.1.enc.f.0.bias 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.0.weight 90000
layers.2.enc.f.0.bias 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.0.weight 90000
layers.3.enc.f.0.bias 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.0.weight 90000
layers.4.enc.f.0.bias 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 9687092
Start Training
train_mask {0, 1, 2, 3, 4}
gc 9
Train Epoch0 Acc 0.9109166666666667 (109310/120000), AUC 0.9846904277801514
ep0_train_time 10.40654468536377
Test Epoch0 threshold 0.2 Acc 0.9177631578947368, AUC 0.9805480241775513, avg_entr 0.022238269448280334
ep0_t0.2_test_time 0.28331446647644043
Save ckpt to ckpt/ag_news_linearal_l5adf_pad175_t0.2_m5//ag_news_linearal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.949 (113880/120000), AUC 0.9929947853088379
ep1_train_time 9.836435317993164
Test Epoch1 threshold 0.2 Acc 0.912828947368421, AUC 0.9804037809371948, avg_entr 0.020559918135404587
ep1_t0.2_test_time 0.27997779846191406
gc 0
Train Epoch2 Acc 0.950675 (114081/120000), AUC 0.9932548999786377
ep2_train_time 10.014072179794312
Test Epoch2 threshold 0.2 Acc 0.915296052631579, AUC 0.980195164680481, avg_entr 0.017956670373678207
ep2_t0.2_test_time 0.2795979976654053
gc 0
Train Epoch3 Acc 0.9516166666666667 (114194/120000), AUC 0.9933422803878784
ep3_train_time 9.97563099861145
Test Epoch3 threshold 0.2 Acc 0.9157894736842105, AUC 0.9801135063171387, avg_entr 0.01803329959511757
ep3_t0.2_test_time 0.2790100574493408
gc 0
Train Epoch4 Acc 0.952575 (114309/120000), AUC 0.993747353553772
ep4_train_time 9.885890245437622
Test Epoch4 threshold 0.2 Acc 0.9141447368421053, AUC 0.980023980140686, avg_entr 0.017739012837409973
ep4_t0.2_test_time 0.2782912254333496
gc 0
Train Epoch5 Acc 0.9546416666666667 (114557/120000), AUC 0.9944372177124023
ep5_train_time 9.860312700271606
Test Epoch5 threshold 0.2 Acc 0.9133223684210526, AUC 0.9798327684402466, avg_entr 0.018023965880274773
ep5_t0.2_test_time 0.27721476554870605
gc 0
Train Epoch6 Acc 0.9548916666666667 (114587/120000), AUC 0.9945298433303833
ep6_train_time 9.949845790863037
Test Epoch6 threshold 0.2 Acc 0.9143092105263158, AUC 0.9797204732894897, avg_entr 0.01784096099436283
ep6_t0.2_test_time 0.2768094539642334
gc 0
Train Epoch7 Acc 0.9555083333333333 (114661/120000), AUC 0.9947371482849121
ep7_train_time 9.866787433624268
Test Epoch7 threshold 0.2 Acc 0.9121710526315789, AUC 0.979610025882721, avg_entr 0.0177143607288599
ep7_t0.2_test_time 0.27750539779663086
gc 0
Train Epoch8 Acc 0.9561083333333333 (114733/120000), AUC 0.9948247671127319
ep8_train_time 9.853157043457031
Test Epoch8 threshold 0.2 Acc 0.9138157894736842, AUC 0.979659914970398, avg_entr 0.01675945147871971
ep8_t0.2_test_time 0.27826523780822754
gc 0
Train Epoch9 Acc 0.956875 (114825/120000), AUC 0.9951590299606323
ep9_train_time 10.089253187179565
Test Epoch9 threshold 0.2 Acc 0.9111842105263158, AUC 0.9794833660125732, avg_entr 0.01693756692111492
ep9_t0.2_test_time 0.2753570079803467
Best AUC 0.9805480241775513
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_linearal_l5adf_pad175_t0.2_m5//ag_news_linearal_l5_prefix.pt
[[1379   50   69   34]
 [  13 1478    6   10]
 [  37   13 1330  120]
 [  38   13   97 1393]]
Figure(640x480)
tensor([3.2415e-03, 6.3771e-08, 1.7509e-04,  ..., 3.3475e-08, 3.3198e-06,
        3.8104e-04])
[[1376   50   73   33]
 [  13 1478    5   11]
 [  38   12 1331  119]
 [  37   16   97 1391]]
Figure(640x480)
tensor([2.8276e-03, 2.1878e-07, 2.7178e-04,  ..., 6.9562e-08, 7.5590e-06,
        6.7004e-04])
[[1384   50   65   33]
 [  14 1478    5   10]
 [  40   15 1317  128]
 [  39   16   88 1398]]
Figure(640x480)
tensor([2.0885e-03, 1.8493e-07, 1.0460e-04,  ..., 3.8223e-08, 4.0371e-06,
        9.4907e-04])
[[1388   50   60   34]
 [  14 1478    5   10]
 [  43   14 1313  130]
 [  37   14   88 1402]]
Figure(640x480)
tensor([1.3846e-03, 4.0952e-08, 2.0727e-05,  ..., 3.3454e-08, 1.2298e-06,
        1.2547e-04])
[[1384   50   63   35]
 [  14 1478    5   10]
 [  40   14 1323  123]
 [  38   16   92 1395]]
Figure(640x480)
tensor([6.7519e-04, 6.2222e-08, 2.1134e-05,  ..., 3.3413e-08, 1.0273e-06,
        6.7688e-05])
