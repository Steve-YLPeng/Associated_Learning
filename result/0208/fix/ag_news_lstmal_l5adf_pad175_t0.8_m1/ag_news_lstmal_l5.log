total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.25 (30000/120000), AUC 0.4856265187263489
ep0_train_time 46.833829402923584
Test Epoch0 threshold 0.8 Acc 0.9006578947368421, AUC 0.9740046858787537, avg_entr 0.17808924615383148
ep0_t0.8_test_time 0.25507307052612305
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.8_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.25 (30000/120000), AUC 0.487123966217041
ep1_train_time 47.05981922149658
Test Epoch1 threshold 0.8 Acc 0.9106907894736842, AUC 0.9777855277061462, avg_entr 0.10375818610191345
ep1_t0.8_test_time 0.2541348934173584
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.8_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.25 (30000/120000), AUC 0.4886170029640198
ep2_train_time 47.11031246185303
Test Epoch2 threshold 0.8 Acc 0.9149671052631579, AUC 0.9794453978538513, avg_entr 0.07819642126560211
ep2_t0.8_test_time 0.25234127044677734
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.8_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.25 (30000/120000), AUC 0.48947474360466003
ep3_train_time 47.21649956703186
Test Epoch3 threshold 0.8 Acc 0.9167763157894737, AUC 0.9801461696624756, avg_entr 0.06474009901285172
ep3_t0.8_test_time 0.2539188861846924
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.8_m1//ag_news_lstmal_l5_prefix.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.25 (30000/120000), AUC 0.48996400833129883
ep4_train_time 47.114089012145996
Test Epoch4 threshold 0.8 Acc 0.9167763157894737, AUC 0.9805344343185425, avg_entr 0.05881494656205177
ep4_t0.8_test_time 0.25382089614868164
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.8_m1//ag_news_lstmal_l5_prefix.pt  ,ep 4
gc 0
Train Epoch5 Acc 0.25 (30000/120000), AUC 0.4907990097999573
ep5_train_time 47.32318425178528
Test Epoch5 threshold 0.8 Acc 0.9164473684210527, AUC 0.9807071685791016, avg_entr 0.05404702574014664
ep5_t0.8_test_time 0.2645399570465088
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.8_m1//ag_news_lstmal_l5_prefix.pt  ,ep 5
gc 0
Train Epoch6 Acc 0.25 (30000/120000), AUC 0.491349995136261
ep6_train_time 47.572388648986816
Test Epoch6 threshold 0.8 Acc 0.9146381578947368, AUC 0.9805642366409302, avg_entr 0.04953254014253616
ep6_t0.8_test_time 0.2572023868560791
gc 0
Train Epoch7 Acc 0.25 (30000/120000), AUC 0.4920006990432739
ep7_train_time 47.57399344444275
Test Epoch7 threshold 0.8 Acc 0.9129934210526316, AUC 0.9806379675865173, avg_entr 0.04547033831477165
ep7_t0.8_test_time 0.2579843997955322
gc 0
Train Epoch8 Acc 0.25 (30000/120000), AUC 0.4930279850959778
ep8_train_time 47.55082178115845
Test Epoch8 threshold 0.8 Acc 0.9148026315789474, AUC 0.9804308414459229, avg_entr 0.04182369261980057
ep8_t0.8_test_time 0.2689955234527588
gc 0
Train Epoch9 Acc 0.25 (30000/120000), AUC 0.4938610792160034
ep9_train_time 47.54049062728882
Test Epoch9 threshold 0.8 Acc 0.915625, AUC 0.9803065061569214, avg_entr 0.04073520377278328
ep9_t0.8_test_time 0.2576882839202881
Best AUC 0.9807071685791016
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad175_t0.8_m1//ag_news_lstmal_l5_prefix.pt
[[1363   53   82   34]
 [   9 1480    9    9]
 [  29   10 1352  109]
 [  34   12  118 1377]]
Figure(640x480)
tensor([0.0315, 0.0006, 0.0264,  ..., 0.0007, 0.0054, 0.0245])
[[759  91 338 344]
 [444 302 154 607]
 [269 251 337 643]
 [481 159 114 787]]
Figure(640x480)
tensor([1.4237, 1.4249, 1.4184,  ..., 1.3338, 1.3081, 1.3180])
[[1123  349   60    0]
 [1147  289   71    0]
 [1028  435   37    0]
 [1314  154   73    0]]
Figure(640x480)
tensor([1.0166, 1.0504, 1.1387,  ..., 1.1159, 1.0044, 1.1051])
[[  27  349  981  175]
 [  26  511  728  242]
 [  31  550  621  298]
 [  41 1240  119  141]]
Figure(640x480)
tensor([1.3398, 1.3452, 1.3586,  ..., 1.3318, 1.3328, 1.3389])
[[   0 1532    0    0]
 [   0 1507    0    0]
 [   0 1500    0    0]
 [   0 1541    0    0]]
Figure(640x480)
tensor([1.2460, 1.2575, 1.2463,  ..., 1.2590, 1.2339, 1.2637])
