total count words 102019
vocab size 30000
found 26754 words in glove
Load ckpt from ckpt/ag_news_linearal_l5adf_pad175_t0.9_m3//ag_news_linearal_l5_prefix.pt
model: LinearModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.0.weight 90000
layers.1.enc.f.0.bias 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.0.weight 90000
layers.2.enc.f.0.bias 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.0.weight 90000
layers.3.enc.f.0.bias 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.0.weight 90000
layers.4.enc.f.0.bias 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 9687092
Start Training
train_mask {0, 1, 2, 3}
gc 9
Train Epoch0 Acc 0.45624166666666666 (54749/120000), AUC 0.6249657273292542
ep0_train_time 10.097044706344604
Test Epoch0 threshold 0.9 Acc 0.9169407894736842, AUC 0.980553388595581, avg_entr 0.02680794894695282
ep0_t0.9_test_time 0.25417351722717285
Save ckpt to ckpt/ag_news_linearal_l5adf_pad175_t0.9_m4//ag_news_linearal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.45126666666666665 (54152/120000), AUC 0.6218467354774475
ep1_train_time 9.593881607055664
Test Epoch1 threshold 0.9 Acc 0.9148026315789474, AUC 0.9804272651672363, avg_entr 0.026457279920578003
ep1_t0.9_test_time 0.24883699417114258
gc 0
Train Epoch2 Acc 0.3471666666666667 (41660/120000), AUC 0.6229363083839417
ep2_train_time 9.628341674804688
Test Epoch2 threshold 0.9 Acc 0.9138157894736842, AUC 0.9802753925323486, avg_entr 0.02651033364236355
ep2_t0.9_test_time 0.24889397621154785
gc 0
Train Epoch3 Acc 0.303275 (36393/120000), AUC 0.664793848991394
ep3_train_time 9.70200490951538
Test Epoch3 threshold 0.9 Acc 0.9151315789473684, AUC 0.980185866355896, avg_entr 0.02605227194726467
ep3_t0.9_test_time 0.24961376190185547
gc 0
Train Epoch4 Acc 0.29490833333333333 (35389/120000), AUC 0.7112072706222534
ep4_train_time 9.67188024520874
Test Epoch4 threshold 0.9 Acc 0.9110197368421052, AUC 0.9799719452857971, avg_entr 0.025480689480900764
ep4_t0.9_test_time 0.24928069114685059
gc 0
Train Epoch5 Acc 0.29609166666666664 (35531/120000), AUC 0.7259716987609863
ep5_train_time 9.706648826599121
Test Epoch5 threshold 0.9 Acc 0.9125, AUC 0.9797605872154236, avg_entr 0.025482259690761566
ep5_t0.9_test_time 0.24947786331176758
gc 0
Train Epoch6 Acc 0.3012666666666667 (36152/120000), AUC 0.7304902076721191
ep6_train_time 9.626844644546509
Test Epoch6 threshold 0.9 Acc 0.9113486842105263, AUC 0.9797465205192566, avg_entr 0.02576499991118908
ep6_t0.9_test_time 0.25228261947631836
gc 0
Train Epoch7 Acc 0.307475 (36897/120000), AUC 0.7378807663917542
ep7_train_time 9.588330030441284
Test Epoch7 threshold 0.9 Acc 0.9131578947368421, AUC 0.979626476764679, avg_entr 0.02646678313612938
ep7_t0.9_test_time 0.2498188018798828
gc 0
Train Epoch8 Acc 0.310775 (37293/120000), AUC 0.7423408031463623
ep8_train_time 9.60934591293335
Test Epoch8 threshold 0.9 Acc 0.9126644736842106, AUC 0.9794381856918335, avg_entr 0.02590123750269413
ep8_t0.9_test_time 0.24835586547851562
gc 0
Train Epoch9 Acc 0.31135 (37362/120000), AUC 0.7450788021087646
ep9_train_time 9.613589525222778
Test Epoch9 threshold 0.9 Acc 0.9121710526315789, AUC 0.9794690012931824, avg_entr 0.02610834501683712
ep9_t0.9_test_time 0.24886727333068848
Best AUC 0.980553388595581
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_linearal_l5adf_pad175_t0.9_m4//ag_news_linearal_l5_prefix.pt
[[1387   49   65   31]
 [  18 1473    4   12]
 [  42   11 1323  124]
 [  43   12   94 1392]]
Figure(640x480)
tensor([2.5680e-03, 7.0909e-08, 1.8048e-04,  ..., 5.0386e-08, 1.1891e-06,
        1.2873e-04])
[[1390   49   63   30]
 [  20 1470    4   13]
 [  41   11 1320  128]
 [  48   12   90 1391]]
Figure(640x480)
tensor([3.1461e-03, 4.3303e-07, 1.2047e-04,  ..., 7.0775e-08, 1.2953e-06,
        1.9338e-04])
[[1392   50   60   30]
 [  21 1469    4   13]
 [  47   12 1318  123]
 [  48   11   87 1395]]
Figure(640x480)
tensor([3.7281e-03, 5.2740e-07, 1.3503e-04,  ..., 7.9250e-08, 1.1854e-06,
        7.4189e-05])
[[1394   50   58   30]
 [  19 1471    4   13]
 [  47   13 1316  124]
 [  50   11   87 1393]]
Figure(640x480)
tensor([4.1595e-03, 1.6252e-07, 9.6146e-05,  ..., 7.1583e-08, 1.4100e-06,
        7.0808e-05])
[[   0   79 1453    0]
 [   0 1463   44    0]
 [   0  178 1320    2]
 [   0 1411  130    0]]
Figure(640x480)
tensor([0.8002, 0.3326, 0.4094,  ..., 0.5083, 0.4386, 0.6519])
