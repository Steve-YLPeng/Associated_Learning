total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.24425 (29310/120000), AUC 0.4893493354320526
ep0_train_time 47.01407718658447
Test Epoch0 threshold 0.2 Acc 0.8973684210526316, AUC 0.974011242389679, avg_entr 0.183546245098114
ep0_t0.2_test_time 0.2622716426849365
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.24795 (29754/120000), AUC 0.5209697484970093
ep1_train_time 47.2015106678009
Test Epoch1 threshold 0.2 Acc 0.9082236842105263, AUC 0.9778968095779419, avg_entr 0.10683382302522659
ep1_t0.2_test_time 0.25915956497192383
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.24915833333333334 (29899/120000), AUC 0.5290539264678955
ep2_train_time 47.169493436813354
Test Epoch2 threshold 0.2 Acc 0.915296052631579, AUC 0.9795969724655151, avg_entr 0.07936809957027435
ep2_t0.2_test_time 0.2596583366394043
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.24963333333333335 (29956/120000), AUC 0.5339969396591187
ep3_train_time 47.26778173446655
Test Epoch3 threshold 0.2 Acc 0.9171052631578948, AUC 0.9803012609481812, avg_entr 0.06712330877780914
ep3_t0.2_test_time 0.25978517532348633
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.249825 (29979/120000), AUC 0.5371994972229004
ep4_train_time 47.208818197250366
Test Epoch4 threshold 0.2 Acc 0.9175986842105263, AUC 0.9808337092399597, avg_entr 0.05869408696889877
ep4_t0.2_test_time 0.2597975730895996
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 4
gc 0
Train Epoch5 Acc 0.2501833333333333 (30022/120000), AUC 0.5395844578742981
ep5_train_time 47.2222626209259
Test Epoch5 threshold 0.2 Acc 0.9162828947368421, AUC 0.9809259176254272, avg_entr 0.05388077720999718
ep5_t0.2_test_time 0.25977063179016113
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 5
gc 0
Train Epoch6 Acc 0.250175 (30021/120000), AUC 0.5412383079528809
ep6_train_time 47.22319293022156
Test Epoch6 threshold 0.2 Acc 0.9159539473684211, AUC 0.9809165000915527, avg_entr 0.04909885302186012
ep6_t0.2_test_time 0.25922584533691406
gc 0
Train Epoch7 Acc 0.2504416666666667 (30053/120000), AUC 0.5427284240722656
ep7_train_time 47.3312451839447
Test Epoch7 threshold 0.2 Acc 0.9169407894736842, AUC 0.980920672416687, avg_entr 0.046387530863285065
ep7_t0.2_test_time 0.2584972381591797
gc 0
Train Epoch8 Acc 0.2506 (30072/120000), AUC 0.5445276498794556
ep8_train_time 47.292325496673584
Test Epoch8 threshold 0.2 Acc 0.9172697368421052, AUC 0.9806708097457886, avg_entr 0.04189020395278931
ep8_t0.2_test_time 0.2591269016265869
gc 0
Train Epoch9 Acc 0.2507333333333333 (30088/120000), AUC 0.5454312562942505
ep9_train_time 47.238603591918945
Test Epoch9 threshold 0.2 Acc 0.9159539473684211, AUC 0.9807499051094055, avg_entr 0.04101940616965294
ep9_t0.2_test_time 0.2589700222015381
Best AUC 0.9809259176254272
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad175_t0.2_m1//ag_news_lstmal_l5_prefix.pt
[[1370   52   77   33]
 [  13 1482    4    8]
 [  36   14 1339  111]
 [  42   14  105 1380]]
Figure(640x480)
tensor([0.0516, 0.0010, 0.0217,  ..., 0.0008, 0.0043, 0.0186])
[[   7  151 1148  226]
 [   2   83 1148  274]
 [   0  179  862  459]
 [   1   72 1352  116]]
Figure(640x480)
tensor([1.2288, 1.2497, 1.3158,  ..., 1.2555, 1.3374, 1.1183])
[[   0  180   27 1325]
 [   0    1   12 1494]
 [   0    4   19 1477]
 [   0   70  114 1357]]
Figure(640x480)
tensor([1.3486, 1.3659, 1.3359,  ..., 1.3135, 1.3886, 1.3661])
[[1143   21   23  345]
 [ 757    9   29  712]
 [ 799    1   22  678]
 [1176   16   15  334]]
Figure(640x480)
tensor([1.3839, 1.4211, 1.4048,  ..., 1.4194, 1.4390, 1.4319])
[[   0    0 1530    2]
 [   0    0 1506    1]
 [   0    0 1462   38]
 [   0    0 1506   35]]
Figure(640x480)
tensor([1.4231, 1.4259, 1.4267,  ..., 1.4118, 1.4161, 1.4338])
