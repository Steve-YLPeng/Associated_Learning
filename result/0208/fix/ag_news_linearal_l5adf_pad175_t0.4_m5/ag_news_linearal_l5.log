total count words 102019
vocab size 30000
found 26754 words in glove
Load ckpt from ckpt/ag_news_linearal_l5adf_pad175_t0.4_m4//ag_news_linearal_l5_prefix.pt
model: LinearModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.0.weight 90000
layers.1.enc.f.0.bias 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.0.weight 90000
layers.2.enc.f.0.bias 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.0.weight 90000
layers.3.enc.f.0.bias 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.0.weight 90000
layers.4.enc.f.0.bias 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 9687092
Start Training
train_mask {0, 1, 2, 3, 4}
gc 9
Train Epoch0 Acc 0.9095166666666666 (109142/120000), AUC 0.9846186637878418
ep0_train_time 10.398893356323242
Test Epoch0 threshold 0.4 Acc 0.9139802631578947, AUC 0.9801601767539978, avg_entr 0.026116766035556793
ep0_t0.4_test_time 0.2621278762817383
Save ckpt to ckpt/ag_news_linearal_l5adf_pad175_t0.4_m5//ag_news_linearal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.9505 (114060/120000), AUC 0.9935243725776672
ep1_train_time 9.995064973831177
Test Epoch1 threshold 0.4 Acc 0.9129934210526316, AUC 0.9800083041191101, avg_entr 0.02473306469619274
ep1_t0.4_test_time 0.2586827278137207
gc 0
Train Epoch2 Acc 0.9521166666666666 (114254/120000), AUC 0.9936648607254028
ep2_train_time 10.089254379272461
Test Epoch2 threshold 0.4 Acc 0.9126644736842106, AUC 0.97988361120224, avg_entr 0.02517070062458515
ep2_t0.4_test_time 0.25870704650878906
gc 0
Train Epoch3 Acc 0.953125 (114375/120000), AUC 0.993624210357666
ep3_train_time 9.9927396774292
Test Epoch3 threshold 0.4 Acc 0.912828947368421, AUC 0.9798088669776917, avg_entr 0.026210222393274307
ep3_t0.4_test_time 0.25907421112060547
gc 0
Train Epoch4 Acc 0.9539 (114468/120000), AUC 0.9939814805984497
ep4_train_time 10.175416946411133
Test Epoch4 threshold 0.4 Acc 0.9138157894736842, AUC 0.9797062277793884, avg_entr 0.025146402418613434
ep4_t0.4_test_time 0.25765347480773926
gc 0
Train Epoch5 Acc 0.9555666666666667 (114668/120000), AUC 0.9945838451385498
ep5_train_time 9.948616027832031
Test Epoch5 threshold 0.4 Acc 0.9103618421052632, AUC 0.979502260684967, avg_entr 0.026546906679868698
ep5_t0.4_test_time 0.25798583030700684
gc 0
Train Epoch6 Acc 0.9561833333333334 (114742/120000), AUC 0.9947392344474792
ep6_train_time 10.009381294250488
Test Epoch6 threshold 0.4 Acc 0.9118421052631579, AUC 0.9794350266456604, avg_entr 0.025604955852031708
ep6_t0.4_test_time 0.2580852508544922
gc 0
Train Epoch7 Acc 0.9563 (114756/120000), AUC 0.9949524998664856
ep7_train_time 9.9988374710083
Test Epoch7 threshold 0.4 Acc 0.9121710526315789, AUC 0.9792913198471069, avg_entr 0.026150213554501534
ep7_t0.4_test_time 0.25868725776672363
gc 0
Train Epoch8 Acc 0.956575 (114789/120000), AUC 0.9949976801872253
ep8_train_time 10.101165533065796
Test Epoch8 threshold 0.4 Acc 0.9103618421052632, AUC 0.9792274236679077, avg_entr 0.02547435462474823
ep8_t0.4_test_time 0.2559480667114258
gc 0
Train Epoch9 Acc 0.9577833333333333 (114934/120000), AUC 0.9953142404556274
ep9_train_time 9.96773910522461
Test Epoch9 threshold 0.4 Acc 0.9106907894736842, AUC 0.9791762828826904, avg_entr 0.026078036054968834
ep9_t0.4_test_time 0.25776028633117676
Best AUC 0.9801601767539978
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_linearal_l5adf_pad175_t0.4_m5//ag_news_linearal_l5_prefix.pt
[[1378   50   69   35]
 [  18 1473    5   11]
 [  37   15 1320  128]
 [  40   13   99 1389]]
Figure(640x480)
tensor([4.5769e-03, 4.0946e-08, 9.2782e-05,  ..., 2.0789e-08, 2.3108e-06,
        9.5419e-05])
[[1381   51   66   34]
 [  17 1473    6   11]
 [  40   13 1322  125]
 [  38   13  102 1388]]
Figure(640x480)
tensor([3.8298e-03, 4.6886e-07, 1.6205e-04,  ..., 3.4521e-08, 5.9110e-06,
        7.1739e-05])
[[1378   51   67   36]
 [  18 1473    4   12]
 [  39   16 1311  134]
 [  37   14   95 1395]]
Figure(640x480)
tensor([2.8632e-03, 8.0118e-08, 4.9616e-05,  ..., 2.2135e-08, 2.2433e-06,
        4.3169e-05])
[[1384   50   63   35]
 [  21 1470    4   12]
 [  43   16 1309  132]
 [  41   13   98 1389]]
Figure(640x480)
tensor([2.0354e-03, 4.2838e-08, 1.5562e-05,  ..., 3.2329e-08, 9.0377e-07,
        7.7284e-06])
[[1386   50   62   34]
 [  19 1472    5   11]
 [  43   16 1312  129]
 [  41   14   96 1390]]
Figure(640x480)
tensor([1.4461e-03, 2.3355e-08, 2.0458e-05,  ..., 4.3216e-08, 9.4190e-07,
        1.1850e-05])
