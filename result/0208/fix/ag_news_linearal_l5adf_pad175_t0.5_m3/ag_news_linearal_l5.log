total count words 102019
vocab size 30000
found 26754 words in glove
Load ckpt from ckpt/ag_news_linearal_l5adf_pad175_t0.5_m2//ag_news_linearal_l5_prefix.pt
model: LinearModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.0.weight 90000
layers.1.enc.f.0.bias 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.0.weight 90000
layers.2.enc.f.0.bias 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.0.weight 90000
layers.3.enc.f.0.bias 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.0.weight 90000
layers.4.enc.f.0.bias 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 9687092
Start Training
train_mask {0, 1, 2}
gc 9
Train Epoch0 Acc 0.05334166666666667 (6401/120000), AUC 0.3298977315425873
ep0_train_time 9.495965242385864
Test Epoch0 threshold 0.5 Acc 0.9151315789473684, AUC 0.9809020757675171, avg_entr 0.027049735188484192
ep0_t0.5_test_time 0.2583506107330322
Save ckpt to ckpt/ag_news_linearal_l5adf_pad175_t0.5_m3//ag_news_linearal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.06433333333333334 (7720/120000), AUC 0.3352113962173462
ep1_train_time 9.023316860198975
Test Epoch1 threshold 0.5 Acc 0.9154605263157894, AUC 0.9806301593780518, avg_entr 0.026328766718506813
ep1_t0.5_test_time 0.2574045658111572
gc 0
Train Epoch2 Acc 0.101325 (12159/120000), AUC 0.3059391677379608
ep2_train_time 9.060122728347778
Test Epoch2 threshold 0.5 Acc 0.9159539473684211, AUC 0.9805440306663513, avg_entr 0.025616372004151344
ep2_t0.5_test_time 0.25734615325927734
gc 0
Train Epoch3 Acc 0.11735833333333333 (14083/120000), AUC 0.24409985542297363
ep3_train_time 9.048961877822876
Test Epoch3 threshold 0.5 Acc 0.9133223684210526, AUC 0.980546236038208, avg_entr 0.02560524456202984
ep3_t0.5_test_time 0.25647497177124023
gc 0
Train Epoch4 Acc 0.11686666666666666 (14024/120000), AUC 0.20580266416072845
ep4_train_time 9.127411127090454
Test Epoch4 threshold 0.5 Acc 0.9149671052631579, AUC 0.9802727103233337, avg_entr 0.025275666266679764
ep4_t0.5_test_time 0.2565593719482422
gc 0
Train Epoch5 Acc 0.115025 (13803/120000), AUC 0.19675859808921814
ep5_train_time 9.301697254180908
Test Epoch5 threshold 0.5 Acc 0.9139802631578947, AUC 0.980138897895813, avg_entr 0.02582365646958351
ep5_t0.5_test_time 0.25588464736938477
gc 0
Train Epoch6 Acc 0.11134166666666667 (13361/120000), AUC 0.19550730288028717
ep6_train_time 9.157444715499878
Test Epoch6 threshold 0.5 Acc 0.9144736842105263, AUC 0.980038046836853, avg_entr 0.025682587176561356
ep6_t0.5_test_time 0.25632786750793457
gc 0
Train Epoch7 Acc 0.10485833333333333 (12583/120000), AUC 0.19799740612506866
ep7_train_time 9.111620664596558
Test Epoch7 threshold 0.5 Acc 0.9131578947368421, AUC 0.9798332452774048, avg_entr 0.02644248679280281
ep7_t0.5_test_time 0.2576122283935547
gc 0
Train Epoch8 Acc 0.09693333333333333 (11632/120000), AUC 0.20313166081905365
ep8_train_time 9.088247060775757
Test Epoch8 threshold 0.5 Acc 0.9129934210526316, AUC 0.9797691106796265, avg_entr 0.02612326107919216
ep8_t0.5_test_time 0.25686097145080566
gc 0
Train Epoch9 Acc 0.09251666666666666 (11102/120000), AUC 0.20729835331439972
ep9_train_time 9.109307527542114
Test Epoch9 threshold 0.5 Acc 0.9126644736842106, AUC 0.9797306060791016, avg_entr 0.02578316256403923
ep9_t0.5_test_time 0.25678420066833496
Best AUC 0.9809020757675171
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_linearal_l5adf_pad175_t0.5_m3//ag_news_linearal_l5_prefix.pt
[[1374   49   76   33]
 [  16 1471   10   10]
 [  36    9 1343  112]
 [  37   11  116 1377]]
Figure(640x480)
tensor([6.6144e-04, 1.0581e-07, 2.5981e-04,  ..., 9.3717e-08, 1.0666e-05,
        3.3736e-04])
[[1368   49   82   33]
 [  14 1473   10   10]
 [  37    8 1340  115]
 [  43   11  108 1379]]
Figure(640x480)
tensor([6.8865e-04, 7.5602e-07, 1.8485e-04,  ..., 1.3142e-07, 1.5258e-05,
        1.8917e-04])
[[1369   49   81   33]
 [  15 1471   10   11]
 [  36    8 1343  113]
 [  38   10  117 1376]]
Figure(640x480)
tensor([4.8130e-04, 7.9635e-07, 1.8128e-04,  ..., 1.4805e-07, 2.5157e-05,
        1.5079e-04])
[[  19   74 1439    0]
 [  14    1 1492    0]
 [  59 1340  100    1]
 [1139  341   61    0]]
Figure(640x480)
tensor([0.8398, 0.9104, 1.0346,  ..., 0.5383, 0.8872, 0.8619])
[[   0    0   47 1485]
 [   0    0    3 1504]
 [   1    0  267 1232]
 [   2    0 1422  117]]
Figure(640x480)
tensor([0.5433, 0.4814, 0.9402,  ..., 0.5496, 0.7503, 0.8838])
