total count words 102019
vocab size 30000
found 26754 words in glove
Load ckpt from ckpt/ag_news_linearal_l5adf_pad175_t0.9_m4//ag_news_linearal_l5_prefix.pt
model: LinearModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.0.weight 90000
layers.1.enc.f.0.bias 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.0.weight 90000
layers.2.enc.f.0.bias 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.0.weight 90000
layers.3.enc.f.0.bias 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.0.weight 90000
layers.4.enc.f.0.bias 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 9687092
Start Training
train_mask {0, 1, 2, 3, 4}
gc 9
Train Epoch0 Acc 0.9219833333333334 (110638/120000), AUC 0.9836724996566772
ep0_train_time 10.6234130859375
Test Epoch0 threshold 0.9 Acc 0.9161184210526315, AUC 0.9804016947746277, avg_entr 0.026126889511942863
ep0_t0.9_test_time 0.2567744255065918
Save ckpt to ckpt/ag_news_linearal_l5adf_pad175_t0.9_m5//ag_news_linearal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.9493083333333333 (113917/120000), AUC 0.9928562045097351
ep1_train_time 10.163666725158691
Test Epoch1 threshold 0.9 Acc 0.9167763157894737, AUC 0.9803117513656616, avg_entr 0.02596691995859146
ep1_t0.9_test_time 0.2548530101776123
gc 0
Train Epoch2 Acc 0.9510833333333333 (114130/120000), AUC 0.9930135607719421
ep2_train_time 10.207708597183228
Test Epoch2 threshold 0.9 Acc 0.9146381578947368, AUC 0.9800204038619995, avg_entr 0.02577969618141651
ep2_t0.9_test_time 0.25390028953552246
gc 0
Train Epoch3 Acc 0.95195 (114234/120000), AUC 0.993026852607727
ep3_train_time 10.252060651779175
Test Epoch3 threshold 0.9 Acc 0.9138157894736842, AUC 0.9798899292945862, avg_entr 0.026661351323127747
ep3_t0.9_test_time 0.25441956520080566
gc 0
Train Epoch4 Acc 0.9526 (114312/120000), AUC 0.9935460090637207
ep4_train_time 10.163675546646118
Test Epoch4 threshold 0.9 Acc 0.9123355263157895, AUC 0.9797883033752441, avg_entr 0.025926923379302025
ep4_t0.9_test_time 0.25539159774780273
gc 0
Train Epoch5 Acc 0.9547166666666667 (114566/120000), AUC 0.9942102432250977
ep5_train_time 10.132829189300537
Test Epoch5 threshold 0.9 Acc 0.9138157894736842, AUC 0.9797626733779907, avg_entr 0.026385528966784477
ep5_t0.9_test_time 0.258836030960083
gc 0
Train Epoch6 Acc 0.9553083333333333 (114637/120000), AUC 0.994407057762146
ep6_train_time 10.202594518661499
Test Epoch6 threshold 0.9 Acc 0.912828947368421, AUC 0.9795988202095032, avg_entr 0.026226960122585297
ep6_t0.9_test_time 0.25241541862487793
gc 0
Train Epoch7 Acc 0.955875 (114705/120000), AUC 0.9947060942649841
ep7_train_time 10.168392181396484
Test Epoch7 threshold 0.9 Acc 0.9123355263157895, AUC 0.9794667363166809, avg_entr 0.025965485721826553
ep7_t0.9_test_time 0.2576560974121094
gc 0
Train Epoch8 Acc 0.95615 (114738/120000), AUC 0.9947559833526611
ep8_train_time 10.20406699180603
Test Epoch8 threshold 0.9 Acc 0.9136513157894737, AUC 0.9794222712516785, avg_entr 0.026163417845964432
ep8_t0.9_test_time 0.2550482749938965
gc 0
Train Epoch9 Acc 0.9571166666666666 (114854/120000), AUC 0.9949990510940552
ep9_train_time 10.23979115486145
Test Epoch9 threshold 0.9 Acc 0.9111842105263158, AUC 0.9793381690979004, avg_entr 0.02575588785111904
ep9_t0.9_test_time 0.25322651863098145
Best AUC 0.9804016947746277
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_linearal_l5adf_pad175_t0.9_m5//ag_news_linearal_l5_prefix.pt
[[1370   50   71   41]
 [  11 1475    8   13]
 [  37   12 1322  129]
 [  33   11   94 1403]]
Figure(640x480)
tensor([1.4381e-03, 8.7112e-08, 9.2458e-05,  ..., 4.9061e-08, 1.0686e-06,
        2.4713e-04])
[[1373   50   73   36]
 [  12 1474    8   13]
 [  36   12 1317  135]
 [  37   13   89 1402]]
Figure(640x480)
tensor([1.3608e-03, 5.0682e-07, 7.1004e-05,  ..., 5.9067e-08, 1.2516e-06,
        6.0970e-04])
[[1374   50   71   37]
 [  12 1475    7   13]
 [  37   13 1318  132]
 [  35   13   87 1406]]
Figure(640x480)
tensor([8.3192e-04, 5.3396e-07, 4.8835e-05,  ..., 4.3932e-08, 6.8431e-07,
        1.8039e-04])
[[1375   51   66   40]
 [  13 1475    6   13]
 [  38   15 1311  136]
 [  35   13   82 1411]]
Figure(640x480)
tensor([6.0353e-04, 4.5357e-08, 1.2825e-05,  ..., 4.4337e-08, 4.6313e-07,
        3.3845e-05])
[[1376   51   66   39]
 [  14 1474    6   13]
 [  38   12 1315  135]
 [  35   13   85 1408]]
Figure(640x480)
tensor([6.1740e-04, 2.6852e-08, 1.0357e-05,  ..., 4.5091e-08, 3.4066e-07,
        4.6100e-05])
