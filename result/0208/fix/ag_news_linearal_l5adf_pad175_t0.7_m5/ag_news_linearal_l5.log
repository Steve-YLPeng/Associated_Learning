total count words 102019
vocab size 30000
found 26754 words in glove
Load ckpt from ckpt/ag_news_linearal_l5adf_pad175_t0.7_m4//ag_news_linearal_l5_prefix.pt
model: LinearModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LinearLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): ELU(alpha=1.0)
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.0.weight 90000
layers.1.enc.f.0.bias 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.0.weight 90000
layers.2.enc.f.0.bias 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.0.weight 90000
layers.3.enc.f.0.bias 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.0.weight 90000
layers.4.enc.f.0.bias 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 9687092
Start Training
train_mask {0, 1, 2, 3, 4}
gc 9
Train Epoch0 Acc 0.923025 (110763/120000), AUC 0.9866971969604492
ep0_train_time 10.336244106292725
Test Epoch0 threshold 0.7 Acc 0.915625, AUC 0.9807171821594238, avg_entr 0.027012299746274948
ep0_t0.7_test_time 0.2518618106842041
Save ckpt to ckpt/ag_news_linearal_l5adf_pad175_t0.7_m5//ag_news_linearal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.9502583333333333 (114031/120000), AUC 0.9933550357818604
ep1_train_time 9.878227949142456
Test Epoch1 threshold 0.7 Acc 0.9151315789473684, AUC 0.9805118441581726, avg_entr 0.027392204850912094
ep1_t0.7_test_time 0.25037503242492676
gc 0
Train Epoch2 Acc 0.951375 (114165/120000), AUC 0.9934873580932617
ep2_train_time 9.893508195877075
Test Epoch2 threshold 0.7 Acc 0.9136513157894737, AUC 0.9804011583328247, avg_entr 0.026292260736227036
ep2_t0.7_test_time 0.2501082420349121
gc 0
Train Epoch3 Acc 0.9532666666666667 (114392/120000), AUC 0.993476152420044
ep3_train_time 9.939481973648071
Test Epoch3 threshold 0.7 Acc 0.9103618421052632, AUC 0.9799995422363281, avg_entr 0.02479369193315506
ep3_t0.7_test_time 0.24968695640563965
gc 0
Train Epoch4 Acc 0.9539166666666666 (114470/120000), AUC 0.993889570236206
ep4_train_time 9.966349363327026
Test Epoch4 threshold 0.7 Acc 0.9141447368421053, AUC 0.9801718592643738, avg_entr 0.025236455723643303
ep4_t0.7_test_time 0.24951434135437012
gc 0
Train Epoch5 Acc 0.9553833333333334 (114646/120000), AUC 0.9945371150970459
ep5_train_time 9.978159427642822
Test Epoch5 threshold 0.7 Acc 0.9136513157894737, AUC 0.9799379110336304, avg_entr 0.026520442217588425
ep5_t0.7_test_time 0.24988174438476562
gc 0
Train Epoch6 Acc 0.9558666666666666 (114704/120000), AUC 0.9946861267089844
ep6_train_time 9.98235011100769
Test Epoch6 threshold 0.7 Acc 0.9133223684210526, AUC 0.9798035621643066, avg_entr 0.025890134274959564
ep6_t0.7_test_time 0.250110387802124
gc 0
Train Epoch7 Acc 0.9564166666666667 (114770/120000), AUC 0.9948410987854004
ep7_train_time 10.009705066680908
Test Epoch7 threshold 0.7 Acc 0.9110197368421052, AUC 0.9797253012657166, avg_entr 0.026304468512535095
ep7_t0.7_test_time 0.2496328353881836
gc 0
Train Epoch8 Acc 0.9566083333333333 (114793/120000), AUC 0.9949333071708679
ep8_train_time 10.053382396697998
Test Epoch8 threshold 0.7 Acc 0.912828947368421, AUC 0.9795994758605957, avg_entr 0.026002241298556328
ep8_t0.7_test_time 0.2497391700744629
gc 0
Train Epoch9 Acc 0.9577666666666667 (114932/120000), AUC 0.995241641998291
ep9_train_time 9.936658382415771
Test Epoch9 threshold 0.7 Acc 0.9131578947368421, AUC 0.9795222878456116, avg_entr 0.02622004970908165
ep9_t0.7_test_time 0.24948525428771973
Best AUC 0.9807171821594238
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_linearal_l5adf_pad175_t0.7_m5//ag_news_linearal_l5_prefix.pt
[[1379   50   68   35]
 [  18 1469    6   14]
 [  39   12 1320  129]
 [  35   11   96 1399]]
Figure(640x480)
tensor([6.0166e-03, 4.1483e-08, 4.8202e-05,  ..., 3.3419e-08, 1.5169e-06,
        4.5200e-04])
[[1378   50   68   36]
 [  17 1471    5   14]
 [  39   12 1321  128]
 [  35   11   93 1402]]
Figure(640x480)
tensor([4.7483e-03, 1.5379e-07, 6.4725e-05,  ..., 5.6944e-08, 1.9219e-06,
        2.2909e-03])
[[1378   50   68   36]
 [  20 1467    5   15]
 [  39   12 1317  132]
 [  35   10   89 1407]]
Figure(640x480)
tensor([2.4408e-03, 6.5872e-08, 2.1134e-05,  ..., 4.7691e-08, 1.4722e-06,
        8.4735e-04])
[[1382   50   62   38]
 [  20 1467    5   15]
 [  42   12 1307  139]
 [  35   10   82 1414]]
Figure(640x480)
tensor([2.0609e-03, 2.8168e-08, 1.0003e-05,  ..., 4.4683e-08, 4.9780e-07,
        4.0974e-04])
[[1385   50   60   37]
 [  19 1468    6   14]
 [  40   12 1313  135]
 [  35   11   88 1407]]
Figure(640x480)
tensor([1.6386e-03, 2.5469e-08, 8.3841e-06,  ..., 4.9543e-08, 5.1221e-07,
        1.6079e-04])
