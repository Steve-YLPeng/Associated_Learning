total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.23558333333333334 (28270/120000), AUC 0.4827573299407959
ep0_train_time 9.834812641143799
Test Epoch0 threshold 0.1 Acc 0.9098684210526315, AUC 0.979597270488739, avg_entr 0.14953315258026123
ep0_t0.1_test_time 0.07336091995239258
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.22971666666666668 (27566/120000), AUC 0.477459192276001
ep1_train_time 9.910240411758423
Test Epoch1 threshold 0.1 Acc 0.912828947368421, AUC 0.9811177849769592, avg_entr 0.09577153623104095
ep1_t0.1_test_time 0.07139229774475098
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.22744166666666665 (27293/120000), AUC 0.47723084688186646
ep2_train_time 10.319012641906738
Test Epoch2 threshold 0.1 Acc 0.9131578947368421, AUC 0.9809087514877319, avg_entr 0.07547292858362198
ep2_t0.1_test_time 0.07215142250061035
gc 0
Train Epoch3 Acc 0.22574166666666667 (27089/120000), AUC 0.47731518745422363
ep3_train_time 9.866809844970703
Test Epoch3 threshold 0.1 Acc 0.9129934210526316, AUC 0.9809145927429199, avg_entr 0.06574472039937973
ep3_t0.1_test_time 0.07152009010314941
gc 0
Train Epoch4 Acc 0.223675 (26841/120000), AUC 0.47707948088645935
ep4_train_time 9.985690593719482
Test Epoch4 threshold 0.1 Acc 0.9113486842105263, AUC 0.9797248840332031, avg_entr 0.05905146524310112
ep4_t0.1_test_time 0.07123112678527832
gc 0
Train Epoch5 Acc 0.2219 (26628/120000), AUC 0.4769667387008667
ep5_train_time 10.065823793411255
Test Epoch5 threshold 0.1 Acc 0.9129934210526316, AUC 0.9802534580230713, avg_entr 0.05351927876472473
ep5_t0.1_test_time 0.07340383529663086
gc 0
Train Epoch6 Acc 0.22073333333333334 (26488/120000), AUC 0.47690439224243164
ep6_train_time 10.02517032623291
Test Epoch6 threshold 0.1 Acc 0.9116776315789473, AUC 0.9800546169281006, avg_entr 0.05097527429461479
ep6_t0.1_test_time 0.0716545581817627
gc 0
Train Epoch7 Acc 0.22034166666666666 (26441/120000), AUC 0.47678229212760925
ep7_train_time 9.779813766479492
Test Epoch7 threshold 0.1 Acc 0.9115131578947369, AUC 0.9796766042709351, avg_entr 0.0490853376686573
ep7_t0.1_test_time 0.0727078914642334
gc 0
Train Epoch8 Acc 0.21954166666666666 (26345/120000), AUC 0.47665834426879883
ep8_train_time 9.84858512878418
Test Epoch8 threshold 0.1 Acc 0.9110197368421052, AUC 0.9794907569885254, avg_entr 0.04585763439536095
ep8_t0.1_test_time 0.07160568237304688
gc 0
Train Epoch9 Acc 0.21878333333333333 (26254/120000), AUC 0.4766451120376587
ep9_train_time 9.876469850540161
Test Epoch9 threshold 0.1 Acc 0.9110197368421052, AUC 0.9794834852218628, avg_entr 0.04376505687832832
ep9_t0.1_test_time 0.07139801979064941
Best AUC 0.9811177849769592
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adp_pad25_t0.1_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.1 Acc 0.9177631578947368, AUC 0.9859336018562317, avg_entr 0.09977026283740997
t0.1_test_time 0.018964529037475586
