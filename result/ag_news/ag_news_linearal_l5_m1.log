total count words 102019
vocab size 30000
found 26754 words in glove
Start Training
gc 0
[[381.74676892  12.01034222]
 [166.1965526   90.7891326 ]
 [125.57801715  96.48904455]
 [147.5444721   82.58931337]
 [133.93155989  75.43092974]]
Train Epoch0 Acc 0.25051666666666667 (30062/120000), AUC 0.49000290036201477
Test Epoch0 layer0 Acc 0.9122368421052631, AUC 0.9805095195770264
Save ckpt to ./ckpt/mask1//ag_news/ag_news_linearal_l5_m1.pt  ,ep 0
Test Epoch0 layer1 Acc 0.24, AUC 0.4735991358757019
Test Epoch0 layer2 Acc 0.22473684210526315, AUC 0.44094929099082947
Test Epoch0 layer3 Acc 0.195, AUC 0.41622596979141235
Test Epoch0 layer4 Acc 0.25894736842105265, AUC 0.49989649653434753
gc 0
[[320.61959475  10.97423771]
 [192.38722929 101.2001657 ]
 [146.80930811 103.43111925]
 [163.71281815  89.67938232]
 [143.62411816  79.99567963]]
Train Epoch1 Acc 0.2568416666666667 (30821/120000), AUC 0.5016263127326965
Test Epoch1 layer0 Acc 0.9136842105263158, AUC 0.981399416923523
Save ckpt to ./ckpt/mask1//ag_news/ag_news_linearal_l5_m1.pt  ,ep 1
Test Epoch1 layer1 Acc 0.24289473684210527, AUC 0.4727960526943207
Test Epoch1 layer2 Acc 0.22526315789473683, AUC 0.4384421706199646
Test Epoch1 layer3 Acc 0.19105263157894736, AUC 0.41335684061050415
Test Epoch1 layer4 Acc 0.26302631578947366, AUC 0.5062524080276489
gc 0
[[319.93023676  11.36278168]
 [205.81924857 106.08889277]
 [156.67054139 106.64062116]
 [170.97779417  92.53314283]
 [148.83905293  81.86222859]]
Train Epoch2 Acc 0.260475 (31257/120000), AUC 0.5063484311103821
Test Epoch2 layer0 Acc 0.9126315789473685, AUC 0.9811199903488159
Test Epoch2 layer1 Acc 0.2417105263157895, AUC 0.4725853204727173
Test Epoch2 layer2 Acc 0.22302631578947368, AUC 0.43788814544677734
Test Epoch2 layer3 Acc 0.19144736842105264, AUC 0.41226089000701904
Test Epoch2 layer4 Acc 0.26394736842105265, AUC 0.5093814730644226
gc 0
[[319.75810173  11.78365286]
 [215.74049459 109.65700146]
 [163.76576842 108.91944394]
 [176.11718626  94.45201552]
 [152.65977263  83.12735346]]
Train Epoch3 Acc 0.26231666666666664 (31478/120000), AUC 0.5102083683013916
Test Epoch3 layer0 Acc 0.9147368421052632, AUC 0.9804390668869019
Test Epoch3 layer1 Acc 0.24342105263157895, AUC 0.4726940989494324
Test Epoch3 layer2 Acc 0.22276315789473683, AUC 0.43644943833351135
Test Epoch3 layer3 Acc 0.18881578947368421, AUC 0.41110169887542725
Test Epoch3 layer4 Acc 0.2668421052631579, AUC 0.5126521587371826
gc 0
[[319.69218478  12.19675764]
 [224.08299257 112.62192181]
 [169.63220257 110.78546176]
 [180.3043433   95.96500262]
 [155.83540301  84.11264373]]
Train Epoch4 Acc 0.2646833333333333 (31762/120000), AUC 0.5132383108139038
Test Epoch4 layer0 Acc 0.9140789473684211, AUC 0.9808990955352783
Test Epoch4 layer1 Acc 0.24460526315789474, AUC 0.47346633672714233
Test Epoch4 layer2 Acc 0.22210526315789475, AUC 0.4352622926235199
Test Epoch4 layer3 Acc 0.1856578947368421, AUC 0.4095476269721985
Test Epoch4 layer4 Acc 0.26842105263157895, AUC 0.5157120823860168
gc 0
[[319.66172022  12.62878023]
 [231.56237465 115.23250595]
 [174.82984759 112.37108403]
 [183.97340426  97.1751538 ]
 [158.65486962  84.90499168]]
Train Epoch5 Acc 0.26676666666666665 (32012/120000), AUC 0.5164667963981628
Test Epoch5 layer0 Acc 0.9110526315789473, AUC 0.9807592034339905
Test Epoch5 layer1 Acc 0.24605263157894736, AUC 0.47434860467910767
Test Epoch5 layer2 Acc 0.22026315789473686, AUC 0.43355637788772583
Test Epoch5 layer3 Acc 0.18539473684210525, AUC 0.4091736078262329
Test Epoch5 layer4 Acc 0.27092105263157895, AUC 0.5183278918266296
gc 0
[[319.64869606  12.25186631]
 [236.95751078 117.11012387]
 [178.54727393 113.50047584]
 [186.5820554   98.0463668 ]
 [160.67352094  85.48694943]]
Train Epoch6 Acc 0.26831666666666665 (32198/120000), AUC 0.5185165405273438
Test Epoch6 layer0 Acc 0.9132894736842105, AUC 0.9804073572158813
Test Epoch6 layer1 Acc 0.24644736842105264, AUC 0.4746662974357605
Test Epoch6 layer2 Acc 0.22026315789473686, AUC 0.43396368622779846
Test Epoch6 layer3 Acc 0.18552631578947368, AUC 0.40934035181999207
Test Epoch6 layer4 Acc 0.2711842105263158, AUC 0.5186742544174194
gc 0
[[319.64219642  12.46124396]
 [241.09197655 118.63674735]
 [181.37409219 114.48764562]
 [188.55095996  98.8845612 ]
 [162.20736273  86.06740505]]
Train Epoch7 Acc 0.26935 (32322/120000), AUC 0.5191043019294739
Test Epoch7 layer0 Acc 0.9125, AUC 0.9800345301628113
Test Epoch7 layer1 Acc 0.24644736842105264, AUC 0.4749562740325928
Test Epoch7 layer2 Acc 0.22026315789473686, AUC 0.43443965911865234
Test Epoch7 layer3 Acc 0.18526315789473685, AUC 0.40902382135391235
Test Epoch7 layer4 Acc 0.2714473684210526, AUC 0.5194208025932312
gc 0
[[319.6370391   12.75349538]
 [245.78746518 120.34375864]
 [184.56796126 115.5509925 ]
 [190.76014635  99.79171786]
 [163.93632369  86.70767819]]
Train Epoch8 Acc 0.27020833333333333 (32425/120000), AUC 0.5203046798706055
Test Epoch8 layer0 Acc 0.910921052631579, AUC 0.9799461960792542
Test Epoch8 layer1 Acc 0.24710526315789474, AUC 0.4749006927013397
Test Epoch8 layer2 Acc 0.21960526315789475, AUC 0.43431907892227173
Test Epoch8 layer3 Acc 0.18552631578947368, AUC 0.4090116620063782
Test Epoch8 layer4 Acc 0.2719736842105263, AUC 0.5200223326683044
gc 0
[[319.63328829  13.10051309]
 [250.89533299 122.24868574]
 [188.01712707 116.78173589]
 [193.12465616 100.81555196]
 [165.79624158  87.4095907 ]]
Train Epoch9 Acc 0.271375 (32565/120000), AUC 0.5212622880935669
Test Epoch9 layer0 Acc 0.9098684210526315, AUC 0.9798823595046997
Test Epoch9 layer1 Acc 0.24697368421052632, AUC 0.4757761061191559
Test Epoch9 layer2 Acc 0.21947368421052632, AUC 0.4341791272163391
Test Epoch9 layer3 Acc 0.18539473684210525, AUC 0.40849003195762634
Test Epoch9 layer4 Acc 0.27381578947368423, AUC 0.5212955474853516
Best AUC 0.981399416923523
train_loss (2, 5, 10)
valid_acc (5, 10)
valid_AUC (5, 10)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ./ckpt/mask1//ag_news/ag_news_linearal_l5_m1.pt
[[1711   59   89   41]
 [  15 1865   10   10]
 [  50   15 1688  147]
 [  59   16  145 1680]]
Figure(640x480)
[[   1 1072  715  112]
 [   2 1178  642   78]
 [   3 1137  494  266]
 [  14 1051  662  173]]
Figure(640x480)
[[ 150    3   53 1694]
 [ 204   18  109 1569]
 [ 216    2  101 1581]
 [ 176   14  267 1443]]
Figure(640x480)
[[ 483  163 1237   17]
 [ 813  302  717   68]
 [ 723  448  639   90]
 [ 691  233  948   28]]
Figure(640x480)
[[   0  184 1710    6]
 [   1  368 1529    2]
 [   0  269 1631    0]
 [   0  456 1444    0]]
Figure(640x480)
