total count words 887881
vocab size 30000
train size 560000, valid size 35000, test size 35000
found 28354 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=14, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=14, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 1792
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 1792
layers.0.ae.h.0.bias 14
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13674862
init_time 57.76338219642639
Start Training
gc 0
Train Epoch0 Acc 0.8346267857142857 (467391/560000), AUC 0.9804450869560242
ep0_train_time 191.03267908096313
Test Epoch0 layer0 Acc 0.9721142857142857, AUC 0.9983044862747192, avg_entr 0.08605062961578369, f1 0.9721142649650574
ep0_l0_test_time 0.8605430126190186
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad80//dbpedia_14_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9740857142857143, AUC 0.9984979033470154, avg_entr 0.03619828075170517, f1 0.9740856885910034
ep0_l1_test_time 1.4562110900878906
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad80//dbpedia_14_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.974, AUC 0.9981110692024231, avg_entr 0.02623673900961876, f1 0.9739999771118164
ep0_l2_test_time 1.961362361907959
Test Epoch0 layer3 Acc 0.9741142857142857, AUC 0.9981069564819336, avg_entr 0.02320634201169014, f1 0.9741142988204956
ep0_l3_test_time 2.465317726135254
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad80//dbpedia_14_transformeral_l5.pt  ,ep 0
Test Epoch0 layer4 Acc 0.9741714285714286, AUC 0.9981444478034973, avg_entr 0.021887879818677902, f1 0.9741714000701904
ep0_l4_test_time 2.98028826713562
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad80//dbpedia_14_transformeral_l5.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.9802767857142857 (548955/560000), AUC 0.997662365436554
ep1_train_time 189.7521231174469
Test Epoch1 layer0 Acc 0.9741714285714286, AUC 0.9984020590782166, avg_entr 0.04670282453298569, f1 0.9741714000701904
ep1_l0_test_time 0.8534307479858398
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad80//dbpedia_14_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.9782285714285714, AUC 0.997911274433136, avg_entr 0.00978299044072628, f1 0.9782285690307617
ep1_l1_test_time 1.4150617122650146
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad80//dbpedia_14_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.9782571428571428, AUC 0.9980774521827698, avg_entr 0.006987037602812052, f1 0.9782571196556091
ep1_l2_test_time 1.9345753192901611
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad80//dbpedia_14_transformeral_l5.pt  ,ep 1
Test Epoch1 layer3 Acc 0.9783714285714286, AUC 0.9978267550468445, avg_entr 0.005896276794373989, f1 0.9783714413642883
ep1_l3_test_time 2.454486131668091
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad80//dbpedia_14_transformeral_l5.pt  ,ep 1
Test Epoch1 layer4 Acc 0.9784857142857143, AUC 0.9976887106895447, avg_entr 0.005375689826905727, f1 0.9784857034683228
ep1_l4_test_time 2.9930949211120605
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad80//dbpedia_14_transformeral_l5.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.9839267857142857 (550999/560000), AUC 0.998071551322937
ep2_train_time 189.57963371276855
Test Epoch2 layer0 Acc 0.9744, AUC 0.9984272122383118, avg_entr 0.03373901546001434, f1 0.974399983882904
ep2_l0_test_time 0.8832509517669678
Test Epoch2 layer1 Acc 0.9784571428571428, AUC 0.9981488585472107, avg_entr 0.006915010511875153, f1 0.9784571528434753
ep2_l1_test_time 1.4185810089111328
Test Epoch2 layer2 Acc 0.9785428571428572, AUC 0.9981315732002258, avg_entr 0.004674311261624098, f1 0.9785428643226624
ep2_l2_test_time 1.9618017673492432
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad80//dbpedia_14_transformeral_l5.pt  ,ep 2
Test Epoch2 layer3 Acc 0.9785142857142857, AUC 0.9979209899902344, avg_entr 0.00386190228164196, f1 0.9785143136978149
ep2_l3_test_time 2.474942207336426
Test Epoch2 layer4 Acc 0.9785142857142857, AUC 0.9977461099624634, avg_entr 0.0034852614626288414, f1 0.9785143136978149
ep2_l4_test_time 2.9845564365386963
gc 0
Train Epoch3 Acc 0.9857160714285714 (552001/560000), AUC 0.9981766939163208
ep3_train_time 190.08717608451843
Test Epoch3 layer0 Acc 0.9746, AUC 0.998446524143219, avg_entr 0.027097079902887344, f1 0.9746000170707703
ep3_l0_test_time 0.8514270782470703
Test Epoch3 layer1 Acc 0.9787714285714286, AUC 0.9977732300758362, avg_entr 0.005151445511728525, f1 0.978771448135376
ep3_l1_test_time 1.4215712547302246
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad80//dbpedia_14_transformeral_l5.pt  ,ep 3
Test Epoch3 layer2 Acc 0.9789142857142857, AUC 0.9974961876869202, avg_entr 0.0035000036004930735, f1 0.9789142608642578
ep3_l2_test_time 1.9163916110992432
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad80//dbpedia_14_transformeral_l5.pt  ,ep 3
Test Epoch3 layer3 Acc 0.9788, AUC 0.997092604637146, avg_entr 0.00296986335888505, f1 0.9787999987602234
ep3_l3_test_time 2.4663350582122803
Test Epoch3 layer4 Acc 0.9788285714285714, AUC 0.9967594146728516, avg_entr 0.0026451353915035725, f1 0.9788285493850708
ep3_l4_test_time 2.9934897422790527
gc 0
Train Epoch4 Acc 0.9869678571428572 (552702/560000), AUC 0.9982863068580627
ep4_train_time 189.85013151168823
Test Epoch4 layer0 Acc 0.9741428571428571, AUC 0.9984556436538696, avg_entr 0.025220850482583046, f1 0.974142849445343
ep4_l0_test_time 0.8839819431304932
Test Epoch4 layer1 Acc 0.9783714285714286, AUC 0.9976544380187988, avg_entr 0.004852783866226673, f1 0.9783714413642883
ep4_l1_test_time 1.4255738258361816
Test Epoch4 layer2 Acc 0.9787714285714286, AUC 0.9975824952125549, avg_entr 0.003061190713196993, f1 0.978771448135376
ep4_l2_test_time 2.0167276859283447
Test Epoch4 layer3 Acc 0.9787142857142858, AUC 0.9972137808799744, avg_entr 0.0025506496895104647, f1 0.9787142872810364
ep4_l3_test_time 2.4658775329589844
Test Epoch4 layer4 Acc 0.9786285714285714, AUC 0.9966021180152893, avg_entr 0.0022609755396842957, f1 0.9786285758018494
ep4_l4_test_time 2.9710917472839355
gc 0
Train Epoch5 Acc 0.9879928571428571 (553276/560000), AUC 0.9985317587852478
ep5_train_time 189.7912368774414
Test Epoch5 layer0 Acc 0.9745714285714285, AUC 0.9984791874885559, avg_entr 0.024713125079870224, f1 0.9745714068412781
ep5_l0_test_time 0.8837580680847168
Test Epoch5 layer1 Acc 0.9788571428571429, AUC 0.9977205991744995, avg_entr 0.003946094308048487, f1 0.978857159614563
ep5_l1_test_time 1.4144115447998047
Test Epoch5 layer2 Acc 0.9790285714285715, AUC 0.9974600076675415, avg_entr 0.0024616040755063295, f1 0.979028582572937
ep5_l2_test_time 1.9224824905395508
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad80//dbpedia_14_transformeral_l5.pt  ,ep 5
Test Epoch5 layer3 Acc 0.9790571428571428, AUC 0.9971164464950562, avg_entr 0.002024626825004816, f1 0.9790571331977844
ep5_l3_test_time 2.4664931297302246
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad80//dbpedia_14_transformeral_l5.pt  ,ep 5
Test Epoch5 layer4 Acc 0.9791714285714286, AUC 0.9965998530387878, avg_entr 0.001836129929870367, f1 0.9791714549064636
ep5_l4_test_time 2.978785514831543
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad80//dbpedia_14_transformeral_l5.pt  ,ep 5
gc 0
Train Epoch6 Acc 0.9885660714285714 (553597/560000), AUC 0.998742938041687
ep6_train_time 189.9532356262207
Test Epoch6 layer0 Acc 0.9747428571428571, AUC 0.9984989166259766, avg_entr 0.024302015081048012, f1 0.9747428297996521
ep6_l0_test_time 0.8469951152801514
Test Epoch6 layer1 Acc 0.9787714285714286, AUC 0.9975167512893677, avg_entr 0.004120464902371168, f1 0.978771448135376
ep6_l1_test_time 1.5062167644500732
Test Epoch6 layer2 Acc 0.9791714285714286, AUC 0.9974600076675415, avg_entr 0.0027710238937288523, f1 0.9791714549064636
ep6_l2_test_time 1.9059579372406006
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad80//dbpedia_14_transformeral_l5.pt  ,ep 6
Test Epoch6 layer3 Acc 0.9789428571428571, AUC 0.9971259832382202, avg_entr 0.0023827985860407352, f1 0.97894287109375
ep6_l3_test_time 2.434346914291382
Test Epoch6 layer4 Acc 0.9789714285714286, AUC 0.9963444471359253, avg_entr 0.002083482686430216, f1 0.9789714217185974
ep6_l4_test_time 2.948007345199585
gc 0
Train Epoch7 Acc 0.9895732142857143 (554161/560000), AUC 0.9988833069801331
ep7_train_time 189.53934788703918
Test Epoch7 layer0 Acc 0.9747428571428571, AUC 0.998478353023529, avg_entr 0.023944281041622162, f1 0.9747428297996521
ep7_l0_test_time 0.8590171337127686
Test Epoch7 layer1 Acc 0.9789142857142857, AUC 0.997309684753418, avg_entr 0.004257225897163153, f1 0.9789142608642578
ep7_l1_test_time 1.4009170532226562
Test Epoch7 layer2 Acc 0.9787428571428571, AUC 0.9974241852760315, avg_entr 0.0026334880385547876, f1 0.9787428379058838
ep7_l2_test_time 2.0179951190948486
Test Epoch7 layer3 Acc 0.9786, AUC 0.9971040487289429, avg_entr 0.0021301000379025936, f1 0.978600025177002
ep7_l3_test_time 2.435067653656006
Test Epoch7 layer4 Acc 0.9784857142857143, AUC 0.9964371919631958, avg_entr 0.001809208421036601, f1 0.9784857034683228
ep7_l4_test_time 2.9682042598724365
gc 0
Train Epoch8 Acc 0.9899553571428571 (554375/560000), AUC 0.9989290237426758
ep8_train_time 189.9926733970642
Test Epoch8 layer0 Acc 0.9746857142857143, AUC 0.9984880685806274, avg_entr 0.02413935959339142, f1 0.9746857285499573
ep8_l0_test_time 0.8546125888824463
Test Epoch8 layer1 Acc 0.979, AUC 0.9972822070121765, avg_entr 0.004015213344246149, f1 0.9789999723434448
ep8_l1_test_time 1.4092111587524414
Test Epoch8 layer2 Acc 0.979, AUC 0.9973940253257751, avg_entr 0.0025668372400105, f1 0.9789999723434448
ep8_l2_test_time 1.9106309413909912
Test Epoch8 layer3 Acc 0.9791428571428571, AUC 0.9970933794975281, avg_entr 0.0022224897984415293, f1 0.9791428446769714
ep8_l3_test_time 2.4318413734436035
Test Epoch8 layer4 Acc 0.9789714285714286, AUC 0.9964098334312439, avg_entr 0.0020332010462880135, f1 0.9789714217185974
ep8_l4_test_time 2.9584012031555176
gc 0
Train Epoch9 Acc 0.9904767857142858 (554667/560000), AUC 0.998944878578186
ep9_train_time 189.53379249572754
Test Epoch9 layer0 Acc 0.9748, AUC 0.9984882473945618, avg_entr 0.023640591651201248, f1 0.9747999906539917
ep9_l0_test_time 0.8507480621337891
Test Epoch9 layer1 Acc 0.9787714285714286, AUC 0.9972041249275208, avg_entr 0.0041495864279568195, f1 0.978771448135376
ep9_l1_test_time 1.4141271114349365
Test Epoch9 layer2 Acc 0.9791714285714286, AUC 0.9971016049385071, avg_entr 0.002567364601418376, f1 0.9791714549064636
ep9_l2_test_time 1.9130723476409912
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad80//dbpedia_14_transformeral_l5.pt  ,ep 9
Test Epoch9 layer3 Acc 0.979, AUC 0.9968479871749878, avg_entr 0.0020778870675712824, f1 0.9789999723434448
ep9_l3_test_time 2.4280169010162354
Test Epoch9 layer4 Acc 0.9788857142857142, AUC 0.9962437748908997, avg_entr 0.0019715854432433844, f1 0.9788857698440552
ep9_l4_test_time 2.959049940109253
gc 0
Train Epoch10 Acc 0.9907821428571428 (554838/560000), AUC 0.9989733695983887
ep10_train_time 189.59285497665405
Test Epoch10 layer0 Acc 0.9745142857142857, AUC 0.9984931349754333, avg_entr 0.02359721250832081, f1 0.9745143055915833
ep10_l0_test_time 0.8774154186248779
Test Epoch10 layer1 Acc 0.9787428571428571, AUC 0.9971807599067688, avg_entr 0.003993525635451078, f1 0.9787428379058838
ep10_l1_test_time 1.433013916015625
Test Epoch10 layer2 Acc 0.9784857142857143, AUC 0.9972265958786011, avg_entr 0.0025390698574483395, f1 0.9784857034683228
ep10_l2_test_time 1.9174106121063232
Test Epoch10 layer3 Acc 0.9783714285714286, AUC 0.9967999458312988, avg_entr 0.0023280116729438305, f1 0.9783714413642883
ep10_l3_test_time 2.4246928691864014
Test Epoch10 layer4 Acc 0.9784, AUC 0.9961186051368713, avg_entr 0.002131296321749687, f1 0.9783999919891357
ep10_l4_test_time 2.950951337814331
gc 0
Train Epoch11 Acc 0.991275 (555114/560000), AUC 0.9990152716636658
ep11_train_time 189.67830967903137
Test Epoch11 layer0 Acc 0.9744857142857143, AUC 0.9984748959541321, avg_entr 0.023723602294921875, f1 0.9744856953620911
ep11_l0_test_time 0.8648719787597656
Test Epoch11 layer1 Acc 0.9788571428571429, AUC 0.9971302151679993, avg_entr 0.004097428638488054, f1 0.978857159614563
ep11_l1_test_time 1.3877990245819092
Test Epoch11 layer2 Acc 0.9788, AUC 0.9970473051071167, avg_entr 0.002563516376540065, f1 0.9787999987602234
ep11_l2_test_time 1.9149432182312012
Test Epoch11 layer3 Acc 0.9788857142857142, AUC 0.9970012307167053, avg_entr 0.0021255009341984987, f1 0.9788857698440552
ep11_l3_test_time 2.426131248474121
Test Epoch11 layer4 Acc 0.9789142857142857, AUC 0.9961452484130859, avg_entr 0.001893361797556281, f1 0.9789142608642578
ep11_l4_test_time 2.983982563018799
gc 0
Train Epoch12 Acc 0.9914821428571429 (555230/560000), AUC 0.9990662932395935
ep12_train_time 189.6909511089325
Test Epoch12 layer0 Acc 0.9747142857142858, AUC 0.9984970688819885, avg_entr 0.023563992232084274, f1 0.9747142791748047
ep12_l0_test_time 0.8486769199371338
Test Epoch12 layer1 Acc 0.9787142857142858, AUC 0.9971547722816467, avg_entr 0.004002853762358427, f1 0.9787142872810364
ep12_l1_test_time 1.3929462432861328
Test Epoch12 layer2 Acc 0.9786571428571429, AUC 0.9971663355827332, avg_entr 0.0025205789133906364, f1 0.9786571264266968
ep12_l2_test_time 1.9098742008209229
Test Epoch12 layer3 Acc 0.9786, AUC 0.9968324899673462, avg_entr 0.0021783807314932346, f1 0.978600025177002
ep12_l3_test_time 2.4534430503845215
Test Epoch12 layer4 Acc 0.9785714285714285, AUC 0.9959477782249451, avg_entr 0.0019349372014403343, f1 0.9785714149475098
ep12_l4_test_time 2.949744701385498
gc 0
Train Epoch13 Acc 0.9918 (555408/560000), AUC 0.9990278482437134
ep13_train_time 189.63987517356873
Test Epoch13 layer0 Acc 0.9745714285714285, AUC 0.9984866976737976, avg_entr 0.023519132286310196, f1 0.9745714068412781
ep13_l0_test_time 0.8681929111480713
Test Epoch13 layer1 Acc 0.9786857142857143, AUC 0.9970777630805969, avg_entr 0.004090919625014067, f1 0.978685736656189
ep13_l1_test_time 1.4264729022979736
Test Epoch13 layer2 Acc 0.9786857142857143, AUC 0.9971298575401306, avg_entr 0.0026011706795543432, f1 0.978685736656189
ep13_l2_test_time 1.9595651626586914
Test Epoch13 layer3 Acc 0.9788571428571429, AUC 0.9969009160995483, avg_entr 0.002200896618887782, f1 0.978857159614563
ep13_l3_test_time 2.4354188442230225
Test Epoch13 layer4 Acc 0.9787714285714286, AUC 0.9961143732070923, avg_entr 0.002003374742344022, f1 0.978771448135376
ep13_l4_test_time 3.008815288543701
gc 0
Train Epoch14 Acc 0.9918678571428572 (555446/560000), AUC 0.9990754723548889
ep14_train_time 190.28324270248413
Test Epoch14 layer0 Acc 0.9746, AUC 0.9984821677207947, avg_entr 0.023423409089446068, f1 0.9746000170707703
ep14_l0_test_time 0.8620367050170898
Test Epoch14 layer1 Acc 0.9786285714285714, AUC 0.9969961047172546, avg_entr 0.004037000238895416, f1 0.9786285758018494
ep14_l1_test_time 1.452793836593628
Test Epoch14 layer2 Acc 0.9785714285714285, AUC 0.9970918893814087, avg_entr 0.0023707267828285694, f1 0.9785714149475098
ep14_l2_test_time 1.9479198455810547
Test Epoch14 layer3 Acc 0.9786, AUC 0.9967404007911682, avg_entr 0.001965647330507636, f1 0.978600025177002
ep14_l3_test_time 2.4218480587005615
Test Epoch14 layer4 Acc 0.9786857142857143, AUC 0.9958500862121582, avg_entr 0.0018269160063937306, f1 0.978685736656189
ep14_l4_test_time 2.931783437728882
gc 0
Train Epoch15 Acc 0.9921107142857143 (555582/560000), AUC 0.9990666508674622
ep15_train_time 191.06467580795288
Test Epoch15 layer0 Acc 0.9746, AUC 0.9984807968139648, avg_entr 0.023513950407505035, f1 0.9746000170707703
ep15_l0_test_time 0.8890345096588135
Test Epoch15 layer1 Acc 0.9788, AUC 0.9970082640647888, avg_entr 0.003961405251175165, f1 0.9787999987602234
ep15_l1_test_time 1.452930212020874
Test Epoch15 layer2 Acc 0.9788285714285714, AUC 0.9969657063484192, avg_entr 0.0024671307764947414, f1 0.9788285493850708
ep15_l2_test_time 1.952988862991333
Test Epoch15 layer3 Acc 0.9786285714285714, AUC 0.9967570900917053, avg_entr 0.002068683272227645, f1 0.9786285758018494
ep15_l3_test_time 2.518634080886841
Test Epoch15 layer4 Acc 0.9786857142857143, AUC 0.9958167672157288, avg_entr 0.0019043786451220512, f1 0.978685736656189
ep15_l4_test_time 3.041317939758301
gc 0
Train Epoch16 Acc 0.9921553571428572 (555607/560000), AUC 0.9990743398666382
ep16_train_time 196.02443742752075
Test Epoch16 layer0 Acc 0.9744571428571429, AUC 0.9984807968139648, avg_entr 0.023417364805936813, f1 0.9744571447372437
ep16_l0_test_time 0.8667738437652588
Test Epoch16 layer1 Acc 0.9787142857142858, AUC 0.9969808459281921, avg_entr 0.004071774892508984, f1 0.9787142872810364
ep16_l1_test_time 1.527517318725586
Test Epoch16 layer2 Acc 0.9786857142857143, AUC 0.9969962239265442, avg_entr 0.0025426580104976892, f1 0.978685736656189
ep16_l2_test_time 2.1773393154144287
Test Epoch16 layer3 Acc 0.9786571428571429, AUC 0.9967886209487915, avg_entr 0.0021194000728428364, f1 0.9786571264266968
ep16_l3_test_time 2.7740478515625
Test Epoch16 layer4 Acc 0.9786571428571429, AUC 0.9958299994468689, avg_entr 0.0018965990748256445, f1 0.9786571264266968
ep16_l4_test_time 3.347777843475342
gc 0
Train Epoch17 Acc 0.9924160714285715 (555753/560000), AUC 0.9990520477294922
ep17_train_time 191.4667685031891
Test Epoch17 layer0 Acc 0.9745714285714285, AUC 0.9984889030456543, avg_entr 0.023408224806189537, f1 0.9745714068412781
ep17_l0_test_time 0.8551287651062012
Test Epoch17 layer1 Acc 0.9785428571428572, AUC 0.9969805479049683, avg_entr 0.0039052385836839676, f1 0.9785428643226624
ep17_l1_test_time 1.3768811225891113
Test Epoch17 layer2 Acc 0.9783428571428572, AUC 0.9969278573989868, avg_entr 0.00241660512983799, f1 0.9783428311347961
ep17_l2_test_time 1.9036588668823242
Test Epoch17 layer3 Acc 0.9784, AUC 0.9967401623725891, avg_entr 0.0019031433621421456, f1 0.9783999919891357
ep17_l3_test_time 2.4322152137756348
Test Epoch17 layer4 Acc 0.9785142857142857, AUC 0.9957867860794067, avg_entr 0.0016822797479107976, f1 0.9785143136978149
ep17_l4_test_time 2.948570966720581
gc 0
Train Epoch18 Acc 0.992425 (555758/560000), AUC 0.9990983009338379
ep18_train_time 190.14419984817505
Test Epoch18 layer0 Acc 0.9744, AUC 0.9984793663024902, avg_entr 0.02335997112095356, f1 0.974399983882904
ep18_l0_test_time 0.847280740737915
Test Epoch18 layer1 Acc 0.9786571428571429, AUC 0.9969695210456848, avg_entr 0.0038640075363218784, f1 0.9786571264266968
ep18_l1_test_time 1.4446995258331299
Test Epoch18 layer2 Acc 0.9782571428571428, AUC 0.996951162815094, avg_entr 0.002496344968676567, f1 0.9782571196556091
ep18_l2_test_time 1.9678623676300049
Test Epoch18 layer3 Acc 0.9784571428571428, AUC 0.9966835379600525, avg_entr 0.002005204325541854, f1 0.9784571528434753
ep18_l3_test_time 2.5004723072052
Test Epoch18 layer4 Acc 0.9785142857142857, AUC 0.995752215385437, avg_entr 0.0018192111747339368, f1 0.9785143136978149
ep18_l4_test_time 2.948134660720825
gc 0
Train Epoch19 Acc 0.9925714285714285 (555840/560000), AUC 0.9990944862365723
ep19_train_time 197.02764678001404
Test Epoch19 layer0 Acc 0.9745142857142857, AUC 0.9984785914421082, avg_entr 0.02343137562274933, f1 0.9745143055915833
ep19_l0_test_time 1.001406192779541
Test Epoch19 layer1 Acc 0.9790857142857143, AUC 0.9969070553779602, avg_entr 0.003927749581634998, f1 0.9790857434272766
ep19_l1_test_time 1.556509256362915
Test Epoch19 layer2 Acc 0.9782, AUC 0.9969512224197388, avg_entr 0.0024247949477285147, f1 0.9782000184059143
ep19_l2_test_time 1.927880048751831
Test Epoch19 layer3 Acc 0.9783142857142857, AUC 0.996739387512207, avg_entr 0.001955960178747773, f1 0.9783142805099487
ep19_l3_test_time 2.4653680324554443
Test Epoch19 layer4 Acc 0.9782857142857143, AUC 0.9958666563034058, avg_entr 0.001818917691707611, f1 0.9782857298851013
ep19_l4_test_time 2.9632480144500732
gc 0
Train Epoch20 Acc 0.9926089285714286 (555861/560000), AUC 0.9991083145141602
ep20_train_time 245.34100580215454
Test Epoch20 layer0 Acc 0.9744571428571429, AUC 0.9984813332557678, avg_entr 0.023434126749634743, f1 0.9744571447372437
ep20_l0_test_time 1.18074369430542
Test Epoch20 layer1 Acc 0.9785714285714285, AUC 0.9969659447669983, avg_entr 0.003933667670935392, f1 0.9785714149475098
ep20_l1_test_time 1.792525053024292
Test Epoch20 layer2 Acc 0.9781714285714286, AUC 0.9968423843383789, avg_entr 0.002468276536092162, f1 0.9781714081764221
ep20_l2_test_time 2.5489819049835205
Test Epoch20 layer3 Acc 0.9782285714285714, AUC 0.9965617060661316, avg_entr 0.002017366234213114, f1 0.9782285690307617
ep20_l3_test_time 3.2101032733917236
Test Epoch20 layer4 Acc 0.9782, AUC 0.9955758452415466, avg_entr 0.0018276252085343003, f1 0.9782000184059143
ep20_l4_test_time 3.8970582485198975
gc 0
Train Epoch21 Acc 0.9927214285714285 (555924/560000), AUC 0.9990989565849304
ep21_train_time 240.839262008667
Test Epoch21 layer0 Acc 0.9746, AUC 0.9984807968139648, avg_entr 0.02340584248304367, f1 0.9746000170707703
ep21_l0_test_time 1.180884838104248
Test Epoch21 layer1 Acc 0.9786, AUC 0.9969291090965271, avg_entr 0.003996381536126137, f1 0.978600025177002
ep21_l1_test_time 1.784423589706421
Test Epoch21 layer2 Acc 0.9781428571428571, AUC 0.9968026280403137, avg_entr 0.002458145609125495, f1 0.9781428575515747
ep21_l2_test_time 2.5623116493225098
Test Epoch21 layer3 Acc 0.9780857142857143, AUC 0.9966318011283875, avg_entr 0.00198285817168653, f1 0.9780856966972351
ep21_l3_test_time 3.1845710277557373
Test Epoch21 layer4 Acc 0.9781714285714286, AUC 0.9956788420677185, avg_entr 0.0018540320452302694, f1 0.9781714081764221
ep21_l4_test_time 3.891777992248535
gc 0
Train Epoch22 Acc 0.9927553571428571 (555943/560000), AUC 0.9990962743759155
ep22_train_time 240.70759105682373
Test Epoch22 layer0 Acc 0.9745428571428572, AUC 0.9984776377677917, avg_entr 0.023324716836214066, f1 0.9745428562164307
ep22_l0_test_time 1.5955307483673096
Test Epoch22 layer1 Acc 0.9786857142857143, AUC 0.9969272613525391, avg_entr 0.003908766433596611, f1 0.978685736656189
ep22_l1_test_time 2.124617338180542
Test Epoch22 layer2 Acc 0.9783142857142857, AUC 0.9968723058700562, avg_entr 0.002469241851940751, f1 0.9783142805099487
ep22_l2_test_time 2.620626926422119
Test Epoch22 layer3 Acc 0.9783142857142857, AUC 0.996635377407074, avg_entr 0.0019314426463097334, f1 0.9783142805099487
ep22_l3_test_time 3.341313123703003
Test Epoch22 layer4 Acc 0.9782857142857143, AUC 0.9956576228141785, avg_entr 0.0016850297106429935, f1 0.9782857298851013
ep22_l4_test_time 3.9160261154174805
gc 0
Train Epoch23 Acc 0.9927214285714285 (555924/560000), AUC 0.9991058111190796
ep23_train_time 224.65427613258362
Test Epoch23 layer0 Acc 0.9746285714285714, AUC 0.9984785914421082, avg_entr 0.023370979353785515, f1 0.9746285676956177
ep23_l0_test_time 0.8497710227966309
Test Epoch23 layer1 Acc 0.9787428571428571, AUC 0.9969269633293152, avg_entr 0.003953701816499233, f1 0.9787428379058838
ep23_l1_test_time 1.4091670513153076
Test Epoch23 layer2 Acc 0.9781142857142857, AUC 0.9968448877334595, avg_entr 0.002506253542378545, f1 0.9781143069267273
ep23_l2_test_time 1.9365975856781006
Test Epoch23 layer3 Acc 0.9780571428571428, AUC 0.9966661334037781, avg_entr 0.0019998305942863226, f1 0.9780571460723877
ep23_l3_test_time 2.4340600967407227
Test Epoch23 layer4 Acc 0.9781142857142857, AUC 0.9955865740776062, avg_entr 0.0017830387223511934, f1 0.9781143069267273
ep23_l4_test_time 2.927495002746582
gc 0
Train Epoch24 Acc 0.9928303571428572 (555985/560000), AUC 0.9991008639335632
ep24_train_time 190.10532784461975
Test Epoch24 layer0 Acc 0.9746285714285714, AUC 0.9984792470932007, avg_entr 0.02338234893977642, f1 0.9746285676956177
ep24_l0_test_time 0.8576357364654541
Test Epoch24 layer1 Acc 0.9785714285714285, AUC 0.9968662261962891, avg_entr 0.003869998501613736, f1 0.9785714149475098
ep24_l1_test_time 1.488349437713623
Test Epoch24 layer2 Acc 0.9782571428571428, AUC 0.9967977404594421, avg_entr 0.002468659309670329, f1 0.9782571196556091
ep24_l2_test_time 1.9835224151611328
Test Epoch24 layer3 Acc 0.9784, AUC 0.9965528249740601, avg_entr 0.001953250030055642, f1 0.9783999919891357
ep24_l3_test_time 2.426809072494507
Test Epoch24 layer4 Acc 0.9784285714285714, AUC 0.995578944683075, avg_entr 0.0018054649699479342, f1 0.9784285426139832
ep24_l4_test_time 2.9587934017181396
gc 0
Train Epoch25 Acc 0.9928125 (555975/560000), AUC 0.9991150498390198
ep25_train_time 189.95984959602356
Test Epoch25 layer0 Acc 0.9746, AUC 0.9984773397445679, avg_entr 0.023366890847682953, f1 0.9746000170707703
ep25_l0_test_time 0.8502576351165771
Test Epoch25 layer1 Acc 0.9784285714285714, AUC 0.9969117045402527, avg_entr 0.0039126030169427395, f1 0.9784285426139832
ep25_l1_test_time 1.436203956604004
Test Epoch25 layer2 Acc 0.9781428571428571, AUC 0.9968280792236328, avg_entr 0.0024655633606016636, f1 0.9781428575515747
ep25_l2_test_time 1.9499797821044922
Test Epoch25 layer3 Acc 0.9782285714285714, AUC 0.996605396270752, avg_entr 0.001906963181681931, f1 0.9782285690307617
ep25_l3_test_time 2.428504228591919
Test Epoch25 layer4 Acc 0.9782857142857143, AUC 0.995580792427063, avg_entr 0.001693593105301261, f1 0.9782857298851013
ep25_l4_test_time 2.992112874984741
gc 0
Train Epoch26 Acc 0.9928214285714285 (555980/560000), AUC 0.9991036653518677
ep26_train_time 189.83458375930786
Test Epoch26 layer0 Acc 0.9745714285714285, AUC 0.9984766840934753, avg_entr 0.023326300084590912, f1 0.9745714068412781
ep26_l0_test_time 0.8541321754455566
Test Epoch26 layer1 Acc 0.9785142857142857, AUC 0.9969156980514526, avg_entr 0.003946002572774887, f1 0.9785143136978149
ep26_l1_test_time 1.379223346710205
Test Epoch26 layer2 Acc 0.9779714285714286, AUC 0.9967923760414124, avg_entr 0.0025199055671691895, f1 0.9779714345932007
ep26_l2_test_time 1.9295687675476074
Test Epoch26 layer3 Acc 0.9780285714285715, AUC 0.9965471625328064, avg_entr 0.00192361231893301, f1 0.9780285954475403
ep26_l3_test_time 2.4360711574554443
Test Epoch26 layer4 Acc 0.9780857142857143, AUC 0.9955537915229797, avg_entr 0.0017324092332273722, f1 0.9780856966972351
ep26_l4_test_time 2.953734874725342
gc 0
Train Epoch27 Acc 0.9928767857142857 (556011/560000), AUC 0.9991025924682617
ep27_train_time 189.7504870891571
Test Epoch27 layer0 Acc 0.9746285714285714, AUC 0.9984769225120544, avg_entr 0.02335270866751671, f1 0.9746285676956177
ep27_l0_test_time 0.8533985614776611
Test Epoch27 layer1 Acc 0.9786, AUC 0.9968982934951782, avg_entr 0.003949450794607401, f1 0.978600025177002
ep27_l1_test_time 1.4367306232452393
Test Epoch27 layer2 Acc 0.9781428571428571, AUC 0.9968069195747375, avg_entr 0.0024465001188218594, f1 0.9781428575515747
ep27_l2_test_time 1.9088735580444336
Test Epoch27 layer3 Acc 0.9782, AUC 0.9966106414794922, avg_entr 0.001850854023359716, f1 0.9782000184059143
ep27_l3_test_time 2.434495687484741
Test Epoch27 layer4 Acc 0.9782285714285714, AUC 0.9955825209617615, avg_entr 0.0016400273889303207, f1 0.9782285690307617
ep27_l4_test_time 2.9525647163391113
gc 0
Train Epoch28 Acc 0.9929125 (556031/560000), AUC 0.9991146922111511
ep28_train_time 189.7756872177124
Test Epoch28 layer0 Acc 0.9746, AUC 0.9984763860702515, avg_entr 0.023329446092247963, f1 0.9746000170707703
ep28_l0_test_time 0.8792693614959717
Test Epoch28 layer1 Acc 0.9784857142857143, AUC 0.9968934059143066, avg_entr 0.003938511945307255, f1 0.9784857034683228
ep28_l1_test_time 1.3847906589508057
Test Epoch28 layer2 Acc 0.9782, AUC 0.9968103766441345, avg_entr 0.0024310455191880465, f1 0.9782000184059143
ep28_l2_test_time 1.928328514099121
Test Epoch28 layer3 Acc 0.9781714285714286, AUC 0.99659663438797, avg_entr 0.0018562644254416227, f1 0.9781714081764221
ep28_l3_test_time 2.4416415691375732
Test Epoch28 layer4 Acc 0.9782, AUC 0.9955299496650696, avg_entr 0.0016150823794305325, f1 0.9782000184059143
ep28_l4_test_time 2.968362331390381
gc 0
Train Epoch29 Acc 0.9929303571428572 (556041/560000), AUC 0.9991103410720825
ep29_train_time 190.5577142238617
Test Epoch29 layer0 Acc 0.9746285714285714, AUC 0.998477041721344, avg_entr 0.023326054215431213, f1 0.9746285676956177
ep29_l0_test_time 0.875709056854248
Test Epoch29 layer1 Acc 0.9786285714285714, AUC 0.9968892931938171, avg_entr 0.003931257873773575, f1 0.9786285758018494
ep29_l1_test_time 1.3785333633422852
Test Epoch29 layer2 Acc 0.9780571428571428, AUC 0.9968032836914062, avg_entr 0.002454483648762107, f1 0.9780571460723877
ep29_l2_test_time 1.9467101097106934
Test Epoch29 layer3 Acc 0.9781142857142857, AUC 0.996604323387146, avg_entr 0.0018685220275074244, f1 0.9781143069267273
ep29_l3_test_time 2.4545154571533203
Test Epoch29 layer4 Acc 0.9782, AUC 0.9955410361289978, avg_entr 0.0016554015455767512, f1 0.9782000184059143
ep29_l4_test_time 2.931303024291992
Best AUC tensor(0.9792) 9 2
train_loss (2, 5, 30)
valid_acc (5, 30)
valid_AUC (5, 30)
train_acc (30,)
total_train+valid_time 6208.722494363785
Start Testing
Load ckpt at ckpt/dbpedia_14_transformeral_l5_pad80//dbpedia_14_transformeral_l5.pt
Test layer0 Acc 0.9746857142857143, AUC 0.9983209371566772, avg_entr 0.023326314985752106, f1 0.9746857285499573
l0_test_time 0.8366751670837402
Test layer1 Acc 0.9800857142857143, AUC 0.9977882504463196, avg_entr 0.003803819417953491, f1 0.9800857305526733
l1_test_time 1.4641473293304443
Test layer2 Acc 0.9804285714285714, AUC 0.9976462125778198, avg_entr 0.002464895136654377, f1 0.9804285764694214
l2_test_time 1.9188511371612549
Test layer3 Acc 0.9803714285714286, AUC 0.9973655343055725, avg_entr 0.0021862464491277933, f1 0.9803714156150818
l3_test_time 2.4575419425964355
Test layer4 Acc 0.9802571428571428, AUC 0.9967703819274902, avg_entr 0.0019153428729623556, f1 0.9802571535110474
l4_test_time 2.953477144241333
