total count words 222751
vocab size 30000
train size 40000, valid size 5000, test size 5000
found 27937 words in glove
model: TransformerALsideText(
  (layers): ModuleList(
    (0): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=2, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=2, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
  (emb_layers): ModuleList(
    (0): Embedding(30000, 300)
    (1): Embedding(30000, 300)
    (2): Embedding(30000, 300)
    (3): Embedding(30000, 300)
    (4): Embedding(30000, 300)
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.multi_headed_attention.linears.0.weight 90000
layers.0.enc.f.multi_headed_attention.linears.0.bias 300
layers.0.enc.f.multi_headed_attention.linears.1.weight 90000
layers.0.enc.f.multi_headed_attention.linears.1.bias 300
layers.0.enc.f.multi_headed_attention.linears.2.weight 90000
layers.0.enc.f.multi_headed_attention.linears.2.bias 300
layers.0.enc.f.multi_headed_attention.linears.3.weight 90000
layers.0.enc.f.multi_headed_attention.linears.3.bias 300
layers.0.enc.f.feed_forward.w_1.weight 90000
layers.0.enc.f.feed_forward.w_1.bias 300
layers.0.enc.f.feed_forward.w_2.weight 90000
layers.0.enc.f.feed_forward.w_2.bias 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.0.enc.f.encoder.norm.a 300
layers.0.enc.f.encoder.norm.b 300
layers.0.ae.g.0.weight 256
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 256
layers.0.ae.h.0.bias 2
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
emb_layers.0.weight 9000000
emb_layers.1.weight 9000000
emb_layers.2.weight 9000000
emb_layers.3.weight 9000000
emb_layers.4.weight 9000000
Total Trainable Params: 50758378
init_time 21.628941415
Start Training
gc 0
Train Epoch0 Acc 0.500175 (20007/40000), AUC 0.5007013082504272
ep0_train_time 23.512084086999998
Test Epoch0 layer0 Acc 0.514, AUC 0.5405720472335815, avg_entr 0.6961802244186401, f1 0.5139999985694885
ep0_l0_test_time 0.28582404200000155
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 0
Test Epoch0 layer1 Acc 0.5604, AUC 0.5772959589958191, avg_entr 0.6944748163223267, f1 0.5604000091552734
ep0_l1_test_time 0.3559232699999981
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 0
Test Epoch0 layer2 Acc 0.5296, AUC 0.542435884475708, avg_entr 0.6922218799591064, f1 0.5296000242233276
ep0_l2_test_time 0.46270426399999565
Test Epoch0 layer3 Acc 0.5066, AUC 0.5052674412727356, avg_entr 0.6913812160491943, f1 0.506600022315979
ep0_l3_test_time 0.6119862939999976
Test Epoch0 layer4 Acc 0.5002, AUC 0.5219389200210571, avg_entr 0.6912462711334229, f1 0.5001999735832214
ep0_l4_test_time 0.8055788489999998
gc 0
Train Epoch1 Acc 0.51155 (20462/40000), AUC 0.515784740447998
ep1_train_time 23.060034641
Test Epoch1 layer0 Acc 0.5096, AUC 0.5915016531944275, avg_entr 0.6810075044631958, f1 0.5095999836921692
ep1_l0_test_time 0.2842031750000018
Test Epoch1 layer1 Acc 0.5112, AUC 0.5932213664054871, avg_entr 0.6696492433547974, f1 0.5112000107765198
ep1_l1_test_time 0.3550388529999964
Test Epoch1 layer2 Acc 0.5006, AUC 0.5982280969619751, avg_entr 0.6783173084259033, f1 0.5005999803543091
ep1_l2_test_time 0.4643930130000058
Test Epoch1 layer3 Acc 0.5174, AUC 0.5565625429153442, avg_entr 0.6922176480293274, f1 0.5174000263214111
ep1_l3_test_time 0.6140296229999933
Test Epoch1 layer4 Acc 0.5008, AUC 0.5386183857917786, avg_entr 0.6890697479248047, f1 0.5008000135421753
ep1_l4_test_time 0.8089480229999992
gc 0
Train Epoch2 Acc 0.5188 (20752/40000), AUC 0.5303224921226501
ep2_train_time 23.036267504999998
Test Epoch2 layer0 Acc 0.6026, AUC 0.6477798223495483, avg_entr 0.6272724866867065, f1 0.6025999784469604
ep2_l0_test_time 0.28803779599999757
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 2
Test Epoch2 layer1 Acc 0.5834, AUC 0.6656134128570557, avg_entr 0.61757493019104, f1 0.5834000110626221
ep2_l1_test_time 0.3564350599999955
Test Epoch2 layer2 Acc 0.54, AUC 0.6523065567016602, avg_entr 0.6139122843742371, f1 0.5400000214576721
ep2_l2_test_time 0.46443078800000137
Test Epoch2 layer3 Acc 0.541, AUC 0.6490519046783447, avg_entr 0.6799716949462891, f1 0.5410000085830688
ep2_l3_test_time 0.6129052729999955
Test Epoch2 layer4 Acc 0.5572, AUC 0.6078014373779297, avg_entr 0.6856938600540161, f1 0.557200014591217
ep2_l4_test_time 0.8086471240000037
gc 0
Train Epoch3 Acc 0.5782 (23128/40000), AUC 0.6022006273269653
ep3_train_time 23.062884984000007
Test Epoch3 layer0 Acc 0.6258, AUC 0.69225013256073, avg_entr 0.5330188274383545, f1 0.6258000135421753
ep3_l0_test_time 0.28469186300000615
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer1 Acc 0.6388, AUC 0.726753830909729, avg_entr 0.48664653301239014, f1 0.6388000249862671
ep3_l1_test_time 0.35532441200000164
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer2 Acc 0.655, AUC 0.7336957454681396, avg_entr 0.5201009511947632, f1 0.6549999713897705
ep3_l2_test_time 0.46523727999999664
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer3 Acc 0.6668, AUC 0.727632999420166, avg_entr 0.5786572098731995, f1 0.6668000221252441
ep3_l3_test_time 0.6159631419999982
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer4 Acc 0.6526, AUC 0.7121421098709106, avg_entr 0.6281625032424927, f1 0.6525999903678894
ep3_l4_test_time 0.8111090780000012
gc 0
Train Epoch4 Acc 0.622 (24880/40000), AUC 0.6674259305000305
ep4_train_time 23.203763169
Test Epoch4 layer0 Acc 0.6506, AUC 0.7292797565460205, avg_entr 0.4534473717212677, f1 0.650600016117096
ep4_l0_test_time 0.2834595770000021
Test Epoch4 layer1 Acc 0.6138, AUC 0.7579819560050964, avg_entr 0.36342740058898926, f1 0.6137999892234802
ep4_l1_test_time 0.35556594100000893
Test Epoch4 layer2 Acc 0.5658, AUC 0.7644890546798706, avg_entr 0.31130191683769226, f1 0.5658000111579895
ep4_l2_test_time 0.4638832789999867
Test Epoch4 layer3 Acc 0.5284, AUC 0.7621785998344421, avg_entr 0.2548377811908722, f1 0.5284000039100647
ep4_l3_test_time 0.6166224480000153
Test Epoch4 layer4 Acc 0.5092, AUC 0.7439489364624023, avg_entr 0.242011159658432, f1 0.5091999769210815
ep4_l4_test_time 0.8089381979999928
gc 0
Train Epoch5 Acc 0.66125 (26450/40000), AUC 0.725553035736084
ep5_train_time 23.091383279000013
Test Epoch5 layer0 Acc 0.6478, AUC 0.7518444061279297, avg_entr 0.35263147950172424, f1 0.6478000283241272
ep5_l0_test_time 0.28536779300000603
Test Epoch5 layer1 Acc 0.6666, AUC 0.7878496646881104, avg_entr 0.3318171501159668, f1 0.6665999889373779
ep5_l1_test_time 0.3539998249999883
Test Epoch5 layer2 Acc 0.6614, AUC 0.7969330549240112, avg_entr 0.3104923367500305, f1 0.6614000201225281
ep5_l2_test_time 0.463074234000004
Test Epoch5 layer3 Acc 0.6536, AUC 0.7961412072181702, avg_entr 0.3070704936981201, f1 0.6535999774932861
ep5_l3_test_time 0.6123803090000024
Test Epoch5 layer4 Acc 0.6406, AUC 0.7940576076507568, avg_entr 0.311100035905838, f1 0.6406000256538391
ep5_l4_test_time 0.807875523000007
gc 0
Train Epoch6 Acc 0.70825 (28330/40000), AUC 0.7811374664306641
ep6_train_time 23.149007571
Test Epoch6 layer0 Acc 0.6928, AUC 0.7665433883666992, avg_entr 0.3693506717681885, f1 0.692799985408783
ep6_l0_test_time 0.28586450199998126
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer1 Acc 0.724, AUC 0.8016395568847656, avg_entr 0.34022894501686096, f1 0.7239999175071716
ep6_l1_test_time 0.35532426599999667
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer2 Acc 0.7302, AUC 0.8106244802474976, avg_entr 0.3283174932003021, f1 0.7301999926567078
ep6_l2_test_time 0.46587783100000024
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer3 Acc 0.7258, AUC 0.8098077774047852, avg_entr 0.3191467225551605, f1 0.7257999777793884
ep6_l3_test_time 0.6144157889999917
Test Epoch6 layer4 Acc 0.7138, AUC 0.8083018064498901, avg_entr 0.31279850006103516, f1 0.7138000130653381
ep6_l4_test_time 0.8098857080000244
gc 0
Train Epoch7 Acc 0.731225 (29249/40000), AUC 0.8071277737617493
ep7_train_time 23.056702752999996
Test Epoch7 layer0 Acc 0.6978, AUC 0.7759374380111694, avg_entr 0.3699931502342224, f1 0.6977999806404114
ep7_l0_test_time 0.28424967699999115
Test Epoch7 layer1 Acc 0.73, AUC 0.8129467964172363, avg_entr 0.33373719453811646, f1 0.7300000190734863
ep7_l1_test_time 0.35417675200000076
Test Epoch7 layer2 Acc 0.7414, AUC 0.8250289559364319, avg_entr 0.3188832402229309, f1 0.7414000034332275
ep7_l2_test_time 0.464412579999987
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 7
Test Epoch7 layer3 Acc 0.7438, AUC 0.8262048363685608, avg_entr 0.31808382272720337, f1 0.7437999248504639
ep7_l3_test_time 0.6136026630000231
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 7
Test Epoch7 layer4 Acc 0.7374, AUC 0.825228214263916, avg_entr 0.3319944143295288, f1 0.7373999953269958
ep7_l4_test_time 0.8100229850000176
gc 0
Train Epoch8 Acc 0.765875 (30635/40000), AUC 0.8449453711509705
ep8_train_time 23.184205531000003
Test Epoch8 layer0 Acc 0.7008, AUC 0.783348560333252, avg_entr 0.292605996131897, f1 0.7008000016212463
ep8_l0_test_time 0.2842734019999966
Test Epoch8 layer1 Acc 0.7364, AUC 0.8187297582626343, avg_entr 0.28004297614097595, f1 0.7364000082015991
ep8_l1_test_time 0.35550273199999083
Test Epoch8 layer2 Acc 0.7514, AUC 0.8331302404403687, avg_entr 0.2769940197467804, f1 0.7513999938964844
ep8_l2_test_time 0.4652145109999992
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 8
Test Epoch8 layer3 Acc 0.7526, AUC 0.8345102667808533, avg_entr 0.2716168463230133, f1 0.7526000142097473
ep8_l3_test_time 0.6164728850000074
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 8
Test Epoch8 layer4 Acc 0.7462, AUC 0.83317631483078, avg_entr 0.27940526604652405, f1 0.7462000250816345
ep8_l4_test_time 0.8114986570000156
gc 0
Train Epoch9 Acc 0.76795 (30718/40000), AUC 0.8494784832000732
ep9_train_time 23.047754235000014
Test Epoch9 layer0 Acc 0.665, AUC 0.787895917892456, avg_entr 0.24075791239738464, f1 0.6650000214576721
ep9_l0_test_time 0.2833373490000213
Test Epoch9 layer1 Acc 0.6834, AUC 0.8248714208602905, avg_entr 0.23156528174877167, f1 0.6833999752998352
ep9_l1_test_time 0.3540736869999819
Test Epoch9 layer2 Acc 0.6642, AUC 0.8405941128730774, avg_entr 0.230817973613739, f1 0.6642000079154968
ep9_l2_test_time 0.4637710530000163
Test Epoch9 layer3 Acc 0.643, AUC 0.839662492275238, avg_entr 0.21987231075763702, f1 0.6430000066757202
ep9_l3_test_time 0.6126885159999915
Test Epoch9 layer4 Acc 0.6254, AUC 0.8366791009902954, avg_entr 0.20708520710468292, f1 0.6254000067710876
ep9_l4_test_time 0.8086525069999766
gc 0
Train Epoch10 Acc 0.785675 (31427/40000), AUC 0.8667950630187988
ep10_train_time 23.041589302999967
Test Epoch10 layer0 Acc 0.714, AUC 0.7917435169219971, avg_entr 0.3107777535915375, f1 0.7139999866485596
ep10_l0_test_time 0.2854198900000142
Test Epoch10 layer1 Acc 0.7486, AUC 0.8286736607551575, avg_entr 0.2741205096244812, f1 0.7486000061035156
ep10_l1_test_time 0.3567056599999887
Test Epoch10 layer2 Acc 0.7602, AUC 0.8439484238624573, avg_entr 0.2569688856601715, f1 0.7602000832557678
ep10_l2_test_time 0.4665024309999808
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 10
Test Epoch10 layer3 Acc 0.7624, AUC 0.8461114168167114, avg_entr 0.2345828115940094, f1 0.7623999714851379
ep10_l3_test_time 0.6141015690000131
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 10
Test Epoch10 layer4 Acc 0.7564, AUC 0.8450801372528076, avg_entr 0.22264501452445984, f1 0.7563999891281128
ep10_l4_test_time 0.8125492789999953
gc 0
Train Epoch11 Acc 0.8057 (32228/40000), AUC 0.8879185914993286
ep11_train_time 23.055834032000007
Test Epoch11 layer0 Acc 0.6876, AUC 0.7901017665863037, avg_entr 0.2631130814552307, f1 0.6876000165939331
ep11_l0_test_time 0.2854355129999817
Test Epoch11 layer1 Acc 0.7042, AUC 0.8282098174095154, avg_entr 0.21277084946632385, f1 0.704200029373169
ep11_l1_test_time 0.3560841400000072
Test Epoch11 layer2 Acc 0.7092, AUC 0.8419729471206665, avg_entr 0.1852501481771469, f1 0.7092000246047974
ep11_l2_test_time 0.4672426590000214
Test Epoch11 layer3 Acc 0.6882, AUC 0.8432935476303101, avg_entr 0.16405126452445984, f1 0.6881999969482422
ep11_l3_test_time 0.6136317280000299
Test Epoch11 layer4 Acc 0.6854, AUC 0.8414472341537476, avg_entr 0.1616542488336563, f1 0.6854000091552734
ep11_l4_test_time 0.8092598679999696
gc 0
Train Epoch12 Acc 0.808675 (32347/40000), AUC 0.8888678550720215
ep12_train_time 23.024401726999997
Test Epoch12 layer0 Acc 0.7158, AUC 0.7884212136268616, avg_entr 0.2585742175579071, f1 0.7157999873161316
ep12_l0_test_time 0.2848545120000381
Test Epoch12 layer1 Acc 0.7468, AUC 0.8272355794906616, avg_entr 0.2007826268672943, f1 0.7468000054359436
ep12_l1_test_time 0.3552217039999732
Test Epoch12 layer2 Acc 0.7634, AUC 0.8439488410949707, avg_entr 0.18319633603096008, f1 0.7634000182151794
ep12_l2_test_time 0.4652497200000312
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 12
Test Epoch12 layer3 Acc 0.7606, AUC 0.845651388168335, avg_entr 0.16710807383060455, f1 0.7605999708175659
ep12_l3_test_time 0.6162187770000287
Test Epoch12 layer4 Acc 0.7574, AUC 0.8443266153335571, avg_entr 0.1572861522436142, f1 0.7573999762535095
ep12_l4_test_time 0.8096341209999878
gc 0
Train Epoch13 Acc 0.843475 (33739/40000), AUC 0.9187383651733398
ep13_train_time 23.120219058000032
Test Epoch13 layer0 Acc 0.7092, AUC 0.7844854593276978, avg_entr 0.2546495497226715, f1 0.7092000246047974
ep13_l0_test_time 0.2838547270000049
Test Epoch13 layer1 Acc 0.7474, AUC 0.8288295269012451, avg_entr 0.2224976271390915, f1 0.7473999857902527
ep13_l1_test_time 0.3620307969999885
Test Epoch13 layer2 Acc 0.7618, AUC 0.8461684584617615, avg_entr 0.20470774173736572, f1 0.7618000507354736
ep13_l2_test_time 0.46337487200003125
Test Epoch13 layer3 Acc 0.7644, AUC 0.8489807844161987, avg_entr 0.18425607681274414, f1 0.7644000053405762
ep13_l3_test_time 0.614190184999984
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 13
Test Epoch13 layer4 Acc 0.765, AUC 0.8484517335891724, avg_entr 0.16968266665935516, f1 0.7649999856948853
ep13_l4_test_time 0.8103003599999852
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 13
gc 0
Train Epoch14 Acc 0.8556 (34224/40000), AUC 0.9281497001647949
ep14_train_time 23.163975083000025
Test Epoch14 layer0 Acc 0.7146, AUC 0.783994734287262, avg_entr 0.22034066915512085, f1 0.7146000266075134
ep14_l0_test_time 0.28540954199996804
Test Epoch14 layer1 Acc 0.747, AUC 0.8247054815292358, avg_entr 0.1819966733455658, f1 0.746999979019165
ep14_l1_test_time 0.3537963860000559
Test Epoch14 layer2 Acc 0.7604, AUC 0.841535210609436, avg_entr 0.16239780187606812, f1 0.7603999972343445
ep14_l2_test_time 0.4631133229999591
Test Epoch14 layer3 Acc 0.7636, AUC 0.8433550596237183, avg_entr 0.13807988166809082, f1 0.7635999917984009
ep14_l3_test_time 0.6129649999999742
Test Epoch14 layer4 Acc 0.7656, AUC 0.8436371088027954, avg_entr 0.1301194578409195, f1 0.7655999660491943
ep14_l4_test_time 0.8104092199999968
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 14
gc 0
Train Epoch15 Acc 0.86255 (34502/40000), AUC 0.9336434602737427
ep15_train_time 23.042790949999983
Test Epoch15 layer0 Acc 0.703, AUC 0.7773877382278442, avg_entr 0.23365607857704163, f1 0.703000009059906
ep15_l0_test_time 0.2837474760000305
Test Epoch15 layer1 Acc 0.7108, AUC 0.8218765258789062, avg_entr 0.19517379999160767, f1 0.7107999920845032
ep15_l1_test_time 0.3532367480000289
Test Epoch15 layer2 Acc 0.7126, AUC 0.8414785265922546, avg_entr 0.16578459739685059, f1 0.7125999927520752
ep15_l2_test_time 0.4626946809999595
Test Epoch15 layer3 Acc 0.7014, AUC 0.8425934314727783, avg_entr 0.1444801688194275, f1 0.7013999819755554
ep15_l3_test_time 0.6129029150000065
Test Epoch15 layer4 Acc 0.6908, AUC 0.8395872116088867, avg_entr 0.1442045420408249, f1 0.6908000111579895
ep15_l4_test_time 0.8083133500000486
gc 0
Train Epoch16 Acc 0.874875 (34995/40000), AUC 0.9440118074417114
ep16_train_time 23.158431397999948
Test Epoch16 layer0 Acc 0.7054, AUC 0.7759469747543335, avg_entr 0.2246478796005249, f1 0.7053999900817871
ep16_l0_test_time 0.28337916399999585
Test Epoch16 layer1 Acc 0.7402, AUC 0.8177835941314697, avg_entr 0.18238471448421478, f1 0.7401999831199646
ep16_l1_test_time 0.3536595329999841
Test Epoch16 layer2 Acc 0.7516, AUC 0.8326927423477173, avg_entr 0.13232925534248352, f1 0.7516000270843506
ep16_l2_test_time 0.46336859600000935
Test Epoch16 layer3 Acc 0.7544, AUC 0.833913266658783, avg_entr 0.09485764056444168, f1 0.7544000148773193
ep16_l3_test_time 0.6132266500000014
Test Epoch16 layer4 Acc 0.7558, AUC 0.8338363766670227, avg_entr 0.08951295912265778, f1 0.7557999491691589
ep16_l4_test_time 0.8086068310000201
gc 0
Train Epoch17 Acc 0.88915 (35566/40000), AUC 0.9520483613014221
ep17_train_time 23.113418238999998
Test Epoch17 layer0 Acc 0.7074, AUC 0.7747540473937988, avg_entr 0.21186679601669312, f1 0.7074000239372253
ep17_l0_test_time 0.28406433399999287
Test Epoch17 layer1 Acc 0.739, AUC 0.8184216618537903, avg_entr 0.17348645627498627, f1 0.7390000820159912
ep17_l1_test_time 0.3543492039999592
Test Epoch17 layer2 Acc 0.7478, AUC 0.8300603628158569, avg_entr 0.11045298725366592, f1 0.7477999925613403
ep17_l2_test_time 0.4636839820000205
Test Epoch17 layer3 Acc 0.7498, AUC 0.8331613540649414, avg_entr 0.09320157021284103, f1 0.7498000264167786
ep17_l3_test_time 0.6123270630000093
Test Epoch17 layer4 Acc 0.7506, AUC 0.8331344127655029, avg_entr 0.08706141263246536, f1 0.7505999803543091
ep17_l4_test_time 0.8096492440000134
gc 0
Train Epoch18 Acc 0.91025 (36410/40000), AUC 0.9682378768920898
ep18_train_time 23.106255574000045
Test Epoch18 layer0 Acc 0.695, AUC 0.7716752290725708, avg_entr 0.21186691522598267, f1 0.6949999928474426
ep18_l0_test_time 0.28551453700004004
Test Epoch18 layer1 Acc 0.7326, AUC 0.8179853558540344, avg_entr 0.17547182738780975, f1 0.7325999140739441
ep18_l1_test_time 0.35624782100001084
Test Epoch18 layer2 Acc 0.7354, AUC 0.8340054750442505, avg_entr 0.09788435697555542, f1 0.7354000210762024
ep18_l2_test_time 0.4690067230000068
Test Epoch18 layer3 Acc 0.7394, AUC 0.8370323777198792, avg_entr 0.0797099843621254, f1 0.7394000291824341
ep18_l3_test_time 0.6139402350000864
Test Epoch18 layer4 Acc 0.7432, AUC 0.8377677202224731, avg_entr 0.0778452605009079, f1 0.7432000041007996
ep18_l4_test_time 0.8158595319999904
gc 0
Train Epoch19 Acc 0.913625 (36545/40000), AUC 0.9689229726791382
ep19_train_time 23.14992934199995
Test Epoch19 layer0 Acc 0.7012, AUC 0.7709535360336304, avg_entr 0.2014082819223404, f1 0.701200008392334
ep19_l0_test_time 0.2833364759999313
Test Epoch19 layer1 Acc 0.739, AUC 0.815177857875824, avg_entr 0.16961273550987244, f1 0.7390000820159912
ep19_l1_test_time 0.35623310000005404
Test Epoch19 layer2 Acc 0.7534, AUC 0.8286533355712891, avg_entr 0.1031360998749733, f1 0.7533999681472778
ep19_l2_test_time 0.46934225500001503
Test Epoch19 layer3 Acc 0.7554, AUC 0.8322131037712097, avg_entr 0.09114792943000793, f1 0.7554000020027161
ep19_l3_test_time 0.6137460379999311
Test Epoch19 layer4 Acc 0.7556, AUC 0.8329774141311646, avg_entr 0.09006930887699127, f1 0.7555999755859375
ep19_l4_test_time 0.8085634390000678
gc 0
Train Epoch20 Acc 0.919475 (36779/40000), AUC 0.9722153544425964
ep20_train_time 23.060343751000005
Test Epoch20 layer0 Acc 0.6956, AUC 0.770256757736206, avg_entr 0.2020244598388672, f1 0.6955999732017517
ep20_l0_test_time 0.2848388200000045
Test Epoch20 layer1 Acc 0.7184, AUC 0.8151854276657104, avg_entr 0.16565124690532684, f1 0.7184000015258789
ep20_l1_test_time 0.3551601760000267
Test Epoch20 layer2 Acc 0.7236, AUC 0.8304265737533569, avg_entr 0.08145535737276077, f1 0.7236000299453735
ep20_l2_test_time 0.46480218199997125
Test Epoch20 layer3 Acc 0.7284, AUC 0.8339084386825562, avg_entr 0.0742419958114624, f1 0.7284000515937805
ep20_l3_test_time 0.6134986350000418
Test Epoch20 layer4 Acc 0.7284, AUC 0.8343504071235657, avg_entr 0.07080785185098648, f1 0.7284000515937805
ep20_l4_test_time 0.8130774030000794
gc 0
Train Epoch21 Acc 0.9275 (37100/40000), AUC 0.9755572080612183
ep21_train_time 23.133628630999965
Test Epoch21 layer0 Acc 0.7012, AUC 0.7664006948471069, avg_entr 0.20001168549060822, f1 0.701200008392334
ep21_l0_test_time 0.2846355909999829
Test Epoch21 layer1 Acc 0.733, AUC 0.8120744228363037, avg_entr 0.16307060420513153, f1 0.7329999804496765
ep21_l1_test_time 0.35247256100001323
Test Epoch21 layer2 Acc 0.7378, AUC 0.8244341611862183, avg_entr 0.08134476095438004, f1 0.7378000020980835
ep21_l2_test_time 0.4611924600000066
Test Epoch21 layer3 Acc 0.7392, AUC 0.8284091353416443, avg_entr 0.07224386930465698, f1 0.7391999959945679
ep21_l3_test_time 0.6144306649999862
Test Epoch21 layer4 Acc 0.7408, AUC 0.8300526142120361, avg_entr 0.06764590740203857, f1 0.7408000230789185
ep21_l4_test_time 0.8108350859999973
gc 0
Train Epoch22 Acc 0.93595 (37438/40000), AUC 0.9808197021484375
ep22_train_time 23.057251545999975
Test Epoch22 layer0 Acc 0.697, AUC 0.7653119564056396, avg_entr 0.1977798044681549, f1 0.6970000267028809
ep22_l0_test_time 0.28359505599996737
Test Epoch22 layer1 Acc 0.731, AUC 0.8101987242698669, avg_entr 0.1571667194366455, f1 0.7310000061988831
ep22_l1_test_time 0.35367979400007243
Test Epoch22 layer2 Acc 0.7358, AUC 0.8195927143096924, avg_entr 0.07216646522283554, f1 0.73580002784729
ep22_l2_test_time 0.46430726299990965
Test Epoch22 layer3 Acc 0.7396, AUC 0.8246099352836609, avg_entr 0.06427239626646042, f1 0.7396000027656555
ep22_l3_test_time 0.6144721050000044
Test Epoch22 layer4 Acc 0.7424, AUC 0.8273235559463501, avg_entr 0.058850646018981934, f1 0.742400050163269
ep22_l4_test_time 0.8097735520000242
gc 0
Train Epoch23 Acc 0.936475 (37459/40000), AUC 0.9808540344238281
ep23_train_time 23.18432563700003
Test Epoch23 layer0 Acc 0.6936, AUC 0.764477014541626, avg_entr 0.19158464670181274, f1 0.6935999989509583
ep23_l0_test_time 0.284645122000029
Test Epoch23 layer1 Acc 0.7274, AUC 0.8065378069877625, avg_entr 0.14856307208538055, f1 0.7274000644683838
ep23_l1_test_time 0.3555336739999575
Test Epoch23 layer2 Acc 0.7344, AUC 0.8185589909553528, avg_entr 0.06591200828552246, f1 0.7343999147415161
ep23_l2_test_time 0.46484305799992853
Test Epoch23 layer3 Acc 0.74, AUC 0.8212892413139343, avg_entr 0.05712399259209633, f1 0.7400000095367432
ep23_l3_test_time 0.6138040920000094
Test Epoch23 layer4 Acc 0.7402, AUC 0.8240005970001221, avg_entr 0.05294393375515938, f1 0.7401999831199646
ep23_l4_test_time 0.8101199879999967
gc 0
Train Epoch24 Acc 0.93685 (37474/40000), AUC 0.9819005727767944
ep24_train_time 23.136207044000002
Test Epoch24 layer0 Acc 0.6932, AUC 0.7634390592575073, avg_entr 0.19152121245861053, f1 0.6931999921798706
ep24_l0_test_time 0.28395112500004416
Test Epoch24 layer1 Acc 0.7268, AUC 0.8053578734397888, avg_entr 0.14895755052566528, f1 0.7268000245094299
ep24_l1_test_time 0.35428032200002235
Test Epoch24 layer2 Acc 0.7402, AUC 0.8178478479385376, avg_entr 0.06691053509712219, f1 0.7401999831199646
ep24_l2_test_time 0.4646971999999323
Test Epoch24 layer3 Acc 0.7422, AUC 0.8216756582260132, avg_entr 0.05919047072529793, f1 0.7422000169754028
ep24_l3_test_time 0.6136813550000397
Test Epoch24 layer4 Acc 0.7474, AUC 0.8241114020347595, avg_entr 0.054769665002822876, f1 0.7473999857902527
ep24_l4_test_time 0.8107593979999592
gc 0
Train Epoch25 Acc 0.943275 (37731/40000), AUC 0.984157919883728
ep25_train_time 23.140686071000005
Test Epoch25 layer0 Acc 0.6938, AUC 0.7626945376396179, avg_entr 0.19260059297084808, f1 0.6937999725341797
ep25_l0_test_time 0.2840138830000569
Test Epoch25 layer1 Acc 0.7304, AUC 0.8048104047775269, avg_entr 0.15064558386802673, f1 0.7304000854492188
ep25_l1_test_time 0.35362500499991256
Test Epoch25 layer2 Acc 0.7408, AUC 0.8155118823051453, avg_entr 0.06686689704656601, f1 0.7408000230789185
ep25_l2_test_time 0.4635469700000385
Test Epoch25 layer3 Acc 0.7442, AUC 0.8178502321243286, avg_entr 0.05870980769395828, f1 0.7441999316215515
ep25_l3_test_time 0.6134118859999944
Test Epoch25 layer4 Acc 0.744, AUC 0.8208915591239929, avg_entr 0.053884174674749374, f1 0.7439999580383301
ep25_l4_test_time 0.8111497080000163
gc 0
Train Epoch26 Acc 0.944175 (37767/40000), AUC 0.9856585264205933
ep26_train_time 23.188842762000036
Test Epoch26 layer0 Acc 0.6922, AUC 0.7630429267883301, avg_entr 0.19085557758808136, f1 0.6922000050544739
ep26_l0_test_time 0.2862279049999188
Test Epoch26 layer1 Acc 0.7318, AUC 0.8060758113861084, avg_entr 0.1486901193857193, f1 0.7318000197410583
ep26_l1_test_time 0.35654291000003013
Test Epoch26 layer2 Acc 0.7404, AUC 0.8140960931777954, avg_entr 0.06297559291124344, f1 0.7404000163078308
ep26_l2_test_time 0.46568369399994936
Test Epoch26 layer3 Acc 0.7444, AUC 0.8190360069274902, avg_entr 0.056379906833171844, f1 0.7444000244140625
ep26_l3_test_time 0.6139601940000148
Test Epoch26 layer4 Acc 0.7482, AUC 0.8218940496444702, avg_entr 0.05213654786348343, f1 0.748199999332428
ep26_l4_test_time 0.8104233349999959
gc 0
Train Epoch27 Acc 0.944075 (37763/40000), AUC 0.9858090877532959
ep27_train_time 23.036905422000018
Test Epoch27 layer0 Acc 0.6926, AUC 0.7623759508132935, avg_entr 0.18855653703212738, f1 0.6926000118255615
ep27_l0_test_time 0.28444726299994727
Test Epoch27 layer1 Acc 0.729, AUC 0.8034721612930298, avg_entr 0.14580686390399933, f1 0.7289999723434448
ep27_l1_test_time 0.354880210000033
Test Epoch27 layer2 Acc 0.7376, AUC 0.8113032579421997, avg_entr 0.0631188452243805, f1 0.7376000285148621
ep27_l2_test_time 0.4637408810000352
Test Epoch27 layer3 Acc 0.7404, AUC 0.8154665231704712, avg_entr 0.05709448084235191, f1 0.7404000163078308
ep27_l3_test_time 0.614789883999947
Test Epoch27 layer4 Acc 0.7442, AUC 0.8194065093994141, avg_entr 0.05318035930395126, f1 0.7441999316215515
ep27_l4_test_time 0.8097857650000151
gc 0
Train Epoch28 Acc 0.946825 (37873/40000), AUC 0.9859192371368408
ep28_train_time 23.08840103299997
Test Epoch28 layer0 Acc 0.693, AUC 0.7619688510894775, avg_entr 0.18929557502269745, f1 0.6930000185966492
ep28_l0_test_time 0.28431721300000845
Test Epoch28 layer1 Acc 0.7306, AUC 0.8046748638153076, avg_entr 0.1491522192955017, f1 0.7305999994277954
ep28_l1_test_time 0.35468309899999895
Test Epoch28 layer2 Acc 0.7408, AUC 0.8123953938484192, avg_entr 0.0655779093503952, f1 0.7408000230789185
ep28_l2_test_time 0.4637584250000373
Test Epoch28 layer3 Acc 0.743, AUC 0.815125584602356, avg_entr 0.056219298392534256, f1 0.7430000305175781
ep28_l3_test_time 0.6149979629999507
Test Epoch28 layer4 Acc 0.7464, AUC 0.8197553157806396, avg_entr 0.05253906920552254, f1 0.7463999390602112
ep28_l4_test_time 0.8091153530000383
gc 0
Train Epoch29 Acc 0.948425 (37937/40000), AUC 0.9864712953567505
ep29_train_time 23.070403770999974
Test Epoch29 layer0 Acc 0.6936, AUC 0.7621350884437561, avg_entr 0.1895308792591095, f1 0.6935999989509583
ep29_l0_test_time 0.2844628510000575
Test Epoch29 layer1 Acc 0.7266, AUC 0.8050881624221802, avg_entr 0.14583544433116913, f1 0.7265999913215637
ep29_l1_test_time 0.3546268750000081
Test Epoch29 layer2 Acc 0.7326, AUC 0.813104510307312, avg_entr 0.058079224079847336, f1 0.7325999140739441
ep29_l2_test_time 0.4645227729999988
Test Epoch29 layer3 Acc 0.7348, AUC 0.8166438341140747, avg_entr 0.05204731598496437, f1 0.7347999811172485
ep29_l3_test_time 0.6131960850000269
Test Epoch29 layer4 Acc 0.7384, AUC 0.8215380907058716, avg_entr 0.04735259711742401, f1 0.7384000420570374
ep29_l4_test_time 0.808468844999993
gc 0
Train Epoch30 Acc 0.950625 (38025/40000), AUC 0.988437294960022
ep30_train_time 23.105393399000036
Test Epoch30 layer0 Acc 0.6962, AUC 0.7618798017501831, avg_entr 0.18837633728981018, f1 0.6962000131607056
ep30_l0_test_time 0.28846235900005013
Test Epoch30 layer1 Acc 0.7302, AUC 0.8042181730270386, avg_entr 0.14644259214401245, f1 0.7301999926567078
ep30_l1_test_time 0.3560030920000372
Test Epoch30 layer2 Acc 0.7412, AUC 0.8133254051208496, avg_entr 0.06125081330537796, f1 0.7411999702453613
ep30_l2_test_time 0.4656401029999415
Test Epoch30 layer3 Acc 0.744, AUC 0.8156145811080933, avg_entr 0.056388597935438156, f1 0.7439999580383301
ep30_l3_test_time 0.6143808179999724
Test Epoch30 layer4 Acc 0.7464, AUC 0.8194303512573242, avg_entr 0.052263274788856506, f1 0.7463999390602112
ep30_l4_test_time 0.8101849370000309
gc 0
Train Epoch31 Acc 0.952075 (38083/40000), AUC 0.9887820482254028
ep31_train_time 23.08374990699997
Test Epoch31 layer0 Acc 0.6916, AUC 0.7615485191345215, avg_entr 0.18612687289714813, f1 0.6916000247001648
ep31_l0_test_time 0.2841333720000421
Test Epoch31 layer1 Acc 0.7246, AUC 0.8040077686309814, avg_entr 0.14479732513427734, f1 0.7245999574661255
ep31_l1_test_time 0.3685412660000793
Test Epoch31 layer2 Acc 0.7368, AUC 0.8112938404083252, avg_entr 0.05792613700032234, f1 0.7368000149726868
ep31_l2_test_time 0.46708413700002893
Test Epoch31 layer3 Acc 0.7382, AUC 0.8158833980560303, avg_entr 0.05303874984383583, f1 0.7382000684738159
ep31_l3_test_time 0.6132446840000512
Test Epoch31 layer4 Acc 0.7418, AUC 0.819973886013031, avg_entr 0.04868343099951744, f1 0.74180006980896
ep31_l4_test_time 0.8207379420000507
gc 0
Train Epoch32 Acc 0.9509 (38036/40000), AUC 0.9874155521392822
ep32_train_time 23.066776917000084
Test Epoch32 layer0 Acc 0.6912, AUC 0.7608119249343872, avg_entr 0.18723784387111664, f1 0.6912000179290771
ep32_l0_test_time 0.28573700300000837
Test Epoch32 layer1 Acc 0.7288, AUC 0.8023218512535095, avg_entr 0.14542122185230255, f1 0.7287999987602234
ep32_l1_test_time 0.35472045500000604
Test Epoch32 layer2 Acc 0.7412, AUC 0.8111911416053772, avg_entr 0.06126299872994423, f1 0.7411999702453613
ep32_l2_test_time 0.4639610229999107
Test Epoch32 layer3 Acc 0.745, AUC 0.8148514032363892, avg_entr 0.05457208305597305, f1 0.7449999451637268
ep32_l3_test_time 0.6133212850000973
Test Epoch32 layer4 Acc 0.7472, AUC 0.8182629346847534, avg_entr 0.05109965801239014, f1 0.747200071811676
ep32_l4_test_time 0.8098166260000426
gc 0
Train Epoch33 Acc 0.95275 (38110/40000), AUC 0.9887452125549316
ep33_train_time 23.12957221599993
Test Epoch33 layer0 Acc 0.6924, AUC 0.7611669301986694, avg_entr 0.1874496340751648, f1 0.6923999786376953
ep33_l0_test_time 0.2840765509999983
Test Epoch33 layer1 Acc 0.725, AUC 0.803192138671875, avg_entr 0.14343631267547607, f1 0.7250000238418579
ep33_l1_test_time 0.35827206999999817
Test Epoch33 layer2 Acc 0.7336, AUC 0.8100018501281738, avg_entr 0.056512501090765, f1 0.7335999608039856
ep33_l2_test_time 0.4651542660000132
Test Epoch33 layer3 Acc 0.7372, AUC 0.8150292634963989, avg_entr 0.051072873175144196, f1 0.7372000217437744
ep33_l3_test_time 0.6142836230000057
Test Epoch33 layer4 Acc 0.74, AUC 0.81966233253479, avg_entr 0.04638080298900604, f1 0.7400000095367432
ep33_l4_test_time 0.8114194009999665
gc 0
Train Epoch34 Acc 0.95315 (38126/40000), AUC 0.9897156953811646
ep34_train_time 23.071345106999956
Test Epoch34 layer0 Acc 0.6942, AUC 0.7614554166793823, avg_entr 0.18370862305164337, f1 0.6941999793052673
ep34_l0_test_time 0.28422013399995194
Test Epoch34 layer1 Acc 0.7276, AUC 0.8036917448043823, avg_entr 0.14263197779655457, f1 0.7275999784469604
ep34_l1_test_time 0.3541078960000732
Test Epoch34 layer2 Acc 0.7388, AUC 0.812299370765686, avg_entr 0.05688144639134407, f1 0.7387999892234802
ep34_l2_test_time 0.46363481200000933
Test Epoch34 layer3 Acc 0.7412, AUC 0.8154342174530029, avg_entr 0.05075773969292641, f1 0.7411999702453613
ep34_l3_test_time 0.6141362859999617
Test Epoch34 layer4 Acc 0.7412, AUC 0.82015460729599, avg_entr 0.0465056449174881, f1 0.7411999702453613
ep34_l4_test_time 0.8103877040000498
gc 0
Train Epoch35 Acc 0.95395 (38158/40000), AUC 0.9894434213638306
ep35_train_time 23.03438961500001
Test Epoch35 layer0 Acc 0.693, AUC 0.7611666917800903, avg_entr 0.18431155383586884, f1 0.6930000185966492
ep35_l0_test_time 0.28444698399994195
Test Epoch35 layer1 Acc 0.7258, AUC 0.8031773567199707, avg_entr 0.14225664734840393, f1 0.7257999777793884
ep35_l1_test_time 0.3546563370000513
Test Epoch35 layer2 Acc 0.738, AUC 0.811299204826355, avg_entr 0.058100901544094086, f1 0.7379999160766602
ep35_l2_test_time 0.4660403390000738
Test Epoch35 layer3 Acc 0.7416, AUC 0.8137880563735962, avg_entr 0.05007359758019447, f1 0.741599977016449
ep35_l3_test_time 0.6131693809999206
Test Epoch35 layer4 Acc 0.7446, AUC 0.8187167644500732, avg_entr 0.04604683816432953, f1 0.7445999979972839
ep35_l4_test_time 0.8075746510000954
gc 0
Train Epoch36 Acc 0.956325 (38253/40000), AUC 0.9896873235702515
ep36_train_time 23.035114478000082
Test Epoch36 layer0 Acc 0.692, AUC 0.7608474493026733, avg_entr 0.18446530401706696, f1 0.6919999718666077
ep36_l0_test_time 0.283580397000037
Test Epoch36 layer1 Acc 0.727, AUC 0.8026740550994873, avg_entr 0.14296212792396545, f1 0.7269999980926514
ep36_l1_test_time 0.3543121999999812
Test Epoch36 layer2 Acc 0.739, AUC 0.810145378112793, avg_entr 0.0584343858063221, f1 0.7390000820159912
ep36_l2_test_time 0.46325872700003856
Test Epoch36 layer3 Acc 0.745, AUC 0.8136968612670898, avg_entr 0.050284165889024734, f1 0.7449999451637268
ep36_l3_test_time 0.613140584000007
Test Epoch36 layer4 Acc 0.7456, AUC 0.8186746835708618, avg_entr 0.04639969393610954, f1 0.7455999851226807
ep36_l4_test_time 0.809484586999929
gc 0
Train Epoch37 Acc 0.956025 (38241/40000), AUC 0.9899491667747498
ep37_train_time 23.048511933999976
Test Epoch37 layer0 Acc 0.6926, AUC 0.7609765529632568, avg_entr 0.1831907480955124, f1 0.6926000118255615
ep37_l0_test_time 0.28597586499995487
Test Epoch37 layer1 Acc 0.727, AUC 0.802873969078064, avg_entr 0.1409110575914383, f1 0.7269999980926514
ep37_l1_test_time 0.35481553199997506
Test Epoch37 layer2 Acc 0.7382, AUC 0.8103491067886353, avg_entr 0.05792054906487465, f1 0.7382000684738159
ep37_l2_test_time 0.46393491100002393
Test Epoch37 layer3 Acc 0.7412, AUC 0.8139581680297852, avg_entr 0.05084889382123947, f1 0.7411999702453613
ep37_l3_test_time 0.6140937270000677
Test Epoch37 layer4 Acc 0.7426, AUC 0.8189377784729004, avg_entr 0.04679030925035477, f1 0.7426000237464905
ep37_l4_test_time 0.8129545259999986
gc 0
Train Epoch38 Acc 0.95605 (38242/40000), AUC 0.9905717968940735
ep38_train_time 23.107105047999994
Test Epoch38 layer0 Acc 0.6922, AUC 0.7610107660293579, avg_entr 0.18279951810836792, f1 0.6922000050544739
ep38_l0_test_time 0.28340593000007175
Test Epoch38 layer1 Acc 0.7282, AUC 0.8023966550827026, avg_entr 0.14068903028964996, f1 0.7282000184059143
ep38_l1_test_time 0.35412260099997184
Test Epoch38 layer2 Acc 0.7376, AUC 0.8095381855964661, avg_entr 0.05707443878054619, f1 0.7376000285148621
ep38_l2_test_time 0.46413646099995276
Test Epoch38 layer3 Acc 0.7434, AUC 0.8132457733154297, avg_entr 0.04965836927294731, f1 0.743399977684021
ep38_l3_test_time 0.6125351809998847
Test Epoch38 layer4 Acc 0.7438, AUC 0.818110466003418, avg_entr 0.04578681290149689, f1 0.7437999248504639
ep38_l4_test_time 0.8100124580000738
gc 0
Train Epoch39 Acc 0.955925 (38237/40000), AUC 0.9901461601257324
ep39_train_time 23.04989925599989
Test Epoch39 layer0 Acc 0.6926, AUC 0.7608928680419922, avg_entr 0.1833934187889099, f1 0.6926000118255615
ep39_l0_test_time 0.28588262799985387
Test Epoch39 layer1 Acc 0.7252, AUC 0.8025346994400024, avg_entr 0.14132878184318542, f1 0.7251999974250793
ep39_l1_test_time 0.3550852879998274
Test Epoch39 layer2 Acc 0.7358, AUC 0.8099648952484131, avg_entr 0.05626091733574867, f1 0.73580002784729
ep39_l2_test_time 0.4654134410000097
Test Epoch39 layer3 Acc 0.7392, AUC 0.8142595291137695, avg_entr 0.05109380558133125, f1 0.7391999959945679
ep39_l3_test_time 0.617927839999993
Test Epoch39 layer4 Acc 0.7418, AUC 0.8192319869995117, avg_entr 0.04724276810884476, f1 0.74180006980896
ep39_l4_test_time 0.8104950679999092
gc 0
Train Epoch40 Acc 0.956775 (38271/40000), AUC 0.990246593952179
ep40_train_time 23.055146347000118
Test Epoch40 layer0 Acc 0.6924, AUC 0.7608437538146973, avg_entr 0.18276283144950867, f1 0.6923999786376953
ep40_l0_test_time 0.2839202119998845
Test Epoch40 layer1 Acc 0.7268, AUC 0.8021059632301331, avg_entr 0.14031092822551727, f1 0.7268000245094299
ep40_l1_test_time 0.3562073519999558
Test Epoch40 layer2 Acc 0.7382, AUC 0.8090254068374634, avg_entr 0.05742641165852547, f1 0.7382000684738159
ep40_l2_test_time 0.46338727000011204
Test Epoch40 layer3 Acc 0.7434, AUC 0.812052309513092, avg_entr 0.04984920844435692, f1 0.743399977684021
ep40_l3_test_time 0.6134734019999541
Test Epoch40 layer4 Acc 0.7458, AUC 0.8172035813331604, avg_entr 0.04602617770433426, f1 0.7458000183105469
ep40_l4_test_time 0.8107039720000557
gc 0
Train Epoch41 Acc 0.9572 (38288/40000), AUC 0.9901187419891357
ep41_train_time 23.07364493199998
Test Epoch41 layer0 Acc 0.6916, AUC 0.760660707950592, avg_entr 0.18334268033504486, f1 0.6916000247001648
ep41_l0_test_time 0.28453104499999426
Test Epoch41 layer1 Acc 0.7246, AUC 0.8027942180633545, avg_entr 0.14147444069385529, f1 0.7245999574661255
ep41_l1_test_time 0.35637145700002293
Test Epoch41 layer2 Acc 0.7366, AUC 0.8090416193008423, avg_entr 0.05549391359090805, f1 0.7365999817848206
ep41_l2_test_time 0.4687794699998449
Test Epoch41 layer3 Acc 0.7414, AUC 0.81378173828125, avg_entr 0.04890843480825424, f1 0.7414000034332275
ep41_l3_test_time 0.6158582810001008
Test Epoch41 layer4 Acc 0.742, AUC 0.8188239932060242, avg_entr 0.04505510255694389, f1 0.7419999837875366
ep41_l4_test_time 0.8092982660000416
gc 0
Train Epoch42 Acc 0.95655 (38262/40000), AUC 0.9903545379638672
ep42_train_time 23.145252008999933
Test Epoch42 layer0 Acc 0.6928, AUC 0.7605956196784973, avg_entr 0.18345573544502258, f1 0.692799985408783
ep42_l0_test_time 0.2846713019998788
Test Epoch42 layer1 Acc 0.7258, AUC 0.8026413917541504, avg_entr 0.14079780876636505, f1 0.7257999777793884
ep42_l1_test_time 0.3539829940000345
Test Epoch42 layer2 Acc 0.7364, AUC 0.8087318539619446, avg_entr 0.05510568991303444, f1 0.7364000082015991
ep42_l2_test_time 0.46565583899996454
Test Epoch42 layer3 Acc 0.7402, AUC 0.8133970499038696, avg_entr 0.04896247759461403, f1 0.7401999831199646
ep42_l3_test_time 0.6141263350000372
Test Epoch42 layer4 Acc 0.7426, AUC 0.8186571598052979, avg_entr 0.04542941972613335, f1 0.7426000237464905
ep42_l4_test_time 0.8092887249999876
gc 0
Train Epoch43 Acc 0.956625 (38265/40000), AUC 0.9900420904159546
ep43_train_time 23.18200171700005
Test Epoch43 layer0 Acc 0.6926, AUC 0.7606410980224609, avg_entr 0.18280616402626038, f1 0.6926000118255615
ep43_l0_test_time 0.28443441100012024
Test Epoch43 layer1 Acc 0.7268, AUC 0.8024426102638245, avg_entr 0.14051200449466705, f1 0.7268000245094299
ep43_l1_test_time 0.3547754129999703
Test Epoch43 layer2 Acc 0.7372, AUC 0.8093602061271667, avg_entr 0.056147899478673935, f1 0.7372000217437744
ep43_l2_test_time 0.46608015199990405
Test Epoch43 layer3 Acc 0.743, AUC 0.813419759273529, avg_entr 0.04954053834080696, f1 0.7430000305175781
ep43_l3_test_time 0.6144512939999913
Test Epoch43 layer4 Acc 0.7426, AUC 0.8185016512870789, avg_entr 0.045982979238033295, f1 0.7426000237464905
ep43_l4_test_time 0.8091318570000112
gc 0
Train Epoch44 Acc 0.9563 (38252/40000), AUC 0.99075847864151
ep44_train_time 23.12544412400007
Test Epoch44 layer0 Acc 0.6922, AUC 0.7606481313705444, avg_entr 0.18276691436767578, f1 0.6922000050544739
ep44_l0_test_time 0.2848451260001639
Test Epoch44 layer1 Acc 0.7268, AUC 0.8024178743362427, avg_entr 0.14048203825950623, f1 0.7268000245094299
ep44_l1_test_time 0.3559985320000578
Test Epoch44 layer2 Acc 0.737, AUC 0.8096249103546143, avg_entr 0.05597493425011635, f1 0.7369999885559082
ep44_l2_test_time 0.4744016729998748
Test Epoch44 layer3 Acc 0.7426, AUC 0.8133205771446228, avg_entr 0.04951019957661629, f1 0.7426000237464905
ep44_l3_test_time 0.6151718259998233
Test Epoch44 layer4 Acc 0.7428, AUC 0.8184118270874023, avg_entr 0.04600843787193298, f1 0.7427999973297119
ep44_l4_test_time 0.8121320879999985
gc 0
Train Epoch45 Acc 0.956825 (38273/40000), AUC 0.990429699420929
ep45_train_time 23.066031152999813
Test Epoch45 layer0 Acc 0.6918, AUC 0.7605564594268799, avg_entr 0.18282738327980042, f1 0.6917999982833862
ep45_l0_test_time 0.2852148459999171
Test Epoch45 layer1 Acc 0.727, AUC 0.8019764423370361, avg_entr 0.14021825790405273, f1 0.7269999980926514
ep45_l1_test_time 0.3544879559999572
Test Epoch45 layer2 Acc 0.7372, AUC 0.8086251020431519, avg_entr 0.05599530041217804, f1 0.7372000217437744
ep45_l2_test_time 0.4684229290000985
Test Epoch45 layer3 Acc 0.7412, AUC 0.8127223253250122, avg_entr 0.049707379192113876, f1 0.7411999702453613
ep45_l3_test_time 0.6139980489999743
Test Epoch45 layer4 Acc 0.7412, AUC 0.8177917003631592, avg_entr 0.046020347625017166, f1 0.7411999702453613
ep45_l4_test_time 0.8125817719999304
gc 0
Train Epoch46 Acc 0.957125 (38285/40000), AUC 0.9905390739440918
ep46_train_time 23.200264570000172
Test Epoch46 layer0 Acc 0.6926, AUC 0.7604200839996338, avg_entr 0.18288962543010712, f1 0.6926000118255615
ep46_l0_test_time 0.28915823299985277
Test Epoch46 layer1 Acc 0.7274, AUC 0.801999568939209, avg_entr 0.14024865627288818, f1 0.7274000644683838
ep46_l1_test_time 0.35473806899995
Test Epoch46 layer2 Acc 0.7372, AUC 0.8085595965385437, avg_entr 0.05542343109846115, f1 0.7372000217437744
ep46_l2_test_time 0.46330229399995915
Test Epoch46 layer3 Acc 0.7396, AUC 0.8132277727127075, avg_entr 0.04962638020515442, f1 0.7396000027656555
ep46_l3_test_time 0.6137984150000193
Test Epoch46 layer4 Acc 0.7424, AUC 0.8181040287017822, avg_entr 0.04586411640048027, f1 0.742400050163269
ep46_l4_test_time 0.8100323809999281
gc 0
Train Epoch47 Acc 0.957025 (38281/40000), AUC 0.9905121326446533
ep47_train_time 23.08404818500003
Test Epoch47 layer0 Acc 0.693, AUC 0.7603915333747864, avg_entr 0.18271715939044952, f1 0.6930000185966492
ep47_l0_test_time 0.2839220620001015
Test Epoch47 layer1 Acc 0.7256, AUC 0.8020310401916504, avg_entr 0.14015375077724457, f1 0.7255999445915222
ep47_l1_test_time 0.3565693770001417
Test Epoch47 layer2 Acc 0.7364, AUC 0.8083707094192505, avg_entr 0.0555061399936676, f1 0.7364000082015991
ep47_l2_test_time 0.4669717249998939
Test Epoch47 layer3 Acc 0.7404, AUC 0.8130335807800293, avg_entr 0.049401551485061646, f1 0.7404000163078308
ep47_l3_test_time 0.6139568819999113
Test Epoch47 layer4 Acc 0.7418, AUC 0.8179987668991089, avg_entr 0.04573097079992294, f1 0.74180006980896
ep47_l4_test_time 0.8089427370000521
gc 0
Train Epoch48 Acc 0.95655 (38262/40000), AUC 0.9900151491165161
ep48_train_time 23.079824960999986
Test Epoch48 layer0 Acc 0.6922, AUC 0.7604159712791443, avg_entr 0.18251387774944305, f1 0.6922000050544739
ep48_l0_test_time 0.2860401489999731
Test Epoch48 layer1 Acc 0.7264, AUC 0.8021444082260132, avg_entr 0.13997043669223785, f1 0.7264000177383423
ep48_l1_test_time 0.355795550999801
Test Epoch48 layer2 Acc 0.7362, AUC 0.8085339665412903, avg_entr 0.055313996970653534, f1 0.7361999750137329
ep48_l2_test_time 0.4652747340001042
Test Epoch48 layer3 Acc 0.741, AUC 0.8131076097488403, avg_entr 0.049196235835552216, f1 0.7409999370574951
ep48_l3_test_time 0.6146689610000067
Test Epoch48 layer4 Acc 0.742, AUC 0.8180700540542603, avg_entr 0.04550578445196152, f1 0.7419999837875366
ep48_l4_test_time 0.808457935999968
gc 0
Train Epoch49 Acc 0.9573 (38292/40000), AUC 0.9909161329269409
ep49_train_time 23.028471479000018
Test Epoch49 layer0 Acc 0.6924, AUC 0.7604042291641235, avg_entr 0.18242831528186798, f1 0.6923999786376953
ep49_l0_test_time 0.28654832199981684
Test Epoch49 layer1 Acc 0.7262, AUC 0.8020639419555664, avg_entr 0.139760822057724, f1 0.7261999845504761
ep49_l1_test_time 0.3554107949998979
Test Epoch49 layer2 Acc 0.7362, AUC 0.8082540035247803, avg_entr 0.05534528195858002, f1 0.7361999750137329
ep49_l2_test_time 0.4650090579998505
Test Epoch49 layer3 Acc 0.7414, AUC 0.8127637505531311, avg_entr 0.04903481900691986, f1 0.7414000034332275
ep49_l3_test_time 0.6152145639998707
Test Epoch49 layer4 Acc 0.742, AUC 0.8178679943084717, avg_entr 0.045284681022167206, f1 0.7419999837875366
ep49_l4_test_time 0.8100950619998457
Best AUC tensor(0.7656) 14 4
train_as_loss [[8.97316425e+01 5.97793759e+01 5.21811778e+01 5.04898038e+01
  4.99037746e+01 4.96364131e+01 4.94927173e+01 4.94067452e+01
  4.93512929e+01 4.93134845e+01 4.92865775e+01 4.92667721e+01
  4.92517886e+01 4.92401951e+01 4.92310534e+01 4.92253427e+01
  4.92219423e+01 4.92187676e+01 4.92158100e+01 4.92137147e+01
  4.92123437e+01 4.92109768e+01 4.92096181e+01 4.92086031e+01
  4.92079082e+01 4.92071972e+01 4.92064650e+01 4.92059032e+01
  4.92055093e+01 4.92050961e+01 4.92046667e+01 4.92043329e+01
  4.92040903e+01 4.92038378e+01 4.92035751e+01 4.92033624e+01
  4.92032126e+01 4.92030511e+01 4.92028815e+01 4.92027512e+01
  4.92026526e+01 4.92025444e+01 4.92024428e+01 4.92023459e+01
  4.92022907e+01 4.92022129e+01 4.92021525e+01 4.92020816e+01
  4.92020463e+01 4.92020109e+01]
 [1.91702221e+00 5.08620065e-04 1.91434949e-05 4.21225488e-06
  1.52111383e-06 8.88363795e-07 4.26800779e-07 4.52961105e-07
  5.68695206e-07 1.86096467e-07 7.36118366e-08 2.91182734e-07
  5.46786684e-07 6.11264366e-07 4.39448455e-08 3.90958675e-07
  6.29868477e-07 1.09454229e-06 5.60191099e-07 2.06865393e-09
  1.48443631e-09 1.37079711e-09 4.98537637e-09 1.26849319e-09
  1.03051122e-09 9.75495506e-10 3.83496863e-09 9.53865874e-10
  8.24957732e-10 8.37095766e-10 3.20210228e-09 7.79102752e-10
  7.20769508e-10 7.03053342e-10 2.81557995e-09 6.79128887e-10
  6.41970003e-10 6.28848004e-10 2.47572467e-09 6.28159952e-10
  5.98269079e-10 5.78978906e-10 2.24977739e-09 6.13248811e-10
  5.67426816e-10 5.51073583e-10 2.03454984e-09 6.36048545e-10
  5.58923270e-10 5.26942760e-10]
 [1.94541798e+00 3.07956684e-04 1.40889278e-05 3.47600499e-06
  1.35242669e-06 6.23662169e-07 3.43193752e-07 2.08276221e-07
  1.31612023e-07 8.65249914e-08 6.00139511e-08 5.50987724e-08
  6.62617768e-08 1.42731755e-07 2.70098890e-08 1.62915987e-07
  5.32738704e-07 9.54716155e-07 6.91231401e-07 3.21913632e-09
  1.67344479e-09 1.59502737e-09 5.23161218e-09 1.62504508e-09
  1.05632536e-09 1.01994032e-09 3.78268032e-09 1.10420954e-09
  7.89087884e-10 8.29911772e-10 3.04697047e-09 8.40184502e-10
  6.86121751e-10 6.82998670e-10 2.64550438e-09 6.85608771e-10
  5.93477848e-10 5.80812446e-10 2.29147145e-09 6.19764573e-10
  5.53718313e-10 5.37490464e-10 2.06906391e-09 5.97468088e-10
  5.25392190e-10 5.13753399e-10 1.88061944e-09 6.38036148e-10
  5.31878470e-10 5.01675995e-10]
 [2.55621057e+00 9.58994177e-04 1.85214780e-05 5.19846511e-06
  2.17364695e-06 1.02169696e-06 6.00006036e-07 3.67531008e-07
  2.34481088e-07 1.67664593e-07 1.26280578e-07 1.15599077e-07
  9.98685916e-08 1.46542224e-07 4.64306466e-08 1.61707029e-07
  4.57479995e-07 8.80124663e-07 5.88436714e-07 9.26274993e-09
  3.84306672e-09 3.75546374e-09 9.99928970e-09 3.74984181e-09
  1.97519941e-09 1.97290520e-09 6.63125086e-09 2.25171425e-09
  1.31667125e-09 1.47996846e-09 4.96376354e-09 1.60959406e-09
  1.13316082e-09 1.16464282e-09 4.21378354e-09 1.20927706e-09
  9.56206291e-10 9.29324597e-10 3.53492635e-09 1.07383628e-09
  8.73483201e-10 8.37193108e-10 3.12322394e-09 1.02075203e-09
  8.17371854e-10 7.95237751e-10 2.69668308e-09 1.11847934e-09
  8.34927189e-10 7.92398601e-10]
 [1.88509044e+00 1.84925932e-03 1.58151201e-05 5.02297795e-06
  2.37484658e-06 1.15907810e-06 7.38005812e-07 4.21748699e-07
  3.00158913e-07 2.61401397e-07 2.00754265e-07 2.40552373e-07
  1.61008916e-07 1.82650659e-07 9.16551890e-08 2.31556044e-07
  4.14544065e-07 8.49688899e-07 5.19914371e-07 2.30588477e-08
  7.83398645e-09 7.91805038e-09 1.20944198e-08 6.49414396e-09
  2.44769122e-09 2.65764297e-09 6.26757177e-09 3.06089308e-09
  1.08751108e-09 1.60446889e-09 3.74852694e-09 1.70650456e-09
  9.22027843e-10 1.00598544e-09 3.03527262e-09 9.90913727e-10
  6.33043008e-10 6.15613005e-10 2.35693869e-09 7.63978971e-10
  5.95539921e-10 5.61715148e-10 2.13356737e-09 6.82593539e-10
  5.69785723e-10 5.54952555e-10 1.91097617e-09 7.52361575e-10
  5.94892832e-10 5.64838472e-10]]
train_ae_loss [[4.55502313 3.26049546 4.66836259 5.34590238 5.70839711 5.88086667
  6.03816199 6.14448666 6.16561196 6.20889787 6.23328074 6.10069
  6.03629465 5.74463643 5.61696982 5.14208505 4.94573992 4.84572041
  4.68457106 4.43775559 4.3300452  4.25969765 4.20088343 4.08714215
  4.04992767 4.00857645 4.00003996 3.93806532 3.94536288 3.93491025
  3.90194796 3.87680942 3.88097513 3.87111217 3.87561228 3.84585592
  3.83420353 3.83799901 3.84101328 3.8309832  3.82433932 3.82498692
  3.83277074 3.84524902 3.83743111 3.82386049 3.82381639 3.81202644
  3.84257344 3.8190691 ]
 [3.44099125 2.79393334 4.08105721 4.5768532  4.79227119 4.87283695
  4.89610771 4.93638642 4.85584358 4.88525457 4.84156881 4.6862349
  4.61331914 4.31595173 4.19849573 3.88551916 3.71951739 3.58276395
  3.24994051 3.12162985 3.0042172  2.92412777 2.7664451  2.70897767
  2.65423588 2.58381782 2.53985087 2.49771074 2.49107834 2.48120136
  2.42989613 2.38883794 2.40419345 2.38842403 2.37862626 2.34193405
  2.33484865 2.34224006 2.3290759  2.32121748 2.31264816 2.32029299
  2.30492186 2.32125141 2.31430127 2.30568744 2.31119756 2.29881083
  2.28965144 2.2950997 ]
 [3.77100618 2.68063475 3.9327065  4.45315497 4.5369961  4.56653543
  4.55001861 4.56152449 4.40610092 4.45515739 4.3710719  4.18347491
  4.16223348 3.78868607 3.67453474 3.43984885 3.20194221 2.94207929
  2.40746397 2.32155941 2.15936825 2.03298149 1.80770617 1.78312734
  1.71955838 1.61237941 1.54133852 1.50309089 1.50760496 1.48819245
  1.41319182 1.37120754 1.38939753 1.36861671 1.35949728 1.3237724
  1.31072633 1.31466405 1.29335033 1.28595507 1.28906541 1.28559941
  1.27619354 1.29776875 1.26913385 1.27711559 1.27417503 1.2714007
  1.25290256 1.2546872 ]
 [4.06834477 2.32711984 3.44725269 4.07545589 4.09431738 4.08596359
  4.02032478 4.02141778 3.82922882 3.89738735 3.82835784 3.62559707
  3.67205527 3.25084279 3.12098076 2.94835066 2.7341606  2.49166743
  2.00297917 1.951475   1.81525267 1.69809642 1.49970142 1.48626009
  1.43110306 1.3374339  1.27075648 1.24662809 1.25264129 1.23016038
  1.15603175 1.12240062 1.14306542 1.11978444 1.10983488 1.08042596
  1.07095332 1.07364909 1.05137865 1.04990786 1.04764075 1.04509836
  1.03618605 1.05694765 1.02789255 1.03669918 1.03460115 1.03564953
  1.01894641 1.02182442]
 [4.35856689 2.19481514 3.284733   4.00602954 4.19280547 4.20515241
  4.04575286 4.03453905 3.78242702 3.86508138 3.79009759 3.5516363
  3.69937705 3.20507064 3.0203128  2.92780891 2.69044848 2.44754817
  1.91492416 1.88669435 1.7541454  1.63096789 1.43232034 1.42567963
  1.37192425 1.27643387 1.2109187  1.19019824 1.19791672 1.17287588
  1.09656458 1.06519551 1.08460641 1.06422124 1.05254872 1.02356004
  1.0162184  1.01732464 0.99630736 0.99475662 0.99208148 0.99082771
  0.98044481 0.99965719 0.96908357 0.98122579 0.97619506 0.97966477
  0.96206225 0.96851958]]
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
total_train+valid_time 1288.991238588
Start Testing
Load ckpt at ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt
gc 9
Test layer0 Acc 0.7242, AUC 0.8022499084472656, avg_entr 0.21439068019390106, f1 0.7242000699043274
l0_test_time 0.28334310600007484
gc 0
Test layer1 Acc 0.7502, AUC 0.8358579277992249, avg_entr 0.18085378408432007, f1 0.7501999735832214
l1_test_time 0.35812805199998365
gc 0
Test layer2 Acc 0.7652, AUC 0.8523271679878235, avg_entr 0.16266444325447083, f1 0.7652000188827515
l2_test_time 0.46450701599997046
gc 0
Test layer3 Acc 0.7644, AUC 0.8538209199905396, avg_entr 0.13788704574108124, f1 0.7644000053405762
l3_test_time 0.6159055890000218
gc 0
Test layer4 Acc 0.7696, AUC 0.8552151918411255, avg_entr 0.12870757281780243, f1 0.769599974155426
l4_test_time 0.8130200939999668
gc 0
Test threshold 0.1 Acc 0.7672, AUC 0.836815595626831, avg_entr 0.17744620144367218, f1 0.7671999931335449
t0.1_test_time 0.5736096519999592
gc 0
Test threshold 0.2 Acc 0.7642, AUC 0.8310261964797974, avg_entr 0.17946216464042664, f1 0.76419997215271
t0.2_test_time 0.5096717459998672
gc 0
Test threshold 0.3 Acc 0.7602, AUC 0.8262890577316284, avg_entr 0.18368877470493317, f1 0.7602000832557678
t0.3_test_time 0.47149305900006766
gc 0
Test threshold 0.4 Acc 0.756, AUC 0.8232152462005615, avg_entr 0.19072896242141724, f1 0.7559999227523804
t0.4_test_time 0.44235178899998573
gc 0
Test threshold 0.5 Acc 0.751, AUC 0.8198896646499634, avg_entr 0.2021113634109497, f1 0.7509999871253967
t0.5_test_time 0.440526564000038
gc 0
Test threshold 0.6 Acc 0.7476, AUC 0.8174323439598083, avg_entr 0.21292050182819366, f1 0.7476000189781189
t0.6_test_time 0.3965813799998159
gc 0
Test threshold 0.7 Acc 0.745, AUC 0.8140841722488403, avg_entr 0.22657036781311035, f1 0.7449999451637268
t0.7_test_time 0.3810755890001474
gc 0
Test threshold 0.8 Acc 0.7392, AUC 0.8111380934715271, avg_entr 0.2424146980047226, f1 0.7391999959945679
t0.8_test_time 0.3701176080001005
gc 0
Test threshold 0.9 Acc 0.7364, AUC 0.8071144819259644, avg_entr 0.2647424340248108, f1 0.7364000082015991
t0.9_test_time 0.35662001900004725
