total count words 222751
vocab size 30000
train size 40000, valid size 5000, test size 5000
found 27937 words in glove
model: TransformerALsideText(
  (layers): ModuleList(
    (0): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=2, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=2, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
  (emb_layers): ModuleList(
    (0): Embedding(30000, 300)
    (1): Embedding(30000, 300)
    (2): Embedding(30000, 300)
    (3): Embedding(30000, 300)
    (4): Embedding(30000, 300)
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.multi_headed_attention.linears.0.weight 90000
layers.0.enc.f.multi_headed_attention.linears.0.bias 300
layers.0.enc.f.multi_headed_attention.linears.1.weight 90000
layers.0.enc.f.multi_headed_attention.linears.1.bias 300
layers.0.enc.f.multi_headed_attention.linears.2.weight 90000
layers.0.enc.f.multi_headed_attention.linears.2.bias 300
layers.0.enc.f.multi_headed_attention.linears.3.weight 90000
layers.0.enc.f.multi_headed_attention.linears.3.bias 300
layers.0.enc.f.feed_forward.w_1.weight 90000
layers.0.enc.f.feed_forward.w_1.bias 300
layers.0.enc.f.feed_forward.w_2.weight 90000
layers.0.enc.f.feed_forward.w_2.bias 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.0.enc.f.encoder.norm.a 300
layers.0.enc.f.encoder.norm.b 300
layers.0.ae.g.0.weight 256
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 256
layers.0.ae.h.0.bias 2
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
emb_layers.0.weight 9000000
emb_layers.1.weight 9000000
emb_layers.2.weight 9000000
emb_layers.3.weight 9000000
emb_layers.4.weight 9000000
Total Trainable Params: 50758378
init_time 21.920098883999998
Start Training
gc 0
Train Epoch0 Acc 0.505975 (20239/40000), AUC 0.5042589902877808
ep0_train_time 23.504899770999998
Test Epoch0 layer0 Acc 0.5534, AUC 0.5742232799530029, avg_entr 0.6833913326263428, f1 0.5533999800682068
ep0_l0_test_time 0.290776766999997
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 0
Test Epoch0 layer1 Acc 0.536, AUC 0.5680071115493774, avg_entr 0.6885752081871033, f1 0.5360000133514404
ep0_l1_test_time 0.3606442720000018
Test Epoch0 layer2 Acc 0.5204, AUC 0.5300619602203369, avg_entr 0.6872937083244324, f1 0.5203999876976013
ep0_l2_test_time 0.4733010859999993
Test Epoch0 layer3 Acc 0.4986, AUC 0.5088087320327759, avg_entr 0.6924020648002625, f1 0.4986000061035156
ep0_l3_test_time 0.6230430569999967
Test Epoch0 layer4 Acc 0.5064, AUC 0.5044569969177246, avg_entr 0.6875923871994019, f1 0.5063999891281128
ep0_l4_test_time 0.8160840490000041
gc 0
Train Epoch1 Acc 0.50855 (20342/40000), AUC 0.5160693526268005
ep1_train_time 23.142620158
Test Epoch1 layer0 Acc 0.581, AUC 0.6170556545257568, avg_entr 0.6546408534049988, f1 0.5809999704360962
ep1_l0_test_time 0.28958569200000284
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 1
Test Epoch1 layer1 Acc 0.546, AUC 0.6404407620429993, avg_entr 0.6776421666145325, f1 0.5460000038146973
ep1_l1_test_time 0.36165817399999867
Test Epoch1 layer2 Acc 0.5268, AUC 0.6077295541763306, avg_entr 0.6844097375869751, f1 0.5267999768257141
ep1_l2_test_time 0.47174911999999836
Test Epoch1 layer3 Acc 0.5, AUC 0.551689863204956, avg_entr 0.6747097373008728, f1 0.5
ep1_l3_test_time 0.6240834879999966
Test Epoch1 layer4 Acc 0.5, AUC 0.506890594959259, avg_entr 0.6846036911010742, f1 0.5
ep1_l4_test_time 0.8150645580000031
gc 0
Train Epoch2 Acc 0.51265 (20506/40000), AUC 0.5172743201255798
ep2_train_time 23.12655859600001
Test Epoch2 layer0 Acc 0.591, AUC 0.6510423421859741, avg_entr 0.5936716794967651, f1 0.5910000205039978
ep2_l0_test_time 0.302787151000004
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 2
Test Epoch2 layer1 Acc 0.617, AUC 0.693791389465332, avg_entr 0.5595607757568359, f1 0.6169999837875366
ep2_l1_test_time 0.36311915000000283
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 2
Test Epoch2 layer2 Acc 0.6022, AUC 0.6968567967414856, avg_entr 0.6323783993721008, f1 0.6021999716758728
ep2_l2_test_time 0.47359553100000085
Test Epoch2 layer3 Acc 0.5562, AUC 0.6765973567962646, avg_entr 0.6812548637390137, f1 0.5562000274658203
ep2_l3_test_time 0.6262825089999922
Test Epoch2 layer4 Acc 0.5, AUC 0.5889818668365479, avg_entr 0.6798246502876282, f1 0.5
ep2_l4_test_time 0.8168117400000057
gc 0
Train Epoch3 Acc 0.54335 (21734/40000), AUC 0.5614251494407654
ep3_train_time 23.165629093999996
Test Epoch3 layer0 Acc 0.6422, AUC 0.695813775062561, avg_entr 0.5331767201423645, f1 0.6421999931335449
ep3_l0_test_time 0.2994377069999956
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer1 Acc 0.6748, AUC 0.7421432733535767, avg_entr 0.524030864238739, f1 0.6747999787330627
ep3_l1_test_time 0.3644365420000071
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer2 Acc 0.6644, AUC 0.7457955479621887, avg_entr 0.5867467522621155, f1 0.6643999814987183
ep3_l2_test_time 0.4739241230000033
Test Epoch3 layer3 Acc 0.6454, AUC 0.7393897771835327, avg_entr 0.634619951248169, f1 0.6453999876976013
ep3_l3_test_time 0.6272438680000079
Test Epoch3 layer4 Acc 0.5, AUC 0.7186019420623779, avg_entr 0.5723959803581238, f1 0.5
ep3_l4_test_time 0.8200773979999809
gc 0
Train Epoch4 Acc 0.610625 (24425/40000), AUC 0.6494227647781372
ep4_train_time 23.149523756999997
Test Epoch4 layer0 Acc 0.6634, AUC 0.7263913154602051, avg_entr 0.4814942479133606, f1 0.6633999943733215
ep4_l0_test_time 0.2906507440000041
Test Epoch4 layer1 Acc 0.6968, AUC 0.7703421115875244, avg_entr 0.42873895168304443, f1 0.6967999935150146
ep4_l1_test_time 0.36933031299997765
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
Test Epoch4 layer2 Acc 0.6938, AUC 0.775267481803894, avg_entr 0.4251193702220917, f1 0.6937999725341797
ep4_l2_test_time 0.4753795679999939
Test Epoch4 layer3 Acc 0.681, AUC 0.774610161781311, avg_entr 0.454295814037323, f1 0.6809999942779541
ep4_l3_test_time 0.6243357029999856
Test Epoch4 layer4 Acc 0.672, AUC 0.7756539583206177, avg_entr 0.5759761929512024, f1 0.671999990940094
ep4_l4_test_time 0.8223396719999982
gc 0
Train Epoch5 Acc 0.662925 (26517/40000), AUC 0.7226952910423279
ep5_train_time 23.166822892
Test Epoch5 layer0 Acc 0.672, AUC 0.7458856105804443, avg_entr 0.4477452039718628, f1 0.671999990940094
ep5_l0_test_time 0.2929477010000028
Test Epoch5 layer1 Acc 0.7148, AUC 0.7900830507278442, avg_entr 0.42038851976394653, f1 0.7148000597953796
ep5_l1_test_time 0.36307978300001764
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 5
Test Epoch5 layer2 Acc 0.7192, AUC 0.7995933890342712, avg_entr 0.42780762910842896, f1 0.719200074672699
ep5_l2_test_time 0.47503482399997665
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 5
Test Epoch5 layer3 Acc 0.7224, AUC 0.8017919659614563, avg_entr 0.45671606063842773, f1 0.7224000096321106
ep5_l3_test_time 0.6229042150000055
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 5
Test Epoch5 layer4 Acc 0.7246, AUC 0.8023192286491394, avg_entr 0.5024628043174744, f1 0.7245999574661255
ep5_l4_test_time 0.8229362529999946
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 5
gc 0
Train Epoch6 Acc 0.722625 (28905/40000), AUC 0.7989794015884399
ep6_train_time 23.28272446400001
Test Epoch6 layer0 Acc 0.67, AUC 0.7658980488777161, avg_entr 0.34938257932662964, f1 0.6700000166893005
ep6_l0_test_time 0.29288679599997636
Test Epoch6 layer1 Acc 0.695, AUC 0.8124271631240845, avg_entr 0.3136098086833954, f1 0.6949999928474426
ep6_l1_test_time 0.3631087449999768
Test Epoch6 layer2 Acc 0.6916, AUC 0.8224160075187683, avg_entr 0.301822304725647, f1 0.6916000247001648
ep6_l2_test_time 0.472503837000005
Test Epoch6 layer3 Acc 0.695, AUC 0.8269273638725281, avg_entr 0.31084153056144714, f1 0.6949999928474426
ep6_l3_test_time 0.6303188570000202
Test Epoch6 layer4 Acc 0.6646, AUC 0.8265420198440552, avg_entr 0.3048042356967926, f1 0.6646000146865845
ep6_l4_test_time 0.8197070559999986
gc 0
Train Epoch7 Acc 0.757625 (30305/40000), AUC 0.840146541595459
ep7_train_time 23.169168156000012
Test Epoch7 layer0 Acc 0.6928, AUC 0.7772750854492188, avg_entr 0.32693538069725037, f1 0.692799985408783
ep7_l0_test_time 0.2932953510000118
Test Epoch7 layer1 Acc 0.7304, AUC 0.8231894969940186, avg_entr 0.29665982723236084, f1 0.7304000854492188
ep7_l1_test_time 0.36261290699999904
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 7
Test Epoch7 layer2 Acc 0.7328, AUC 0.8339707851409912, avg_entr 0.28590816259384155, f1 0.7327999472618103
ep7_l2_test_time 0.47210299699997904
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 7
Test Epoch7 layer3 Acc 0.7334, AUC 0.8398881554603577, avg_entr 0.2949342429637909, f1 0.7333999872207642
ep7_l3_test_time 0.6242728280000165
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 7
Test Epoch7 layer4 Acc 0.7268, AUC 0.8404934406280518, avg_entr 0.307902455329895, f1 0.7268000245094299
ep7_l4_test_time 0.8182771330000094
gc 0
Train Epoch8 Acc 0.77625 (31050/40000), AUC 0.8578123450279236
ep8_train_time 23.161110587999985
Test Epoch8 layer0 Acc 0.708, AUC 0.7850396633148193, avg_entr 0.32998529076576233, f1 0.7080000638961792
ep8_l0_test_time 0.2926842279999846
Test Epoch8 layer1 Acc 0.7518, AUC 0.831876277923584, avg_entr 0.2819806635379791, f1 0.751800000667572
ep8_l1_test_time 0.3644168719999925
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 8
Test Epoch8 layer2 Acc 0.7596, AUC 0.8434255123138428, avg_entr 0.270704060792923, f1 0.7595999836921692
ep8_l2_test_time 0.48094167499999685
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 8
Test Epoch8 layer3 Acc 0.7626, AUC 0.8468018770217896, avg_entr 0.26446768641471863, f1 0.7626000046730042
ep8_l3_test_time 0.6235333999999852
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 8
Test Epoch8 layer4 Acc 0.7624, AUC 0.8475896120071411, avg_entr 0.2689962089061737, f1 0.7623999714851379
ep8_l4_test_time 0.8195174880000309
gc 0
Train Epoch9 Acc 0.79265 (31706/40000), AUC 0.8745326995849609
ep9_train_time 23.16319874000004
Test Epoch9 layer0 Acc 0.7074, AUC 0.7858818173408508, avg_entr 0.29453933238983154, f1 0.7074000239372253
ep9_l0_test_time 0.29370056499999464
Test Epoch9 layer1 Acc 0.7494, AUC 0.8330868482589722, avg_entr 0.2588839828968048, f1 0.7494000196456909
ep9_l1_test_time 0.36423001100001784
Test Epoch9 layer2 Acc 0.754, AUC 0.8463374376296997, avg_entr 0.24170969426631927, f1 0.7540000081062317
ep9_l2_test_time 0.4723620149999874
Test Epoch9 layer3 Acc 0.7578, AUC 0.8511314988136292, avg_entr 0.21086731553077698, f1 0.7577999830245972
ep9_l3_test_time 0.6340662110000039
Test Epoch9 layer4 Acc 0.7582, AUC 0.8521699905395508, avg_entr 0.1956450194120407, f1 0.7582000494003296
ep9_l4_test_time 0.8196358029999828
gc 0
Train Epoch10 Acc 0.8104 (32416/40000), AUC 0.8896853923797607
ep10_train_time 23.15673763700005
Test Epoch10 layer0 Acc 0.707, AUC 0.7890498638153076, avg_entr 0.31099462509155273, f1 0.7070000171661377
ep10_l0_test_time 0.2954298299999891
Test Epoch10 layer1 Acc 0.757, AUC 0.8370543122291565, avg_entr 0.2721804082393646, f1 0.7570000886917114
ep10_l1_test_time 0.364088584000001
Test Epoch10 layer2 Acc 0.7646, AUC 0.8493913412094116, avg_entr 0.2586582601070404, f1 0.7645999789237976
ep10_l2_test_time 0.47344452900000533
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 10
Test Epoch10 layer3 Acc 0.7662, AUC 0.8548258543014526, avg_entr 0.2116437703371048, f1 0.766200065612793
ep10_l3_test_time 0.6323864340000114
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 10
Test Epoch10 layer4 Acc 0.7672, AUC 0.8563146591186523, avg_entr 0.21039220690727234, f1 0.7671999931335449
ep10_l4_test_time 0.8190256120000186
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 10
gc 0
Train Epoch11 Acc 0.832475 (33299/40000), AUC 0.9099164009094238
ep11_train_time 23.16804413600005
Test Epoch11 layer0 Acc 0.7068, AUC 0.7828170657157898, avg_entr 0.2633936107158661, f1 0.7067999839782715
ep11_l0_test_time 0.294348029000048
Test Epoch11 layer1 Acc 0.7498, AUC 0.8314353227615356, avg_entr 0.20966686308383942, f1 0.7498000264167786
ep11_l1_test_time 0.3615053770000145
Test Epoch11 layer2 Acc 0.7604, AUC 0.8455745577812195, avg_entr 0.18368633091449738, f1 0.7603999972343445
ep11_l2_test_time 0.48169979600004353
Test Epoch11 layer3 Acc 0.764, AUC 0.8504074811935425, avg_entr 0.14258748292922974, f1 0.7639999985694885
ep11_l3_test_time 0.6216865530000177
Test Epoch11 layer4 Acc 0.7634, AUC 0.8519552946090698, avg_entr 0.137283593416214, f1 0.7634000182151794
ep11_l4_test_time 0.8162851109999565
gc 0
Train Epoch12 Acc 0.84415 (33766/40000), AUC 0.9189618825912476
ep12_train_time 23.185671436999996
Test Epoch12 layer0 Acc 0.701, AUC 0.7894075512886047, avg_entr 0.2374497354030609, f1 0.7009999752044678
ep12_l0_test_time 0.29115932399997746
Test Epoch12 layer1 Acc 0.7388, AUC 0.8377456665039062, avg_entr 0.21853996813297272, f1 0.7387999892234802
ep12_l1_test_time 0.36224372200001653
Test Epoch12 layer2 Acc 0.7466, AUC 0.851568877696991, avg_entr 0.17485027015209198, f1 0.7465999126434326
ep12_l2_test_time 0.4721135259999869
Test Epoch12 layer3 Acc 0.7472, AUC 0.8563041090965271, avg_entr 0.14577233791351318, f1 0.747200071811676
ep12_l3_test_time 0.6323397339999701
Test Epoch12 layer4 Acc 0.7418, AUC 0.8581313490867615, avg_entr 0.1421981006860733, f1 0.74180006980896
ep12_l4_test_time 0.8181114999999863
gc 0
Train Epoch13 Acc 0.861975 (34479/40000), AUC 0.9335403442382812
ep13_train_time 23.16940134600003
Test Epoch13 layer0 Acc 0.706, AUC 0.7872635126113892, avg_entr 0.24577714502811432, f1 0.7059999704360962
ep13_l0_test_time 0.2909529519999978
Test Epoch13 layer1 Acc 0.7458, AUC 0.8324706554412842, avg_entr 0.19934938848018646, f1 0.7458000183105469
ep13_l1_test_time 0.3612660230000415
Test Epoch13 layer2 Acc 0.7564, AUC 0.8449878692626953, avg_entr 0.13852111995220184, f1 0.7563999891281128
ep13_l2_test_time 0.470876713999985
Test Epoch13 layer3 Acc 0.7574, AUC 0.8512043952941895, avg_entr 0.11947868764400482, f1 0.7573999762535095
ep13_l3_test_time 0.6260077250000222
Test Epoch13 layer4 Acc 0.7588, AUC 0.8529343605041504, avg_entr 0.11844107508659363, f1 0.7588000297546387
ep13_l4_test_time 0.8229611209999916
gc 0
Train Epoch14 Acc 0.869225 (34769/40000), AUC 0.9388198852539062
ep14_train_time 23.17595301
Test Epoch14 layer0 Acc 0.6996, AUC 0.7855211496353149, avg_entr 0.2338341325521469, f1 0.6995999813079834
ep14_l0_test_time 0.2981942360000289
Test Epoch14 layer1 Acc 0.7562, AUC 0.8338176012039185, avg_entr 0.21278584003448486, f1 0.7561999559402466
ep14_l1_test_time 0.372296834999986
Test Epoch14 layer2 Acc 0.7678, AUC 0.8485265970230103, avg_entr 0.14832928776741028, f1 0.767799973487854
ep14_l2_test_time 0.4876684249999812
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 14
Test Epoch14 layer3 Acc 0.7702, AUC 0.854358971118927, avg_entr 0.1335543394088745, f1 0.7702000141143799
ep14_l3_test_time 0.621509973000002
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 14
Test Epoch14 layer4 Acc 0.774, AUC 0.8569232821464539, avg_entr 0.13657395541667938, f1 0.7739999890327454
ep14_l4_test_time 0.8183753309999702
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 14
gc 0
Train Epoch15 Acc 0.887475 (35499/40000), AUC 0.9508481025695801
ep15_train_time 23.136952069000017
Test Epoch15 layer0 Acc 0.7134, AUC 0.7854189872741699, avg_entr 0.218485027551651, f1 0.7134000062942505
ep15_l0_test_time 0.29605284800004483
Test Epoch15 layer1 Acc 0.752, AUC 0.8289990425109863, avg_entr 0.17517322301864624, f1 0.7519999742507935
ep15_l1_test_time 0.3629267000000027
Test Epoch15 layer2 Acc 0.757, AUC 0.8414020538330078, avg_entr 0.11188239604234695, f1 0.7570000886917114
ep15_l2_test_time 0.4736571500000082
Test Epoch15 layer3 Acc 0.7566, AUC 0.8496016263961792, avg_entr 0.09930749237537384, f1 0.756600022315979
ep15_l3_test_time 0.6235157369999911
Test Epoch15 layer4 Acc 0.7584, AUC 0.8524160385131836, avg_entr 0.09819082170724869, f1 0.758400022983551
ep15_l4_test_time 0.825712244999977
gc 0
Train Epoch16 Acc 0.898675 (35947/40000), AUC 0.9607843160629272
ep16_train_time 23.185824416000003
Test Epoch16 layer0 Acc 0.7086, AUC 0.7832933664321899, avg_entr 0.20818647742271423, f1 0.7085999846458435
ep16_l0_test_time 0.2911430959999848
Test Epoch16 layer1 Acc 0.748, AUC 0.8274063467979431, avg_entr 0.1629289984703064, f1 0.7480000257492065
ep16_l1_test_time 0.36126030299999456
Test Epoch16 layer2 Acc 0.759, AUC 0.8396656513214111, avg_entr 0.10136843472719193, f1 0.7589999437332153
ep16_l2_test_time 0.48706479600002694
Test Epoch16 layer3 Acc 0.7688, AUC 0.8477075099945068, avg_entr 0.09173771739006042, f1 0.7688000202178955
ep16_l3_test_time 0.6226890489999732
Test Epoch16 layer4 Acc 0.7694, AUC 0.8507949113845825, avg_entr 0.08899308741092682, f1 0.7694000005722046
ep16_l4_test_time 0.8186771210000074
gc 0
Train Epoch17 Acc 0.917 (36680/40000), AUC 0.971915066242218
ep17_train_time 23.187425978999954
Test Epoch17 layer0 Acc 0.7082, AUC 0.7810273170471191, avg_entr 0.2001848965883255, f1 0.7081999778747559
ep17_l0_test_time 0.29412148399995885
Test Epoch17 layer1 Acc 0.7412, AUC 0.8192155957221985, avg_entr 0.14196524024009705, f1 0.7411999702453613
ep17_l1_test_time 0.36231898900001624
Test Epoch17 layer2 Acc 0.7548, AUC 0.8316980600357056, avg_entr 0.08247656375169754, f1 0.754800021648407
ep17_l2_test_time 0.47382828399997834
Test Epoch17 layer3 Acc 0.7596, AUC 0.8400318622589111, avg_entr 0.07945143431425095, f1 0.7595999836921692
ep17_l3_test_time 0.6266794959999515
Test Epoch17 layer4 Acc 0.7602, AUC 0.842718243598938, avg_entr 0.07814203947782516, f1 0.7602000832557678
ep17_l4_test_time 0.818399071999977
gc 0
Train Epoch18 Acc 0.9245 (36980/40000), AUC 0.9756292104721069
ep18_train_time 23.15162756699999
Test Epoch18 layer0 Acc 0.7042, AUC 0.7791181802749634, avg_entr 0.19167719781398773, f1 0.704200029373169
ep18_l0_test_time 0.30988842900001146
Test Epoch18 layer1 Acc 0.7348, AUC 0.8176897764205933, avg_entr 0.11245131492614746, f1 0.7347999811172485
ep18_l1_test_time 0.3633460970000897
Test Epoch18 layer2 Acc 0.748, AUC 0.8318018317222595, avg_entr 0.07252980768680573, f1 0.7480000257492065
ep18_l2_test_time 0.4732833360000086
Test Epoch18 layer3 Acc 0.7546, AUC 0.8384174108505249, avg_entr 0.06750573962926865, f1 0.7546000480651855
ep18_l3_test_time 0.6253740319999679
Test Epoch18 layer4 Acc 0.7554, AUC 0.840750515460968, avg_entr 0.06525390595197678, f1 0.7554000020027161
ep18_l4_test_time 0.8191620979999925
gc 0
Train Epoch19 Acc 0.931225 (37249/40000), AUC 0.9788433313369751
ep19_train_time 23.175095768999995
Test Epoch19 layer0 Acc 0.703, AUC 0.7784325480461121, avg_entr 0.19320057332515717, f1 0.703000009059906
ep19_l0_test_time 0.28828537099991536
Test Epoch19 layer1 Acc 0.7366, AUC 0.8151402473449707, avg_entr 0.10743208229541779, f1 0.7365999817848206
ep19_l1_test_time 0.35843720299999404
Test Epoch19 layer2 Acc 0.7474, AUC 0.8305870294570923, avg_entr 0.07496961951255798, f1 0.7473999857902527
ep19_l2_test_time 0.46832908099997894
Test Epoch19 layer3 Acc 0.7552, AUC 0.8379083871841431, avg_entr 0.07291677594184875, f1 0.7552000284194946
ep19_l3_test_time 0.62336042000004
Test Epoch19 layer4 Acc 0.7574, AUC 0.8403134346008301, avg_entr 0.06918767839670181, f1 0.7573999762535095
ep19_l4_test_time 0.8235206749999406
gc 0
Train Epoch20 Acc 0.933875 (37355/40000), AUC 0.9803754687309265
ep20_train_time 23.07801781899991
Test Epoch20 layer0 Acc 0.6956, AUC 0.7756235599517822, avg_entr 0.18758215010166168, f1 0.6955999732017517
ep20_l0_test_time 0.2876645579999604
Test Epoch20 layer1 Acc 0.7044, AUC 0.8076597452163696, avg_entr 0.08919209241867065, f1 0.7044000029563904
ep20_l1_test_time 0.35779775299999983
Test Epoch20 layer2 Acc 0.7176, AUC 0.8233044147491455, avg_entr 0.06661155074834824, f1 0.7175999879837036
ep20_l2_test_time 0.46711463600001935
Test Epoch20 layer3 Acc 0.7232, AUC 0.8323152661323547, avg_entr 0.0641188696026802, f1 0.7232000827789307
ep20_l3_test_time 0.6180027799999834
Test Epoch20 layer4 Acc 0.726, AUC 0.8327374458312988, avg_entr 0.060754649341106415, f1 0.7260000109672546
ep20_l4_test_time 0.8137969599999906
gc 0
Train Epoch21 Acc 0.945475 (37819/40000), AUC 0.985611081123352
ep21_train_time 23.142592906000004
Test Epoch21 layer0 Acc 0.7054, AUC 0.7750784158706665, avg_entr 0.18361259996891022, f1 0.7053999900817871
ep21_l0_test_time 0.2937150389999488
Test Epoch21 layer1 Acc 0.7276, AUC 0.8064786791801453, avg_entr 0.08463187515735626, f1 0.7275999784469604
ep21_l1_test_time 0.36341475900007936
Test Epoch21 layer2 Acc 0.7446, AUC 0.8228939771652222, avg_entr 0.06306394934654236, f1 0.7445999979972839
ep21_l2_test_time 0.47282556599998316
Test Epoch21 layer3 Acc 0.7516, AUC 0.8311271667480469, avg_entr 0.060024816542863846, f1 0.7516000270843506
ep21_l3_test_time 0.6238102030000618
Test Epoch21 layer4 Acc 0.7508, AUC 0.83453369140625, avg_entr 0.05693845823407173, f1 0.7508000135421753
ep21_l4_test_time 0.819345017000046
gc 0
Train Epoch22 Acc 0.94985 (37994/40000), AUC 0.9880784749984741
ep22_train_time 23.137113928999952
Test Epoch22 layer0 Acc 0.7056, AUC 0.7725117206573486, avg_entr 0.1856166571378708, f1 0.7056000232696533
ep22_l0_test_time 0.28984697900000356
Test Epoch22 layer1 Acc 0.728, AUC 0.804145336151123, avg_entr 0.08136192709207535, f1 0.7279999852180481
ep22_l1_test_time 0.36280447799993
Test Epoch22 layer2 Acc 0.7444, AUC 0.81876540184021, avg_entr 0.061209019273519516, f1 0.7444000244140625
ep22_l2_test_time 0.4706485529999327
Test Epoch22 layer3 Acc 0.752, AUC 0.8289100527763367, avg_entr 0.058417510241270065, f1 0.7519999742507935
ep22_l3_test_time 0.6247039879999647
Test Epoch22 layer4 Acc 0.7518, AUC 0.8329910039901733, avg_entr 0.05655892938375473, f1 0.751800000667572
ep22_l4_test_time 0.817847817000029
gc 0
Train Epoch23 Acc 0.95225 (38090/40000), AUC 0.9885175228118896
ep23_train_time 23.161554248000016
Test Epoch23 layer0 Acc 0.7052, AUC 0.7705466151237488, avg_entr 0.18341290950775146, f1 0.7052000164985657
ep23_l0_test_time 0.292162714999904
Test Epoch23 layer1 Acc 0.7248, AUC 0.8008462190628052, avg_entr 0.08023262023925781, f1 0.7247999906539917
ep23_l1_test_time 0.36216208799999094
Test Epoch23 layer2 Acc 0.7422, AUC 0.8188153505325317, avg_entr 0.06210608407855034, f1 0.7422000169754028
ep23_l2_test_time 0.47368297499997425
Test Epoch23 layer3 Acc 0.7512, AUC 0.8261836171150208, avg_entr 0.05859843268990517, f1 0.7512000203132629
ep23_l3_test_time 0.6223542110000153
Test Epoch23 layer4 Acc 0.7514, AUC 0.8298449516296387, avg_entr 0.05657655745744705, f1 0.7513999938964844
ep23_l4_test_time 0.8180061209999394
gc 0
Train Epoch24 Acc 0.952725 (38109/40000), AUC 0.9888691902160645
ep24_train_time 23.165526159000024
Test Epoch24 layer0 Acc 0.7018, AUC 0.7704060077667236, avg_entr 0.1781112402677536, f1 0.7017999887466431
ep24_l0_test_time 0.2915003740000657
Test Epoch24 layer1 Acc 0.7242, AUC 0.8006227016448975, avg_entr 0.0778442844748497, f1 0.7242000699043274
ep24_l1_test_time 0.36358111200001986
Test Epoch24 layer2 Acc 0.7454, AUC 0.8184821605682373, avg_entr 0.061602476984262466, f1 0.745400071144104
ep24_l2_test_time 0.4727289040000642
Test Epoch24 layer3 Acc 0.7514, AUC 0.8272135257720947, avg_entr 0.05712023749947548, f1 0.7513999938964844
ep24_l3_test_time 0.6241786069999762
Test Epoch24 layer4 Acc 0.7534, AUC 0.8309328556060791, avg_entr 0.0540122427046299, f1 0.7533999681472778
ep24_l4_test_time 0.8167862819999527
gc 0
Train Epoch25 Acc 0.959825 (38393/40000), AUC 0.9915133714675903
ep25_train_time 23.133151672000054
Test Epoch25 layer0 Acc 0.7014, AUC 0.7688866853713989, avg_entr 0.1774894893169403, f1 0.7013999819755554
ep25_l0_test_time 0.29617031099996893
Test Epoch25 layer1 Acc 0.7214, AUC 0.7969052195549011, avg_entr 0.07651545852422714, f1 0.7214000225067139
ep25_l1_test_time 0.36352789600005053
Test Epoch25 layer2 Acc 0.7406, AUC 0.8123241662979126, avg_entr 0.05685333162546158, f1 0.7405999302864075
ep25_l2_test_time 0.47182170500002485
Test Epoch25 layer3 Acc 0.7436, AUC 0.8223587870597839, avg_entr 0.052605390548706055, f1 0.7436000108718872
ep25_l3_test_time 0.6230005440000923
Test Epoch25 layer4 Acc 0.747, AUC 0.8268545866012573, avg_entr 0.050580285489559174, f1 0.746999979019165
ep25_l4_test_time 0.8168166670000119
gc 0
Train Epoch26 Acc 0.959625 (38385/40000), AUC 0.991348385810852
ep26_train_time 23.141727741000068
Test Epoch26 layer0 Acc 0.7004, AUC 0.7686786651611328, avg_entr 0.17742690443992615, f1 0.7003999948501587
ep26_l0_test_time 0.290841687000011
Test Epoch26 layer1 Acc 0.7166, AUC 0.7958712577819824, avg_entr 0.06782112270593643, f1 0.7165999412536621
ep26_l1_test_time 0.36697220799999286
Test Epoch26 layer2 Acc 0.7356, AUC 0.809200644493103, avg_entr 0.052565399557352066, f1 0.7355999946594238
ep26_l2_test_time 0.4719726340000534
Test Epoch26 layer3 Acc 0.7408, AUC 0.8197542428970337, avg_entr 0.04865285009145737, f1 0.7408000230789185
ep26_l3_test_time 0.6231850210000403
Test Epoch26 layer4 Acc 0.7442, AUC 0.824843168258667, avg_entr 0.04600759595632553, f1 0.7441999316215515
ep26_l4_test_time 0.8198617220000415
gc 0
Train Epoch27 Acc 0.960875 (38435/40000), AUC 0.9916179180145264
ep27_train_time 23.2334923410001
Test Epoch27 layer0 Acc 0.6984, AUC 0.7675461173057556, avg_entr 0.17572011053562164, f1 0.6984000205993652
ep27_l0_test_time 0.29583090200003426
Test Epoch27 layer1 Acc 0.7176, AUC 0.793226420879364, avg_entr 0.0687941461801529, f1 0.7175999879837036
ep27_l1_test_time 0.3663687260000188
Test Epoch27 layer2 Acc 0.739, AUC 0.8071330785751343, avg_entr 0.05240466445684433, f1 0.7390000820159912
ep27_l2_test_time 0.4710721219998959
Test Epoch27 layer3 Acc 0.7424, AUC 0.8171703815460205, avg_entr 0.04898875206708908, f1 0.742400050163269
ep27_l3_test_time 0.6277832619999799
Test Epoch27 layer4 Acc 0.7444, AUC 0.8220968246459961, avg_entr 0.04629693180322647, f1 0.7444000244140625
ep27_l4_test_time 0.8170024590000367
gc 0
Train Epoch28 Acc 0.963125 (38525/40000), AUC 0.9925161600112915
ep28_train_time 23.150067326
Test Epoch28 layer0 Acc 0.7024, AUC 0.7674456834793091, avg_entr 0.1724550724029541, f1 0.7024000287055969
ep28_l0_test_time 0.2977849229999947
Test Epoch28 layer1 Acc 0.7224, AUC 0.7928357124328613, avg_entr 0.07059308141469955, f1 0.7224000096321106
ep28_l1_test_time 0.36129642599996714
Test Epoch28 layer2 Acc 0.7446, AUC 0.8103960752487183, avg_entr 0.05748393386602402, f1 0.7445999979972839
ep28_l2_test_time 0.4705767549999109
Test Epoch28 layer3 Acc 0.7472, AUC 0.8201218247413635, avg_entr 0.05142061784863472, f1 0.747200071811676
ep28_l3_test_time 0.62591326200004
Test Epoch28 layer4 Acc 0.7494, AUC 0.824360728263855, avg_entr 0.04776140674948692, f1 0.7494000196456909
ep28_l4_test_time 0.8177826149999419
gc 0
Train Epoch29 Acc 0.96455 (38582/40000), AUC 0.9933362603187561
ep29_train_time 23.131203037999967
Test Epoch29 layer0 Acc 0.701, AUC 0.7666780948638916, avg_entr 0.17282554507255554, f1 0.7009999752044678
ep29_l0_test_time 0.2917569009999852
Test Epoch29 layer1 Acc 0.7196, AUC 0.7932060360908508, avg_entr 0.06721114367246628, f1 0.7196000218391418
ep29_l1_test_time 0.3620818260000078
Test Epoch29 layer2 Acc 0.7352, AUC 0.8041471838951111, avg_entr 0.04654117301106453, f1 0.7351999282836914
ep29_l2_test_time 0.4757312520000596
Test Epoch29 layer3 Acc 0.7404, AUC 0.8163570761680603, avg_entr 0.043774329125881195, f1 0.7404000163078308
ep29_l3_test_time 0.6223005030000195
Test Epoch29 layer4 Acc 0.7418, AUC 0.8217844367027283, avg_entr 0.04067810997366905, f1 0.74180006980896
ep29_l4_test_time 0.8197155270000849
gc 0
Train Epoch30 Acc 0.96565 (38626/40000), AUC 0.9934035539627075
ep30_train_time 23.14506940700005
Test Epoch30 layer0 Acc 0.6994, AUC 0.7660552263259888, avg_entr 0.17149153351783752, f1 0.699400007724762
ep30_l0_test_time 0.29242626500001734
Test Epoch30 layer1 Acc 0.7192, AUC 0.792091965675354, avg_entr 0.06711380183696747, f1 0.719200074672699
ep30_l1_test_time 0.36195850299998256
Test Epoch30 layer2 Acc 0.7376, AUC 0.8071417212486267, avg_entr 0.052190881222486496, f1 0.7376000285148621
ep30_l2_test_time 0.4720738579999306
Test Epoch30 layer3 Acc 0.7438, AUC 0.8168262839317322, avg_entr 0.04856341332197189, f1 0.7437999248504639
ep30_l3_test_time 0.6296025120000195
Test Epoch30 layer4 Acc 0.744, AUC 0.8225760459899902, avg_entr 0.04610995203256607, f1 0.7439999580383301
ep30_l4_test_time 0.8179772090001052
gc 0
Train Epoch31 Acc 0.96675 (38670/40000), AUC 0.9937043190002441
ep31_train_time 23.185993431000043
Test Epoch31 layer0 Acc 0.6988, AUC 0.7659503817558289, avg_entr 0.17047284543514252, f1 0.6988000273704529
ep31_l0_test_time 0.292603098000086
Test Epoch31 layer1 Acc 0.7174, AUC 0.7900627851486206, avg_entr 0.06374825537204742, f1 0.717400074005127
ep31_l1_test_time 0.3618301620000466
Test Epoch31 layer2 Acc 0.7324, AUC 0.8014139533042908, avg_entr 0.044605329632759094, f1 0.7323999404907227
ep31_l2_test_time 0.4772062409999762
Test Epoch31 layer3 Acc 0.7392, AUC 0.8133057355880737, avg_entr 0.04319910332560539, f1 0.7391999959945679
ep31_l3_test_time 0.62190680599997
Test Epoch31 layer4 Acc 0.7402, AUC 0.8185513019561768, avg_entr 0.040115032345056534, f1 0.7401999831199646
ep31_l4_test_time 0.8166598110000223
gc 0
Train Epoch32 Acc 0.9666 (38664/40000), AUC 0.9936095476150513
ep32_train_time 23.171528001999945
Test Epoch32 layer0 Acc 0.7016, AUC 0.7659926414489746, avg_entr 0.16902516782283783, f1 0.7016000151634216
ep32_l0_test_time 0.2915103220000219
Test Epoch32 layer1 Acc 0.72, AUC 0.7902299165725708, avg_entr 0.06707929819822311, f1 0.7199999690055847
ep32_l1_test_time 0.3618870269999661
Test Epoch32 layer2 Acc 0.7386, AUC 0.8071517944335938, avg_entr 0.0502794049680233, f1 0.7386000156402588
ep32_l2_test_time 0.4727442890000475
Test Epoch32 layer3 Acc 0.7424, AUC 0.8155183792114258, avg_entr 0.045630019158124924, f1 0.742400050163269
ep32_l3_test_time 0.622214893999967
Test Epoch32 layer4 Acc 0.7452, AUC 0.8207861185073853, avg_entr 0.04241705313324928, f1 0.745199978351593
ep32_l4_test_time 0.8217301449999468
gc 0
Train Epoch33 Acc 0.969425 (38777/40000), AUC 0.9942467212677002
ep33_train_time 23.110810678000007
Test Epoch33 layer0 Acc 0.6994, AUC 0.7654199600219727, avg_entr 0.1699656844139099, f1 0.699400007724762
ep33_l0_test_time 0.30003154400003496
Test Epoch33 layer1 Acc 0.7194, AUC 0.7889728546142578, avg_entr 0.06544681638479233, f1 0.7193999886512756
ep33_l1_test_time 0.360499797999978
Test Epoch33 layer2 Acc 0.735, AUC 0.8049958944320679, avg_entr 0.048288099467754364, f1 0.7350000143051147
ep33_l2_test_time 0.48389903999998296
Test Epoch33 layer3 Acc 0.743, AUC 0.813530683517456, avg_entr 0.045352209359407425, f1 0.7430000305175781
ep33_l3_test_time 0.6239949089999755
Test Epoch33 layer4 Acc 0.7416, AUC 0.8193334937095642, avg_entr 0.042732518166303635, f1 0.741599977016449
ep33_l4_test_time 0.8204006529999788
gc 0
Train Epoch34 Acc 0.96895 (38758/40000), AUC 0.9942837953567505
ep34_train_time 23.157086480999965
Test Epoch34 layer0 Acc 0.7008, AUC 0.7656472325325012, avg_entr 0.17063505947589874, f1 0.7008000016212463
ep34_l0_test_time 0.2922644580000906
Test Epoch34 layer1 Acc 0.719, AUC 0.790338397026062, avg_entr 0.06476093828678131, f1 0.718999981880188
ep34_l1_test_time 0.3614902809999876
Test Epoch34 layer2 Acc 0.7346, AUC 0.8055758476257324, avg_entr 0.048700373619794846, f1 0.7345999479293823
ep34_l2_test_time 0.4707727559999739
Test Epoch34 layer3 Acc 0.7404, AUC 0.814044177532196, avg_entr 0.04519902169704437, f1 0.7404000163078308
ep34_l3_test_time 0.6224324949999982
Test Epoch34 layer4 Acc 0.7418, AUC 0.820289671421051, avg_entr 0.04270254448056221, f1 0.74180006980896
ep34_l4_test_time 0.820378081000058
gc 0
Train Epoch35 Acc 0.9683 (38732/40000), AUC 0.9944361448287964
ep35_train_time 23.12162923400001
Test Epoch35 layer0 Acc 0.7, AUC 0.7658267021179199, avg_entr 0.16778454184532166, f1 0.699999988079071
ep35_l0_test_time 0.29145899499997086
Test Epoch35 layer1 Acc 0.7198, AUC 0.7894349098205566, avg_entr 0.06524243950843811, f1 0.7197999358177185
ep35_l1_test_time 0.3614655659999926
Test Epoch35 layer2 Acc 0.7372, AUC 0.8061051368713379, avg_entr 0.04868919774889946, f1 0.7372000217437744
ep35_l2_test_time 0.473860932999969
Test Epoch35 layer3 Acc 0.7422, AUC 0.8135104179382324, avg_entr 0.04400690644979477, f1 0.7422000169754028
ep35_l3_test_time 0.6248936670000376
Test Epoch35 layer4 Acc 0.7436, AUC 0.8194372653961182, avg_entr 0.04055248573422432, f1 0.7436000108718872
ep35_l4_test_time 0.8172744239999474
gc 0
Train Epoch36 Acc 0.96855 (38742/40000), AUC 0.994164228439331
ep36_train_time 23.180532808999942
Test Epoch36 layer0 Acc 0.7004, AUC 0.7653136253356934, avg_entr 0.1678028106689453, f1 0.7003999948501587
ep36_l0_test_time 0.2900679610000907
Test Epoch36 layer1 Acc 0.7184, AUC 0.7887188196182251, avg_entr 0.06486023962497711, f1 0.7184000015258789
ep36_l1_test_time 0.3609348330001012
Test Epoch36 layer2 Acc 0.7354, AUC 0.8062113523483276, avg_entr 0.04813830554485321, f1 0.7354000210762024
ep36_l2_test_time 0.4714592770000081
Test Epoch36 layer3 Acc 0.7398, AUC 0.8124535083770752, avg_entr 0.0430615097284317, f1 0.7398000359535217
ep36_l3_test_time 0.62835367699995
Test Epoch36 layer4 Acc 0.7414, AUC 0.8185524344444275, avg_entr 0.039216600358486176, f1 0.7414000034332275
ep36_l4_test_time 0.8188161850000597
gc 0
Train Epoch37 Acc 0.969475 (38779/40000), AUC 0.9945793151855469
ep37_train_time 23.155592138000088
Test Epoch37 layer0 Acc 0.7016, AUC 0.7652640342712402, avg_entr 0.16763927042484283, f1 0.7016000151634216
ep37_l0_test_time 0.29243736700004774
Test Epoch37 layer1 Acc 0.7194, AUC 0.7885524034500122, avg_entr 0.06432931870222092, f1 0.7193999886512756
ep37_l1_test_time 0.3643827800000281
Test Epoch37 layer2 Acc 0.7338, AUC 0.8037463426589966, avg_entr 0.047907937318086624, f1 0.7338000535964966
ep37_l2_test_time 0.4785354630000711
Test Epoch37 layer3 Acc 0.74, AUC 0.8126482367515564, avg_entr 0.044125549495220184, f1 0.7400000095367432
ep37_l3_test_time 0.6253696039999568
Test Epoch37 layer4 Acc 0.7424, AUC 0.818849503993988, avg_entr 0.04155128449201584, f1 0.742400050163269
ep37_l4_test_time 0.8191432500000246
gc 0
Train Epoch38 Acc 0.970075 (38803/40000), AUC 0.9946002960205078
ep38_train_time 23.139657033999924
Test Epoch38 layer0 Acc 0.701, AUC 0.7650183439254761, avg_entr 0.16754958033561707, f1 0.7009999752044678
ep38_l0_test_time 0.2966382929998872
Test Epoch38 layer1 Acc 0.7206, AUC 0.7886101603507996, avg_entr 0.06398842483758926, f1 0.7206000685691833
ep38_l1_test_time 0.36326127699999233
Test Epoch38 layer2 Acc 0.7336, AUC 0.8032310009002686, avg_entr 0.04748706519603729, f1 0.7335999608039856
ep38_l2_test_time 0.4731951889998527
Test Epoch38 layer3 Acc 0.7402, AUC 0.811891496181488, avg_entr 0.04335601627826691, f1 0.7401999831199646
ep38_l3_test_time 0.6233570370000052
Test Epoch38 layer4 Acc 0.74, AUC 0.8178294897079468, avg_entr 0.040685780346393585, f1 0.7400000095367432
ep38_l4_test_time 0.816914228999849
gc 0
Train Epoch39 Acc 0.96965 (38786/40000), AUC 0.9946911334991455
ep39_train_time 23.149936775000015
Test Epoch39 layer0 Acc 0.7016, AUC 0.7650991678237915, avg_entr 0.16725364327430725, f1 0.7016000151634216
ep39_l0_test_time 0.29926733700017394
Test Epoch39 layer1 Acc 0.7184, AUC 0.788386344909668, avg_entr 0.06278169900178909, f1 0.7184000015258789
ep39_l1_test_time 0.3691017500000271
Test Epoch39 layer2 Acc 0.7342, AUC 0.8020697236061096, avg_entr 0.046434663236141205, f1 0.7342000007629395
ep39_l2_test_time 0.47109611999985646
Test Epoch39 layer3 Acc 0.7388, AUC 0.8124438524246216, avg_entr 0.0432160384953022, f1 0.7387999892234802
ep39_l3_test_time 0.6224401599999965
Test Epoch39 layer4 Acc 0.7404, AUC 0.8179654479026794, avg_entr 0.04018162935972214, f1 0.7404000163078308
ep39_l4_test_time 0.8174885289997746
gc 0
Train Epoch40 Acc 0.96915 (38766/40000), AUC 0.9946713447570801
ep40_train_time 23.15635744999986
Test Epoch40 layer0 Acc 0.7, AUC 0.765105128288269, avg_entr 0.16752445697784424, f1 0.699999988079071
ep40_l0_test_time 0.2910450510000828
Test Epoch40 layer1 Acc 0.7184, AUC 0.788762629032135, avg_entr 0.06298169493675232, f1 0.7184000015258789
ep40_l1_test_time 0.3627702539999973
Test Epoch40 layer2 Acc 0.7348, AUC 0.8031817674636841, avg_entr 0.04719533026218414, f1 0.7347999811172485
ep40_l2_test_time 0.4733446499999445
Test Epoch40 layer3 Acc 0.74, AUC 0.8124039173126221, avg_entr 0.04378432780504227, f1 0.7400000095367432
ep40_l3_test_time 0.6220544660000087
Test Epoch40 layer4 Acc 0.7398, AUC 0.818455696105957, avg_entr 0.040869422256946564, f1 0.7398000359535217
ep40_l4_test_time 0.8225101090001772
gc 0
Train Epoch41 Acc 0.969825 (38793/40000), AUC 0.9947319030761719
ep41_train_time 23.171699283999942
Test Epoch41 layer0 Acc 0.7002, AUC 0.7651763558387756, avg_entr 0.16697131097316742, f1 0.7002000212669373
ep41_l0_test_time 0.2997125760000472
Test Epoch41 layer1 Acc 0.7196, AUC 0.7883689403533936, avg_entr 0.06338758021593094, f1 0.7196000218391418
ep41_l1_test_time 0.36198145900016243
Test Epoch41 layer2 Acc 0.7338, AUC 0.8033583760261536, avg_entr 0.04739779978990555, f1 0.7338000535964966
ep41_l2_test_time 0.47079316000008475
Test Epoch41 layer3 Acc 0.7398, AUC 0.8117848634719849, avg_entr 0.04320278763771057, f1 0.7398000359535217
ep41_l3_test_time 0.621188175000043
Test Epoch41 layer4 Acc 0.7414, AUC 0.818068265914917, avg_entr 0.04031042382121086, f1 0.7414000034332275
ep41_l4_test_time 0.815934716999891
gc 0
Train Epoch42 Acc 0.97 (38800/40000), AUC 0.9948173761367798
ep42_train_time 23.126761650999924
Test Epoch42 layer0 Acc 0.7006, AUC 0.765151858329773, avg_entr 0.16690415143966675, f1 0.7006000280380249
ep42_l0_test_time 0.29263909199994487
Test Epoch42 layer1 Acc 0.7204, AUC 0.7886165380477905, avg_entr 0.06386955082416534, f1 0.7204000353813171
ep42_l1_test_time 0.3670217579999644
Test Epoch42 layer2 Acc 0.7336, AUC 0.8041025400161743, avg_entr 0.04764082282781601, f1 0.7335999608039856
ep42_l2_test_time 0.4813695650000227
Test Epoch42 layer3 Acc 0.7392, AUC 0.812156081199646, avg_entr 0.04308275878429413, f1 0.7391999959945679
ep42_l3_test_time 0.623102986999811
Test Epoch42 layer4 Acc 0.741, AUC 0.818610429763794, avg_entr 0.04048535227775574, f1 0.7409999370574951
ep42_l4_test_time 0.8181873130001804
gc 0
Train Epoch43 Acc 0.97095 (38838/40000), AUC 0.9945840835571289
ep43_train_time 23.13721086800001
Test Epoch43 layer0 Acc 0.6996, AUC 0.7651689052581787, avg_entr 0.16722321510314941, f1 0.6995999813079834
ep43_l0_test_time 0.2922402780000084
Test Epoch43 layer1 Acc 0.717, AUC 0.7883434295654297, avg_entr 0.06265892833471298, f1 0.7169999480247498
ep43_l1_test_time 0.3619237880000128
Test Epoch43 layer2 Acc 0.7344, AUC 0.8018413782119751, avg_entr 0.04671137407422066, f1 0.7343999147415161
ep43_l2_test_time 0.4712646030000087
Test Epoch43 layer3 Acc 0.7398, AUC 0.8116054534912109, avg_entr 0.043022509664297104, f1 0.7398000359535217
ep43_l3_test_time 0.6221872730000086
Test Epoch43 layer4 Acc 0.741, AUC 0.8178970217704773, avg_entr 0.040271397680044174, f1 0.7409999370574951
ep43_l4_test_time 0.8228601389998857
gc 0
Train Epoch44 Acc 0.969375 (38775/40000), AUC 0.9945063591003418
ep44_train_time 23.132317614000158
Test Epoch44 layer0 Acc 0.7002, AUC 0.7650727033615112, avg_entr 0.16670756042003632, f1 0.7002000212669373
ep44_l0_test_time 0.292616776000159
Test Epoch44 layer1 Acc 0.7196, AUC 0.7885124087333679, avg_entr 0.06342341750860214, f1 0.7196000218391418
ep44_l1_test_time 0.36322681399997236
Test Epoch44 layer2 Acc 0.732, AUC 0.8033286929130554, avg_entr 0.04732612520456314, f1 0.7319999933242798
ep44_l2_test_time 0.472452801999907
Test Epoch44 layer3 Acc 0.7396, AUC 0.8117316961288452, avg_entr 0.04274962097406387, f1 0.7396000027656555
ep44_l3_test_time 0.6216085440000825
Test Epoch44 layer4 Acc 0.7408, AUC 0.8182215690612793, avg_entr 0.039979852735996246, f1 0.7408000230789185
ep44_l4_test_time 0.8166724469999735
gc 0
Train Epoch45 Acc 0.9704 (38816/40000), AUC 0.9946696758270264
ep45_train_time 23.12751893399991
Test Epoch45 layer0 Acc 0.7, AUC 0.7650250792503357, avg_entr 0.16670972108840942, f1 0.699999988079071
ep45_l0_test_time 0.2926358810000238
Test Epoch45 layer1 Acc 0.7184, AUC 0.7885563969612122, avg_entr 0.06273717433214188, f1 0.7184000015258789
ep45_l1_test_time 0.3630424250000033
Test Epoch45 layer2 Acc 0.7328, AUC 0.8019134998321533, avg_entr 0.04647529125213623, f1 0.7327999472618103
ep45_l2_test_time 0.4719032159998733
Test Epoch45 layer3 Acc 0.7396, AUC 0.8117315769195557, avg_entr 0.04290660470724106, f1 0.7396000027656555
ep45_l3_test_time 0.6262122969999382
Test Epoch45 layer4 Acc 0.7406, AUC 0.8179923295974731, avg_entr 0.039918918162584305, f1 0.7405999302864075
ep45_l4_test_time 0.8230734809999376
gc 0
Train Epoch46 Acc 0.970025 (38801/40000), AUC 0.9947816133499146
ep46_train_time 23.157068398000092
Test Epoch46 layer0 Acc 0.7, AUC 0.764965295791626, avg_entr 0.16663801670074463, f1 0.699999988079071
ep46_l0_test_time 0.2899547739998525
Test Epoch46 layer1 Acc 0.7196, AUC 0.7884482741355896, avg_entr 0.06332631409168243, f1 0.7196000218391418
ep46_l1_test_time 0.36203253100006805
Test Epoch46 layer2 Acc 0.7338, AUC 0.8026331663131714, avg_entr 0.04674859344959259, f1 0.7338000535964966
ep46_l2_test_time 0.4728236509999988
Test Epoch46 layer3 Acc 0.7396, AUC 0.8119548559188843, avg_entr 0.042988914996385574, f1 0.7396000027656555
ep46_l3_test_time 0.6320165700001326
Test Epoch46 layer4 Acc 0.7404, AUC 0.8181723952293396, avg_entr 0.04001693055033684, f1 0.7404000163078308
ep46_l4_test_time 0.8180752749999556
gc 0
Train Epoch47 Acc 0.97065 (38826/40000), AUC 0.9945513606071472
ep47_train_time 23.096481895999887
Test Epoch47 layer0 Acc 0.7002, AUC 0.7650018930435181, avg_entr 0.16626261174678802, f1 0.7002000212669373
ep47_l0_test_time 0.28824332199997116
Test Epoch47 layer1 Acc 0.7202, AUC 0.7883162498474121, avg_entr 0.0633852407336235, f1 0.7202000021934509
ep47_l1_test_time 0.363523134000161
Test Epoch47 layer2 Acc 0.7328, AUC 0.8031282424926758, avg_entr 0.04694666340947151, f1 0.7327999472618103
ep47_l2_test_time 0.4705822379999063
Test Epoch47 layer3 Acc 0.7394, AUC 0.8115249872207642, avg_entr 0.042569614946842194, f1 0.7394000291824341
ep47_l3_test_time 0.6277272539998648
Test Epoch47 layer4 Acc 0.7414, AUC 0.817986011505127, avg_entr 0.03965669125318527, f1 0.7414000034332275
ep47_l4_test_time 0.8148431990000518
gc 0
Train Epoch48 Acc 0.9709 (38836/40000), AUC 0.9949976205825806
ep48_train_time 23.56285760300011
Test Epoch48 layer0 Acc 0.6998, AUC 0.7649588584899902, avg_entr 0.1662851870059967, f1 0.6998000144958496
ep48_l0_test_time 0.28617405499994675
Test Epoch48 layer1 Acc 0.7192, AUC 0.7882909178733826, avg_entr 0.06330127269029617, f1 0.719200074672699
ep48_l1_test_time 0.3555692119998639
Test Epoch48 layer2 Acc 0.7342, AUC 0.802536129951477, avg_entr 0.04638702794909477, f1 0.7342000007629395
ep48_l2_test_time 0.4658045870000933
Test Epoch48 layer3 Acc 0.7394, AUC 0.8111792802810669, avg_entr 0.042163509875535965, f1 0.7394000291824341
ep48_l3_test_time 0.6138966120001896
Test Epoch48 layer4 Acc 0.741, AUC 0.817768394947052, avg_entr 0.03924769163131714, f1 0.7409999370574951
ep48_l4_test_time 0.8083008809999228
gc 0
Train Epoch49 Acc 0.970275 (38811/40000), AUC 0.9951573014259338
ep49_train_time 23.007519652999918
Test Epoch49 layer0 Acc 0.7004, AUC 0.7649968266487122, avg_entr 0.1663515269756317, f1 0.7003999948501587
ep49_l0_test_time 0.285875156999964
Test Epoch49 layer1 Acc 0.7202, AUC 0.7884597182273865, avg_entr 0.06335087865591049, f1 0.7202000021934509
ep49_l1_test_time 0.35798835099990356
Test Epoch49 layer2 Acc 0.7344, AUC 0.8023660182952881, avg_entr 0.04625088348984718, f1 0.7343999147415161
ep49_l2_test_time 0.46829675999993015
Test Epoch49 layer3 Acc 0.7396, AUC 0.8114181756973267, avg_entr 0.04216069355607033, f1 0.7396000027656555
ep49_l3_test_time 0.615438180999945
Test Epoch49 layer4 Acc 0.7392, AUC 0.81800776720047, avg_entr 0.039193328469991684, f1 0.7391999959945679
ep49_l4_test_time 0.8093779939999877
Best AUC tensor(0.7740) 14 4
train_as_loss [[8.73549497e+01 5.90448749e+01 5.19915595e+01 5.04030024e+01
  4.98522836e+01 4.96018459e+01 4.94677638e+01 4.93878723e+01
  4.93365395e+01 4.93016596e+01 4.92769145e+01 4.92587552e+01
  4.92450550e+01 4.92344797e+01 4.92261621e+01 4.92195096e+01
  4.92141164e+01 4.92106768e+01 4.92085996e+01 4.92066391e+01
  4.92047978e+01 4.92034804e+01 4.92026149e+01 4.92017468e+01
  4.92008807e+01 4.92002289e+01 4.91997848e+01 4.91993245e+01
  4.91988514e+01 4.91984877e+01 4.91982324e+01 4.91979643e+01
  4.91976851e+01 4.91974646e+01 4.91973103e+01 4.91971443e+01
  4.91969705e+01 4.91968308e+01 4.91967348e+01 4.91966299e+01
  4.91965149e+01 4.91964290e+01 4.91963643e+01 4.91962973e+01
  4.91962253e+01 4.91961674e+01 4.91961210e+01 4.91960784e+01
  4.91960372e+01 4.91959965e+01]
 [2.20987196e+00 2.78733244e-04 1.44376009e-05 3.45489156e-06
  1.34309914e-06 6.40802087e-07 3.54668641e-07 2.12979420e-07
  1.37486589e-07 9.38017398e-08 6.44563382e-08 1.37098301e-07
  1.49213146e-07 4.16039239e-07 1.90488765e-08 5.63260371e-07
  8.11884519e-07 3.49916320e-08 7.60917186e-09 6.72995887e-09
  5.90318068e-09 5.16779051e-09 4.78671282e-09 4.52609283e-09
  4.14821843e-09 3.77501456e-09 3.67737517e-09 3.41366224e-09
  3.25119152e-09 3.09992627e-09 3.00005407e-09 2.90707680e-09
  2.80956327e-09 2.70362124e-09 2.64945851e-09 2.59262362e-09
  2.51881893e-09 2.47334952e-09 2.40731692e-09 2.35650473e-09
  2.30470583e-09 2.30793769e-09 2.24576016e-09 2.17865674e-09
  2.10747759e-09 2.19148521e-09 2.11716509e-09 2.04164157e-09
  1.97325570e-09 2.17887869e-09]
 [2.65487040e+00 1.39314370e-03 2.47229203e-05 6.59117605e-06
  2.81256392e-06 1.36487958e-06 7.89073636e-07 4.79226587e-07
  3.13411673e-07 2.14872279e-07 1.51498390e-07 1.13871603e-07
  8.63473517e-08 9.53961338e-08 4.24507647e-08 1.23435454e-07
  2.50684499e-07 2.68703548e-08 1.74030279e-08 1.54040254e-08
  1.36086510e-08 1.15710164e-08 1.07246429e-08 1.01919697e-08
  9.29819400e-09 8.36612746e-09 8.19654342e-09 7.56238433e-09
  7.18184802e-09 6.83264873e-09 6.59958822e-09 6.39010822e-09
  6.18960878e-09 5.95998054e-09 5.82052451e-09 5.68021390e-09
  5.54257390e-09 5.40395168e-09 5.29274914e-09 5.18168459e-09
  5.08220522e-09 5.01108280e-09 4.91708657e-09 4.80560714e-09
  4.66590842e-09 4.74218699e-09 4.65155280e-09 4.49670275e-09
  4.31452289e-09 4.62368015e-09]
 [1.61635026e+00 5.13856012e-04 9.42457534e-06 2.68489052e-06
  1.31402222e-06 5.57542493e-07 3.41574822e-07 2.09113411e-07
  1.44387514e-07 9.62137786e-08 8.67778346e-08 6.44943420e-08
  5.37506666e-08 7.22542462e-08 2.28970776e-08 1.17436604e-07
  2.84250025e-07 2.15213029e-08 9.38025151e-09 8.22305851e-09
  7.70808520e-09 5.45306052e-09 4.99731301e-09 5.04475636e-09
  4.48072441e-09 3.71477964e-09 3.77154988e-09 3.30924624e-09
  3.11872492e-09 2.88043558e-09 2.75416310e-09 2.69751126e-09
  2.61431862e-09 2.47496651e-09 2.41214643e-09 2.36777619e-09
  2.31382523e-09 2.23753936e-09 2.17127271e-09 2.12331827e-09
  2.08720213e-09 2.05359298e-09 2.01454429e-09 1.95976079e-09
  1.90140310e-09 1.91755997e-09 1.87002783e-09 1.80503231e-09
  1.74035068e-09 1.91392059e-09]
 [2.00184374e+00 1.78318251e-03 1.47551553e-05 4.08393680e-06
  2.11975779e-06 7.78343409e-07 4.87793882e-07 2.93416448e-07
  2.07046063e-07 1.36956339e-07 1.54332646e-07 1.13885006e-07
  9.58386823e-08 1.03174199e-07 4.01669082e-08 1.40381963e-07
  3.33217672e-07 3.94892149e-08 1.54188682e-08 1.35941223e-08
  1.38703236e-08 7.47128854e-09 6.49269579e-09 7.15095565e-09
  6.32010133e-09 4.50748904e-09 4.68709453e-09 3.93567658e-09
  3.67950483e-09 3.24963851e-09 3.06894185e-09 3.05019008e-09
  2.97721858e-09 2.71447053e-09 2.67591342e-09 2.61462441e-09
  2.59754507e-09 2.44073104e-09 2.37180135e-09 2.33399629e-09
  2.30029354e-09 2.26813904e-09 2.21022253e-09 2.12761918e-09
  2.06172143e-09 2.23183697e-09 2.19968862e-09 2.10646360e-09
  1.98842355e-09 2.25444434e-09]]
train_ae_loss [[3.78037731 3.22769012 4.65657859 5.46328505 5.9000653  6.17463204
  6.22759379 6.2694773  6.31454346 6.33979521 6.26750401 6.08491129
  5.98135225 5.79910026 5.68124897 5.42056601 5.22076695 4.67566684
  4.54498781 4.40894571 4.32885733 4.02441869 3.95036669 3.87972669
  3.87332062 3.69322699 3.66481764 3.67697625 3.61463437 3.58209444
  3.56471739 3.49318922 3.53178235 3.48674595 3.50380236 3.48734227
  3.47942497 3.46213609 3.44712132 3.43483857 3.44934679 3.43074001
  3.43822635 3.44604849 3.42876281 3.43300623 3.44608584 3.4472973
  3.4308303  3.44827351]
 [3.89841564 3.18600264 4.71488154 5.35948261 5.66318321 5.91476636
  5.85835025 5.78323417 5.79753366 5.78131143 5.64624703 5.40555775
  5.29612335 5.0644185  4.97331939 4.64432617 4.37966336 3.71894506
  3.4603493  3.15390262 3.02746037 2.59946769 2.47210297 2.40784388
  2.38898955 2.14164897 2.09233322 2.09465207 2.01055687 1.969568
  1.95559843 1.89058457 1.90165626 1.84783141 1.84620131 1.83558205
  1.8381248  1.80272571 1.78014448 1.77605403 1.78671882 1.75626666
  1.77830578 1.79462315 1.77604431 1.76053453 1.78337249 1.77158361
  1.76096922 1.7744963 ]
 [3.63534496 2.92303722 4.39672131 4.99854087 5.10362977 5.25903806
  5.10233425 4.95011933 4.94075007 4.89608398 4.75582667 4.48229967
  4.36109407 4.03309905 3.8924698  3.47391186 3.21803336 2.59971872
  2.47847196 2.30632269 2.24682769 1.86194851 1.74516539 1.7007485
  1.68393385 1.44359601 1.40965995 1.40372122 1.32652418 1.2812672
  1.27074546 1.22068993 1.22568271 1.18211479 1.17657387 1.16430267
  1.1646985  1.14184114 1.12207673 1.11570284 1.11779544 1.09626346
  1.11536355 1.10808372 1.103858   1.0968038  1.12075222 1.09247849
  1.09130615 1.09851359]
 [3.98322302 3.04671696 4.5400676  5.4611653  5.45495318 5.49756438
  5.18404844 4.96333094 4.90690329 4.80037682 4.60792845 4.23301819
  4.13949527 3.83610165 3.72564781 3.31853838 3.0617172  2.45374789
  2.34372777 2.1741518  2.11115757 1.73936795 1.62696779 1.57963692
  1.56439878 1.32843223 1.29243312 1.28690674 1.21667052 1.16932628
  1.16167268 1.10962208 1.11434622 1.07843554 1.06461596 1.05627241
  1.05520601 1.0300845  1.01424574 1.00074122 1.00599719 0.9861467
  1.00331363 0.99834126 0.99648342 0.98642361 1.01089423 0.9710734
  0.97714184 0.98715252]
 [4.43619082 2.71761158 4.00047429 4.89085601 5.17022957 5.09667295
  4.62028544 4.37239371 4.28992518 4.15729592 3.98003348 3.63417353
  3.5621371  3.28204695 3.18885766 2.8298399  2.60024279 2.07076245
  1.97799134 1.83072595 1.7821098  1.45617287 1.36040315 1.32366822
  1.31177592 1.10357201 1.07621844 1.07016212 1.01613257 0.97420688
  0.96586454 0.92175873 0.92564718 0.89278997 0.88042333 0.87528173
  0.87592529 0.85499622 0.83860773 0.83010663 0.83157609 0.81782091
  0.82985083 0.8282092  0.82605694 0.81656173 0.83451595 0.80241315
  0.80862447 0.81787579]]
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
total_train+valid_time 1295.184902114
Start Testing
Load ckpt at ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt
gc 9
Test layer0 Acc 0.7076, AUC 0.7978922128677368, avg_entr 0.22716903686523438, f1 0.707599937915802
l0_test_time 0.2835629300000164
gc 0
Test layer1 Acc 0.7562, AUC 0.8414736390113831, avg_entr 0.2044380009174347, f1 0.7561999559402466
l1_test_time 0.3559303849999651
gc 0
Test layer2 Acc 0.7738, AUC 0.8573222160339355, avg_entr 0.14384497702121735, f1 0.7738000154495239
l2_test_time 0.46447516500006714
gc 0
Test layer3 Acc 0.7762, AUC 0.8617750406265259, avg_entr 0.12805968523025513, f1 0.776199996471405
l3_test_time 0.6145429549999335
gc 0
Test layer4 Acc 0.782, AUC 0.8644751906394958, avg_entr 0.13107207417488098, f1 0.7820000052452087
l4_test_time 0.8087711600001057
gc 0
Test threshold 0.1 Acc 0.7738, AUC 0.8408631086349487, avg_entr 0.17280390858650208, f1 0.7738000154495239
t0.1_test_time 0.5707582739998998
gc 0
Test threshold 0.2 Acc 0.7672, AUC 0.8332608938217163, avg_entr 0.1734030693769455, f1 0.7671999931335449
t0.2_test_time 0.5099313229998188
gc 0
Test threshold 0.3 Acc 0.7648, AUC 0.8271350860595703, avg_entr 0.1789029836654663, f1 0.764799952507019
t0.3_test_time 0.4691895910000312
gc 0
Test threshold 0.4 Acc 0.761, AUC 0.8221511840820312, avg_entr 0.19008870422840118, f1 0.7610000371932983
t0.4_test_time 0.4425532049999674
gc 0
Test threshold 0.5 Acc 0.753, AUC 0.8182953000068665, avg_entr 0.20115017890930176, f1 0.753000020980835
t0.5_test_time 0.4247549059998619
gc 0
Test threshold 0.6 Acc 0.7462, AUC 0.8135524988174438, avg_entr 0.21627524495124817, f1 0.7462000250816345
t0.6_test_time 0.39992757999993955
gc 0
Test threshold 0.7 Acc 0.7388, AUC 0.8110616207122803, avg_entr 0.23319345712661743, f1 0.7387999892234802
t0.7_test_time 0.3826122849998228
gc 0
Test threshold 0.8 Acc 0.7326, AUC 0.8078161478042603, avg_entr 0.2526828646659851, f1 0.7325999140739441
t0.8_test_time 0.3791062130001137
gc 0
Test threshold 0.9 Acc 0.7244, AUC 0.8040826916694641, avg_entr 0.2802291512489319, f1 0.7244000434875488
t0.9_test_time 0.3545493929998429
