total count words 222751
vocab size 30000
train size 40000, valid size 5000, test size 5000
found 27937 words in glove
model: TransformerALsideText(
  (layers): ModuleList(
    (0): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=2, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=2, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
  (emb_layers): ModuleList(
    (0): Embedding(30000, 300)
    (1): Embedding(30000, 300)
    (2): Embedding(30000, 300)
    (3): Embedding(30000, 300)
    (4): Embedding(30000, 300)
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.multi_headed_attention.linears.0.weight 90000
layers.0.enc.f.multi_headed_attention.linears.0.bias 300
layers.0.enc.f.multi_headed_attention.linears.1.weight 90000
layers.0.enc.f.multi_headed_attention.linears.1.bias 300
layers.0.enc.f.multi_headed_attention.linears.2.weight 90000
layers.0.enc.f.multi_headed_attention.linears.2.bias 300
layers.0.enc.f.multi_headed_attention.linears.3.weight 90000
layers.0.enc.f.multi_headed_attention.linears.3.bias 300
layers.0.enc.f.feed_forward.w_1.weight 90000
layers.0.enc.f.feed_forward.w_1.bias 300
layers.0.enc.f.feed_forward.w_2.weight 90000
layers.0.enc.f.feed_forward.w_2.bias 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.0.enc.f.encoder.norm.a 300
layers.0.enc.f.encoder.norm.b 300
layers.0.ae.g.0.weight 256
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 256
layers.0.ae.h.0.bias 2
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
emb_layers.0.weight 9000000
emb_layers.1.weight 9000000
emb_layers.2.weight 9000000
emb_layers.3.weight 9000000
emb_layers.4.weight 9000000
Total Trainable Params: 50758378
init_time 21.754658297
Start Training
gc 0
Train Epoch0 Acc 0.50505 (20202/40000), AUC 0.5073768496513367
ep0_train_time 23.422124397999998
Test Epoch0 layer0 Acc 0.5492, AUC 0.5709768533706665, avg_entr 0.6937836408615112, f1 0.5491999983787537
ep0_l0_test_time 0.2873961749999978
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 0
Test Epoch0 layer1 Acc 0.522, AUC 0.5482295751571655, avg_entr 0.6919758915901184, f1 0.5220000147819519
ep0_l1_test_time 0.353877562000001
Test Epoch0 layer2 Acc 0.519, AUC 0.5376948118209839, avg_entr 0.6929238438606262, f1 0.5189999938011169
ep0_l2_test_time 0.4609094070000026
Test Epoch0 layer3 Acc 0.524, AUC 0.5375776290893555, avg_entr 0.6950629949569702, f1 0.5239999890327454
ep0_l3_test_time 0.6116470369999973
Test Epoch0 layer4 Acc 0.5036, AUC 0.5219718217849731, avg_entr 0.6953169107437134, f1 0.503600001335144
ep0_l4_test_time 0.8052758609999984
gc 0
Train Epoch1 Acc 0.51755 (20702/40000), AUC 0.5217267870903015
ep1_train_time 23.037847097000004
Test Epoch1 layer0 Acc 0.5722, AUC 0.6149775981903076, avg_entr 0.6662548780441284, f1 0.5722000002861023
ep1_l0_test_time 0.2837745049999967
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 1
Test Epoch1 layer1 Acc 0.5364, AUC 0.6283876299858093, avg_entr 0.6846264600753784, f1 0.5364000201225281
ep1_l1_test_time 0.3543902049999872
Test Epoch1 layer2 Acc 0.5476, AUC 0.6092722415924072, avg_entr 0.6855385899543762, f1 0.5475999712944031
ep1_l2_test_time 0.46279655800000796
Test Epoch1 layer3 Acc 0.5102, AUC 0.5662554502487183, avg_entr 0.6875741481781006, f1 0.510200023651123
ep1_l3_test_time 0.6123174830000124
Test Epoch1 layer4 Acc 0.5, AUC 0.5428340435028076, avg_entr 0.6907624006271362, f1 0.5
ep1_l4_test_time 0.8075217859999952
gc 0
Train Epoch2 Acc 0.529925 (21197/40000), AUC 0.5385947227478027
ep2_train_time 23.078392908000012
Test Epoch2 layer0 Acc 0.5954, AUC 0.670185387134552, avg_entr 0.5936537981033325, f1 0.5953999757766724
ep2_l0_test_time 0.28340808000000095
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 2
Test Epoch2 layer1 Acc 0.5578, AUC 0.695030689239502, avg_entr 0.6157495379447937, f1 0.5577999949455261
ep2_l1_test_time 0.35417438000000345
Test Epoch2 layer2 Acc 0.5128, AUC 0.6822256445884705, avg_entr 0.6175806522369385, f1 0.5127999782562256
ep2_l2_test_time 0.4610333319999995
Test Epoch2 layer3 Acc 0.5, AUC 0.6546036005020142, avg_entr 0.5534924268722534, f1 0.5
ep2_l3_test_time 0.6166642919999958
Test Epoch2 layer4 Acc 0.5, AUC 0.6276416778564453, avg_entr 0.5894047021865845, f1 0.5
ep2_l4_test_time 0.808031186000008
gc 0
Train Epoch3 Acc 0.57175 (22870/40000), AUC 0.5853445529937744
ep3_train_time 23.08002639
Test Epoch3 layer0 Acc 0.6342, AUC 0.703007698059082, avg_entr 0.5280832648277283, f1 0.6341999769210815
ep3_l0_test_time 0.2838603149999983
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer1 Acc 0.635, AUC 0.7345578074455261, avg_entr 0.5177894234657288, f1 0.6349999904632568
ep3_l1_test_time 0.35418792200000837
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer2 Acc 0.5928, AUC 0.737587571144104, avg_entr 0.5087419748306274, f1 0.5928000211715698
ep3_l2_test_time 0.46319250099999465
Test Epoch3 layer3 Acc 0.5788, AUC 0.7290390729904175, avg_entr 0.5851453542709351, f1 0.5788000226020813
ep3_l3_test_time 0.6120300259999993
Test Epoch3 layer4 Acc 0.5376, AUC 0.7185631394386292, avg_entr 0.6205145716667175, f1 0.5375999808311462
ep3_l4_test_time 0.8073965090000002
gc 0
Train Epoch4 Acc 0.61475 (24590/40000), AUC 0.656495213508606
ep4_train_time 23.218697352999982
Test Epoch4 layer0 Acc 0.6368, AUC 0.7273895740509033, avg_entr 0.46635591983795166, f1 0.6367999911308289
ep4_l0_test_time 0.2847596179999812
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
Test Epoch4 layer1 Acc 0.5948, AUC 0.7600598335266113, avg_entr 0.36278411746025085, f1 0.5947999954223633
ep4_l1_test_time 0.3594072159999939
Test Epoch4 layer2 Acc 0.5538, AUC 0.7644431591033936, avg_entr 0.2905283570289612, f1 0.5537999868392944
ep4_l2_test_time 0.46345373899998776
Test Epoch4 layer3 Acc 0.519, AUC 0.7636570930480957, avg_entr 0.22310249507427216, f1 0.5189999938011169
ep4_l3_test_time 0.6142332099999805
Test Epoch4 layer4 Acc 0.504, AUC 0.7421616315841675, avg_entr 0.21162931621074677, f1 0.5040000081062317
ep4_l4_test_time 0.8090825660000007
gc 0
Train Epoch5 Acc 0.6686 (26744/40000), AUC 0.7326302528381348
ep5_train_time 23.03547102600001
Test Epoch5 layer0 Acc 0.6622, AUC 0.7471480369567871, avg_entr 0.38807180523872375, f1 0.6621999740600586
ep5_l0_test_time 0.29023331900000926
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 5
Test Epoch5 layer1 Acc 0.6944, AUC 0.7813255190849304, avg_entr 0.35251694917678833, f1 0.6944000124931335
ep5_l1_test_time 0.3603178089999801
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 5
Test Epoch5 layer2 Acc 0.6984, AUC 0.7892234325408936, avg_entr 0.3564227223396301, f1 0.6984000205993652
ep5_l2_test_time 0.4644170210000027
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 5
Test Epoch5 layer3 Acc 0.6892, AUC 0.7964739799499512, avg_entr 0.3645384907722473, f1 0.6891999840736389
ep5_l3_test_time 0.6140003060000083
Test Epoch5 layer4 Acc 0.6868, AUC 0.7936967611312866, avg_entr 0.3877224326133728, f1 0.6868000030517578
ep5_l4_test_time 0.811746080000006
gc 0
Train Epoch6 Acc 0.715225 (28609/40000), AUC 0.7848962545394897
ep6_train_time 23.120980110000005
Test Epoch6 layer0 Acc 0.6878, AUC 0.7635278701782227, avg_entr 0.3929334580898285, f1 0.6877999901771545
ep6_l0_test_time 0.2890628230000232
Test Epoch6 layer1 Acc 0.7152, AUC 0.8018162250518799, avg_entr 0.3633507788181305, f1 0.7151999473571777
ep6_l1_test_time 0.3545069049999938
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer2 Acc 0.7198, AUC 0.8075767159461975, avg_entr 0.3772377073764801, f1 0.7197999358177185
ep6_l2_test_time 0.4640906639999969
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer3 Acc 0.7322, AUC 0.8161913752555847, avg_entr 0.4106219708919525, f1 0.732200026512146
ep6_l3_test_time 0.613703036000004
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer4 Acc 0.729, AUC 0.8148816823959351, avg_entr 0.46733686327934265, f1 0.7289999723434448
ep6_l4_test_time 0.8084158409999986
gc 0
Train Epoch7 Acc 0.7233 (28932/40000), AUC 0.7987252473831177
ep7_train_time 23.02248129
Test Epoch7 layer0 Acc 0.6876, AUC 0.7708927392959595, avg_entr 0.3660067915916443, f1 0.6876000165939331
ep7_l0_test_time 0.284642343999991
Test Epoch7 layer1 Acc 0.713, AUC 0.8091743588447571, avg_entr 0.31541234254837036, f1 0.7130000591278076
ep7_l1_test_time 0.3538525269999866
Test Epoch7 layer2 Acc 0.7114, AUC 0.8145802021026611, avg_entr 0.31998270750045776, f1 0.7113999724388123
ep7_l2_test_time 0.46248436400000514
Test Epoch7 layer3 Acc 0.7138, AUC 0.8230480551719666, avg_entr 0.32978329062461853, f1 0.7138000130653381
ep7_l3_test_time 0.6138552140000115
Test Epoch7 layer4 Acc 0.7076, AUC 0.8230470418930054, avg_entr 0.36410507559776306, f1 0.707599937915802
ep7_l4_test_time 0.8079425049999998
gc 0
Train Epoch8 Acc 0.758775 (30351/40000), AUC 0.8408147096633911
ep8_train_time 23.13779703900002
Test Epoch8 layer0 Acc 0.7036, AUC 0.7802461385726929, avg_entr 0.335877925157547, f1 0.7035999894142151
ep8_l0_test_time 0.28352433800000654
Test Epoch8 layer1 Acc 0.7374, AUC 0.8192296624183655, avg_entr 0.3045397996902466, f1 0.7373999953269958
ep8_l1_test_time 0.35282463000001485
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 8
Test Epoch8 layer2 Acc 0.7398, AUC 0.8269236087799072, avg_entr 0.295984148979187, f1 0.7398000359535217
ep8_l2_test_time 0.4618222679999917
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 8
Test Epoch8 layer3 Acc 0.7456, AUC 0.834189772605896, avg_entr 0.30071595311164856, f1 0.7455999851226807
ep8_l3_test_time 0.6137872389999757
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 8
Test Epoch8 layer4 Acc 0.7426, AUC 0.8340853452682495, avg_entr 0.31967103481292725, f1 0.7426000237464905
ep8_l4_test_time 0.8088511139999923
gc 0
Train Epoch9 Acc 0.7708 (30832/40000), AUC 0.8509119749069214
ep9_train_time 23.165980405000028
Test Epoch9 layer0 Acc 0.7068, AUC 0.784540057182312, avg_entr 0.3290737271308899, f1 0.7067999839782715
ep9_l0_test_time 0.28575888699998586
Test Epoch9 layer1 Acc 0.7388, AUC 0.8241788148880005, avg_entr 0.2671968340873718, f1 0.7387999892234802
ep9_l1_test_time 0.3657225480000079
Test Epoch9 layer2 Acc 0.7448, AUC 0.8326847553253174, avg_entr 0.25237855315208435, f1 0.7447999715805054
ep9_l2_test_time 0.4634130669999763
Test Epoch9 layer3 Acc 0.7486, AUC 0.8412883281707764, avg_entr 0.24153916537761688, f1 0.7486000061035156
ep9_l3_test_time 0.619136941000022
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 9
Test Epoch9 layer4 Acc 0.7452, AUC 0.8418716192245483, avg_entr 0.23014575242996216, f1 0.745199978351593
ep9_l4_test_time 0.8116580280000107
gc 0
Train Epoch10 Acc 0.799525 (31981/40000), AUC 0.880083441734314
ep10_train_time 23.09611844699998
Test Epoch10 layer0 Acc 0.7042, AUC 0.7864148020744324, avg_entr 0.29665127396583557, f1 0.704200029373169
ep10_l0_test_time 0.28475879000001214
Test Epoch10 layer1 Acc 0.7138, AUC 0.825980544090271, avg_entr 0.24395491182804108, f1 0.7138000130653381
ep10_l1_test_time 0.3540313459999993
Test Epoch10 layer2 Acc 0.695, AUC 0.8368219137191772, avg_entr 0.22724054753780365, f1 0.6949999928474426
ep10_l2_test_time 0.46276256299995566
Test Epoch10 layer3 Acc 0.6686, AUC 0.8471174240112305, avg_entr 0.19791966676712036, f1 0.6686000227928162
ep10_l3_test_time 0.6145964880000179
Test Epoch10 layer4 Acc 0.6554, AUC 0.8467560410499573, avg_entr 0.15485896170139313, f1 0.6553999781608582
ep10_l4_test_time 0.8082820449999986
gc 0
Train Epoch11 Acc 0.810575 (32423/40000), AUC 0.8911975026130676
ep11_train_time 23.025689340999975
Test Epoch11 layer0 Acc 0.6992, AUC 0.7890474796295166, avg_entr 0.28347861766815186, f1 0.6991999745368958
ep11_l0_test_time 0.28472245300002896
Test Epoch11 layer1 Acc 0.728, AUC 0.8305113315582275, avg_entr 0.2507813572883606, f1 0.7279999852180481
ep11_l1_test_time 0.3533958689999963
Test Epoch11 layer2 Acc 0.7234, AUC 0.8416006565093994, avg_entr 0.2467517852783203, f1 0.7233999967575073
ep11_l2_test_time 0.46306157700001904
Test Epoch11 layer3 Acc 0.7356, AUC 0.8515474796295166, avg_entr 0.23793451488018036, f1 0.7355999946594238
ep11_l3_test_time 0.6132648070000073
Test Epoch11 layer4 Acc 0.7378, AUC 0.8520445227622986, avg_entr 0.19691982865333557, f1 0.7378000020980835
ep11_l4_test_time 0.816593370000021
gc 0
Train Epoch12 Acc 0.827675 (33107/40000), AUC 0.9058490991592407
ep12_train_time 23.198104838999996
Test Epoch12 layer0 Acc 0.712, AUC 0.7891807556152344, avg_entr 0.2731155455112457, f1 0.7120000123977661
ep12_l0_test_time 0.2895300469999711
Test Epoch12 layer1 Acc 0.7394, AUC 0.8275673389434814, avg_entr 0.22363847494125366, f1 0.7394000291824341
ep12_l1_test_time 0.35363111999998864
Test Epoch12 layer2 Acc 0.7468, AUC 0.8400808572769165, avg_entr 0.20594967901706696, f1 0.7468000054359436
ep12_l2_test_time 0.4615190199999688
Test Epoch12 layer3 Acc 0.7486, AUC 0.8513989448547363, avg_entr 0.18547959625720978, f1 0.7486000061035156
ep12_l3_test_time 0.6116786629999638
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 12
Test Epoch12 layer4 Acc 0.7476, AUC 0.8507382869720459, avg_entr 0.14482153952121735, f1 0.7476000189781189
ep12_l4_test_time 0.8088509579999936
gc 0
Train Epoch13 Acc 0.8469 (33876/40000), AUC 0.9229956865310669
ep13_train_time 23.034606682999993
Test Epoch13 layer0 Acc 0.709, AUC 0.7880552411079407, avg_entr 0.25570470094680786, f1 0.7090000510215759
ep13_l0_test_time 0.28301500000003443
Test Epoch13 layer1 Acc 0.729, AUC 0.8295663595199585, avg_entr 0.21587775647640228, f1 0.7289999723434448
ep13_l1_test_time 0.35283804699997745
Test Epoch13 layer2 Acc 0.7364, AUC 0.8440225720405579, avg_entr 0.20956875383853912, f1 0.7364000082015991
ep13_l2_test_time 0.4612064390000228
Test Epoch13 layer3 Acc 0.733, AUC 0.8505477905273438, avg_entr 0.17508351802825928, f1 0.7329999804496765
ep13_l3_test_time 0.6125284240000042
Test Epoch13 layer4 Acc 0.7298, AUC 0.854716956615448, avg_entr 0.14651130139827728, f1 0.7297999858856201
ep13_l4_test_time 0.8073455610000337
gc 0
Train Epoch14 Acc 0.861825 (34473/40000), AUC 0.9352962970733643
ep14_train_time 23.054703885000038
Test Epoch14 layer0 Acc 0.71, AUC 0.7858704924583435, avg_entr 0.246954083442688, f1 0.7099999785423279
ep14_l0_test_time 0.2828229780000129
Test Epoch14 layer1 Acc 0.7434, AUC 0.8269013166427612, avg_entr 0.19935175776481628, f1 0.743399977684021
ep14_l1_test_time 0.35367042899997614
Test Epoch14 layer2 Acc 0.7552, AUC 0.841598391532898, avg_entr 0.18251225352287292, f1 0.7552000284194946
ep14_l2_test_time 0.4623637189999954
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 14
Test Epoch14 layer3 Acc 0.7606, AUC 0.8494852185249329, avg_entr 0.12086955457925797, f1 0.7605999708175659
ep14_l3_test_time 0.6142124679999483
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 14
Test Epoch14 layer4 Acc 0.7626, AUC 0.8526090383529663, avg_entr 0.11611621081829071, f1 0.7626000046730042
ep14_l4_test_time 0.8094013329999825
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 14
gc 0
Train Epoch15 Acc 0.876825 (35073/40000), AUC 0.9455819129943848
ep15_train_time 23.02782305400001
Test Epoch15 layer0 Acc 0.7098, AUC 0.7807924747467041, avg_entr 0.2302517592906952, f1 0.7098000049591064
ep15_l0_test_time 0.285282063000011
Test Epoch15 layer1 Acc 0.7412, AUC 0.8223776817321777, avg_entr 0.17542664706707, f1 0.7411999702453613
ep15_l1_test_time 0.3537939779999988
Test Epoch15 layer2 Acc 0.7514, AUC 0.8363764882087708, avg_entr 0.15149785578250885, f1 0.7513999938964844
ep15_l2_test_time 0.4649967550000156
Test Epoch15 layer3 Acc 0.7536, AUC 0.8463174104690552, avg_entr 0.1030137911438942, f1 0.7535999417304993
ep15_l3_test_time 0.6164616510000087
Test Epoch15 layer4 Acc 0.7538, AUC 0.8493809700012207, avg_entr 0.0968874841928482, f1 0.7537999749183655
ep15_l4_test_time 0.8100614090000136
gc 0
Train Epoch16 Acc 0.8937 (35748/40000), AUC 0.9563280344009399
ep16_train_time 23.090627006000034
Test Epoch16 layer0 Acc 0.6744, AUC 0.7724807262420654, avg_entr 0.18742848932743073, f1 0.6743999719619751
ep16_l0_test_time 0.28342115999998896
Test Epoch16 layer1 Acc 0.7202, AUC 0.8132196068763733, avg_entr 0.16079582273960114, f1 0.7202000021934509
ep16_l1_test_time 0.35288814800003365
Test Epoch16 layer2 Acc 0.7008, AUC 0.8270145058631897, avg_entr 0.11427004635334015, f1 0.7008000016212463
ep16_l2_test_time 0.46135984200003577
Test Epoch16 layer3 Acc 0.714, AUC 0.8386303186416626, avg_entr 0.08657079935073853, f1 0.7139999866485596
ep16_l3_test_time 0.6126255279999668
Test Epoch16 layer4 Acc 0.7138, AUC 0.8375388383865356, avg_entr 0.08973526954650879, f1 0.7138000130653381
ep16_l4_test_time 0.8090005150000366
gc 0
Train Epoch17 Acc 0.88645 (35458/40000), AUC 0.9509024620056152
ep17_train_time 23.255699953999965
Test Epoch17 layer0 Acc 0.7052, AUC 0.7772120237350464, avg_entr 0.20919811725616455, f1 0.7052000164985657
ep17_l0_test_time 0.291974917999994
Test Epoch17 layer1 Acc 0.7378, AUC 0.8162722587585449, avg_entr 0.15740332007408142, f1 0.7378000020980835
ep17_l1_test_time 0.3613958480000292
Test Epoch17 layer2 Acc 0.7454, AUC 0.8264656066894531, avg_entr 0.08954151719808578, f1 0.745400071144104
ep17_l2_test_time 0.46174823600000536
Test Epoch17 layer3 Acc 0.7486, AUC 0.8375123739242554, avg_entr 0.07309875637292862, f1 0.7486000061035156
ep17_l3_test_time 0.6132922429999894
Test Epoch17 layer4 Acc 0.7504, AUC 0.8396642208099365, avg_entr 0.07343724370002747, f1 0.7504000067710876
ep17_l4_test_time 0.8077007350000258
gc 0
Train Epoch18 Acc 0.91745 (36698/40000), AUC 0.9724855422973633
ep18_train_time 23.11497852399998
Test Epoch18 layer0 Acc 0.7026, AUC 0.7724769115447998, avg_entr 0.20234641432762146, f1 0.7026000022888184
ep18_l0_test_time 0.2835442589999957
Test Epoch18 layer1 Acc 0.736, AUC 0.8132362961769104, avg_entr 0.16374409198760986, f1 0.7360000014305115
ep18_l1_test_time 0.3556034960000716
Test Epoch18 layer2 Acc 0.7452, AUC 0.8268601894378662, avg_entr 0.08901447802782059, f1 0.745199978351593
ep18_l2_test_time 0.4643821989999424
Test Epoch18 layer3 Acc 0.752, AUC 0.8371222019195557, avg_entr 0.08233805000782013, f1 0.7519999742507935
ep18_l3_test_time 0.6268189200000052
Test Epoch18 layer4 Acc 0.7546, AUC 0.8404186367988586, avg_entr 0.07918255031108856, f1 0.7546000480651855
ep18_l4_test_time 0.8117847500000153
gc 0
Train Epoch19 Acc 0.92675 (37070/40000), AUC 0.9764671325683594
ep19_train_time 23.213157295000087
Test Epoch19 layer0 Acc 0.703, AUC 0.7715566754341125, avg_entr 0.198944553732872, f1 0.703000009059906
ep19_l0_test_time 0.2842915469999525
Test Epoch19 layer1 Acc 0.728, AUC 0.8092734813690186, avg_entr 0.14765019714832306, f1 0.7279999852180481
ep19_l1_test_time 0.3541457009999931
Test Epoch19 layer2 Acc 0.7376, AUC 0.8205627799034119, avg_entr 0.0693000853061676, f1 0.7376000285148621
ep19_l2_test_time 0.4625713350000069
Test Epoch19 layer3 Acc 0.7452, AUC 0.8282901048660278, avg_entr 0.06512833386659622, f1 0.745199978351593
ep19_l3_test_time 0.6136748929999385
Test Epoch19 layer4 Acc 0.7446, AUC 0.836675763130188, avg_entr 0.06070012226700783, f1 0.7445999979972839
ep19_l4_test_time 0.8103267340000002
gc 0
Train Epoch20 Acc 0.934475 (37379/40000), AUC 0.9814414978027344
ep20_train_time 23.159397541999965
Test Epoch20 layer0 Acc 0.7094, AUC 0.7699797749519348, avg_entr 0.1880999207496643, f1 0.709399938583374
ep20_l0_test_time 0.2833027670000092
Test Epoch20 layer1 Acc 0.732, AUC 0.8065518140792847, avg_entr 0.14695243537425995, f1 0.7319999933242798
ep20_l1_test_time 0.3540789119999772
Test Epoch20 layer2 Acc 0.7396, AUC 0.8188955783843994, avg_entr 0.07253745198249817, f1 0.7396000027656555
ep20_l2_test_time 0.46395799599997645
Test Epoch20 layer3 Acc 0.7478, AUC 0.8292847871780396, avg_entr 0.0707150399684906, f1 0.7477999925613403
ep20_l3_test_time 0.6153249129999949
Test Epoch20 layer4 Acc 0.7512, AUC 0.8337891697883606, avg_entr 0.06889887154102325, f1 0.7512000203132629
ep20_l4_test_time 0.8084558549999201
gc 0
Train Epoch21 Acc 0.9386 (37544/40000), AUC 0.9814789295196533
ep21_train_time 23.148747111000034
Test Epoch21 layer0 Acc 0.7058, AUC 0.7690285444259644, avg_entr 0.18974965810775757, f1 0.7057999968528748
ep21_l0_test_time 0.286161049000043
Test Epoch21 layer1 Acc 0.7296, AUC 0.8035664558410645, avg_entr 0.14565353095531464, f1 0.7295999526977539
ep21_l1_test_time 0.3546514780000507
Test Epoch21 layer2 Acc 0.7384, AUC 0.8128758072853088, avg_entr 0.06492568552494049, f1 0.7384000420570374
ep21_l2_test_time 0.4645150909999529
Test Epoch21 layer3 Acc 0.7442, AUC 0.823960542678833, avg_entr 0.06200089678168297, f1 0.7441999316215515
ep21_l3_test_time 0.6147722680000243
Test Epoch21 layer4 Acc 0.7448, AUC 0.8281834125518799, avg_entr 0.058290187269449234, f1 0.7447999715805054
ep21_l4_test_time 0.8099317799999426
gc 0
Train Epoch22 Acc 0.94325 (37730/40000), AUC 0.9855439066886902
ep22_train_time 23.054100316999893
Test Epoch22 layer0 Acc 0.7022, AUC 0.767229437828064, avg_entr 0.1949869990348816, f1 0.7021999955177307
ep22_l0_test_time 0.2882138259999465
Test Epoch22 layer1 Acc 0.7286, AUC 0.8030270338058472, avg_entr 0.1446830779314041, f1 0.728600025177002
ep22_l1_test_time 0.3548617190000414
Test Epoch22 layer2 Acc 0.7398, AUC 0.8116006255149841, avg_entr 0.06097274273633957, f1 0.7398000359535217
ep22_l2_test_time 0.46303126499992686
Test Epoch22 layer3 Acc 0.7412, AUC 0.8232735395431519, avg_entr 0.057543665170669556, f1 0.7411999702453613
ep22_l3_test_time 0.615011963000029
Test Epoch22 layer4 Acc 0.7474, AUC 0.829885721206665, avg_entr 0.0550825335085392, f1 0.7473999857902527
ep22_l4_test_time 0.8084332949999862
gc 0
Train Epoch23 Acc 0.9474 (37896/40000), AUC 0.9866721630096436
ep23_train_time 23.020877736999978
Test Epoch23 layer0 Acc 0.6968, AUC 0.7674797177314758, avg_entr 0.18744076788425446, f1 0.6967999935150146
ep23_l0_test_time 0.2826136260000567
Test Epoch23 layer1 Acc 0.7244, AUC 0.80331951379776, avg_entr 0.13692888617515564, f1 0.7244000434875488
ep23_l1_test_time 0.35306117400000403
Test Epoch23 layer2 Acc 0.7364, AUC 0.8116705417633057, avg_entr 0.06202435865998268, f1 0.7364000082015991
ep23_l2_test_time 0.4614635629999384
Test Epoch23 layer3 Acc 0.7448, AUC 0.8229741454124451, avg_entr 0.057932671159505844, f1 0.7447999715805054
ep23_l3_test_time 0.612759901000004
Test Epoch23 layer4 Acc 0.7454, AUC 0.8309568166732788, avg_entr 0.053780242800712585, f1 0.745400071144104
ep23_l4_test_time 0.8086961459999884
gc 0
Train Epoch24 Acc 0.94945 (37978/40000), AUC 0.987464189529419
ep24_train_time 23.043834708999952
Test Epoch24 layer0 Acc 0.7054, AUC 0.7666819095611572, avg_entr 0.1862487941980362, f1 0.7053999900817871
ep24_l0_test_time 0.28668236399994385
Test Epoch24 layer1 Acc 0.7266, AUC 0.7995815873146057, avg_entr 0.13072174787521362, f1 0.7265999913215637
ep24_l1_test_time 0.35437306699998317
Test Epoch24 layer2 Acc 0.7352, AUC 0.809860348701477, avg_entr 0.05574953556060791, f1 0.7351999282836914
ep24_l2_test_time 0.46670679800001835
Test Epoch24 layer3 Acc 0.7416, AUC 0.8203064203262329, avg_entr 0.05263525992631912, f1 0.741599977016449
ep24_l3_test_time 0.6127005640000789
Test Epoch24 layer4 Acc 0.7456, AUC 0.8272188901901245, avg_entr 0.050527989864349365, f1 0.7455999851226807
ep24_l4_test_time 0.8166418939999858
gc 0
Train Epoch25 Acc 0.949725 (37989/40000), AUC 0.987287700176239
ep25_train_time 23.097049274999904
Test Epoch25 layer0 Acc 0.7048, AUC 0.7651519775390625, avg_entr 0.18172572553157806, f1 0.704800009727478
ep25_l0_test_time 0.28362601599997106
Test Epoch25 layer1 Acc 0.7254, AUC 0.7983818054199219, avg_entr 0.12486835569143295, f1 0.7253999710083008
ep25_l1_test_time 0.3534106580000298
Test Epoch25 layer2 Acc 0.732, AUC 0.8035577535629272, avg_entr 0.050819337368011475, f1 0.7319999933242798
ep25_l2_test_time 0.4629163460000427
Test Epoch25 layer3 Acc 0.7374, AUC 0.8141663074493408, avg_entr 0.047986894845962524, f1 0.7373999953269958
ep25_l3_test_time 0.613538321999954
Test Epoch25 layer4 Acc 0.7414, AUC 0.8235745429992676, avg_entr 0.044290460646152496, f1 0.7414000034332275
ep25_l4_test_time 0.8085120769999321
gc 0
Train Epoch26 Acc 0.956225 (38249/40000), AUC 0.9900116920471191
ep26_train_time 23.172594081000057
Test Epoch26 layer0 Acc 0.7008, AUC 0.7649803757667542, avg_entr 0.18190619349479675, f1 0.7008000016212463
ep26_l0_test_time 0.2839365600000292
Test Epoch26 layer1 Acc 0.7214, AUC 0.7982951402664185, avg_entr 0.12049867957830429, f1 0.7214000225067139
ep26_l1_test_time 0.35427163000008477
Test Epoch26 layer2 Acc 0.7324, AUC 0.8069114685058594, avg_entr 0.0511372946202755, f1 0.7323999404907227
ep26_l2_test_time 0.46253559400008726
Test Epoch26 layer3 Acc 0.7394, AUC 0.8170965909957886, avg_entr 0.050086088478565216, f1 0.7394000291824341
ep26_l3_test_time 0.6207964210000227
Test Epoch26 layer4 Acc 0.7448, AUC 0.8245266675949097, avg_entr 0.048165760934352875, f1 0.7447999715805054
ep26_l4_test_time 0.8128578519999792
gc 0
Train Epoch27 Acc 0.95485 (38194/40000), AUC 0.9902365207672119
ep27_train_time 23.13279921200001
Test Epoch27 layer0 Acc 0.6998, AUC 0.76475989818573, avg_entr 0.18259067833423615, f1 0.6998000144958496
ep27_l0_test_time 0.28628228299999137
Test Epoch27 layer1 Acc 0.7176, AUC 0.7964150905609131, avg_entr 0.11737402528524399, f1 0.7175999879837036
ep27_l1_test_time 0.3527512550000438
Test Epoch27 layer2 Acc 0.732, AUC 0.8049004077911377, avg_entr 0.05380593240261078, f1 0.7319999933242798
ep27_l2_test_time 0.4649061809999466
Test Epoch27 layer3 Acc 0.7372, AUC 0.8136316537857056, avg_entr 0.05094614252448082, f1 0.7372000217437744
ep27_l3_test_time 0.6131982959999505
Test Epoch27 layer4 Acc 0.739, AUC 0.8233509063720703, avg_entr 0.04888157173991203, f1 0.7390000820159912
ep27_l4_test_time 0.8074001249999583
gc 0
Train Epoch28 Acc 0.957525 (38301/40000), AUC 0.9908658266067505
ep28_train_time 23.108884968999973
Test Epoch28 layer0 Acc 0.7006, AUC 0.7650905847549438, avg_entr 0.17804747819900513, f1 0.7006000280380249
ep28_l0_test_time 0.2850209430000632
Test Epoch28 layer1 Acc 0.7168, AUC 0.7956732511520386, avg_entr 0.10795765370130539, f1 0.7168000340461731
ep28_l1_test_time 0.3548899200000051
Test Epoch28 layer2 Acc 0.7308, AUC 0.804995059967041, avg_entr 0.04726104065775871, f1 0.7307999730110168
ep28_l2_test_time 0.46252951799999664
Test Epoch28 layer3 Acc 0.7372, AUC 0.8130049705505371, avg_entr 0.04601813852787018, f1 0.7372000217437744
ep28_l3_test_time 0.6146361099999922
Test Epoch28 layer4 Acc 0.74, AUC 0.8209465742111206, avg_entr 0.04271083325147629, f1 0.7400000095367432
ep28_l4_test_time 0.8081898760000286
gc 0
Train Epoch29 Acc 0.957175 (38287/40000), AUC 0.9904509782791138
ep29_train_time 23.01884197100003
Test Epoch29 layer0 Acc 0.697, AUC 0.7637669444084167, avg_entr 0.18114376068115234, f1 0.6970000267028809
ep29_l0_test_time 0.2844815580000386
Test Epoch29 layer1 Acc 0.713, AUC 0.7930135726928711, avg_entr 0.10593341290950775, f1 0.7130000591278076
ep29_l1_test_time 0.3572002269999075
Test Epoch29 layer2 Acc 0.732, AUC 0.8006181716918945, avg_entr 0.05125780776143074, f1 0.7319999933242798
ep29_l2_test_time 0.469013431999997
Test Epoch29 layer3 Acc 0.733, AUC 0.8093475103378296, avg_entr 0.04843705892562866, f1 0.7329999804496765
ep29_l3_test_time 0.6199888940000164
Test Epoch29 layer4 Acc 0.7344, AUC 0.8198543190956116, avg_entr 0.045968007296323776, f1 0.7343999147415161
ep29_l4_test_time 0.8144048650000286
gc 0
Train Epoch30 Acc 0.960225 (38409/40000), AUC 0.9917479753494263
ep30_train_time 23.130418296000016
Test Epoch30 layer0 Acc 0.6984, AUC 0.7629076838493347, avg_entr 0.17906911671161652, f1 0.6984000205993652
ep30_l0_test_time 0.2838863350000338
Test Epoch30 layer1 Acc 0.7198, AUC 0.7939972281455994, avg_entr 0.10012241452932358, f1 0.7197999358177185
ep30_l1_test_time 0.35353285600001527
Test Epoch30 layer2 Acc 0.7306, AUC 0.8058586120605469, avg_entr 0.050593022257089615, f1 0.7305999994277954
ep30_l2_test_time 0.4633418429999665
Test Epoch30 layer3 Acc 0.7366, AUC 0.8136695623397827, avg_entr 0.04933148995041847, f1 0.7365999817848206
ep30_l3_test_time 0.6136260869999433
Test Epoch30 layer4 Acc 0.7414, AUC 0.821779727935791, avg_entr 0.04636143520474434, f1 0.7414000034332275
ep30_l4_test_time 0.8085393729999168
gc 0
Train Epoch31 Acc 0.960075 (38403/40000), AUC 0.991917073726654
ep31_train_time 23.207386713000005
Test Epoch31 layer0 Acc 0.6988, AUC 0.7634710073471069, avg_entr 0.17619019746780396, f1 0.6988000273704529
ep31_l0_test_time 0.2838638919999994
Test Epoch31 layer1 Acc 0.7164, AUC 0.7938807010650635, avg_entr 0.09366060048341751, f1 0.7164000272750854
ep31_l1_test_time 0.35274105899998176
Test Epoch31 layer2 Acc 0.7318, AUC 0.803299605846405, avg_entr 0.048441082239151, f1 0.7318000197410583
ep31_l2_test_time 0.4618232640000315
Test Epoch31 layer3 Acc 0.7362, AUC 0.8124063014984131, avg_entr 0.0474679172039032, f1 0.7361999750137329
ep31_l3_test_time 0.613021222000043
Test Epoch31 layer4 Acc 0.7408, AUC 0.8204889297485352, avg_entr 0.04451450705528259, f1 0.7408000230789185
ep31_l4_test_time 0.8089386689999856
gc 0
Train Epoch32 Acc 0.9615 (38460/40000), AUC 0.9920073747634888
ep32_train_time 23.139886034999904
Test Epoch32 layer0 Acc 0.6978, AUC 0.7619838714599609, avg_entr 0.17674408853054047, f1 0.6977999806404114
ep32_l0_test_time 0.2835047559999566
Test Epoch32 layer1 Acc 0.7164, AUC 0.7915439009666443, avg_entr 0.09251108765602112, f1 0.7164000272750854
ep32_l1_test_time 0.35437025199996697
Test Epoch32 layer2 Acc 0.7324, AUC 0.8028383255004883, avg_entr 0.050718117505311966, f1 0.7323999404907227
ep32_l2_test_time 0.4730452520000199
Test Epoch32 layer3 Acc 0.736, AUC 0.8102759122848511, avg_entr 0.048346247524023056, f1 0.7360000014305115
ep32_l3_test_time 0.6429085449999548
Test Epoch32 layer4 Acc 0.7394, AUC 0.81934654712677, avg_entr 0.04468575119972229, f1 0.7394000291824341
ep32_l4_test_time 0.8225455980000334
gc 0
Train Epoch33 Acc 0.961475 (38459/40000), AUC 0.9920971989631653
ep33_train_time 23.14793674400005
Test Epoch33 layer0 Acc 0.7, AUC 0.762389063835144, avg_entr 0.1747846007347107, f1 0.699999988079071
ep33_l0_test_time 0.2885906960000284
Test Epoch33 layer1 Acc 0.7152, AUC 0.7917567491531372, avg_entr 0.08843423426151276, f1 0.7151999473571777
ep33_l1_test_time 0.3613776309999821
Test Epoch33 layer2 Acc 0.73, AUC 0.8026129007339478, avg_entr 0.045993998646736145, f1 0.7300000190734863
ep33_l2_test_time 0.47239728700003525
Test Epoch33 layer3 Acc 0.7338, AUC 0.8099199533462524, avg_entr 0.0448230504989624, f1 0.7338000535964966
ep33_l3_test_time 0.6202394530000674
Test Epoch33 layer4 Acc 0.7388, AUC 0.8190593719482422, avg_entr 0.040276020765304565, f1 0.7387999892234802
ep33_l4_test_time 0.8159306139999671
gc 0
Train Epoch34 Acc 0.960575 (38423/40000), AUC 0.99208664894104
ep34_train_time 23.127472062000038
Test Epoch34 layer0 Acc 0.7, AUC 0.7623229026794434, avg_entr 0.17560620605945587, f1 0.699999988079071
ep34_l0_test_time 0.2921359270000039
Test Epoch34 layer1 Acc 0.7146, AUC 0.7923630475997925, avg_entr 0.08767027407884598, f1 0.7146000266075134
ep34_l1_test_time 0.3612046380000038
Test Epoch34 layer2 Acc 0.7334, AUC 0.8035385608673096, avg_entr 0.04747619107365608, f1 0.7333999872207642
ep34_l2_test_time 0.47159615999999005
Test Epoch34 layer3 Acc 0.7378, AUC 0.8110203742980957, avg_entr 0.04466782510280609, f1 0.7378000020980835
ep34_l3_test_time 0.6217085989999305
Test Epoch34 layer4 Acc 0.7396, AUC 0.820549488067627, avg_entr 0.04176650196313858, f1 0.7396000027656555
ep34_l4_test_time 0.8171721870000965
gc 0
Train Epoch35 Acc 0.960925 (38437/40000), AUC 0.9924647212028503
ep35_train_time 23.15487491600004
Test Epoch35 layer0 Acc 0.6986, AUC 0.7620757818222046, avg_entr 0.17397207021713257, f1 0.6985999941825867
ep35_l0_test_time 0.29355441300003804
Test Epoch35 layer1 Acc 0.7158, AUC 0.7910201549530029, avg_entr 0.08500780910253525, f1 0.7157999873161316
ep35_l1_test_time 0.3600680030000376
Test Epoch35 layer2 Acc 0.7316, AUC 0.8029601573944092, avg_entr 0.046964675188064575, f1 0.7316000461578369
ep35_l2_test_time 0.46821428700002343
Test Epoch35 layer3 Acc 0.737, AUC 0.809001624584198, avg_entr 0.04308956116437912, f1 0.7369999885559082
ep35_l3_test_time 0.6227824269999473
Test Epoch35 layer4 Acc 0.7384, AUC 0.8192284107208252, avg_entr 0.04060026630759239, f1 0.7384000420570374
ep35_l4_test_time 0.8172218749999729
gc 0
Train Epoch36 Acc 0.9637 (38548/40000), AUC 0.9927266836166382
ep36_train_time 23.149465704000022
Test Epoch36 layer0 Acc 0.698, AUC 0.7619351148605347, avg_entr 0.17586511373519897, f1 0.6980000138282776
ep36_l0_test_time 0.2936768890000394
Test Epoch36 layer1 Acc 0.7156, AUC 0.7907207012176514, avg_entr 0.08459801226854324, f1 0.7155999541282654
ep36_l1_test_time 0.3618104160000257
Test Epoch36 layer2 Acc 0.731, AUC 0.8019795417785645, avg_entr 0.0453597828745842, f1 0.7310000061988831
ep36_l2_test_time 0.47163425300004747
Test Epoch36 layer3 Acc 0.7372, AUC 0.808373212814331, avg_entr 0.0424482561647892, f1 0.7372000217437744
ep36_l3_test_time 0.6196914279998964
Test Epoch36 layer4 Acc 0.7408, AUC 0.8183295130729675, avg_entr 0.03914615511894226, f1 0.7408000230789185
ep36_l4_test_time 0.8153082020000966
gc 0
Train Epoch37 Acc 0.962475 (38499/40000), AUC 0.9925315380096436
ep37_train_time 23.146217438999997
Test Epoch37 layer0 Acc 0.6974, AUC 0.7620104551315308, avg_entr 0.17566817998886108, f1 0.6973999738693237
ep37_l0_test_time 0.289793732000021
Test Epoch37 layer1 Acc 0.715, AUC 0.7905165553092957, avg_entr 0.08351373672485352, f1 0.7150000333786011
ep37_l1_test_time 0.3634777029999441
Test Epoch37 layer2 Acc 0.7304, AUC 0.802619993686676, avg_entr 0.045352112501859665, f1 0.7304000854492188
ep37_l2_test_time 0.47043532299994695
Test Epoch37 layer3 Acc 0.7362, AUC 0.8086999654769897, avg_entr 0.04239073023200035, f1 0.7361999750137329
ep37_l3_test_time 0.6208405940000148
Test Epoch37 layer4 Acc 0.738, AUC 0.8187355995178223, avg_entr 0.040717560797929764, f1 0.7379999160766602
ep37_l4_test_time 0.8207600739999634
gc 0
Train Epoch38 Acc 0.963625 (38545/40000), AUC 0.9930522441864014
ep38_train_time 23.22534460999998
Test Epoch38 layer0 Acc 0.6992, AUC 0.7619850635528564, avg_entr 0.17404362559318542, f1 0.6991999745368958
ep38_l0_test_time 0.28833741699986604
Test Epoch38 layer1 Acc 0.714, AUC 0.7909491062164307, avg_entr 0.0824752226471901, f1 0.7139999866485596
ep38_l1_test_time 0.3651991080000698
Test Epoch38 layer2 Acc 0.731, AUC 0.8035488128662109, avg_entr 0.045898064970970154, f1 0.7310000061988831
ep38_l2_test_time 0.46947541499980616
Test Epoch38 layer3 Acc 0.7362, AUC 0.8100115060806274, avg_entr 0.043761540204286575, f1 0.7361999750137329
ep38_l3_test_time 0.6202376579999509
Test Epoch38 layer4 Acc 0.7408, AUC 0.81931471824646, avg_entr 0.04003211855888367, f1 0.7408000230789185
ep38_l4_test_time 0.8166196189999937
gc 0
Train Epoch39 Acc 0.96345 (38538/40000), AUC 0.9928481578826904
ep39_train_time 23.140191226999832
Test Epoch39 layer0 Acc 0.6976, AUC 0.7619143724441528, avg_entr 0.17417453229427338, f1 0.6976000070571899
ep39_l0_test_time 0.288502268000002
Test Epoch39 layer1 Acc 0.7154, AUC 0.7900609970092773, avg_entr 0.08170939981937408, f1 0.715399980545044
ep39_l1_test_time 0.35866460900001584
Test Epoch39 layer2 Acc 0.7304, AUC 0.8020973801612854, avg_entr 0.044877879321575165, f1 0.7304000854492188
ep39_l2_test_time 0.47002871299991966
Test Epoch39 layer3 Acc 0.7362, AUC 0.8089231848716736, avg_entr 0.04210595041513443, f1 0.7361999750137329
ep39_l3_test_time 0.6244070630000351
Test Epoch39 layer4 Acc 0.739, AUC 0.8186155557632446, avg_entr 0.03948010876774788, f1 0.7390000820159912
ep39_l4_test_time 0.816041685999835
gc 0
Train Epoch40 Acc 0.9635 (38540/40000), AUC 0.9932010173797607
ep40_train_time 23.182500226000002
Test Epoch40 layer0 Acc 0.6982, AUC 0.7621403336524963, avg_entr 0.17397060990333557, f1 0.698199987411499
ep40_l0_test_time 0.2919093210000483
Test Epoch40 layer1 Acc 0.7154, AUC 0.7900069952011108, avg_entr 0.08042651414871216, f1 0.715399980545044
ep40_l1_test_time 0.36074596599996767
Test Epoch40 layer2 Acc 0.7312, AUC 0.8017247915267944, avg_entr 0.04441101849079132, f1 0.7311999797821045
ep40_l2_test_time 0.4738281709999228
Test Epoch40 layer3 Acc 0.7354, AUC 0.8085055351257324, avg_entr 0.04178890213370323, f1 0.7354000210762024
ep40_l3_test_time 0.6208907549998912
Test Epoch40 layer4 Acc 0.738, AUC 0.8182079792022705, avg_entr 0.03885063901543617, f1 0.7379999160766602
ep40_l4_test_time 0.8187944769999831
gc 0
Train Epoch41 Acc 0.963925 (38557/40000), AUC 0.9926291108131409
ep41_train_time 23.14831725099998
Test Epoch41 layer0 Acc 0.698, AUC 0.7620735168457031, avg_entr 0.1737491488456726, f1 0.6980000138282776
ep41_l0_test_time 0.28809666100005416
Test Epoch41 layer1 Acc 0.7154, AUC 0.7897737622261047, avg_entr 0.0801670178771019, f1 0.715399980545044
ep41_l1_test_time 0.3591365519998817
Test Epoch41 layer2 Acc 0.7304, AUC 0.8012230396270752, avg_entr 0.044587720185518265, f1 0.7304000854492188
ep41_l2_test_time 0.4682262209998953
Test Epoch41 layer3 Acc 0.736, AUC 0.8078323602676392, avg_entr 0.04143907502293587, f1 0.7360000014305115
ep41_l3_test_time 0.6204062910001085
Test Epoch41 layer4 Acc 0.7368, AUC 0.8179454207420349, avg_entr 0.039026111364364624, f1 0.7368000149726868
ep41_l4_test_time 0.8181036139999378
gc 0
Train Epoch42 Acc 0.9641 (38564/40000), AUC 0.9927269220352173
ep42_train_time 23.142805023999927
Test Epoch42 layer0 Acc 0.699, AUC 0.7620388269424438, avg_entr 0.17342664301395416, f1 0.6990000009536743
ep42_l0_test_time 0.28878830700000435
Test Epoch42 layer1 Acc 0.7144, AUC 0.7900182008743286, avg_entr 0.07981286197900772, f1 0.7143999934196472
ep42_l1_test_time 0.3589937239999017
Test Epoch42 layer2 Acc 0.7308, AUC 0.8026320934295654, avg_entr 0.04489865154027939, f1 0.7307999730110168
ep42_l2_test_time 0.4757452200001353
Test Epoch42 layer3 Acc 0.7362, AUC 0.8094773292541504, avg_entr 0.043163053691387177, f1 0.7361999750137329
ep42_l3_test_time 0.6205559909999465
Test Epoch42 layer4 Acc 0.7402, AUC 0.8185869455337524, avg_entr 0.03945741802453995, f1 0.7401999831199646
ep42_l4_test_time 0.8150872129999698
gc 0
Train Epoch43 Acc 0.963275 (38531/40000), AUC 0.9933812618255615
ep43_train_time 23.14912418499989
Test Epoch43 layer0 Acc 0.698, AUC 0.7620677947998047, avg_entr 0.1742306798696518, f1 0.6980000138282776
ep43_l0_test_time 0.29707927599997674
Test Epoch43 layer1 Acc 0.7162, AUC 0.7902886867523193, avg_entr 0.0802152007818222, f1 0.7161999940872192
ep43_l1_test_time 0.3601466850000179
Test Epoch43 layer2 Acc 0.7314, AUC 0.802610456943512, avg_entr 0.04610170051455498, f1 0.7314000129699707
ep43_l2_test_time 0.46874320000006264
Test Epoch43 layer3 Acc 0.7364, AUC 0.8096883893013, avg_entr 0.04297567903995514, f1 0.7364000082015991
ep43_l3_test_time 0.6193839879999814
Test Epoch43 layer4 Acc 0.7392, AUC 0.8191496133804321, avg_entr 0.04037408158183098, f1 0.7391999959945679
ep43_l4_test_time 0.8159723079998003
gc 0
Train Epoch44 Acc 0.964975 (38599/40000), AUC 0.9933469295501709
ep44_train_time 23.154615163000017
Test Epoch44 layer0 Acc 0.6994, AUC 0.7620289325714111, avg_entr 0.17335575819015503, f1 0.699400007724762
ep44_l0_test_time 0.28830122499994104
Test Epoch44 layer1 Acc 0.716, AUC 0.7902684211730957, avg_entr 0.0793762356042862, f1 0.7160000205039978
ep44_l1_test_time 0.37190237400000115
Test Epoch44 layer2 Acc 0.7324, AUC 0.8028801083564758, avg_entr 0.045660149306058884, f1 0.7323999404907227
ep44_l2_test_time 0.46940011700007744
Test Epoch44 layer3 Acc 0.7368, AUC 0.8099112510681152, avg_entr 0.04340575635433197, f1 0.7368000149726868
ep44_l3_test_time 0.6207782660001158
Test Epoch44 layer4 Acc 0.7402, AUC 0.8189752101898193, avg_entr 0.03962846100330353, f1 0.7401999831199646
ep44_l4_test_time 0.8151979340000253
gc 0
Train Epoch45 Acc 0.9645 (38580/40000), AUC 0.9930765628814697
ep45_train_time 23.167225766
Test Epoch45 layer0 Acc 0.7, AUC 0.7620539665222168, avg_entr 0.17328299582004547, f1 0.699999988079071
ep45_l0_test_time 0.29282377599997744
Test Epoch45 layer1 Acc 0.716, AUC 0.7900658845901489, avg_entr 0.07904352247714996, f1 0.7160000205039978
ep45_l1_test_time 0.3592782119999356
Test Epoch45 layer2 Acc 0.732, AUC 0.8022987246513367, avg_entr 0.0454481802880764, f1 0.7319999933242798
ep45_l2_test_time 0.46944090800002414
Test Epoch45 layer3 Acc 0.7366, AUC 0.8092919588088989, avg_entr 0.04272305220365524, f1 0.7365999817848206
ep45_l3_test_time 0.6196441260001393
Test Epoch45 layer4 Acc 0.7394, AUC 0.8185650110244751, avg_entr 0.039158500730991364, f1 0.7394000291824341
ep45_l4_test_time 0.8186332610000591
gc 0
Train Epoch46 Acc 0.96475 (38590/40000), AUC 0.993350625038147
ep46_train_time 23.168846513000062
Test Epoch46 layer0 Acc 0.7, AUC 0.7620227932929993, avg_entr 0.17330224812030792, f1 0.699999988079071
ep46_l0_test_time 0.2894299179999962
Test Epoch46 layer1 Acc 0.7164, AUC 0.7898622155189514, avg_entr 0.07898301631212234, f1 0.7164000272750854
ep46_l1_test_time 0.3606752079999751
Test Epoch46 layer2 Acc 0.732, AUC 0.8019956350326538, avg_entr 0.04559789225459099, f1 0.7319999933242798
ep46_l2_test_time 0.4690395959999023
Test Epoch46 layer3 Acc 0.7358, AUC 0.8089746236801147, avg_entr 0.04254798963665962, f1 0.73580002784729
ep46_l3_test_time 0.6213848970000981
Test Epoch46 layer4 Acc 0.7388, AUC 0.8183431625366211, avg_entr 0.03914521634578705, f1 0.7387999892234802
ep46_l4_test_time 0.8268266130000939
gc 0
Train Epoch47 Acc 0.963975 (38559/40000), AUC 0.9930204749107361
ep47_train_time 23.214917352000157
Test Epoch47 layer0 Acc 0.698, AUC 0.7620037198066711, avg_entr 0.1734946221113205, f1 0.6980000138282776
ep47_l0_test_time 0.2943512910001118
Test Epoch47 layer1 Acc 0.7158, AUC 0.7897464036941528, avg_entr 0.07888966798782349, f1 0.7157999873161316
ep47_l1_test_time 0.35959719599986784
Test Epoch47 layer2 Acc 0.7306, AUC 0.8019864559173584, avg_entr 0.04573918506503105, f1 0.7305999994277954
ep47_l2_test_time 0.4704769679999572
Test Epoch47 layer3 Acc 0.736, AUC 0.8089098930358887, avg_entr 0.04246702045202255, f1 0.7360000014305115
ep47_l3_test_time 0.6210256130000289
Test Epoch47 layer4 Acc 0.7388, AUC 0.8184272646903992, avg_entr 0.03968968614935875, f1 0.7387999892234802
ep47_l4_test_time 0.8167553890000363
gc 0
Train Epoch48 Acc 0.9638 (38552/40000), AUC 0.9928195476531982
ep48_train_time 23.18880769800012
Test Epoch48 layer0 Acc 0.6982, AUC 0.7620434761047363, avg_entr 0.17330484092235565, f1 0.698199987411499
ep48_l0_test_time 0.29045307599994885
Test Epoch48 layer1 Acc 0.7164, AUC 0.7898211479187012, avg_entr 0.07847870886325836, f1 0.7164000272750854
ep48_l1_test_time 0.3585748049999893
Test Epoch48 layer2 Acc 0.731, AUC 0.8022058010101318, avg_entr 0.045401424169540405, f1 0.7310000061988831
ep48_l2_test_time 0.4696680480001305
Test Epoch48 layer3 Acc 0.7362, AUC 0.8091586828231812, avg_entr 0.04255857691168785, f1 0.7361999750137329
ep48_l3_test_time 0.6269030809999094
Test Epoch48 layer4 Acc 0.7384, AUC 0.8184964656829834, avg_entr 0.03975079208612442, f1 0.7384000420570374
ep48_l4_test_time 0.8180029830000421
gc 0
Train Epoch49 Acc 0.964 (38560/40000), AUC 0.9928845167160034
ep49_train_time 23.17225026899996
Test Epoch49 layer0 Acc 0.6998, AUC 0.7620654106140137, avg_entr 0.17276960611343384, f1 0.6998000144958496
ep49_l0_test_time 0.2896699699999772
Test Epoch49 layer1 Acc 0.7162, AUC 0.7900238037109375, avg_entr 0.07820146530866623, f1 0.7161999940872192
ep49_l1_test_time 0.37248789399995985
Test Epoch49 layer2 Acc 0.731, AUC 0.8025645017623901, avg_entr 0.04455236345529556, f1 0.7310000061988831
ep49_l2_test_time 0.4702023380000355
Test Epoch49 layer3 Acc 0.7366, AUC 0.8093270063400269, avg_entr 0.04268048703670502, f1 0.7365999817848206
ep49_l3_test_time 0.6208903470001133
Test Epoch49 layer4 Acc 0.7398, AUC 0.8185831308364868, avg_entr 0.03915969654917717, f1 0.7398000359535217
ep49_l4_test_time 0.8165553000001182
Best AUC tensor(0.7626) 14 4
train_as_loss [[8.58128144e+01 5.88130941e+01 5.20862987e+01 5.04803652e+01
  4.99052205e+01 4.96390070e+01 4.94949203e+01 4.94084044e+01
  4.93525075e+01 4.93143677e+01 4.92872179e+01 4.92672366e+01
  4.92521275e+01 4.92404387e+01 4.92312284e+01 4.92238506e+01
  4.92178597e+01 4.92140377e+01 4.92117253e+01 4.92095428e+01
  4.92074918e+01 4.92060252e+01 4.92050587e+01 4.92040911e+01
  4.92031239e+01 4.92023981e+01 4.92019007e+01 4.92013869e+01
  4.92008598e+01 4.92004521e+01 4.92001656e+01 4.91998676e+01
  4.91995544e+01 4.91993079e+01 4.91991334e+01 4.91989518e+01
  4.91987561e+01 4.91986009e+01 4.91984887e+01 4.91983728e+01
  4.91982495e+01 4.91981502e+01 4.91980805e+01 4.91980029e+01
  4.91979187e+01 4.91978557e+01 4.91978171e+01 4.91977551e+01
  4.91977057e+01 4.91976705e+01]
 [2.42244436e+00 3.69524010e-04 1.87703765e-05 4.65525464e-06
  1.87173167e-06 9.20115220e-07 4.95038411e-07 3.00035720e-07
  1.80395082e-07 1.21307917e-07 8.04466222e-08 5.53719914e-08
  3.91321289e-08 3.04971281e-08 2.17905875e-08 1.60242274e-08
  5.16585303e-08 1.17130941e-08 8.12559837e-09 7.30297270e-09
  2.59593351e-08 5.81460373e-09 4.82672588e-09 4.61265756e-09
  1.71741516e-08 3.98203466e-09 3.67591667e-09 3.53309756e-09
  1.38038126e-08 3.19294625e-09 2.98965137e-09 2.89827088e-09
  1.15470479e-08 2.73773219e-09 2.64335659e-09 2.58183921e-09
  1.00961272e-08 2.54892887e-09 2.41604951e-09 2.36307097e-09
  8.99864062e-09 2.47702518e-09 2.25019574e-09 2.20029312e-09
  8.13789910e-09 2.55882863e-09 2.16386238e-09 2.10232681e-09
  7.21953556e-09 2.78341491e-09]
 [2.29086275e+00 2.40222214e-04 1.47728710e-05 4.00614775e-06
  1.71089998e-06 8.80695511e-07 4.67317687e-07 2.93998556e-07
  1.71800897e-07 1.19662585e-07 7.72918633e-08 5.39594942e-08
  3.80344182e-08 3.35878416e-08 2.28801185e-08 1.66827554e-08
  1.70205839e-08 7.51162738e-09 7.90288277e-09 6.80370494e-09
  6.73753344e-09 2.71693371e-09 4.31524697e-09 3.88820195e-09
  3.72244309e-09 1.37491056e-09 3.13008083e-09 2.84852494e-09
  2.91034036e-09 8.59914757e-10 2.41064308e-09 2.24581111e-09
  2.35357139e-09 6.42419624e-10 2.08335995e-09 1.97275863e-09
  1.95984448e-09 5.39842355e-10 1.88413718e-09 1.80569812e-09
  1.75224214e-09 5.00213367e-10 1.71259293e-09 1.68755478e-09
  1.64058042e-09 5.02288510e-10 1.61859220e-09 1.64394011e-09
  1.56997910e-09 5.17179993e-10]
 [1.79841174e+00 4.80608616e-04 1.92031259e-05 5.60212450e-06
  2.56256840e-06 1.41510094e-06 7.32517202e-07 4.85558796e-07
  2.88500918e-07 2.09892990e-07 1.33199175e-07 9.67039378e-08
  6.98128465e-08 7.12884101e-08 4.87991107e-08 3.51001705e-08
  8.46638640e-08 3.04394438e-08 1.27901389e-08 1.26622734e-08
  3.50406900e-08 1.10955560e-08 6.65394646e-09 6.30729256e-09
  2.06432824e-08 6.14684625e-09 4.49099828e-09 4.30294528e-09
  1.60698690e-08 4.29305753e-09 3.44222098e-09 3.38235183e-09
  1.29295637e-08 3.50610517e-09 2.98756406e-09 2.94314909e-09
  1.09435907e-08 3.28209706e-09 2.74761179e-09 2.65956179e-09
  9.53580215e-09 3.28590470e-09 2.49290566e-09 2.47629015e-09
  8.33515745e-09 3.48512227e-09 2.42549807e-09 2.34252862e-09
  7.31361626e-09 3.68056239e-09]
 [2.44787801e+00 1.37034548e-03 2.42344540e-05 7.12732781e-06
  3.37722300e-06 2.05657861e-06 1.08359102e-06 7.97065552e-07
  4.54663115e-07 3.56891130e-07 2.16928198e-07 1.82426537e-07
  1.27741368e-07 1.83366808e-07 1.19842771e-07 9.22350553e-08
  1.32334225e-07 9.31427211e-08 2.28963451e-08 2.73548840e-08
  2.78253540e-08 2.14596386e-08 1.00321763e-08 9.96845490e-09
  9.69094631e-09 6.97129538e-09 5.83359487e-09 5.68399654e-09
  6.55339565e-09 2.77332445e-09 4.10165791e-09 3.93482274e-09
  4.42109818e-09 1.59911170e-09 3.46210237e-09 3.36188125e-09
  3.34289596e-09 1.12011074e-09 3.04285622e-09 2.98958737e-09
  2.88447991e-09 9.78912111e-10 2.65967227e-09 2.76922349e-09
  2.61783660e-09 9.74284608e-10 2.40880228e-09 2.60304318e-09
  2.41791982e-09 9.94711070e-10]]
train_ae_loss [[4.95870534 3.49269983 4.79724435 5.45703672 5.85221739 6.09307955
  6.20310127 6.38590696 6.42024779 6.36385415 6.28868927 6.22893399
  6.0824189  5.88804524 5.69803667 5.49011147 5.31012881 4.85072111
  4.63475877 4.44355229 4.34201519 4.13193775 4.02267645 3.94556131
  3.91902222 3.80948236 3.75664288 3.73333921 3.71546455 3.6597904
  3.63806722 3.61711962 3.61237321 3.58096857 3.58491625 3.57370638
  3.56258356 3.56616809 3.51709776 3.51229294 3.54272476 3.50937746
  3.5437597  3.52685621 3.53476242 3.5362211  3.54335863 3.54598135
  3.54400809 3.55092267]
 [3.61512453 3.3106859  4.65169919 5.20525346 5.4050855  5.5272802
  5.54701753 5.66862626 5.57057114 5.5084218  5.36475256 5.30855891
  5.13790862 4.93450039 4.73402333 4.49753548 4.15947537 3.9136956
  3.66038024 3.4517765  3.25316286 3.10328162 2.9636544  2.87546921
  2.75133017 2.67967567 2.53913727 2.50248179 2.37066992 2.33582303
  2.25874693 2.20830552 2.17411882 2.1225339  2.11191893 2.08741516
  2.05705523 2.06452539 2.01730948 2.00729944 2.01646586 1.98734835
  2.02017156 2.01752921 1.99569666 2.0028286  2.00101977 2.01578972
  2.01238787 2.00471438]
 [3.74840575 3.0112745  4.35612495 4.95415634 4.95806648 4.99177025
  4.99021536 5.11724691 4.94794134 4.91799265 4.73226699 4.68998115
  4.50298031 4.28891105 4.06988681 3.82395682 3.46026066 3.47544553
  2.62754866 2.38245792 2.15657769 2.03539384 1.84307764 1.7786256
  1.69471725 1.67622263 1.53450489 1.5564226  1.46792615 1.49046138
  1.42068885 1.39745784 1.39401136 1.34424409 1.34494756 1.32052158
  1.31314114 1.3246463  1.2926484  1.28594082 1.29228564 1.25775871
  1.29443655 1.2921376  1.28912415 1.28466374 1.27898305 1.29947524
  1.2883211  1.28862197]
 [4.20838102 2.97293107 4.27383584 4.97277328 4.9360459  4.79803541
  4.7217198  4.80284925 4.54416435 4.53962303 4.27703146 4.21980722
  4.00572998 3.72873179 3.39845082 3.13694104 2.74658406 2.79040367
  2.24226288 2.03565873 1.82267148 1.71531226 1.56413262 1.50363051
  1.4239972  1.40488509 1.29144275 1.31154209 1.22390964 1.2437759
  1.19364462 1.17327721 1.16358645 1.12043514 1.1202277  1.10088275
  1.08897606 1.10052927 1.07916442 1.0719461  1.08003572 1.04725867
  1.08029024 1.07780516 1.06865971 1.06830861 1.06801343 1.08355177
  1.07426756 1.0709339 ]
 [4.64711135 2.68074133 3.85142264 4.76448969 4.82230745 4.67366642
  4.53121699 4.58356037 4.28654383 4.32032115 3.95457102 3.84414871
  3.59182516 3.34099674 3.07974961 2.84586145 2.55339581 2.78322352
  2.01873667 1.82521121 1.63656304 1.56319201 1.39435433 1.33529092
  1.2697421  1.26618007 1.14530142 1.16343134 1.08225077 1.10638665
  1.05384317 1.03650063 1.02528784 0.98703066 0.9887077  0.96871098
  0.95518642 0.96758735 0.94859218 0.93986941 0.95170684 0.91780063
  0.94883771 0.9435382  0.93203994 0.93512642 0.93759512 0.95169756
  0.94197023 0.93956945]]
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
total_train+valid_time 1290.949656253
Start Testing
Load ckpt at ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt
gc 9
Test layer0 Acc 0.7062, AUC 0.7871266603469849, avg_entr 0.24196654558181763, f1 0.7062000036239624
l0_test_time 0.28749908999998297
gc 0
Test layer1 Acc 0.7384, AUC 0.8299804925918579, avg_entr 0.205370232462883, f1 0.7384000420570374
l1_test_time 0.359801028999982
gc 0
Test layer2 Acc 0.7506, AUC 0.8448953628540039, avg_entr 0.18833866715431213, f1 0.7505999803543091
l2_test_time 0.46974164499988547
gc 0
Test layer3 Acc 0.7586, AUC 0.8527402877807617, avg_entr 0.12836475670337677, f1 0.7585999965667725
l3_test_time 0.6282814240000789
gc 0
Test layer4 Acc 0.7632, AUC 0.8553334474563599, avg_entr 0.12403791397809982, f1 0.7631999850273132
l4_test_time 0.8156339490001301
gc 0
Test threshold 0.1 Acc 0.7614, AUC 0.8330867290496826, avg_entr 0.17723146080970764, f1 0.7613999843597412
t0.1_test_time 0.5901031840000996
gc 0
Test threshold 0.2 Acc 0.7574, AUC 0.8269467353820801, avg_entr 0.18228638172149658, f1 0.7573999762535095
t0.2_test_time 0.5331030820000251
gc 0
Test threshold 0.3 Acc 0.7528, AUC 0.8194308876991272, avg_entr 0.19223903119564056, f1 0.7528000473976135
t0.3_test_time 0.49413275500000964
gc 0
Test threshold 0.4 Acc 0.753, AUC 0.8162523508071899, avg_entr 0.20322927832603455, f1 0.753000020980835
t0.4_test_time 0.4719998730001862
gc 0
Test threshold 0.5 Acc 0.7462, AUC 0.8104516863822937, avg_entr 0.2168208509683609, f1 0.7462000250816345
t0.5_test_time 0.4368240799999512
gc 0
Test threshold 0.6 Acc 0.7426, AUC 0.8049788475036621, avg_entr 0.23392745852470398, f1 0.7426000237464905
t0.6_test_time 0.41268503899982534
gc 0
Test threshold 0.7 Acc 0.738, AUC 0.8036138415336609, avg_entr 0.24936193227767944, f1 0.7379999160766602
t0.7_test_time 0.3911165810000057
gc 0
Test threshold 0.8 Acc 0.7318, AUC 0.8004798889160156, avg_entr 0.26844197511672974, f1 0.7318000197410583
t0.8_test_time 0.3845390869998937
gc 0
Test threshold 0.9 Acc 0.7246, AUC 0.7969732284545898, avg_entr 0.29524415731430054, f1 0.7245999574661255
t0.9_test_time 0.3676003639998271
