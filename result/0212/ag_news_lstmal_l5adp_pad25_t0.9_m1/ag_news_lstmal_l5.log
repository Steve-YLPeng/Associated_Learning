total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.2518166666666667 (30218/120000), AUC 0.5154722929000854
ep0_train_time 10.184921264648438
Test Epoch0 threshold 0.9 Acc 0.9110197368421052, AUC 0.9795123934745789, avg_entr 0.15250565111637115
ep0_t0.9_test_time 0.07385730743408203
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.9_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.255 (30600/120000), AUC 0.5205317735671997
ep1_train_time 9.98729920387268
Test Epoch1 threshold 0.9 Acc 0.9139802631578947, AUC 0.9808169603347778, avg_entr 0.09669514745473862
ep1_t0.9_test_time 0.07347297668457031
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.9_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.2557833333333333 (30694/120000), AUC 0.5210704207420349
ep2_train_time 10.069604396820068
Test Epoch2 threshold 0.9 Acc 0.9136513157894737, AUC 0.9808672666549683, avg_entr 0.07626349478960037
ep2_t0.9_test_time 0.072265625
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.9_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.25640833333333335 (30769/120000), AUC 0.521857500076294
ep3_train_time 10.160276412963867
Test Epoch3 threshold 0.9 Acc 0.912828947368421, AUC 0.9806835055351257, avg_entr 0.06570982933044434
ep3_t0.9_test_time 0.0728909969329834
gc 0
Train Epoch4 Acc 0.25680833333333336 (30817/120000), AUC 0.5226359367370605
ep4_train_time 9.990913391113281
Test Epoch4 threshold 0.9 Acc 0.9139802631578947, AUC 0.9808018207550049, avg_entr 0.05950397253036499
ep4_t0.9_test_time 0.07293200492858887
gc 0
Train Epoch5 Acc 0.25766666666666665 (30920/120000), AUC 0.5235825777053833
ep5_train_time 10.030105829238892
Test Epoch5 threshold 0.9 Acc 0.9133223684210526, AUC 0.9801647067070007, avg_entr 0.053626179695129395
ep5_t0.9_test_time 0.07298684120178223
gc 0
Train Epoch6 Acc 0.2579 (30948/120000), AUC 0.5242501497268677
ep6_train_time 10.026220560073853
Test Epoch6 threshold 0.9 Acc 0.9120065789473685, AUC 0.9800881147384644, avg_entr 0.050963420420885086
ep6_t0.9_test_time 0.07250833511352539
gc 0
Train Epoch7 Acc 0.2577583333333333 (30931/120000), AUC 0.5242601037025452
ep7_train_time 9.988161087036133
Test Epoch7 threshold 0.9 Acc 0.912828947368421, AUC 0.9798922538757324, avg_entr 0.04868173971772194
ep7_t0.9_test_time 0.07191824913024902
gc 0
Train Epoch8 Acc 0.25810833333333333 (30973/120000), AUC 0.524468719959259
ep8_train_time 10.029252529144287
Test Epoch8 threshold 0.9 Acc 0.9120065789473685, AUC 0.9795643091201782, avg_entr 0.046213191002607346
ep8_t0.9_test_time 0.0732107162475586
gc 0
Train Epoch9 Acc 0.258425 (31011/120000), AUC 0.5247883796691895
ep9_train_time 10.05966329574585
Test Epoch9 threshold 0.9 Acc 0.9125, AUC 0.9795048832893372, avg_entr 0.044007156044244766
ep9_t0.9_test_time 0.07305908203125
Best AUC 0.9808672666549683
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adp_pad25_t0.9_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.9 Acc 0.9184210526315789, AUC 0.9856007099151611, avg_entr 0.08041989058256149
t0.9_test_time 0.020727157592773438
