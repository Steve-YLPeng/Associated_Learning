total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.24699166666666666 (29639/120000), AUC 0.5064339637756348
ep0_train_time 9.958993673324585
Test Epoch0 threshold 0.3 Acc 0.9087171052631579, AUC 0.9794919490814209, avg_entr 0.14778216183185577
ep0_t0.3_test_time 0.07429313659667969
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.3_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.24189166666666667 (29027/120000), AUC 0.5075908899307251
ep1_train_time 9.920289993286133
Test Epoch1 threshold 0.3 Acc 0.9113486842105263, AUC 0.9805636405944824, avg_entr 0.09321872144937515
ep1_t0.3_test_time 0.07206249237060547
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.3_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.24101666666666666 (28922/120000), AUC 0.5070446133613586
ep2_train_time 9.92805004119873
Test Epoch2 threshold 0.3 Acc 0.9115131578947369, AUC 0.9809489846229553, avg_entr 0.07507289201021194
ep2_t0.3_test_time 0.07236003875732422
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.3_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.24018333333333333 (28822/120000), AUC 0.5065869688987732
ep3_train_time 9.80347490310669
Test Epoch3 threshold 0.3 Acc 0.9126644736842106, AUC 0.9803725481033325, avg_entr 0.0637325644493103
ep3_t0.3_test_time 0.07324719429016113
gc 0
Train Epoch4 Acc 0.23923333333333333 (28708/120000), AUC 0.5063271522521973
ep4_train_time 10.004794836044312
Test Epoch4 threshold 0.3 Acc 0.9131578947368421, AUC 0.9805002212524414, avg_entr 0.05746632441878319
ep4_t0.3_test_time 0.07199883460998535
gc 0
Train Epoch5 Acc 0.238075 (28569/120000), AUC 0.5060034394264221
ep5_train_time 9.75706696510315
Test Epoch5 threshold 0.3 Acc 0.9123355263157895, AUC 0.979916512966156, avg_entr 0.05247044935822487
ep5_t0.3_test_time 0.07204055786132812
gc 0
Train Epoch6 Acc 0.23689166666666667 (28427/120000), AUC 0.5056136846542358
ep6_train_time 10.16859745979309
Test Epoch6 threshold 0.3 Acc 0.9139802631578947, AUC 0.9801634550094604, avg_entr 0.04872851446270943
ep6_t0.3_test_time 0.07211971282958984
gc 0
Train Epoch7 Acc 0.23660833333333334 (28393/120000), AUC 0.5055503845214844
ep7_train_time 9.823130130767822
Test Epoch7 threshold 0.3 Acc 0.9121710526315789, AUC 0.9799759387969971, avg_entr 0.04679948836565018
ep7_t0.3_test_time 0.07200956344604492
gc 0
Train Epoch8 Acc 0.23650833333333332 (28381/120000), AUC 0.5053826570510864
ep8_train_time 9.928081035614014
Test Epoch8 threshold 0.3 Acc 0.9106907894736842, AUC 0.9795223474502563, avg_entr 0.04505907744169235
ep8_t0.3_test_time 0.0720217227935791
gc 0
Train Epoch9 Acc 0.23615 (28338/120000), AUC 0.5052297115325928
ep9_train_time 10.177963733673096
Test Epoch9 threshold 0.3 Acc 0.9106907894736842, AUC 0.9792623519897461, avg_entr 0.043092917650938034
ep9_t0.3_test_time 0.07214045524597168
Best AUC 0.9809489846229553
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad25_t0.3_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.3 Acc 0.9197368421052632, AUC 0.9848552942276001, avg_entr 0.07977672666311264
t0.3_test_time 0.01892685890197754
