total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.2502 (30024/120000), AUC 0.5533398985862732
ep0_train_time 10.139112949371338
Test Epoch0 threshold 0.1 Acc 0.9115131578947369, AUC 0.9793708324432373, avg_entr 0.14812667667865753
ep0_t0.1_test_time 0.07479238510131836
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.2506333333333333 (30076/120000), AUC 0.5798649191856384
ep1_train_time 9.971533060073853
Test Epoch1 threshold 0.1 Acc 0.9134868421052632, AUC 0.9813074469566345, avg_entr 0.0947313979268074
ep1_t0.1_test_time 0.07192277908325195
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.25114166666666665 (30137/120000), AUC 0.5846737623214722
ep2_train_time 9.797727108001709
Test Epoch2 threshold 0.1 Acc 0.9143092105263158, AUC 0.9808563590049744, avg_entr 0.07479827105998993
ep2_t0.1_test_time 0.0729837417602539
gc 0
Train Epoch3 Acc 0.251675 (30201/120000), AUC 0.5877524018287659
ep3_train_time 10.01249623298645
Test Epoch3 threshold 0.1 Acc 0.9134868421052632, AUC 0.9808491468429565, avg_entr 0.06346207857131958
ep3_t0.1_test_time 0.0714101791381836
gc 0
Train Epoch4 Acc 0.252325 (30279/120000), AUC 0.5903253555297852
ep4_train_time 10.024504899978638
Test Epoch4 threshold 0.1 Acc 0.9136513157894737, AUC 0.9803243279457092, avg_entr 0.05802111700177193
ep4_t0.1_test_time 0.07280898094177246
gc 0
Train Epoch5 Acc 0.252975 (30357/120000), AUC 0.5927322506904602
ep5_train_time 10.039445638656616
Test Epoch5 threshold 0.1 Acc 0.912828947368421, AUC 0.98030686378479, avg_entr 0.05323100835084915
ep5_t0.1_test_time 0.07086968421936035
gc 0
Train Epoch6 Acc 0.25343333333333334 (30412/120000), AUC 0.5939889550209045
ep6_train_time 9.827301979064941
Test Epoch6 threshold 0.1 Acc 0.9120065789473685, AUC 0.9801306128501892, avg_entr 0.05091755464673042
ep6_t0.1_test_time 0.07112812995910645
gc 0
Train Epoch7 Acc 0.253775 (30453/120000), AUC 0.5938590168952942
ep7_train_time 9.780896186828613
Test Epoch7 threshold 0.1 Acc 0.9113486842105263, AUC 0.9798177480697632, avg_entr 0.04880261793732643
ep7_t0.1_test_time 0.0715169906616211
gc 0
Train Epoch8 Acc 0.254075 (30489/120000), AUC 0.5937387943267822
ep8_train_time 10.003352403640747
Test Epoch8 threshold 0.1 Acc 0.9103618421052632, AUC 0.979494035243988, avg_entr 0.04596596211194992
ep8_t0.1_test_time 0.07310652732849121
gc 0
Train Epoch9 Acc 0.25454166666666667 (30545/120000), AUC 0.593997597694397
ep9_train_time 10.017837285995483
Test Epoch9 threshold 0.1 Acc 0.9108552631578948, AUC 0.9793605208396912, avg_entr 0.0442190021276474
ep9_t0.1_test_time 0.07175302505493164
Best AUC 0.9813074469566345
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad25_t0.1_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.1 Acc 0.9263157894736842, AUC 0.9856212735176086, avg_entr 0.10032007098197937
t0.1_test_time 0.01880955696105957
