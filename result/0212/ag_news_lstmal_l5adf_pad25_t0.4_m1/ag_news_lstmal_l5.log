total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.24975 (29970/120000), AUC 0.5014419555664062
ep0_train_time 9.941254377365112
Test Epoch0 threshold 0.4 Acc 0.9120065789473685, AUC 0.9795432090759277, avg_entr 0.1491907685995102
ep0_t0.4_test_time 0.07267308235168457
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.249725 (29967/120000), AUC 0.5015451312065125
ep1_train_time 9.940625429153442
Test Epoch1 threshold 0.4 Acc 0.9138157894736842, AUC 0.9809142351150513, avg_entr 0.09425298124551773
ep1_t0.4_test_time 0.07431411743164062
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.24949166666666667 (29939/120000), AUC 0.5012092590332031
ep2_train_time 10.082091808319092
Test Epoch2 threshold 0.4 Acc 0.9121710526315789, AUC 0.9808964133262634, avg_entr 0.07453925162553787
ep2_t0.4_test_time 0.0737910270690918
gc 0
Train Epoch3 Acc 0.24953333333333333 (29944/120000), AUC 0.5014445185661316
ep3_train_time 9.954175472259521
Test Epoch3 threshold 0.4 Acc 0.9136513157894737, AUC 0.9803301692008972, avg_entr 0.06533303111791611
ep3_t0.4_test_time 0.07210683822631836
gc 0
Train Epoch4 Acc 0.24951666666666666 (29942/120000), AUC 0.5014283657073975
ep4_train_time 10.007897853851318
Test Epoch4 threshold 0.4 Acc 0.9111842105263158, AUC 0.9805487394332886, avg_entr 0.05831952020525932
ep4_t0.4_test_time 0.07159876823425293
gc 0
Train Epoch5 Acc 0.24955 (29946/120000), AUC 0.501487672328949
ep5_train_time 10.036514043807983
Test Epoch5 threshold 0.4 Acc 0.9134868421052632, AUC 0.980049729347229, avg_entr 0.05399876460433006
ep5_t0.4_test_time 0.07218313217163086
gc 0
Train Epoch6 Acc 0.249475 (29937/120000), AUC 0.5015215277671814
ep6_train_time 9.93790316581726
Test Epoch6 threshold 0.4 Acc 0.9101973684210526, AUC 0.9799550771713257, avg_entr 0.05071832612156868
ep6_t0.4_test_time 0.07217526435852051
gc 0
Train Epoch7 Acc 0.24948333333333333 (29938/120000), AUC 0.5011708736419678
ep7_train_time 9.953702211380005
Test Epoch7 threshold 0.4 Acc 0.9125, AUC 0.9797069430351257, avg_entr 0.0483710877597332
ep7_t0.4_test_time 0.07261085510253906
gc 0
Train Epoch8 Acc 0.24948333333333333 (29938/120000), AUC 0.5010523200035095
ep8_train_time 9.95864748954773
Test Epoch8 threshold 0.4 Acc 0.9108552631578948, AUC 0.9795762300491333, avg_entr 0.04626066982746124
ep8_t0.4_test_time 0.07236146926879883
gc 0
Train Epoch9 Acc 0.24948333333333333 (29938/120000), AUC 0.5008376836776733
ep9_train_time 9.979712724685669
Test Epoch9 threshold 0.4 Acc 0.9115131578947369, AUC 0.9792753458023071, avg_entr 0.043910954147577286
ep9_t0.4_test_time 0.07192778587341309
Best AUC 0.9809142351150513
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad25_t0.4_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.4 Acc 0.9177631578947368, AUC 0.9858664870262146, avg_entr 0.09907043725252151
t0.4_test_time 0.018798112869262695
