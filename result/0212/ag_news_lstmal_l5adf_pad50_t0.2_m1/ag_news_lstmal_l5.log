total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.248075 (29769/120000), AUC 0.5083456039428711
ep0_train_time 16.40262532234192
Test Epoch0 threshold 0.2 Acc 0.9115131578947369, AUC 0.9780718088150024, avg_entr 0.15998142957687378
ep0_t0.2_test_time 0.1045231819152832
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad50_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.24920833333333334 (29905/120000), AUC 0.517184317111969
ep1_train_time 16.466372966766357
Test Epoch1 threshold 0.2 Acc 0.9162828947368421, AUC 0.9803553819656372, avg_entr 0.09692906588315964
ep1_t0.2_test_time 0.10204243659973145
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad50_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.24925 (29910/120000), AUC 0.5200679302215576
ep2_train_time 16.41718339920044
Test Epoch2 threshold 0.2 Acc 0.9164473684210527, AUC 0.9801172018051147, avg_entr 0.07645004242658615
ep2_t0.2_test_time 0.10240793228149414
gc 0
Train Epoch3 Acc 0.24925833333333333 (29911/120000), AUC 0.5220239758491516
ep3_train_time 16.41909098625183
Test Epoch3 threshold 0.2 Acc 0.9154605263157894, AUC 0.980779767036438, avg_entr 0.0665104016661644
ep3_t0.2_test_time 0.10402798652648926
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad50_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.24929166666666666 (29915/120000), AUC 0.5237160921096802
ep4_train_time 16.44752788543701
Test Epoch4 threshold 0.2 Acc 0.9149671052631579, AUC 0.9804938435554504, avg_entr 0.05949025973677635
ep4_t0.2_test_time 0.1063387393951416
gc 0
Train Epoch5 Acc 0.249275 (29913/120000), AUC 0.5249466896057129
ep5_train_time 16.365350246429443
Test Epoch5 threshold 0.2 Acc 0.9131578947368421, AUC 0.9804108142852783, avg_entr 0.05473466217517853
ep5_t0.2_test_time 0.10553264617919922
gc 0
Train Epoch6 Acc 0.24929166666666666 (29915/120000), AUC 0.5263156294822693
ep6_train_time 16.453578233718872
Test Epoch6 threshold 0.2 Acc 0.9129934210526316, AUC 0.9799590110778809, avg_entr 0.051669150590896606
ep6_t0.2_test_time 0.10223245620727539
gc 0
Train Epoch7 Acc 0.249325 (29919/120000), AUC 0.5273346900939941
ep7_train_time 16.437363624572754
Test Epoch7 threshold 0.2 Acc 0.912828947368421, AUC 0.9800384640693665, avg_entr 0.047321006655693054
ep7_t0.2_test_time 0.10171079635620117
gc 0
Train Epoch8 Acc 0.24934166666666666 (29921/120000), AUC 0.528099775314331
ep8_train_time 16.428273916244507
Test Epoch8 threshold 0.2 Acc 0.9121710526315789, AUC 0.9796253442764282, avg_entr 0.045262109488248825
ep8_t0.2_test_time 0.10168671607971191
gc 0
Train Epoch9 Acc 0.24934166666666666 (29921/120000), AUC 0.5285646915435791
ep9_train_time 16.393688678741455
Test Epoch9 threshold 0.2 Acc 0.9123355263157895, AUC 0.9793524146080017, avg_entr 0.04478668048977852
ep9_t0.2_test_time 0.10302948951721191
Best AUC 0.980779767036438
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad50_t0.2_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.2 Acc 0.9296052631578947, AUC 0.9862266778945923, avg_entr 0.06877191364765167
t0.2_test_time 0.026403427124023438
