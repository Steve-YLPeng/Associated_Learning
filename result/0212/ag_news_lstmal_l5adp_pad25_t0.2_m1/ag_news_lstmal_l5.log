total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.23906666666666668 (28688/120000), AUC 0.47942090034484863
ep0_train_time 10.110021591186523
Test Epoch0 threshold 0.2 Acc 0.9125, AUC 0.9794589281082153, avg_entr 0.15112780034542084
ep0_t0.2_test_time 0.07279729843139648
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.24391666666666667 (29270/120000), AUC 0.47551673650741577
ep1_train_time 9.846038341522217
Test Epoch1 threshold 0.2 Acc 0.9120065789473685, AUC 0.9806054830551147, avg_entr 0.09321226924657822
ep1_t0.2_test_time 0.07226896286010742
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.24525833333333333 (29431/120000), AUC 0.47687816619873047
ep2_train_time 10.109476566314697
Test Epoch2 threshold 0.2 Acc 0.912828947368421, AUC 0.981177568435669, avg_entr 0.07557649910449982
ep2_t0.2_test_time 0.07173895835876465
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.245975 (29517/120000), AUC 0.4780714511871338
ep3_train_time 9.97028136253357
Test Epoch3 threshold 0.2 Acc 0.9116776315789473, AUC 0.9807727336883545, avg_entr 0.06506740301847458
ep3_t0.2_test_time 0.07132577896118164
gc 0
Train Epoch4 Acc 0.24641666666666667 (29570/120000), AUC 0.4791337847709656
ep4_train_time 9.965995788574219
Test Epoch4 threshold 0.2 Acc 0.9129934210526316, AUC 0.9806139469146729, avg_entr 0.059552405029535294
ep4_t0.2_test_time 0.07165193557739258
gc 0
Train Epoch5 Acc 0.24649166666666666 (29579/120000), AUC 0.4797789454460144
ep5_train_time 9.786962032318115
Test Epoch5 threshold 0.2 Acc 0.9131578947368421, AUC 0.9800575971603394, avg_entr 0.05260717123746872
ep5_t0.2_test_time 0.07132506370544434
gc 0
Train Epoch6 Acc 0.2469 (29628/120000), AUC 0.48064130544662476
ep6_train_time 10.020878314971924
Test Epoch6 threshold 0.2 Acc 0.9115131578947369, AUC 0.9797687530517578, avg_entr 0.0491226501762867
ep6_t0.2_test_time 0.07192707061767578
gc 0
Train Epoch7 Acc 0.24704166666666666 (29645/120000), AUC 0.48086756467819214
ep7_train_time 9.883146047592163
Test Epoch7 threshold 0.2 Acc 0.9123355263157895, AUC 0.9797267913818359, avg_entr 0.04655588045716286
ep7_t0.2_test_time 0.07120704650878906
gc 0
Train Epoch8 Acc 0.24725833333333333 (29671/120000), AUC 0.48156774044036865
ep8_train_time 10.089125156402588
Test Epoch8 threshold 0.2 Acc 0.9115131578947369, AUC 0.9795106053352356, avg_entr 0.04578046873211861
ep8_t0.2_test_time 0.07400393486022949
gc 0
Train Epoch9 Acc 0.24743333333333334 (29692/120000), AUC 0.48197683691978455
ep9_train_time 9.942196607589722
Test Epoch9 threshold 0.2 Acc 0.9105263157894737, AUC 0.9793137311935425, avg_entr 0.04400629177689552
ep9_t0.2_test_time 0.07173681259155273
Best AUC 0.981177568435669
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adp_pad25_t0.2_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.2 Acc 0.9217105263157894, AUC 0.9860477447509766, avg_entr 0.0798095315694809
t0.2_test_time 0.018797874450683594
