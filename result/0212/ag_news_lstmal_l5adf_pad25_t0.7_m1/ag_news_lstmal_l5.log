total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.2541 (30492/120000), AUC 0.5166975855827332
ep0_train_time 10.288352012634277
Test Epoch0 threshold 0.7 Acc 0.9133223684210526, AUC 0.9793438911437988, avg_entr 0.14856620132923126
ep0_t0.7_test_time 0.07331061363220215
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.7_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.25095833333333334 (30115/120000), AUC 0.5214205980300903
ep1_train_time 9.817724704742432
Test Epoch1 threshold 0.7 Acc 0.912828947368421, AUC 0.980411171913147, avg_entr 0.0932517871260643
ep1_t0.7_test_time 0.07227516174316406
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.7_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.25064166666666665 (30077/120000), AUC 0.5197096467018127
ep2_train_time 9.95727801322937
Test Epoch2 threshold 0.7 Acc 0.9138157894736842, AUC 0.9807114601135254, avg_entr 0.07522246986627579
ep2_t0.7_test_time 0.07600545883178711
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.7_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.2503666666666667 (30044/120000), AUC 0.5189993977546692
ep3_train_time 10.081430912017822
Test Epoch3 threshold 0.7 Acc 0.9129934210526316, AUC 0.9808647632598877, avg_entr 0.06522254645824432
ep3_t0.7_test_time 0.0715336799621582
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.7_m1//ag_news_lstmal_l5_prefix.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.2502 (30024/120000), AUC 0.5185471177101135
ep4_train_time 9.8861243724823
Test Epoch4 threshold 0.7 Acc 0.9110197368421052, AUC 0.9803951382637024, avg_entr 0.058479197323322296
ep4_t0.7_test_time 0.07127833366394043
gc 0
Train Epoch5 Acc 0.2501583333333333 (30019/120000), AUC 0.5180481672286987
ep5_train_time 9.8814537525177
Test Epoch5 threshold 0.7 Acc 0.9116776315789473, AUC 0.9803059697151184, avg_entr 0.053289156407117844
ep5_t0.7_test_time 0.07199382781982422
gc 0
Train Epoch6 Acc 0.250175 (30021/120000), AUC 0.5176213383674622
ep6_train_time 9.849670648574829
Test Epoch6 threshold 0.7 Acc 0.9111842105263158, AUC 0.9798905849456787, avg_entr 0.050163619220256805
ep6_t0.7_test_time 0.07183456420898438
gc 0
Train Epoch7 Acc 0.250075 (30009/120000), AUC 0.5173963904380798
ep7_train_time 9.91015338897705
Test Epoch7 threshold 0.7 Acc 0.909375, AUC 0.9799388647079468, avg_entr 0.04715672507882118
ep7_t0.7_test_time 0.07197761535644531
gc 0
Train Epoch8 Acc 0.2500833333333333 (30010/120000), AUC 0.5170654058456421
ep8_train_time 9.960838079452515
Test Epoch8 threshold 0.7 Acc 0.9126644736842106, AUC 0.979655921459198, avg_entr 0.04443981125950813
ep8_t0.7_test_time 0.07634997367858887
gc 0
Train Epoch9 Acc 0.25001666666666666 (30002/120000), AUC 0.5164448618888855
ep9_train_time 10.171068668365479
Test Epoch9 threshold 0.7 Acc 0.9115131578947369, AUC 0.9792010188102722, avg_entr 0.04291076585650444
ep9_t0.7_test_time 0.07204794883728027
Best AUC 0.9808647632598877
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad25_t0.7_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.7 Acc 0.9197368421052632, AUC 0.985456109046936, avg_entr 0.06948963552713394
t0.7_test_time 0.01864171028137207
