total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.24170833333333333 (29005/120000), AUC 0.5026992559432983
ep0_train_time 10.054712295532227
Test Epoch0 threshold 0.2 Acc 0.9129934210526316, AUC 0.979438841342926, avg_entr 0.1504371464252472
ep0_t0.2_test_time 0.07283639907836914
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.232825 (27939/120000), AUC 0.5037552118301392
ep1_train_time 9.839378118515015
Test Epoch1 threshold 0.2 Acc 0.9125, AUC 0.9809347987174988, avg_entr 0.09543603658676147
ep1_t0.2_test_time 0.07201242446899414
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.229925 (27591/120000), AUC 0.5026026964187622
ep2_train_time 9.854803323745728
Test Epoch2 threshold 0.2 Acc 0.9138157894736842, AUC 0.981420636177063, avg_entr 0.07580003887414932
ep2_t0.2_test_time 0.07156157493591309
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.22895 (27474/120000), AUC 0.501953125
ep3_train_time 9.724509716033936
Test Epoch3 threshold 0.2 Acc 0.9123355263157895, AUC 0.9809281826019287, avg_entr 0.06536202877759933
ep3_t0.2_test_time 0.071533203125
gc 0
Train Epoch4 Acc 0.22778333333333334 (27334/120000), AUC 0.5014267563819885
ep4_train_time 9.802120923995972
Test Epoch4 threshold 0.2 Acc 0.9138157894736842, AUC 0.9809920191764832, avg_entr 0.058925528079271317
ep4_t0.2_test_time 0.07194352149963379
gc 0
Train Epoch5 Acc 0.22734166666666666 (27281/120000), AUC 0.5010296106338501
ep5_train_time 10.043616771697998
Test Epoch5 threshold 0.2 Acc 0.9120065789473685, AUC 0.9801559448242188, avg_entr 0.05288049951195717
ep5_t0.2_test_time 0.07181334495544434
gc 0
Train Epoch6 Acc 0.22761666666666666 (27314/120000), AUC 0.5004631280899048
ep6_train_time 10.003289461135864
Test Epoch6 threshold 0.2 Acc 0.912828947368421, AUC 0.9802743792533875, avg_entr 0.04977436736226082
ep6_t0.2_test_time 0.07128143310546875
gc 0
Train Epoch7 Acc 0.22745 (27294/120000), AUC 0.500179648399353
ep7_train_time 9.875929832458496
Test Epoch7 threshold 0.2 Acc 0.9126644736842106, AUC 0.9797903299331665, avg_entr 0.047519974410533905
ep7_t0.2_test_time 0.07142281532287598
gc 0
Train Epoch8 Acc 0.22730833333333333 (27277/120000), AUC 0.5001040101051331
ep8_train_time 9.806472063064575
Test Epoch8 threshold 0.2 Acc 0.9110197368421052, AUC 0.9795629978179932, avg_entr 0.04528702795505524
ep8_t0.2_test_time 0.07120013236999512
gc 0
Train Epoch9 Acc 0.22753333333333334 (27304/120000), AUC 0.5000683069229126
ep9_train_time 9.853389024734497
Test Epoch9 threshold 0.2 Acc 0.9118421052631579, AUC 0.9793631434440613, avg_entr 0.04267880693078041
ep9_t0.2_test_time 0.07133173942565918
Best AUC 0.981420636177063
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad25_t0.2_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.2 Acc 0.9223684210526316, AUC 0.9854967594146729, avg_entr 0.08127473294734955
t0.2_test_time 0.018992185592651367
