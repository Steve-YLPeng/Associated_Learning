total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.21626666666666666 (25952/120000), AUC 0.4758416414260864
ep0_train_time 16.312578916549683
Test Epoch0 threshold 0.8 Acc 0.9106907894736842, AUC 0.9774278998374939, avg_entr 0.1596291959285736
ep0_t0.8_test_time 0.10241317749023438
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad50_t0.8_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.20005 (24006/120000), AUC 0.4749506711959839
ep1_train_time 16.153443813323975
Test Epoch1 threshold 0.8 Acc 0.915625, AUC 0.9802252650260925, avg_entr 0.09864353388547897
ep1_t0.8_test_time 0.10061335563659668
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad50_t0.8_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.19990833333333333 (23989/120000), AUC 0.47484707832336426
ep2_train_time 16.285791635513306
Test Epoch2 threshold 0.8 Acc 0.9177631578947368, AUC 0.9805716276168823, avg_entr 0.07696880400180817
ep2_t0.8_test_time 0.1015617847442627
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad50_t0.8_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.20076666666666668 (24092/120000), AUC 0.4751615822315216
ep3_train_time 16.75836968421936
Test Epoch3 threshold 0.8 Acc 0.9154605263157894, AUC 0.9804444909095764, avg_entr 0.06586984544992447
ep3_t0.8_test_time 0.10001325607299805
gc 0
Train Epoch4 Acc 0.20181666666666667 (24218/120000), AUC 0.4754643738269806
ep4_train_time 16.317684650421143
Test Epoch4 threshold 0.8 Acc 0.915296052631579, AUC 0.9801859855651855, avg_entr 0.05947352945804596
ep4_t0.8_test_time 0.10032439231872559
gc 0
Train Epoch5 Acc 0.20276666666666668 (24332/120000), AUC 0.4749150276184082
ep5_train_time 16.351703882217407
Test Epoch5 threshold 0.8 Acc 0.915625, AUC 0.9803760647773743, avg_entr 0.053320012986660004
ep5_t0.8_test_time 0.10044050216674805
gc 0
Train Epoch6 Acc 0.20448333333333332 (24538/120000), AUC 0.4745562970638275
ep6_train_time 16.512779712677002
Test Epoch6 threshold 0.8 Acc 0.9141447368421053, AUC 0.9799289107322693, avg_entr 0.05092494934797287
ep6_t0.8_test_time 0.10366964340209961
gc 0
Train Epoch7 Acc 0.205425 (24651/120000), AUC 0.47395116090774536
ep7_train_time 16.56134581565857
Test Epoch7 threshold 0.8 Acc 0.9133223684210526, AUC 0.9799564480781555, avg_entr 0.04813409224152565
ep7_t0.8_test_time 0.10052061080932617
gc 0
Train Epoch8 Acc 0.20689166666666667 (24827/120000), AUC 0.4745664596557617
ep8_train_time 16.233588695526123
Test Epoch8 threshold 0.8 Acc 0.912828947368421, AUC 0.9797372221946716, avg_entr 0.04567199572920799
ep8_t0.8_test_time 0.10061430931091309
gc 0
Train Epoch9 Acc 0.20815833333333333 (24979/120000), AUC 0.47461044788360596
ep9_train_time 16.45392870903015
Test Epoch9 threshold 0.8 Acc 0.9120065789473685, AUC 0.979537308216095, avg_entr 0.04392914101481438
ep9_t0.8_test_time 0.10058164596557617
Best AUC 0.9805716276168823
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad50_t0.8_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.8 Acc 0.9243421052631579, AUC 0.986574649810791, avg_entr 0.08135024458169937
t0.8_test_time 0.026070117950439453
