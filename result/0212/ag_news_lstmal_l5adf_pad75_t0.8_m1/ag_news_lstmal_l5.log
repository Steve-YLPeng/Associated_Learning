total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.24429166666666666 (29315/120000), AUC 0.527162492275238
ep0_train_time 22.673722743988037
Test Epoch0 threshold 0.8 Acc 0.9085526315789474, AUC 0.9768747091293335, avg_entr 0.16223374009132385
ep0_t0.8_test_time 0.14133739471435547
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad75_t0.8_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.241075 (28929/120000), AUC 0.5419657230377197
ep1_train_time 22.583376169204712
Test Epoch1 threshold 0.8 Acc 0.9141447368421053, AUC 0.9796329140663147, avg_entr 0.09842724353075027
ep1_t0.8_test_time 0.13226532936096191
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad75_t0.8_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.24160833333333334 (28993/120000), AUC 0.5427573919296265
ep2_train_time 22.59411311149597
Test Epoch2 threshold 0.8 Acc 0.9151315789473684, AUC 0.9804186224937439, avg_entr 0.07654888927936554
ep2_t0.8_test_time 0.13657903671264648
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad75_t0.8_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.24233333333333335 (29080/120000), AUC 0.5422240495681763
ep3_train_time 22.6314799785614
Test Epoch3 threshold 0.8 Acc 0.9149671052631579, AUC 0.980526328086853, avg_entr 0.06647377461194992
ep3_t0.8_test_time 0.13162493705749512
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad75_t0.8_m1//ag_news_lstmal_l5_prefix.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.242675 (29121/120000), AUC 0.541359007358551
ep4_train_time 22.68924856185913
Test Epoch4 threshold 0.8 Acc 0.915625, AUC 0.9802678823471069, avg_entr 0.0595657043159008
ep4_t0.8_test_time 0.13119029998779297
gc 0
Train Epoch5 Acc 0.2427 (29124/120000), AUC 0.5407590270042419
ep5_train_time 22.642672777175903
Test Epoch5 threshold 0.8 Acc 0.9133223684210526, AUC 0.9803910851478577, avg_entr 0.05429866164922714
ep5_t0.8_test_time 0.13088750839233398
gc 0
Train Epoch6 Acc 0.24264166666666667 (29117/120000), AUC 0.5402278900146484
ep6_train_time 22.662120580673218
Test Epoch6 threshold 0.8 Acc 0.9144736842105263, AUC 0.9803500771522522, avg_entr 0.05046536400914192
ep6_t0.8_test_time 0.13789749145507812
gc 0
Train Epoch7 Acc 0.24225 (29070/120000), AUC 0.5397306084632874
ep7_train_time 22.68919086456299
Test Epoch7 threshold 0.8 Acc 0.9149671052631579, AUC 0.9800112247467041, avg_entr 0.046959444880485535
ep7_t0.8_test_time 0.13094568252563477
gc 0
Train Epoch8 Acc 0.242075 (29049/120000), AUC 0.5395615100860596
ep8_train_time 22.622572660446167
Test Epoch8 threshold 0.8 Acc 0.912828947368421, AUC 0.9796810150146484, avg_entr 0.04526375234127045
ep8_t0.8_test_time 0.1365962028503418
gc 0
Train Epoch9 Acc 0.24225 (29070/120000), AUC 0.5393108129501343
ep9_train_time 22.645811796188354
Test Epoch9 threshold 0.8 Acc 0.9133223684210526, AUC 0.9795307517051697, avg_entr 0.042623184621334076
ep9_t0.8_test_time 0.13183021545410156
Best AUC 0.980526328086853
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad75_t0.8_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.8 Acc 0.9223684210526316, AUC 0.9858568906784058, avg_entr 0.069587841629982
t0.8_test_time 0.034238338470458984
