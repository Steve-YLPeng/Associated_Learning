total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.25001666666666666 (30002/120000), AUC 0.48213326930999756
ep0_train_time 22.73689866065979
Test Epoch0 threshold 0.6 Acc 0.9080592105263158, AUC 0.9765721559524536, avg_entr 0.16057217121124268
ep0_t0.6_test_time 0.13753557205200195
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad75_t0.6_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.25 (30000/120000), AUC 0.4644257426261902
ep1_train_time 22.693302869796753
Test Epoch1 threshold 0.6 Acc 0.9136513157894737, AUC 0.9794813990592957, avg_entr 0.09925001859664917
ep1_t0.6_test_time 0.13328981399536133
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad75_t0.6_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.25001666666666666 (30002/120000), AUC 0.46665000915527344
ep2_train_time 22.604878425598145
Test Epoch2 threshold 0.6 Acc 0.9162828947368421, AUC 0.9802790880203247, avg_entr 0.07646575570106506
ep2_t0.6_test_time 0.13378477096557617
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad75_t0.6_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.25003333333333333 (30004/120000), AUC 0.46892115473747253
ep3_train_time 22.752863883972168
Test Epoch3 threshold 0.6 Acc 0.915625, AUC 0.9803480505943298, avg_entr 0.06598711758852005
ep3_t0.6_test_time 0.13887548446655273
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad75_t0.6_m1//ag_news_lstmal_l5_prefix.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.250025 (30003/120000), AUC 0.47082632780075073
ep4_train_time 22.691755294799805
Test Epoch4 threshold 0.6 Acc 0.9159539473684211, AUC 0.98027104139328, avg_entr 0.05860208347439766
ep4_t0.6_test_time 0.13857817649841309
gc 0
Train Epoch5 Acc 0.25005 (30006/120000), AUC 0.47224631905555725
ep5_train_time 22.691474437713623
Test Epoch5 threshold 0.6 Acc 0.9169407894736842, AUC 0.9801682829856873, avg_entr 0.05373101308941841
ep5_t0.6_test_time 0.13540363311767578
gc 0
Train Epoch6 Acc 0.25005 (30006/120000), AUC 0.4739009141921997
ep6_train_time 22.65676999092102
Test Epoch6 threshold 0.6 Acc 0.9120065789473685, AUC 0.9800046682357788, avg_entr 0.0500313825905323
ep6_t0.6_test_time 0.13212037086486816
gc 0
Train Epoch7 Acc 0.25004166666666666 (30005/120000), AUC 0.474820613861084
ep7_train_time 22.500203371047974
Test Epoch7 threshold 0.6 Acc 0.9148026315789474, AUC 0.9799768924713135, avg_entr 0.04803808033466339
ep7_t0.6_test_time 0.13205766677856445
gc 0
Train Epoch8 Acc 0.25005 (30006/120000), AUC 0.47564634680747986
ep8_train_time 22.392666578292847
Test Epoch8 threshold 0.6 Acc 0.9144736842105263, AUC 0.9797812700271606, avg_entr 0.04554535821080208
ep8_t0.6_test_time 0.13127446174621582
gc 0
Train Epoch9 Acc 0.25004166666666666 (30005/120000), AUC 0.47663143277168274
ep9_train_time 23.031431674957275
Test Epoch9 threshold 0.6 Acc 0.9136513157894737, AUC 0.9795622229576111, avg_entr 0.04334932565689087
ep9_t0.6_test_time 0.13443493843078613
Best AUC 0.9803480505943298
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad75_t0.6_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.6 Acc 0.925, AUC 0.986140251159668, avg_entr 0.0681115984916687
t0.6_test_time 0.0341799259185791
