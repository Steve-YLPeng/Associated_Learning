total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.24965833333333334 (29959/120000), AUC 0.46098050475120544
ep0_train_time 10.087700843811035
Test Epoch0 threshold 0.6 Acc 0.9097039473684211, AUC 0.9793987274169922, avg_entr 0.14726707339286804
ep0_t0.6_test_time 0.07402491569519043
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.6_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.24934166666666666 (29921/120000), AUC 0.43889498710632324
ep1_train_time 9.787178754806519
Test Epoch1 threshold 0.6 Acc 0.9138157894736842, AUC 0.9808140397071838, avg_entr 0.09256964921951294
ep1_t0.6_test_time 0.07336783409118652
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.6_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.24916666666666668 (29900/120000), AUC 0.4365915060043335
ep2_train_time 9.83414626121521
Test Epoch2 threshold 0.6 Acc 0.912828947368421, AUC 0.9809672832489014, avg_entr 0.07502922415733337
ep2_t0.6_test_time 0.07160520553588867
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.6_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.24900833333333333 (29881/120000), AUC 0.4353576600551605
ep3_train_time 9.874736309051514
Test Epoch3 threshold 0.6 Acc 0.9129934210526316, AUC 0.9804307818412781, avg_entr 0.0651082918047905
ep3_t0.6_test_time 0.07166123390197754
gc 0
Train Epoch4 Acc 0.24883333333333332 (29860/120000), AUC 0.43456095457077026
ep4_train_time 9.806458711624146
Test Epoch4 threshold 0.6 Acc 0.9101973684210526, AUC 0.9804916381835938, avg_entr 0.05821283161640167
ep4_t0.6_test_time 0.07168436050415039
gc 0
Train Epoch5 Acc 0.248875 (29865/120000), AUC 0.43362224102020264
ep5_train_time 9.82074499130249
Test Epoch5 threshold 0.6 Acc 0.9126644736842106, AUC 0.9800657033920288, avg_entr 0.052262548357248306
ep5_t0.6_test_time 0.07191324234008789
gc 0
Train Epoch6 Acc 0.24870833333333334 (29845/120000), AUC 0.43233147263526917
ep6_train_time 10.113698482513428
Test Epoch6 threshold 0.6 Acc 0.9118421052631579, AUC 0.9796900749206543, avg_entr 0.04840700328350067
ep6_t0.6_test_time 0.07413482666015625
gc 0
Train Epoch7 Acc 0.24864166666666668 (29837/120000), AUC 0.4315577745437622
ep7_train_time 9.818540573120117
Test Epoch7 threshold 0.6 Acc 0.9125, AUC 0.9798259735107422, avg_entr 0.047307033091783524
ep7_t0.6_test_time 0.07523822784423828
gc 0
Train Epoch8 Acc 0.24869166666666667 (29843/120000), AUC 0.43198829889297485
ep8_train_time 9.768790006637573
Test Epoch8 threshold 0.6 Acc 0.9118421052631579, AUC 0.9793183207511902, avg_entr 0.04540159925818443
ep8_t0.6_test_time 0.07241272926330566
gc 0
Train Epoch9 Acc 0.24865 (29838/120000), AUC 0.4322702884674072
ep9_train_time 9.768687009811401
Test Epoch9 threshold 0.6 Acc 0.9097039473684211, AUC 0.9794362187385559, avg_entr 0.04372585564851761
ep9_t0.6_test_time 0.0721287727355957
Best AUC 0.9809672832489014
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adp_pad25_t0.6_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.6 Acc 0.9190789473684211, AUC 0.985507607460022, avg_entr 0.07882378995418549
t0.6_test_time 0.018919944763183594
