total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.244925 (29391/120000), AUC 0.47443482279777527
ep0_train_time 16.549003839492798
Test Epoch0 threshold 0.9 Acc 0.9101973684210526, AUC 0.9769030809402466, avg_entr 0.1586105227470398
ep0_t0.9_test_time 0.10536766052246094
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad50_t0.9_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.2338 (28056/120000), AUC 0.46257340908050537
ep1_train_time 16.445247888565063
Test Epoch1 threshold 0.9 Acc 0.9162828947368421, AUC 0.9797461628913879, avg_entr 0.09883764386177063
ep1_t0.9_test_time 0.1084909439086914
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad50_t0.9_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.223325 (26799/120000), AUC 0.4652301073074341
ep2_train_time 16.476261377334595
Test Epoch2 threshold 0.9 Acc 0.9159539473684211, AUC 0.980396568775177, avg_entr 0.07905656844377518
ep2_t0.9_test_time 0.10298490524291992
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad50_t0.9_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.2155 (25860/120000), AUC 0.46728938817977905
ep3_train_time 16.539011478424072
Test Epoch3 threshold 0.9 Acc 0.9171052631578948, AUC 0.9800247550010681, avg_entr 0.06707898527383804
ep3_t0.9_test_time 0.10239458084106445
gc 0
Train Epoch4 Acc 0.2108 (25296/120000), AUC 0.46864455938339233
ep4_train_time 16.52767777442932
Test Epoch4 threshold 0.9 Acc 0.9154605263157894, AUC 0.979839563369751, avg_entr 0.05939562991261482
ep4_t0.9_test_time 0.10193848609924316
gc 0
Train Epoch5 Acc 0.20686666666666667 (24824/120000), AUC 0.4693801999092102
ep5_train_time 16.549458503723145
Test Epoch5 threshold 0.9 Acc 0.9136513157894737, AUC 0.9794865846633911, avg_entr 0.054598864167928696
ep5_t0.9_test_time 0.1026768684387207
gc 0
Train Epoch6 Acc 0.204975 (24597/120000), AUC 0.47010117769241333
ep6_train_time 16.552772998809814
Test Epoch6 threshold 0.9 Acc 0.9129934210526316, AUC 0.9799942970275879, avg_entr 0.050166331231594086
ep6_t0.9_test_time 0.10257220268249512
gc 0
Train Epoch7 Acc 0.20468333333333333 (24562/120000), AUC 0.47028136253356934
ep7_train_time 16.54183864593506
Test Epoch7 threshold 0.9 Acc 0.9126644736842106, AUC 0.9796636700630188, avg_entr 0.04798435419797897
ep7_t0.9_test_time 0.10384225845336914
gc 0
Train Epoch8 Acc 0.20545 (24654/120000), AUC 0.4707937240600586
ep8_train_time 16.51809310913086
Test Epoch8 threshold 0.9 Acc 0.9111842105263158, AUC 0.979402482509613, avg_entr 0.04625680297613144
ep8_t0.9_test_time 0.10227298736572266
gc 0
Train Epoch9 Acc 0.20746666666666666 (24896/120000), AUC 0.47144556045532227
ep9_train_time 16.476460933685303
Test Epoch9 threshold 0.9 Acc 0.9116776315789473, AUC 0.9794762134552002, avg_entr 0.04372146353125572
ep9_t0.9_test_time 0.10023784637451172
Best AUC 0.980396568775177
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad50_t0.9_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.9 Acc 0.9289473684210526, AUC 0.9864897131919861, avg_entr 0.08099498599767685
t0.9_test_time 0.026693105697631836
