total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.276775 (33213/120000), AUC 0.5199587941169739
ep0_train_time 22.530985116958618
Test Epoch0 threshold 0.2 Acc 0.9082236842105263, AUC 0.9768761992454529, avg_entr 0.16300757229328156
ep0_t0.2_test_time 0.13218331336975098
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad75_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.279625 (33555/120000), AUC 0.5402965545654297
ep1_train_time 22.364365816116333
Test Epoch1 threshold 0.2 Acc 0.9143092105263158, AUC 0.9797279834747314, avg_entr 0.0974871963262558
ep1_t0.2_test_time 0.1305394172668457
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad75_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.2789333333333333 (33472/120000), AUC 0.541092574596405
ep2_train_time 22.7426335811615
Test Epoch2 threshold 0.2 Acc 0.915296052631579, AUC 0.9803680777549744, avg_entr 0.07628041505813599
ep2_t0.2_test_time 0.13663792610168457
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad75_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.2790916666666667 (33491/120000), AUC 0.5406394004821777
ep3_train_time 22.48287868499756
Test Epoch3 threshold 0.2 Acc 0.9159539473684211, AUC 0.9803234338760376, avg_entr 0.06461362540721893
ep3_t0.2_test_time 0.12969970703125
gc 0
Train Epoch4 Acc 0.2797 (33564/120000), AUC 0.5397297739982605
ep4_train_time 22.33173394203186
Test Epoch4 threshold 0.2 Acc 0.915625, AUC 0.9803910851478577, avg_entr 0.0584125854074955
ep4_t0.2_test_time 0.13013911247253418
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad75_t0.2_m1//ag_news_lstmal_l5_prefix.pt  ,ep 4
gc 0
Train Epoch5 Acc 0.280325 (33639/120000), AUC 0.5390910506248474
ep5_train_time 22.915761470794678
Test Epoch5 threshold 0.2 Acc 0.9164473684210527, AUC 0.9802230596542358, avg_entr 0.0535295344889164
ep5_t0.2_test_time 0.1300065517425537
gc 0
Train Epoch6 Acc 0.2809833333333333 (33718/120000), AUC 0.5387234687805176
ep6_train_time 22.366437673568726
Test Epoch6 threshold 0.2 Acc 0.9169407894736842, AUC 0.9800818562507629, avg_entr 0.04948917031288147
ep6_t0.2_test_time 0.13005614280700684
gc 0
Train Epoch7 Acc 0.28145 (33774/120000), AUC 0.5386619567871094
ep7_train_time 22.451771020889282
Test Epoch7 threshold 0.2 Acc 0.9148026315789474, AUC 0.9799745678901672, avg_entr 0.04708528146147728
ep7_t0.2_test_time 0.13473081588745117
gc 0
Train Epoch8 Acc 0.28163333333333335 (33796/120000), AUC 0.5380635261535645
ep8_train_time 22.759057998657227
Test Epoch8 threshold 0.2 Acc 0.9134868421052632, AUC 0.9798473119735718, avg_entr 0.04543980211019516
ep8_t0.2_test_time 0.1300671100616455
gc 0
Train Epoch9 Acc 0.28149166666666664 (33779/120000), AUC 0.5375823974609375
ep9_train_time 22.41114616394043
Test Epoch9 threshold 0.2 Acc 0.9134868421052632, AUC 0.9796898365020752, avg_entr 0.043167777359485626
ep9_t0.2_test_time 0.13034987449645996
Best AUC 0.9803910851478577
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad75_t0.2_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.2 Acc 0.9217105263157894, AUC 0.9858373999595642, avg_entr 0.06054750829935074
t0.2_test_time 0.03357100486755371
