total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.23558333333333334 (28270/120000), AUC 0.44934725761413574
ep0_train_time 10.00514817237854
Test Epoch0 threshold 0.8 Acc 0.9075657894736842, AUC 0.9795697927474976, avg_entr 0.15401364862918854
ep0_t0.8_test_time 0.07352948188781738
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.8_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.23525833333333335 (28231/120000), AUC 0.4356125593185425
ep1_train_time 10.097351789474487
Test Epoch1 threshold 0.8 Acc 0.9118421052631579, AUC 0.9811017513275146, avg_entr 0.09767623990774155
ep1_t0.8_test_time 0.07229328155517578
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.8_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.23503333333333334 (28204/120000), AUC 0.4343727231025696
ep2_train_time 9.890557050704956
Test Epoch2 threshold 0.8 Acc 0.912828947368421, AUC 0.9807034134864807, avg_entr 0.07559090852737427
ep2_t0.8_test_time 0.0718076229095459
gc 0
Train Epoch3 Acc 0.23513333333333333 (28216/120000), AUC 0.43398118019104004
ep3_train_time 9.796785593032837
Test Epoch3 threshold 0.8 Acc 0.9108552631578948, AUC 0.9804463386535645, avg_entr 0.06597515195608139
ep3_t0.8_test_time 0.07159566879272461
gc 0
Train Epoch4 Acc 0.23509166666666667 (28211/120000), AUC 0.4337666630744934
ep4_train_time 10.036738872528076
Test Epoch4 threshold 0.8 Acc 0.9116776315789473, AUC 0.9802802801132202, avg_entr 0.05914227291941643
ep4_t0.8_test_time 0.07444930076599121
gc 0
Train Epoch5 Acc 0.23530833333333334 (28237/120000), AUC 0.43356209993362427
ep5_train_time 10.202434301376343
Test Epoch5 threshold 0.8 Acc 0.9103618421052632, AUC 0.9800026416778564, avg_entr 0.054581671953201294
ep5_t0.8_test_time 0.07445669174194336
gc 0
Train Epoch6 Acc 0.23525833333333335 (28231/120000), AUC 0.43345165252685547
ep6_train_time 9.687724113464355
Test Epoch6 threshold 0.8 Acc 0.9126644736842106, AUC 0.979788064956665, avg_entr 0.05120955407619476
ep6_t0.8_test_time 0.07175636291503906
gc 0
Train Epoch7 Acc 0.23526666666666668 (28232/120000), AUC 0.4334319233894348
ep7_train_time 9.938455820083618
Test Epoch7 threshold 0.8 Acc 0.9131578947368421, AUC 0.9796366095542908, avg_entr 0.04911588504910469
ep7_t0.8_test_time 0.07185578346252441
gc 0
Train Epoch8 Acc 0.23535 (28242/120000), AUC 0.43342381715774536
ep8_train_time 9.904840469360352
Test Epoch8 threshold 0.8 Acc 0.9116776315789473, AUC 0.9792211651802063, avg_entr 0.04647844657301903
ep8_t0.8_test_time 0.07114815711975098
gc 0
Train Epoch9 Acc 0.2353 (28236/120000), AUC 0.43332648277282715
ep9_train_time 10.591288805007935
Test Epoch9 threshold 0.8 Acc 0.9101973684210526, AUC 0.9794059991836548, avg_entr 0.04476850479841232
ep9_t0.8_test_time 0.07281184196472168
Best AUC 0.9811017513275146
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad25_t0.8_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.8 Acc 0.9217105263157894, AUC 0.9858728647232056, avg_entr 0.10169307142496109
t0.8_test_time 0.018666505813598633
