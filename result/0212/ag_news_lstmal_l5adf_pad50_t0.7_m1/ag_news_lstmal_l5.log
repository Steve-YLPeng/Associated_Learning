total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.25366666666666665 (30440/120000), AUC 0.48897796869277954
ep0_train_time 16.806498765945435
Test Epoch0 threshold 0.7 Acc 0.9100328947368421, AUC 0.9780604243278503, avg_entr 0.1597902774810791
ep0_t0.7_test_time 0.10668420791625977
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad50_t0.7_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.25753333333333334 (30904/120000), AUC 0.4848174452781677
ep1_train_time 16.318307638168335
Test Epoch1 threshold 0.7 Acc 0.9148026315789474, AUC 0.9802666902542114, avg_entr 0.09812868386507034
ep1_t0.7_test_time 0.10230588912963867
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad50_t0.7_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.25885833333333336 (31063/120000), AUC 0.48259681463241577
ep2_train_time 16.29975938796997
Test Epoch2 threshold 0.7 Acc 0.9162828947368421, AUC 0.9800862669944763, avg_entr 0.07701127231121063
ep2_t0.7_test_time 0.10236597061157227
gc 0
Train Epoch3 Acc 0.2588666666666667 (31064/120000), AUC 0.48075899481773376
ep3_train_time 16.36206841468811
Test Epoch3 threshold 0.7 Acc 0.9169407894736842, AUC 0.9806762933731079, avg_entr 0.06716837733983994
ep3_t0.7_test_time 0.10624098777770996
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad50_t0.7_m1//ag_news_lstmal_l5_prefix.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.25931666666666664 (31118/120000), AUC 0.47975343465805054
ep4_train_time 16.974509477615356
Test Epoch4 threshold 0.7 Acc 0.915296052631579, AUC 0.9803583025932312, avg_entr 0.05959406495094299
ep4_t0.7_test_time 0.10344934463500977
gc 0
Train Epoch5 Acc 0.25929166666666664 (31115/120000), AUC 0.4788128733634949
ep5_train_time 16.556865215301514
Test Epoch5 threshold 0.7 Acc 0.9143092105263158, AUC 0.9799166321754456, avg_entr 0.055112361907958984
ep5_t0.7_test_time 0.10677695274353027
gc 0
Train Epoch6 Acc 0.25955 (31146/120000), AUC 0.4781498610973358
ep6_train_time 16.450388193130493
Test Epoch6 threshold 0.7 Acc 0.9134868421052632, AUC 0.9798250198364258, avg_entr 0.05163789913058281
ep6_t0.7_test_time 0.10416412353515625
gc 0
Train Epoch7 Acc 0.25961666666666666 (31154/120000), AUC 0.4776914715766907
ep7_train_time 16.550922870635986
Test Epoch7 threshold 0.7 Acc 0.9115131578947369, AUC 0.9794821739196777, avg_entr 0.04779432341456413
ep7_t0.7_test_time 0.10384416580200195
gc 0
Train Epoch8 Acc 0.26008333333333333 (31210/120000), AUC 0.47703611850738525
ep8_train_time 16.53209161758423
Test Epoch8 threshold 0.7 Acc 0.9115131578947369, AUC 0.9795935153961182, avg_entr 0.04599698632955551
ep8_t0.7_test_time 0.10324501991271973
gc 0
Train Epoch9 Acc 0.2598666666666667 (31184/120000), AUC 0.4765750467777252
ep9_train_time 16.500794887542725
Test Epoch9 threshold 0.7 Acc 0.9123355263157895, AUC 0.979345440864563, avg_entr 0.043797705322504044
ep9_t0.7_test_time 0.10348677635192871
Best AUC 0.9806762933731079
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad50_t0.7_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.7 Acc 0.9243421052631579, AUC 0.9860996603965759, avg_entr 0.06853144615888596
t0.7_test_time 0.027359962463378906
