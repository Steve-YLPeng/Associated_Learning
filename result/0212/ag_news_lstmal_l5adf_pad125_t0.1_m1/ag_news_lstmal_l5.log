total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.25 (30000/120000), AUC 0.5243297219276428
ep0_train_time 34.68531060218811
Test Epoch0 threshold 0.1 Acc 0.9026315789473685, AUC 0.9754765033721924, avg_entr 0.17185227572917938
ep0_t0.1_test_time 0.2000129222869873
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad125_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.25 (30000/120000), AUC 0.5538438558578491
ep1_train_time 34.672125577926636
Test Epoch1 threshold 0.1 Acc 0.9111842105263158, AUC 0.9788267612457275, avg_entr 0.10485454648733139
ep1_t0.1_test_time 0.1908705234527588
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad125_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.25 (30000/120000), AUC 0.5601514577865601
ep2_train_time 34.70343780517578
Test Epoch2 threshold 0.1 Acc 0.9167763157894737, AUC 0.9799623489379883, avg_entr 0.07688403129577637
ep2_t0.1_test_time 0.18982648849487305
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad125_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.25 (30000/120000), AUC 0.5625641345977783
ep3_train_time 34.727139472961426
Test Epoch3 threshold 0.1 Acc 0.9167763157894737, AUC 0.980527937412262, avg_entr 0.0656447485089302
ep3_t0.1_test_time 0.18972253799438477
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad125_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.25 (30000/120000), AUC 0.5638589262962341
ep4_train_time 34.74116826057434
Test Epoch4 threshold 0.1 Acc 0.915296052631579, AUC 0.9807844758033752, avg_entr 0.05868018418550491
ep4_t0.1_test_time 0.1905198097229004
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad125_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 4
gc 0
Train Epoch5 Acc 0.25 (30000/120000), AUC 0.5645376443862915
ep5_train_time 34.755860567092896
Test Epoch5 threshold 0.1 Acc 0.9154605263157894, AUC 0.9805984497070312, avg_entr 0.052415382117033005
ep5_t0.1_test_time 0.18961453437805176
gc 0
Train Epoch6 Acc 0.25 (30000/120000), AUC 0.5652442574501038
ep6_train_time 34.81985783576965
Test Epoch6 threshold 0.1 Acc 0.9162828947368421, AUC 0.9806376695632935, avg_entr 0.05036130174994469
ep6_t0.1_test_time 0.18913865089416504
gc 0
Train Epoch7 Acc 0.25 (30000/120000), AUC 0.5660305619239807
ep7_train_time 34.79777550697327
Test Epoch7 threshold 0.1 Acc 0.9161184210526315, AUC 0.9804794788360596, avg_entr 0.04567713662981987
ep7_t0.1_test_time 0.18959307670593262
gc 0
Train Epoch8 Acc 0.25 (30000/120000), AUC 0.5664522051811218
ep8_train_time 34.72094917297363
Test Epoch8 threshold 0.1 Acc 0.9136513157894737, AUC 0.9804148077964783, avg_entr 0.042534731328487396
ep8_t0.1_test_time 0.1896059513092041
gc 0
Train Epoch9 Acc 0.25 (30000/120000), AUC 0.5672242045402527
ep9_train_time 34.786789655685425
Test Epoch9 threshold 0.1 Acc 0.9154605263157894, AUC 0.9802104830741882, avg_entr 0.04125598445534706
ep9_t0.1_test_time 0.18953776359558105
Best AUC 0.9807844758033752
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad125_t0.1_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.1 Acc 0.9236842105263158, AUC 0.9862635135650635, avg_entr 0.06062861159443855
t0.1_test_time 0.048265695571899414
