total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.25155 (30186/120000), AUC 0.5016413331031799
ep0_train_time 10.371786117553711
Test Epoch0 threshold 0.5 Acc 0.9111842105263158, AUC 0.9797465205192566, avg_entr 0.1509779542684555
ep0_t0.5_test_time 0.07360363006591797
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.5_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.25011666666666665 (30014/120000), AUC 0.5051617622375488
ep1_train_time 10.079300165176392
Test Epoch1 threshold 0.5 Acc 0.9131578947368421, AUC 0.981189489364624, avg_entr 0.0951012670993805
ep1_t0.5_test_time 0.07137513160705566
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.5_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.24946666666666667 (29936/120000), AUC 0.5069335699081421
ep2_train_time 9.848020553588867
Test Epoch2 threshold 0.5 Acc 0.9134868421052632, AUC 0.9808503985404968, avg_entr 0.0754474550485611
ep2_t0.5_test_time 0.0718684196472168
gc 0
Train Epoch3 Acc 0.24863333333333335 (29836/120000), AUC 0.5077602863311768
ep3_train_time 10.01348328590393
Test Epoch3 threshold 0.5 Acc 0.9126644736842106, AUC 0.9807658195495605, avg_entr 0.0660431981086731
ep3_t0.5_test_time 0.07087564468383789
gc 0
Train Epoch4 Acc 0.248075 (29769/120000), AUC 0.5087162256240845
ep4_train_time 10.161704301834106
Test Epoch4 threshold 0.5 Acc 0.9108552631578948, AUC 0.980516791343689, avg_entr 0.05864102765917778
ep4_t0.5_test_time 0.07329249382019043
gc 0
Train Epoch5 Acc 0.24764166666666668 (29717/120000), AUC 0.509479820728302
ep5_train_time 10.027794361114502
Test Epoch5 threshold 0.5 Acc 0.9121710526315789, AUC 0.9801908135414124, avg_entr 0.05428783595561981
ep5_t0.5_test_time 0.07161331176757812
gc 0
Train Epoch6 Acc 0.247625 (29715/120000), AUC 0.5097653269767761
ep6_train_time 9.986926317214966
Test Epoch6 threshold 0.5 Acc 0.9123355263157895, AUC 0.9799940586090088, avg_entr 0.050520725548267365
ep6_t0.5_test_time 0.07127833366394043
gc 0
Train Epoch7 Acc 0.2477 (29724/120000), AUC 0.5098288059234619
ep7_train_time 9.799522399902344
Test Epoch7 threshold 0.5 Acc 0.9101973684210526, AUC 0.9796881079673767, avg_entr 0.048521723598241806
ep7_t0.5_test_time 0.07116460800170898
gc 0
Train Epoch8 Acc 0.24735833333333335 (29683/120000), AUC 0.5097988843917847
ep8_train_time 10.06013536453247
Test Epoch8 threshold 0.5 Acc 0.9101973684210526, AUC 0.9794578552246094, avg_entr 0.04611290246248245
ep8_t0.5_test_time 0.07111787796020508
gc 0
Train Epoch9 Acc 0.24748333333333333 (29698/120000), AUC 0.509773313999176
ep9_train_time 9.912423133850098
Test Epoch9 threshold 0.5 Acc 0.9115131578947369, AUC 0.9793239831924438, avg_entr 0.04396352916955948
ep9_t0.5_test_time 0.07164573669433594
Best AUC 0.981189489364624
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad25_t0.5_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.5 Acc 0.9203947368421053, AUC 0.985669732093811, avg_entr 0.10166841745376587
t0.5_test_time 0.018663883209228516
