total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.24184166666666668 (29021/120000), AUC 0.49178439378738403
ep0_train_time 9.905157566070557
Test Epoch0 threshold 0.3 Acc 0.9098684210526315, AUC 0.9793596863746643, avg_entr 0.15256036818027496
ep0_t0.3_test_time 0.07360959053039551
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.3_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.24153333333333332 (28984/120000), AUC 0.4931167960166931
ep1_train_time 9.860897302627563
Test Epoch1 threshold 0.3 Acc 0.9136513157894737, AUC 0.9809259176254272, avg_entr 0.09444348514080048
ep1_t0.3_test_time 0.07367825508117676
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.3_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.24375833333333333 (29251/120000), AUC 0.4944784939289093
ep2_train_time 9.881006956100464
Test Epoch2 threshold 0.3 Acc 0.912828947368421, AUC 0.9808213710784912, avg_entr 0.0765184834599495
ep2_t0.3_test_time 0.07163500785827637
gc 0
Train Epoch3 Acc 0.24530833333333332 (29437/120000), AUC 0.4957576394081116
ep3_train_time 9.824661493301392
Test Epoch3 threshold 0.3 Acc 0.9106907894736842, AUC 0.9807381629943848, avg_entr 0.06685733050107956
ep3_t0.3_test_time 0.07166290283203125
gc 0
Train Epoch4 Acc 0.24604166666666666 (29525/120000), AUC 0.4968837797641754
ep4_train_time 10.076505422592163
Test Epoch4 threshold 0.3 Acc 0.9131578947368421, AUC 0.980326235294342, avg_entr 0.05957985296845436
ep4_t0.3_test_time 0.07324051856994629
gc 0
Train Epoch5 Acc 0.24731666666666666 (29678/120000), AUC 0.49809831380844116
ep5_train_time 9.861027956008911
Test Epoch5 threshold 0.3 Acc 0.9139802631578947, AUC 0.9799790382385254, avg_entr 0.054308172315359116
ep5_t0.3_test_time 0.07154083251953125
gc 0
Train Epoch6 Acc 0.24851666666666666 (29822/120000), AUC 0.4991201162338257
ep6_train_time 9.773639440536499
Test Epoch6 threshold 0.3 Acc 0.9126644736842106, AUC 0.9798057079315186, avg_entr 0.05102589726448059
ep6_t0.3_test_time 0.07191967964172363
gc 0
Train Epoch7 Acc 0.249275 (29913/120000), AUC 0.4996491074562073
ep7_train_time 9.83978819847107
Test Epoch7 threshold 0.3 Acc 0.9108552631578948, AUC 0.9796162247657776, avg_entr 0.048991020768880844
ep7_t0.3_test_time 0.07160019874572754
gc 0
Train Epoch8 Acc 0.24975833333333333 (29971/120000), AUC 0.5003021955490112
ep8_train_time 9.963848114013672
Test Epoch8 threshold 0.3 Acc 0.9108552631578948, AUC 0.9796478748321533, avg_entr 0.04666366055607796
ep8_t0.3_test_time 0.07145047187805176
gc 0
Train Epoch9 Acc 0.2505583333333333 (30067/120000), AUC 0.5010135173797607
ep9_train_time 9.75035285949707
Test Epoch9 threshold 0.3 Acc 0.9100328947368421, AUC 0.9794453382492065, avg_entr 0.04453742504119873
ep9_t0.3_test_time 0.07172131538391113
Best AUC 0.9809259176254272
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adp_pad25_t0.3_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.3 Acc 0.9217105263157894, AUC 0.9854975342750549, avg_entr 0.10167145729064941
t0.3_test_time 0.018844127655029297
