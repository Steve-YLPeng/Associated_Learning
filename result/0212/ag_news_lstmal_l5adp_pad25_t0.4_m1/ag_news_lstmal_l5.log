total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.24024166666666666 (28829/120000), AUC 0.5168167352676392
ep0_train_time 10.114895582199097
Test Epoch0 threshold 0.4 Acc 0.9101973684210526, AUC 0.9795650839805603, avg_entr 0.15584522485733032
ep0_t0.4_test_time 0.07564806938171387
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.230875 (27705/120000), AUC 0.5138238072395325
ep1_train_time 10.03885293006897
Test Epoch1 threshold 0.4 Acc 0.9138157894736842, AUC 0.9809018969535828, avg_entr 0.09659026563167572
ep1_t0.4_test_time 0.0719292163848877
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.22919166666666665 (27503/120000), AUC 0.5129963159561157
ep2_train_time 9.832348823547363
Test Epoch2 threshold 0.4 Acc 0.9139802631578947, AUC 0.9809249639511108, avg_entr 0.07768696546554565
ep2_t0.4_test_time 0.07187080383300781
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.22805 (27366/120000), AUC 0.5118907690048218
ep3_train_time 9.855448722839355
Test Epoch3 threshold 0.4 Acc 0.9131578947368421, AUC 0.9806374311447144, avg_entr 0.0657561793923378
ep3_t0.4_test_time 0.07183122634887695
gc 0
Train Epoch4 Acc 0.22781666666666667 (27338/120000), AUC 0.5112414360046387
ep4_train_time 9.732900142669678
Test Epoch4 threshold 0.4 Acc 0.9133223684210526, AUC 0.9803149700164795, avg_entr 0.060154519975185394
ep4_t0.4_test_time 0.07156229019165039
gc 0
Train Epoch5 Acc 0.22678333333333334 (27214/120000), AUC 0.5104016065597534
ep5_train_time 9.906346082687378
Test Epoch5 threshold 0.4 Acc 0.9108552631578948, AUC 0.9803861379623413, avg_entr 0.053771425038576126
ep5_t0.4_test_time 0.07104635238647461
gc 0
Train Epoch6 Acc 0.22694166666666668 (27233/120000), AUC 0.5099440813064575
ep6_train_time 9.906163215637207
Test Epoch6 threshold 0.4 Acc 0.9129934210526316, AUC 0.9800959825515747, avg_entr 0.051858555525541306
ep6_t0.4_test_time 0.07511162757873535
gc 0
Train Epoch7 Acc 0.2269 (27228/120000), AUC 0.510062038898468
ep7_train_time 10.076303720474243
Test Epoch7 threshold 0.4 Acc 0.9116776315789473, AUC 0.9797827005386353, avg_entr 0.04930267855525017
ep7_t0.4_test_time 0.07158088684082031
gc 0
Train Epoch8 Acc 0.22685833333333333 (27223/120000), AUC 0.5098751187324524
ep8_train_time 9.789701700210571
Test Epoch8 threshold 0.4 Acc 0.9106907894736842, AUC 0.9795989394187927, avg_entr 0.047510113567113876
ep8_t0.4_test_time 0.07152962684631348
gc 0
Train Epoch9 Acc 0.226925 (27231/120000), AUC 0.5099748373031616
ep9_train_time 9.75227952003479
Test Epoch9 threshold 0.4 Acc 0.9095394736842105, AUC 0.9794546961784363, avg_entr 0.04496626555919647
ep9_t0.4_test_time 0.0720205307006836
Best AUC 0.9809249639511108
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adp_pad25_t0.4_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.4 Acc 0.9243421052631579, AUC 0.9859943985939026, avg_entr 0.08186925202608109
t0.4_test_time 0.018822193145751953
