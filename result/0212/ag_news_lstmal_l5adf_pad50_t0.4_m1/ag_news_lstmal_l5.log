total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.2599 (31188/120000), AUC 0.5270434021949768
ep0_train_time 16.369527339935303
Test Epoch0 threshold 0.4 Acc 0.9105263157894737, AUC 0.9770135879516602, avg_entr 0.15928314626216888
ep0_t0.4_test_time 0.10465884208679199
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad50_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.2788833333333333 (33466/120000), AUC 0.5251467823982239
ep1_train_time 16.301376342773438
Test Epoch1 threshold 0.4 Acc 0.9143092105263158, AUC 0.9798017740249634, avg_entr 0.0974879190325737
ep1_t0.4_test_time 0.10311627388000488
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad50_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.2894 (34728/120000), AUC 0.5259888768196106
ep2_train_time 16.473081350326538
Test Epoch2 threshold 0.4 Acc 0.9166118421052631, AUC 0.9805084466934204, avg_entr 0.07650487869977951
ep2_t0.4_test_time 0.10630083084106445
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad50_t0.4_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.2969833333333333 (35638/120000), AUC 0.5269500017166138
ep3_train_time 16.519686222076416
Test Epoch3 threshold 0.4 Acc 0.9167763157894737, AUC 0.9801056385040283, avg_entr 0.06616872549057007
ep3_t0.4_test_time 0.10384082794189453
gc 0
Train Epoch4 Acc 0.30335 (36402/120000), AUC 0.5274444818496704
ep4_train_time 16.275526762008667
Test Epoch4 threshold 0.4 Acc 0.9184210526315789, AUC 0.9802753925323486, avg_entr 0.059210579842329025
ep4_t0.4_test_time 0.10320496559143066
gc 0
Train Epoch5 Acc 0.308225 (36987/120000), AUC 0.5283525586128235
ep5_train_time 16.222484588623047
Test Epoch5 threshold 0.4 Acc 0.9136513157894737, AUC 0.9800131320953369, avg_entr 0.05561528354883194
ep5_t0.4_test_time 0.10263180732727051
gc 0
Train Epoch6 Acc 0.31235833333333335 (37483/120000), AUC 0.5292118787765503
ep6_train_time 16.718071222305298
Test Epoch6 threshold 0.4 Acc 0.9139802631578947, AUC 0.9798614978790283, avg_entr 0.05076706409454346
ep6_t0.4_test_time 0.10326242446899414
gc 0
Train Epoch7 Acc 0.31498333333333334 (37798/120000), AUC 0.5297749042510986
ep7_train_time 16.247771978378296
Test Epoch7 threshold 0.4 Acc 0.9136513157894737, AUC 0.9797554016113281, avg_entr 0.04818147420883179
ep7_t0.4_test_time 0.10337328910827637
gc 0
Train Epoch8 Acc 0.31680833333333336 (38017/120000), AUC 0.5303135514259338
ep8_train_time 16.401487112045288
Test Epoch8 threshold 0.4 Acc 0.9136513157894737, AUC 0.979656994342804, avg_entr 0.046624526381492615
ep8_t0.4_test_time 0.1035163402557373
gc 0
Train Epoch9 Acc 0.318475 (38217/120000), AUC 0.5308207869529724
ep9_train_time 16.388550758361816
Test Epoch9 threshold 0.4 Acc 0.9133223684210526, AUC 0.9794434309005737, avg_entr 0.044868286699056625
ep9_t0.4_test_time 0.10820341110229492
Best AUC 0.9805084466934204
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad50_t0.4_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.4 Acc 0.9263157894736842, AUC 0.9865512251853943, avg_entr 0.08012966066598892
t0.4_test_time 0.027851581573486328
