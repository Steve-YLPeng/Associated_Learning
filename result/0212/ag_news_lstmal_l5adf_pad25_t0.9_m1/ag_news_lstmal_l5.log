total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.2345 (28140/120000), AUC 0.5096533298492432
ep0_train_time 9.964077234268188
Test Epoch0 threshold 0.9 Acc 0.9098684210526315, AUC 0.9795063734054565, avg_entr 0.14885397255420685
ep0_t0.9_test_time 0.07364273071289062
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.9_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.23746666666666666 (28496/120000), AUC 0.5207499861717224
ep1_train_time 10.088081121444702
Test Epoch1 threshold 0.9 Acc 0.9115131578947369, AUC 0.9806303381919861, avg_entr 0.09534183144569397
ep1_t0.9_test_time 0.0721745491027832
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.9_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.23828333333333335 (28594/120000), AUC 0.5219268798828125
ep2_train_time 9.941046476364136
Test Epoch2 threshold 0.9 Acc 0.9139802631578947, AUC 0.9812967777252197, avg_entr 0.07505707442760468
ep2_t0.9_test_time 0.07193732261657715
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.9_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.23875 (28650/120000), AUC 0.5223351716995239
ep3_train_time 9.808410167694092
Test Epoch3 threshold 0.9 Acc 0.9131578947368421, AUC 0.9806325435638428, avg_entr 0.06552837789058685
ep3_t0.9_test_time 0.07226157188415527
gc 0
Train Epoch4 Acc 0.23986666666666667 (28784/120000), AUC 0.5231165885925293
ep4_train_time 10.056960582733154
Test Epoch4 threshold 0.9 Acc 0.9105263157894737, AUC 0.9806488752365112, avg_entr 0.058822475373744965
ep4_t0.9_test_time 0.0727543830871582
gc 0
Train Epoch5 Acc 0.24030833333333335 (28837/120000), AUC 0.5236876010894775
ep5_train_time 9.885825395584106
Test Epoch5 threshold 0.9 Acc 0.9103618421052632, AUC 0.98021399974823, avg_entr 0.05320466309785843
ep5_t0.9_test_time 0.07235431671142578
gc 0
Train Epoch6 Acc 0.2411 (28932/120000), AUC 0.5246718525886536
ep6_train_time 9.763495683670044
Test Epoch6 threshold 0.9 Acc 0.9126644736842106, AUC 0.9803426265716553, avg_entr 0.05030454695224762
ep6_t0.9_test_time 0.07189178466796875
gc 0
Train Epoch7 Acc 0.24178333333333332 (29014/120000), AUC 0.5251038074493408
ep7_train_time 10.13788366317749
Test Epoch7 threshold 0.9 Acc 0.9118421052631579, AUC 0.9800699353218079, avg_entr 0.0473504364490509
ep7_t0.9_test_time 0.07399654388427734
gc 0
Train Epoch8 Acc 0.24190833333333334 (29029/120000), AUC 0.5242419242858887
ep8_train_time 10.097059726715088
Test Epoch8 threshold 0.9 Acc 0.9105263157894737, AUC 0.9796020984649658, avg_entr 0.04570462927222252
ep8_t0.9_test_time 0.0713040828704834
gc 0
Train Epoch9 Acc 0.24210833333333334 (29053/120000), AUC 0.5235746502876282
ep9_train_time 10.087625503540039
Test Epoch9 threshold 0.9 Acc 0.9116776315789473, AUC 0.9794005751609802, avg_entr 0.043412189930677414
ep9_t0.9_test_time 0.0717003345489502
Best AUC 0.9812967777252197
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad25_t0.9_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.9 Acc 0.9197368421052632, AUC 0.985749363899231, avg_entr 0.0808144211769104
t0.9_test_time 0.019237279891967773
