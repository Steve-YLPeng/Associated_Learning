total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.24980833333333333 (29977/120000), AUC 0.4788365364074707
ep0_train_time 46.715381145477295
Test Epoch0 threshold 0.9 Acc 0.8995065789473684, AUC 0.973730206489563, avg_entr 0.18176211416721344
ep0_t0.9_test_time 0.26262927055358887
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.9_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.24813333333333334 (29776/120000), AUC 0.43505311012268066
ep1_train_time 46.771400928497314
Test Epoch1 threshold 0.9 Acc 0.9115131578947369, AUC 0.9776431918144226, avg_entr 0.10785139352083206
ep1_t0.9_test_time 0.25133585929870605
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.9_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.24708333333333332 (29650/120000), AUC 0.4369770884513855
ep2_train_time 46.73168110847473
Test Epoch2 threshold 0.9 Acc 0.912828947368421, AUC 0.9794428944587708, avg_entr 0.08102191239595413
ep2_t0.9_test_time 0.25078630447387695
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.9_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.2464 (29568/120000), AUC 0.44045981764793396
ep3_train_time 46.78078746795654
Test Epoch3 threshold 0.9 Acc 0.915296052631579, AUC 0.9801732301712036, avg_entr 0.0668095275759697
ep3_t0.9_test_time 0.24968957901000977
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.9_m1//ag_news_lstmal_l5_prefix.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.24624166666666666 (29549/120000), AUC 0.44377681612968445
ep4_train_time 46.87155628204346
Test Epoch4 threshold 0.9 Acc 0.9164473684210527, AUC 0.980528712272644, avg_entr 0.05965027958154678
ep4_t0.9_test_time 0.2488234043121338
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.9_m1//ag_news_lstmal_l5_prefix.pt  ,ep 4
gc 0
Train Epoch5 Acc 0.24574166666666666 (29489/120000), AUC 0.44627082347869873
ep5_train_time 46.716917991638184
Test Epoch5 threshold 0.9 Acc 0.915296052631579, AUC 0.9806001782417297, avg_entr 0.052974022924900055
ep5_t0.9_test_time 0.2491445541381836
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.9_m1//ag_news_lstmal_l5_prefix.pt  ,ep 5
gc 0
Train Epoch6 Acc 0.24549166666666666 (29459/120000), AUC 0.44835472106933594
ep6_train_time 46.78982758522034
Test Epoch6 threshold 0.9 Acc 0.9151315789473684, AUC 0.980591356754303, avg_entr 0.04927000775933266
ep6_t0.9_test_time 0.24962496757507324
gc 0
Train Epoch7 Acc 0.245475 (29457/120000), AUC 0.4502599537372589
ep7_train_time 46.75072240829468
Test Epoch7 threshold 0.9 Acc 0.9141447368421053, AUC 0.9805338382720947, avg_entr 0.04583578556776047
ep7_t0.9_test_time 0.25011706352233887
gc 0
Train Epoch8 Acc 0.24510833333333334 (29413/120000), AUC 0.4521011710166931
ep8_train_time 46.78567886352539
Test Epoch8 threshold 0.9 Acc 0.9167763157894737, AUC 0.9804061651229858, avg_entr 0.04350348934531212
ep8_t0.9_test_time 0.24939703941345215
gc 0
Train Epoch9 Acc 0.24494166666666667 (29393/120000), AUC 0.4527066946029663
ep9_train_time 46.80856227874756
Test Epoch9 threshold 0.9 Acc 0.9159539473684211, AUC 0.9803689122200012, avg_entr 0.04068874940276146
ep9_t0.9_test_time 0.24910950660705566
Best AUC 0.9806001782417297
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad175_t0.9_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.9 Acc 0.9256578947368421, AUC 0.9861124157905579, avg_entr 0.05483480170369148
t0.9_test_time 0.06315946578979492
