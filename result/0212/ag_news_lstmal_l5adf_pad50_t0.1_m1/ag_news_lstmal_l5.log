total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.23375 (28050/120000), AUC 0.46290621161460876
ep0_train_time 16.503034114837646
Test Epoch0 threshold 0.1 Acc 0.9105263157894737, AUC 0.9776561260223389, avg_entr 0.16075269877910614
ep0_t0.1_test_time 0.1036081314086914
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad50_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.223725 (26847/120000), AUC 0.45623624324798584
ep1_train_time 16.3719642162323
Test Epoch1 threshold 0.1 Acc 0.915625, AUC 0.9798315167427063, avg_entr 0.09685502201318741
ep1_t0.1_test_time 0.1028444766998291
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad50_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.21939166666666668 (26327/120000), AUC 0.45933759212493896
ep2_train_time 16.422048330307007
Test Epoch2 threshold 0.1 Acc 0.9126644736842106, AUC 0.9807737469673157, avg_entr 0.07955490052700043
ep2_t0.1_test_time 0.10201621055603027
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad50_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.21546666666666667 (25856/120000), AUC 0.46140021085739136
ep3_train_time 16.439733743667603
Test Epoch3 threshold 0.1 Acc 0.9149671052631579, AUC 0.9804172515869141, avg_entr 0.06781323254108429
ep3_t0.1_test_time 0.10191893577575684
gc 0
Train Epoch4 Acc 0.21245833333333333 (25495/120000), AUC 0.4630611538887024
ep4_train_time 16.475194215774536
Test Epoch4 threshold 0.1 Acc 0.9164473684210527, AUC 0.9804969429969788, avg_entr 0.059596948325634
ep4_t0.1_test_time 0.10207962989807129
gc 0
Train Epoch5 Acc 0.21023333333333333 (25228/120000), AUC 0.46388494968414307
ep5_train_time 16.423457384109497
Test Epoch5 threshold 0.1 Acc 0.9149671052631579, AUC 0.9801498651504517, avg_entr 0.056400563567876816
ep5_t0.1_test_time 0.10139656066894531
gc 0
Train Epoch6 Acc 0.208525 (25023/120000), AUC 0.46518266201019287
ep6_train_time 16.4267795085907
Test Epoch6 threshold 0.1 Acc 0.9136513157894737, AUC 0.9797693490982056, avg_entr 0.05012758821249008
ep6_t0.1_test_time 0.10198640823364258
gc 0
Train Epoch7 Acc 0.20728333333333335 (24874/120000), AUC 0.4661162197589874
ep7_train_time 16.489630699157715
Test Epoch7 threshold 0.1 Acc 0.9133223684210526, AUC 0.9797236323356628, avg_entr 0.04800504818558693
ep7_t0.1_test_time 0.1016545295715332
gc 0
Train Epoch8 Acc 0.20741666666666667 (24890/120000), AUC 0.4669853150844574
ep8_train_time 16.425403833389282
Test Epoch8 threshold 0.1 Acc 0.9126644736842106, AUC 0.979505181312561, avg_entr 0.04672846570611
ep8_t0.1_test_time 0.10310959815979004
gc 0
Train Epoch9 Acc 0.20745833333333333 (24895/120000), AUC 0.46754950284957886
ep9_train_time 16.45949411392212
Test Epoch9 threshold 0.1 Acc 0.9115131578947369, AUC 0.9794483184814453, avg_entr 0.04421291872859001
ep9_t0.1_test_time 0.10283732414245605
Best AUC 0.9807737469673157
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad50_t0.1_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.1 Acc 0.9243421052631579, AUC 0.9861668944358826, avg_entr 0.08181439340114594
t0.1_test_time 0.0262753963470459
