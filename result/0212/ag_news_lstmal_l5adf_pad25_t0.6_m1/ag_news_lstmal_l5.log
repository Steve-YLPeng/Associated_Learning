total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.24508333333333332 (29410/120000), AUC 0.4912760555744171
ep0_train_time 9.868057489395142
Test Epoch0 threshold 0.6 Acc 0.9126644736842106, AUC 0.979633629322052, avg_entr 0.15376652777194977
ep0_t0.6_test_time 0.07884907722473145
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.6_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.24234166666666668 (29081/120000), AUC 0.48881345987319946
ep1_train_time 10.097873449325562
Test Epoch1 threshold 0.6 Acc 0.912828947368421, AUC 0.9810853600502014, avg_entr 0.09350549429655075
ep1_t0.6_test_time 0.07166004180908203
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad25_t0.6_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.24158333333333334 (28990/120000), AUC 0.48886892199516296
ep2_train_time 9.787539005279541
Test Epoch2 threshold 0.6 Acc 0.9138157894736842, AUC 0.9808400273323059, avg_entr 0.07576579600572586
ep2_t0.6_test_time 0.07182097434997559
gc 0
Train Epoch3 Acc 0.24185833333333334 (29023/120000), AUC 0.488856703042984
ep3_train_time 9.88083267211914
Test Epoch3 threshold 0.6 Acc 0.9136513157894737, AUC 0.980772852897644, avg_entr 0.06431856006383896
ep3_t0.6_test_time 0.07200837135314941
gc 0
Train Epoch4 Acc 0.241575 (28989/120000), AUC 0.48865455389022827
ep4_train_time 9.781158924102783
Test Epoch4 threshold 0.6 Acc 0.9129934210526316, AUC 0.9804674386978149, avg_entr 0.058502648025751114
ep4_t0.6_test_time 0.07185792922973633
gc 0
Train Epoch5 Acc 0.24116666666666667 (28940/120000), AUC 0.48858344554901123
ep5_train_time 10.024258136749268
Test Epoch5 threshold 0.6 Acc 0.9120065789473685, AUC 0.9799620509147644, avg_entr 0.0531395822763443
ep5_t0.6_test_time 0.0713961124420166
gc 0
Train Epoch6 Acc 0.24088333333333334 (28906/120000), AUC 0.48843368887901306
ep6_train_time 9.906956911087036
Test Epoch6 threshold 0.6 Acc 0.9125, AUC 0.9801381826400757, avg_entr 0.051150333136320114
ep6_t0.6_test_time 0.07396173477172852
gc 0
Train Epoch7 Acc 0.24085833333333334 (28903/120000), AUC 0.4885835349559784
ep7_train_time 10.302115440368652
Test Epoch7 threshold 0.6 Acc 0.912828947368421, AUC 0.9798035025596619, avg_entr 0.04883682355284691
ep7_t0.6_test_time 0.07297730445861816
gc 0
Train Epoch8 Acc 0.24078333333333332 (28894/120000), AUC 0.48876121640205383
ep8_train_time 9.851869821548462
Test Epoch8 threshold 0.6 Acc 0.9116776315789473, AUC 0.9794905185699463, avg_entr 0.04703725501894951
ep8_t0.6_test_time 0.07210373878479004
gc 0
Train Epoch9 Acc 0.24078333333333332 (28894/120000), AUC 0.4888381361961365
ep9_train_time 9.85314416885376
Test Epoch9 threshold 0.6 Acc 0.9108552631578948, AUC 0.9794881939888, avg_entr 0.044316407293081284
ep9_t0.6_test_time 0.07223057746887207
Best AUC 0.9810853600502014
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad25_t0.6_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.6 Acc 0.9197368421052632, AUC 0.986129105091095, avg_entr 0.10086091607809067
t0.6_test_time 0.01889491081237793
