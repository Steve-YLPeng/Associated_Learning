total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.23244166666666666 (27893/120000), AUC 0.4676525890827179
ep0_train_time 9.809628963470459
Test Epoch0 threshold 0.7 Acc 0.9108552631578948, AUC 0.9791988134384155, avg_entr 0.14360497891902924
ep0_t0.7_test_time 0.07392549514770508
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.7_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.23956666666666668 (28748/120000), AUC 0.46175140142440796
ep1_train_time 10.075244188308716
Test Epoch1 threshold 0.7 Acc 0.9138157894736842, AUC 0.9806573987007141, avg_entr 0.093194380402565
ep1_t0.7_test_time 0.07345438003540039
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.7_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.24205 (29046/120000), AUC 0.4623414874076843
ep2_train_time 9.907051086425781
Test Epoch2 threshold 0.7 Acc 0.9120065789473685, AUC 0.9809145331382751, avg_entr 0.07568787038326263
ep2_t0.7_test_time 0.07121920585632324
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.7_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.243575 (29229/120000), AUC 0.46293655037879944
ep3_train_time 9.798861265182495
Test Epoch3 threshold 0.7 Acc 0.9115131578947369, AUC 0.9807632565498352, avg_entr 0.06404847651720047
ep3_t0.7_test_time 0.07141685485839844
gc 0
Train Epoch4 Acc 0.24465833333333334 (29359/120000), AUC 0.4631574749946594
ep4_train_time 9.856966733932495
Test Epoch4 threshold 0.7 Acc 0.9126644736842106, AUC 0.9803524613380432, avg_entr 0.05742599070072174
ep4_t0.7_test_time 0.0713348388671875
gc 0
Train Epoch5 Acc 0.24505 (29406/120000), AUC 0.463373601436615
ep5_train_time 10.006733417510986
Test Epoch5 threshold 0.7 Acc 0.9108552631578948, AUC 0.9797748923301697, avg_entr 0.05310726538300514
ep5_t0.7_test_time 0.07173442840576172
gc 0
Train Epoch6 Acc 0.245425 (29451/120000), AUC 0.4634147882461548
ep6_train_time 10.091676712036133
Test Epoch6 threshold 0.7 Acc 0.9129934210526316, AUC 0.9799329042434692, avg_entr 0.04861783608794212
ep6_t0.7_test_time 0.07162976264953613
gc 0
Train Epoch7 Acc 0.24579166666666666 (29495/120000), AUC 0.4634750485420227
ep7_train_time 10.044060230255127
Test Epoch7 threshold 0.7 Acc 0.9108552631578948, AUC 0.979640543460846, avg_entr 0.04659469425678253
ep7_t0.7_test_time 0.07378268241882324
gc 0
Train Epoch8 Acc 0.24601666666666666 (29522/120000), AUC 0.46398454904556274
ep8_train_time 9.966291666030884
Test Epoch8 threshold 0.7 Acc 0.9120065789473685, AUC 0.9796046614646912, avg_entr 0.04503745585680008
ep8_t0.7_test_time 0.07101058959960938
gc 0
Train Epoch9 Acc 0.24635833333333335 (29563/120000), AUC 0.46425047516822815
ep9_train_time 9.967309951782227
Test Epoch9 threshold 0.7 Acc 0.9115131578947369, AUC 0.9791821241378784, avg_entr 0.04282943904399872
ep9_t0.7_test_time 0.07171177864074707
Best AUC 0.9809145331382751
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adp_pad25_t0.7_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.7 Acc 0.9210526315789473, AUC 0.9859427809715271, avg_entr 0.08053494244813919
t0.7_test_time 0.01925349235534668
