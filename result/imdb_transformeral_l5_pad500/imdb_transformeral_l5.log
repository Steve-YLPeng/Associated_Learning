total count words 222751
vocab size 30000
train size 40000, valid size 5000, test size 5000
found 27937 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=2, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=2, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 256
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 256
layers.0.ae.h.0.bias 2
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13671778
init_time 21.60287070274353
Start Training
gc 0
Train Epoch0 Acc 0.54235 (21694/40000), AUC 0.5586493015289307
ep0_train_time 92.35527420043945
Test Epoch0 layer0 Acc 0.8078, AUC 0.8875405788421631, avg_entr 0.573741614818573
ep0_l0_test_time 0.5547397136688232
Save ckpt to ckpt/imdb_transformeral_l5_pad500//imdb_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.8292, AUC 0.9125608801841736, avg_entr 0.33154296875
ep0_l1_test_time 1.193155288696289
Save ckpt to ckpt/imdb_transformeral_l5_pad500//imdb_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.8236, AUC 0.9153298139572144, avg_entr 0.5044179558753967
ep0_l2_test_time 1.812727451324463
Save ckpt to ckpt/imdb_transformeral_l5_pad500//imdb_transformeral_l5.pt  ,ep 0
Test Epoch0 layer3 Acc 0.7984, AUC 0.9105809330940247, avg_entr 0.6226378679275513
ep0_l3_test_time 2.4421494007110596
Test Epoch0 layer4 Acc 0.7674, AUC 0.9133400917053223, avg_entr 0.6437320113182068
ep0_l4_test_time 3.063262462615967
gc 0
Train Epoch1 Acc 0.8637 (34548/40000), AUC 0.9321513175964355
ep1_train_time 92.03946924209595
Test Epoch1 layer0 Acc 0.882, AUC 0.9451417922973633, avg_entr 0.2942555546760559
ep1_l0_test_time 0.5518455505371094
Save ckpt to ckpt/imdb_transformeral_l5_pad500//imdb_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.888, AUC 0.9544578790664673, avg_entr 0.1804693043231964
ep1_l1_test_time 1.1848788261413574
Save ckpt to ckpt/imdb_transformeral_l5_pad500//imdb_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.8896, AUC 0.9555445909500122, avg_entr 0.15825612843036652
ep1_l2_test_time 1.8096623420715332
Save ckpt to ckpt/imdb_transformeral_l5_pad500//imdb_transformeral_l5.pt  ,ep 1
Test Epoch1 layer3 Acc 0.8892, AUC 0.9557732343673706, avg_entr 0.12948614358901978
ep1_l3_test_time 2.435136079788208
Save ckpt to ckpt/imdb_transformeral_l5_pad500//imdb_transformeral_l5.pt  ,ep 1
Test Epoch1 layer4 Acc 0.8894, AUC 0.955672025680542, avg_entr 0.11953858286142349
ep1_l4_test_time 3.0643253326416016
gc 0
Train Epoch2 Acc 0.921125 (36845/40000), AUC 0.9724905490875244
ep2_train_time 92.07920932769775
Test Epoch2 layer0 Acc 0.8932, AUC 0.9547548890113831, avg_entr 0.23065771162509918
ep2_l0_test_time 0.5518002510070801
Test Epoch2 layer1 Acc 0.8888, AUC 0.958084225654602, avg_entr 0.12173381447792053
ep2_l1_test_time 1.1861236095428467
Save ckpt to ckpt/imdb_transformeral_l5_pad500//imdb_transformeral_l5.pt  ,ep 2
Test Epoch2 layer2 Acc 0.8854, AUC 0.9580594301223755, avg_entr 0.07745255529880524
ep2_l2_test_time 1.813321590423584
Test Epoch2 layer3 Acc 0.882, AUC 0.9577261209487915, avg_entr 0.05899277329444885
ep2_l3_test_time 2.4381918907165527
Test Epoch2 layer4 Acc 0.8812, AUC 0.9583845138549805, avg_entr 0.056840602308511734
ep2_l4_test_time 3.062213897705078
Save ckpt to ckpt/imdb_transformeral_l5_pad500//imdb_transformeral_l5.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.9404 (37616/40000), AUC 0.9812755584716797
ep3_train_time 91.99017763137817
Test Epoch3 layer0 Acc 0.8964, AUC 0.9580092430114746, avg_entr 0.19843710958957672
ep3_l0_test_time 0.5586323738098145
Test Epoch3 layer1 Acc 0.893, AUC 0.9551641941070557, avg_entr 0.0681697353720665
ep3_l1_test_time 1.1903386116027832
Test Epoch3 layer2 Acc 0.892, AUC 0.9562129974365234, avg_entr 0.046200212091207504
ep3_l2_test_time 1.806351661682129
Test Epoch3 layer3 Acc 0.892, AUC 0.9561916589736938, avg_entr 0.0423208512365818
ep3_l3_test_time 2.4382269382476807
Test Epoch3 layer4 Acc 0.8914, AUC 0.9561408758163452, avg_entr 0.04099886119365692
ep3_l4_test_time 3.0649821758270264
gc 0
Train Epoch4 Acc 0.952875 (38115/40000), AUC 0.985389232635498
ep4_train_time 91.99313831329346
Test Epoch4 layer0 Acc 0.897, AUC 0.9589155912399292, avg_entr 0.1784501075744629
ep4_l0_test_time 0.5491921901702881
Save ckpt to ckpt/imdb_transformeral_l5_pad500//imdb_transformeral_l5.pt  ,ep 4
Test Epoch4 layer1 Acc 0.8912, AUC 0.9516211748123169, avg_entr 0.053150732070207596
ep4_l1_test_time 1.1840448379516602
Test Epoch4 layer2 Acc 0.8922, AUC 0.9547070264816284, avg_entr 0.038052935153245926
ep4_l2_test_time 1.8061397075653076
Test Epoch4 layer3 Acc 0.8918, AUC 0.9543914794921875, avg_entr 0.0359807163476944
ep4_l3_test_time 2.434343099594116
Test Epoch4 layer4 Acc 0.892, AUC 0.9542635679244995, avg_entr 0.03495173901319504
ep4_l4_test_time 3.0606689453125
gc 0
Train Epoch5 Acc 0.958125 (38325/40000), AUC 0.9871701002120972
ep5_train_time 91.98011803627014
Test Epoch5 layer0 Acc 0.8958, AUC 0.9585527181625366, avg_entr 0.16319547593593597
ep5_l0_test_time 0.5693244934082031
Test Epoch5 layer1 Acc 0.8856, AUC 0.9481985569000244, avg_entr 0.04629240557551384
ep5_l1_test_time 1.181230068206787
Test Epoch5 layer2 Acc 0.8866, AUC 0.9531118869781494, avg_entr 0.03258053585886955
ep5_l2_test_time 1.8104736804962158
Test Epoch5 layer3 Acc 0.8866, AUC 0.9528191089630127, avg_entr 0.03019796498119831
ep5_l3_test_time 2.439013957977295
Test Epoch5 layer4 Acc 0.8868, AUC 0.9527379274368286, avg_entr 0.02906809002161026
ep5_l4_test_time 3.063734292984009
gc 0
Train Epoch6 Acc 0.962325 (38493/40000), AUC 0.9887377023696899
ep6_train_time 92.10543966293335
Test Epoch6 layer0 Acc 0.8936, AUC 0.9574191570281982, avg_entr 0.1512904316186905
ep6_l0_test_time 0.5527422428131104
Test Epoch6 layer1 Acc 0.8808, AUC 0.9443143606185913, avg_entr 0.0402485728263855
ep6_l1_test_time 1.1831202507019043
Test Epoch6 layer2 Acc 0.8788, AUC 0.951828122138977, avg_entr 0.030975690111517906
ep6_l2_test_time 1.8086159229278564
Test Epoch6 layer3 Acc 0.8786, AUC 0.9516178369522095, avg_entr 0.030018215999007225
ep6_l3_test_time 2.4365861415863037
Test Epoch6 layer4 Acc 0.879, AUC 0.9514743089675903, avg_entr 0.02923748455941677
ep6_l4_test_time 3.060101270675659
gc 0
Train Epoch7 Acc 0.966075 (38643/40000), AUC 0.991403341293335
ep7_train_time 92.008225440979
Test Epoch7 layer0 Acc 0.8952, AUC 0.9560599327087402, avg_entr 0.1455862671136856
ep7_l0_test_time 0.559605598449707
Test Epoch7 layer1 Acc 0.8786, AUC 0.9399577379226685, avg_entr 0.03567378968000412
ep7_l1_test_time 1.191676139831543
Test Epoch7 layer2 Acc 0.88, AUC 0.9478124380111694, avg_entr 0.026606673374772072
ep7_l2_test_time 1.8108434677124023
Test Epoch7 layer3 Acc 0.8802, AUC 0.9481019377708435, avg_entr 0.02469894103705883
ep7_l3_test_time 2.434244394302368
Test Epoch7 layer4 Acc 0.8808, AUC 0.9478389024734497, avg_entr 0.023741379380226135
ep7_l4_test_time 3.0685365200042725
gc 0
Train Epoch8 Acc 0.969625 (38785/40000), AUC 0.9920903444290161
ep8_train_time 91.98674869537354
Test Epoch8 layer0 Acc 0.8862, AUC 0.9540613889694214, avg_entr 0.14427107572555542
ep8_l0_test_time 0.5461623668670654
Test Epoch8 layer1 Acc 0.8758, AUC 0.9358265399932861, avg_entr 0.0352577343583107
ep8_l1_test_time 1.182356834411621
Test Epoch8 layer2 Acc 0.8762, AUC 0.9450652003288269, avg_entr 0.02612607181072235
ep8_l2_test_time 1.8024182319641113
Test Epoch8 layer3 Acc 0.8764, AUC 0.9471293687820435, avg_entr 0.024294180795550346
ep8_l3_test_time 2.434532642364502
Test Epoch8 layer4 Acc 0.8768, AUC 0.9469947218894958, avg_entr 0.023759875446558
ep8_l4_test_time 3.06734561920166
gc 0
Train Epoch9 Acc 0.97305 (38922/40000), AUC 0.9931784272193909
ep9_train_time 91.97104907035828
Test Epoch9 layer0 Acc 0.8892, AUC 0.9532119035720825, avg_entr 0.13508324325084686
ep9_l0_test_time 0.5493040084838867
Test Epoch9 layer1 Acc 0.877, AUC 0.9339107871055603, avg_entr 0.03177598491311073
ep9_l1_test_time 1.1840834617614746
Test Epoch9 layer2 Acc 0.8786, AUC 0.9433343410491943, avg_entr 0.023956766352057457
ep9_l2_test_time 1.8032817840576172
Test Epoch9 layer3 Acc 0.8786, AUC 0.9458688497543335, avg_entr 0.022276904433965683
ep9_l3_test_time 2.433905601501465
Test Epoch9 layer4 Acc 0.8782, AUC 0.9457054138183594, avg_entr 0.021632134914398193
ep9_l4_test_time 3.059622287750244
gc 0
Train Epoch10 Acc 0.97465 (38986/40000), AUC 0.9936687350273132
ep10_train_time 91.97036361694336
Test Epoch10 layer0 Acc 0.8912, AUC 0.9522299766540527, avg_entr 0.1335260421037674
ep10_l0_test_time 0.5492517948150635
Test Epoch10 layer1 Acc 0.8764, AUC 0.9325085878372192, avg_entr 0.02975904755294323
ep10_l1_test_time 1.1772208213806152
Test Epoch10 layer2 Acc 0.8766, AUC 0.9415403604507446, avg_entr 0.022140346467494965
ep10_l2_test_time 1.8030946254730225
Test Epoch10 layer3 Acc 0.8756, AUC 0.9449445009231567, avg_entr 0.019860394299030304
ep10_l3_test_time 2.430824041366577
Test Epoch10 layer4 Acc 0.8762, AUC 0.9448203444480896, avg_entr 0.01932569034397602
ep10_l4_test_time 3.062025547027588
gc 0
Train Epoch11 Acc 0.975575 (39023/40000), AUC 0.9943414330482483
ep11_train_time 91.96874380111694
Test Epoch11 layer0 Acc 0.8866, AUC 0.9510025978088379, avg_entr 0.1296178549528122
ep11_l0_test_time 0.5497288703918457
Test Epoch11 layer1 Acc 0.8756, AUC 0.9291037321090698, avg_entr 0.029165010899305344
ep11_l1_test_time 1.1831724643707275
Test Epoch11 layer2 Acc 0.8766, AUC 0.939306378364563, avg_entr 0.022246817126870155
ep11_l2_test_time 1.8069539070129395
Test Epoch11 layer3 Acc 0.8772, AUC 0.9436129331588745, avg_entr 0.02018999122083187
ep11_l3_test_time 2.4371964931488037
Test Epoch11 layer4 Acc 0.877, AUC 0.943554162979126, avg_entr 0.019517922773957253
ep11_l4_test_time 3.076331853866577
gc 0
Train Epoch12 Acc 0.9772 (39088/40000), AUC 0.9946225881576538
ep12_train_time 91.99786257743835
Test Epoch12 layer0 Acc 0.8806, AUC 0.9496477842330933, avg_entr 0.12681160867214203
ep12_l0_test_time 0.550973653793335
Test Epoch12 layer1 Acc 0.8746, AUC 0.9269781112670898, avg_entr 0.026322253048419952
ep12_l1_test_time 1.1841485500335693
Test Epoch12 layer2 Acc 0.8742, AUC 0.9373278617858887, avg_entr 0.01919502019882202
ep12_l2_test_time 1.8063085079193115
Test Epoch12 layer3 Acc 0.8738, AUC 0.9427289366722107, avg_entr 0.017277218401432037
ep12_l3_test_time 2.4341797828674316
Test Epoch12 layer4 Acc 0.8738, AUC 0.9427706599235535, avg_entr 0.016612686216831207
ep12_l4_test_time 3.067547559738159
gc 0
Train Epoch13 Acc 0.978525 (39141/40000), AUC 0.9949591159820557
ep13_train_time 92.0998969078064
Test Epoch13 layer0 Acc 0.885, AUC 0.9489535689353943, avg_entr 0.12562620639801025
ep13_l0_test_time 0.5470271110534668
Test Epoch13 layer1 Acc 0.8718, AUC 0.9248435497283936, avg_entr 0.028459975495934486
ep13_l1_test_time 1.1806704998016357
Test Epoch13 layer2 Acc 0.871, AUC 0.9334685802459717, avg_entr 0.022082870826125145
ep13_l2_test_time 1.8038406372070312
Test Epoch13 layer3 Acc 0.8716, AUC 0.940766453742981, avg_entr 0.019930671900510788
ep13_l3_test_time 2.436354637145996
Test Epoch13 layer4 Acc 0.8712, AUC 0.9409652352333069, avg_entr 0.01935780793428421
ep13_l4_test_time 3.0615484714508057
gc 0
Train Epoch14 Acc 0.979125 (39165/40000), AUC 0.9948331117630005
ep14_train_time 92.25748920440674
Test Epoch14 layer0 Acc 0.885, AUC 0.9485615491867065, avg_entr 0.12517087161540985
ep14_l0_test_time 0.5494074821472168
Test Epoch14 layer1 Acc 0.872, AUC 0.9234750270843506, avg_entr 0.026041870936751366
ep14_l1_test_time 1.1861259937286377
Test Epoch14 layer2 Acc 0.8728, AUC 0.9336270689964294, avg_entr 0.01935722306370735
ep14_l2_test_time 1.8070530891418457
Test Epoch14 layer3 Acc 0.8738, AUC 0.9409956932067871, avg_entr 0.017494434490799904
ep14_l3_test_time 2.4522650241851807
Test Epoch14 layer4 Acc 0.8736, AUC 0.9412782788276672, avg_entr 0.016819709911942482
ep14_l4_test_time 3.075232982635498
gc 0
Train Epoch15 Acc 0.9795 (39180/40000), AUC 0.995194673538208
ep15_train_time 92.09932065010071
Test Epoch15 layer0 Acc 0.8834, AUC 0.9480383396148682, avg_entr 0.1248437762260437
ep15_l0_test_time 0.5592248439788818
Test Epoch15 layer1 Acc 0.8724, AUC 0.9224714040756226, avg_entr 0.026942547410726547
ep15_l1_test_time 1.1920123100280762
Test Epoch15 layer2 Acc 0.8732, AUC 0.9319761991500854, avg_entr 0.021109528839588165
ep15_l2_test_time 1.8191516399383545
Test Epoch15 layer3 Acc 0.8736, AUC 0.9400650262832642, avg_entr 0.01930115558207035
ep15_l3_test_time 2.4664223194122314
Test Epoch15 layer4 Acc 0.8736, AUC 0.9405338168144226, avg_entr 0.018731705844402313
ep15_l4_test_time 3.083441734313965
gc 0
Train Epoch16 Acc 0.979975 (39199/40000), AUC 0.9953941106796265
ep16_train_time 92.14334177970886
Test Epoch16 layer0 Acc 0.8824, AUC 0.9472544193267822, avg_entr 0.12368354201316833
ep16_l0_test_time 0.5537707805633545
Test Epoch16 layer1 Acc 0.8684, AUC 0.9199568033218384, avg_entr 0.024737466126680374
ep16_l1_test_time 1.1792504787445068
Test Epoch16 layer2 Acc 0.8684, AUC 0.9276961088180542, avg_entr 0.018338527530431747
ep16_l2_test_time 1.8103642463684082
Test Epoch16 layer3 Acc 0.8684, AUC 0.937962532043457, avg_entr 0.016333477571606636
ep16_l3_test_time 2.4465205669403076
Test Epoch16 layer4 Acc 0.8682, AUC 0.9391434788703918, avg_entr 0.015772102400660515
ep16_l4_test_time 3.065563678741455
gc 0
Train Epoch17 Acc 0.980875 (39235/40000), AUC 0.9956889152526855
ep17_train_time 92.13016247749329
Test Epoch17 layer0 Acc 0.8844, AUC 0.9470583200454712, avg_entr 0.12187246233224869
ep17_l0_test_time 0.5509910583496094
Test Epoch17 layer1 Acc 0.8708, AUC 0.9204150438308716, avg_entr 0.025770876556634903
ep17_l1_test_time 1.1940786838531494
Test Epoch17 layer2 Acc 0.8708, AUC 0.9283052682876587, avg_entr 0.019707636907696724
ep17_l2_test_time 1.8149473667144775
Test Epoch17 layer3 Acc 0.8706, AUC 0.9382365942001343, avg_entr 0.0177973173558712
ep17_l3_test_time 2.4427309036254883
Test Epoch17 layer4 Acc 0.8702, AUC 0.9392685890197754, avg_entr 0.01720568537712097
ep17_l4_test_time 3.0634522438049316
gc 0
Train Epoch18 Acc 0.981125 (39245/40000), AUC 0.9959090948104858
ep18_train_time 92.13897490501404
Test Epoch18 layer0 Acc 0.8842, AUC 0.9467580318450928, avg_entr 0.12058564275503159
ep18_l0_test_time 0.5522325038909912
Test Epoch18 layer1 Acc 0.871, AUC 0.9199144840240479, avg_entr 0.026085907593369484
ep18_l1_test_time 1.1807634830474854
Test Epoch18 layer2 Acc 0.8714, AUC 0.9286075830459595, avg_entr 0.01996784284710884
ep18_l2_test_time 1.8049731254577637
Test Epoch18 layer3 Acc 0.8714, AUC 0.9381676316261292, avg_entr 0.01835908740758896
ep18_l3_test_time 2.450396776199341
Test Epoch18 layer4 Acc 0.8706, AUC 0.9391512870788574, avg_entr 0.017836151644587517
ep18_l4_test_time 3.0844502449035645
gc 0
Train Epoch19 Acc 0.981125 (39245/40000), AUC 0.995692253112793
ep19_train_time 92.13934826850891
Test Epoch19 layer0 Acc 0.8816, AUC 0.9464905858039856, avg_entr 0.12029560655355453
ep19_l0_test_time 0.558837890625
Test Epoch19 layer1 Acc 0.871, AUC 0.9189776182174683, avg_entr 0.02485775016248226
ep19_l1_test_time 1.1973049640655518
Test Epoch19 layer2 Acc 0.8698, AUC 0.9266429543495178, avg_entr 0.018578171730041504
ep19_l2_test_time 1.8051683902740479
Test Epoch19 layer3 Acc 0.8696, AUC 0.9371581673622131, avg_entr 0.01694047637283802
ep19_l3_test_time 2.429776430130005
Test Epoch19 layer4 Acc 0.8694, AUC 0.9385113716125488, avg_entr 0.01636504754424095
ep19_l4_test_time 3.0579187870025635
gc 0
Train Epoch20 Acc 0.98175 (39270/40000), AUC 0.9960029125213623
ep20_train_time 92.13581991195679
Test Epoch20 layer0 Acc 0.8798, AUC 0.9460225105285645, avg_entr 0.11774173378944397
ep20_l0_test_time 0.5461208820343018
Test Epoch20 layer1 Acc 0.871, AUC 0.9184003472328186, avg_entr 0.024894384667277336
ep20_l1_test_time 1.1852545738220215
Test Epoch20 layer2 Acc 0.8702, AUC 0.9270315170288086, avg_entr 0.018934691324830055
ep20_l2_test_time 1.8105370998382568
Test Epoch20 layer3 Acc 0.8702, AUC 0.9370365142822266, avg_entr 0.017257703468203545
ep20_l3_test_time 2.431422710418701
Test Epoch20 layer4 Acc 0.87, AUC 0.9383459091186523, avg_entr 0.0167094673961401
ep20_l4_test_time 3.066786289215088
gc 0
Train Epoch21 Acc 0.98185 (39274/40000), AUC 0.9959936738014221
ep21_train_time 92.04968690872192
Test Epoch21 layer0 Acc 0.8832, AUC 0.9459515810012817, avg_entr 0.11825144290924072
ep21_l0_test_time 0.5545375347137451
Test Epoch21 layer1 Acc 0.8678, AUC 0.9179254770278931, avg_entr 0.02264770306646824
ep21_l1_test_time 1.182685375213623
Test Epoch21 layer2 Acc 0.8676, AUC 0.9244122505187988, avg_entr 0.016179561614990234
ep21_l2_test_time 1.8067524433135986
Test Epoch21 layer3 Acc 0.8676, AUC 0.9353810548782349, avg_entr 0.014555090107023716
ep21_l3_test_time 2.4348459243774414
Test Epoch21 layer4 Acc 0.8678, AUC 0.9375357627868652, avg_entr 0.013923797756433487
ep21_l4_test_time 3.0604331493377686
gc 0
Train Epoch22 Acc 0.981625 (39265/40000), AUC 0.9959490299224854
ep22_train_time 92.01704406738281
Test Epoch22 layer0 Acc 0.8832, AUC 0.945838451385498, avg_entr 0.1179368868470192
ep22_l0_test_time 0.5494909286499023
Test Epoch22 layer1 Acc 0.871, AUC 0.9177333116531372, avg_entr 0.024900203570723534
ep22_l1_test_time 1.1921439170837402
Test Epoch22 layer2 Acc 0.8708, AUC 0.9258420467376709, avg_entr 0.018986815586686134
ep22_l2_test_time 1.802271842956543
Test Epoch22 layer3 Acc 0.8704, AUC 0.9362367391586304, avg_entr 0.017489822581410408
ep22_l3_test_time 2.43310284614563
Test Epoch22 layer4 Acc 0.87, AUC 0.9378732442855835, avg_entr 0.01702459342777729
ep22_l4_test_time 3.063222646713257
gc 0
Train Epoch23 Acc 0.9825 (39300/40000), AUC 0.9960430860519409
ep23_train_time 92.02931022644043
Test Epoch23 layer0 Acc 0.8826, AUC 0.9456384181976318, avg_entr 0.11705523729324341
ep23_l0_test_time 0.5465712547302246
Test Epoch23 layer1 Acc 0.8704, AUC 0.9178004264831543, avg_entr 0.023740826174616814
ep23_l1_test_time 1.1790885925292969
Test Epoch23 layer2 Acc 0.869, AUC 0.925512433052063, avg_entr 0.017739932984113693
ep23_l2_test_time 1.8061580657958984
Test Epoch23 layer3 Acc 0.8692, AUC 0.935867965221405, avg_entr 0.016305770725011826
ep23_l3_test_time 2.442366600036621
Test Epoch23 layer4 Acc 0.8692, AUC 0.9376446008682251, avg_entr 0.01589447259902954
ep23_l4_test_time 3.064068555831909
gc 0
Train Epoch24 Acc 0.982525 (39301/40000), AUC 0.9959632754325867
ep24_train_time 92.12775611877441
Test Epoch24 layer0 Acc 0.8808, AUC 0.9455403089523315, avg_entr 0.11686652898788452
ep24_l0_test_time 0.5876333713531494
Test Epoch24 layer1 Acc 0.8686, AUC 0.9170169234275818, avg_entr 0.02291879802942276
ep24_l1_test_time 1.1813442707061768
Test Epoch24 layer2 Acc 0.8684, AUC 0.9230030179023743, avg_entr 0.01643843948841095
ep24_l2_test_time 1.8033764362335205
Test Epoch24 layer3 Acc 0.8678, AUC 0.9343973398208618, avg_entr 0.015039412304759026
ep24_l3_test_time 2.4389076232910156
Test Epoch24 layer4 Acc 0.8678, AUC 0.9369679689407349, avg_entr 0.014532887376844883
ep24_l4_test_time 3.0616250038146973
gc 0
Train Epoch25 Acc 0.9825 (39300/40000), AUC 0.9961024522781372
ep25_train_time 92.15764570236206
Test Epoch25 layer0 Acc 0.8822, AUC 0.9454599618911743, avg_entr 0.11590389162302017
ep25_l0_test_time 0.5542075634002686
Test Epoch25 layer1 Acc 0.8704, AUC 0.9171692132949829, avg_entr 0.023641295731067657
ep25_l1_test_time 1.1943128108978271
Test Epoch25 layer2 Acc 0.87, AUC 0.9250190258026123, avg_entr 0.017794029787182808
ep25_l2_test_time 1.8139004707336426
Test Epoch25 layer3 Acc 0.8704, AUC 0.9354429841041565, avg_entr 0.016411788761615753
ep25_l3_test_time 2.4335312843322754
Test Epoch25 layer4 Acc 0.8708, AUC 0.9373908638954163, avg_entr 0.015982598066329956
ep25_l4_test_time 3.0673952102661133
gc 0
Train Epoch26 Acc 0.98245 (39298/40000), AUC 0.996199369430542
ep26_train_time 92.15232014656067
Test Epoch26 layer0 Acc 0.882, AUC 0.9453794956207275, avg_entr 0.1154504120349884
ep26_l0_test_time 0.5591201782226562
Test Epoch26 layer1 Acc 0.8704, AUC 0.9167494177818298, avg_entr 0.02342132478952408
ep26_l1_test_time 1.1835944652557373
Test Epoch26 layer2 Acc 0.8694, AUC 0.9242297410964966, avg_entr 0.017546841874718666
ep26_l2_test_time 1.807760238647461
Test Epoch26 layer3 Acc 0.8696, AUC 0.9348489046096802, avg_entr 0.016153255477547646
ep26_l3_test_time 2.4409372806549072
Test Epoch26 layer4 Acc 0.8696, AUC 0.9371151924133301, avg_entr 0.015659809112548828
ep26_l4_test_time 3.0887017250061035
gc 0
Train Epoch27 Acc 0.98255 (39302/40000), AUC 0.9961968660354614
ep27_train_time 92.14141464233398
Test Epoch27 layer0 Acc 0.8814, AUC 0.9453409314155579, avg_entr 0.11485728621482849
ep27_l0_test_time 0.5479118824005127
Test Epoch27 layer1 Acc 0.8708, AUC 0.9163815975189209, avg_entr 0.023659398779273033
ep27_l1_test_time 1.1832036972045898
Test Epoch27 layer2 Acc 0.87, AUC 0.9243256449699402, avg_entr 0.017779897898435593
ep27_l2_test_time 1.806105375289917
Test Epoch27 layer3 Acc 0.8702, AUC 0.934992790222168, avg_entr 0.01639857515692711
ep27_l3_test_time 2.457180976867676
Test Epoch27 layer4 Acc 0.8704, AUC 0.9371541142463684, avg_entr 0.0159110426902771
ep27_l4_test_time 3.0730159282684326
gc 0
Train Epoch28 Acc 0.98255 (39302/40000), AUC 0.9961158037185669
ep28_train_time 92.1219048500061
Test Epoch28 layer0 Acc 0.8808, AUC 0.9451789855957031, avg_entr 0.11428488790988922
ep28_l0_test_time 0.5495254993438721
Test Epoch28 layer1 Acc 0.8708, AUC 0.916278600692749, avg_entr 0.02359156124293804
ep28_l1_test_time 1.2042779922485352
Test Epoch28 layer2 Acc 0.8696, AUC 0.9236911535263062, avg_entr 0.01780899241566658
ep28_l2_test_time 1.8066179752349854
Test Epoch28 layer3 Acc 0.87, AUC 0.9347038865089417, avg_entr 0.01646406576037407
ep28_l3_test_time 2.4397318363189697
Test Epoch28 layer4 Acc 0.8706, AUC 0.9369438290596008, avg_entr 0.016031622886657715
ep28_l4_test_time 3.071876049041748
gc 0
Train Epoch29 Acc 0.982875 (39315/40000), AUC 0.9963533878326416
ep29_train_time 92.14996004104614
Test Epoch29 layer0 Acc 0.881, AUC 0.9452412724494934, avg_entr 0.1142059788107872
ep29_l0_test_time 0.558307409286499
Test Epoch29 layer1 Acc 0.8706, AUC 0.9164365530014038, avg_entr 0.023005641996860504
ep29_l1_test_time 1.1838617324829102
Test Epoch29 layer2 Acc 0.8696, AUC 0.923608660697937, avg_entr 0.017191695049405098
ep29_l2_test_time 1.805755615234375
Test Epoch29 layer3 Acc 0.8698, AUC 0.9346331357955933, avg_entr 0.015852751210331917
ep29_l3_test_time 2.440432548522949
Test Epoch29 layer4 Acc 0.8698, AUC 0.9369379878044128, avg_entr 0.015378405340015888
ep29_l4_test_time 3.0661752223968506
gc 0
Train Epoch30 Acc 0.9828 (39312/40000), AUC 0.9961349964141846
ep30_train_time 92.19822382926941
Test Epoch30 layer0 Acc 0.882, AUC 0.9452101588249207, avg_entr 0.11396501213312149
ep30_l0_test_time 0.5488681793212891
Test Epoch30 layer1 Acc 0.87, AUC 0.9162231683731079, avg_entr 0.023125318810343742
ep30_l1_test_time 1.185354232788086
Test Epoch30 layer2 Acc 0.8696, AUC 0.9233388304710388, avg_entr 0.017402702942490578
ep30_l2_test_time 1.8089828491210938
Test Epoch30 layer3 Acc 0.8696, AUC 0.934349775314331, avg_entr 0.016106292605400085
ep30_l3_test_time 2.4429407119750977
Test Epoch30 layer4 Acc 0.8698, AUC 0.9368252754211426, avg_entr 0.015678701922297478
ep30_l4_test_time 3.070976734161377
gc 0
Train Epoch31 Acc 0.982875 (39315/40000), AUC 0.9961668848991394
ep31_train_time 92.084890127182
Test Epoch31 layer0 Acc 0.8806, AUC 0.9452036619186401, avg_entr 0.11409623920917511
ep31_l0_test_time 0.5485303401947021
Test Epoch31 layer1 Acc 0.8696, AUC 0.9163503646850586, avg_entr 0.022581100463867188
ep31_l1_test_time 1.180708408355713
Test Epoch31 layer2 Acc 0.8686, AUC 0.922902524471283, avg_entr 0.016796348616480827
ep31_l2_test_time 1.802267074584961
Test Epoch31 layer3 Acc 0.8692, AUC 0.9340550303459167, avg_entr 0.015529967844486237
ep31_l3_test_time 2.4319374561309814
Test Epoch31 layer4 Acc 0.869, AUC 0.9366470575332642, avg_entr 0.015081599354743958
ep31_l4_test_time 3.0587244033813477
gc 0
Train Epoch32 Acc 0.982975 (39319/40000), AUC 0.9962875247001648
ep32_train_time 92.13244342803955
Test Epoch32 layer0 Acc 0.882, AUC 0.9451605081558228, avg_entr 0.11342722177505493
ep32_l0_test_time 0.5509364604949951
Test Epoch32 layer1 Acc 0.8702, AUC 0.916239857673645, avg_entr 0.02275419421494007
ep32_l1_test_time 1.1832633018493652
Test Epoch32 layer2 Acc 0.8692, AUC 0.9229156970977783, avg_entr 0.017027799040079117
ep32_l2_test_time 1.8065903186798096
Test Epoch32 layer3 Acc 0.8696, AUC 0.9340183138847351, avg_entr 0.01574518345296383
ep32_l3_test_time 2.4333395957946777
Test Epoch32 layer4 Acc 0.8696, AUC 0.9366507530212402, avg_entr 0.015294010750949383
ep32_l4_test_time 3.0594279766082764
gc 0
Train Epoch33 Acc 0.983075 (39323/40000), AUC 0.9962148666381836
ep33_train_time 92.16513347625732
Test Epoch33 layer0 Acc 0.8816, AUC 0.9451503157615662, avg_entr 0.11323918402194977
ep33_l0_test_time 0.5563821792602539
Test Epoch33 layer1 Acc 0.8702, AUC 0.9161001443862915, avg_entr 0.022730199620127678
ep33_l1_test_time 1.1810369491577148
Test Epoch33 layer2 Acc 0.8694, AUC 0.9228528141975403, avg_entr 0.01708223484456539
ep33_l2_test_time 1.8200933933258057
Test Epoch33 layer3 Acc 0.8698, AUC 0.934061586856842, avg_entr 0.015783729031682014
ep33_l3_test_time 2.4438812732696533
Test Epoch33 layer4 Acc 0.8696, AUC 0.9366528987884521, avg_entr 0.01535853836685419
ep33_l4_test_time 3.085010290145874
gc 0
Train Epoch34 Acc 0.983075 (39323/40000), AUC 0.9962995052337646
ep34_train_time 104.54970502853394
Test Epoch34 layer0 Acc 0.88, AUC 0.9451481103897095, avg_entr 0.11328044533729553
ep34_l0_test_time 0.6168060302734375
Test Epoch34 layer1 Acc 0.8694, AUC 0.9161298871040344, avg_entr 0.02237571030855179
ep34_l1_test_time 1.330761432647705
Test Epoch34 layer2 Acc 0.8686, AUC 0.9225044846534729, avg_entr 0.01658633165061474
ep34_l2_test_time 2.0102930068969727
Test Epoch34 layer3 Acc 0.8688, AUC 0.9336905479431152, avg_entr 0.015303501859307289
ep34_l3_test_time 2.716463088989258
Test Epoch34 layer4 Acc 0.8688, AUC 0.9364691972732544, avg_entr 0.014845800586044788
ep34_l4_test_time 3.4466850757598877
gc 0
Train Epoch35 Acc 0.9827 (39308/40000), AUC 0.9963791370391846
ep35_train_time 104.7403814792633
Test Epoch35 layer0 Acc 0.8808, AUC 0.9451298713684082, avg_entr 0.11292049288749695
ep35_l0_test_time 0.6693332195281982
Test Epoch35 layer1 Acc 0.8698, AUC 0.9161443710327148, avg_entr 0.022195659577846527
ep35_l1_test_time 1.3495614528656006
Test Epoch35 layer2 Acc 0.868, AUC 0.922502338886261, avg_entr 0.016415448859333992
ep35_l2_test_time 2.0116496086120605
Test Epoch35 layer3 Acc 0.8682, AUC 0.9337127208709717, avg_entr 0.015184098854660988
ep35_l3_test_time 2.721569776535034
Test Epoch35 layer4 Acc 0.8682, AUC 0.9364690780639648, avg_entr 0.014741971157491207
ep35_l4_test_time 3.435082197189331
gc 0
Train Epoch36 Acc 0.982875 (39315/40000), AUC 0.9962337017059326
ep36_train_time 104.73460841178894
Test Epoch36 layer0 Acc 0.8814, AUC 0.9451220035552979, avg_entr 0.11260129511356354
ep36_l0_test_time 0.616966724395752
Test Epoch36 layer1 Acc 0.8698, AUC 0.9160335063934326, avg_entr 0.022366978228092194
ep36_l1_test_time 1.3195133209228516
Test Epoch36 layer2 Acc 0.869, AUC 0.9224932193756104, avg_entr 0.01665475219488144
ep36_l2_test_time 2.0138704776763916
Test Epoch36 layer3 Acc 0.869, AUC 0.9337749481201172, avg_entr 0.015387365594506264
ep36_l3_test_time 2.722090005874634
Test Epoch36 layer4 Acc 0.869, AUC 0.9364897012710571, avg_entr 0.014942950569093227
ep36_l4_test_time 3.4608089923858643
gc 0
Train Epoch37 Acc 0.98305 (39322/40000), AUC 0.9962401390075684
ep37_train_time 104.74074029922485
Test Epoch37 layer0 Acc 0.8814, AUC 0.9451181888580322, avg_entr 0.11249125748872757
ep37_l0_test_time 0.598980188369751
Test Epoch37 layer1 Acc 0.87, AUC 0.9160627126693726, avg_entr 0.022311130538582802
ep37_l1_test_time 1.3247473239898682
Test Epoch37 layer2 Acc 0.869, AUC 0.9224638938903809, avg_entr 0.016621852293610573
ep37_l2_test_time 2.019066095352173
Test Epoch37 layer3 Acc 0.8688, AUC 0.9336812496185303, avg_entr 0.01534581184387207
ep37_l3_test_time 2.7345986366271973
Test Epoch37 layer4 Acc 0.869, AUC 0.9364731311798096, avg_entr 0.014901087619364262
ep37_l4_test_time 3.4426944255828857
gc 0
Train Epoch38 Acc 0.9828 (39312/40000), AUC 0.9964040517807007
ep38_train_time 104.71601605415344
Test Epoch38 layer0 Acc 0.8814, AUC 0.9451146125793457, avg_entr 0.11227396130561829
ep38_l0_test_time 0.6235349178314209
Test Epoch38 layer1 Acc 0.8704, AUC 0.916043758392334, avg_entr 0.02232028916478157
ep38_l1_test_time 1.3187942504882812
Test Epoch38 layer2 Acc 0.869, AUC 0.9225523471832275, avg_entr 0.01667632907629013
ep38_l2_test_time 2.018383264541626
Test Epoch38 layer3 Acc 0.8692, AUC 0.933713972568512, avg_entr 0.015412014909088612
ep38_l3_test_time 2.7309861183166504
Test Epoch38 layer4 Acc 0.869, AUC 0.9365028142929077, avg_entr 0.01498060580343008
ep38_l4_test_time 3.4403226375579834
gc 0
Train Epoch39 Acc 0.983325 (39333/40000), AUC 0.9962615966796875
ep39_train_time 104.76932048797607
Test Epoch39 layer0 Acc 0.88, AUC 0.945121169090271, avg_entr 0.11227501183748245
ep39_l0_test_time 0.5949327945709229
Test Epoch39 layer1 Acc 0.8698, AUC 0.9160486459732056, avg_entr 0.022194236516952515
ep39_l1_test_time 1.3289976119995117
Test Epoch39 layer2 Acc 0.869, AUC 0.922441840171814, avg_entr 0.016523094847798347
ep39_l2_test_time 2.0131819248199463
Test Epoch39 layer3 Acc 0.8688, AUC 0.9336071610450745, avg_entr 0.015267445705831051
ep39_l3_test_time 2.7342567443847656
Test Epoch39 layer4 Acc 0.8688, AUC 0.9364235401153564, avg_entr 0.014822692610323429
ep39_l4_test_time 3.4413864612579346
gc 0
Train Epoch40 Acc 0.982825 (39313/40000), AUC 0.9961602091789246
ep40_train_time 104.63987636566162
Test Epoch40 layer0 Acc 0.8822, AUC 0.9451018571853638, avg_entr 0.11169718950986862
ep40_l0_test_time 0.6242275238037109
Test Epoch40 layer1 Acc 0.87, AUC 0.9159600734710693, avg_entr 0.022429849952459335
ep40_l1_test_time 1.3278284072875977
Test Epoch40 layer2 Acc 0.8694, AUC 0.9226747751235962, avg_entr 0.016840441152453423
ep40_l2_test_time 2.010712146759033
Test Epoch40 layer3 Acc 0.8698, AUC 0.9338279962539673, avg_entr 0.015566552989184856
ep40_l3_test_time 2.728682041168213
Test Epoch40 layer4 Acc 0.8692, AUC 0.9365412592887878, avg_entr 0.015133112668991089
ep40_l4_test_time 3.4479660987854004
gc 0
Train Epoch41 Acc 0.98305 (39322/40000), AUC 0.9962753057479858
ep41_train_time 104.89167737960815
Test Epoch41 layer0 Acc 0.8812, AUC 0.9451101422309875, avg_entr 0.11176801472902298
ep41_l0_test_time 0.6114976406097412
Test Epoch41 layer1 Acc 0.8698, AUC 0.9159989356994629, avg_entr 0.022315965965390205
ep41_l1_test_time 1.3284950256347656
Test Epoch41 layer2 Acc 0.8692, AUC 0.9225854873657227, avg_entr 0.016710588708519936
ep41_l2_test_time 2.016381025314331
Test Epoch41 layer3 Acc 0.8694, AUC 0.9337002635002136, avg_entr 0.015438626520335674
ep41_l3_test_time 2.724480628967285
Test Epoch41 layer4 Acc 0.8694, AUC 0.9365239143371582, avg_entr 0.015003918670117855
ep41_l4_test_time 3.449193000793457
gc 0
Train Epoch42 Acc 0.982975 (39319/40000), AUC 0.9962220191955566
ep42_train_time 104.78318238258362
Test Epoch42 layer0 Acc 0.8814, AUC 0.9451068639755249, avg_entr 0.11168565601110458
ep42_l0_test_time 0.5915524959564209
Test Epoch42 layer1 Acc 0.87, AUC 0.9160176515579224, avg_entr 0.022245552390813828
ep42_l1_test_time 1.3159644603729248
Test Epoch42 layer2 Acc 0.869, AUC 0.922553300857544, avg_entr 0.01664443127810955
ep42_l2_test_time 2.010956287384033
Test Epoch42 layer3 Acc 0.8692, AUC 0.9336645603179932, avg_entr 0.015374518930912018
ep42_l3_test_time 2.730365037918091
Test Epoch42 layer4 Acc 0.8692, AUC 0.9364780187606812, avg_entr 0.014934565871953964
ep42_l4_test_time 3.454413890838623
gc 0
Train Epoch43 Acc 0.9832 (39328/40000), AUC 0.9963685274124146
ep43_train_time 104.84528493881226
Test Epoch43 layer0 Acc 0.8814, AUC 0.9451084136962891, avg_entr 0.11158505827188492
ep43_l0_test_time 0.6012833118438721
Test Epoch43 layer1 Acc 0.8698, AUC 0.9159960150718689, avg_entr 0.022241439670324326
ep43_l1_test_time 1.3297309875488281
Test Epoch43 layer2 Acc 0.8692, AUC 0.9225144982337952, avg_entr 0.01665118895471096
ep43_l2_test_time 2.021137237548828
Test Epoch43 layer3 Acc 0.8692, AUC 0.9336836338043213, avg_entr 0.015384136699140072
ep43_l3_test_time 2.735408067703247
Test Epoch43 layer4 Acc 0.8694, AUC 0.9364858865737915, avg_entr 0.014949203468859196
ep43_l4_test_time 3.4559247493743896
gc 0
Train Epoch44 Acc 0.98325 (39330/40000), AUC 0.9964827299118042
ep44_train_time 104.78253293037415
Test Epoch44 layer0 Acc 0.8812, AUC 0.9451068639755249, avg_entr 0.1114097535610199
ep44_l0_test_time 0.6008255481719971
Test Epoch44 layer1 Acc 0.87, AUC 0.9160292148590088, avg_entr 0.02216731384396553
ep44_l1_test_time 1.3275961875915527
Test Epoch44 layer2 Acc 0.869, AUC 0.9225267171859741, avg_entr 0.01657017320394516
ep44_l2_test_time 2.030555486679077
Test Epoch44 layer3 Acc 0.8692, AUC 0.9336636662483215, avg_entr 0.015301642008125782
ep44_l3_test_time 2.726454734802246
Test Epoch44 layer4 Acc 0.8692, AUC 0.9364334344863892, avg_entr 0.01486177183687687
ep44_l4_test_time 3.4515345096588135
gc 0
Train Epoch45 Acc 0.98295 (39318/40000), AUC 0.9963464736938477
ep45_train_time 104.73871159553528
Test Epoch45 layer0 Acc 0.8814, AUC 0.9451038241386414, avg_entr 0.11136229336261749
ep45_l0_test_time 0.6353785991668701
Test Epoch45 layer1 Acc 0.87, AUC 0.9160432815551758, avg_entr 0.02205638773739338
ep45_l1_test_time 1.3297276496887207
Test Epoch45 layer2 Acc 0.869, AUC 0.9224280118942261, avg_entr 0.01644093357026577
ep45_l2_test_time 2.026202440261841
Test Epoch45 layer3 Acc 0.869, AUC 0.9335699081420898, avg_entr 0.015180349349975586
ep45_l3_test_time 2.725792169570923
Test Epoch45 layer4 Acc 0.869, AUC 0.936437726020813, avg_entr 0.014739756472408772
ep45_l4_test_time 3.4504098892211914
gc 0
Train Epoch46 Acc 0.98295 (39318/40000), AUC 0.9962674975395203
ep46_train_time 104.75686764717102
Test Epoch46 layer0 Acc 0.8814, AUC 0.9451037645339966, avg_entr 0.1112750992178917
ep46_l0_test_time 0.6062755584716797
Test Epoch46 layer1 Acc 0.8702, AUC 0.9160605669021606, avg_entr 0.02204040251672268
ep46_l1_test_time 1.3044054508209229
Test Epoch46 layer2 Acc 0.869, AUC 0.9224909543991089, avg_entr 0.0164430383592844
ep46_l2_test_time 2.0253841876983643
Test Epoch46 layer3 Acc 0.869, AUC 0.9335753917694092, avg_entr 0.015185142867267132
ep46_l3_test_time 2.7230429649353027
Test Epoch46 layer4 Acc 0.869, AUC 0.9363911151885986, avg_entr 0.014747414737939835
ep46_l4_test_time 3.4514269828796387
gc 0
Train Epoch47 Acc 0.982875 (39315/40000), AUC 0.9963217973709106
ep47_train_time 104.75598120689392
Test Epoch47 layer0 Acc 0.8812, AUC 0.9451056718826294, avg_entr 0.11117228120565414
ep47_l0_test_time 0.6120090484619141
Test Epoch47 layer1 Acc 0.8702, AUC 0.9160492420196533, avg_entr 0.022045543417334557
ep47_l1_test_time 1.3137593269348145
Test Epoch47 layer2 Acc 0.869, AUC 0.9224539995193481, avg_entr 0.01646031253039837
ep47_l2_test_time 2.007260799407959
Test Epoch47 layer3 Acc 0.869, AUC 0.9335843324661255, avg_entr 0.01519859116524458
ep47_l3_test_time 2.7387545108795166
Test Epoch47 layer4 Acc 0.869, AUC 0.9364140033721924, avg_entr 0.014760328456759453
ep47_l4_test_time 3.4472784996032715
gc 0
Train Epoch48 Acc 0.983075 (39323/40000), AUC 0.9961667060852051
ep48_train_time 104.82327699661255
Test Epoch48 layer0 Acc 0.8812, AUC 0.9451044797897339, avg_entr 0.1110537201166153
ep48_l0_test_time 0.6251988410949707
Test Epoch48 layer1 Acc 0.87, AUC 0.916045606136322, avg_entr 0.022038539871573448
ep48_l1_test_time 1.3249611854553223
Test Epoch48 layer2 Acc 0.869, AUC 0.9225375652313232, avg_entr 0.01646311953663826
ep48_l2_test_time 2.0189132690429688
Test Epoch48 layer3 Acc 0.8692, AUC 0.9336159229278564, avg_entr 0.015199891291558743
ep48_l3_test_time 2.720111608505249
Test Epoch48 layer4 Acc 0.8692, AUC 0.9364446401596069, avg_entr 0.014761049300432205
ep48_l4_test_time 3.448110342025757
gc 0
Train Epoch49 Acc 0.983025 (39321/40000), AUC 0.9963715076446533
ep49_train_time 104.74899482727051
Test Epoch49 layer0 Acc 0.8814, AUC 0.9451048970222473, avg_entr 0.11101432889699936
ep49_l0_test_time 0.6057865619659424
Test Epoch49 layer1 Acc 0.8702, AUC 0.9160729646682739, avg_entr 0.021997109055519104
ep49_l1_test_time 1.3120253086090088
Test Epoch49 layer2 Acc 0.8692, AUC 0.9224647283554077, avg_entr 0.01642276532948017
ep49_l2_test_time 2.0101990699768066
Test Epoch49 layer3 Acc 0.869, AUC 0.933624804019928, avg_entr 0.015162116847932339
ep49_l3_test_time 2.7291276454925537
Test Epoch49 layer4 Acc 0.869, AUC 0.9364492297172546, avg_entr 0.014724519103765488
ep49_l4_test_time 3.4484429359436035
Best AUC 0.9589155912399292
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train+valid_time 5280.35547041893
Start Testing
Load ckpt at ckpt/imdb_transformeral_l5_pad500//imdb_transformeral_l5.pt
Test layer0 Acc 0.8948, AUC 0.956157922744751, avg_entr 0.1787121295928955
l0_test_time 0.5999536514282227
Test layer1 Acc 0.8868, AUC 0.9485118389129639, avg_entr 0.05517292022705078
l1_test_time 1.3067960739135742
Test layer2 Acc 0.8882, AUC 0.952431321144104, avg_entr 0.038460057228803635
l2_test_time 2.012645959854126
Test layer3 Acc 0.8876, AUC 0.953137993812561, avg_entr 0.036086305975914
l3_test_time 2.7226943969726562
Test layer4 Acc 0.8878, AUC 0.9532495737075806, avg_entr 0.035030897706747055
l4_test_time 3.4387855529785156
