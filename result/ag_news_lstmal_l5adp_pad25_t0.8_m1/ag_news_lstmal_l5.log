total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.23375833333333335 (28051/120000), AUC 0.467298686504364
ep0_train_time 10.030631065368652
Test Epoch0 threshold 0.8 Acc 0.9126644736842106, AUC 0.9798439741134644, avg_entr 0.14516955614089966
ep0_t0.8_test_time 0.07364153861999512
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.8_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.23420833333333332 (28105/120000), AUC 0.4564300775527954
ep1_train_time 9.898317337036133
Test Epoch1 threshold 0.8 Acc 0.9120065789473685, AUC 0.9811609983444214, avg_entr 0.09332244098186493
ep1_t0.8_test_time 0.0722200870513916
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad25_t0.8_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.23553333333333334 (28264/120000), AUC 0.4541221261024475
ep2_train_time 10.009550094604492
Test Epoch2 threshold 0.8 Acc 0.9123355263157895, AUC 0.9808005094528198, avg_entr 0.07448554784059525
ep2_t0.8_test_time 0.07156014442443848
gc 0
Train Epoch3 Acc 0.23645 (28374/120000), AUC 0.4524921476840973
ep3_train_time 10.430718183517456
Test Epoch3 threshold 0.8 Acc 0.9123355263157895, AUC 0.9810119867324829, avg_entr 0.06581716239452362
ep3_t0.8_test_time 0.07383489608764648
gc 0
Train Epoch4 Acc 0.237075 (28449/120000), AUC 0.4511910676956177
ep4_train_time 10.168172597885132
Test Epoch4 threshold 0.8 Acc 0.9146381578947368, AUC 0.9805734753608704, avg_entr 0.0580260343849659
ep4_t0.8_test_time 0.07162022590637207
gc 0
Train Epoch5 Acc 0.23751666666666665 (28502/120000), AUC 0.4500221312046051
ep5_train_time 9.961747884750366
Test Epoch5 threshold 0.8 Acc 0.9111842105263158, AUC 0.9798598289489746, avg_entr 0.052268754690885544
ep5_t0.8_test_time 0.07236146926879883
gc 0
Train Epoch6 Acc 0.23785 (28542/120000), AUC 0.4492054879665375
ep6_train_time 9.90057921409607
Test Epoch6 threshold 0.8 Acc 0.9110197368421052, AUC 0.9799343347549438, avg_entr 0.049838125705718994
ep6_t0.8_test_time 0.0719151496887207
gc 0
Train Epoch7 Acc 0.23818333333333333 (28582/120000), AUC 0.4494277834892273
ep7_train_time 9.940907955169678
Test Epoch7 threshold 0.8 Acc 0.9113486842105263, AUC 0.9795925617218018, avg_entr 0.04837265983223915
ep7_t0.8_test_time 0.0723123550415039
gc 0
Train Epoch8 Acc 0.23859166666666667 (28631/120000), AUC 0.4494874179363251
ep8_train_time 10.11845588684082
Test Epoch8 threshold 0.8 Acc 0.9115131578947369, AUC 0.9795254468917847, avg_entr 0.04603902995586395
ep8_t0.8_test_time 0.07132649421691895
gc 0
Train Epoch9 Acc 0.238775 (28653/120000), AUC 0.44929927587509155
ep9_train_time 9.947574853897095
Test Epoch9 threshold 0.8 Acc 0.9108552631578948, AUC 0.9793941974639893, avg_entr 0.043355781584978104
ep9_t0.8_test_time 0.07415270805358887
Best AUC 0.9811609983444214
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adp_pad25_t0.8_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.8 Acc 0.9217105263157894, AUC 0.9858675599098206, avg_entr 0.09796806424856186
t0.8_test_time 0.019451379776000977
