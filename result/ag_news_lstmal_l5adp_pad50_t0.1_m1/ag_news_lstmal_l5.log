total count words 102019
vocab size 30000
found 26754 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.24296666666666666 (29156/120000), AUC 0.4342725872993469
ep0_train_time 16.650683164596558
Test Epoch0 threshold 0.1 Acc 0.9077302631578947, AUC 0.9776541590690613, avg_entr 0.15810221433639526
ep0_t0.1_test_time 0.10785222053527832
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad50_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.23558333333333334 (28270/120000), AUC 0.39236876368522644
ep1_train_time 16.626983880996704
Test Epoch1 threshold 0.1 Acc 0.9159539473684211, AUC 0.979839563369751, avg_entr 0.09821674227714539
ep1_t0.1_test_time 0.1037297248840332
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad50_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.23391666666666666 (28070/120000), AUC 0.39203760027885437
ep2_train_time 16.551013231277466
Test Epoch2 threshold 0.1 Acc 0.9151315789473684, AUC 0.9809063673019409, avg_entr 0.07650331407785416
ep2_t0.1_test_time 0.10326385498046875
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad50_t0.1_m1//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.23351666666666668 (28022/120000), AUC 0.3927556276321411
ep3_train_time 16.600711584091187
Test Epoch3 threshold 0.1 Acc 0.9141447368421053, AUC 0.980688214302063, avg_entr 0.06678086519241333
ep3_t0.1_test_time 0.10413646697998047
gc 0
Train Epoch4 Acc 0.23426666666666668 (28112/120000), AUC 0.3940839469432831
ep4_train_time 16.567870378494263
Test Epoch4 threshold 0.1 Acc 0.915296052631579, AUC 0.9805290102958679, avg_entr 0.05926616117358208
ep4_t0.1_test_time 0.10514593124389648
gc 0
Train Epoch5 Acc 0.23478333333333334 (28174/120000), AUC 0.3948974609375
ep5_train_time 16.597816705703735
Test Epoch5 threshold 0.1 Acc 0.915625, AUC 0.9802454113960266, avg_entr 0.05496189370751381
ep5_t0.1_test_time 0.10386776924133301
gc 0
Train Epoch6 Acc 0.23626666666666668 (28352/120000), AUC 0.39547061920166016
ep6_train_time 16.58215022087097
Test Epoch6 threshold 0.1 Acc 0.9143092105263158, AUC 0.979942798614502, avg_entr 0.05108627676963806
ep6_t0.1_test_time 0.10861086845397949
gc 0
Train Epoch7 Acc 0.23694166666666666 (28433/120000), AUC 0.3956117630004883
ep7_train_time 16.55958867073059
Test Epoch7 threshold 0.1 Acc 0.9141447368421053, AUC 0.9799410700798035, avg_entr 0.047887496650218964
ep7_t0.1_test_time 0.10995841026306152
gc 0
Train Epoch8 Acc 0.23726666666666665 (28472/120000), AUC 0.39698755741119385
ep8_train_time 16.60258674621582
Test Epoch8 threshold 0.1 Acc 0.9138157894736842, AUC 0.9796862602233887, avg_entr 0.044972553849220276
ep8_t0.1_test_time 0.1045527458190918
gc 0
Train Epoch9 Acc 0.23789166666666667 (28547/120000), AUC 0.3978833258152008
ep9_train_time 16.604981422424316
Test Epoch9 threshold 0.1 Acc 0.9134868421052632, AUC 0.9796538352966309, avg_entr 0.04372864589095116
ep9_t0.1_test_time 0.10322809219360352
Best AUC 0.9809063673019409
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adp_pad50_t0.1_m1//ag_news_lstmal_l5_prefix.pt
Test threshold 0.1 Acc 0.925, AUC 0.9861823320388794, avg_entr 0.08108795434236526
t0.1_test_time 0.02689504623413086
