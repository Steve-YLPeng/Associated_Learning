total count words 222751
vocab size 30000
train size 40000, valid size 5000, test size 5000
found 27937 words in glove
model: TransformerALsideText(
  (layers): ModuleList(
    (0): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=2, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=2, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
  (emb_layers): ModuleList(
    (0): Embedding(30000, 300)
    (1): Embedding(30000, 300)
    (2): Embedding(30000, 300)
    (3): Embedding(30000, 300)
    (4): Embedding(30000, 300)
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.multi_headed_attention.linears.0.weight 90000
layers.0.enc.f.multi_headed_attention.linears.0.bias 300
layers.0.enc.f.multi_headed_attention.linears.1.weight 90000
layers.0.enc.f.multi_headed_attention.linears.1.bias 300
layers.0.enc.f.multi_headed_attention.linears.2.weight 90000
layers.0.enc.f.multi_headed_attention.linears.2.bias 300
layers.0.enc.f.multi_headed_attention.linears.3.weight 90000
layers.0.enc.f.multi_headed_attention.linears.3.bias 300
layers.0.enc.f.feed_forward.w_1.weight 90000
layers.0.enc.f.feed_forward.w_1.bias 300
layers.0.enc.f.feed_forward.w_2.weight 90000
layers.0.enc.f.feed_forward.w_2.bias 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.0.enc.f.encoder.norm.a 300
layers.0.enc.f.encoder.norm.b 300
layers.0.ae.g.0.weight 256
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 256
layers.0.ae.h.0.bias 2
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
emb_layers.0.weight 9000000
emb_layers.1.weight 9000000
emb_layers.2.weight 9000000
emb_layers.3.weight 9000000
emb_layers.4.weight 9000000
Total Trainable Params: 50758378
init_time 22.959514227000003
Start Training
gc 0
Train Epoch0 Acc 0.50055 (20022/40000), AUC 0.5015392303466797
ep0_train_time 23.880808617000003
Test Epoch0 layer0 Acc 0.558, AUC 0.5743680000305176, avg_entr 0.6985729336738586, f1 0.5580000281333923
ep0_l0_test_time 0.306874932999996
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 0
Test Epoch0 layer1 Acc 0.5492, AUC 0.5833832025527954, avg_entr 0.692010760307312, f1 0.5491999983787537
ep0_l1_test_time 0.38101264299999826
Test Epoch0 layer2 Acc 0.5148, AUC 0.5261908769607544, avg_entr 0.692420244216919, f1 0.5148000121116638
ep0_l2_test_time 0.49077016399999707
Test Epoch0 layer3 Acc 0.503, AUC 0.5021629929542542, avg_entr 0.6949475407600403, f1 0.503000020980835
ep0_l3_test_time 0.6394842600000032
Test Epoch0 layer4 Acc 0.4942, AUC 0.4999721646308899, avg_entr 0.6930933594703674, f1 0.4941999912261963
ep0_l4_test_time 0.8333866899999975
gc 0
Train Epoch1 Acc 0.50855 (20342/40000), AUC 0.5128004550933838
ep1_train_time 23.450045589999995
Test Epoch1 layer0 Acc 0.5814, AUC 0.6195489168167114, avg_entr 0.6723690629005432, f1 0.5813999772071838
ep1_l0_test_time 0.31406168499999865
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 1
Test Epoch1 layer1 Acc 0.5918, AUC 0.6353361010551453, avg_entr 0.6780040860176086, f1 0.5917999744415283
ep1_l1_test_time 0.3858942819999953
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 1
Test Epoch1 layer2 Acc 0.5696, AUC 0.5975875854492188, avg_entr 0.6870620846748352, f1 0.569599986076355
ep1_l2_test_time 0.49548146100001134
Test Epoch1 layer3 Acc 0.514, AUC 0.5281784534454346, avg_entr 0.6868968605995178, f1 0.5139999985694885
ep1_l3_test_time 0.6415990759999914
Test Epoch1 layer4 Acc 0.5, AUC 0.520294189453125, avg_entr 0.691123902797699, f1 0.5
ep1_l4_test_time 0.8318948480000046
gc 0
Train Epoch2 Acc 0.526225 (21049/40000), AUC 0.5369892120361328
ep2_train_time 23.438940735000003
Test Epoch2 layer0 Acc 0.5644, AUC 0.6719595789909363, avg_entr 0.5234676003456116, f1 0.5644000172615051
ep2_l0_test_time 0.3129008549999952
Test Epoch2 layer1 Acc 0.5558, AUC 0.7161116600036621, avg_entr 0.39711180329322815, f1 0.5558000206947327
ep2_l1_test_time 0.3822865549999932
Test Epoch2 layer2 Acc 0.5396, AUC 0.7130706310272217, avg_entr 0.34480753540992737, f1 0.5396000146865845
ep2_l2_test_time 0.4952396859999908
Test Epoch2 layer3 Acc 0.5242, AUC 0.7082778215408325, avg_entr 0.49869227409362793, f1 0.5242000222206116
ep2_l3_test_time 0.6447889490000023
Test Epoch2 layer4 Acc 0.501, AUC 0.6651041507720947, avg_entr 0.6534478664398193, f1 0.5009999871253967
ep2_l4_test_time 0.8397909389999967
gc 0
Train Epoch3 Acc 0.57025 (22810/40000), AUC 0.5943709015846252
ep3_train_time 23.509622913
Test Epoch3 layer0 Acc 0.6516, AUC 0.7170010805130005, avg_entr 0.5199550986289978, f1 0.6516000032424927
ep3_l0_test_time 0.32201057099999275
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer1 Acc 0.699, AUC 0.7700591087341309, avg_entr 0.46256059408187866, f1 0.6990000009536743
ep3_l1_test_time 0.3900386219999916
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer2 Acc 0.7002, AUC 0.7741924524307251, avg_entr 0.4633132219314575, f1 0.7002000212669373
ep3_l2_test_time 0.5025728390000097
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer3 Acc 0.6754, AUC 0.7674149870872498, avg_entr 0.5015398859977722, f1 0.6754000186920166
ep3_l3_test_time 0.6500832389999971
Test Epoch3 layer4 Acc 0.5548, AUC 0.7632684707641602, avg_entr 0.44080644845962524, f1 0.5547999739646912
ep3_l4_test_time 0.838535319000016
gc 0
Train Epoch4 Acc 0.650475 (26019/40000), AUC 0.7104251980781555
ep4_train_time 23.484443512999974
Test Epoch4 layer0 Acc 0.668, AUC 0.7347403168678284, avg_entr 0.47745662927627563, f1 0.6679999828338623
ep4_l0_test_time 0.3056032310000205
Test Epoch4 layer1 Acc 0.7128, AUC 0.7887536287307739, avg_entr 0.43034014105796814, f1 0.7128000259399414
ep4_l1_test_time 0.38524493700001017
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
Test Epoch4 layer2 Acc 0.7242, AUC 0.794937014579773, avg_entr 0.42804789543151855, f1 0.7242000699043274
ep4_l2_test_time 0.49336538800000085
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
Test Epoch4 layer3 Acc 0.7216, AUC 0.7929112315177917, avg_entr 0.44116416573524475, f1 0.7215999960899353
ep4_l3_test_time 0.6412543080000148
Test Epoch4 layer4 Acc 0.7178, AUC 0.7894692420959473, avg_entr 0.46631255745887756, f1 0.7178000211715698
ep4_l4_test_time 0.8359810009999933
gc 0
Train Epoch5 Acc 0.7181 (28724/40000), AUC 0.7906754016876221
ep5_train_time 23.47378794400001
Test Epoch5 layer0 Acc 0.6686, AUC 0.7556477785110474, avg_entr 0.39202287793159485, f1 0.6686000227928162
ep5_l0_test_time 0.31001786199999515
Test Epoch5 layer1 Acc 0.6936, AUC 0.8058593273162842, avg_entr 0.31358110904693604, f1 0.6935999989509583
ep5_l1_test_time 0.38264837400001284
Test Epoch5 layer2 Acc 0.6918, AUC 0.8154603242874146, avg_entr 0.2742122709751129, f1 0.6917999982833862
ep5_l2_test_time 0.4901726740000072
Test Epoch5 layer3 Acc 0.6832, AUC 0.8152562379837036, avg_entr 0.26086118817329407, f1 0.6832000017166138
ep5_l3_test_time 0.6405366969999875
Test Epoch5 layer4 Acc 0.6764, AUC 0.8151615858078003, avg_entr 0.26414361596107483, f1 0.6764000058174133
ep5_l4_test_time 0.8383200869999996
gc 0
Train Epoch6 Acc 0.727275 (29091/40000), AUC 0.8028535842895508
ep6_train_time 23.614152773
Test Epoch6 layer0 Acc 0.6628, AUC 0.772485077381134, avg_entr 0.38350868225097656, f1 0.6628000140190125
ep6_l0_test_time 0.3124043420000078
Test Epoch6 layer1 Acc 0.7214, AUC 0.8184910416603088, avg_entr 0.3665231168270111, f1 0.7214000225067139
ep6_l1_test_time 0.3862686989999986
Test Epoch6 layer2 Acc 0.7386, AUC 0.8274866938591003, avg_entr 0.3490079343318939, f1 0.7386000156402588
ep6_l2_test_time 0.49093237200000317
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer3 Acc 0.7394, AUC 0.8272789120674133, avg_entr 0.3516544997692108, f1 0.7394000291824341
ep6_l3_test_time 0.6401435920000154
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer4 Acc 0.7456, AUC 0.8271121978759766, avg_entr 0.3772470951080322, f1 0.7455999851226807
ep6_l4_test_time 0.8349384849999808
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
gc 0
Train Epoch7 Acc 0.7546 (30184/40000), AUC 0.8322190046310425
ep7_train_time 23.554566754999996
Test Epoch7 layer0 Acc 0.703, AUC 0.7823327779769897, avg_entr 0.36919745802879333, f1 0.703000009059906
ep7_l0_test_time 0.3082886070000086
Test Epoch7 layer1 Acc 0.7318, AUC 0.8254990577697754, avg_entr 0.32693514227867126, f1 0.7318000197410583
ep7_l1_test_time 0.38079866199998946
Test Epoch7 layer2 Acc 0.7402, AUC 0.8341785669326782, avg_entr 0.33086666464805603, f1 0.7401999831199646
ep7_l2_test_time 0.4933172210000123
Test Epoch7 layer3 Acc 0.7398, AUC 0.8345272541046143, avg_entr 0.34625786542892456, f1 0.7398000359535217
ep7_l3_test_time 0.6411121359999754
Test Epoch7 layer4 Acc 0.7362, AUC 0.8347826600074768, avg_entr 0.3738254904747009, f1 0.7361999750137329
ep7_l4_test_time 0.8336476409999989
gc 0
Train Epoch8 Acc 0.77595 (31038/40000), AUC 0.856423020362854
ep8_train_time 23.481637562999992
Test Epoch8 layer0 Acc 0.7104, AUC 0.7864344716072083, avg_entr 0.33655086159706116, f1 0.7103999257087708
ep8_l0_test_time 0.3064884519999964
Test Epoch8 layer1 Acc 0.7522, AUC 0.8317095637321472, avg_entr 0.26634472608566284, f1 0.7522000074386597
ep8_l1_test_time 0.3819585520000146
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 8
Test Epoch8 layer2 Acc 0.7422, AUC 0.8424458503723145, avg_entr 0.22353947162628174, f1 0.7422000169754028
ep8_l2_test_time 0.4885764770000378
Test Epoch8 layer3 Acc 0.7176, AUC 0.8453177213668823, avg_entr 0.18743887543678284, f1 0.7175999879837036
ep8_l3_test_time 0.6373878590000004
Test Epoch8 layer4 Acc 0.6778, AUC 0.8456432819366455, avg_entr 0.15472543239593506, f1 0.6777999997138977
ep8_l4_test_time 0.8326540969999883
gc 0
Train Epoch9 Acc 0.7967 (31868/40000), AUC 0.8762814998626709
ep9_train_time 23.409157257000004
Test Epoch9 layer0 Acc 0.711, AUC 0.7904566526412964, avg_entr 0.298831969499588, f1 0.7110000848770142
ep9_l0_test_time 0.3101407510000058
Test Epoch9 layer1 Acc 0.7502, AUC 0.8356640934944153, avg_entr 0.2618620693683624, f1 0.7501999735832214
ep9_l1_test_time 0.3804333319999955
Test Epoch9 layer2 Acc 0.7508, AUC 0.8485590815544128, avg_entr 0.23079892992973328, f1 0.7508000135421753
ep9_l2_test_time 0.49011625900004674
Test Epoch9 layer3 Acc 0.7518, AUC 0.8508026599884033, avg_entr 0.22115476429462433, f1 0.751800000667572
ep9_l3_test_time 0.6386110729999928
Test Epoch9 layer4 Acc 0.7474, AUC 0.8518972396850586, avg_entr 0.21021613478660583, f1 0.7473999857902527
ep9_l4_test_time 0.8323646129999815
gc 0
Train Epoch10 Acc 0.815125 (32605/40000), AUC 0.8940504789352417
ep10_train_time 23.426064134
Test Epoch10 layer0 Acc 0.7144, AUC 0.7909227013587952, avg_entr 0.2908925414085388, f1 0.7143999934196472
ep10_l0_test_time 0.3055824189999612
Test Epoch10 layer1 Acc 0.7528, AUC 0.8378929495811462, avg_entr 0.2514544725418091, f1 0.7528000473976135
ep10_l1_test_time 0.37899753299996064
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 10
Test Epoch10 layer2 Acc 0.7572, AUC 0.8516486883163452, avg_entr 0.22111886739730835, f1 0.7572000026702881
ep10_l2_test_time 0.48710177099997054
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 10
Test Epoch10 layer3 Acc 0.755, AUC 0.854032039642334, avg_entr 0.20280751585960388, f1 0.7549999356269836
ep10_l3_test_time 0.6375234849999742
Test Epoch10 layer4 Acc 0.7494, AUC 0.8553938269615173, avg_entr 0.1806066334247589, f1 0.7494000196456909
ep10_l4_test_time 0.8312352030000056
gc 0
Train Epoch11 Acc 0.83385 (33354/40000), AUC 0.9125583171844482
ep11_train_time 23.44522761600001
Test Epoch11 layer0 Acc 0.7218, AUC 0.7931677103042603, avg_entr 0.2693733870983124, f1 0.7217999696731567
ep11_l0_test_time 0.3053167900000062
Test Epoch11 layer1 Acc 0.761, AUC 0.838962197303772, avg_entr 0.23848386108875275, f1 0.7610000371932983
ep11_l1_test_time 0.37813023999996176
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 11
Test Epoch11 layer2 Acc 0.7666, AUC 0.8509872555732727, avg_entr 0.19138388335704803, f1 0.7666000127792358
ep11_l2_test_time 0.4868245760000036
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 11
Test Epoch11 layer3 Acc 0.765, AUC 0.8525005578994751, avg_entr 0.15793611109256744, f1 0.7649999856948853
ep11_l3_test_time 0.6379089089999752
Test Epoch11 layer4 Acc 0.7652, AUC 0.8542253971099854, avg_entr 0.14440633356571198, f1 0.7652000188827515
ep11_l4_test_time 0.8304167419999544
gc 0
Train Epoch12 Acc 0.84375 (33750/40000), AUC 0.9181838035583496
ep12_train_time 23.40390139499999
Test Epoch12 layer0 Acc 0.7148, AUC 0.7901713848114014, avg_entr 0.25558924674987793, f1 0.7148000597953796
ep12_l0_test_time 0.3061754619999988
Test Epoch12 layer1 Acc 0.76, AUC 0.83842933177948, avg_entr 0.22582411766052246, f1 0.7599999904632568
ep12_l1_test_time 0.37951463999996804
Test Epoch12 layer2 Acc 0.7734, AUC 0.8515009880065918, avg_entr 0.15387621521949768, f1 0.7734000086784363
ep12_l2_test_time 0.48918417900000577
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 12
Test Epoch12 layer3 Acc 0.773, AUC 0.8531975150108337, avg_entr 0.1342102587223053, f1 0.7730000019073486
ep12_l3_test_time 0.6404958050000005
Test Epoch12 layer4 Acc 0.7728, AUC 0.8544816970825195, avg_entr 0.12709352374076843, f1 0.7728000283241272
ep12_l4_test_time 0.8320220319999976
gc 0
Train Epoch13 Acc 0.863025 (34521/40000), AUC 0.9362369775772095
ep13_train_time 23.417339346999995
Test Epoch13 layer0 Acc 0.7022, AUC 0.7913910150527954, avg_entr 0.24057137966156006, f1 0.7021999955177307
ep13_l0_test_time 0.3056046410000022
Test Epoch13 layer1 Acc 0.7442, AUC 0.8389681577682495, avg_entr 0.20367887616157532, f1 0.7441999316215515
ep13_l1_test_time 0.3848583119999489
Test Epoch13 layer2 Acc 0.7598, AUC 0.8501149415969849, avg_entr 0.13029754161834717, f1 0.7598000168800354
ep13_l2_test_time 0.49010556199999655
Test Epoch13 layer3 Acc 0.7626, AUC 0.8541737198829651, avg_entr 0.12114520370960236, f1 0.7626000046730042
ep13_l3_test_time 0.6393313190000072
Test Epoch13 layer4 Acc 0.7626, AUC 0.8552221655845642, avg_entr 0.12198812514543533, f1 0.7626000046730042
ep13_l4_test_time 0.8331072309999854
gc 0
Train Epoch14 Acc 0.87315 (34926/40000), AUC 0.9420145750045776
ep14_train_time 23.453409263000026
Test Epoch14 layer0 Acc 0.704, AUC 0.7854053974151611, avg_entr 0.2306644767522812, f1 0.7039999961853027
ep14_l0_test_time 0.3061584929999981
Test Epoch14 layer1 Acc 0.7294, AUC 0.8364899158477783, avg_entr 0.21049904823303223, f1 0.7293999791145325
ep14_l1_test_time 0.37937816100003374
Test Epoch14 layer2 Acc 0.725, AUC 0.8477680683135986, avg_entr 0.14343883097171783, f1 0.7250000238418579
ep14_l2_test_time 0.4891202559999783
Test Epoch14 layer3 Acc 0.7206, AUC 0.8518961668014526, avg_entr 0.12701675295829773, f1 0.7206000685691833
ep14_l3_test_time 0.6381784129999915
Test Epoch14 layer4 Acc 0.712, AUC 0.8504205942153931, avg_entr 0.12510985136032104, f1 0.7120000123977661
ep14_l4_test_time 0.8346597749999773
gc 0
Train Epoch15 Acc 0.89275 (35710/40000), AUC 0.9580247402191162
ep15_train_time 23.51298258899999
Test Epoch15 layer0 Acc 0.7158, AUC 0.7812694311141968, avg_entr 0.231253519654274, f1 0.7157999873161316
ep15_l0_test_time 0.3072398500000304
Test Epoch15 layer1 Acc 0.7528, AUC 0.8314186930656433, avg_entr 0.19285506010055542, f1 0.7528000473976135
ep15_l1_test_time 0.3777456200000415
Test Epoch15 layer2 Acc 0.7678, AUC 0.8440558910369873, avg_entr 0.11277469247579575, f1 0.767799973487854
ep15_l2_test_time 0.48748747399997683
Test Epoch15 layer3 Acc 0.7704, AUC 0.848199725151062, avg_entr 0.10245867818593979, f1 0.7703999280929565
ep15_l3_test_time 0.6367421009999816
Test Epoch15 layer4 Acc 0.7698, AUC 0.8489782810211182, avg_entr 0.10045528411865234, f1 0.7698000073432922
ep15_l4_test_time 0.8306393319999756
gc 0
Train Epoch16 Acc 0.91605 (36642/40000), AUC 0.9695980548858643
ep16_train_time 23.421593121
Test Epoch16 layer0 Acc 0.7138, AUC 0.7812389731407166, avg_entr 0.21221433579921722, f1 0.7138000130653381
ep16_l0_test_time 0.30402041599995755
Test Epoch16 layer1 Acc 0.7502, AUC 0.8248965740203857, avg_entr 0.179488405585289, f1 0.7501999735832214
ep16_l1_test_time 0.37736645799998314
Test Epoch16 layer2 Acc 0.7596, AUC 0.8337725400924683, avg_entr 0.09091488271951675, f1 0.7595999836921692
ep16_l2_test_time 0.48542396200002713
Test Epoch16 layer3 Acc 0.762, AUC 0.8411594033241272, avg_entr 0.0801699310541153, f1 0.7619999647140503
ep16_l3_test_time 0.6360025339999993
Test Epoch16 layer4 Acc 0.7604, AUC 0.8425922393798828, avg_entr 0.07702583819627762, f1 0.7603999972343445
ep16_l4_test_time 0.8290213330000142
gc 0
Train Epoch17 Acc 0.920375 (36815/40000), AUC 0.9733648896217346
ep17_train_time 23.41441226500001
Test Epoch17 layer0 Acc 0.7124, AUC 0.7791894674301147, avg_entr 0.20921769738197327, f1 0.712399959564209
ep17_l0_test_time 0.306089256000007
Test Epoch17 layer1 Acc 0.7508, AUC 0.8260491490364075, avg_entr 0.173437237739563, f1 0.7508000135421753
ep17_l1_test_time 0.37981823399996983
Test Epoch17 layer2 Acc 0.758, AUC 0.8320012092590332, avg_entr 0.08354217559099197, f1 0.7580000162124634
ep17_l2_test_time 0.4924447989999976
Test Epoch17 layer3 Acc 0.7572, AUC 0.8400914669036865, avg_entr 0.07470711320638657, f1 0.7572000026702881
ep17_l3_test_time 0.6380114650000337
Test Epoch17 layer4 Acc 0.7576, AUC 0.8417533040046692, avg_entr 0.0710710659623146, f1 0.7576000690460205
ep17_l4_test_time 0.8325927430000206
gc 0
Train Epoch18 Acc 0.929525 (37181/40000), AUC 0.9784983396530151
ep18_train_time 23.43118249600002
Test Epoch18 layer0 Acc 0.7082, AUC 0.7773991227149963, avg_entr 0.20461560785770416, f1 0.7081999778747559
ep18_l0_test_time 0.30369142199992893
Test Epoch18 layer1 Acc 0.7354, AUC 0.821337878704071, avg_entr 0.16312912106513977, f1 0.7354000210762024
ep18_l1_test_time 0.3774431199999526
Test Epoch18 layer2 Acc 0.7398, AUC 0.8294897079467773, avg_entr 0.08360456675291061, f1 0.7398000359535217
ep18_l2_test_time 0.4874037340000541
Test Epoch18 layer3 Acc 0.7408, AUC 0.8365648984909058, avg_entr 0.0773950070142746, f1 0.7408000230789185
ep18_l3_test_time 0.6363436770000135
Test Epoch18 layer4 Acc 0.7412, AUC 0.8386805057525635, avg_entr 0.0749826654791832, f1 0.7411999702453613
ep18_l4_test_time 0.8302518289999625
gc 0
Train Epoch19 Acc 0.936975 (37479/40000), AUC 0.9825475215911865
ep19_train_time 23.417367605000095
Test Epoch19 layer0 Acc 0.7052, AUC 0.7785788774490356, avg_entr 0.19913245737552643, f1 0.7052000164985657
ep19_l0_test_time 0.3103442099999256
Test Epoch19 layer1 Acc 0.739, AUC 0.820094108581543, avg_entr 0.14700493216514587, f1 0.7390000820159912
ep19_l1_test_time 0.3797118049999426
Test Epoch19 layer2 Acc 0.7562, AUC 0.8267992734909058, avg_entr 0.0772625282406807, f1 0.7561999559402466
ep19_l2_test_time 0.49614760800000113
Test Epoch19 layer3 Acc 0.7592, AUC 0.8359817266464233, avg_entr 0.0712558776140213, f1 0.7591999769210815
ep19_l3_test_time 0.6367853929999683
Test Epoch19 layer4 Acc 0.76, AUC 0.8368732929229736, avg_entr 0.07062621414661407, f1 0.7599999904632568
ep19_l4_test_time 0.8343035619999455
gc 0
Train Epoch20 Acc 0.9465 (37860/40000), AUC 0.9854549765586853
ep20_train_time 23.429009277999967
Test Epoch20 layer0 Acc 0.7056, AUC 0.7748739719390869, avg_entr 0.19562242925167084, f1 0.7056000232696533
ep20_l0_test_time 0.3059750310000027
Test Epoch20 layer1 Acc 0.7372, AUC 0.8141167163848877, avg_entr 0.1341281235218048, f1 0.7372000217437744
ep20_l1_test_time 0.3793546050000032
Test Epoch20 layer2 Acc 0.7468, AUC 0.8191457986831665, avg_entr 0.06720928847789764, f1 0.7468000054359436
ep20_l2_test_time 0.4965019940000275
Test Epoch20 layer3 Acc 0.7464, AUC 0.8309412002563477, avg_entr 0.06057025119662285, f1 0.7463999390602112
ep20_l3_test_time 0.6399361070000396
Test Epoch20 layer4 Acc 0.748, AUC 0.8335191011428833, avg_entr 0.058501947671175, f1 0.7480000257492065
ep20_l4_test_time 0.8318560349999871
gc 0
Train Epoch21 Acc 0.94755 (37902/40000), AUC 0.9874054193496704
ep21_train_time 23.40716945700001
Test Epoch21 layer0 Acc 0.7084, AUC 0.774247407913208, avg_entr 0.19460467994213104, f1 0.7084000110626221
ep21_l0_test_time 0.3050335199999381
Test Epoch21 layer1 Acc 0.7318, AUC 0.8117035627365112, avg_entr 0.12104596942663193, f1 0.7318000197410583
ep21_l1_test_time 0.3788387370000237
Test Epoch21 layer2 Acc 0.7446, AUC 0.8168083429336548, avg_entr 0.0670105516910553, f1 0.7445999979972839
ep21_l2_test_time 0.49017573300000095
Test Epoch21 layer3 Acc 0.7472, AUC 0.8282315731048584, avg_entr 0.05920598283410072, f1 0.747200071811676
ep21_l3_test_time 0.6371423189999632
Test Epoch21 layer4 Acc 0.7466, AUC 0.8308897018432617, avg_entr 0.05823444947600365, f1 0.7465999126434326
ep21_l4_test_time 0.8328516230000105
gc 0
Train Epoch22 Acc 0.9508 (38032/40000), AUC 0.9881289005279541
ep22_train_time 23.40908054600004
Test Epoch22 layer0 Acc 0.7078, AUC 0.7737252712249756, avg_entr 0.1880636215209961, f1 0.7077999711036682
ep22_l0_test_time 0.3041891069999565
Test Epoch22 layer1 Acc 0.7314, AUC 0.8101718425750732, avg_entr 0.1135847270488739, f1 0.7314000129699707
ep22_l1_test_time 0.37830580199999986
Test Epoch22 layer2 Acc 0.7408, AUC 0.813190221786499, avg_entr 0.06063006445765495, f1 0.7408000230789185
ep22_l2_test_time 0.4879224129999784
Test Epoch22 layer3 Acc 0.7438, AUC 0.8282654285430908, avg_entr 0.05629180744290352, f1 0.7437999248504639
ep22_l3_test_time 0.636166151999987
Test Epoch22 layer4 Acc 0.7452, AUC 0.8296340107917786, avg_entr 0.05499057099223137, f1 0.745199978351593
ep22_l4_test_time 0.8303165119999676
gc 0
Train Epoch23 Acc 0.954825 (38193/40000), AUC 0.9898501634597778
ep23_train_time 23.418689471999983
Test Epoch23 layer0 Acc 0.7062, AUC 0.7719058990478516, avg_entr 0.18332676589488983, f1 0.7062000036239624
ep23_l0_test_time 0.30487240499996915
Test Epoch23 layer1 Acc 0.7272, AUC 0.8078361749649048, avg_entr 0.10802916437387466, f1 0.7271999716758728
ep23_l1_test_time 0.37795010100001036
Test Epoch23 layer2 Acc 0.7446, AUC 0.813034176826477, avg_entr 0.06040283665060997, f1 0.7445999979972839
ep23_l2_test_time 0.4891166349999594
Test Epoch23 layer3 Acc 0.7456, AUC 0.8234415054321289, avg_entr 0.05382537841796875, f1 0.7455999851226807
ep23_l3_test_time 0.6379501810000647
Test Epoch23 layer4 Acc 0.7464, AUC 0.8275489211082458, avg_entr 0.0528886653482914, f1 0.7463999390602112
ep23_l4_test_time 0.8312823689999504
gc 0
Train Epoch24 Acc 0.9591 (38364/40000), AUC 0.9914336204528809
ep24_train_time 23.426097056999993
Test Epoch24 layer0 Acc 0.7072, AUC 0.7701692581176758, avg_entr 0.18312732875347137, f1 0.7071999907493591
ep24_l0_test_time 0.3053319000000556
Test Epoch24 layer1 Acc 0.728, AUC 0.8054379224777222, avg_entr 0.10355817526578903, f1 0.7279999852180481
ep24_l1_test_time 0.3783055220000051
Test Epoch24 layer2 Acc 0.741, AUC 0.8085329532623291, avg_entr 0.059236809611320496, f1 0.7409999370574951
ep24_l2_test_time 0.4877074940000057
Test Epoch24 layer3 Acc 0.7438, AUC 0.8236052989959717, avg_entr 0.05233043059706688, f1 0.7437999248504639
ep24_l3_test_time 0.6367406690000053
Test Epoch24 layer4 Acc 0.7432, AUC 0.8272514343261719, avg_entr 0.05116191878914833, f1 0.7432000041007996
ep24_l4_test_time 0.8317004210000505
gc 0
Train Epoch25 Acc 0.96155 (38462/40000), AUC 0.9919651746749878
ep25_train_time 23.43880723899997
Test Epoch25 layer0 Acc 0.7028, AUC 0.7698025703430176, avg_entr 0.17997123301029205, f1 0.7027999758720398
ep25_l0_test_time 0.30533351299993683
Test Epoch25 layer1 Acc 0.7202, AUC 0.8048245906829834, avg_entr 0.10697250813245773, f1 0.7202000021934509
ep25_l1_test_time 0.3782210040000109
Test Epoch25 layer2 Acc 0.7394, AUC 0.8069093227386475, avg_entr 0.06330659985542297, f1 0.7394000291824341
ep25_l2_test_time 0.4891326630000776
Test Epoch25 layer3 Acc 0.7406, AUC 0.820755660533905, avg_entr 0.05690485239028931, f1 0.7405999302864075
ep25_l3_test_time 0.6374785719999636
Test Epoch25 layer4 Acc 0.7406, AUC 0.8249915838241577, avg_entr 0.05579300969839096, f1 0.7405999302864075
ep25_l4_test_time 0.8312038190000521
gc 0
Train Epoch26 Acc 0.9613 (38452/40000), AUC 0.9920374751091003
ep26_train_time 23.403328478999924
Test Epoch26 layer0 Acc 0.705, AUC 0.7713963985443115, avg_entr 0.1784714311361313, f1 0.7049999833106995
ep26_l0_test_time 0.30413920199998756
Test Epoch26 layer1 Acc 0.7272, AUC 0.8031638860702515, avg_entr 0.09851095825433731, f1 0.7271999716758728
ep26_l1_test_time 0.37755547299991576
Test Epoch26 layer2 Acc 0.7376, AUC 0.8064451813697815, avg_entr 0.05743737891316414, f1 0.7376000285148621
ep26_l2_test_time 0.4874009659999956
Test Epoch26 layer3 Acc 0.7408, AUC 0.8209972381591797, avg_entr 0.05166752263903618, f1 0.7408000230789185
ep26_l3_test_time 0.6354817120000007
Test Epoch26 layer4 Acc 0.7412, AUC 0.8247203826904297, avg_entr 0.05092007294297218, f1 0.7411999702453613
ep26_l4_test_time 0.8307378409999728
gc 0
Train Epoch27 Acc 0.96245 (38498/40000), AUC 0.9925878643989563
ep27_train_time 23.523462776999963
Test Epoch27 layer0 Acc 0.7008, AUC 0.7695810794830322, avg_entr 0.17714346945285797, f1 0.7008000016212463
ep27_l0_test_time 0.3055675440000414
Test Epoch27 layer1 Acc 0.7258, AUC 0.8000459671020508, avg_entr 0.09351157397031784, f1 0.7257999777793884
ep27_l1_test_time 0.37922872999990886
Test Epoch27 layer2 Acc 0.738, AUC 0.8059613704681396, avg_entr 0.0554192028939724, f1 0.7379999160766602
ep27_l2_test_time 0.49127858400004243
Test Epoch27 layer3 Acc 0.7406, AUC 0.8180991411209106, avg_entr 0.051086388528347015, f1 0.7405999302864075
ep27_l3_test_time 0.6414482380000663
Test Epoch27 layer4 Acc 0.7402, AUC 0.8226219415664673, avg_entr 0.05038851872086525, f1 0.7401999831199646
ep27_l4_test_time 0.8297390150000865
gc 0
Train Epoch28 Acc 0.965475 (38619/40000), AUC 0.9934725165367126
ep28_train_time 23.498860080999975
Test Epoch28 layer0 Acc 0.7018, AUC 0.7694370150566101, avg_entr 0.17723260819911957, f1 0.7017999887466431
ep28_l0_test_time 0.31578970299995035
Test Epoch28 layer1 Acc 0.7226, AUC 0.800079345703125, avg_entr 0.0912594199180603, f1 0.722599983215332
ep28_l1_test_time 0.38519531299994014
Test Epoch28 layer2 Acc 0.7336, AUC 0.803368866443634, avg_entr 0.05094069987535477, f1 0.7335999608039856
ep28_l2_test_time 0.488164826000002
Test Epoch28 layer3 Acc 0.7366, AUC 0.8173369765281677, avg_entr 0.04534449800848961, f1 0.7365999817848206
ep28_l3_test_time 0.6361529799999062
Test Epoch28 layer4 Acc 0.737, AUC 0.8216531276702881, avg_entr 0.04468771442770958, f1 0.7369999885559082
ep28_l4_test_time 0.8306332219999604
gc 0
Train Epoch29 Acc 0.96535 (38614/40000), AUC 0.9936666488647461
ep29_train_time 23.41038021700001
Test Epoch29 layer0 Acc 0.7018, AUC 0.7686464786529541, avg_entr 0.17793941497802734, f1 0.7017999887466431
ep29_l0_test_time 0.3048539430000119
Test Epoch29 layer1 Acc 0.7238, AUC 0.801304280757904, avg_entr 0.0937110036611557, f1 0.723800003528595
ep29_l1_test_time 0.37973877199999606
Test Epoch29 layer2 Acc 0.7344, AUC 0.8050821423530579, avg_entr 0.05500944331288338, f1 0.7343999147415161
ep29_l2_test_time 0.4877543190000324
Test Epoch29 layer3 Acc 0.7384, AUC 0.8191665410995483, avg_entr 0.048748359084129333, f1 0.7384000420570374
ep29_l3_test_time 0.6391040500000145
Test Epoch29 layer4 Acc 0.7396, AUC 0.8235830068588257, avg_entr 0.04765322431921959, f1 0.7396000027656555
ep29_l4_test_time 0.8326419190000252
gc 0
Train Epoch30 Acc 0.967025 (38681/40000), AUC 0.9940600395202637
ep30_train_time 23.415212136000036
Test Epoch30 layer0 Acc 0.7034, AUC 0.7688592672348022, avg_entr 0.17682404816150665, f1 0.7034000158309937
ep30_l0_test_time 0.30556205400000636
Test Epoch30 layer1 Acc 0.7232, AUC 0.8001348376274109, avg_entr 0.09367088973522186, f1 0.7232000827789307
ep30_l1_test_time 0.37966413999993165
Test Epoch30 layer2 Acc 0.7344, AUC 0.8030073642730713, avg_entr 0.05202435329556465, f1 0.7343999147415161
ep30_l2_test_time 0.48834206600008656
Test Epoch30 layer3 Acc 0.7362, AUC 0.8167613744735718, avg_entr 0.04627429321408272, f1 0.7361999750137329
ep30_l3_test_time 0.6374320480000506
Test Epoch30 layer4 Acc 0.7372, AUC 0.8218971490859985, avg_entr 0.04506684094667435, f1 0.7372000217437744
ep30_l4_test_time 0.8320903809999436
gc 0
Train Epoch31 Acc 0.9669 (38676/40000), AUC 0.9940909147262573
ep31_train_time 23.421790565999913
Test Epoch31 layer0 Acc 0.7014, AUC 0.7680966854095459, avg_entr 0.1764114797115326, f1 0.7013999819755554
ep31_l0_test_time 0.30593934199998785
Test Epoch31 layer1 Acc 0.7202, AUC 0.7995635271072388, avg_entr 0.09078236669301987, f1 0.7202000021934509
ep31_l1_test_time 0.3800982699999622
Test Epoch31 layer2 Acc 0.734, AUC 0.7999585866928101, avg_entr 0.05052475258708, f1 0.7339999675750732
ep31_l2_test_time 0.488055777999989
Test Epoch31 layer3 Acc 0.7364, AUC 0.814499020576477, avg_entr 0.044765882194042206, f1 0.7364000082015991
ep31_l3_test_time 0.6381603869999708
Test Epoch31 layer4 Acc 0.737, AUC 0.8208101987838745, avg_entr 0.043737392872571945, f1 0.7369999885559082
ep31_l4_test_time 0.8310232830000359
gc 0
Train Epoch32 Acc 0.9681 (38724/40000), AUC 0.9946269989013672
ep32_train_time 23.434874182000044
Test Epoch32 layer0 Acc 0.7012, AUC 0.7679358720779419, avg_entr 0.17566996812820435, f1 0.701200008392334
ep32_l0_test_time 0.3055423299999802
Test Epoch32 layer1 Acc 0.7202, AUC 0.7993996143341064, avg_entr 0.08994992822408676, f1 0.7202000021934509
ep32_l1_test_time 0.3926018519999843
Test Epoch32 layer2 Acc 0.7336, AUC 0.8013429641723633, avg_entr 0.0514727421104908, f1 0.7335999608039856
ep32_l2_test_time 0.48816813099995215
Test Epoch32 layer3 Acc 0.7392, AUC 0.8146466016769409, avg_entr 0.046128589659929276, f1 0.7391999959945679
ep32_l3_test_time 0.636789641000064
Test Epoch32 layer4 Acc 0.7382, AUC 0.8208862543106079, avg_entr 0.0448840893805027, f1 0.7382000684738159
ep32_l4_test_time 0.8308106260000159
gc 0
Train Epoch33 Acc 0.96905 (38762/40000), AUC 0.9946914315223694
ep33_train_time 23.397832161999986
Test Epoch33 layer0 Acc 0.702, AUC 0.7680702209472656, avg_entr 0.17450636625289917, f1 0.7020000219345093
ep33_l0_test_time 0.3042648080000845
Test Epoch33 layer1 Acc 0.7238, AUC 0.7981529235839844, avg_entr 0.08925709873437881, f1 0.723800003528595
ep33_l1_test_time 0.3780964640000093
Test Epoch33 layer2 Acc 0.7368, AUC 0.802029013633728, avg_entr 0.0498347170650959, f1 0.7368000149726868
ep33_l2_test_time 0.48795233600003485
Test Epoch33 layer3 Acc 0.74, AUC 0.8136926293373108, avg_entr 0.04380818456411362, f1 0.7400000095367432
ep33_l3_test_time 0.6375918880000881
Test Epoch33 layer4 Acc 0.74, AUC 0.8201845288276672, avg_entr 0.042631376534700394, f1 0.7400000095367432
ep33_l4_test_time 0.8308462659999805
gc 0
Train Epoch34 Acc 0.968275 (38731/40000), AUC 0.9944723844528198
ep34_train_time 23.41695108199997
Test Epoch34 layer0 Acc 0.7016, AUC 0.7676138877868652, avg_entr 0.17455615103244781, f1 0.7016000151634216
ep34_l0_test_time 0.30604260699999486
Test Epoch34 layer1 Acc 0.7202, AUC 0.7975693941116333, avg_entr 0.08810196816921234, f1 0.7202000021934509
ep34_l1_test_time 0.3794643640000004
Test Epoch34 layer2 Acc 0.7346, AUC 0.7974385619163513, avg_entr 0.04811321571469307, f1 0.7345999479293823
ep34_l2_test_time 0.4900458859999617
Test Epoch34 layer3 Acc 0.7366, AUC 0.8118997812271118, avg_entr 0.04258515685796738, f1 0.7365999817848206
ep34_l3_test_time 0.6379967399999487
Test Epoch34 layer4 Acc 0.7372, AUC 0.8191378116607666, avg_entr 0.041726041585206985, f1 0.7372000217437744
ep34_l4_test_time 0.8305784860000358
gc 0
Train Epoch35 Acc 0.96905 (38762/40000), AUC 0.994644045829773
ep35_train_time 23.43744571100001
Test Epoch35 layer0 Acc 0.7012, AUC 0.76728755235672, avg_entr 0.17425537109375, f1 0.701200008392334
ep35_l0_test_time 0.30691913900000145
Test Epoch35 layer1 Acc 0.7234, AUC 0.7975852489471436, avg_entr 0.086606465280056, f1 0.7233999967575073
ep35_l1_test_time 0.37794004300008055
Test Epoch35 layer2 Acc 0.7354, AUC 0.7995674014091492, avg_entr 0.04813961312174797, f1 0.7354000210762024
ep35_l2_test_time 0.4899186349999809
Test Epoch35 layer3 Acc 0.737, AUC 0.8127362728118896, avg_entr 0.042652811855077744, f1 0.7369999885559082
ep35_l3_test_time 0.6368919909999704
Test Epoch35 layer4 Acc 0.7372, AUC 0.8193837404251099, avg_entr 0.04157945141196251, f1 0.7372000217437744
ep35_l4_test_time 0.8304657830000224
gc 0
Train Epoch36 Acc 0.9694 (38776/40000), AUC 0.9948136806488037
ep36_train_time 23.48663499199995
Test Epoch36 layer0 Acc 0.7014, AUC 0.7672351598739624, avg_entr 0.17394550144672394, f1 0.7013999819755554
ep36_l0_test_time 0.3051207109999723
Test Epoch36 layer1 Acc 0.7232, AUC 0.797857940196991, avg_entr 0.08818057924509048, f1 0.7232000827789307
ep36_l1_test_time 0.37800336299994797
Test Epoch36 layer2 Acc 0.7342, AUC 0.8001735210418701, avg_entr 0.04859575256705284, f1 0.7342000007629395
ep36_l2_test_time 0.4878601159999789
Test Epoch36 layer3 Acc 0.7382, AUC 0.8135954737663269, avg_entr 0.043793585151433945, f1 0.7382000684738159
ep36_l3_test_time 0.6365787110000838
Test Epoch36 layer4 Acc 0.7376, AUC 0.8197463750839233, avg_entr 0.042772676795721054, f1 0.7376000285148621
ep36_l4_test_time 0.8314319940000132
gc 0
Train Epoch37 Acc 0.96995 (38798/40000), AUC 0.9949342012405396
ep37_train_time 23.449166835000028
Test Epoch37 layer0 Acc 0.6992, AUC 0.7672898769378662, avg_entr 0.174966961145401, f1 0.6991999745368958
ep37_l0_test_time 0.30733087900000555
Test Epoch37 layer1 Acc 0.723, AUC 0.7976188659667969, avg_entr 0.08799481391906738, f1 0.7229999899864197
ep37_l1_test_time 0.3852652620000754
Test Epoch37 layer2 Acc 0.7348, AUC 0.8008847236633301, avg_entr 0.0490778423845768, f1 0.7347999811172485
ep37_l2_test_time 0.4900226390000171
Test Epoch37 layer3 Acc 0.7376, AUC 0.8135513067245483, avg_entr 0.0437193438410759, f1 0.7376000285148621
ep37_l3_test_time 0.6384852310000042
Test Epoch37 layer4 Acc 0.7382, AUC 0.8197370767593384, avg_entr 0.042603492736816406, f1 0.7382000684738159
ep37_l4_test_time 0.8333951380000144
gc 0
Train Epoch38 Acc 0.97005 (38802/40000), AUC 0.9949556589126587
ep38_train_time 23.490588434000074
Test Epoch38 layer0 Acc 0.7, AUC 0.7674949169158936, avg_entr 0.1727682203054428, f1 0.699999988079071
ep38_l0_test_time 0.3064765430001444
Test Epoch38 layer1 Acc 0.717, AUC 0.7981334924697876, avg_entr 0.0873154029250145, f1 0.7169999480247498
ep38_l1_test_time 0.3793707140000606
Test Epoch38 layer2 Acc 0.7336, AUC 0.7970561385154724, avg_entr 0.04814070463180542, f1 0.7335999608039856
ep38_l2_test_time 0.489420219999829
Test Epoch38 layer3 Acc 0.736, AUC 0.8113591074943542, avg_entr 0.04265391826629639, f1 0.7360000014305115
ep38_l3_test_time 0.6390098370000032
Test Epoch38 layer4 Acc 0.737, AUC 0.8190696239471436, avg_entr 0.04158996418118477, f1 0.7369999885559082
ep38_l4_test_time 0.8329423770001085
gc 0
Train Epoch39 Acc 0.96995 (38798/40000), AUC 0.9951863884925842
ep39_train_time 23.431527332000087
Test Epoch39 layer0 Acc 0.701, AUC 0.7671494483947754, avg_entr 0.17292465269565582, f1 0.7009999752044678
ep39_l0_test_time 0.3062558659999013
Test Epoch39 layer1 Acc 0.722, AUC 0.7966420650482178, avg_entr 0.08623502403497696, f1 0.722000002861023
ep39_l1_test_time 0.3802696019999985
Test Epoch39 layer2 Acc 0.7348, AUC 0.7976928949356079, avg_entr 0.04674138128757477, f1 0.7347999811172485
ep39_l2_test_time 0.49013558800015744
Test Epoch39 layer3 Acc 0.7364, AUC 0.81178879737854, avg_entr 0.041471052914857864, f1 0.7364000082015991
ep39_l3_test_time 0.6401189319999503
Test Epoch39 layer4 Acc 0.7364, AUC 0.8186933994293213, avg_entr 0.04029040411114693, f1 0.7364000082015991
ep39_l4_test_time 0.8368901359999654
gc 0
Train Epoch40 Acc 0.970425 (38817/40000), AUC 0.9950331449508667
ep40_train_time 23.444252749000043
Test Epoch40 layer0 Acc 0.6994, AUC 0.766997754573822, avg_entr 0.1736096292734146, f1 0.699400007724762
ep40_l0_test_time 0.30617501799997626
Test Epoch40 layer1 Acc 0.7234, AUC 0.7964819073677063, avg_entr 0.08821343630552292, f1 0.7233999967575073
ep40_l1_test_time 0.3795371809999324
Test Epoch40 layer2 Acc 0.7336, AUC 0.7999767661094666, avg_entr 0.047548770904541016, f1 0.7335999608039856
ep40_l2_test_time 0.4897220760001346
Test Epoch40 layer3 Acc 0.7362, AUC 0.8127070069313049, avg_entr 0.042461395263671875, f1 0.7361999750137329
ep40_l3_test_time 0.6387196560001485
Test Epoch40 layer4 Acc 0.7346, AUC 0.8191573619842529, avg_entr 0.04136506840586662, f1 0.7345999479293823
ep40_l4_test_time 0.8334430740001153
gc 0
Train Epoch41 Acc 0.9707 (38828/40000), AUC 0.99498450756073
ep41_train_time 23.455192275000172
Test Epoch41 layer0 Acc 0.7008, AUC 0.7669748663902283, avg_entr 0.1727425754070282, f1 0.7008000016212463
ep41_l0_test_time 0.30667139499996665
Test Epoch41 layer1 Acc 0.7212, AUC 0.7970632314682007, avg_entr 0.0865188017487526, f1 0.7211999893188477
ep41_l1_test_time 0.3798606220000238
Test Epoch41 layer2 Acc 0.7354, AUC 0.7979282736778259, avg_entr 0.04709140583872795, f1 0.7354000210762024
ep41_l2_test_time 0.48981570700016164
Test Epoch41 layer3 Acc 0.737, AUC 0.8120598793029785, avg_entr 0.041841719299554825, f1 0.7369999885559082
ep41_l3_test_time 0.6394598510000833
Test Epoch41 layer4 Acc 0.7374, AUC 0.8190380334854126, avg_entr 0.04059334099292755, f1 0.7373999953269958
ep41_l4_test_time 0.834041993000028
gc 0
Train Epoch42 Acc 0.970725 (38829/40000), AUC 0.9948421716690063
ep42_train_time 23.442631410000104
Test Epoch42 layer0 Acc 0.7002, AUC 0.7670316696166992, avg_entr 0.17270302772521973, f1 0.7002000212669373
ep42_l0_test_time 0.3047845110002072
Test Epoch42 layer1 Acc 0.7218, AUC 0.7968698740005493, avg_entr 0.08671639859676361, f1 0.7217999696731567
ep42_l1_test_time 0.37957914399999027
Test Epoch42 layer2 Acc 0.736, AUC 0.7977391481399536, avg_entr 0.04690508171916008, f1 0.7360000014305115
ep42_l2_test_time 0.4885377839998455
Test Epoch42 layer3 Acc 0.7364, AUC 0.811906635761261, avg_entr 0.04131489619612694, f1 0.7364000082015991
ep42_l3_test_time 0.6370522340000662
Test Epoch42 layer4 Acc 0.737, AUC 0.8188203573226929, avg_entr 0.04010407254099846, f1 0.7369999885559082
ep42_l4_test_time 0.8303318099999615
gc 0
Train Epoch43 Acc 0.97105 (38842/40000), AUC 0.9955530762672424
ep43_train_time 23.477918475000024
Test Epoch43 layer0 Acc 0.6988, AUC 0.7670144438743591, avg_entr 0.17238089442253113, f1 0.6988000273704529
ep43_l0_test_time 0.30592600299996775
Test Epoch43 layer1 Acc 0.7222, AUC 0.7972204089164734, avg_entr 0.08645787090063095, f1 0.7222000360488892
ep43_l1_test_time 0.3798915790000592
Test Epoch43 layer2 Acc 0.7358, AUC 0.7988227605819702, avg_entr 0.0466826856136322, f1 0.73580002784729
ep43_l2_test_time 0.48802541500003827
Test Epoch43 layer3 Acc 0.7368, AUC 0.8119944334030151, avg_entr 0.04172458127140999, f1 0.7368000149726868
ep43_l3_test_time 0.6397451200000432
Test Epoch43 layer4 Acc 0.737, AUC 0.8191041946411133, avg_entr 0.04055637866258621, f1 0.7369999885559082
ep43_l4_test_time 0.8331358410000576
gc 0
Train Epoch44 Acc 0.970225 (38809/40000), AUC 0.9951735734939575
ep44_train_time 23.525158723999994
Test Epoch44 layer0 Acc 0.6996, AUC 0.7670096158981323, avg_entr 0.17235541343688965, f1 0.6995999813079834
ep44_l0_test_time 0.3079369060001227
Test Epoch44 layer1 Acc 0.7228, AUC 0.7969988584518433, avg_entr 0.08671074360609055, f1 0.7227999567985535
ep44_l1_test_time 0.387071153000079
Test Epoch44 layer2 Acc 0.7356, AUC 0.7984944581985474, avg_entr 0.046947162598371506, f1 0.7355999946594238
ep44_l2_test_time 0.4887039210000239
Test Epoch44 layer3 Acc 0.7372, AUC 0.8119909167289734, avg_entr 0.04178962484002113, f1 0.7372000217437744
ep44_l3_test_time 0.6369939129999693
Test Epoch44 layer4 Acc 0.7368, AUC 0.8189907073974609, avg_entr 0.04063626006245613, f1 0.7368000149726868
ep44_l4_test_time 0.8311862499999734
gc 0
Train Epoch45 Acc 0.970475 (38819/40000), AUC 0.9952974915504456
ep45_train_time 23.486598852000043
Test Epoch45 layer0 Acc 0.7, AUC 0.7669913172721863, avg_entr 0.17225992679595947, f1 0.699999988079071
ep45_l0_test_time 0.30627988999981426
Test Epoch45 layer1 Acc 0.7216, AUC 0.7967612147331238, avg_entr 0.08646012842655182, f1 0.7215999960899353
ep45_l1_test_time 0.37909265300004336
Test Epoch45 layer2 Acc 0.736, AUC 0.7983689308166504, avg_entr 0.04701096937060356, f1 0.7360000014305115
ep45_l2_test_time 0.48800283900004615
Test Epoch45 layer3 Acc 0.7386, AUC 0.8118003606796265, avg_entr 0.041812874376773834, f1 0.7386000156402588
ep45_l3_test_time 0.6380207390000123
Test Epoch45 layer4 Acc 0.739, AUC 0.8189022541046143, avg_entr 0.04063395783305168, f1 0.7390000820159912
ep45_l4_test_time 0.8316922110000178
gc 0
Train Epoch46 Acc 0.9707 (38828/40000), AUC 0.9955102205276489
ep46_train_time 23.43330591600011
Test Epoch46 layer0 Acc 0.7, AUC 0.7669469118118286, avg_entr 0.17214976251125336, f1 0.699999988079071
ep46_l0_test_time 0.3056111769999461
Test Epoch46 layer1 Acc 0.7216, AUC 0.7968603372573853, avg_entr 0.0859425812959671, f1 0.7215999960899353
ep46_l1_test_time 0.37856229900012295
Test Epoch46 layer2 Acc 0.7364, AUC 0.7985600829124451, avg_entr 0.04699400067329407, f1 0.7364000082015991
ep46_l2_test_time 0.48838926100006574
Test Epoch46 layer3 Acc 0.7376, AUC 0.8116786479949951, avg_entr 0.04194742441177368, f1 0.7376000285148621
ep46_l3_test_time 0.6370397599998796
Test Epoch46 layer4 Acc 0.738, AUC 0.8188354969024658, avg_entr 0.040875144302845, f1 0.7379999160766602
ep46_l4_test_time 0.8299523220000538
gc 0
Train Epoch47 Acc 0.970375 (38815/40000), AUC 0.9953055381774902
ep47_train_time 23.48109522499999
Test Epoch47 layer0 Acc 0.7002, AUC 0.7669178247451782, avg_entr 0.17190130054950714, f1 0.7002000212669373
ep47_l0_test_time 0.30578733299989835
Test Epoch47 layer1 Acc 0.7208, AUC 0.7968580722808838, avg_entr 0.08652012795209885, f1 0.7207999229431152
ep47_l1_test_time 0.3794877320001433
Test Epoch47 layer2 Acc 0.736, AUC 0.7985879182815552, avg_entr 0.04700980335474014, f1 0.7360000014305115
ep47_l2_test_time 0.488793608999913
Test Epoch47 layer3 Acc 0.7384, AUC 0.8114882707595825, avg_entr 0.04209510609507561, f1 0.7384000420570374
ep47_l3_test_time 0.6374695169999995
Test Epoch47 layer4 Acc 0.739, AUC 0.8187891244888306, avg_entr 0.04106540232896805, f1 0.7390000820159912
ep47_l4_test_time 0.8352491110001665
gc 0
Train Epoch48 Acc 0.971625 (38865/40000), AUC 0.9954370260238647
ep48_train_time 23.477794293999978
Test Epoch48 layer0 Acc 0.6998, AUC 0.7668781280517578, avg_entr 0.17212466895580292, f1 0.6998000144958496
ep48_l0_test_time 0.30759332699994957
Test Epoch48 layer1 Acc 0.7216, AUC 0.7966939806938171, avg_entr 0.08611085265874863, f1 0.7215999960899353
ep48_l1_test_time 0.3815014249998967
Test Epoch48 layer2 Acc 0.7356, AUC 0.7984902858734131, avg_entr 0.04692240059375763, f1 0.7355999946594238
ep48_l2_test_time 0.4878652760000932
Test Epoch48 layer3 Acc 0.738, AUC 0.8115642666816711, avg_entr 0.042033348232507706, f1 0.7379999160766602
ep48_l3_test_time 0.6373642940000082
Test Epoch48 layer4 Acc 0.7386, AUC 0.8187363147735596, avg_entr 0.04099075496196747, f1 0.7386000156402588
ep48_l4_test_time 0.8308697170000414
gc 0
Train Epoch49 Acc 0.9712 (38848/40000), AUC 0.9952709674835205
ep49_train_time 23.500264736999952
Test Epoch49 layer0 Acc 0.6996, AUC 0.7668646574020386, avg_entr 0.17222201824188232, f1 0.6995999813079834
ep49_l0_test_time 0.3047886889999063
Test Epoch49 layer1 Acc 0.7226, AUC 0.7964203357696533, avg_entr 0.08627871423959732, f1 0.722599983215332
ep49_l1_test_time 0.37937830500004566
Test Epoch49 layer2 Acc 0.7362, AUC 0.7983627319335938, avg_entr 0.046796709299087524, f1 0.7361999750137329
ep49_l2_test_time 0.4877606970001125
Test Epoch49 layer3 Acc 0.7376, AUC 0.811529278755188, avg_entr 0.04191356897354126, f1 0.7376000285148621
ep49_l3_test_time 0.637104994000083
Test Epoch49 layer4 Acc 0.737, AUC 0.81867516040802, avg_entr 0.040866874158382416, f1 0.7369999885559082
ep49_l4_test_time 0.8317298469999059
Best AUC tensor(0.7734) 12 2
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
total_train+valid_time 1312.380402452
Start Testing
Load ckpt at ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt
gc 9
Test layer0 Acc 0.7254, AUC 0.8046913146972656, avg_entr 0.25748199224472046, f1 0.7253999710083008
l0_test_time 0.3093977400001222
gc 0
Test layer1 Acc 0.7638, AUC 0.8493842482566833, avg_entr 0.22692863643169403, f1 0.7638000249862671
l1_test_time 0.3798006130000431
gc 0
Test layer2 Acc 0.779, AUC 0.8633129596710205, avg_entr 0.15904152393341064, f1 0.7789999842643738
l2_test_time 0.48768114100016646
gc 0
Test layer3 Acc 0.78, AUC 0.8643772006034851, avg_entr 0.1398005187511444, f1 0.7799999117851257
l3_test_time 0.6422353479999856
gc 0
Test layer4 Acc 0.7804, AUC 0.8666229248046875, avg_entr 0.13275711238384247, f1 0.7803999781608582
l4_test_time 0.8360559340001146
gc 0
Test threshold 0.1 Acc 0.7796, AUC 0.8505642414093018, avg_entr 0.1901247650384903, f1 0.7796000838279724
t0.1_test_time 0.62515653499986
gc 0
Test threshold 0.2 Acc 0.7798, AUC 0.8456230163574219, avg_entr 0.19986727833747864, f1 0.7797999978065491
t0.2_test_time 0.5627005670000926
gc 0
Test threshold 0.3 Acc 0.7772, AUC 0.8415597677230835, avg_entr 0.21011902391910553, f1 0.777199923992157
t0.3_test_time 0.524051886000052
gc 0
Test threshold 0.4 Acc 0.7736, AUC 0.8375535607337952, avg_entr 0.223823681473732, f1 0.7735999822616577
t0.4_test_time 0.4909888570000476
gc 0
Test threshold 0.5 Acc 0.7704, AUC 0.8330370187759399, avg_entr 0.23746144771575928, f1 0.7703999280929565
t0.5_test_time 0.4694567009998991
gc 0
Test threshold 0.6 Acc 0.7678, AUC 0.8285517692565918, avg_entr 0.2527617812156677, f1 0.767799973487854
t0.6_test_time 0.4425243819998741
gc 0
Test threshold 0.7 Acc 0.7612, AUC 0.823865532875061, avg_entr 0.268938273191452, f1 0.7612000107765198
t0.7_test_time 0.41978087999996205
gc 0
Test threshold 0.8 Acc 0.7548, AUC 0.8199145197868347, avg_entr 0.2894400954246521, f1 0.754800021648407
t0.8_test_time 0.4028221369999301
gc 0
Test threshold 0.9 Acc 0.7496, AUC 0.8163054585456848, avg_entr 0.31369301676750183, f1 0.7495999932289124
t0.9_test_time 0.39004031700005726
