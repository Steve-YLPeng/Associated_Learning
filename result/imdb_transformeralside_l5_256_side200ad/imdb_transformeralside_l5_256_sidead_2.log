total count words 222751
vocab size 30000
train size 40000, valid size 5000, test size 5000
found 27937 words in glove
model: TransformerALsideText(
  (layers): ModuleList(
    (0): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=2, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=2, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
  (emb_layers): ModuleList(
    (0): Embedding(30000, 300)
    (1): Embedding(30000, 300)
    (2): Embedding(30000, 300)
    (3): Embedding(30000, 300)
    (4): Embedding(30000, 300)
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.multi_headed_attention.linears.0.weight 90000
layers.0.enc.f.multi_headed_attention.linears.0.bias 300
layers.0.enc.f.multi_headed_attention.linears.1.weight 90000
layers.0.enc.f.multi_headed_attention.linears.1.bias 300
layers.0.enc.f.multi_headed_attention.linears.2.weight 90000
layers.0.enc.f.multi_headed_attention.linears.2.bias 300
layers.0.enc.f.multi_headed_attention.linears.3.weight 90000
layers.0.enc.f.multi_headed_attention.linears.3.bias 300
layers.0.enc.f.feed_forward.w_1.weight 90000
layers.0.enc.f.feed_forward.w_1.bias 300
layers.0.enc.f.feed_forward.w_2.weight 90000
layers.0.enc.f.feed_forward.w_2.bias 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.0.enc.f.encoder.norm.a 300
layers.0.enc.f.encoder.norm.b 300
layers.0.ae.g.0.weight 256
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 256
layers.0.ae.h.0.bias 2
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
emb_layers.0.weight 9000000
emb_layers.1.weight 9000000
emb_layers.2.weight 9000000
emb_layers.3.weight 9000000
emb_layers.4.weight 9000000
Total Trainable Params: 50758378
init_time 22.57649237
Start Training
gc 0
Train Epoch0 Acc 0.504725 (20189/40000), AUC 0.5037779808044434
ep0_train_time 23.796461718000003
Test Epoch0 layer0 Acc 0.5146, AUC 0.554730236530304, avg_entr 0.6925370693206787, f1 0.5145999789237976
ep0_l0_test_time 0.30477964299999627
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 0
Test Epoch0 layer1 Acc 0.523, AUC 0.5344998836517334, avg_entr 0.6911649703979492, f1 0.5230000019073486
ep0_l1_test_time 0.37723993200000194
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 0
Test Epoch0 layer2 Acc 0.52, AUC 0.5354630351066589, avg_entr 0.6947913765907288, f1 0.5199999809265137
ep0_l2_test_time 0.48653118200000023
Test Epoch0 layer3 Acc 0.5004, AUC 0.5375691652297974, avg_entr 0.6892317533493042, f1 0.5004000067710876
ep0_l3_test_time 0.6369871289999978
Test Epoch0 layer4 Acc 0.5184, AUC 0.5120521783828735, avg_entr 0.6960453391075134, f1 0.5184000134468079
ep0_l4_test_time 0.8278797250000025
gc 0
Train Epoch1 Acc 0.514675 (20587/40000), AUC 0.5193103551864624
ep1_train_time 23.302531676
Test Epoch1 layer0 Acc 0.584, AUC 0.6189781427383423, avg_entr 0.6659256219863892, f1 0.5839999914169312
ep1_l0_test_time 0.3070165120000041
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 1
Test Epoch1 layer1 Acc 0.5732, AUC 0.6399787664413452, avg_entr 0.6847103238105774, f1 0.573199987411499
ep1_l1_test_time 0.3807483190000056
Test Epoch1 layer2 Acc 0.577, AUC 0.6099082827568054, avg_entr 0.696007490158081, f1 0.5770000219345093
ep1_l2_test_time 0.4884533450000106
Test Epoch1 layer3 Acc 0.5316, AUC 0.5476450324058533, avg_entr 0.6910706758499146, f1 0.5315999984741211
ep1_l3_test_time 0.6382273950000013
Test Epoch1 layer4 Acc 0.4996, AUC 0.5301309823989868, avg_entr 0.6897286772727966, f1 0.49959999322891235
ep1_l4_test_time 0.830252373999997
gc 0
Train Epoch2 Acc 0.5247 (20988/40000), AUC 0.5331568717956543
ep2_train_time 23.358243435999995
Test Epoch2 layer0 Acc 0.6036, AUC 0.6726228594779968, avg_entr 0.5888422131538391, f1 0.603600025177002
ep2_l0_test_time 0.30708169900000826
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 2
Test Epoch2 layer1 Acc 0.64, AUC 0.7012712955474854, avg_entr 0.6188817024230957, f1 0.6399999856948853
ep2_l1_test_time 0.3795470039999884
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 2
Test Epoch2 layer2 Acc 0.6448, AUC 0.7115602493286133, avg_entr 0.665972113609314, f1 0.6448000073432922
ep2_l2_test_time 0.4897335880000071
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 2
Test Epoch2 layer3 Acc 0.5, AUC 0.7111271619796753, avg_entr 0.6319035887718201, f1 0.5
ep2_l3_test_time 0.6376846959999938
Test Epoch2 layer4 Acc 0.5, AUC 0.6602827310562134, avg_entr 0.6505922079086304, f1 0.5
ep2_l4_test_time 0.8304880920000102
gc 0
Train Epoch3 Acc 0.5663 (22652/40000), AUC 0.5900722742080688
ep3_train_time 23.39164665
Test Epoch3 layer0 Acc 0.6156, AUC 0.7030917406082153, avg_entr 0.48338910937309265, f1 0.6155999898910522
ep3_l0_test_time 0.3073534220000056
Test Epoch3 layer1 Acc 0.6628, AUC 0.7346283197402954, avg_entr 0.4806821346282959, f1 0.6628000140190125
ep3_l1_test_time 0.3805948020000045
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer2 Acc 0.6718, AUC 0.7404345870018005, avg_entr 0.5099523663520813, f1 0.6718000173568726
ep3_l2_test_time 0.4898765130000129
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer3 Acc 0.6646, AUC 0.7403250932693481, avg_entr 0.5639758110046387, f1 0.6646000146865845
ep3_l3_test_time 0.6401188409999747
Test Epoch3 layer4 Acc 0.5026, AUC 0.7401067018508911, avg_entr 0.43885859847068787, f1 0.5026000142097473
ep3_l4_test_time 0.8324484239999776
gc 0
Train Epoch4 Acc 0.6251 (25004/40000), AUC 0.6771243810653687
ep4_train_time 23.33751076599998
Test Epoch4 layer0 Acc 0.651, AUC 0.7294009327888489, avg_entr 0.451951801776886, f1 0.6510000228881836
ep4_l0_test_time 0.3062156590000029
Test Epoch4 layer1 Acc 0.6626, AUC 0.7705330848693848, avg_entr 0.38355591893196106, f1 0.6625999808311462
ep4_l1_test_time 0.37880601899999533
Test Epoch4 layer2 Acc 0.6242, AUC 0.7780728936195374, avg_entr 0.33375874161720276, f1 0.6241999864578247
ep4_l2_test_time 0.4894396189999952
Test Epoch4 layer3 Acc 0.5856, AUC 0.7774200439453125, avg_entr 0.2895065248012543, f1 0.5856000185012817
ep4_l3_test_time 0.6368848589999914
Test Epoch4 layer4 Acc 0.525, AUC 0.7778607606887817, avg_entr 0.1904841810464859, f1 0.5249999761581421
ep4_l4_test_time 0.8315282510000088
gc 0
Train Epoch5 Acc 0.68855 (27542/40000), AUC 0.7510765790939331
ep5_train_time 23.362644132000014
Test Epoch5 layer0 Acc 0.6624, AUC 0.7523615956306458, avg_entr 0.3802117705345154, f1 0.6624000072479248
ep5_l0_test_time 0.3060925600000246
Test Epoch5 layer1 Acc 0.6544, AUC 0.7895785570144653, avg_entr 0.3035462498664856, f1 0.6543999910354614
ep5_l1_test_time 0.37872595499999306
Test Epoch5 layer2 Acc 0.6066, AUC 0.7987232208251953, avg_entr 0.2590547800064087, f1 0.6065999865531921
ep5_l2_test_time 0.48895732599999064
Test Epoch5 layer3 Acc 0.567, AUC 0.8012126088142395, avg_entr 0.22624355554580688, f1 0.5669999718666077
ep5_l3_test_time 0.6391636830000209
Test Epoch5 layer4 Acc 0.5354, AUC 0.8014190793037415, avg_entr 0.1925450712442398, f1 0.5353999733924866
ep5_l4_test_time 0.832100816999997
gc 0
Train Epoch6 Acc 0.719275 (28771/40000), AUC 0.792458713054657
ep6_train_time 23.406602295
Test Epoch6 layer0 Acc 0.6876, AUC 0.766753613948822, avg_entr 0.3744763135910034, f1 0.6876000165939331
ep6_l0_test_time 0.3071179340000185
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer1 Acc 0.7236, AUC 0.8048770427703857, avg_entr 0.33098462224006653, f1 0.7236000299453735
ep6_l1_test_time 0.3797038650000104
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer2 Acc 0.731, AUC 0.8138860464096069, avg_entr 0.32059094309806824, f1 0.7310000061988831
ep6_l2_test_time 0.4867691420000142
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer3 Acc 0.7334, AUC 0.8168774843215942, avg_entr 0.3263086676597595, f1 0.7333999872207642
ep6_l3_test_time 0.637001644999998
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer4 Acc 0.7312, AUC 0.8176463842391968, avg_entr 0.3348577320575714, f1 0.7311999797821045
ep6_l4_test_time 0.8371173419999991
gc 0
Train Epoch7 Acc 0.7543 (30172/40000), AUC 0.8322986960411072
ep7_train_time 23.365100797000025
Test Epoch7 layer0 Acc 0.6968, AUC 0.779480516910553, avg_entr 0.338568776845932, f1 0.6967999935150146
ep7_l0_test_time 0.3060990150000009
Test Epoch7 layer1 Acc 0.7034, AUC 0.8161882162094116, avg_entr 0.2842712104320526, f1 0.7034000158309937
ep7_l1_test_time 0.3785170790000052
Test Epoch7 layer2 Acc 0.7092, AUC 0.826113224029541, avg_entr 0.29242491722106934, f1 0.7092000246047974
ep7_l2_test_time 0.48880961700001535
Test Epoch7 layer3 Acc 0.7102, AUC 0.8303351998329163, avg_entr 0.30873599648475647, f1 0.7102000117301941
ep7_l3_test_time 0.6382456039999909
Test Epoch7 layer4 Acc 0.7086, AUC 0.8309565782546997, avg_entr 0.3216172456741333, f1 0.7085999846458435
ep7_l4_test_time 0.8323504310000089
gc 0
Train Epoch8 Acc 0.77535 (31014/40000), AUC 0.8549600839614868
ep8_train_time 23.410162076999995
Test Epoch8 layer0 Acc 0.692, AUC 0.78349369764328, avg_entr 0.3204515278339386, f1 0.6919999718666077
ep8_l0_test_time 0.3061991920000082
Test Epoch8 layer1 Acc 0.7262, AUC 0.8187720775604248, avg_entr 0.279811829328537, f1 0.7261999845504761
ep8_l1_test_time 0.37957770499997423
Test Epoch8 layer2 Acc 0.7362, AUC 0.8269714117050171, avg_entr 0.2616731822490692, f1 0.7361999750137329
ep8_l2_test_time 0.48866297200004283
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 8
Test Epoch8 layer3 Acc 0.743, AUC 0.8321729898452759, avg_entr 0.2461453676223755, f1 0.7430000305175781
ep8_l3_test_time 0.637628301999996
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 8
Test Epoch8 layer4 Acc 0.7402, AUC 0.8328571319580078, avg_entr 0.25275683403015137, f1 0.7401999831199646
ep8_l4_test_time 0.8298995089999721
gc 0
Train Epoch9 Acc 0.7722 (30888/40000), AUC 0.851310670375824
ep9_train_time 23.381108605999998
Test Epoch9 layer0 Acc 0.6658, AUC 0.7880266308784485, avg_entr 0.30658429861068726, f1 0.6657999753952026
ep9_l0_test_time 0.30648994399996354
Test Epoch9 layer1 Acc 0.69, AUC 0.8159782886505127, avg_entr 0.2652253806591034, f1 0.6899999976158142
ep9_l1_test_time 0.38125643600000103
Test Epoch9 layer2 Acc 0.6934, AUC 0.8237523436546326, avg_entr 0.23527485132217407, f1 0.6934000253677368
ep9_l2_test_time 0.4916138090000004
Test Epoch9 layer3 Acc 0.6922, AUC 0.8300201892852783, avg_entr 0.21002709865570068, f1 0.6922000050544739
ep9_l3_test_time 0.6393250710000302
Test Epoch9 layer4 Acc 0.6852, AUC 0.8311883807182312, avg_entr 0.20681039988994598, f1 0.6851999759674072
ep9_l4_test_time 0.8322633900000369
gc 0
Train Epoch10 Acc 0.8158 (32632/40000), AUC 0.8940671682357788
ep10_train_time 23.428332211999987
Test Epoch10 layer0 Acc 0.7086, AUC 0.7852111458778381, avg_entr 0.28907039761543274, f1 0.7085999846458435
ep10_l0_test_time 0.30427424900000233
Test Epoch10 layer1 Acc 0.7388, AUC 0.8242060542106628, avg_entr 0.23546773195266724, f1 0.7387999892234802
ep10_l1_test_time 0.37810023699995554
Test Epoch10 layer2 Acc 0.7396, AUC 0.8331981897354126, avg_entr 0.19201211631298065, f1 0.7396000027656555
ep10_l2_test_time 0.48758237599997756
Test Epoch10 layer3 Acc 0.7394, AUC 0.8384369611740112, avg_entr 0.15684498846530914, f1 0.7394000291824341
ep10_l3_test_time 0.6380160500000329
Test Epoch10 layer4 Acc 0.7378, AUC 0.8393012285232544, avg_entr 0.15078933537006378, f1 0.7378000020980835
ep10_l4_test_time 0.8316662100000372
gc 0
Train Epoch11 Acc 0.8234 (32936/40000), AUC 0.8997002840042114
ep11_train_time 23.38531100700004
Test Epoch11 layer0 Acc 0.7082, AUC 0.7859126329421997, avg_entr 0.27804261445999146, f1 0.7081999778747559
ep11_l0_test_time 0.3060524530000066
Test Epoch11 layer1 Acc 0.7334, AUC 0.8231794238090515, avg_entr 0.24372848868370056, f1 0.7333999872207642
ep11_l1_test_time 0.3797704410000051
Test Epoch11 layer2 Acc 0.7354, AUC 0.8331745862960815, avg_entr 0.2043195217847824, f1 0.7354000210762024
ep11_l2_test_time 0.489775064000014
Test Epoch11 layer3 Acc 0.7342, AUC 0.8409522771835327, avg_entr 0.1934976577758789, f1 0.7342000007629395
ep11_l3_test_time 0.6381787459999941
Test Epoch11 layer4 Acc 0.7288, AUC 0.8423550128936768, avg_entr 0.20332016050815582, f1 0.7287999987602234
ep11_l4_test_time 0.8322203449999961
gc 0
Train Epoch12 Acc 0.8389 (33556/40000), AUC 0.9131386280059814
ep12_train_time 23.43266219100002
Test Epoch12 layer0 Acc 0.7102, AUC 0.7778265476226807, avg_entr 0.27166539430618286, f1 0.7102000117301941
ep12_l0_test_time 0.3062270120000221
Test Epoch12 layer1 Acc 0.7354, AUC 0.8114935755729675, avg_entr 0.22073449194431305, f1 0.7354000210762024
ep12_l1_test_time 0.37920258700000886
Test Epoch12 layer2 Acc 0.7414, AUC 0.8209385871887207, avg_entr 0.15599611401557922, f1 0.7414000034332275
ep12_l2_test_time 0.48784204300000056
Test Epoch12 layer3 Acc 0.747, AUC 0.8291809558868408, avg_entr 0.15429967641830444, f1 0.746999979019165
ep12_l3_test_time 0.6401449740000089
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 12
Test Epoch12 layer4 Acc 0.7468, AUC 0.8310357928276062, avg_entr 0.15449091792106628, f1 0.7468000054359436
ep12_l4_test_time 0.8341583899999705
gc 0
Train Epoch13 Acc 0.856275 (34251/40000), AUC 0.9290076494216919
ep13_train_time 23.36111074300004
Test Epoch13 layer0 Acc 0.7066, AUC 0.7802492380142212, avg_entr 0.24601750075817108, f1 0.70660001039505
ep13_l0_test_time 0.30608006099998875
Test Epoch13 layer1 Acc 0.7382, AUC 0.8187628984451294, avg_entr 0.2156040072441101, f1 0.7382000684738159
ep13_l1_test_time 0.37975500200002443
Test Epoch13 layer2 Acc 0.7458, AUC 0.8293758630752563, avg_entr 0.15571236610412598, f1 0.7458000183105469
ep13_l2_test_time 0.48891103900001553
Test Epoch13 layer3 Acc 0.7566, AUC 0.838005781173706, avg_entr 0.1518968939781189, f1 0.756600022315979
ep13_l3_test_time 0.6364845690000038
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 13
Test Epoch13 layer4 Acc 0.754, AUC 0.839203953742981, avg_entr 0.1560356765985489, f1 0.7540000081062317
ep13_l4_test_time 0.8312812820000204
gc 0
Train Epoch14 Acc 0.864725 (34589/40000), AUC 0.9316043853759766
ep14_train_time 23.334674625000048
Test Epoch14 layer0 Acc 0.6972, AUC 0.7771520018577576, avg_entr 0.22712966799736023, f1 0.6972000002861023
ep14_l0_test_time 0.3057511740000223
Test Epoch14 layer1 Acc 0.7134, AUC 0.8091214895248413, avg_entr 0.1807696670293808, f1 0.7134000062942505
ep14_l1_test_time 0.3788830580000422
Test Epoch14 layer2 Acc 0.7214, AUC 0.8157644271850586, avg_entr 0.11810252815485, f1 0.7214000225067139
ep14_l2_test_time 0.48839768999999933
Test Epoch14 layer3 Acc 0.7264, AUC 0.8244591951370239, avg_entr 0.11095608025789261, f1 0.7264000177383423
ep14_l3_test_time 0.6368279710000024
Test Epoch14 layer4 Acc 0.729, AUC 0.8229838013648987, avg_entr 0.11231449246406555, f1 0.7289999723434448
ep14_l4_test_time 0.8311124919999884
gc 0
Train Epoch15 Acc 0.8942 (35768/40000), AUC 0.9566065073013306
ep15_train_time 23.412919730999988
Test Epoch15 layer0 Acc 0.7012, AUC 0.776791512966156, avg_entr 0.20817133784294128, f1 0.701200008392334
ep15_l0_test_time 0.3050966519999747
Test Epoch15 layer1 Acc 0.7264, AUC 0.8097483515739441, avg_entr 0.153959259390831, f1 0.7264000177383423
ep15_l1_test_time 0.37816356100000803
Test Epoch15 layer2 Acc 0.7274, AUC 0.820570707321167, avg_entr 0.09340430051088333, f1 0.7274000644683838
ep15_l2_test_time 0.48878225599997904
Test Epoch15 layer3 Acc 0.729, AUC 0.8275375366210938, avg_entr 0.09115056693553925, f1 0.7289999723434448
ep15_l3_test_time 0.6370665970000005
Test Epoch15 layer4 Acc 0.7278, AUC 0.8271111249923706, avg_entr 0.09003639966249466, f1 0.7277999520301819
ep15_l4_test_time 0.830765744999951
gc 0
Train Epoch16 Acc 0.90305 (36122/40000), AUC 0.9625874757766724
ep16_train_time 23.372490792000008
Test Epoch16 layer0 Acc 0.6952, AUC 0.7709058523178101, avg_entr 0.20201489329338074, f1 0.6952000260353088
ep16_l0_test_time 0.3062668160000044
Test Epoch16 layer1 Acc 0.7198, AUC 0.8060240745544434, avg_entr 0.13570259511470795, f1 0.7197999358177185
ep16_l1_test_time 0.38035737199999176
Test Epoch16 layer2 Acc 0.7262, AUC 0.8192368745803833, avg_entr 0.09136562794446945, f1 0.7261999845504761
ep16_l2_test_time 0.4906821039999727
Test Epoch16 layer3 Acc 0.7324, AUC 0.8266934752464294, avg_entr 0.09060094505548477, f1 0.7323999404907227
ep16_l3_test_time 0.6404411460000006
Test Epoch16 layer4 Acc 0.7352, AUC 0.827256441116333, avg_entr 0.08965424448251724, f1 0.7351999282836914
ep16_l4_test_time 0.833019537000041
gc 0
Train Epoch17 Acc 0.911825 (36473/40000), AUC 0.9682360887527466
ep17_train_time 23.44966522599998
Test Epoch17 layer0 Acc 0.6958, AUC 0.7724136114120483, avg_entr 0.20898467302322388, f1 0.6958000063896179
ep17_l0_test_time 0.30562828099999706
Test Epoch17 layer1 Acc 0.716, AUC 0.8012794256210327, avg_entr 0.12431806325912476, f1 0.7160000205039978
ep17_l1_test_time 0.37898061200002076
Test Epoch17 layer2 Acc 0.7262, AUC 0.8157780170440674, avg_entr 0.09086458384990692, f1 0.7261999845504761
ep17_l2_test_time 0.4883365990000357
Test Epoch17 layer3 Acc 0.7308, AUC 0.8240152597427368, avg_entr 0.08839713037014008, f1 0.7307999730110168
ep17_l3_test_time 0.6374371010000459
Test Epoch17 layer4 Acc 0.7318, AUC 0.823973536491394, avg_entr 0.08949566632509232, f1 0.7318000197410583
ep17_l4_test_time 0.8310378439999795
gc 0
Train Epoch18 Acc 0.917675 (36707/40000), AUC 0.9707095623016357
ep18_train_time 23.38507779799994
Test Epoch18 layer0 Acc 0.6932, AUC 0.7691164016723633, avg_entr 0.20600639283657074, f1 0.6931999921798706
ep18_l0_test_time 0.3067989139999554
Test Epoch18 layer1 Acc 0.7036, AUC 0.7946508526802063, avg_entr 0.10894962400197983, f1 0.7035999894142151
ep18_l1_test_time 0.3811879160000444
Test Epoch18 layer2 Acc 0.7166, AUC 0.8109234571456909, avg_entr 0.08339136838912964, f1 0.7165999412536621
ep18_l2_test_time 0.4904028070000095
Test Epoch18 layer3 Acc 0.7238, AUC 0.8202461004257202, avg_entr 0.08110891282558441, f1 0.723800003528595
ep18_l3_test_time 0.6383668810000245
Test Epoch18 layer4 Acc 0.7244, AUC 0.8188389539718628, avg_entr 0.07874360680580139, f1 0.7244000434875488
ep18_l4_test_time 0.8320469660000072
gc 0
Train Epoch19 Acc 0.9265 (37060/40000), AUC 0.9764010906219482
ep19_train_time 23.399906916999953
Test Epoch19 layer0 Acc 0.696, AUC 0.7682774662971497, avg_entr 0.19598817825317383, f1 0.6959999799728394
ep19_l0_test_time 0.3084018649999507
Test Epoch19 layer1 Acc 0.718, AUC 0.7904669046401978, avg_entr 0.09597765654325485, f1 0.7179999351501465
ep19_l1_test_time 0.37839857099993424
Test Epoch19 layer2 Acc 0.7256, AUC 0.8092451095581055, avg_entr 0.0769176259636879, f1 0.7255999445915222
ep19_l2_test_time 0.48844820800002253
Test Epoch19 layer3 Acc 0.7332, AUC 0.8167917728424072, avg_entr 0.07400397956371307, f1 0.7332000136375427
ep19_l3_test_time 0.637074617000053
Test Epoch19 layer4 Acc 0.734, AUC 0.8182539939880371, avg_entr 0.07369686663150787, f1 0.7339999675750732
ep19_l4_test_time 0.8313266349999822
gc 0
Train Epoch20 Acc 0.930575 (37223/40000), AUC 0.9796335101127625
ep20_train_time 23.408010469000033
Test Epoch20 layer0 Acc 0.6956, AUC 0.7676786184310913, avg_entr 0.19620731472969055, f1 0.6955999732017517
ep20_l0_test_time 0.30690296399995987
Test Epoch20 layer1 Acc 0.7154, AUC 0.7903801202774048, avg_entr 0.09554502367973328, f1 0.715399980545044
ep20_l1_test_time 0.38005809200001295
Test Epoch20 layer2 Acc 0.729, AUC 0.8064880967140198, avg_entr 0.07721061259508133, f1 0.7289999723434448
ep20_l2_test_time 0.48942125100006706
Test Epoch20 layer3 Acc 0.7362, AUC 0.8164598941802979, avg_entr 0.07086747884750366, f1 0.7361999750137329
ep20_l3_test_time 0.6378482439999971
Test Epoch20 layer4 Acc 0.7356, AUC 0.8161994218826294, avg_entr 0.07079120725393295, f1 0.7355999946594238
ep20_l4_test_time 0.8317016739999872
gc 0
Train Epoch21 Acc 0.935025 (37401/40000), AUC 0.9815688133239746
ep21_train_time 23.369751543000007
Test Epoch21 layer0 Acc 0.6944, AUC 0.7666981816291809, avg_entr 0.19408440589904785, f1 0.6944000124931335
ep21_l0_test_time 0.30651826600001186
Test Epoch21 layer1 Acc 0.7178, AUC 0.7872411012649536, avg_entr 0.08569107204675674, f1 0.7178000211715698
ep21_l1_test_time 0.37876828299999943
Test Epoch21 layer2 Acc 0.732, AUC 0.8077571988105774, avg_entr 0.06912195682525635, f1 0.7319999933242798
ep21_l2_test_time 0.4904949099999385
Test Epoch21 layer3 Acc 0.7366, AUC 0.817510724067688, avg_entr 0.06722564995288849, f1 0.7365999817848206
ep21_l3_test_time 0.6394292700000506
Test Epoch21 layer4 Acc 0.7376, AUC 0.817891001701355, avg_entr 0.06717575341463089, f1 0.7376000285148621
ep21_l4_test_time 0.8337199979999923
gc 0
Train Epoch22 Acc 0.936025 (37441/40000), AUC 0.9812551736831665
ep22_train_time 23.387919242999942
Test Epoch22 layer0 Acc 0.6918, AUC 0.7643846273422241, avg_entr 0.19349022209644318, f1 0.6917999982833862
ep22_l0_test_time 0.3060634639999762
Test Epoch22 layer1 Acc 0.7108, AUC 0.7843641042709351, avg_entr 0.08603956550359726, f1 0.7107999920845032
ep22_l1_test_time 0.38009455500002787
Test Epoch22 layer2 Acc 0.7242, AUC 0.802747368812561, avg_entr 0.06813994795084, f1 0.7242000699043274
ep22_l2_test_time 0.48906021799996324
Test Epoch22 layer3 Acc 0.7304, AUC 0.8131581544876099, avg_entr 0.06460624933242798, f1 0.7304000854492188
ep22_l3_test_time 0.6380878709999251
Test Epoch22 layer4 Acc 0.7304, AUC 0.8134236335754395, avg_entr 0.06363095343112946, f1 0.7304000854492188
ep22_l4_test_time 0.8319264030000113
gc 0
Train Epoch23 Acc 0.941975 (37679/40000), AUC 0.9841619729995728
ep23_train_time 23.44457696799998
Test Epoch23 layer0 Acc 0.6962, AUC 0.7646877765655518, avg_entr 0.19065915048122406, f1 0.6962000131607056
ep23_l0_test_time 0.30669295600000623
Test Epoch23 layer1 Acc 0.7112, AUC 0.7842360138893127, avg_entr 0.0821630209684372, f1 0.7111999988555908
ep23_l1_test_time 0.38078694499995436
Test Epoch23 layer2 Acc 0.729, AUC 0.8036668300628662, avg_entr 0.06939376890659332, f1 0.7289999723434448
ep23_l2_test_time 0.4913555489999908
Test Epoch23 layer3 Acc 0.735, AUC 0.814934492111206, avg_entr 0.06444817036390305, f1 0.7350000143051147
ep23_l3_test_time 0.6384781470000007
Test Epoch23 layer4 Acc 0.7342, AUC 0.814440906047821, avg_entr 0.06446457654237747, f1 0.7342000007629395
ep23_l4_test_time 0.8316429980000066
gc 0
Train Epoch24 Acc 0.942625 (37705/40000), AUC 0.9849782586097717
ep24_train_time 23.381096564000018
Test Epoch24 layer0 Acc 0.693, AUC 0.7645502090454102, avg_entr 0.18210259079933167, f1 0.6930000185966492
ep24_l0_test_time 0.3064062290000038
Test Epoch24 layer1 Acc 0.717, AUC 0.7826772928237915, avg_entr 0.07817656546831131, f1 0.7169999480247498
ep24_l1_test_time 0.3795357010000089
Test Epoch24 layer2 Acc 0.7212, AUC 0.8026556372642517, avg_entr 0.06685315817594528, f1 0.7211999893188477
ep24_l2_test_time 0.4886571130000448
Test Epoch24 layer3 Acc 0.726, AUC 0.813561201095581, avg_entr 0.0635349228978157, f1 0.7260000109672546
ep24_l3_test_time 0.6379466619999903
Test Epoch24 layer4 Acc 0.7296, AUC 0.8135235905647278, avg_entr 0.06484855711460114, f1 0.7295999526977539
ep24_l4_test_time 0.8328699549999783
gc 0
Train Epoch25 Acc 0.94275 (37710/40000), AUC 0.984846830368042
ep25_train_time 23.390756830999976
Test Epoch25 layer0 Acc 0.6924, AUC 0.7627884149551392, avg_entr 0.18941238522529602, f1 0.6923999786376953
ep25_l0_test_time 0.3046997740000279
Test Epoch25 layer1 Acc 0.712, AUC 0.7822756767272949, avg_entr 0.0820443257689476, f1 0.7120000123977661
ep25_l1_test_time 0.37911465600006977
Test Epoch25 layer2 Acc 0.7248, AUC 0.8033164739608765, avg_entr 0.06804225593805313, f1 0.7247999906539917
ep25_l2_test_time 0.4890774919999785
Test Epoch25 layer3 Acc 0.7346, AUC 0.8141590356826782, avg_entr 0.060596391558647156, f1 0.7345999479293823
ep25_l3_test_time 0.637750088999951
Test Epoch25 layer4 Acc 0.7332, AUC 0.8135737180709839, avg_entr 0.060552384704351425, f1 0.7332000136375427
ep25_l4_test_time 0.831784935000087
gc 0
Train Epoch26 Acc 0.94575 (37830/40000), AUC 0.9857468605041504
ep26_train_time 23.384189969999966
Test Epoch26 layer0 Acc 0.6936, AUC 0.7625085711479187, avg_entr 0.18688608705997467, f1 0.6935999989509583
ep26_l0_test_time 0.3071385810000038
Test Epoch26 layer1 Acc 0.7074, AUC 0.775268018245697, avg_entr 0.07485992461442947, f1 0.7074000239372253
ep26_l1_test_time 0.3810051080000676
Test Epoch26 layer2 Acc 0.7192, AUC 0.7993302345275879, avg_entr 0.06355001032352448, f1 0.719200074672699
ep26_l2_test_time 0.4907741270000088
Test Epoch26 layer3 Acc 0.7262, AUC 0.8110090494155884, avg_entr 0.05814415216445923, f1 0.7261999845504761
ep26_l3_test_time 0.6383550470000046
Test Epoch26 layer4 Acc 0.7248, AUC 0.8101524114608765, avg_entr 0.057916730642318726, f1 0.7247999906539917
ep26_l4_test_time 0.8334517790000291
gc 0
Train Epoch27 Acc 0.94715 (37886/40000), AUC 0.9865500926971436
ep27_train_time 23.41419118099998
Test Epoch27 layer0 Acc 0.6922, AUC 0.7620302438735962, avg_entr 0.18539263308048248, f1 0.6922000050544739
ep27_l0_test_time 0.30692908200001057
Test Epoch27 layer1 Acc 0.7086, AUC 0.7765001058578491, avg_entr 0.0737907886505127, f1 0.7085999846458435
ep27_l1_test_time 0.3806884989999162
Test Epoch27 layer2 Acc 0.7238, AUC 0.7996039986610413, avg_entr 0.06455645710229874, f1 0.723800003528595
ep27_l2_test_time 0.4903803089999883
Test Epoch27 layer3 Acc 0.7332, AUC 0.8113770484924316, avg_entr 0.05791812762618065, f1 0.7332000136375427
ep27_l3_test_time 0.6395094030000337
Test Epoch27 layer4 Acc 0.7326, AUC 0.8104139566421509, avg_entr 0.056874506175518036, f1 0.7325999140739441
ep27_l4_test_time 0.8329837339999813
gc 0
Train Epoch28 Acc 0.948725 (37949/40000), AUC 0.9873369932174683
ep28_train_time 23.410127860999978
Test Epoch28 layer0 Acc 0.6916, AUC 0.7615391612052917, avg_entr 0.18540646135807037, f1 0.6916000247001648
ep28_l0_test_time 0.3071562750000112
Test Epoch28 layer1 Acc 0.7084, AUC 0.7771592140197754, avg_entr 0.07449950277805328, f1 0.7084000110626221
ep28_l1_test_time 0.3799334180000642
Test Epoch28 layer2 Acc 0.723, AUC 0.7982897758483887, avg_entr 0.0641968697309494, f1 0.7229999899864197
ep28_l2_test_time 0.4897874869999441
Test Epoch28 layer3 Acc 0.7342, AUC 0.8108687400817871, avg_entr 0.05804547294974327, f1 0.7342000007629395
ep28_l3_test_time 0.6380908909999334
Test Epoch28 layer4 Acc 0.7328, AUC 0.8097888231277466, avg_entr 0.05658336728811264, f1 0.7327999472618103
ep28_l4_test_time 0.8321446689999448
gc 0
Train Epoch29 Acc 0.9502 (38008/40000), AUC 0.9876439571380615
ep29_train_time 23.389663622000057
Test Epoch29 layer0 Acc 0.6904, AUC 0.761380136013031, avg_entr 0.1844702661037445, f1 0.6904000043869019
ep29_l0_test_time 0.30691401800004314
Test Epoch29 layer1 Acc 0.7074, AUC 0.7761445045471191, avg_entr 0.07232783734798431, f1 0.7074000239372253
ep29_l1_test_time 0.3797420680000414
Test Epoch29 layer2 Acc 0.7228, AUC 0.7973296046257019, avg_entr 0.06307651102542877, f1 0.7227999567985535
ep29_l2_test_time 0.4893338850000646
Test Epoch29 layer3 Acc 0.731, AUC 0.8102748990058899, avg_entr 0.05722265690565109, f1 0.7310000061988831
ep29_l3_test_time 0.6380179760000146
Test Epoch29 layer4 Acc 0.729, AUC 0.8092901110649109, avg_entr 0.056819017976522446, f1 0.7289999723434448
ep29_l4_test_time 0.8347024839999904
gc 0
Train Epoch30 Acc 0.95115 (38046/40000), AUC 0.9879188537597656
ep30_train_time 23.399236985000016
Test Epoch30 layer0 Acc 0.691, AUC 0.7607791423797607, avg_entr 0.18340232968330383, f1 0.6909999847412109
ep30_l0_test_time 0.3062263619999612
Test Epoch30 layer1 Acc 0.7068, AUC 0.7765129804611206, avg_entr 0.072568379342556, f1 0.7067999839782715
ep30_l1_test_time 0.3797849459999725
Test Epoch30 layer2 Acc 0.7222, AUC 0.7975261211395264, avg_entr 0.06198806315660477, f1 0.7222000360488892
ep30_l2_test_time 0.4904297589999942
Test Epoch30 layer3 Acc 0.7302, AUC 0.8098966479301453, avg_entr 0.05563121289014816, f1 0.7301999926567078
ep30_l3_test_time 0.6399349289999918
Test Epoch30 layer4 Acc 0.729, AUC 0.8088958263397217, avg_entr 0.055049046874046326, f1 0.7289999723434448
ep30_l4_test_time 0.8315367750000178
gc 0
Train Epoch31 Acc 0.9503 (38012/40000), AUC 0.9884942770004272
ep31_train_time 23.383302533000005
Test Epoch31 layer0 Acc 0.6906, AUC 0.7607076168060303, avg_entr 0.18353746831417084, f1 0.6905999779701233
ep31_l0_test_time 0.3051399150000407
Test Epoch31 layer1 Acc 0.706, AUC 0.7752765417098999, avg_entr 0.07145633548498154, f1 0.7059999704360962
ep31_l1_test_time 0.37920130300005894
Test Epoch31 layer2 Acc 0.7222, AUC 0.7972180843353271, avg_entr 0.06210652366280556, f1 0.7222000360488892
ep31_l2_test_time 0.48855045899995275
Test Epoch31 layer3 Acc 0.73, AUC 0.8097881078720093, avg_entr 0.05500272661447525, f1 0.7300000190734863
ep31_l3_test_time 0.6379112140000416
Test Epoch31 layer4 Acc 0.73, AUC 0.8090129494667053, avg_entr 0.05396734178066254, f1 0.7300000190734863
ep31_l4_test_time 0.831815440000014
gc 0
Train Epoch32 Acc 0.951275 (38051/40000), AUC 0.9888188242912292
ep32_train_time 23.376367848000086
Test Epoch32 layer0 Acc 0.6922, AUC 0.7603273391723633, avg_entr 0.18172886967658997, f1 0.6922000050544739
ep32_l0_test_time 0.31319830600000387
Test Epoch32 layer1 Acc 0.7086, AUC 0.775288999080658, avg_entr 0.07077985256910324, f1 0.7085999846458435
ep32_l1_test_time 0.38064945099995384
Test Epoch32 layer2 Acc 0.7214, AUC 0.796602725982666, avg_entr 0.06019249185919762, f1 0.7214000225067139
ep32_l2_test_time 0.4900014730000066
Test Epoch32 layer3 Acc 0.7302, AUC 0.8083769083023071, avg_entr 0.05465302616357803, f1 0.7301999926567078
ep32_l3_test_time 0.6389686790000724
Test Epoch32 layer4 Acc 0.7298, AUC 0.8074698448181152, avg_entr 0.053070105612277985, f1 0.7297999858856201
ep32_l4_test_time 0.8335717290000275
gc 0
Train Epoch33 Acc 0.9516 (38064/40000), AUC 0.9889612197875977
ep33_train_time 23.391026709000016
Test Epoch33 layer0 Acc 0.691, AUC 0.760309100151062, avg_entr 0.18193185329437256, f1 0.6909999847412109
ep33_l0_test_time 0.30524867899998753
Test Epoch33 layer1 Acc 0.707, AUC 0.7743856906890869, avg_entr 0.0707322359085083, f1 0.7070000171661377
ep33_l1_test_time 0.38145619100009753
Test Epoch33 layer2 Acc 0.7218, AUC 0.7981806993484497, avg_entr 0.06266604363918304, f1 0.7217999696731567
ep33_l2_test_time 0.49038099999995666
Test Epoch33 layer3 Acc 0.7308, AUC 0.8104442358016968, avg_entr 0.055509068071842194, f1 0.7307999730110168
ep33_l3_test_time 0.637837453999964
Test Epoch33 layer4 Acc 0.73, AUC 0.8100767135620117, avg_entr 0.05485673248767853, f1 0.7300000190734863
ep33_l4_test_time 0.8322632979999298
gc 0
Train Epoch34 Acc 0.951 (38040/40000), AUC 0.9885475635528564
ep34_train_time 23.456149344000096
Test Epoch34 layer0 Acc 0.6904, AUC 0.7599565982818604, avg_entr 0.18177475035190582, f1 0.6904000043869019
ep34_l0_test_time 0.3065426260000095
Test Epoch34 layer1 Acc 0.7062, AUC 0.7728362083435059, avg_entr 0.06833881884813309, f1 0.7062000036239624
ep34_l1_test_time 0.380385251000007
Test Epoch34 layer2 Acc 0.7206, AUC 0.7964362502098083, avg_entr 0.05993391573429108, f1 0.7206000685691833
ep34_l2_test_time 0.48935939299997244
Test Epoch34 layer3 Acc 0.7284, AUC 0.8085720539093018, avg_entr 0.05287931486964226, f1 0.7284000515937805
ep34_l3_test_time 0.6391423560000931
Test Epoch34 layer4 Acc 0.7298, AUC 0.8077136874198914, avg_entr 0.05198107287287712, f1 0.7297999858856201
ep34_l4_test_time 0.8321815360000073
gc 0
Train Epoch35 Acc 0.95355 (38142/40000), AUC 0.989010214805603
ep35_train_time 23.40280769100002
Test Epoch35 layer0 Acc 0.6906, AUC 0.7599188089370728, avg_entr 0.1820031851530075, f1 0.6905999779701233
ep35_l0_test_time 0.30713425699991603
Test Epoch35 layer1 Acc 0.7054, AUC 0.7727874517440796, avg_entr 0.06817112118005753, f1 0.7053999900817871
ep35_l1_test_time 0.3807376449999538
Test Epoch35 layer2 Acc 0.7214, AUC 0.7956671118736267, avg_entr 0.0591302290558815, f1 0.7214000225067139
ep35_l2_test_time 0.48993202400004066
Test Epoch35 layer3 Acc 0.7298, AUC 0.8079200983047485, avg_entr 0.05272794887423515, f1 0.7297999858856201
ep35_l3_test_time 0.6415944959999251
Test Epoch35 layer4 Acc 0.7306, AUC 0.8073166012763977, avg_entr 0.05186713859438896, f1 0.7305999994277954
ep35_l4_test_time 0.8337119929999517
gc 0
Train Epoch36 Acc 0.952775 (38111/40000), AUC 0.9892895221710205
ep36_train_time 23.393181817000027
Test Epoch36 layer0 Acc 0.6904, AUC 0.7600158452987671, avg_entr 0.18084467947483063, f1 0.6904000043869019
ep36_l0_test_time 0.3060636650000106
Test Epoch36 layer1 Acc 0.7068, AUC 0.7736551761627197, avg_entr 0.06819011270999908, f1 0.7067999839782715
ep36_l1_test_time 0.38143367499992564
Test Epoch36 layer2 Acc 0.7218, AUC 0.7970415353775024, avg_entr 0.05886057764291763, f1 0.7217999696731567
ep36_l2_test_time 0.49680585300006896
Test Epoch36 layer3 Acc 0.7304, AUC 0.8091351985931396, avg_entr 0.05163465067744255, f1 0.7304000854492188
ep36_l3_test_time 0.6428342109999221
Test Epoch36 layer4 Acc 0.7298, AUC 0.8083117604255676, avg_entr 0.05077509209513664, f1 0.7297999858856201
ep36_l4_test_time 0.8315787509999382
gc 0
Train Epoch37 Acc 0.953 (38120/40000), AUC 0.9896022081375122
ep37_train_time 23.43535049000002
Test Epoch37 layer0 Acc 0.6918, AUC 0.7597141265869141, avg_entr 0.18093112111091614, f1 0.6917999982833862
ep37_l0_test_time 0.30568015500000456
Test Epoch37 layer1 Acc 0.7074, AUC 0.7737661004066467, avg_entr 0.0686626136302948, f1 0.7074000239372253
ep37_l1_test_time 0.3797360219999746
Test Epoch37 layer2 Acc 0.7218, AUC 0.7963405847549438, avg_entr 0.05926625803112984, f1 0.7217999696731567
ep37_l2_test_time 0.4892959730000257
Test Epoch37 layer3 Acc 0.7314, AUC 0.8083781003952026, avg_entr 0.05336179956793785, f1 0.7314000129699707
ep37_l3_test_time 0.6393570929999441
Test Epoch37 layer4 Acc 0.7316, AUC 0.8077234625816345, avg_entr 0.052478887140750885, f1 0.7316000461578369
ep37_l4_test_time 0.8320464540000785
gc 0
Train Epoch38 Acc 0.9521 (38084/40000), AUC 0.9894106984138489
ep38_train_time 23.382636076999916
Test Epoch38 layer0 Acc 0.691, AUC 0.7597376704216003, avg_entr 0.18115663528442383, f1 0.6909999847412109
ep38_l0_test_time 0.30679871600000297
Test Epoch38 layer1 Acc 0.7058, AUC 0.7720184326171875, avg_entr 0.06703805178403854, f1 0.7057999968528748
ep38_l1_test_time 0.380366598999899
Test Epoch38 layer2 Acc 0.7206, AUC 0.796138346195221, avg_entr 0.059060029685497284, f1 0.7206000685691833
ep38_l2_test_time 0.48914862099991296
Test Epoch38 layer3 Acc 0.7304, AUC 0.8075777292251587, avg_entr 0.05194048956036568, f1 0.7304000854492188
ep38_l3_test_time 0.6382450680000602
Test Epoch38 layer4 Acc 0.7312, AUC 0.806860089302063, avg_entr 0.05089745298027992, f1 0.7311999797821045
ep38_l4_test_time 0.8315371810001579
gc 0
Train Epoch39 Acc 0.953425 (38137/40000), AUC 0.9897151589393616
ep39_train_time 23.477616218999856
Test Epoch39 layer0 Acc 0.6912, AUC 0.759760320186615, avg_entr 0.18105001747608185, f1 0.6912000179290771
ep39_l0_test_time 0.3100881880000088
Test Epoch39 layer1 Acc 0.7052, AUC 0.772756814956665, avg_entr 0.06797099113464355, f1 0.7052000164985657
ep39_l1_test_time 0.38569800999994186
Test Epoch39 layer2 Acc 0.7224, AUC 0.7964907884597778, avg_entr 0.05956835299730301, f1 0.7224000096321106
ep39_l2_test_time 0.4981311569999889
Test Epoch39 layer3 Acc 0.7316, AUC 0.8082658052444458, avg_entr 0.05228608846664429, f1 0.7316000461578369
ep39_l3_test_time 0.6463046080000368
Test Epoch39 layer4 Acc 0.7304, AUC 0.8077259063720703, avg_entr 0.05157244950532913, f1 0.7304000854492188
ep39_l4_test_time 0.8399421829999483
gc 0
Train Epoch40 Acc 0.954375 (38175/40000), AUC 0.9899007081985474
ep40_train_time 23.546171461999847
Test Epoch40 layer0 Acc 0.6912, AUC 0.7597048282623291, avg_entr 0.18106412887573242, f1 0.6912000179290771
ep40_l0_test_time 0.3080039480000778
Test Epoch40 layer1 Acc 0.7064, AUC 0.7725989818572998, avg_entr 0.06770343333482742, f1 0.7063999772071838
ep40_l1_test_time 0.3862550859998919
Test Epoch40 layer2 Acc 0.7202, AUC 0.7966088056564331, avg_entr 0.059195104986429214, f1 0.7202000021934509
ep40_l2_test_time 0.49854240299987396
Test Epoch40 layer3 Acc 0.7296, AUC 0.8083721399307251, avg_entr 0.05156077817082405, f1 0.7295999526977539
ep40_l3_test_time 0.6457925520001027
Test Epoch40 layer4 Acc 0.731, AUC 0.8076382875442505, avg_entr 0.05087866261601448, f1 0.7310000061988831
ep40_l4_test_time 0.8430458790001012
gc 0
Train Epoch41 Acc 0.953 (38120/40000), AUC 0.9897388219833374
ep41_train_time 23.482476053000028
Test Epoch41 layer0 Acc 0.6906, AUC 0.7596378922462463, avg_entr 0.18027329444885254, f1 0.6905999779701233
ep41_l0_test_time 0.31011381500002244
Test Epoch41 layer1 Acc 0.7052, AUC 0.7727236747741699, avg_entr 0.06733984500169754, f1 0.7052000164985657
ep41_l1_test_time 0.38354741000011927
Test Epoch41 layer2 Acc 0.7216, AUC 0.7964065074920654, avg_entr 0.0592016838490963, f1 0.7215999960899353
ep41_l2_test_time 0.49351466300004176
Test Epoch41 layer3 Acc 0.7316, AUC 0.8081575632095337, avg_entr 0.051546309143304825, f1 0.7316000461578369
ep41_l3_test_time 0.6434459399999923
Test Epoch41 layer4 Acc 0.731, AUC 0.8075155019760132, avg_entr 0.050762783735990524, f1 0.7310000061988831
ep41_l4_test_time 0.8382888389999152
gc 0
Train Epoch42 Acc 0.95435 (38174/40000), AUC 0.9900509715080261
ep42_train_time 23.470150659999945
Test Epoch42 layer0 Acc 0.6916, AUC 0.7596426606178284, avg_entr 0.1798986941576004, f1 0.6916000247001648
ep42_l0_test_time 0.30908257100008996
Test Epoch42 layer1 Acc 0.7042, AUC 0.7732882499694824, avg_entr 0.06771627068519592, f1 0.704200029373169
ep42_l1_test_time 0.37883324800009177
Test Epoch42 layer2 Acc 0.7224, AUC 0.7965097427368164, avg_entr 0.05900585278868675, f1 0.7224000096321106
ep42_l2_test_time 0.4878348009999627
Test Epoch42 layer3 Acc 0.7318, AUC 0.808272123336792, avg_entr 0.05161624774336815, f1 0.7318000197410583
ep42_l3_test_time 0.6413787259998571
Test Epoch42 layer4 Acc 0.732, AUC 0.8074839115142822, avg_entr 0.05082987621426582, f1 0.7319999933242798
ep42_l4_test_time 0.8355859169998894
gc 0
Train Epoch43 Acc 0.954875 (38195/40000), AUC 0.9899133443832397
ep43_train_time 23.513980234999963
Test Epoch43 layer0 Acc 0.691, AUC 0.7596138715744019, avg_entr 0.1801626980304718, f1 0.6909999847412109
ep43_l0_test_time 0.3126362240000162
Test Epoch43 layer1 Acc 0.7048, AUC 0.7730427384376526, avg_entr 0.0676923468708992, f1 0.704800009727478
ep43_l1_test_time 0.38797179399989545
Test Epoch43 layer2 Acc 0.7218, AUC 0.7967007160186768, avg_entr 0.05949586629867554, f1 0.7217999696731567
ep43_l2_test_time 0.49146768100013105
Test Epoch43 layer3 Acc 0.7312, AUC 0.808416485786438, avg_entr 0.051832932978868484, f1 0.7311999797821045
ep43_l3_test_time 0.6374140309999348
Test Epoch43 layer4 Acc 0.7304, AUC 0.8075889348983765, avg_entr 0.05119297653436661, f1 0.7304000854492188
ep43_l4_test_time 0.8386095409998688
gc 0
Train Epoch44 Acc 0.954925 (38197/40000), AUC 0.9898388981819153
ep44_train_time 23.486259092999944
Test Epoch44 layer0 Acc 0.6914, AUC 0.7596015930175781, avg_entr 0.1797194927930832, f1 0.6913999915122986
ep44_l0_test_time 0.3095153570000093
Test Epoch44 layer1 Acc 0.7044, AUC 0.7729946374893188, avg_entr 0.06719526648521423, f1 0.7044000029563904
ep44_l1_test_time 0.3806311139999252
Test Epoch44 layer2 Acc 0.7224, AUC 0.7965838313102722, avg_entr 0.058738794177770615, f1 0.7224000096321106
ep44_l2_test_time 0.4957768400001896
Test Epoch44 layer3 Acc 0.7314, AUC 0.8083347678184509, avg_entr 0.0511920303106308, f1 0.7314000129699707
ep44_l3_test_time 0.644210540999893
Test Epoch44 layer4 Acc 0.7312, AUC 0.8075052499771118, avg_entr 0.05041886866092682, f1 0.7311999797821045
ep44_l4_test_time 0.8340243019999889
gc 0
Train Epoch45 Acc 0.953725 (38149/40000), AUC 0.9895418882369995
ep45_train_time 23.492155414999843
Test Epoch45 layer0 Acc 0.691, AUC 0.7595757246017456, avg_entr 0.17978698015213013, f1 0.6909999847412109
ep45_l0_test_time 0.31194727799993416
Test Epoch45 layer1 Acc 0.7048, AUC 0.7728021144866943, avg_entr 0.06699731945991516, f1 0.704800009727478
ep45_l1_test_time 0.38483508499984964
Test Epoch45 layer2 Acc 0.7224, AUC 0.7965797185897827, avg_entr 0.058388255536556244, f1 0.7224000096321106
ep45_l2_test_time 0.49559784500002024
Test Epoch45 layer3 Acc 0.7314, AUC 0.80824875831604, avg_entr 0.0508585162460804, f1 0.7314000129699707
ep45_l3_test_time 0.6379664809999213
Test Epoch45 layer4 Acc 0.7324, AUC 0.8074214458465576, avg_entr 0.05000293627381325, f1 0.7323999404907227
ep45_l4_test_time 0.8353228089999902
gc 0
Train Epoch46 Acc 0.95455 (38182/40000), AUC 0.9897903800010681
ep46_train_time 23.46869164099985
Test Epoch46 layer0 Acc 0.6912, AUC 0.7595921754837036, avg_entr 0.17985396087169647, f1 0.6912000179290771
ep46_l0_test_time 0.31558464499994443
Test Epoch46 layer1 Acc 0.7048, AUC 0.7731417417526245, avg_entr 0.06730443239212036, f1 0.704800009727478
ep46_l1_test_time 0.39076401500005886
Test Epoch46 layer2 Acc 0.7232, AUC 0.7966829538345337, avg_entr 0.05861169472336769, f1 0.7232000827789307
ep46_l2_test_time 0.4988722250000137
Test Epoch46 layer3 Acc 0.7318, AUC 0.8084082007408142, avg_entr 0.05108962208032608, f1 0.7318000197410583
ep46_l3_test_time 0.6457167309999932
Test Epoch46 layer4 Acc 0.732, AUC 0.8076281547546387, avg_entr 0.05033610388636589, f1 0.7319999933242798
ep46_l4_test_time 0.8382441129999734
gc 0
Train Epoch47 Acc 0.9534 (38136/40000), AUC 0.9896577000617981
ep47_train_time 23.535976605000087
Test Epoch47 layer0 Acc 0.6906, AUC 0.7595686912536621, avg_entr 0.18003317713737488, f1 0.6905999779701233
ep47_l0_test_time 0.3079735860001165
Test Epoch47 layer1 Acc 0.7056, AUC 0.7727065086364746, avg_entr 0.06718759983778, f1 0.7056000232696533
ep47_l1_test_time 0.38536626199993407
Test Epoch47 layer2 Acc 0.7212, AUC 0.7967433929443359, avg_entr 0.05885474756360054, f1 0.7211999893188477
ep47_l2_test_time 0.49582481100014775
Test Epoch47 layer3 Acc 0.7318, AUC 0.808373212814331, avg_entr 0.051060356199741364, f1 0.7318000197410583
ep47_l3_test_time 0.643648618999805
Test Epoch47 layer4 Acc 0.7318, AUC 0.8075850605964661, avg_entr 0.05024927482008934, f1 0.7318000197410583
ep47_l4_test_time 0.8349271730000964
gc 0
Train Epoch48 Acc 0.95435 (38174/40000), AUC 0.9900919795036316
ep48_train_time 23.501651191000065
Test Epoch48 layer0 Acc 0.6916, AUC 0.7595689296722412, avg_entr 0.17993350327014923, f1 0.6916000247001648
ep48_l0_test_time 0.31017095000015615
Test Epoch48 layer1 Acc 0.7054, AUC 0.7732136845588684, avg_entr 0.06739966571331024, f1 0.7053999900817871
ep48_l1_test_time 0.3882449190000443
Test Epoch48 layer2 Acc 0.7218, AUC 0.7968603372573853, avg_entr 0.058846697211265564, f1 0.7217999696731567
ep48_l2_test_time 0.4977568169999813
Test Epoch48 layer3 Acc 0.7318, AUC 0.808564305305481, avg_entr 0.05100349709391594, f1 0.7318000197410583
ep48_l3_test_time 0.6426810799998748
Test Epoch48 layer4 Acc 0.7312, AUC 0.8077685236930847, avg_entr 0.05021249130368233, f1 0.7311999797821045
ep48_l4_test_time 0.8393415830000777
gc 0
Train Epoch49 Acc 0.9542 (38168/40000), AUC 0.989844560623169
ep49_train_time 23.536692320000157
Test Epoch49 layer0 Acc 0.6912, AUC 0.7595458030700684, avg_entr 0.17981331050395966, f1 0.6912000179290771
ep49_l0_test_time 0.3086125600000287
Test Epoch49 layer1 Acc 0.7058, AUC 0.7727082371711731, avg_entr 0.0669119730591774, f1 0.7057999968528748
ep49_l1_test_time 0.3871550860001207
Test Epoch49 layer2 Acc 0.722, AUC 0.7966742515563965, avg_entr 0.05865855887532234, f1 0.722000002861023
ep49_l2_test_time 0.494996780000065
Test Epoch49 layer3 Acc 0.7312, AUC 0.8083251714706421, avg_entr 0.0509306900203228, f1 0.7311999797821045
ep49_l3_test_time 0.6440286570000353
Test Epoch49 layer4 Acc 0.7308, AUC 0.8075393438339233, avg_entr 0.050191380083560944, f1 0.7307999730110168
ep49_l4_test_time 0.8351931209999748
Best AUC tensor(0.7566) 13 3
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
total_train+valid_time 1310.39080305
Start Testing
Load ckpt at ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt
gc 9
Test layer0 Acc 0.7134, AUC 0.795427680015564, avg_entr 0.2419378161430359, f1 0.7134000062942505
l0_test_time 0.31252541900016695
gc 0
Test layer1 Acc 0.7484, AUC 0.8301182985305786, avg_entr 0.20891445875167847, f1 0.7483999729156494
l1_test_time 0.38606592499991166
gc 0
Test layer2 Acc 0.7586, AUC 0.8416616320610046, avg_entr 0.14911265671253204, f1 0.7585999965667725
l2_test_time 0.4952678769998329
gc 0
Test layer3 Acc 0.7636, AUC 0.8474705219268799, avg_entr 0.14619193971157074, f1 0.7635999917984009
l3_test_time 0.6435165640000378
gc 0
Test layer4 Acc 0.7686, AUC 0.8499901294708252, avg_entr 0.1512657105922699, f1 0.7685999870300293
l4_test_time 0.8342530219999844
gc 0
Test threshold 0.1 Acc 0.7658, AUC 0.8353058695793152, avg_entr 0.2067410945892334, f1 0.7657999992370605
t0.1_test_time 0.6199010139998791
gc 0
Test threshold 0.2 Acc 0.762, AUC 0.8258620500564575, avg_entr 0.20829111337661743, f1 0.7619999647140503
t0.2_test_time 0.5692310629999611
gc 0
Test threshold 0.3 Acc 0.761, AUC 0.822927713394165, avg_entr 0.2140098214149475, f1 0.7610000371932983
t0.3_test_time 0.5206907780000165
gc 0
Test threshold 0.4 Acc 0.7592, AUC 0.8200064897537231, avg_entr 0.22479496896266937, f1 0.7591999769210815
t0.4_test_time 0.487243129999797
gc 0
Test threshold 0.5 Acc 0.7554, AUC 0.8161972761154175, avg_entr 0.23516179621219635, f1 0.7554000020027161
t0.5_test_time 0.4670552879999832
gc 0
Test threshold 0.6 Acc 0.7528, AUC 0.8128093481063843, avg_entr 0.24766889214515686, f1 0.7528000473976135
t0.6_test_time 0.4426446060001581
gc 0
Test threshold 0.7 Acc 0.7482, AUC 0.8097814917564392, avg_entr 0.2636726200580597, f1 0.748199999332428
t0.7_test_time 0.43780352900012076
gc 0
Test threshold 0.8 Acc 0.743, AUC 0.8070259094238281, avg_entr 0.28088271617889404, f1 0.7430000305175781
t0.8_test_time 0.40942516099994464
gc 0
Test threshold 0.9 Acc 0.7326, AUC 0.8026810884475708, avg_entr 0.30485308170318604, f1 0.7325999140739441
t0.9_test_time 0.394082446000084
