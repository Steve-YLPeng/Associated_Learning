total count words 222751
vocab size 30000
train size 40000, valid size 5000, test size 5000
found 27937 words in glove
model: TransformerALsideText(
  (layers): ModuleList(
    (0): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=2, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=2, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
  (emb_layers): ModuleList(
    (0): Embedding(30000, 300)
    (1): Embedding(30000, 300)
    (2): Embedding(30000, 300)
    (3): Embedding(30000, 300)
    (4): Embedding(30000, 300)
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.multi_headed_attention.linears.0.weight 90000
layers.0.enc.f.multi_headed_attention.linears.0.bias 300
layers.0.enc.f.multi_headed_attention.linears.1.weight 90000
layers.0.enc.f.multi_headed_attention.linears.1.bias 300
layers.0.enc.f.multi_headed_attention.linears.2.weight 90000
layers.0.enc.f.multi_headed_attention.linears.2.bias 300
layers.0.enc.f.multi_headed_attention.linears.3.weight 90000
layers.0.enc.f.multi_headed_attention.linears.3.bias 300
layers.0.enc.f.feed_forward.w_1.weight 90000
layers.0.enc.f.feed_forward.w_1.bias 300
layers.0.enc.f.feed_forward.w_2.weight 90000
layers.0.enc.f.feed_forward.w_2.bias 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.0.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.0.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.0.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.0.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.0.enc.f.encoder.norm.a 300
layers.0.enc.f.encoder.norm.b 300
layers.0.ae.g.0.weight 256
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 256
layers.0.ae.h.0.bias 2
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
emb_layers.0.weight 9000000
emb_layers.1.weight 9000000
emb_layers.2.weight 9000000
emb_layers.3.weight 9000000
emb_layers.4.weight 9000000
Total Trainable Params: 50758378
init_time 22.459756315
Start Training
gc 0
Train Epoch0 Acc 0.49965 (19986/40000), AUC 0.5005161762237549
ep0_train_time 23.745440391
Test Epoch0 layer0 Acc 0.5002, AUC 0.5788524150848389, avg_entr 0.6837097406387329, f1 0.5001999735832214
ep0_l0_test_time 0.3053581080000001
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 0
Test Epoch0 layer1 Acc 0.4988, AUC 0.5191746354103088, avg_entr 0.6902614831924438, f1 0.49880000948905945
ep0_l1_test_time 0.37744933599999797
Test Epoch0 layer2 Acc 0.5002, AUC 0.5167222023010254, avg_entr 0.6929745078086853, f1 0.5001999735832214
ep0_l2_test_time 0.4869531599999988
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 0
Test Epoch0 layer3 Acc 0.5002, AUC 0.5013427734375, avg_entr 0.687038004398346, f1 0.5001999735832214
ep0_l3_test_time 0.6378464369999932
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 0
Test Epoch0 layer4 Acc 0.5, AUC 0.4874919652938843, avg_entr 0.6914678812026978, f1 0.5
ep0_l4_test_time 0.8279682860000008
gc 0
Train Epoch1 Acc 0.510275 (20411/40000), AUC 0.5128523111343384
ep1_train_time 23.431655833999997
Test Epoch1 layer0 Acc 0.5706, AUC 0.6221756339073181, avg_entr 0.65765780210495, f1 0.5705999732017517
ep1_l0_test_time 0.3062462369999963
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 1
Test Epoch1 layer1 Acc 0.5782, AUC 0.607372522354126, avg_entr 0.6920539140701294, f1 0.5781999826431274
ep1_l1_test_time 0.37727311499999416
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 1
Test Epoch1 layer2 Acc 0.5458, AUC 0.5669790506362915, avg_entr 0.6969893574714661, f1 0.545799970626831
ep1_l2_test_time 0.4870286299999975
Test Epoch1 layer3 Acc 0.5176, AUC 0.5313614010810852, avg_entr 0.6939582228660583, f1 0.5175999999046326
ep1_l3_test_time 0.6375324369999902
Test Epoch1 layer4 Acc 0.5032, AUC 0.5070181488990784, avg_entr 0.6963270306587219, f1 0.5031999945640564
ep1_l4_test_time 0.8287656449999901
gc 0
Train Epoch2 Acc 0.51655 (20662/40000), AUC 0.5220193862915039
ep2_train_time 23.332022707999997
Test Epoch2 layer0 Acc 0.5694, AUC 0.6870220303535461, avg_entr 0.4445444941520691, f1 0.5694000124931335
ep2_l0_test_time 0.30532210600000553
Test Epoch2 layer1 Acc 0.579, AUC 0.7111614942550659, avg_entr 0.4754818379878998, f1 0.5789999961853027
ep2_l1_test_time 0.3784837869999933
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 2
Test Epoch2 layer2 Acc 0.6328, AUC 0.709281325340271, avg_entr 0.5938604474067688, f1 0.6327999830245972
ep2_l2_test_time 0.4873111790000024
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 2
Test Epoch2 layer3 Acc 0.5194, AUC 0.6904410123825073, avg_entr 0.6391366124153137, f1 0.5194000005722046
ep2_l3_test_time 0.6386080919999984
Test Epoch2 layer4 Acc 0.5, AUC 0.6026784181594849, avg_entr 0.6025449633598328, f1 0.5
ep2_l4_test_time 0.8298296309999955
gc 0
Train Epoch3 Acc 0.559825 (22393/40000), AUC 0.5860394835472107
ep3_train_time 23.45715821600001
Test Epoch3 layer0 Acc 0.6484, AUC 0.7203766107559204, avg_entr 0.4717489778995514, f1 0.6484000086784363
ep3_l0_test_time 0.30678675399998667
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 3
Test Epoch3 layer1 Acc 0.6382, AUC 0.747606635093689, avg_entr 0.39194074273109436, f1 0.6381999850273132
ep3_l1_test_time 0.38305574400001774
Test Epoch3 layer2 Acc 0.5918, AUC 0.7460203170776367, avg_entr 0.30224671959877014, f1 0.5917999744415283
ep3_l2_test_time 0.48786168699999166
Test Epoch3 layer3 Acc 0.541, AUC 0.7475754618644714, avg_entr 0.24914398789405823, f1 0.5410000085830688
ep3_l3_test_time 0.6383100000000184
Test Epoch3 layer4 Acc 0.5156, AUC 0.7474018931388855, avg_entr 0.45836254954338074, f1 0.5156000256538391
ep3_l4_test_time 0.8313605909999922
gc 0
Train Epoch4 Acc 0.6044 (24176/40000), AUC 0.6500741243362427
ep4_train_time 23.44007952999999
Test Epoch4 layer0 Acc 0.6746, AUC 0.7454513907432556, avg_entr 0.429765909910202, f1 0.6746000051498413
ep4_l0_test_time 0.3061046870000155
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
Test Epoch4 layer1 Acc 0.7028, AUC 0.7800354957580566, avg_entr 0.4133836030960083, f1 0.7027999758720398
ep4_l1_test_time 0.3787179229999822
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
Test Epoch4 layer2 Acc 0.7044, AUC 0.7838543057441711, avg_entr 0.41137176752090454, f1 0.7044000029563904
ep4_l2_test_time 0.4871225850000087
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
Test Epoch4 layer3 Acc 0.7084, AUC 0.7849218845367432, avg_entr 0.44504180550575256, f1 0.7084000110626221
ep4_l3_test_time 0.6399216359999969
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 4
Test Epoch4 layer4 Acc 0.6548, AUC 0.7841614484786987, avg_entr 0.5160137414932251, f1 0.6547999978065491
ep4_l4_test_time 0.8315698049999867
gc 0
Train Epoch5 Acc 0.657975 (26319/40000), AUC 0.7113348245620728
ep5_train_time 23.35345326800001
Test Epoch5 layer0 Acc 0.6924, AUC 0.765358567237854, avg_entr 0.40688833594322205, f1 0.6923999786376953
ep5_l0_test_time 0.30910761199999115
Test Epoch5 layer1 Acc 0.6964, AUC 0.7999595403671265, avg_entr 0.38684096932411194, f1 0.696399986743927
ep5_l1_test_time 0.37777307299998597
Test Epoch5 layer2 Acc 0.655, AUC 0.8060506582260132, avg_entr 0.40042248368263245, f1 0.6549999713897705
ep5_l2_test_time 0.4884295869999846
Test Epoch5 layer3 Acc 0.5592, AUC 0.806155800819397, avg_entr 0.3017246723175049, f1 0.5591999888420105
ep5_l3_test_time 0.6384108620000006
Test Epoch5 layer4 Acc 0.5, AUC 0.8053075075149536, avg_entr 0.11887463182210922, f1 0.5
ep5_l4_test_time 0.8310253129999978
gc 0
Train Epoch6 Acc 0.709625 (28385/40000), AUC 0.7852241396903992
ep6_train_time 23.39174867700001
Test Epoch6 layer0 Acc 0.7004, AUC 0.7791367769241333, avg_entr 0.3563535809516907, f1 0.7003999948501587
ep6_l0_test_time 0.30513093700000127
Test Epoch6 layer1 Acc 0.7332, AUC 0.8152668476104736, avg_entr 0.31743133068084717, f1 0.7332000136375427
ep6_l1_test_time 0.3792017989999863
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer2 Acc 0.7394, AUC 0.8207744359970093, avg_entr 0.30610331892967224, f1 0.7394000291824341
ep6_l2_test_time 0.4865267460000098
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
Test Epoch6 layer3 Acc 0.7378, AUC 0.8209448456764221, avg_entr 0.311984121799469, f1 0.7378000020980835
ep6_l3_test_time 0.6364330109999798
Test Epoch6 layer4 Acc 0.7398, AUC 0.8214297294616699, avg_entr 0.35366058349609375, f1 0.7398000359535217
ep6_l4_test_time 0.8294964609999909
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 6
gc 0
Train Epoch7 Acc 0.745425 (29817/40000), AUC 0.8272241950035095
ep7_train_time 23.375921589
Test Epoch7 layer0 Acc 0.7038, AUC 0.7883201837539673, avg_entr 0.3442472219467163, f1 0.7038000226020813
ep7_l0_test_time 0.30691895900000077
Test Epoch7 layer1 Acc 0.7252, AUC 0.8240385055541992, avg_entr 0.31451329588890076, f1 0.7251999974250793
ep7_l1_test_time 0.3788656000000117
Test Epoch7 layer2 Acc 0.6978, AUC 0.8328801393508911, avg_entr 0.2889421284198761, f1 0.6977999806404114
ep7_l2_test_time 0.48987120500001424
Test Epoch7 layer3 Acc 0.6712, AUC 0.8348613977432251, avg_entr 0.2757830321788788, f1 0.6711999773979187
ep7_l3_test_time 0.6378834660000052
Test Epoch7 layer4 Acc 0.6014, AUC 0.8352491855621338, avg_entr 0.23479558527469635, f1 0.6014000177383423
ep7_l4_test_time 0.8352411679999818
gc 0
Train Epoch8 Acc 0.76765 (30706/40000), AUC 0.8507641553878784
ep8_train_time 23.383410688000026
Test Epoch8 layer0 Acc 0.718, AUC 0.7933064699172974, avg_entr 0.32319939136505127, f1 0.7179999351501465
ep8_l0_test_time 0.3052229620000162
Test Epoch8 layer1 Acc 0.7414, AUC 0.8294409513473511, avg_entr 0.2838941216468811, f1 0.7414000034332275
ep8_l1_test_time 0.37904756199998246
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 8
Test Epoch8 layer2 Acc 0.7476, AUC 0.8401801586151123, avg_entr 0.2630867063999176, f1 0.7476000189781189
ep8_l2_test_time 0.48767239599999357
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 8
Test Epoch8 layer3 Acc 0.7452, AUC 0.8431520462036133, avg_entr 0.252667099237442, f1 0.745199978351593
ep8_l3_test_time 0.6364856679999775
Test Epoch8 layer4 Acc 0.7334, AUC 0.8440165519714355, avg_entr 0.2430276870727539, f1 0.7333999872207642
ep8_l4_test_time 0.8299821139999608
gc 0
Train Epoch9 Acc 0.782675 (31307/40000), AUC 0.8634483814239502
ep9_train_time 23.352899974000024
Test Epoch9 layer0 Acc 0.7208, AUC 0.7961630821228027, avg_entr 0.28647804260253906, f1 0.7207999229431152
ep9_l0_test_time 0.31500702300002104
Test Epoch9 layer1 Acc 0.7562, AUC 0.8343927264213562, avg_entr 0.2478865683078766, f1 0.7561999559402466
ep9_l1_test_time 0.3814796830000091
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 9
Test Epoch9 layer2 Acc 0.7626, AUC 0.8449406623840332, avg_entr 0.22491708397865295, f1 0.7626000046730042
ep9_l2_test_time 0.4887140199999749
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 9
Test Epoch9 layer3 Acc 0.7672, AUC 0.8483102321624756, avg_entr 0.2224806845188141, f1 0.7671999931335449
ep9_l3_test_time 0.6380464439999969
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 9
Test Epoch9 layer4 Acc 0.7656, AUC 0.8493858575820923, avg_entr 0.21443462371826172, f1 0.7655999660491943
ep9_l4_test_time 0.830563820000009
gc 0
Train Epoch10 Acc 0.801775 (32071/40000), AUC 0.8834093809127808
ep10_train_time 23.389694652999992
Test Epoch10 layer0 Acc 0.7218, AUC 0.7975696325302124, avg_entr 0.28657227754592896, f1 0.7217999696731567
ep10_l0_test_time 0.3063101860000188
Test Epoch10 layer1 Acc 0.7518, AUC 0.837093710899353, avg_entr 0.2684864401817322, f1 0.751800000667572
ep10_l1_test_time 0.37859239099998376
Test Epoch10 layer2 Acc 0.7624, AUC 0.8492174744606018, avg_entr 0.2631082832813263, f1 0.7623999714851379
ep10_l2_test_time 0.4878701590000105
Test Epoch10 layer3 Acc 0.769, AUC 0.8530905246734619, avg_entr 0.26176223158836365, f1 0.7689999938011169
ep10_l3_test_time 0.6373190369999975
Save ckpt to ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt  ,ep 10
Test Epoch10 layer4 Acc 0.7666, AUC 0.8540768623352051, avg_entr 0.2732923924922943, f1 0.7666000127792358
ep10_l4_test_time 0.8313464180000096
gc 0
Train Epoch11 Acc 0.81995 (32798/40000), AUC 0.9011064171791077
ep11_train_time 23.37889979700003
Test Epoch11 layer0 Acc 0.712, AUC 0.7980830669403076, avg_entr 0.258370041847229, f1 0.7120000123977661
ep11_l0_test_time 0.30964846599999873
Test Epoch11 layer1 Acc 0.7426, AUC 0.8359934091567993, avg_entr 0.22121790051460266, f1 0.7426000237464905
ep11_l1_test_time 0.3803842199999963
Test Epoch11 layer2 Acc 0.7466, AUC 0.8458646535873413, avg_entr 0.19841210544109344, f1 0.7465999126434326
ep11_l2_test_time 0.4891018999999801
Test Epoch11 layer3 Acc 0.749, AUC 0.8508930802345276, avg_entr 0.18116635084152222, f1 0.7490000128746033
ep11_l3_test_time 0.6384303759999739
Test Epoch11 layer4 Acc 0.7414, AUC 0.8513623476028442, avg_entr 0.16622118651866913, f1 0.7414000034332275
ep11_l4_test_time 0.8325303660000145
gc 0
Train Epoch12 Acc 0.84355 (33742/40000), AUC 0.9170107841491699
ep12_train_time 23.427726792999977
Test Epoch12 layer0 Acc 0.7058, AUC 0.7951964139938354, avg_entr 0.24697333574295044, f1 0.7057999968528748
ep12_l0_test_time 0.30749439300001313
Test Epoch12 layer1 Acc 0.7328, AUC 0.8298337459564209, avg_entr 0.21838964521884918, f1 0.7327999472618103
ep12_l1_test_time 0.3838824889999728
Test Epoch12 layer2 Acc 0.7332, AUC 0.8418707251548767, avg_entr 0.18202033638954163, f1 0.7332000136375427
ep12_l2_test_time 0.49646271000000297
Test Epoch12 layer3 Acc 0.7334, AUC 0.8474252223968506, avg_entr 0.15775591135025024, f1 0.7333999872207642
ep12_l3_test_time 0.6385872420000283
Test Epoch12 layer4 Acc 0.732, AUC 0.8474917411804199, avg_entr 0.1470504105091095, f1 0.7319999933242798
ep12_l4_test_time 0.8334755980000068
gc 0
Train Epoch13 Acc 0.86225 (34490/40000), AUC 0.9334051609039307
ep13_train_time 23.229796754999995
Test Epoch13 layer0 Acc 0.6906, AUC 0.7947810292243958, avg_entr 0.23356705904006958, f1 0.6905999779701233
ep13_l0_test_time 0.2895747590000042
Test Epoch13 layer1 Acc 0.7126, AUC 0.8295087814331055, avg_entr 0.19348596036434174, f1 0.7125999927520752
ep13_l1_test_time 0.366393042000027
Test Epoch13 layer2 Acc 0.7054, AUC 0.8391348123550415, avg_entr 0.12357811629772186, f1 0.7053999900817871
ep13_l2_test_time 0.4716488700000241
Test Epoch13 layer3 Acc 0.709, AUC 0.8429578542709351, avg_entr 0.10270421206951141, f1 0.7090000510215759
ep13_l3_test_time 0.6220841690000043
Test Epoch13 layer4 Acc 0.709, AUC 0.8432598114013672, avg_entr 0.09482157975435257, f1 0.7090000510215759
ep13_l4_test_time 0.8183015039999759
gc 0
Train Epoch14 Acc 0.87505 (35002/40000), AUC 0.9418944716453552
ep14_train_time 23.573107452000045
Test Epoch14 layer0 Acc 0.7114, AUC 0.7893215417861938, avg_entr 0.22624169290065765, f1 0.7113999724388123
ep14_l0_test_time 0.2845697110000174
Test Epoch14 layer1 Acc 0.7528, AUC 0.828935980796814, avg_entr 0.19272346794605255, f1 0.7528000473976135
ep14_l1_test_time 0.3554121149999787
Test Epoch14 layer2 Acc 0.7588, AUC 0.8405311107635498, avg_entr 0.11847040057182312, f1 0.7588000297546387
ep14_l2_test_time 0.4648104540000304
Test Epoch14 layer3 Acc 0.762, AUC 0.8474307060241699, avg_entr 0.10880865156650543, f1 0.7619999647140503
ep14_l3_test_time 0.6150676519999934
Test Epoch14 layer4 Acc 0.7668, AUC 0.8499128818511963, avg_entr 0.10703715682029724, f1 0.7667999863624573
ep14_l4_test_time 0.8130997300000331
gc 0
Train Epoch15 Acc 0.900175 (36007/40000), AUC 0.9606531858444214
ep15_train_time 23.008697549999965
Test Epoch15 layer0 Acc 0.6986, AUC 0.7847684621810913, avg_entr 0.21773183345794678, f1 0.6985999941825867
ep15_l0_test_time 0.28576693200000136
Test Epoch15 layer1 Acc 0.7324, AUC 0.8208094835281372, avg_entr 0.17420780658721924, f1 0.7323999404907227
ep15_l1_test_time 0.35968277000000626
Test Epoch15 layer2 Acc 0.743, AUC 0.8333791494369507, avg_entr 0.1028950959444046, f1 0.7430000305175781
ep15_l2_test_time 0.4632180169999742
Test Epoch15 layer3 Acc 0.749, AUC 0.8406046628952026, avg_entr 0.09508905559778214, f1 0.7490000128746033
ep15_l3_test_time 0.6128199409999979
Test Epoch15 layer4 Acc 0.7494, AUC 0.8429223299026489, avg_entr 0.09393087774515152, f1 0.7494000196456909
ep15_l4_test_time 0.807647712000005
gc 0
Train Epoch16 Acc 0.905375 (36215/40000), AUC 0.9625344276428223
ep16_train_time 22.998268623
Test Epoch16 layer0 Acc 0.7138, AUC 0.7817188501358032, avg_entr 0.2097020000219345, f1 0.7138000130653381
ep16_l0_test_time 0.28284288700001525
Test Epoch16 layer1 Acc 0.729, AUC 0.8148840665817261, avg_entr 0.1445789486169815, f1 0.7289999723434448
ep16_l1_test_time 0.35388450499999635
Test Epoch16 layer2 Acc 0.7348, AUC 0.8253400325775146, avg_entr 0.08579989522695541, f1 0.7347999811172485
ep16_l2_test_time 0.46515296199999057
Test Epoch16 layer3 Acc 0.7404, AUC 0.8328552842140198, avg_entr 0.0791148990392685, f1 0.7404000163078308
ep16_l3_test_time 0.6134521129999939
Test Epoch16 layer4 Acc 0.7408, AUC 0.8344460129737854, avg_entr 0.07674626260995865, f1 0.7408000230789185
ep16_l4_test_time 0.8106548310000221
gc 0
Train Epoch17 Acc 0.917675 (36707/40000), AUC 0.9708846211433411
ep17_train_time 23.055592515
Test Epoch17 layer0 Acc 0.7094, AUC 0.7834533452987671, avg_entr 0.19705568253993988, f1 0.709399938583374
ep17_l0_test_time 0.28396475099998497
Test Epoch17 layer1 Acc 0.7306, AUC 0.816760778427124, avg_entr 0.12724392116069794, f1 0.7305999994277954
ep17_l1_test_time 0.3547517639999569
Test Epoch17 layer2 Acc 0.745, AUC 0.8236123323440552, avg_entr 0.0889153778553009, f1 0.7449999451637268
ep17_l2_test_time 0.4644674290000239
Test Epoch17 layer3 Acc 0.7468, AUC 0.8354856967926025, avg_entr 0.08077828586101532, f1 0.7468000054359436
ep17_l3_test_time 0.6135193530000151
Test Epoch17 layer4 Acc 0.746, AUC 0.8391268253326416, avg_entr 0.08013568818569183, f1 0.7459999918937683
ep17_l4_test_time 0.8106832529999792
gc 0
Train Epoch18 Acc 0.922775 (36911/40000), AUC 0.9741071462631226
ep18_train_time 23.054035747
Test Epoch18 layer0 Acc 0.711, AUC 0.7799868583679199, avg_entr 0.20196743309497833, f1 0.7110000848770142
ep18_l0_test_time 0.28523374899998544
Test Epoch18 layer1 Acc 0.729, AUC 0.8070929050445557, avg_entr 0.10515154153108597, f1 0.7289999723434448
ep18_l1_test_time 0.35515404699992814
Test Epoch18 layer2 Acc 0.741, AUC 0.8217226266860962, avg_entr 0.07575526088476181, f1 0.7409999370574951
ep18_l2_test_time 0.4649140139999872
Test Epoch18 layer3 Acc 0.7416, AUC 0.8293620347976685, avg_entr 0.07101872563362122, f1 0.741599977016449
ep18_l3_test_time 0.6147314080000115
Test Epoch18 layer4 Acc 0.7422, AUC 0.831749677658081, avg_entr 0.0693698301911354, f1 0.7422000169754028
ep18_l4_test_time 0.8094654129999981
gc 0
Train Epoch19 Acc 0.933 (37320/40000), AUC 0.9810696840286255
ep19_train_time 23.124651935000088
Test Epoch19 layer0 Acc 0.7062, AUC 0.7776439189910889, avg_entr 0.20281867682933807, f1 0.7062000036239624
ep19_l0_test_time 0.28581556899996485
Test Epoch19 layer1 Acc 0.7252, AUC 0.8054555058479309, avg_entr 0.10616505146026611, f1 0.7251999974250793
ep19_l1_test_time 0.35731486200006657
Test Epoch19 layer2 Acc 0.7374, AUC 0.8189661502838135, avg_entr 0.0808761864900589, f1 0.7373999953269958
ep19_l2_test_time 0.46291326599998683
Test Epoch19 layer3 Acc 0.7432, AUC 0.8281381130218506, avg_entr 0.07749783247709274, f1 0.7432000041007996
ep19_l3_test_time 0.6137514970000666
Test Epoch19 layer4 Acc 0.7454, AUC 0.8308554291725159, avg_entr 0.07604391127824783, f1 0.745400071144104
ep19_l4_test_time 0.8088868100001037
gc 0
Train Epoch20 Acc 0.939025 (37561/40000), AUC 0.9835888147354126
ep20_train_time 23.039074354000036
Test Epoch20 layer0 Acc 0.707, AUC 0.776421308517456, avg_entr 0.19425128400325775, f1 0.7070000171661377
ep20_l0_test_time 0.28411035100009485
Test Epoch20 layer1 Acc 0.722, AUC 0.800727128982544, avg_entr 0.09414616972208023, f1 0.722000002861023
ep20_l1_test_time 0.35471538100000544
Test Epoch20 layer2 Acc 0.7382, AUC 0.8111116886138916, avg_entr 0.06801098585128784, f1 0.7382000684738159
ep20_l2_test_time 0.4644800049999276
Test Epoch20 layer3 Acc 0.7436, AUC 0.82268226146698, avg_entr 0.06547471880912781, f1 0.7436000108718872
ep20_l3_test_time 0.6140424080000457
Test Epoch20 layer4 Acc 0.744, AUC 0.825374960899353, avg_entr 0.06250419467687607, f1 0.7439999580383301
ep20_l4_test_time 0.8089656889999333
gc 0
Train Epoch21 Acc 0.9432 (37728/40000), AUC 0.9845254421234131
ep21_train_time 23.0207152480001
Test Epoch21 layer0 Acc 0.7068, AUC 0.7753808498382568, avg_entr 0.19004122912883759, f1 0.7067999839782715
ep21_l0_test_time 0.2839727470000071
Test Epoch21 layer1 Acc 0.7224, AUC 0.7999595403671265, avg_entr 0.08782605826854706, f1 0.7224000096321106
ep21_l1_test_time 0.3570458840000583
Test Epoch21 layer2 Acc 0.7348, AUC 0.8074457049369812, avg_entr 0.06502728164196014, f1 0.7347999811172485
ep21_l2_test_time 0.4649713270000575
Test Epoch21 layer3 Acc 0.7422, AUC 0.8203123807907104, avg_entr 0.05906511843204498, f1 0.7422000169754028
ep21_l3_test_time 0.6200092900000982
Test Epoch21 layer4 Acc 0.7446, AUC 0.8236991167068481, avg_entr 0.056808508932590485, f1 0.7445999979972839
ep21_l4_test_time 0.8086171219999869
gc 0
Train Epoch22 Acc 0.945825 (37833/40000), AUC 0.9863206148147583
ep22_train_time 23.06800763199999
Test Epoch22 layer0 Acc 0.7048, AUC 0.7743555307388306, avg_entr 0.18880796432495117, f1 0.704800009727478
ep22_l0_test_time 0.2845725319999701
Test Epoch22 layer1 Acc 0.7282, AUC 0.7999598383903503, avg_entr 0.08909094333648682, f1 0.7282000184059143
ep22_l1_test_time 0.35428351400003066
Test Epoch22 layer2 Acc 0.7398, AUC 0.8098269701004028, avg_entr 0.06349065899848938, f1 0.7398000359535217
ep22_l2_test_time 0.46401441599994087
Test Epoch22 layer3 Acc 0.7436, AUC 0.821008026599884, avg_entr 0.0592506118118763, f1 0.7436000108718872
ep22_l3_test_time 0.6139117919999535
Test Epoch22 layer4 Acc 0.745, AUC 0.8249877691268921, avg_entr 0.05677108094096184, f1 0.7449999451637268
ep22_l4_test_time 0.8079596869999932
gc 0
Train Epoch23 Acc 0.950025 (38001/40000), AUC 0.9883884191513062
ep23_train_time 23.002945666000073
Test Epoch23 layer0 Acc 0.7036, AUC 0.7742332220077515, avg_entr 0.18490707874298096, f1 0.7035999894142151
ep23_l0_test_time 0.28415625800005273
Test Epoch23 layer1 Acc 0.7262, AUC 0.7984106540679932, avg_entr 0.08386865258216858, f1 0.7261999845504761
ep23_l1_test_time 0.35415316899991467
Test Epoch23 layer2 Acc 0.7348, AUC 0.8074450492858887, avg_entr 0.06054207682609558, f1 0.7347999811172485
ep23_l2_test_time 0.46349110800008475
Test Epoch23 layer3 Acc 0.7398, AUC 0.8196198344230652, avg_entr 0.05604349821805954, f1 0.7398000359535217
ep23_l3_test_time 0.6147155219999831
Test Epoch23 layer4 Acc 0.741, AUC 0.8234896659851074, avg_entr 0.0536826066672802, f1 0.7409999370574951
ep23_l4_test_time 0.8090154599999551
gc 0
Train Epoch24 Acc 0.95205 (38082/40000), AUC 0.9890208840370178
ep24_train_time 23.003032681000036
Test Epoch24 layer0 Acc 0.7012, AUC 0.7716710567474365, avg_entr 0.18540708720684052, f1 0.701200008392334
ep24_l0_test_time 0.2834877239999969
Test Epoch24 layer1 Acc 0.72, AUC 0.7942894697189331, avg_entr 0.08221204578876495, f1 0.7199999690055847
ep24_l1_test_time 0.35386893199995484
Test Epoch24 layer2 Acc 0.7338, AUC 0.8025493621826172, avg_entr 0.05926283448934555, f1 0.7338000535964966
ep24_l2_test_time 0.4630553599999985
Test Epoch24 layer3 Acc 0.7384, AUC 0.8170992136001587, avg_entr 0.05553795024752617, f1 0.7384000420570374
ep24_l3_test_time 0.6138497150000148
Test Epoch24 layer4 Acc 0.739, AUC 0.820670485496521, avg_entr 0.05244242399930954, f1 0.7390000820159912
ep24_l4_test_time 0.8095849400000361
gc 0
Train Epoch25 Acc 0.953675 (38147/40000), AUC 0.989219605922699
ep25_train_time 23.06565995400001
Test Epoch25 layer0 Acc 0.7016, AUC 0.7716258764266968, avg_entr 0.18285831809043884, f1 0.7016000151634216
ep25_l0_test_time 0.2848963310000272
Test Epoch25 layer1 Acc 0.719, AUC 0.7921905517578125, avg_entr 0.08081834763288498, f1 0.718999981880188
ep25_l1_test_time 0.35719959300001847
Test Epoch25 layer2 Acc 0.7318, AUC 0.8008874654769897, avg_entr 0.056484319269657135, f1 0.7318000197410583
ep25_l2_test_time 0.4651714390000734
Test Epoch25 layer3 Acc 0.7392, AUC 0.8161081075668335, avg_entr 0.053836725652217865, f1 0.7391999959945679
ep25_l3_test_time 0.614333160000001
Test Epoch25 layer4 Acc 0.7402, AUC 0.8192663192749023, avg_entr 0.052141014486551285, f1 0.7401999831199646
ep25_l4_test_time 0.8099614459999884
gc 0
Train Epoch26 Acc 0.9543 (38172/40000), AUC 0.9888681173324585
ep26_train_time 23.097996911999985
Test Epoch26 layer0 Acc 0.6994, AUC 0.7722787261009216, avg_entr 0.18125922977924347, f1 0.699400007724762
ep26_l0_test_time 0.2884432140000399
Test Epoch26 layer1 Acc 0.7198, AUC 0.7934755682945251, avg_entr 0.08120258897542953, f1 0.7197999358177185
ep26_l1_test_time 0.3567288730000655
Test Epoch26 layer2 Acc 0.7322, AUC 0.8022066354751587, avg_entr 0.058001238852739334, f1 0.732200026512146
ep26_l2_test_time 0.46626961999993455
Test Epoch26 layer3 Acc 0.7402, AUC 0.8177295923233032, avg_entr 0.055143047124147415, f1 0.7401999831199646
ep26_l3_test_time 0.6169373190000442
Test Epoch26 layer4 Acc 0.7432, AUC 0.8212996125221252, avg_entr 0.052394673228263855, f1 0.7432000041007996
ep26_l4_test_time 0.8104630340000085
gc 0
Train Epoch27 Acc 0.957175 (38287/40000), AUC 0.9909024238586426
ep27_train_time 23.055491046000043
Test Epoch27 layer0 Acc 0.699, AUC 0.7704893350601196, avg_entr 0.18127326667308807, f1 0.6990000009536743
ep27_l0_test_time 0.28524442800005545
Test Epoch27 layer1 Acc 0.7192, AUC 0.7920361161231995, avg_entr 0.07845274358987808, f1 0.719200074672699
ep27_l1_test_time 0.35443123100003504
Test Epoch27 layer2 Acc 0.7304, AUC 0.7988296151161194, avg_entr 0.05419261008501053, f1 0.7304000854492188
ep27_l2_test_time 0.46418683100000635
Test Epoch27 layer3 Acc 0.7382, AUC 0.8149439096450806, avg_entr 0.05111246556043625, f1 0.7382000684738159
ep27_l3_test_time 0.6126162770000292
Test Epoch27 layer4 Acc 0.7388, AUC 0.8181086778640747, avg_entr 0.047747135162353516, f1 0.7387999892234802
ep27_l4_test_time 0.8088401699999395
gc 0
Train Epoch28 Acc 0.95805 (38322/40000), AUC 0.9911977052688599
ep28_train_time 23.048321447000035
Test Epoch28 layer0 Acc 0.6976, AUC 0.770016074180603, avg_entr 0.18098615109920502, f1 0.6976000070571899
ep28_l0_test_time 0.28590319300008105
Test Epoch28 layer1 Acc 0.7182, AUC 0.7897201776504517, avg_entr 0.07556525617837906, f1 0.7182000279426575
ep28_l1_test_time 0.3550080469999557
Test Epoch28 layer2 Acc 0.7318, AUC 0.7955665588378906, avg_entr 0.053299933671951294, f1 0.7318000197410583
ep28_l2_test_time 0.46404199199992036
Test Epoch28 layer3 Acc 0.7386, AUC 0.812562108039856, avg_entr 0.050311848521232605, f1 0.7386000156402588
ep28_l3_test_time 0.613320323000039
Test Epoch28 layer4 Acc 0.739, AUC 0.8165173530578613, avg_entr 0.048303261399269104, f1 0.7390000820159912
ep28_l4_test_time 0.8082273919999352
gc 0
Train Epoch29 Acc 0.9591 (38364/40000), AUC 0.9914065599441528
ep29_train_time 23.083938374000013
Test Epoch29 layer0 Acc 0.7004, AUC 0.7705259323120117, avg_entr 0.17888009548187256, f1 0.7003999948501587
ep29_l0_test_time 0.2838127730000224
Test Epoch29 layer1 Acc 0.7204, AUC 0.7912980914115906, avg_entr 0.07475020736455917, f1 0.7204000353813171
ep29_l1_test_time 0.3571249149999858
Test Epoch29 layer2 Acc 0.7308, AUC 0.7978541851043701, avg_entr 0.05264213681221008, f1 0.7307999730110168
ep29_l2_test_time 0.4640783669999564
Test Epoch29 layer3 Acc 0.7362, AUC 0.8139488101005554, avg_entr 0.05047401040792465, f1 0.7361999750137329
ep29_l3_test_time 0.6130022380000355
Test Epoch29 layer4 Acc 0.736, AUC 0.817949652671814, avg_entr 0.047940708696842194, f1 0.7360000014305115
ep29_l4_test_time 0.8094532779999781
gc 0
Train Epoch30 Acc 0.959075 (38363/40000), AUC 0.9913000464439392
ep30_train_time 23.113757467000028
Test Epoch30 layer0 Acc 0.697, AUC 0.7697336077690125, avg_entr 0.1805865317583084, f1 0.6970000267028809
ep30_l0_test_time 0.28468189299996993
Test Epoch30 layer1 Acc 0.7164, AUC 0.7886066436767578, avg_entr 0.07489840686321259, f1 0.7164000272750854
ep30_l1_test_time 0.35419527299995934
Test Epoch30 layer2 Acc 0.7334, AUC 0.7949350476264954, avg_entr 0.04980986565351486, f1 0.7333999872207642
ep30_l2_test_time 0.4640137249999725
Test Epoch30 layer3 Acc 0.74, AUC 0.8127976655960083, avg_entr 0.0482330322265625, f1 0.7400000095367432
ep30_l3_test_time 0.6138192969999636
Test Epoch30 layer4 Acc 0.7376, AUC 0.8170156478881836, avg_entr 0.04550689086318016, f1 0.7376000285148621
ep30_l4_test_time 0.8078883750000614
gc 0
Train Epoch31 Acc 0.96 (38400/40000), AUC 0.9918038845062256
ep31_train_time 23.00782854800002
Test Epoch31 layer0 Acc 0.6994, AUC 0.7701160311698914, avg_entr 0.1765662580728531, f1 0.699400007724762
ep31_l0_test_time 0.2855706249999912
Test Epoch31 layer1 Acc 0.7218, AUC 0.7893209457397461, avg_entr 0.07283014804124832, f1 0.7217999696731567
ep31_l1_test_time 0.3550217579999071
Test Epoch31 layer2 Acc 0.7312, AUC 0.7966433763504028, avg_entr 0.05010826513171196, f1 0.7311999797821045
ep31_l2_test_time 0.4645399639999823
Test Epoch31 layer3 Acc 0.7366, AUC 0.8130403757095337, avg_entr 0.045869771391153336, f1 0.7365999817848206
ep31_l3_test_time 0.6136165389999633
Test Epoch31 layer4 Acc 0.7366, AUC 0.8175324201583862, avg_entr 0.043452583253383636, f1 0.7365999817848206
ep31_l4_test_time 0.808643802000006
gc 0
Train Epoch32 Acc 0.960525 (38421/40000), AUC 0.9919843673706055
ep32_train_time 23.10127566799997
Test Epoch32 layer0 Acc 0.6984, AUC 0.7697928547859192, avg_entr 0.17719966173171997, f1 0.6984000205993652
ep32_l0_test_time 0.28430069099999855
Test Epoch32 layer1 Acc 0.7196, AUC 0.7895638942718506, avg_entr 0.07345650345087051, f1 0.7196000218391418
ep32_l1_test_time 0.3545249320000039
Test Epoch32 layer2 Acc 0.7314, AUC 0.7967416048049927, avg_entr 0.05129498988389969, f1 0.7314000129699707
ep32_l2_test_time 0.4631719820000626
Test Epoch32 layer3 Acc 0.7378, AUC 0.812843918800354, avg_entr 0.04763278365135193, f1 0.7378000020980835
ep32_l3_test_time 0.6138229680000222
Test Epoch32 layer4 Acc 0.738, AUC 0.8176634311676025, avg_entr 0.04538574814796448, f1 0.7379999160766602
ep32_l4_test_time 0.8098730140000043
gc 0
Train Epoch33 Acc 0.9621 (38484/40000), AUC 0.9922768473625183
ep33_train_time 23.103994187000012
Test Epoch33 layer0 Acc 0.6984, AUC 0.7695462107658386, avg_entr 0.1777801662683487, f1 0.6984000205993652
ep33_l0_test_time 0.28393088099994657
Test Epoch33 layer1 Acc 0.7192, AUC 0.788485050201416, avg_entr 0.07300113886594772, f1 0.719200074672699
ep33_l1_test_time 0.3548031560000027
Test Epoch33 layer2 Acc 0.732, AUC 0.7951319217681885, avg_entr 0.049431219696998596, f1 0.7319999933242798
ep33_l2_test_time 0.466233705000036
Test Epoch33 layer3 Acc 0.739, AUC 0.8123267889022827, avg_entr 0.04558451846241951, f1 0.7390000820159912
ep33_l3_test_time 0.6144375290000426
Test Epoch33 layer4 Acc 0.741, AUC 0.8165491819381714, avg_entr 0.04267431050539017, f1 0.7409999370574951
ep33_l4_test_time 0.8089709370000264
gc 0
Train Epoch34 Acc 0.96195 (38478/40000), AUC 0.992100715637207
ep34_train_time 23.029739423000024
Test Epoch34 layer0 Acc 0.6978, AUC 0.7697842121124268, avg_entr 0.1764180064201355, f1 0.6977999806404114
ep34_l0_test_time 0.2846269010000242
Test Epoch34 layer1 Acc 0.7184, AUC 0.7881336212158203, avg_entr 0.07181824743747711, f1 0.7184000015258789
ep34_l1_test_time 0.3536442629999783
Test Epoch34 layer2 Acc 0.732, AUC 0.7961591482162476, avg_entr 0.0505451001226902, f1 0.7319999933242798
ep34_l2_test_time 0.46398704900002485
Test Epoch34 layer3 Acc 0.7378, AUC 0.8121213912963867, avg_entr 0.046687908470630646, f1 0.7378000020980835
ep34_l3_test_time 0.6143039500000214
Test Epoch34 layer4 Acc 0.7394, AUC 0.8167638778686523, avg_entr 0.044404540210962296, f1 0.7394000291824341
ep34_l4_test_time 0.8081405289999566
gc 0
Train Epoch35 Acc 0.961825 (38473/40000), AUC 0.9920965433120728
ep35_train_time 23.006313193999972
Test Epoch35 layer0 Acc 0.6982, AUC 0.7689943313598633, avg_entr 0.17714755237102509, f1 0.698199987411499
ep35_l0_test_time 0.2858493169999292
Test Epoch35 layer1 Acc 0.7174, AUC 0.7867879867553711, avg_entr 0.07077107578516006, f1 0.717400074005127
ep35_l1_test_time 0.3568449199999577
Test Epoch35 layer2 Acc 0.7314, AUC 0.7943133115768433, avg_entr 0.04924681410193443, f1 0.7314000129699707
ep35_l2_test_time 0.4740483479999966
Test Epoch35 layer3 Acc 0.7392, AUC 0.8112142086029053, avg_entr 0.04711286351084709, f1 0.7391999959945679
ep35_l3_test_time 0.6146488269999963
Test Epoch35 layer4 Acc 0.741, AUC 0.8155270218849182, avg_entr 0.0440496951341629, f1 0.7409999370574951
ep35_l4_test_time 0.811876818000087
gc 0
Train Epoch36 Acc 0.96235 (38494/40000), AUC 0.9924489259719849
ep36_train_time 22.997162295000066
Test Epoch36 layer0 Acc 0.698, AUC 0.7689546346664429, avg_entr 0.17721755802631378, f1 0.6980000138282776
ep36_l0_test_time 0.28378117299996575
Test Epoch36 layer1 Acc 0.7154, AUC 0.7865673303604126, avg_entr 0.07069260627031326, f1 0.715399980545044
ep36_l1_test_time 0.35490372399999615
Test Epoch36 layer2 Acc 0.7316, AUC 0.7933570742607117, avg_entr 0.04878228157758713, f1 0.7316000461578369
ep36_l2_test_time 0.46486693499991816
Test Epoch36 layer3 Acc 0.7394, AUC 0.8111299276351929, avg_entr 0.046863947063684464, f1 0.7394000291824341
ep36_l3_test_time 0.614513278000004
Test Epoch36 layer4 Acc 0.7392, AUC 0.8150404691696167, avg_entr 0.04426247254014015, f1 0.7391999959945679
ep36_l4_test_time 0.8093453530000261
gc 0
Train Epoch37 Acc 0.96195 (38478/40000), AUC 0.9926500916481018
ep37_train_time 22.998136632999945
Test Epoch37 layer0 Acc 0.698, AUC 0.7690471410751343, avg_entr 0.17656829953193665, f1 0.6980000138282776
ep37_l0_test_time 0.28396445200007747
Test Epoch37 layer1 Acc 0.7184, AUC 0.7882421016693115, avg_entr 0.07135874778032303, f1 0.7184000015258789
ep37_l1_test_time 0.35446220000005724
Test Epoch37 layer2 Acc 0.7304, AUC 0.7960922718048096, avg_entr 0.05008542537689209, f1 0.7304000854492188
ep37_l2_test_time 0.4644420669999363
Test Epoch37 layer3 Acc 0.7376, AUC 0.8125407099723816, avg_entr 0.04684920236468315, f1 0.7376000285148621
ep37_l3_test_time 0.6144967830000496
Test Epoch37 layer4 Acc 0.7368, AUC 0.8172307014465332, avg_entr 0.04445221275091171, f1 0.7368000149726868
ep37_l4_test_time 0.8094070330000704
gc 0
Train Epoch38 Acc 0.963275 (38531/40000), AUC 0.992811918258667
ep38_train_time 23.02530567600013
Test Epoch38 layer0 Acc 0.6996, AUC 0.7691782116889954, avg_entr 0.17533783614635468, f1 0.6995999813079834
ep38_l0_test_time 0.2866667159998997
Test Epoch38 layer1 Acc 0.718, AUC 0.7883998155593872, avg_entr 0.07143012434244156, f1 0.7179999351501465
ep38_l1_test_time 0.35481270900004347
Test Epoch38 layer2 Acc 0.7304, AUC 0.7954187393188477, avg_entr 0.050028786063194275, f1 0.7304000854492188
ep38_l2_test_time 0.46434168899986616
Test Epoch38 layer3 Acc 0.7368, AUC 0.8123974800109863, avg_entr 0.046674542129039764, f1 0.7368000149726868
ep38_l3_test_time 0.6132860990001063
Test Epoch38 layer4 Acc 0.7374, AUC 0.8170312643051147, avg_entr 0.044468194246292114, f1 0.7373999953269958
ep38_l4_test_time 0.8090593740000713
gc 0
Train Epoch39 Acc 0.96325 (38530/40000), AUC 0.9931443929672241
ep39_train_time 23.018928361000007
Test Epoch39 layer0 Acc 0.6986, AUC 0.769096314907074, avg_entr 0.17493648827075958, f1 0.6985999941825867
ep39_l0_test_time 0.28362056600008145
Test Epoch39 layer1 Acc 0.7176, AUC 0.7876733541488647, avg_entr 0.07059186697006226, f1 0.7175999879837036
ep39_l1_test_time 0.35423649199992724
Test Epoch39 layer2 Acc 0.7318, AUC 0.7947155237197876, avg_entr 0.04833438992500305, f1 0.7318000197410583
ep39_l2_test_time 0.46373546199993143
Test Epoch39 layer3 Acc 0.7378, AUC 0.8118596076965332, avg_entr 0.0448615737259388, f1 0.7378000020980835
ep39_l3_test_time 0.6134022480000567
Test Epoch39 layer4 Acc 0.7388, AUC 0.816375732421875, avg_entr 0.04218912497162819, f1 0.7387999892234802
ep39_l4_test_time 0.808220571999982
gc 0
Train Epoch40 Acc 0.9635 (38540/40000), AUC 0.9929859042167664
ep40_train_time 23.150040491000027
Test Epoch40 layer0 Acc 0.6984, AUC 0.769058883190155, avg_entr 0.17538286745548248, f1 0.6984000205993652
ep40_l0_test_time 0.2847405330001038
Test Epoch40 layer1 Acc 0.7182, AUC 0.7873233556747437, avg_entr 0.07063378393650055, f1 0.7182000279426575
ep40_l1_test_time 0.3535884159998659
Test Epoch40 layer2 Acc 0.7304, AUC 0.7940977811813354, avg_entr 0.048810526728630066, f1 0.7304000854492188
ep40_l2_test_time 0.4626328919998741
Test Epoch40 layer3 Acc 0.7372, AUC 0.8117883801460266, avg_entr 0.04538089781999588, f1 0.7372000217437744
ep40_l3_test_time 0.6218527699998049
Test Epoch40 layer4 Acc 0.7378, AUC 0.8164981603622437, avg_entr 0.043027766048908234, f1 0.7378000020980835
ep40_l4_test_time 0.809293291999893
gc 0
Train Epoch41 Acc 0.964425 (38577/40000), AUC 0.9932908415794373
ep41_train_time 23.04799499500018
Test Epoch41 layer0 Acc 0.6976, AUC 0.7688984870910645, avg_entr 0.17534446716308594, f1 0.6976000070571899
ep41_l0_test_time 0.2855800160000399
Test Epoch41 layer1 Acc 0.717, AUC 0.7862465381622314, avg_entr 0.06990764290094376, f1 0.7169999480247498
ep41_l1_test_time 0.35565447299995867
Test Epoch41 layer2 Acc 0.7312, AUC 0.7929835915565491, avg_entr 0.04744685813784599, f1 0.7311999797821045
ep41_l2_test_time 0.464501718000065
Test Epoch41 layer3 Acc 0.7368, AUC 0.810635507106781, avg_entr 0.04482462257146835, f1 0.7368000149726868
ep41_l3_test_time 0.6121795620001649
Test Epoch41 layer4 Acc 0.7386, AUC 0.8149123191833496, avg_entr 0.042114343494176865, f1 0.7386000156402588
ep41_l4_test_time 0.8076173419999577
gc 0
Train Epoch42 Acc 0.962375 (38495/40000), AUC 0.9928255081176758
ep42_train_time 23.067493185999865
Test Epoch42 layer0 Acc 0.6974, AUC 0.7688609957695007, avg_entr 0.17532314360141754, f1 0.6973999738693237
ep42_l0_test_time 0.3055461250000917
Test Epoch42 layer1 Acc 0.716, AUC 0.7867984175682068, avg_entr 0.06984862685203552, f1 0.7160000205039978
ep42_l1_test_time 0.3548248270001295
Test Epoch42 layer2 Acc 0.7302, AUC 0.7933056950569153, avg_entr 0.04741405323147774, f1 0.7301999926567078
ep42_l2_test_time 0.4637050320000071
Test Epoch42 layer3 Acc 0.737, AUC 0.81095290184021, avg_entr 0.044054318219423294, f1 0.7369999885559082
ep42_l3_test_time 0.6226945700000215
Test Epoch42 layer4 Acc 0.7364, AUC 0.815366268157959, avg_entr 0.041164740920066833, f1 0.7364000082015991
ep42_l4_test_time 0.8111969159999717
gc 0
Train Epoch43 Acc 0.964025 (38561/40000), AUC 0.992836594581604
ep43_train_time 23.045398344999967
Test Epoch43 layer0 Acc 0.6978, AUC 0.7687809467315674, avg_entr 0.17551487684249878, f1 0.6977999806404114
ep43_l0_test_time 0.2835079980000046
Test Epoch43 layer1 Acc 0.7166, AUC 0.786527156829834, avg_entr 0.07044479250907898, f1 0.7165999412536621
ep43_l1_test_time 0.35436468899979445
Test Epoch43 layer2 Acc 0.7308, AUC 0.7931743860244751, avg_entr 0.047915734350681305, f1 0.7307999730110168
ep43_l2_test_time 0.4630767430001015
Test Epoch43 layer3 Acc 0.738, AUC 0.8108538389205933, avg_entr 0.0448991134762764, f1 0.7379999160766602
ep43_l3_test_time 0.6146410569999716
Test Epoch43 layer4 Acc 0.7376, AUC 0.8152845501899719, avg_entr 0.04199725389480591, f1 0.7376000285148621
ep43_l4_test_time 0.809876450000047
gc 0
Train Epoch44 Acc 0.96455 (38582/40000), AUC 0.9927862882614136
ep44_train_time 23.059079032
Test Epoch44 layer0 Acc 0.6986, AUC 0.7688533067703247, avg_entr 0.17501585185527802, f1 0.6985999941825867
ep44_l0_test_time 0.2905160860000251
Test Epoch44 layer1 Acc 0.7178, AUC 0.7871004343032837, avg_entr 0.07004103064537048, f1 0.7178000211715698
ep44_l1_test_time 0.3581355829999211
Test Epoch44 layer2 Acc 0.7302, AUC 0.7935479283332825, avg_entr 0.04748525097966194, f1 0.7301999926567078
ep44_l2_test_time 0.46406386300009217
Test Epoch44 layer3 Acc 0.7368, AUC 0.8110939264297485, avg_entr 0.04397903010249138, f1 0.7368000149726868
ep44_l3_test_time 0.6181719559999692
Test Epoch44 layer4 Acc 0.7374, AUC 0.8156384229660034, avg_entr 0.04135487228631973, f1 0.7373999953269958
ep44_l4_test_time 0.8124603919998208
gc 0
Train Epoch45 Acc 0.963375 (38535/40000), AUC 0.9931027889251709
ep45_train_time 23.083105522000096
Test Epoch45 layer0 Acc 0.6982, AUC 0.7687931060791016, avg_entr 0.1750801056623459, f1 0.698199987411499
ep45_l0_test_time 0.31389301900003375
Test Epoch45 layer1 Acc 0.717, AUC 0.7863069772720337, avg_entr 0.06980130076408386, f1 0.7169999480247498
ep45_l1_test_time 0.3606772050000018
Test Epoch45 layer2 Acc 0.7318, AUC 0.7924434542655945, avg_entr 0.04710494726896286, f1 0.7318000197410583
ep45_l2_test_time 0.4634128039999723
Test Epoch45 layer3 Acc 0.7386, AUC 0.8105177283287048, avg_entr 0.044214989989995956, f1 0.7386000156402588
ep45_l3_test_time 0.6129384099999697
Test Epoch45 layer4 Acc 0.7394, AUC 0.8149674534797668, avg_entr 0.04142278432846069, f1 0.7394000291824341
ep45_l4_test_time 0.8082793619998938
gc 0
Train Epoch46 Acc 0.964675 (38587/40000), AUC 0.9927736520767212
ep46_train_time 23.0543421320001
Test Epoch46 layer0 Acc 0.6984, AUC 0.7686488032341003, avg_entr 0.17498430609703064, f1 0.6984000205993652
ep46_l0_test_time 0.28466442300009476
Test Epoch46 layer1 Acc 0.7168, AUC 0.7861998081207275, avg_entr 0.0697309821844101, f1 0.7168000340461731
ep46_l1_test_time 0.35577849800006334
Test Epoch46 layer2 Acc 0.7316, AUC 0.7925970554351807, avg_entr 0.047109294682741165, f1 0.7316000461578369
ep46_l2_test_time 0.4715787929999351
Test Epoch46 layer3 Acc 0.7386, AUC 0.8105862140655518, avg_entr 0.04448899254202843, f1 0.7386000156402588
ep46_l3_test_time 0.6144168250000348
Test Epoch46 layer4 Acc 0.7384, AUC 0.8152458667755127, avg_entr 0.04180576652288437, f1 0.7384000420570374
ep46_l4_test_time 0.8117487350000374
gc 0
Train Epoch47 Acc 0.963325 (38533/40000), AUC 0.9929983615875244
ep47_train_time 23.012797269999965
Test Epoch47 layer0 Acc 0.6968, AUC 0.768673300743103, avg_entr 0.1748127043247223, f1 0.6967999935150146
ep47_l0_test_time 0.2954150140001275
Test Epoch47 layer1 Acc 0.717, AUC 0.7864799499511719, avg_entr 0.06997572630643845, f1 0.7169999480247498
ep47_l1_test_time 0.36273085500010893
Test Epoch47 layer2 Acc 0.729, AUC 0.7929397821426392, avg_entr 0.04751062020659447, f1 0.7289999723434448
ep47_l2_test_time 0.4663236809999489
Test Epoch47 layer3 Acc 0.737, AUC 0.8109040260314941, avg_entr 0.04446842521429062, f1 0.7369999885559082
ep47_l3_test_time 0.6149088449999454
Test Epoch47 layer4 Acc 0.7376, AUC 0.8156794309616089, avg_entr 0.041922274976968765, f1 0.7376000285148621
ep47_l4_test_time 0.8083564759999717
gc 0
Train Epoch48 Acc 0.964225 (38569/40000), AUC 0.9932732582092285
ep48_train_time 22.989044396000054
Test Epoch48 layer0 Acc 0.6976, AUC 0.7686550617218018, avg_entr 0.174928218126297, f1 0.6976000070571899
ep48_l0_test_time 0.2823165400000107
Test Epoch48 layer1 Acc 0.717, AUC 0.7862694263458252, avg_entr 0.06977377086877823, f1 0.7169999480247498
ep48_l1_test_time 0.3535837199999605
Test Epoch48 layer2 Acc 0.729, AUC 0.7927327156066895, avg_entr 0.047335390001535416, f1 0.7289999723434448
ep48_l2_test_time 0.4635343519998969
Test Epoch48 layer3 Acc 0.7372, AUC 0.8107460141181946, avg_entr 0.04432029649615288, f1 0.7372000217437744
ep48_l3_test_time 0.613052203000052
Test Epoch48 layer4 Acc 0.7374, AUC 0.8155242800712585, avg_entr 0.041744038462638855, f1 0.7373999953269958
ep48_l4_test_time 0.8113973810000061
gc 0
Train Epoch49 Acc 0.9642 (38568/40000), AUC 0.9933513402938843
ep49_train_time 23.099113294999825
Test Epoch49 layer0 Acc 0.6986, AUC 0.7686712741851807, avg_entr 0.1747293919324875, f1 0.6985999941825867
ep49_l0_test_time 0.28508356699990145
Test Epoch49 layer1 Acc 0.7172, AUC 0.7862684726715088, avg_entr 0.069857656955719, f1 0.717199981212616
ep49_l1_test_time 0.3560350760001256
Test Epoch49 layer2 Acc 0.7302, AUC 0.792901873588562, avg_entr 0.047251470386981964, f1 0.7301999926567078
ep49_l2_test_time 0.4636097580000751
Test Epoch49 layer3 Acc 0.7374, AUC 0.810843825340271, avg_entr 0.0443386472761631, f1 0.7373999953269958
ep49_l3_test_time 0.6221243259999483
Test Epoch49 layer4 Acc 0.7376, AUC 0.8155670762062073, avg_entr 0.041697096079587936, f1 0.7376000285148621
ep49_l4_test_time 0.8107745509998949
Best AUC tensor(0.7690) 10 3
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
total_train+valid_time 1293.896348314
Start Testing
Load ckpt at ckpt/imdb_transformeralside_l5_256_sidead//imdb_transformeralside_l5_side.pt
gc 9
Test layer0 Acc 0.7138, AUC 0.8051481246948242, avg_entr 0.2863622009754181, f1 0.7138000130653381
l0_test_time 0.2852543640001386
gc 0
Test layer1 Acc 0.7494, AUC 0.8399232625961304, avg_entr 0.2710675597190857, f1 0.7494000196456909
l1_test_time 0.3579519780000737
gc 0
Test layer2 Acc 0.7602, AUC 0.8521260619163513, avg_entr 0.2647673189640045, f1 0.7602000832557678
l2_test_time 0.46652197999992495
gc 0
Test layer3 Acc 0.7676, AUC 0.8556884527206421, avg_entr 0.26457101106643677, f1 0.7675999402999878
l3_test_time 0.6169367929999225
gc 0
Test layer4 Acc 0.7664, AUC 0.8570271730422974, avg_entr 0.27586933970451355, f1 0.7663999199867249
l4_test_time 0.8146214469998085
gc 0
Test threshold 0.1 Acc 0.7654, AUC 0.850178062915802, avg_entr 0.3619774281978607, f1 0.7653999924659729
t0.1_test_time 0.6907306260000041
gc 0
Test threshold 0.2 Acc 0.765, AUC 0.8444865942001343, avg_entr 0.3415013551712036, f1 0.7649999856948853
t0.2_test_time 0.6148664610000196
gc 0
Test threshold 0.3 Acc 0.763, AUC 0.8395118713378906, avg_entr 0.32944321632385254, f1 0.7630000114440918
t0.3_test_time 0.5796789139999419
gc 0
Test threshold 0.4 Acc 0.7616, AUC 0.833778440952301, avg_entr 0.32104548811912537, f1 0.7616000771522522
t0.4_test_time 0.5243581580000409
gc 0
Test threshold 0.5 Acc 0.7576, AUC 0.8310850262641907, avg_entr 0.3209370970726013, f1 0.7576000690460205
t0.5_test_time 0.4883629129999463
gc 0
Test threshold 0.6 Acc 0.755, AUC 0.8266621232032776, avg_entr 0.3244917392730713, f1 0.7549999356269836
t0.6_test_time 0.45613251300005686
gc 0
Test threshold 0.7 Acc 0.7508, AUC 0.8229569792747498, avg_entr 0.3330884575843811, f1 0.7508000135421753
t0.7_test_time 0.42448356900013096
gc 0
Test threshold 0.8 Acc 0.7446, AUC 0.8189486265182495, avg_entr 0.34562215209007263, f1 0.7445999979972839
t0.8_test_time 0.3939534480000475
gc 0
Test threshold 0.9 Acc 0.7374, AUC 0.8149175643920898, avg_entr 0.36494314670562744, f1 0.7373999953269958
t0.9_test_time 0.38859601399985877
