total count words 102019
vocab size 30000
found 26754 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13672292
init_time 19.738273859024048
Start Training
gc 0
Train Epoch0 Acc 0.6343083333333334 (76117/120000), AUC 0.8633873462677002
ep0_train_time 71.6003086566925
Test Epoch0 layer0 Acc 0.8968421052631579, AUC 0.9720737934112549, avg_entr 0.24946105480194092
ep0_l0_test_time 0.14153122901916504
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.8992105263157895, AUC 0.9750537872314453, avg_entr 0.16704826056957245
ep0_l1_test_time 0.25365567207336426
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.8986842105263158, AUC 0.9750800728797913, avg_entr 0.1577116698026657
ep0_l2_test_time 0.3678104877471924
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer3 Acc 0.9, AUC 0.9751285314559937, avg_entr 0.15232354402542114
ep0_l3_test_time 0.47977161407470703
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer4 Acc 0.8997368421052632, AUC 0.9752641916275024, avg_entr 0.15177702903747559
ep0_l4_test_time 0.5937337875366211
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.9211916666666666 (110543/120000), AUC 0.9821149706840515
ep1_train_time 71.21763563156128
Test Epoch1 layer0 Acc 0.9023684210526316, AUC 0.9760043025016785, avg_entr 0.14607176184654236
ep1_l0_test_time 0.1389930248260498
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.91, AUC 0.9791527986526489, avg_entr 0.08292573690414429
ep1_l1_test_time 0.2548682689666748
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.9105263157894737, AUC 0.9792154431343079, avg_entr 0.06639549136161804
ep1_l2_test_time 0.3680455684661865
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer3 Acc 0.9102631578947369, AUC 0.9788405299186707, avg_entr 0.05966531112790108
ep1_l3_test_time 0.4795806407928467
Test Epoch1 layer4 Acc 0.9102631578947369, AUC 0.9789074063301086, avg_entr 0.05411786213517189
ep1_l4_test_time 0.5905675888061523
gc 0
Train Epoch2 Acc 0.9363083333333333 (112357/120000), AUC 0.9869359731674194
ep2_train_time 71.23452615737915
Test Epoch2 layer0 Acc 0.9052631578947369, AUC 0.9776314496994019, avg_entr 0.11222955584526062
ep2_l0_test_time 0.13897943496704102
Test Epoch2 layer1 Acc 0.9123684210526316, AUC 0.9792527556419373, avg_entr 0.04383833333849907
ep2_l1_test_time 0.2529594898223877
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 2
Test Epoch2 layer2 Acc 0.9118421052631579, AUC 0.9795265793800354, avg_entr 0.036277055740356445
ep2_l2_test_time 0.3671388626098633
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 2
Test Epoch2 layer3 Acc 0.9121052631578948, AUC 0.9789626598358154, avg_entr 0.0338718481361866
ep2_l3_test_time 0.48034119606018066
Test Epoch2 layer4 Acc 0.9118421052631579, AUC 0.9789782166481018, avg_entr 0.03085974045097828
ep2_l4_test_time 0.5903236865997314
gc 0
Train Epoch3 Acc 0.9432583333333333 (113191/120000), AUC 0.989419162273407
ep3_train_time 71.29702043533325
Test Epoch3 layer0 Acc 0.9076315789473685, AUC 0.9783223867416382, avg_entr 0.09762338548898697
ep3_l0_test_time 0.13990497589111328
Test Epoch3 layer1 Acc 0.9126315789473685, AUC 0.9791119694709778, avg_entr 0.03489154949784279
ep3_l1_test_time 0.2526106834411621
Test Epoch3 layer2 Acc 0.9139473684210526, AUC 0.9794889092445374, avg_entr 0.029789403080940247
ep3_l2_test_time 0.36509275436401367
Test Epoch3 layer3 Acc 0.9136842105263158, AUC 0.9798484444618225, avg_entr 0.027951641008257866
ep3_l3_test_time 0.47731590270996094
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 3
Test Epoch3 layer4 Acc 0.9128947368421053, AUC 0.9800676107406616, avg_entr 0.02570164017379284
ep3_l4_test_time 0.5922393798828125
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.94865 (113838/120000), AUC 0.990745484828949
ep4_train_time 71.24390435218811
Test Epoch4 layer0 Acc 0.9113157894736842, AUC 0.9784855842590332, avg_entr 0.08343515545129776
ep4_l0_test_time 0.1397247314453125
Test Epoch4 layer1 Acc 0.91, AUC 0.9787655472755432, avg_entr 0.030329808592796326
ep4_l1_test_time 0.25285792350769043
Test Epoch4 layer2 Acc 0.9121052631578948, AUC 0.9793714284896851, avg_entr 0.0260439682751894
ep4_l2_test_time 0.3654196262359619
Test Epoch4 layer3 Acc 0.911578947368421, AUC 0.9801954030990601, avg_entr 0.023475218564271927
ep4_l3_test_time 0.4776625633239746
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 4
Test Epoch4 layer4 Acc 0.911578947368421, AUC 0.9803141355514526, avg_entr 0.020664867013692856
ep4_l4_test_time 0.5923564434051514
Save ckpt to ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt  ,ep 4
gc 0
Train Epoch5 Acc 0.9527916666666667 (114335/120000), AUC 0.9920499920845032
ep5_train_time 71.3211727142334
Test Epoch5 layer0 Acc 0.9123684210526316, AUC 0.978355348110199, avg_entr 0.07626315206289291
ep5_l0_test_time 0.1423783302307129
Test Epoch5 layer1 Acc 0.9113157894736842, AUC 0.9788453578948975, avg_entr 0.027976658195257187
ep5_l1_test_time 0.2529780864715576
Test Epoch5 layer2 Acc 0.9113157894736842, AUC 0.980003833770752, avg_entr 0.02258775196969509
ep5_l2_test_time 0.36603331565856934
Test Epoch5 layer3 Acc 0.9113157894736842, AUC 0.979800820350647, avg_entr 0.02095612697303295
ep5_l3_test_time 0.47826719284057617
Test Epoch5 layer4 Acc 0.9121052631578948, AUC 0.9800132513046265, avg_entr 0.018713999539613724
ep5_l4_test_time 0.5907349586486816
gc 0
Train Epoch6 Acc 0.9562666666666667 (114752/120000), AUC 0.9925960898399353
ep6_train_time 71.251873254776
Test Epoch6 layer0 Acc 0.9121052631578948, AUC 0.9786665439605713, avg_entr 0.07166850566864014
ep6_l0_test_time 0.13931703567504883
Test Epoch6 layer1 Acc 0.9113157894736842, AUC 0.9753140211105347, avg_entr 0.024654939770698547
ep6_l1_test_time 0.2528414726257324
Test Epoch6 layer2 Acc 0.911578947368421, AUC 0.9776622653007507, avg_entr 0.018929148092865944
ep6_l2_test_time 0.3650631904602051
Test Epoch6 layer3 Acc 0.9113157894736842, AUC 0.9787204265594482, avg_entr 0.017417296767234802
ep6_l3_test_time 0.47743654251098633
Test Epoch6 layer4 Acc 0.911578947368421, AUC 0.9777427911758423, avg_entr 0.015529891476035118
ep6_l4_test_time 0.5899591445922852
gc 0
Train Epoch7 Acc 0.9594083333333333 (115129/120000), AUC 0.9931983351707458
ep7_train_time 71.25029706954956
Test Epoch7 layer0 Acc 0.9118421052631579, AUC 0.9785321354866028, avg_entr 0.0658092349767685
ep7_l0_test_time 0.1384115219116211
Test Epoch7 layer1 Acc 0.9089473684210526, AUC 0.9763507843017578, avg_entr 0.02278224006295204
ep7_l1_test_time 0.25219225883483887
Test Epoch7 layer2 Acc 0.908157894736842, AUC 0.9769779443740845, avg_entr 0.017912736162543297
ep7_l2_test_time 0.3643782138824463
Test Epoch7 layer3 Acc 0.908157894736842, AUC 0.9778226613998413, avg_entr 0.0158860944211483
ep7_l3_test_time 0.4773280620574951
Test Epoch7 layer4 Acc 0.908157894736842, AUC 0.9776789546012878, avg_entr 0.013982614502310753
ep7_l4_test_time 0.5903356075286865
gc 0
Train Epoch8 Acc 0.961175 (115341/120000), AUC 0.9940338134765625
ep8_train_time 71.37188720703125
Test Epoch8 layer0 Acc 0.9126315789473685, AUC 0.9781805872917175, avg_entr 0.060003861784935
ep8_l0_test_time 0.13855433464050293
Test Epoch8 layer1 Acc 0.9055263157894737, AUC 0.9755005240440369, avg_entr 0.019454946741461754
ep8_l1_test_time 0.25270676612854004
Test Epoch8 layer2 Acc 0.9060526315789473, AUC 0.9768993854522705, avg_entr 0.014531486667692661
ep8_l2_test_time 0.3660397529602051
Test Epoch8 layer3 Acc 0.9060526315789473, AUC 0.9778705835342407, avg_entr 0.013001670129597187
ep8_l3_test_time 0.4782083034515381
Test Epoch8 layer4 Acc 0.9063157894736842, AUC 0.9777394533157349, avg_entr 0.01151746790856123
ep8_l4_test_time 0.5903253555297852
gc 0
Train Epoch9 Acc 0.962675 (115521/120000), AUC 0.9945371747016907
ep9_train_time 71.30527472496033
Test Epoch9 layer0 Acc 0.9060526315789473, AUC 0.9782522916793823, avg_entr 0.060444749891757965
ep9_l0_test_time 0.1392207145690918
Test Epoch9 layer1 Acc 0.9073684210526316, AUC 0.9755434989929199, avg_entr 0.020156020298600197
ep9_l1_test_time 0.2530062198638916
Test Epoch9 layer2 Acc 0.9026315789473685, AUC 0.9771726131439209, avg_entr 0.016427693888545036
ep9_l2_test_time 0.36522626876831055
Test Epoch9 layer3 Acc 0.9026315789473685, AUC 0.9775594472885132, avg_entr 0.014699006453156471
ep9_l3_test_time 0.4774916172027588
Test Epoch9 layer4 Acc 0.9028947368421053, AUC 0.9775846004486084, avg_entr 0.013342306017875671
ep9_l4_test_time 0.5904362201690674
gc 0
Train Epoch10 Acc 0.963975 (115677/120000), AUC 0.9947450160980225
ep10_train_time 71.33987617492676
Test Epoch10 layer0 Acc 0.911578947368421, AUC 0.9780837297439575, avg_entr 0.05471178516745567
ep10_l0_test_time 0.1392354965209961
Test Epoch10 layer1 Acc 0.9057894736842105, AUC 0.9745422005653381, avg_entr 0.019978418946266174
ep10_l1_test_time 0.25196242332458496
Test Epoch10 layer2 Acc 0.9044736842105263, AUC 0.9760992527008057, avg_entr 0.01539217121899128
ep10_l2_test_time 0.3664052486419678
Test Epoch10 layer3 Acc 0.9042105263157895, AUC 0.9770187735557556, avg_entr 0.013981969095766544
ep10_l3_test_time 0.4792356491088867
Test Epoch10 layer4 Acc 0.9034210526315789, AUC 0.9762781262397766, avg_entr 0.012679985724389553
ep10_l4_test_time 0.5910751819610596
gc 0
Train Epoch11 Acc 0.9669916666666667 (116039/120000), AUC 0.9954521059989929
ep11_train_time 71.3296115398407
Test Epoch11 layer0 Acc 0.9097368421052632, AUC 0.9779747724533081, avg_entr 0.05353504791855812
ep11_l0_test_time 0.13965153694152832
Test Epoch11 layer1 Acc 0.9060526315789473, AUC 0.97379469871521, avg_entr 0.017581213265657425
ep11_l1_test_time 0.25292348861694336
Test Epoch11 layer2 Acc 0.906578947368421, AUC 0.9744607210159302, avg_entr 0.013836028054356575
ep11_l2_test_time 0.36536359786987305
Test Epoch11 layer3 Acc 0.9057894736842105, AUC 0.9760655164718628, avg_entr 0.011925382539629936
ep11_l3_test_time 0.47731709480285645
Test Epoch11 layer4 Acc 0.9057894736842105, AUC 0.9727386832237244, avg_entr 0.0105296541005373
ep11_l4_test_time 0.5899758338928223
gc 0
Train Epoch12 Acc 0.9678 (116136/120000), AUC 0.9955945014953613
ep12_train_time 71.3255968093872
Test Epoch12 layer0 Acc 0.9097368421052632, AUC 0.9778566956520081, avg_entr 0.05130298435688019
ep12_l0_test_time 0.13952064514160156
Test Epoch12 layer1 Acc 0.9047368421052632, AUC 0.9722316265106201, avg_entr 0.016794221475720406
ep12_l1_test_time 0.2527623176574707
Test Epoch12 layer2 Acc 0.906578947368421, AUC 0.9735385179519653, avg_entr 0.012805641628801823
ep12_l2_test_time 0.36573362350463867
Test Epoch12 layer3 Acc 0.9057894736842105, AUC 0.9746057987213135, avg_entr 0.011087315157055855
ep12_l3_test_time 0.4778635501861572
Test Epoch12 layer4 Acc 0.9055263157894737, AUC 0.9743030071258545, avg_entr 0.010005490854382515
ep12_l4_test_time 0.590275764465332
gc 0
Train Epoch13 Acc 0.9682416666666667 (116189/120000), AUC 0.9958535432815552
ep13_train_time 71.32767748832703
Test Epoch13 layer0 Acc 0.9110526315789473, AUC 0.9777462482452393, avg_entr 0.04928966239094734
ep13_l0_test_time 0.13874435424804688
Test Epoch13 layer1 Acc 0.9057894736842105, AUC 0.9729738831520081, avg_entr 0.01573352888226509
ep13_l1_test_time 0.25303125381469727
Test Epoch13 layer2 Acc 0.905, AUC 0.9746817946434021, avg_entr 0.011425280943512917
ep13_l2_test_time 0.3647639751434326
Test Epoch13 layer3 Acc 0.9052631578947369, AUC 0.9745219945907593, avg_entr 0.009485415183007717
ep13_l3_test_time 0.4775116443634033
Test Epoch13 layer4 Acc 0.9052631578947369, AUC 0.975229024887085, avg_entr 0.008509707637131214
ep13_l4_test_time 0.590510368347168
gc 0
Train Epoch14 Acc 0.9689833333333333 (116278/120000), AUC 0.9959719181060791
ep14_train_time 71.28332018852234
Test Epoch14 layer0 Acc 0.9107894736842105, AUC 0.9776442646980286, avg_entr 0.04776110500097275
ep14_l0_test_time 0.13961243629455566
Test Epoch14 layer1 Acc 0.9073684210526316, AUC 0.9720253944396973, avg_entr 0.014704371802508831
ep14_l1_test_time 0.25243258476257324
Test Epoch14 layer2 Acc 0.9063157894736842, AUC 0.9728643894195557, avg_entr 0.010853247717022896
ep14_l2_test_time 0.36468076705932617
Test Epoch14 layer3 Acc 0.9063157894736842, AUC 0.9725038409233093, avg_entr 0.009051595814526081
ep14_l3_test_time 0.4770934581756592
Test Epoch14 layer4 Acc 0.9063157894736842, AUC 0.9691327810287476, avg_entr 0.008036939427256584
ep14_l4_test_time 0.5900757312774658
gc 0
Train Epoch15 Acc 0.9702 (116424/120000), AUC 0.9962173700332642
ep15_train_time 71.27871298789978
Test Epoch15 layer0 Acc 0.9097368421052632, AUC 0.9775956869125366, avg_entr 0.04640680551528931
ep15_l0_test_time 0.13863277435302734
Test Epoch15 layer1 Acc 0.905, AUC 0.9712098836898804, avg_entr 0.014198798686265945
ep15_l1_test_time 0.2529590129852295
Test Epoch15 layer2 Acc 0.9031578947368422, AUC 0.972152054309845, avg_entr 0.01013397891074419
ep15_l2_test_time 0.36456871032714844
Test Epoch15 layer3 Acc 0.9031578947368422, AUC 0.9736325144767761, avg_entr 0.008414477109909058
ep15_l3_test_time 0.47743678092956543
Test Epoch15 layer4 Acc 0.9031578947368422, AUC 0.9715491533279419, avg_entr 0.007646915968507528
ep15_l4_test_time 0.589716911315918
gc 0
Train Epoch16 Acc 0.9705583333333333 (116467/120000), AUC 0.9962795376777649
ep16_train_time 71.31367993354797
Test Epoch16 layer0 Acc 0.9092105263157895, AUC 0.9776307344436646, avg_entr 0.045579295605421066
ep16_l0_test_time 0.1394808292388916
Test Epoch16 layer1 Acc 0.9047368421052632, AUC 0.9715301394462585, avg_entr 0.014176874421536922
ep16_l1_test_time 0.2534317970275879
Test Epoch16 layer2 Acc 0.9028947368421053, AUC 0.9722912311553955, avg_entr 0.010580736212432384
ep16_l2_test_time 0.3655412197113037
Test Epoch16 layer3 Acc 0.9034210526315789, AUC 0.9737471342086792, avg_entr 0.008918537758290768
ep16_l3_test_time 0.47724127769470215
Test Epoch16 layer4 Acc 0.9031578947368422, AUC 0.9707145690917969, avg_entr 0.008035855367779732
ep16_l4_test_time 0.590085506439209
gc 0
Train Epoch17 Acc 0.9710666666666666 (116528/120000), AUC 0.9964388012886047
ep17_train_time 71.32456731796265
Test Epoch17 layer0 Acc 0.9094736842105263, AUC 0.9775171875953674, avg_entr 0.04381317272782326
ep17_l0_test_time 0.13855910301208496
Test Epoch17 layer1 Acc 0.9044736842105263, AUC 0.9710507392883301, avg_entr 0.013821705244481564
ep17_l1_test_time 0.2518594264984131
Test Epoch17 layer2 Acc 0.9028947368421053, AUC 0.9715818762779236, avg_entr 0.010112904943525791
ep17_l2_test_time 0.3649301528930664
Test Epoch17 layer3 Acc 0.9036842105263158, AUC 0.9721275568008423, avg_entr 0.00858720950782299
ep17_l3_test_time 0.4768519401550293
Test Epoch17 layer4 Acc 0.9031578947368422, AUC 0.9697187542915344, avg_entr 0.007931620813906193
ep17_l4_test_time 0.5896239280700684
gc 0
Train Epoch18 Acc 0.9715833333333334 (116590/120000), AUC 0.9963325262069702
ep18_train_time 71.34434056282043
Test Epoch18 layer0 Acc 0.9089473684210526, AUC 0.9775158166885376, avg_entr 0.042728204280138016
ep18_l0_test_time 0.13910627365112305
Test Epoch18 layer1 Acc 0.9047368421052632, AUC 0.9707181453704834, avg_entr 0.01370424684137106
ep18_l1_test_time 0.2526681423187256
Test Epoch18 layer2 Acc 0.9031578947368422, AUC 0.9715167284011841, avg_entr 0.009446310810744762
ep18_l2_test_time 0.36638879776000977
Test Epoch18 layer3 Acc 0.9028947368421053, AUC 0.9717471599578857, avg_entr 0.007835839875042439
ep18_l3_test_time 0.4771449565887451
Test Epoch18 layer4 Acc 0.9031578947368422, AUC 0.9692163467407227, avg_entr 0.007201117463409901
ep18_l4_test_time 0.5897135734558105
gc 0
Train Epoch19 Acc 0.9723666666666667 (116684/120000), AUC 0.9964879751205444
ep19_train_time 71.22707080841064
Test Epoch19 layer0 Acc 0.9084210526315789, AUC 0.9775205850601196, avg_entr 0.0417686328291893
ep19_l0_test_time 0.1393725872039795
Test Epoch19 layer1 Acc 0.9039473684210526, AUC 0.9702707529067993, avg_entr 0.013187101110816002
ep19_l1_test_time 0.2530550956726074
Test Epoch19 layer2 Acc 0.9023684210526316, AUC 0.9705286026000977, avg_entr 0.009195673279464245
ep19_l2_test_time 0.3646962642669678
Test Epoch19 layer3 Acc 0.9028947368421053, AUC 0.971066951751709, avg_entr 0.007688696030527353
ep19_l3_test_time 0.4774458408355713
Test Epoch19 layer4 Acc 0.9026315789473685, AUC 0.9683416485786438, avg_entr 0.0070270937867462635
ep19_l4_test_time 0.5899255275726318
gc 0
Train Epoch20 Acc 0.97235 (116682/120000), AUC 0.9964289665222168
ep20_train_time 71.39117741584778
Test Epoch20 layer0 Acc 0.9092105263157895, AUC 0.9774697422981262, avg_entr 0.04131370410323143
ep20_l0_test_time 0.13929009437561035
Test Epoch20 layer1 Acc 0.9028947368421053, AUC 0.9703596234321594, avg_entr 0.01346576027572155
ep20_l1_test_time 0.2525904178619385
Test Epoch20 layer2 Acc 0.9013157894736842, AUC 0.9711284637451172, avg_entr 0.00937787164002657
ep20_l2_test_time 0.36594724655151367
Test Epoch20 layer3 Acc 0.9010526315789473, AUC 0.9711523056030273, avg_entr 0.007928591221570969
ep20_l3_test_time 0.4777357578277588
Test Epoch20 layer4 Acc 0.9007894736842105, AUC 0.9679750204086304, avg_entr 0.007467161864042282
ep20_l4_test_time 0.5892586708068848
gc 0
Train Epoch21 Acc 0.9725833333333334 (116710/120000), AUC 0.9965899586677551
ep21_train_time 71.31810760498047
Test Epoch21 layer0 Acc 0.9097368421052632, AUC 0.9774073362350464, avg_entr 0.04020457714796066
ep21_l0_test_time 0.13859772682189941
Test Epoch21 layer1 Acc 0.9034210526315789, AUC 0.970187783241272, avg_entr 0.012770356610417366
ep21_l1_test_time 0.253004789352417
Test Epoch21 layer2 Acc 0.9026315789473685, AUC 0.9705883264541626, avg_entr 0.008795049972832203
ep21_l2_test_time 0.3650956153869629
Test Epoch21 layer3 Acc 0.9023684210526316, AUC 0.9705601334571838, avg_entr 0.0072490144520998
ep21_l3_test_time 0.4771130084991455
Test Epoch21 layer4 Acc 0.9023684210526316, AUC 0.967746376991272, avg_entr 0.006521313916891813
ep21_l4_test_time 0.5897955894470215
gc 0
Train Epoch22 Acc 0.97285 (116742/120000), AUC 0.9966235160827637
ep22_train_time 71.32107329368591
Test Epoch22 layer0 Acc 0.9094736842105263, AUC 0.9773541688919067, avg_entr 0.03964501991868019
ep22_l0_test_time 0.142042875289917
Test Epoch22 layer1 Acc 0.9034210526315789, AUC 0.969822108745575, avg_entr 0.012442406266927719
ep22_l1_test_time 0.25261473655700684
Test Epoch22 layer2 Acc 0.9023684210526316, AUC 0.969798743724823, avg_entr 0.008697617799043655
ep22_l2_test_time 0.364699125289917
Test Epoch22 layer3 Acc 0.9023684210526316, AUC 0.9697908759117126, avg_entr 0.007442425470799208
ep22_l3_test_time 0.4768180847167969
Test Epoch22 layer4 Acc 0.9023684210526316, AUC 0.9658126831054688, avg_entr 0.0067442962899804115
ep22_l4_test_time 0.5893311500549316
gc 0
Train Epoch23 Acc 0.9732666666666666 (116792/120000), AUC 0.9966164827346802
ep23_train_time 71.39012622833252
Test Epoch23 layer0 Acc 0.908157894736842, AUC 0.9773458242416382, avg_entr 0.03923677280545235
ep23_l0_test_time 0.13904857635498047
Test Epoch23 layer1 Acc 0.9031578947368422, AUC 0.9696134924888611, avg_entr 0.012492077425122261
ep23_l1_test_time 0.252575159072876
Test Epoch23 layer2 Acc 0.9023684210526316, AUC 0.9697774648666382, avg_entr 0.008841835893690586
ep23_l2_test_time 0.364840030670166
Test Epoch23 layer3 Acc 0.9021052631578947, AUC 0.9698705077171326, avg_entr 0.007440605200827122
ep23_l3_test_time 0.47704601287841797
Test Epoch23 layer4 Acc 0.9026315789473685, AUC 0.9657987356185913, avg_entr 0.006673474330455065
ep23_l4_test_time 0.5893802642822266
gc 0
Train Epoch24 Acc 0.9730083333333334 (116761/120000), AUC 0.9966504573822021
ep24_train_time 71.3666741847992
Test Epoch24 layer0 Acc 0.9078947368421053, AUC 0.9773250818252563, avg_entr 0.0389307402074337
ep24_l0_test_time 0.14015769958496094
Test Epoch24 layer1 Acc 0.9039473684210526, AUC 0.9694344401359558, avg_entr 0.01229847315698862
ep24_l1_test_time 0.25244808197021484
Test Epoch24 layer2 Acc 0.9023684210526316, AUC 0.969112753868103, avg_entr 0.008775470778346062
ep24_l2_test_time 0.3649160861968994
Test Epoch24 layer3 Acc 0.9018421052631579, AUC 0.9686896204948425, avg_entr 0.007301706355065107
ep24_l3_test_time 0.4784884452819824
Test Epoch24 layer4 Acc 0.9021052631578947, AUC 0.9647067189216614, avg_entr 0.006533036008477211
ep24_l4_test_time 0.5900874137878418
gc 0
Train Epoch25 Acc 0.9734416666666666 (116813/120000), AUC 0.9967093467712402
ep25_train_time 71.3844063282013
Test Epoch25 layer0 Acc 0.9078947368421053, AUC 0.977303147315979, avg_entr 0.03866120055317879
ep25_l0_test_time 0.1392509937286377
Test Epoch25 layer1 Acc 0.9034210526315789, AUC 0.9694603681564331, avg_entr 0.012309035286307335
ep25_l1_test_time 0.2529871463775635
Test Epoch25 layer2 Acc 0.9018421052631579, AUC 0.9695690274238586, avg_entr 0.008500441908836365
ep25_l2_test_time 0.36577439308166504
Test Epoch25 layer3 Acc 0.9018421052631579, AUC 0.9698150157928467, avg_entr 0.007302663754671812
ep25_l3_test_time 0.4796488285064697
Test Epoch25 layer4 Acc 0.9018421052631579, AUC 0.9664372205734253, avg_entr 0.0066625140607357025
ep25_l4_test_time 0.5913040637969971
gc 0
Train Epoch26 Acc 0.97345 (116814/120000), AUC 0.9966486692428589
ep26_train_time 71.35908532142639
Test Epoch26 layer0 Acc 0.9076315789473685, AUC 0.977287232875824, avg_entr 0.038270968943834305
ep26_l0_test_time 0.13980937004089355
Test Epoch26 layer1 Acc 0.9034210526315789, AUC 0.9688327312469482, avg_entr 0.012177691794931889
ep26_l1_test_time 0.25319790840148926
Test Epoch26 layer2 Acc 0.9021052631578947, AUC 0.9684203863143921, avg_entr 0.008641209453344345
ep26_l2_test_time 0.3657348155975342
Test Epoch26 layer3 Acc 0.9018421052631579, AUC 0.9683200716972351, avg_entr 0.007268751505762339
ep26_l3_test_time 0.47737860679626465
Test Epoch26 layer4 Acc 0.9023684210526316, AUC 0.9639869928359985, avg_entr 0.006488989572972059
ep26_l4_test_time 0.5900149345397949
gc 0
Train Epoch27 Acc 0.97375 (116850/120000), AUC 0.9966675043106079
ep27_train_time 71.38233876228333
Test Epoch27 layer0 Acc 0.9078947368421053, AUC 0.9772946238517761, avg_entr 0.03833480179309845
ep27_l0_test_time 0.13858985900878906
Test Epoch27 layer1 Acc 0.9028947368421053, AUC 0.9689943194389343, avg_entr 0.012275608256459236
ep27_l1_test_time 0.2525975704193115
Test Epoch27 layer2 Acc 0.901578947368421, AUC 0.9686201810836792, avg_entr 0.008531792089343071
ep27_l2_test_time 0.3643317222595215
Test Epoch27 layer3 Acc 0.9023684210526316, AUC 0.9686023592948914, avg_entr 0.007328344974666834
ep27_l3_test_time 0.476837158203125
Test Epoch27 layer4 Acc 0.9018421052631579, AUC 0.9643296003341675, avg_entr 0.006729661487042904
ep27_l4_test_time 0.5898604393005371
gc 0
Train Epoch28 Acc 0.9737666666666667 (116852/120000), AUC 0.9967926740646362
ep28_train_time 71.39306092262268
Test Epoch28 layer0 Acc 0.9078947368421053, AUC 0.9772875905036926, avg_entr 0.03809962794184685
ep28_l0_test_time 0.1396465301513672
Test Epoch28 layer1 Acc 0.9031578947368422, AUC 0.9691203832626343, avg_entr 0.012294759042561054
ep28_l1_test_time 0.2520866394042969
Test Epoch28 layer2 Acc 0.9018421052631579, AUC 0.9690490961074829, avg_entr 0.008795536123216152
ep28_l2_test_time 0.3649630546569824
Test Epoch28 layer3 Acc 0.9021052631578947, AUC 0.9690808653831482, avg_entr 0.007353472989052534
ep28_l3_test_time 0.4778745174407959
Test Epoch28 layer4 Acc 0.9023684210526316, AUC 0.9650458097457886, avg_entr 0.006638676859438419
ep28_l4_test_time 0.5896551609039307
gc 0
Train Epoch29 Acc 0.9736583333333333 (116839/120000), AUC 0.9967586398124695
ep29_train_time 71.39486122131348
Test Epoch29 layer0 Acc 0.9084210526315789, AUC 0.9772926568984985, avg_entr 0.0380333848297596
ep29_l0_test_time 0.13990378379821777
Test Epoch29 layer1 Acc 0.9034210526315789, AUC 0.9687665104866028, avg_entr 0.012224039994180202
ep29_l1_test_time 0.2533986568450928
Test Epoch29 layer2 Acc 0.901578947368421, AUC 0.9688829779624939, avg_entr 0.008727123029530048
ep29_l2_test_time 0.3655109405517578
Test Epoch29 layer3 Acc 0.9018421052631579, AUC 0.9684721827507019, avg_entr 0.007383596617728472
ep29_l3_test_time 0.47776031494140625
Test Epoch29 layer4 Acc 0.901578947368421, AUC 0.9642635583877563, avg_entr 0.006790712475776672
ep29_l4_test_time 0.5922191143035889
gc 0
Train Epoch30 Acc 0.9738083333333334 (116857/120000), AUC 0.9967315196990967
ep30_train_time 71.38955235481262
Test Epoch30 layer0 Acc 0.9084210526315789, AUC 0.977271556854248, avg_entr 0.037859272211790085
ep30_l0_test_time 0.13856744766235352
Test Epoch30 layer1 Acc 0.9031578947368422, AUC 0.9689198732376099, avg_entr 0.012279252521693707
ep30_l1_test_time 0.2527320384979248
Test Epoch30 layer2 Acc 0.9018421052631579, AUC 0.9692349433898926, avg_entr 0.008641478605568409
ep30_l2_test_time 0.3650200366973877
Test Epoch30 layer3 Acc 0.9013157894736842, AUC 0.9688611030578613, avg_entr 0.007452385034412146
ep30_l3_test_time 0.4778401851654053
Test Epoch30 layer4 Acc 0.901578947368421, AUC 0.965050220489502, avg_entr 0.006971255410462618
ep30_l4_test_time 0.5902118682861328
gc 0
Train Epoch31 Acc 0.973875 (116865/120000), AUC 0.9967542886734009
ep31_train_time 71.4669725894928
Test Epoch31 layer0 Acc 0.9084210526315789, AUC 0.9772621989250183, avg_entr 0.037808600813150406
ep31_l0_test_time 0.13958191871643066
Test Epoch31 layer1 Acc 0.9028947368421053, AUC 0.968839704990387, avg_entr 0.012135632336139679
ep31_l1_test_time 0.25293898582458496
Test Epoch31 layer2 Acc 0.9021052631578947, AUC 0.968513011932373, avg_entr 0.008542550727725029
ep31_l2_test_time 0.36539578437805176
Test Epoch31 layer3 Acc 0.9021052631578947, AUC 0.9681456089019775, avg_entr 0.00728886853903532
ep31_l3_test_time 0.4773824214935303
Test Epoch31 layer4 Acc 0.9018421052631579, AUC 0.9636740684509277, avg_entr 0.006725499406456947
ep31_l4_test_time 0.5894608497619629
gc 0
Train Epoch32 Acc 0.9737416666666666 (116849/120000), AUC 0.9967943429946899
ep32_train_time 71.39649105072021
Test Epoch32 layer0 Acc 0.9086842105263158, AUC 0.9772647619247437, avg_entr 0.0377260260283947
ep32_l0_test_time 0.13945698738098145
Test Epoch32 layer1 Acc 0.9031578947368422, AUC 0.9689391255378723, avg_entr 0.012213560752570629
ep32_l1_test_time 0.2524421215057373
Test Epoch32 layer2 Acc 0.901578947368421, AUC 0.9690172672271729, avg_entr 0.008630486205220222
ep32_l2_test_time 0.3640155792236328
Test Epoch32 layer3 Acc 0.9018421052631579, AUC 0.9686797857284546, avg_entr 0.007371511776000261
ep32_l3_test_time 0.4770021438598633
Test Epoch32 layer4 Acc 0.9021052631578947, AUC 0.9647840261459351, avg_entr 0.006897240411490202
ep32_l4_test_time 0.5895342826843262
gc 0
Train Epoch33 Acc 0.973775 (116853/120000), AUC 0.9968441724777222
ep33_train_time 71.4353358745575
Test Epoch33 layer0 Acc 0.908157894736842, AUC 0.977270781993866, avg_entr 0.03776875510811806
ep33_l0_test_time 0.13946938514709473
Test Epoch33 layer1 Acc 0.9034210526315789, AUC 0.9687245488166809, avg_entr 0.012118116021156311
ep33_l1_test_time 0.2522885799407959
Test Epoch33 layer2 Acc 0.9018421052631579, AUC 0.9688745737075806, avg_entr 0.008594897575676441
ep33_l2_test_time 0.36467504501342773
Test Epoch33 layer3 Acc 0.9023684210526316, AUC 0.9685196876525879, avg_entr 0.007341349963098764
ep33_l3_test_time 0.47700929641723633
Test Epoch33 layer4 Acc 0.9018421052631579, AUC 0.9643855094909668, avg_entr 0.006854854989796877
ep33_l4_test_time 0.5898251533508301
gc 0
Train Epoch34 Acc 0.9739416666666667 (116873/120000), AUC 0.996782660484314
ep34_train_time 71.38482880592346
Test Epoch34 layer0 Acc 0.9076315789473685, AUC 0.97724449634552, avg_entr 0.037684496492147446
ep34_l0_test_time 0.14295339584350586
Test Epoch34 layer1 Acc 0.9026315789473685, AUC 0.968859076499939, avg_entr 0.012171562761068344
ep34_l1_test_time 0.2529795169830322
Test Epoch34 layer2 Acc 0.9018421052631579, AUC 0.9688637256622314, avg_entr 0.008646827191114426
ep34_l2_test_time 0.3651862144470215
Test Epoch34 layer3 Acc 0.9021052631578947, AUC 0.9686864614486694, avg_entr 0.007343322969973087
ep34_l3_test_time 0.47675061225891113
Test Epoch34 layer4 Acc 0.9021052631578947, AUC 0.9647622108459473, avg_entr 0.006847579963505268
ep34_l4_test_time 0.5893235206604004
gc 0
Train Epoch35 Acc 0.974175 (116901/120000), AUC 0.996875524520874
ep35_train_time 71.4277822971344
Test Epoch35 layer0 Acc 0.9076315789473685, AUC 0.977243959903717, avg_entr 0.037579745054244995
ep35_l0_test_time 0.14078927040100098
Test Epoch35 layer1 Acc 0.9028947368421053, AUC 0.96880042552948, avg_entr 0.012206081300973892
ep35_l1_test_time 0.2551119327545166
Test Epoch35 layer2 Acc 0.901578947368421, AUC 0.9689878821372986, avg_entr 0.008585219271481037
ep35_l2_test_time 0.3658313751220703
Test Epoch35 layer3 Acc 0.9013157894736842, AUC 0.9682971239089966, avg_entr 0.0072754258289933205
ep35_l3_test_time 0.4772639274597168
Test Epoch35 layer4 Acc 0.901578947368421, AUC 0.9642617106437683, avg_entr 0.006806631572544575
ep35_l4_test_time 0.5908904075622559
gc 0
Train Epoch36 Acc 0.974025 (116883/120000), AUC 0.9967620968818665
ep36_train_time 71.44293999671936
Test Epoch36 layer0 Acc 0.9084210526315789, AUC 0.977250337600708, avg_entr 0.03755694627761841
ep36_l0_test_time 0.14274263381958008
Test Epoch36 layer1 Acc 0.9028947368421053, AUC 0.9687303304672241, avg_entr 0.012190209701657295
ep36_l1_test_time 0.253143310546875
Test Epoch36 layer2 Acc 0.9013157894736842, AUC 0.9689304232597351, avg_entr 0.008538762107491493
ep36_l2_test_time 0.36562442779541016
Test Epoch36 layer3 Acc 0.9013157894736842, AUC 0.9680274128913879, avg_entr 0.007242850959300995
ep36_l3_test_time 0.4776570796966553
Test Epoch36 layer4 Acc 0.9013157894736842, AUC 0.9638436436653137, avg_entr 0.006782930344343185
ep36_l4_test_time 0.5899779796600342
gc 0
Train Epoch37 Acc 0.9739 (116868/120000), AUC 0.9967980980873108
ep37_train_time 71.42224907875061
Test Epoch37 layer0 Acc 0.9084210526315789, AUC 0.9772524833679199, avg_entr 0.0374935045838356
ep37_l0_test_time 0.14028716087341309
Test Epoch37 layer1 Acc 0.9031578947368422, AUC 0.9686782360076904, avg_entr 0.012183977290987968
ep37_l1_test_time 0.25327396392822266
Test Epoch37 layer2 Acc 0.901578947368421, AUC 0.9688600301742554, avg_entr 0.0085745919495821
ep37_l2_test_time 0.36496567726135254
Test Epoch37 layer3 Acc 0.9013157894736842, AUC 0.9683301448822021, avg_entr 0.007229392416775227
ep37_l3_test_time 0.47736024856567383
Test Epoch37 layer4 Acc 0.9018421052631579, AUC 0.9643072485923767, avg_entr 0.006757859606295824
ep37_l4_test_time 0.5897910594940186
gc 0
Train Epoch38 Acc 0.9740166666666666 (116882/120000), AUC 0.9967783689498901
ep38_train_time 71.44130325317383
Test Epoch38 layer0 Acc 0.9089473684210526, AUC 0.9772567749023438, avg_entr 0.03758074343204498
ep38_l0_test_time 0.13967657089233398
Test Epoch38 layer1 Acc 0.9026315789473685, AUC 0.9686951637268066, avg_entr 0.012164376676082611
ep38_l1_test_time 0.25238990783691406
Test Epoch38 layer2 Acc 0.901578947368421, AUC 0.968792736530304, avg_entr 0.008531262166798115
ep38_l2_test_time 0.3644561767578125
Test Epoch38 layer3 Acc 0.901578947368421, AUC 0.9682082533836365, avg_entr 0.0072218384593725204
ep38_l3_test_time 0.4767475128173828
Test Epoch38 layer4 Acc 0.9018421052631579, AUC 0.9642055034637451, avg_entr 0.006771801505237818
ep38_l4_test_time 0.5893025398254395
gc 0
Train Epoch39 Acc 0.9742 (116904/120000), AUC 0.9967191219329834
ep39_train_time 71.4744758605957
Test Epoch39 layer0 Acc 0.9078947368421053, AUC 0.9772424101829529, avg_entr 0.0375676192343235
ep39_l0_test_time 0.13974905014038086
Test Epoch39 layer1 Acc 0.9026315789473685, AUC 0.9686778783798218, avg_entr 0.012139757163822651
ep39_l1_test_time 0.25285863876342773
Test Epoch39 layer2 Acc 0.9013157894736842, AUC 0.9688360095024109, avg_entr 0.008508252911269665
ep39_l2_test_time 0.3654520511627197
Test Epoch39 layer3 Acc 0.901578947368421, AUC 0.9682508707046509, avg_entr 0.007231107912957668
ep39_l3_test_time 0.4777407646179199
Test Epoch39 layer4 Acc 0.9018421052631579, AUC 0.9642727375030518, avg_entr 0.006797312758862972
ep39_l4_test_time 0.5900177955627441
gc 0
Train Epoch40 Acc 0.97385 (116862/120000), AUC 0.9967529773712158
ep40_train_time 71.50333070755005
Test Epoch40 layer0 Acc 0.9078947368421053, AUC 0.9772335290908813, avg_entr 0.037610944360494614
ep40_l0_test_time 0.14316678047180176
Test Epoch40 layer1 Acc 0.9026315789473685, AUC 0.9686384797096252, avg_entr 0.012118684127926826
ep40_l1_test_time 0.2536647319793701
Test Epoch40 layer2 Acc 0.9018421052631579, AUC 0.9686272144317627, avg_entr 0.00851742085069418
ep40_l2_test_time 0.36531615257263184
Test Epoch40 layer3 Acc 0.9021052631578947, AUC 0.9683002829551697, avg_entr 0.007247327361255884
ep40_l3_test_time 0.47753453254699707
Test Epoch40 layer4 Acc 0.9021052631578947, AUC 0.9640506505966187, avg_entr 0.006797222886234522
ep40_l4_test_time 0.5904285907745361
gc 0
Train Epoch41 Acc 0.9739666666666666 (116876/120000), AUC 0.9968609809875488
ep41_train_time 71.53361535072327
Test Epoch41 layer0 Acc 0.908157894736842, AUC 0.9772495031356812, avg_entr 0.03760819137096405
ep41_l0_test_time 0.1385791301727295
Test Epoch41 layer1 Acc 0.9026315789473685, AUC 0.9686399698257446, avg_entr 0.01212590653449297
ep41_l1_test_time 0.25284695625305176
Test Epoch41 layer2 Acc 0.901578947368421, AUC 0.9687610268592834, avg_entr 0.00848319474607706
ep41_l2_test_time 0.36490797996520996
Test Epoch41 layer3 Acc 0.9018421052631579, AUC 0.968241274356842, avg_entr 0.0072436644695699215
ep41_l3_test_time 0.4768056869506836
Test Epoch41 layer4 Acc 0.9021052631578947, AUC 0.9641929864883423, avg_entr 0.006808308884501457
ep41_l4_test_time 0.5897705554962158
gc 0
Train Epoch42 Acc 0.9740083333333334 (116881/120000), AUC 0.9968664646148682
ep42_train_time 71.50257444381714
Test Epoch42 layer0 Acc 0.9076315789473685, AUC 0.9772499799728394, avg_entr 0.037554316222667694
ep42_l0_test_time 0.1399245262145996
Test Epoch42 layer1 Acc 0.9026315789473685, AUC 0.9685916900634766, avg_entr 0.012114709243178368
ep42_l1_test_time 0.25324201583862305
Test Epoch42 layer2 Acc 0.9018421052631579, AUC 0.9687202572822571, avg_entr 0.008477667346596718
ep42_l2_test_time 0.3657996654510498
Test Epoch42 layer3 Acc 0.9018421052631579, AUC 0.9682517051696777, avg_entr 0.007246396504342556
ep42_l3_test_time 0.47792863845825195
Test Epoch42 layer4 Acc 0.9021052631578947, AUC 0.9641704559326172, avg_entr 0.006811026018112898
ep42_l4_test_time 0.5907704830169678
gc 0
Train Epoch43 Acc 0.9740666666666666 (116888/120000), AUC 0.9968178272247314
ep43_train_time 71.4681134223938
Test Epoch43 layer0 Acc 0.908157894736842, AUC 0.9772498607635498, avg_entr 0.03756052628159523
ep43_l0_test_time 0.13950657844543457
Test Epoch43 layer1 Acc 0.9026315789473685, AUC 0.9686174392700195, avg_entr 0.012122532352805138
ep43_l1_test_time 0.25217771530151367
Test Epoch43 layer2 Acc 0.9018421052631579, AUC 0.9687231779098511, avg_entr 0.008500377647578716
ep43_l2_test_time 0.3652305603027344
Test Epoch43 layer3 Acc 0.9018421052631579, AUC 0.9683070182800293, avg_entr 0.007244637235999107
ep43_l3_test_time 0.4771878719329834
Test Epoch43 layer4 Acc 0.9021052631578947, AUC 0.9642998576164246, avg_entr 0.00680746091529727
ep43_l4_test_time 0.5896382331848145
gc 0
Train Epoch44 Acc 0.9739916666666667 (116879/120000), AUC 0.996877133846283
ep44_train_time 71.46400094032288
Test Epoch44 layer0 Acc 0.908157894736842, AUC 0.9772355556488037, avg_entr 0.03751450777053833
ep44_l0_test_time 0.13983678817749023
Test Epoch44 layer1 Acc 0.9026315789473685, AUC 0.9686058759689331, avg_entr 0.012120666913688183
ep44_l1_test_time 0.2531263828277588
Test Epoch44 layer2 Acc 0.9018421052631579, AUC 0.9688214063644409, avg_entr 0.008490458130836487
ep44_l2_test_time 0.3650364875793457
Test Epoch44 layer3 Acc 0.9018421052631579, AUC 0.9683302640914917, avg_entr 0.007242061197757721
ep44_l3_test_time 0.47767043113708496
Test Epoch44 layer4 Acc 0.9021052631578947, AUC 0.9642558097839355, avg_entr 0.006817760411649942
ep44_l4_test_time 0.5895962715148926
gc 0
Train Epoch45 Acc 0.9740916666666667 (116891/120000), AUC 0.9968662858009338
ep45_train_time 71.4247522354126
Test Epoch45 layer0 Acc 0.908157894736842, AUC 0.9772356152534485, avg_entr 0.03748305141925812
ep45_l0_test_time 0.13973617553710938
Test Epoch45 layer1 Acc 0.9026315789473685, AUC 0.9685960412025452, avg_entr 0.012121477164328098
ep45_l1_test_time 0.25275683403015137
Test Epoch45 layer2 Acc 0.9018421052631579, AUC 0.968768835067749, avg_entr 0.008492841385304928
ep45_l2_test_time 0.3656036853790283
Test Epoch45 layer3 Acc 0.9018421052631579, AUC 0.96830153465271, avg_entr 0.007243220694363117
ep45_l3_test_time 0.47844839096069336
Test Epoch45 layer4 Acc 0.9021052631578947, AUC 0.9642209410667419, avg_entr 0.006814806722104549
ep45_l4_test_time 0.5896306037902832
gc 0
Train Epoch46 Acc 0.973875 (116865/120000), AUC 0.9967644214630127
ep46_train_time 71.53907465934753
Test Epoch46 layer0 Acc 0.908157894736842, AUC 0.9772322177886963, avg_entr 0.03751625493168831
ep46_l0_test_time 0.1398935317993164
Test Epoch46 layer1 Acc 0.9026315789473685, AUC 0.9685580134391785, avg_entr 0.0121174156665802
ep46_l1_test_time 0.25238680839538574
Test Epoch46 layer2 Acc 0.9018421052631579, AUC 0.9687435030937195, avg_entr 0.008479656651616096
ep46_l2_test_time 0.3650813102722168
Test Epoch46 layer3 Acc 0.9018421052631579, AUC 0.9682795405387878, avg_entr 0.007236841134727001
ep46_l3_test_time 0.4771137237548828
Test Epoch46 layer4 Acc 0.9021052631578947, AUC 0.9641863107681274, avg_entr 0.006810832768678665
ep46_l4_test_time 0.5898690223693848
gc 0
Train Epoch47 Acc 0.974275 (116913/120000), AUC 0.996819019317627
ep47_train_time 71.5104877948761
Test Epoch47 layer0 Acc 0.9078947368421053, AUC 0.9772312045097351, avg_entr 0.03751328960061073
ep47_l0_test_time 0.1392221450805664
Test Epoch47 layer1 Acc 0.9026315789473685, AUC 0.96855628490448, avg_entr 0.012117870151996613
ep47_l1_test_time 0.2528080940246582
Test Epoch47 layer2 Acc 0.9018421052631579, AUC 0.9687073230743408, avg_entr 0.008485978469252586
ep47_l2_test_time 0.365032434463501
Test Epoch47 layer3 Acc 0.9018421052631579, AUC 0.9683102965354919, avg_entr 0.007237557787448168
ep47_l3_test_time 0.47675371170043945
Test Epoch47 layer4 Acc 0.9021052631578947, AUC 0.9642115235328674, avg_entr 0.006806886754930019
ep47_l4_test_time 0.5894699096679688
gc 0
Train Epoch48 Acc 0.9739333333333333 (116872/120000), AUC 0.9968348741531372
ep48_train_time 71.5850841999054
Test Epoch48 layer0 Acc 0.908157894736842, AUC 0.9772473573684692, avg_entr 0.03753356635570526
ep48_l0_test_time 0.13982582092285156
Test Epoch48 layer1 Acc 0.9026315789473685, AUC 0.9685682654380798, avg_entr 0.01211571879684925
ep48_l1_test_time 0.2531008720397949
Test Epoch48 layer2 Acc 0.9018421052631579, AUC 0.9687161445617676, avg_entr 0.008487654849886894
ep48_l2_test_time 0.3654818534851074
Test Epoch48 layer3 Acc 0.9018421052631579, AUC 0.9683080911636353, avg_entr 0.0072395107708871365
ep48_l3_test_time 0.47739243507385254
Test Epoch48 layer4 Acc 0.9021052631578947, AUC 0.96422278881073, avg_entr 0.006809573620557785
ep48_l4_test_time 0.5902643203735352
gc 0
Train Epoch49 Acc 0.974125 (116895/120000), AUC 0.9967836141586304
ep49_train_time 71.53235292434692
Test Epoch49 layer0 Acc 0.9078947368421053, AUC 0.9772310853004456, avg_entr 0.037478964775800705
ep49_l0_test_time 0.14015913009643555
Test Epoch49 layer1 Acc 0.9026315789473685, AUC 0.9685671329498291, avg_entr 0.012119908817112446
ep49_l1_test_time 0.2529444694519043
Test Epoch49 layer2 Acc 0.9018421052631579, AUC 0.9687649607658386, avg_entr 0.008497271686792374
ep49_l2_test_time 0.36441636085510254
Test Epoch49 layer3 Acc 0.9018421052631579, AUC 0.9683128595352173, avg_entr 0.007237379904836416
ep49_l3_test_time 0.4771265983581543
Test Epoch49 layer4 Acc 0.9021052631578947, AUC 0.9642328023910522, avg_entr 0.006810042075812817
ep49_l4_test_time 0.5896735191345215
Best AUC 0.9803141355514526
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train+valid_time 3664.294235229492
Start Testing
Load ckpt at ckpt/ag_news_transformeral_l5_pad150//ag_news_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.9242105263157895, AUC 0.9849114418029785, avg_entr 0.08158373087644577
ep49_l0_test_time 0.13883447647094727
Test Epoch49 layer1 Acc 0.9244736842105263, AUC 0.9838134050369263, avg_entr 0.028183476999402046
ep49_l1_test_time 0.25430846214294434
Test Epoch49 layer2 Acc 0.9244736842105263, AUC 0.9848996996879578, avg_entr 0.023552387952804565
ep49_l2_test_time 0.367534875869751
Test Epoch49 layer3 Acc 0.9247368421052632, AUC 0.9848929643630981, avg_entr 0.021729787811636925
ep49_l3_test_time 0.47893857955932617
Test Epoch49 layer4 Acc 0.9239473684210526, AUC 0.9852451086044312, avg_entr 0.01959536410868168
ep49_l4_test_time 0.590712308883667
