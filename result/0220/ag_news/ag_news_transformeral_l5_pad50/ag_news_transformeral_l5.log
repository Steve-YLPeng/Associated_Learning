total count words 102019
vocab size 30000
found 26754 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13672292
init_time 19.28525185585022
Start Training
gc 0
Train Epoch0 Acc 0.62245 (74694/120000), AUC 0.8555907607078552
ep0_train_time 28.411306858062744
Test Epoch0 layer0 Acc 0.9076315789473685, AUC 0.9747207164764404, avg_entr 0.21972927451133728
ep0_l0_test_time 0.06439375877380371
Save ckpt to ckpt/ag_news_transformeral_l5_pad50//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9089473684210526, AUC 0.9760706424713135, avg_entr 0.16073976457118988
ep0_l1_test_time 0.09972691535949707
Save ckpt to ckpt/ag_news_transformeral_l5_pad50//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.908157894736842, AUC 0.9760865569114685, avg_entr 0.15614596009254456
ep0_l2_test_time 0.13766217231750488
Save ckpt to ckpt/ag_news_transformeral_l5_pad50//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer3 Acc 0.9055263157894737, AUC 0.9763469099998474, avg_entr 0.14995203912258148
ep0_l3_test_time 0.17423272132873535
Save ckpt to ckpt/ag_news_transformeral_l5_pad50//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer4 Acc 0.9036842105263158, AUC 0.9765493869781494, avg_entr 0.1474447101354599
ep0_l4_test_time 0.211531400680542
Save ckpt to ckpt/ag_news_transformeral_l5_pad50//ag_news_transformeral_l5.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.927025 (111243/120000), AUC 0.9839848875999451
ep1_train_time 28.081789016723633
Test Epoch1 layer0 Acc 0.9118421052631579, AUC 0.9780910611152649, avg_entr 0.1347956359386444
ep1_l0_test_time 0.06299138069152832
Save ckpt to ckpt/ag_news_transformeral_l5_pad50//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.9144736842105263, AUC 0.9788607358932495, avg_entr 0.08746834099292755
ep1_l1_test_time 0.1013493537902832
Save ckpt to ckpt/ag_news_transformeral_l5_pad50//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.915, AUC 0.9783888459205627, avg_entr 0.07019375264644623
ep1_l2_test_time 0.13806390762329102
Test Epoch1 layer3 Acc 0.9152631578947369, AUC 0.9781957864761353, avg_entr 0.061490248888731
ep1_l3_test_time 0.1729419231414795
Test Epoch1 layer4 Acc 0.9144736842105263, AUC 0.9784966707229614, avg_entr 0.05923891440033913
ep1_l4_test_time 0.20993733406066895
gc 0
Train Epoch2 Acc 0.9400083333333333 (112801/120000), AUC 0.9884727001190186
ep2_train_time 28.253875255584717
Test Epoch2 layer0 Acc 0.9086842105263158, AUC 0.9779665470123291, avg_entr 0.1073949933052063
ep2_l0_test_time 0.06241941452026367
Test Epoch2 layer1 Acc 0.9139473684210526, AUC 0.9788109064102173, avg_entr 0.04954441636800766
ep2_l1_test_time 0.09960174560546875
Test Epoch2 layer2 Acc 0.9134210526315789, AUC 0.9782996773719788, avg_entr 0.03734437748789787
ep2_l2_test_time 0.13524508476257324
Test Epoch2 layer3 Acc 0.9126315789473685, AUC 0.9781962633132935, avg_entr 0.03402821719646454
ep2_l3_test_time 0.17179131507873535
Test Epoch2 layer4 Acc 0.9121052631578948, AUC 0.9788557291030884, avg_entr 0.03327468782663345
ep2_l4_test_time 0.20947742462158203
gc 0
Train Epoch3 Acc 0.94735 (113682/120000), AUC 0.9901736974716187
ep3_train_time 28.137380838394165
Test Epoch3 layer0 Acc 0.9068421052631579, AUC 0.9780681133270264, avg_entr 0.09347321093082428
ep3_l0_test_time 0.06272077560424805
Test Epoch3 layer1 Acc 0.9105263157894737, AUC 0.9758763909339905, avg_entr 0.033579811453819275
ep3_l1_test_time 0.09948897361755371
Test Epoch3 layer2 Acc 0.91, AUC 0.9759536981582642, avg_entr 0.02668842114508152
ep3_l2_test_time 0.1351165771484375
Test Epoch3 layer3 Acc 0.91, AUC 0.9752258062362671, avg_entr 0.024761272594332695
ep3_l3_test_time 0.17168641090393066
Test Epoch3 layer4 Acc 0.9097368421052632, AUC 0.9757272601127625, avg_entr 0.02347165159881115
ep3_l4_test_time 0.20900583267211914
gc 0
Train Epoch4 Acc 0.9523416666666666 (114281/120000), AUC 0.9912768602371216
ep4_train_time 28.11859941482544
Test Epoch4 layer0 Acc 0.9107894736842105, AUC 0.9779099225997925, avg_entr 0.08218520879745483
ep4_l0_test_time 0.06329464912414551
Test Epoch4 layer1 Acc 0.9105263157894737, AUC 0.9766855239868164, avg_entr 0.02915799245238304
ep4_l1_test_time 0.09874916076660156
Test Epoch4 layer2 Acc 0.911578947368421, AUC 0.9770801663398743, avg_entr 0.023548772558569908
ep4_l2_test_time 0.13570141792297363
Test Epoch4 layer3 Acc 0.9118421052631579, AUC 0.9786067008972168, avg_entr 0.021363792940974236
ep4_l3_test_time 0.17185688018798828
Test Epoch4 layer4 Acc 0.9123684210526316, AUC 0.9790617823600769, avg_entr 0.020293105393648148
ep4_l4_test_time 0.2087705135345459
Save ckpt to ckpt/ag_news_transformeral_l5_pad50//ag_news_transformeral_l5.pt  ,ep 4
gc 0
Train Epoch5 Acc 0.9558083333333334 (114697/120000), AUC 0.9922053217887878
ep5_train_time 28.337012767791748
Test Epoch5 layer0 Acc 0.9118421052631579, AUC 0.9779616594314575, avg_entr 0.07541687041521072
ep5_l0_test_time 0.06350588798522949
Test Epoch5 layer1 Acc 0.9128947368421053, AUC 0.9746901988983154, avg_entr 0.025488046929240227
ep5_l1_test_time 0.10020589828491211
Test Epoch5 layer2 Acc 0.9131578947368421, AUC 0.9754421710968018, avg_entr 0.01993018575012684
ep5_l2_test_time 0.1364607810974121
Test Epoch5 layer3 Acc 0.9128947368421053, AUC 0.976934552192688, avg_entr 0.018161030486226082
ep5_l3_test_time 0.17290306091308594
Test Epoch5 layer4 Acc 0.9126315789473685, AUC 0.977281391620636, avg_entr 0.01680111698806286
ep5_l4_test_time 0.20959138870239258
gc 0
Train Epoch6 Acc 0.960975 (115317/120000), AUC 0.9937496185302734
ep6_train_time 28.140495538711548
Test Epoch6 layer0 Acc 0.911578947368421, AUC 0.9782105684280396, avg_entr 0.07212735712528229
ep6_l0_test_time 0.062471628189086914
Test Epoch6 layer1 Acc 0.9089473684210526, AUC 0.9749116897583008, avg_entr 0.02433551475405693
ep6_l1_test_time 0.09995865821838379
Test Epoch6 layer2 Acc 0.9094736842105263, AUC 0.9761753082275391, avg_entr 0.01816387288272381
ep6_l2_test_time 0.1365339756011963
Test Epoch6 layer3 Acc 0.9092105263157895, AUC 0.9772742390632629, avg_entr 0.015722578391432762
ep6_l3_test_time 0.17186903953552246
Test Epoch6 layer4 Acc 0.91, AUC 0.9769307374954224, avg_entr 0.01432962715625763
ep6_l4_test_time 0.20902538299560547
gc 0
Train Epoch7 Acc 0.9625666666666667 (115508/120000), AUC 0.9940760135650635
ep7_train_time 28.40600085258484
Test Epoch7 layer0 Acc 0.9102631578947369, AUC 0.9778754711151123, avg_entr 0.06829294562339783
ep7_l0_test_time 0.06188535690307617
Test Epoch7 layer1 Acc 0.9113157894736842, AUC 0.9747837781906128, avg_entr 0.023125862702727318
ep7_l1_test_time 0.09792900085449219
Test Epoch7 layer2 Acc 0.91, AUC 0.9760304093360901, avg_entr 0.018110046163201332
ep7_l2_test_time 0.13454127311706543
Test Epoch7 layer3 Acc 0.9092105263157895, AUC 0.9774706363677979, avg_entr 0.016535930335521698
ep7_l3_test_time 0.17119598388671875
Test Epoch7 layer4 Acc 0.9092105263157895, AUC 0.976691484451294, avg_entr 0.015184694901108742
ep7_l4_test_time 0.20825862884521484
gc 0
Train Epoch8 Acc 0.9639083333333334 (115669/120000), AUC 0.9942435026168823
ep8_train_time 28.42587447166443
Test Epoch8 layer0 Acc 0.9071052631578947, AUC 0.9774689078330994, avg_entr 0.06643662601709366
ep8_l0_test_time 0.06286025047302246
Test Epoch8 layer1 Acc 0.9094736842105263, AUC 0.9742816686630249, avg_entr 0.021989772096276283
ep8_l1_test_time 0.09845113754272461
Test Epoch8 layer2 Acc 0.9084210526315789, AUC 0.975480318069458, avg_entr 0.016654904931783676
ep8_l2_test_time 0.13497257232666016
Test Epoch8 layer3 Acc 0.908157894736842, AUC 0.9769713878631592, avg_entr 0.014283782802522182
ep8_l3_test_time 0.17163991928100586
Test Epoch8 layer4 Acc 0.9078947368421053, AUC 0.9761849641799927, avg_entr 0.012662176974117756
ep8_l4_test_time 0.20875096321105957
gc 0
Train Epoch9 Acc 0.9652083333333333 (115825/120000), AUC 0.9949398636817932
ep9_train_time 28.291330337524414
Test Epoch9 layer0 Acc 0.9097368421052632, AUC 0.9773679375648499, avg_entr 0.06227344647049904
ep9_l0_test_time 0.06268072128295898
Test Epoch9 layer1 Acc 0.9089473684210526, AUC 0.9733169674873352, avg_entr 0.02097572758793831
ep9_l1_test_time 0.09802842140197754
Test Epoch9 layer2 Acc 0.9068421052631579, AUC 0.9746649265289307, avg_entr 0.016166146844625473
ep9_l2_test_time 0.13437128067016602
Test Epoch9 layer3 Acc 0.9071052631578947, AUC 0.9767533540725708, avg_entr 0.014206785708665848
ep9_l3_test_time 0.17171835899353027
Test Epoch9 layer4 Acc 0.9076315789473685, AUC 0.9775450229644775, avg_entr 0.012741955928504467
ep9_l4_test_time 0.208298921585083
gc 0
Train Epoch10 Acc 0.9668166666666667 (116018/120000), AUC 0.9951480627059937
ep10_train_time 28.320102214813232
Test Epoch10 layer0 Acc 0.908157894736842, AUC 0.9773738384246826, avg_entr 0.05908716470003128
ep10_l0_test_time 0.0627284049987793
Test Epoch10 layer1 Acc 0.9086842105263158, AUC 0.9715330004692078, avg_entr 0.020055528730154037
ep10_l1_test_time 0.09801030158996582
Test Epoch10 layer2 Acc 0.9078947368421053, AUC 0.972974419593811, avg_entr 0.014903159812092781
ep10_l2_test_time 0.13436508178710938
Test Epoch10 layer3 Acc 0.9073684210526316, AUC 0.975370466709137, avg_entr 0.012968302704393864
ep10_l3_test_time 0.17129945755004883
Test Epoch10 layer4 Acc 0.9078947368421053, AUC 0.9765272736549377, avg_entr 0.011431735940277576
ep10_l4_test_time 0.20803475379943848
gc 0
Train Epoch11 Acc 0.9683333333333334 (116200/120000), AUC 0.9956251978874207
ep11_train_time 28.0695960521698
Test Epoch11 layer0 Acc 0.9086842105263158, AUC 0.9774713516235352, avg_entr 0.05707000568509102
ep11_l0_test_time 0.062361955642700195
Test Epoch11 layer1 Acc 0.906578947368421, AUC 0.9708861708641052, avg_entr 0.019951986148953438
ep11_l1_test_time 0.09769058227539062
Test Epoch11 layer2 Acc 0.9052631578947369, AUC 0.9711591601371765, avg_entr 0.014361019246280193
ep11_l2_test_time 0.13441228866577148
Test Epoch11 layer3 Acc 0.9055263157894737, AUC 0.9744194149971008, avg_entr 0.012560094706714153
ep11_l3_test_time 0.1710822582244873
Test Epoch11 layer4 Acc 0.9052631578947369, AUC 0.9744170904159546, avg_entr 0.011308916844427586
ep11_l4_test_time 0.2081911563873291
gc 0
Train Epoch12 Acc 0.9692916666666667 (116315/120000), AUC 0.9955325126647949
ep12_train_time 28.46046018600464
Test Epoch12 layer0 Acc 0.9073684210526316, AUC 0.9770455360412598, avg_entr 0.0564860962331295
ep12_l0_test_time 0.06299448013305664
Test Epoch12 layer1 Acc 0.908157894736842, AUC 0.9696052670478821, avg_entr 0.019739294424653053
ep12_l1_test_time 0.0984349250793457
Test Epoch12 layer2 Acc 0.9052631578947369, AUC 0.9695062637329102, avg_entr 0.013707761652767658
ep12_l2_test_time 0.1350109577178955
Test Epoch12 layer3 Acc 0.9047368421052632, AUC 0.9689685106277466, avg_entr 0.011379935778677464
ep12_l3_test_time 0.1714177131652832
Test Epoch12 layer4 Acc 0.9057894736842105, AUC 0.9694324731826782, avg_entr 0.010166268795728683
ep12_l4_test_time 0.2080535888671875
gc 0
Train Epoch13 Acc 0.9699916666666667 (116399/120000), AUC 0.995822012424469
ep13_train_time 28.473737001419067
Test Epoch13 layer0 Acc 0.9076315789473685, AUC 0.9770631790161133, avg_entr 0.054158758372068405
ep13_l0_test_time 0.06243562698364258
Test Epoch13 layer1 Acc 0.9071052631578947, AUC 0.9704580903053284, avg_entr 0.018960459157824516
ep13_l1_test_time 0.09879755973815918
Test Epoch13 layer2 Acc 0.9057894736842105, AUC 0.9705568552017212, avg_entr 0.013049019500613213
ep13_l2_test_time 0.13570952415466309
Test Epoch13 layer3 Acc 0.905, AUC 0.9731279611587524, avg_entr 0.011018265038728714
ep13_l3_test_time 0.17177796363830566
Test Epoch13 layer4 Acc 0.9047368421052632, AUC 0.9742612838745117, avg_entr 0.009735059924423695
ep13_l4_test_time 0.20830607414245605
gc 0
Train Epoch14 Acc 0.9708083333333334 (116497/120000), AUC 0.9959685802459717
ep14_train_time 28.682944297790527
Test Epoch14 layer0 Acc 0.9071052631578947, AUC 0.9770529866218567, avg_entr 0.051556240767240524
ep14_l0_test_time 0.0629129409790039
Test Epoch14 layer1 Acc 0.9063157894736842, AUC 0.97010338306427, avg_entr 0.017586959525942802
ep14_l1_test_time 0.09832930564880371
Test Epoch14 layer2 Acc 0.9036842105263158, AUC 0.9703615307807922, avg_entr 0.01257855724543333
ep14_l2_test_time 0.13496613502502441
Test Epoch14 layer3 Acc 0.9047368421052632, AUC 0.9731200933456421, avg_entr 0.01051189936697483
ep14_l3_test_time 0.1714160442352295
Test Epoch14 layer4 Acc 0.9044736842105263, AUC 0.9730977416038513, avg_entr 0.0092007489874959
ep14_l4_test_time 0.20775580406188965
gc 0
Train Epoch15 Acc 0.9715333333333334 (116584/120000), AUC 0.9961233139038086
ep15_train_time 28.245423316955566
Test Epoch15 layer0 Acc 0.9076315789473685, AUC 0.9771012663841248, avg_entr 0.05028606206178665
ep15_l0_test_time 0.062329769134521484
Test Epoch15 layer1 Acc 0.9073684210526316, AUC 0.9688371419906616, avg_entr 0.016555294394493103
ep15_l1_test_time 0.09770584106445312
Test Epoch15 layer2 Acc 0.9057894736842105, AUC 0.9684956073760986, avg_entr 0.011259239166975021
ep15_l2_test_time 0.1342780590057373
Test Epoch15 layer3 Acc 0.9052631578947369, AUC 0.9713290333747864, avg_entr 0.009285792708396912
ep15_l3_test_time 0.17048931121826172
Test Epoch15 layer4 Acc 0.9057894736842105, AUC 0.9714972376823425, avg_entr 0.008230848237872124
ep15_l4_test_time 0.20808696746826172
gc 0
Train Epoch16 Acc 0.9719 (116628/120000), AUC 0.9961217641830444
ep16_train_time 28.120450019836426
Test Epoch16 layer0 Acc 0.9057894736842105, AUC 0.9769902229309082, avg_entr 0.04916038736701012
ep16_l0_test_time 0.06277179718017578
Test Epoch16 layer1 Acc 0.9044736842105263, AUC 0.9695885181427002, avg_entr 0.01645829528570175
ep16_l1_test_time 0.09813332557678223
Test Epoch16 layer2 Acc 0.9034210526315789, AUC 0.9698262214660645, avg_entr 0.011888660490512848
ep16_l2_test_time 0.1343989372253418
Test Epoch16 layer3 Acc 0.9034210526315789, AUC 0.9719023108482361, avg_entr 0.010052453726530075
ep16_l3_test_time 0.17120003700256348
Test Epoch16 layer4 Acc 0.9031578947368422, AUC 0.9729634523391724, avg_entr 0.009164784103631973
ep16_l4_test_time 0.20832014083862305
gc 0
Train Epoch17 Acc 0.9725 (116700/120000), AUC 0.9963240623474121
ep17_train_time 28.162901639938354
Test Epoch17 layer0 Acc 0.9084210526315789, AUC 0.9770249724388123, avg_entr 0.047200217843055725
ep17_l0_test_time 0.06226062774658203
Test Epoch17 layer1 Acc 0.9063157894736842, AUC 0.96828293800354, avg_entr 0.016179179772734642
ep17_l1_test_time 0.09818482398986816
Test Epoch17 layer2 Acc 0.9044736842105263, AUC 0.9679757356643677, avg_entr 0.011316636577248573
ep17_l2_test_time 0.13434529304504395
Test Epoch17 layer3 Acc 0.9047368421052632, AUC 0.969664454460144, avg_entr 0.009102092124521732
ep17_l3_test_time 0.17089438438415527
Test Epoch17 layer4 Acc 0.905, AUC 0.9709922075271606, avg_entr 0.008166701532900333
ep17_l4_test_time 0.20771288871765137
gc 0
Train Epoch18 Acc 0.9726083333333333 (116713/120000), AUC 0.9963906407356262
ep18_train_time 28.463010787963867
Test Epoch18 layer0 Acc 0.9073684210526316, AUC 0.9769700169563293, avg_entr 0.046063248068094254
ep18_l0_test_time 0.06298685073852539
Test Epoch18 layer1 Acc 0.9057894736842105, AUC 0.9687880277633667, avg_entr 0.015993867069482803
ep18_l1_test_time 0.09842658042907715
Test Epoch18 layer2 Acc 0.9031578947368422, AUC 0.9687680006027222, avg_entr 0.010771699249744415
ep18_l2_test_time 0.13501882553100586
Test Epoch18 layer3 Acc 0.9034210526315789, AUC 0.971778392791748, avg_entr 0.008855045773088932
ep18_l3_test_time 0.17130708694458008
Test Epoch18 layer4 Acc 0.9036842105263158, AUC 0.9719902276992798, avg_entr 0.007914243265986443
ep18_l4_test_time 0.20804190635681152
gc 0
Train Epoch19 Acc 0.9734166666666667 (116810/120000), AUC 0.9965701699256897
ep19_train_time 28.5351505279541
Test Epoch19 layer0 Acc 0.9057894736842105, AUC 0.9768686294555664, avg_entr 0.04561358317732811
ep19_l0_test_time 0.06368541717529297
Test Epoch19 layer1 Acc 0.9042105263157895, AUC 0.96836918592453, avg_entr 0.015442712232470512
ep19_l1_test_time 0.09810781478881836
Test Epoch19 layer2 Acc 0.9034210526315789, AUC 0.9678776264190674, avg_entr 0.010581708513200283
ep19_l2_test_time 0.1346437931060791
Test Epoch19 layer3 Acc 0.9031578947368422, AUC 0.9703236818313599, avg_entr 0.008594992570579052
ep19_l3_test_time 0.1715993881225586
Test Epoch19 layer4 Acc 0.9028947368421053, AUC 0.9693417549133301, avg_entr 0.0078537967056036
ep19_l4_test_time 0.20858240127563477
gc 0
Train Epoch20 Acc 0.9733333333333334 (116800/120000), AUC 0.9964929223060608
ep20_train_time 28.8751323223114
Test Epoch20 layer0 Acc 0.9063157894736842, AUC 0.9769594669342041, avg_entr 0.04430003464221954
ep20_l0_test_time 0.06269669532775879
Test Epoch20 layer1 Acc 0.905, AUC 0.967990517616272, avg_entr 0.015040406957268715
ep20_l1_test_time 0.0979917049407959
Test Epoch20 layer2 Acc 0.9042105263157895, AUC 0.9667645692825317, avg_entr 0.010292883031070232
ep20_l2_test_time 0.13411641120910645
Test Epoch20 layer3 Acc 0.9036842105263158, AUC 0.9691788554191589, avg_entr 0.00835197139531374
ep20_l3_test_time 0.17082905769348145
Test Epoch20 layer4 Acc 0.9039473684210526, AUC 0.9673714637756348, avg_entr 0.0073779309168457985
ep20_l4_test_time 0.20763897895812988
gc 0
Train Epoch21 Acc 0.97335 (116802/120000), AUC 0.9964708685874939
ep21_train_time 28.614768505096436
Test Epoch21 layer0 Acc 0.9071052631578947, AUC 0.9770099520683289, avg_entr 0.042874258011579514
ep21_l0_test_time 0.061823368072509766
Test Epoch21 layer1 Acc 0.9055263157894737, AUC 0.9681411981582642, avg_entr 0.014961027540266514
ep21_l1_test_time 0.09790706634521484
Test Epoch21 layer2 Acc 0.9042105263157895, AUC 0.966860294342041, avg_entr 0.010534467175602913
ep21_l2_test_time 0.13457918167114258
Test Epoch21 layer3 Acc 0.9031578947368422, AUC 0.9681921005249023, avg_entr 0.008663944900035858
ep21_l3_test_time 0.17068886756896973
Test Epoch21 layer4 Acc 0.9034210526315789, AUC 0.9680905342102051, avg_entr 0.007693553809076548
ep21_l4_test_time 0.20768189430236816
gc 0
Train Epoch22 Acc 0.973825 (116859/120000), AUC 0.9965105056762695
ep22_train_time 28.50510287284851
Test Epoch22 layer0 Acc 0.9060526315789473, AUC 0.976978063583374, avg_entr 0.042295098304748535
ep22_l0_test_time 0.06236553192138672
Test Epoch22 layer1 Acc 0.9057894736842105, AUC 0.9680384397506714, avg_entr 0.014461979269981384
ep22_l1_test_time 0.09810757637023926
Test Epoch22 layer2 Acc 0.9034210526315789, AUC 0.9669796228408813, avg_entr 0.010039390064775944
ep22_l2_test_time 0.1345808506011963
Test Epoch22 layer3 Acc 0.9034210526315789, AUC 0.9689023494720459, avg_entr 0.008158051408827305
ep22_l3_test_time 0.17072319984436035
Test Epoch22 layer4 Acc 0.9031578947368422, AUC 0.9683679342269897, avg_entr 0.007288249209523201
ep22_l4_test_time 0.20777106285095215
gc 0
Train Epoch23 Acc 0.973925 (116871/120000), AUC 0.99654221534729
ep23_train_time 28.172537803649902
Test Epoch23 layer0 Acc 0.906578947368421, AUC 0.9769866466522217, avg_entr 0.041716620326042175
ep23_l0_test_time 0.0627756118774414
Test Epoch23 layer1 Acc 0.9047368421052632, AUC 0.9677838087081909, avg_entr 0.0141939427703619
ep23_l1_test_time 0.0985727310180664
Test Epoch23 layer2 Acc 0.9042105263157895, AUC 0.9661950469017029, avg_entr 0.009748590178787708
ep23_l2_test_time 0.13445281982421875
Test Epoch23 layer3 Acc 0.9031578947368422, AUC 0.9682050347328186, avg_entr 0.007958054542541504
ep23_l3_test_time 0.17114830017089844
Test Epoch23 layer4 Acc 0.9031578947368422, AUC 0.9668915271759033, avg_entr 0.007051186636090279
ep23_l4_test_time 0.20831084251403809
gc 0
Train Epoch24 Acc 0.9744166666666667 (116930/120000), AUC 0.9964323043823242
ep24_train_time 28.300557851791382
Test Epoch24 layer0 Acc 0.906578947368421, AUC 0.9769958853721619, avg_entr 0.041199203580617905
ep24_l0_test_time 0.06232786178588867
Test Epoch24 layer1 Acc 0.9052631578947369, AUC 0.9678582549095154, avg_entr 0.013955449685454369
ep24_l1_test_time 0.09816241264343262
Test Epoch24 layer2 Acc 0.9036842105263158, AUC 0.9668124318122864, avg_entr 0.009788058698177338
ep24_l2_test_time 0.13406085968017578
Test Epoch24 layer3 Acc 0.9036842105263158, AUC 0.9686235189437866, avg_entr 0.008075484074652195
ep24_l3_test_time 0.17090749740600586
Test Epoch24 layer4 Acc 0.9034210526315789, AUC 0.9679040312767029, avg_entr 0.0072261071763932705
ep24_l4_test_time 0.20761609077453613
gc 0
Train Epoch25 Acc 0.974475 (116937/120000), AUC 0.9966548681259155
ep25_train_time 28.345277786254883
Test Epoch25 layer0 Acc 0.906578947368421, AUC 0.9769595861434937, avg_entr 0.04091770201921463
ep25_l0_test_time 0.062323808670043945
Test Epoch25 layer1 Acc 0.9055263157894737, AUC 0.9677721858024597, avg_entr 0.013898717239499092
ep25_l1_test_time 0.09846019744873047
Test Epoch25 layer2 Acc 0.9036842105263158, AUC 0.9666444659233093, avg_entr 0.009794233366847038
ep25_l2_test_time 0.1345374584197998
Test Epoch25 layer3 Acc 0.9031578947368422, AUC 0.9689884185791016, avg_entr 0.007960905320942402
ep25_l3_test_time 0.17098736763000488
Test Epoch25 layer4 Acc 0.9031578947368422, AUC 0.968454122543335, avg_entr 0.007130494341254234
ep25_l4_test_time 0.20804071426391602
gc 0
Train Epoch26 Acc 0.9742583333333333 (116911/120000), AUC 0.9965928196907043
ep26_train_time 28.850883722305298
Test Epoch26 layer0 Acc 0.906578947368421, AUC 0.976989209651947, avg_entr 0.040538955479860306
ep26_l0_test_time 0.06247735023498535
Test Epoch26 layer1 Acc 0.9055263157894737, AUC 0.9675901532173157, avg_entr 0.013597975485026836
ep26_l1_test_time 0.09820127487182617
Test Epoch26 layer2 Acc 0.9036842105263158, AUC 0.9665061235427856, avg_entr 0.009492977522313595
ep26_l2_test_time 0.13478684425354004
Test Epoch26 layer3 Acc 0.9023684210526316, AUC 0.9683769345283508, avg_entr 0.007722750306129456
ep26_l3_test_time 0.17143869400024414
Test Epoch26 layer4 Acc 0.9026315789473685, AUC 0.9679315090179443, avg_entr 0.00685536814853549
ep26_l4_test_time 0.20807170867919922
gc 0
Train Epoch27 Acc 0.9743916666666667 (116927/120000), AUC 0.996641993522644
ep27_train_time 28.343075037002563
Test Epoch27 layer0 Acc 0.9068421052631579, AUC 0.9769644737243652, avg_entr 0.04033932462334633
ep27_l0_test_time 0.06335020065307617
Test Epoch27 layer1 Acc 0.9052631578947369, AUC 0.9672903418540955, avg_entr 0.013350685127079487
ep27_l1_test_time 0.09867048263549805
Test Epoch27 layer2 Acc 0.9034210526315789, AUC 0.9659380912780762, avg_entr 0.009335288777947426
ep27_l2_test_time 0.1351161003112793
Test Epoch27 layer3 Acc 0.9034210526315789, AUC 0.9677950739860535, avg_entr 0.0076923673041164875
ep27_l3_test_time 0.17084622383117676
Test Epoch27 layer4 Acc 0.9039473684210526, AUC 0.9670191407203674, avg_entr 0.006939689628779888
ep27_l4_test_time 0.2075800895690918
gc 0
Train Epoch28 Acc 0.9745 (116940/120000), AUC 0.9967225790023804
ep28_train_time 28.607126474380493
Test Epoch28 layer0 Acc 0.9055263157894737, AUC 0.9769504070281982, avg_entr 0.040338218212127686
ep28_l0_test_time 0.06175422668457031
Test Epoch28 layer1 Acc 0.9055263157894737, AUC 0.9675514698028564, avg_entr 0.013540231622755527
ep28_l1_test_time 0.09764289855957031
Test Epoch28 layer2 Acc 0.9036842105263158, AUC 0.9664396643638611, avg_entr 0.009467260912060738
ep28_l2_test_time 0.13446259498596191
Test Epoch28 layer3 Acc 0.9034210526315789, AUC 0.9682777523994446, avg_entr 0.007761113345623016
ep28_l3_test_time 0.17086267471313477
Test Epoch28 layer4 Acc 0.9034210526315789, AUC 0.9679582118988037, avg_entr 0.006978957448154688
ep28_l4_test_time 0.2082524299621582
gc 0
Train Epoch29 Acc 0.9744416666666667 (116933/120000), AUC 0.9968613386154175
ep29_train_time 28.233923196792603
Test Epoch29 layer0 Acc 0.9055263157894737, AUC 0.9769527912139893, avg_entr 0.04026194289326668
ep29_l0_test_time 0.06291818618774414
Test Epoch29 layer1 Acc 0.9052631578947369, AUC 0.9673894047737122, avg_entr 0.01331279892474413
ep29_l1_test_time 0.09877991676330566
Test Epoch29 layer2 Acc 0.9034210526315789, AUC 0.9662193059921265, avg_entr 0.009273349307477474
ep29_l2_test_time 0.13472867012023926
Test Epoch29 layer3 Acc 0.9023684210526316, AUC 0.9681723713874817, avg_entr 0.0075918841175735
ep29_l3_test_time 0.17114639282226562
Test Epoch29 layer4 Acc 0.9023684210526316, AUC 0.9670851230621338, avg_entr 0.0068024154752492905
ep29_l4_test_time 0.20824241638183594
gc 0
Train Epoch30 Acc 0.9744833333333334 (116938/120000), AUC 0.9967449903488159
ep30_train_time 28.19783067703247
Test Epoch30 layer0 Acc 0.9057894736842105, AUC 0.9769608974456787, avg_entr 0.04000420123338699
ep30_l0_test_time 0.06602931022644043
Test Epoch30 layer1 Acc 0.9057894736842105, AUC 0.967366635799408, avg_entr 0.013394933193922043
ep30_l1_test_time 0.09919357299804688
Test Epoch30 layer2 Acc 0.9031578947368422, AUC 0.9661554098129272, avg_entr 0.009313556365668774
ep30_l2_test_time 0.13508272171020508
Test Epoch30 layer3 Acc 0.9031578947368422, AUC 0.967928409576416, avg_entr 0.007576044648885727
ep30_l3_test_time 0.17143630981445312
Test Epoch30 layer4 Acc 0.9028947368421053, AUC 0.967062771320343, avg_entr 0.0067598856985569
ep30_l4_test_time 0.20850849151611328
gc 0
Train Epoch31 Acc 0.974775 (116973/120000), AUC 0.9968580603599548
ep31_train_time 28.221025705337524
Test Epoch31 layer0 Acc 0.9060526315789473, AUC 0.9769530892372131, avg_entr 0.039991170167922974
ep31_l0_test_time 0.06261897087097168
Test Epoch31 layer1 Acc 0.9055263157894737, AUC 0.9674493074417114, avg_entr 0.013421909883618355
ep31_l1_test_time 0.09810137748718262
Test Epoch31 layer2 Acc 0.9036842105263158, AUC 0.9663228988647461, avg_entr 0.009337015450000763
ep31_l2_test_time 0.13448286056518555
Test Epoch31 layer3 Acc 0.9026315789473685, AUC 0.9687468409538269, avg_entr 0.007559946738183498
ep31_l3_test_time 0.1711127758026123
Test Epoch31 layer4 Acc 0.9028947368421053, AUC 0.967552900314331, avg_entr 0.006776452995836735
ep31_l4_test_time 0.2079463005065918
gc 0
Train Epoch32 Acc 0.97485 (116982/120000), AUC 0.996787428855896
ep32_train_time 28.47242259979248
Test Epoch32 layer0 Acc 0.9060526315789473, AUC 0.9769449830055237, avg_entr 0.03994492068886757
ep32_l0_test_time 0.06306815147399902
Test Epoch32 layer1 Acc 0.9052631578947369, AUC 0.9673476219177246, avg_entr 0.01338723674416542
ep32_l1_test_time 0.0984041690826416
Test Epoch32 layer2 Acc 0.9036842105263158, AUC 0.9661283493041992, avg_entr 0.009309021756052971
ep32_l2_test_time 0.13447284698486328
Test Epoch32 layer3 Acc 0.9028947368421053, AUC 0.9682266116142273, avg_entr 0.00750894146040082
ep32_l3_test_time 0.17078685760498047
Test Epoch32 layer4 Acc 0.9028947368421053, AUC 0.9672084450721741, avg_entr 0.006730322726070881
ep32_l4_test_time 0.20814228057861328
gc 0
Train Epoch33 Acc 0.9747583333333333 (116971/120000), AUC 0.9967560768127441
ep33_train_time 28.736675262451172
Test Epoch33 layer0 Acc 0.906578947368421, AUC 0.9769599437713623, avg_entr 0.03983104228973389
ep33_l0_test_time 0.06269669532775879
Test Epoch33 layer1 Acc 0.9052631578947369, AUC 0.9672043919563293, avg_entr 0.013185710646212101
ep33_l1_test_time 0.09775567054748535
Test Epoch33 layer2 Acc 0.9036842105263158, AUC 0.9659574031829834, avg_entr 0.009226340800523758
ep33_l2_test_time 0.1347975730895996
Test Epoch33 layer3 Acc 0.9026315789473685, AUC 0.9673194289207458, avg_entr 0.007535991724580526
ep33_l3_test_time 0.17097711563110352
Test Epoch33 layer4 Acc 0.9023684210526316, AUC 0.9668210744857788, avg_entr 0.006777417380362749
ep33_l4_test_time 0.20749354362487793
gc 0
Train Epoch34 Acc 0.97465 (116958/120000), AUC 0.9967352151870728
ep34_train_time 28.860131978988647
Test Epoch34 layer0 Acc 0.906578947368421, AUC 0.9769539833068848, avg_entr 0.03973452001810074
ep34_l0_test_time 0.06220293045043945
Test Epoch34 layer1 Acc 0.9052631578947369, AUC 0.9673433303833008, avg_entr 0.01329056266695261
ep34_l1_test_time 0.09814977645874023
Test Epoch34 layer2 Acc 0.9031578947368422, AUC 0.9662922620773315, avg_entr 0.009253812953829765
ep34_l2_test_time 0.13453292846679688
Test Epoch34 layer3 Acc 0.9028947368421053, AUC 0.9682484269142151, avg_entr 0.007398448884487152
ep34_l3_test_time 0.17095685005187988
Test Epoch34 layer4 Acc 0.9028947368421053, AUC 0.9674513339996338, avg_entr 0.006646688561886549
ep34_l4_test_time 0.20777249336242676
gc 0
Train Epoch35 Acc 0.9749583333333334 (116995/120000), AUC 0.9966915845870972
ep35_train_time 28.19186305999756
Test Epoch35 layer0 Acc 0.9060526315789473, AUC 0.976942777633667, avg_entr 0.039781294763088226
ep35_l0_test_time 0.06224966049194336
Test Epoch35 layer1 Acc 0.9052631578947369, AUC 0.9673450589179993, avg_entr 0.013230891898274422
ep35_l1_test_time 0.09779238700866699
Test Epoch35 layer2 Acc 0.9031578947368422, AUC 0.9661770462989807, avg_entr 0.009221290238201618
ep35_l2_test_time 0.13454222679138184
Test Epoch35 layer3 Acc 0.9031578947368422, AUC 0.9681898951530457, avg_entr 0.007464351132512093
ep35_l3_test_time 0.17101049423217773
Test Epoch35 layer4 Acc 0.9031578947368422, AUC 0.9673078656196594, avg_entr 0.0066789849661290646
ep35_l4_test_time 0.20796990394592285
gc 0
Train Epoch36 Acc 0.974925 (116991/120000), AUC 0.9968200325965881
ep36_train_time 28.163210153579712
Test Epoch36 layer0 Acc 0.9063157894736842, AUC 0.9769473075866699, avg_entr 0.03972914069890976
ep36_l0_test_time 0.06235218048095703
Test Epoch36 layer1 Acc 0.9052631578947369, AUC 0.9673241376876831, avg_entr 0.013204396702349186
ep36_l1_test_time 0.0983128547668457
Test Epoch36 layer2 Acc 0.9031578947368422, AUC 0.9661241173744202, avg_entr 0.009230822324752808
ep36_l2_test_time 0.13487577438354492
Test Epoch36 layer3 Acc 0.9031578947368422, AUC 0.9678150415420532, avg_entr 0.007457297295331955
ep36_l3_test_time 0.17152142524719238
Test Epoch36 layer4 Acc 0.9031578947368422, AUC 0.9669647812843323, avg_entr 0.006678358186036348
ep36_l4_test_time 0.2077782154083252
gc 0
Train Epoch37 Acc 0.974925 (116991/120000), AUC 0.9967240691184998
ep37_train_time 28.419521808624268
Test Epoch37 layer0 Acc 0.906578947368421, AUC 0.9769560098648071, avg_entr 0.039653971791267395
ep37_l0_test_time 0.061957359313964844
Test Epoch37 layer1 Acc 0.9052631578947369, AUC 0.9672393798828125, avg_entr 0.013235864229500294
ep37_l1_test_time 0.0980536937713623
Test Epoch37 layer2 Acc 0.9028947368421053, AUC 0.9659909009933472, avg_entr 0.00921559426933527
ep37_l2_test_time 0.13401246070861816
Test Epoch37 layer3 Acc 0.9026315789473685, AUC 0.9679726362228394, avg_entr 0.00739575969055295
ep37_l3_test_time 0.17068982124328613
Test Epoch37 layer4 Acc 0.9028947368421053, AUC 0.9669634699821472, avg_entr 0.0066206203773617744
ep37_l4_test_time 0.20763039588928223
gc 0
Train Epoch38 Acc 0.9748916666666667 (116987/120000), AUC 0.9968016147613525
ep38_train_time 28.413624048233032
Test Epoch38 layer0 Acc 0.9060526315789473, AUC 0.9769404530525208, avg_entr 0.039689790457487106
ep38_l0_test_time 0.06338810920715332
Test Epoch38 layer1 Acc 0.9052631578947369, AUC 0.9672977328300476, avg_entr 0.013226866722106934
ep38_l1_test_time 0.09829282760620117
Test Epoch38 layer2 Acc 0.9028947368421053, AUC 0.9661511182785034, avg_entr 0.00921509601175785
ep38_l2_test_time 0.13451027870178223
Test Epoch38 layer3 Acc 0.9026315789473685, AUC 0.9681479930877686, avg_entr 0.00738426623865962
ep38_l3_test_time 0.1707768440246582
Test Epoch38 layer4 Acc 0.9028947368421053, AUC 0.9674251079559326, avg_entr 0.006612882949411869
ep38_l4_test_time 0.2075192928314209
gc 0
Train Epoch39 Acc 0.9748583333333334 (116983/120000), AUC 0.9967492818832397
ep39_train_time 28.468897104263306
Test Epoch39 layer0 Acc 0.9063157894736842, AUC 0.9769472479820251, avg_entr 0.039654023945331573
ep39_l0_test_time 0.06281661987304688
Test Epoch39 layer1 Acc 0.9052631578947369, AUC 0.9672916531562805, avg_entr 0.013214417733252048
ep39_l1_test_time 0.09807801246643066
Test Epoch39 layer2 Acc 0.9028947368421053, AUC 0.9660595655441284, avg_entr 0.009212182834744453
ep39_l2_test_time 0.1344130039215088
Test Epoch39 layer3 Acc 0.9028947368421053, AUC 0.9680801630020142, avg_entr 0.007378408685326576
ep39_l3_test_time 0.17135095596313477
Test Epoch39 layer4 Acc 0.9028947368421053, AUC 0.9671551585197449, avg_entr 0.006605149712413549
ep39_l4_test_time 0.20766806602478027
gc 0
Train Epoch40 Acc 0.9748583333333334 (116983/120000), AUC 0.9966598749160767
ep40_train_time 28.685954332351685
Test Epoch40 layer0 Acc 0.9063157894736842, AUC 0.9769458770751953, avg_entr 0.03964858129620552
ep40_l0_test_time 0.0619351863861084
Test Epoch40 layer1 Acc 0.9052631578947369, AUC 0.9673261642456055, avg_entr 0.01319918967783451
ep40_l1_test_time 0.0982961654663086
Test Epoch40 layer2 Acc 0.9028947368421053, AUC 0.9661208987236023, avg_entr 0.009213673882186413
ep40_l2_test_time 0.13453388214111328
Test Epoch40 layer3 Acc 0.9028947368421053, AUC 0.9680184125900269, avg_entr 0.007369990460574627
ep40_l3_test_time 0.17085742950439453
Test Epoch40 layer4 Acc 0.9028947368421053, AUC 0.9672617316246033, avg_entr 0.006606447510421276
ep40_l4_test_time 0.20771360397338867
gc 0
Train Epoch41 Acc 0.9745166666666667 (116942/120000), AUC 0.9967721104621887
ep41_train_time 28.151444911956787
Test Epoch41 layer0 Acc 0.9063157894736842, AUC 0.9769457578659058, avg_entr 0.03961728513240814
ep41_l0_test_time 0.06276917457580566
Test Epoch41 layer1 Acc 0.9052631578947369, AUC 0.9672526717185974, avg_entr 0.013211159035563469
ep41_l1_test_time 0.09834671020507812
Test Epoch41 layer2 Acc 0.9028947368421053, AUC 0.966038703918457, avg_entr 0.009206200949847698
ep41_l2_test_time 0.13471150398254395
Test Epoch41 layer3 Acc 0.9028947368421053, AUC 0.9679831266403198, avg_entr 0.007364870514720678
ep41_l3_test_time 0.17100930213928223
Test Epoch41 layer4 Acc 0.9028947368421053, AUC 0.9671605229377747, avg_entr 0.00660116458311677
ep41_l4_test_time 0.20820021629333496
gc 0
Train Epoch42 Acc 0.9749833333333333 (116998/120000), AUC 0.9968451261520386
ep42_train_time 28.588011026382446
Test Epoch42 layer0 Acc 0.9060526315789473, AUC 0.9769394397735596, avg_entr 0.03963294252753258
ep42_l0_test_time 0.06275701522827148
Test Epoch42 layer1 Acc 0.9052631578947369, AUC 0.967258095741272, avg_entr 0.013211678713560104
ep42_l1_test_time 0.09876346588134766
Test Epoch42 layer2 Acc 0.9028947368421053, AUC 0.9660412073135376, avg_entr 0.00920594297349453
ep42_l2_test_time 0.1345508098602295
Test Epoch42 layer3 Acc 0.9028947368421053, AUC 0.967960000038147, avg_entr 0.007358504459261894
ep42_l3_test_time 0.17106914520263672
Test Epoch42 layer4 Acc 0.9028947368421053, AUC 0.9671412706375122, avg_entr 0.006591050419956446
ep42_l4_test_time 0.20809483528137207
gc 0
Train Epoch43 Acc 0.9749166666666667 (116990/120000), AUC 0.9967724680900574
ep43_train_time 28.396811962127686
Test Epoch43 layer0 Acc 0.9063157894736842, AUC 0.9769397974014282, avg_entr 0.03961341083049774
ep43_l0_test_time 0.06236696243286133
Test Epoch43 layer1 Acc 0.9052631578947369, AUC 0.967266857624054, avg_entr 0.013202528469264507
ep43_l1_test_time 0.09861278533935547
Test Epoch43 layer2 Acc 0.9028947368421053, AUC 0.9660516977310181, avg_entr 0.00920343678444624
ep43_l2_test_time 0.13461852073669434
Test Epoch43 layer3 Acc 0.9028947368421053, AUC 0.9679446220397949, avg_entr 0.007360547780990601
ep43_l3_test_time 0.170914888381958
Test Epoch43 layer4 Acc 0.9028947368421053, AUC 0.9671730399131775, avg_entr 0.006596062798053026
ep43_l4_test_time 0.2081298828125
gc 0
Train Epoch44 Acc 0.9750583333333334 (117007/120000), AUC 0.9967605471611023
ep44_train_time 28.505104303359985
Test Epoch44 layer0 Acc 0.9063157894736842, AUC 0.9769439697265625, avg_entr 0.039598871022462845
ep44_l0_test_time 0.062476396560668945
Test Epoch44 layer1 Acc 0.9052631578947369, AUC 0.967259407043457, avg_entr 0.013199514709413052
ep44_l1_test_time 0.09786844253540039
Test Epoch44 layer2 Acc 0.9028947368421053, AUC 0.9660929441452026, avg_entr 0.009201277047395706
ep44_l2_test_time 0.13435029983520508
Test Epoch44 layer3 Acc 0.9028947368421053, AUC 0.9679788947105408, avg_entr 0.007336840964853764
ep44_l3_test_time 0.17107224464416504
Test Epoch44 layer4 Acc 0.9028947368421053, AUC 0.9671489000320435, avg_entr 0.006581076420843601
ep44_l4_test_time 0.2077317237854004
gc 0
Train Epoch45 Acc 0.9745833333333334 (116950/120000), AUC 0.9967695474624634
ep45_train_time 28.185436248779297
Test Epoch45 layer0 Acc 0.9063157894736842, AUC 0.976942777633667, avg_entr 0.03959450498223305
ep45_l0_test_time 0.062476158142089844
Test Epoch45 layer1 Acc 0.9052631578947369, AUC 0.9672497510910034, avg_entr 0.01318515557795763
ep45_l1_test_time 0.09815597534179688
Test Epoch45 layer2 Acc 0.9028947368421053, AUC 0.9660183787345886, avg_entr 0.009194486774504185
ep45_l2_test_time 0.13422489166259766
Test Epoch45 layer3 Acc 0.9028947368421053, AUC 0.967868983745575, avg_entr 0.007339925970882177
ep45_l3_test_time 0.17123007774353027
Test Epoch45 layer4 Acc 0.9028947368421053, AUC 0.9670454859733582, avg_entr 0.006578515749424696
ep45_l4_test_time 0.20767784118652344
gc 0
Train Epoch46 Acc 0.9747833333333333 (116974/120000), AUC 0.9967952966690063
ep46_train_time 28.351516246795654
Test Epoch46 layer0 Acc 0.9063157894736842, AUC 0.9769400358200073, avg_entr 0.03959180414676666
ep46_l0_test_time 0.06186842918395996
Test Epoch46 layer1 Acc 0.9052631578947369, AUC 0.9672365784645081, avg_entr 0.013183055445551872
ep46_l1_test_time 0.09749197959899902
Test Epoch46 layer2 Acc 0.9028947368421053, AUC 0.966011106967926, avg_entr 0.009195225313305855
ep46_l2_test_time 0.13405752182006836
Test Epoch46 layer3 Acc 0.9028947368421053, AUC 0.9678472280502319, avg_entr 0.0073422640562057495
ep46_l3_test_time 0.17125844955444336
Test Epoch46 layer4 Acc 0.9028947368421053, AUC 0.9670959115028381, avg_entr 0.0065798829309642315
ep46_l4_test_time 0.20799541473388672
gc 0
Train Epoch47 Acc 0.9751 (117012/120000), AUC 0.9968267679214478
ep47_train_time 28.233981609344482
Test Epoch47 layer0 Acc 0.9063157894736842, AUC 0.9769411087036133, avg_entr 0.03958917036652565
ep47_l0_test_time 0.06231236457824707
Test Epoch47 layer1 Acc 0.9052631578947369, AUC 0.9672489762306213, avg_entr 0.013182206079363823
ep47_l1_test_time 0.09840869903564453
Test Epoch47 layer2 Acc 0.9028947368421053, AUC 0.9660558700561523, avg_entr 0.00919617060571909
ep47_l2_test_time 0.13442468643188477
Test Epoch47 layer3 Acc 0.9028947368421053, AUC 0.9678775072097778, avg_entr 0.007337371353060007
ep47_l3_test_time 0.17160296440124512
Test Epoch47 layer4 Acc 0.9028947368421053, AUC 0.9671103954315186, avg_entr 0.0065780021250247955
ep47_l4_test_time 0.2081749439239502
gc 0
Train Epoch48 Acc 0.9750333333333333 (117004/120000), AUC 0.9967671632766724
ep48_train_time 28.278618097305298
Test Epoch48 layer0 Acc 0.9063157894736842, AUC 0.9769405126571655, avg_entr 0.039588626474142075
ep48_l0_test_time 0.06346440315246582
Test Epoch48 layer1 Acc 0.9052631578947369, AUC 0.9672537446022034, avg_entr 0.013183546252548695
ep48_l1_test_time 0.09925580024719238
Test Epoch48 layer2 Acc 0.9028947368421053, AUC 0.9660566449165344, avg_entr 0.00919379387050867
ep48_l2_test_time 0.1357574462890625
Test Epoch48 layer3 Acc 0.9028947368421053, AUC 0.9678924679756165, avg_entr 0.00734349898993969
ep48_l3_test_time 0.17167019844055176
Test Epoch48 layer4 Acc 0.9028947368421053, AUC 0.9671013355255127, avg_entr 0.006578048225492239
ep48_l4_test_time 0.20863580703735352
gc 0
Train Epoch49 Acc 0.9751666666666666 (117020/120000), AUC 0.9968039393424988
ep49_train_time 28.363078355789185
Test Epoch49 layer0 Acc 0.9063157894736842, AUC 0.9769408702850342, avg_entr 0.039583656936883926
ep49_l0_test_time 0.0629429817199707
Test Epoch49 layer1 Acc 0.9052631578947369, AUC 0.967255711555481, avg_entr 0.013181965798139572
ep49_l1_test_time 0.0983419418334961
Test Epoch49 layer2 Acc 0.9028947368421053, AUC 0.9660530090332031, avg_entr 0.009194460697472095
ep49_l2_test_time 0.13447332382202148
Test Epoch49 layer3 Acc 0.9028947368421053, AUC 0.9679071307182312, avg_entr 0.00734170014038682
ep49_l3_test_time 0.17125225067138672
Test Epoch49 layer4 Acc 0.9028947368421053, AUC 0.9671095609664917, avg_entr 0.006578450556844473
ep49_l4_test_time 0.20784306526184082
Best AUC 0.9790617823600769
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train+valid_time 1455.760377407074
Start Testing
Load ckpt at ckpt/ag_news_transformeral_l5_pad50//ag_news_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.9231578947368421, AUC 0.9844637513160706, avg_entr 0.0814843624830246
ep49_l0_test_time 0.06080269813537598
Test Epoch49 layer1 Acc 0.9231578947368421, AUC 0.9833468198776245, avg_entr 0.030399996787309647
ep49_l1_test_time 0.09864592552185059
Test Epoch49 layer2 Acc 0.921578947368421, AUC 0.985190212726593, avg_entr 0.02499682828783989
ep49_l2_test_time 0.1355884075164795
Test Epoch49 layer3 Acc 0.9207894736842105, AUC 0.9856829643249512, avg_entr 0.02280580811202526
ep49_l3_test_time 0.172288179397583
Test Epoch49 layer4 Acc 0.921578947368421, AUC 0.9854263067245483, avg_entr 0.021601377055048943
ep49_l4_test_time 0.208876371383667
