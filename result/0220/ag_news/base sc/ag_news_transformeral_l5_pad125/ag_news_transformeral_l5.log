total count words 102019
vocab size 30000
found 26754 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13672292
init_time 19.69406008720398
Start Training
gc 0
Train Epoch0 Acc 0.6436333333333333 (77236/120000), AUC 0.86139976978302
ep0_train_time 57.26453876495361
Test Epoch0 layer0 Acc 0.8910526315789473, AUC 0.9731689691543579, avg_entr 0.2526443898677826
ep0_l0_test_time 0.12205362319946289
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9005263157894737, AUC 0.9756156206130981, avg_entr 0.17201915383338928
ep0_l1_test_time 0.20769357681274414
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.9002631578947369, AUC 0.9759170413017273, avg_entr 0.16791491210460663
ep0_l2_test_time 0.2971656322479248
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer3 Acc 0.8978947368421053, AUC 0.9761722087860107, avg_entr 0.17036820948123932
ep0_l3_test_time 0.3815009593963623
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer4 Acc 0.8973684210526316, AUC 0.9762494564056396, avg_entr 0.16813941299915314
ep0_l4_test_time 0.4647219181060791
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.921975 (110637/120000), AUC 0.9817638397216797
ep1_train_time 57.02792692184448
Test Epoch1 layer0 Acc 0.9076315789473685, AUC 0.9767503142356873, avg_entr 0.14953221380710602
ep1_l0_test_time 0.11975526809692383
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.911578947368421, AUC 0.9799169301986694, avg_entr 0.08924733102321625
ep1_l1_test_time 0.20869684219360352
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.9126315789473685, AUC 0.9796680212020874, avg_entr 0.07760300487279892
ep1_l2_test_time 0.2974576950073242
Test Epoch1 layer3 Acc 0.9105263157894737, AUC 0.9798239469528198, avg_entr 0.07434946298599243
ep1_l3_test_time 0.37850141525268555
Test Epoch1 layer4 Acc 0.9084210526315789, AUC 0.979943037033081, avg_entr 0.07531239837408066
ep1_l4_test_time 0.4608573913574219
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.9364 (112368/120000), AUC 0.9870621562004089
ep2_train_time 56.948182582855225
Test Epoch2 layer0 Acc 0.9097368421052632, AUC 0.9779632091522217, avg_entr 0.1098371222615242
ep2_l0_test_time 0.12278389930725098
Test Epoch2 layer1 Acc 0.9144736842105263, AUC 0.9799754023551941, avg_entr 0.04689566791057587
ep2_l1_test_time 0.2063748836517334
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 2
Test Epoch2 layer2 Acc 0.9142105263157895, AUC 0.9799318313598633, avg_entr 0.04110466688871384
ep2_l2_test_time 0.29608774185180664
Test Epoch2 layer3 Acc 0.9139473684210526, AUC 0.9799734950065613, avg_entr 0.037545345723629
ep2_l3_test_time 0.37743639945983887
Test Epoch2 layer4 Acc 0.9131578947368421, AUC 0.9799222350120544, avg_entr 0.03517962992191315
ep2_l4_test_time 0.4612419605255127
gc 0
Train Epoch3 Acc 0.9442916666666666 (113315/120000), AUC 0.9895676970481873
ep3_train_time 56.829243659973145
Test Epoch3 layer0 Acc 0.9102631578947369, AUC 0.9785977602005005, avg_entr 0.09309708327054977
ep3_l0_test_time 0.11930680274963379
Test Epoch3 layer1 Acc 0.9139473684210526, AUC 0.9798036813735962, avg_entr 0.03526834771037102
ep3_l1_test_time 0.2053077220916748
Test Epoch3 layer2 Acc 0.9134210526315789, AUC 0.9808801412582397, avg_entr 0.029539622366428375
ep3_l2_test_time 0.29415369033813477
Save ckpt to ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt  ,ep 3
Test Epoch3 layer3 Acc 0.9131578947368421, AUC 0.980030357837677, avg_entr 0.026601027697324753
ep3_l3_test_time 0.3800835609436035
Test Epoch3 layer4 Acc 0.9134210526315789, AUC 0.9806270599365234, avg_entr 0.025356676429510117
ep3_l4_test_time 0.46161913871765137
gc 0
Train Epoch4 Acc 0.9499083333333334 (113989/120000), AUC 0.9907488822937012
ep4_train_time 56.8294358253479
Test Epoch4 layer0 Acc 0.9094736842105263, AUC 0.9784915447235107, avg_entr 0.08324182778596878
ep4_l0_test_time 0.11947751045227051
Test Epoch4 layer1 Acc 0.9134210526315789, AUC 0.9777411222457886, avg_entr 0.029778189957141876
ep4_l1_test_time 0.2072906494140625
Test Epoch4 layer2 Acc 0.9134210526315789, AUC 0.9796832799911499, avg_entr 0.0242817010730505
ep4_l2_test_time 0.2956078052520752
Test Epoch4 layer3 Acc 0.9128947368421053, AUC 0.9802984595298767, avg_entr 0.022197455167770386
ep4_l3_test_time 0.37837719917297363
Test Epoch4 layer4 Acc 0.9126315789473685, AUC 0.9801191091537476, avg_entr 0.020571203902363777
ep4_l4_test_time 0.4631922245025635
gc 0
Train Epoch5 Acc 0.9537333333333333 (114448/120000), AUC 0.9918732047080994
ep5_train_time 56.76958441734314
Test Epoch5 layer0 Acc 0.9105263157894737, AUC 0.9787331819534302, avg_entr 0.0745796412229538
ep5_l0_test_time 0.12106013298034668
Test Epoch5 layer1 Acc 0.9102631578947369, AUC 0.9780006408691406, avg_entr 0.02795327641069889
ep5_l1_test_time 0.20684599876403809
Test Epoch5 layer2 Acc 0.9094736842105263, AUC 0.978712797164917, avg_entr 0.022059964016079903
ep5_l2_test_time 0.2948338985443115
Test Epoch5 layer3 Acc 0.9094736842105263, AUC 0.9788219332695007, avg_entr 0.020492887124419212
ep5_l3_test_time 0.3779456615447998
Test Epoch5 layer4 Acc 0.9102631578947369, AUC 0.9793546199798584, avg_entr 0.018949685618281364
ep5_l4_test_time 0.4631044864654541
gc 0
Train Epoch6 Acc 0.9572666666666667 (114872/120000), AUC 0.9927107691764832
ep6_train_time 56.74306535720825
Test Epoch6 layer0 Acc 0.9110526315789473, AUC 0.978483259677887, avg_entr 0.06959331035614014
ep6_l0_test_time 0.12083101272583008
Test Epoch6 layer1 Acc 0.9097368421052632, AUC 0.9777770042419434, avg_entr 0.025311587378382683
ep6_l1_test_time 0.2063279151916504
Test Epoch6 layer2 Acc 0.9092105263157895, AUC 0.978381335735321, avg_entr 0.019867025315761566
ep6_l2_test_time 0.29539918899536133
Test Epoch6 layer3 Acc 0.9089473684210526, AUC 0.9783490300178528, avg_entr 0.018006008118391037
ep6_l3_test_time 0.3795003890991211
Test Epoch6 layer4 Acc 0.9094736842105263, AUC 0.9792444705963135, avg_entr 0.01641755737364292
ep6_l4_test_time 0.4640960693359375
gc 0
Train Epoch7 Acc 0.9592333333333334 (115108/120000), AUC 0.9934604167938232
ep7_train_time 56.82771039009094
Test Epoch7 layer0 Acc 0.9118421052631579, AUC 0.978575587272644, avg_entr 0.06544716656208038
ep7_l0_test_time 0.1203453540802002
Test Epoch7 layer1 Acc 0.9084210526315789, AUC 0.9753596782684326, avg_entr 0.023800387978553772
ep7_l1_test_time 0.20708751678466797
Test Epoch7 layer2 Acc 0.9073684210526316, AUC 0.9768966436386108, avg_entr 0.01757778786122799
ep7_l2_test_time 0.29628920555114746
Test Epoch7 layer3 Acc 0.9078947368421053, AUC 0.9767714738845825, avg_entr 0.015438934788107872
ep7_l3_test_time 0.3791999816894531
Test Epoch7 layer4 Acc 0.908157894736842, AUC 0.9771527051925659, avg_entr 0.013950499705970287
ep7_l4_test_time 0.4631788730621338
gc 0
Train Epoch8 Acc 0.9610833333333333 (115330/120000), AUC 0.9940668344497681
ep8_train_time 56.79294300079346
Test Epoch8 layer0 Acc 0.91, AUC 0.9784482717514038, avg_entr 0.06037814915180206
ep8_l0_test_time 0.12327742576599121
Test Epoch8 layer1 Acc 0.9097368421052632, AUC 0.9740276336669922, avg_entr 0.020569125190377235
ep8_l1_test_time 0.20803523063659668
Test Epoch8 layer2 Acc 0.9094736842105263, AUC 0.9738659858703613, avg_entr 0.014664430171251297
ep8_l2_test_time 0.29616427421569824
Test Epoch8 layer3 Acc 0.91, AUC 0.9729009866714478, avg_entr 0.01326873991638422
ep8_l3_test_time 0.3793039321899414
Test Epoch8 layer4 Acc 0.9089473684210526, AUC 0.9738264679908752, avg_entr 0.011878423392772675
ep8_l4_test_time 0.4635441303253174
gc 0
Train Epoch9 Acc 0.9625333333333334 (115504/120000), AUC 0.9941562414169312
ep9_train_time 56.85581660270691
Test Epoch9 layer0 Acc 0.9107894736842105, AUC 0.9782896637916565, avg_entr 0.05763066187500954
ep9_l0_test_time 0.11941337585449219
Test Epoch9 layer1 Acc 0.9076315789473685, AUC 0.9746907949447632, avg_entr 0.020402800291776657
ep9_l1_test_time 0.20604181289672852
Test Epoch9 layer2 Acc 0.9073684210526316, AUC 0.9756780862808228, avg_entr 0.015238826163113117
ep9_l2_test_time 0.29454612731933594
Test Epoch9 layer3 Acc 0.9078947368421053, AUC 0.9760470986366272, avg_entr 0.013969438150525093
ep9_l3_test_time 0.3776860237121582
Test Epoch9 layer4 Acc 0.9073684210526316, AUC 0.976587176322937, avg_entr 0.012611888349056244
ep9_l4_test_time 0.4627072811126709
gc 0
Train Epoch10 Acc 0.9651583333333333 (115819/120000), AUC 0.9950422048568726
ep10_train_time 56.76882719993591
Test Epoch10 layer0 Acc 0.9094736842105263, AUC 0.9780694842338562, avg_entr 0.055016789585351944
ep10_l0_test_time 0.11955904960632324
Test Epoch10 layer1 Acc 0.9084210526315789, AUC 0.9739843010902405, avg_entr 0.019383644685149193
ep10_l1_test_time 0.2062692642211914
Test Epoch10 layer2 Acc 0.9084210526315789, AUC 0.9753249287605286, avg_entr 0.014479746110737324
ep10_l2_test_time 0.2948474884033203
Test Epoch10 layer3 Acc 0.9086842105263158, AUC 0.9758758544921875, avg_entr 0.012910837307572365
ep10_l3_test_time 0.37757158279418945
Test Epoch10 layer4 Acc 0.9092105263157895, AUC 0.9765890836715698, avg_entr 0.011458202265202999
ep10_l4_test_time 0.46191906929016113
gc 0
Train Epoch11 Acc 0.96655 (115986/120000), AUC 0.995231032371521
ep11_train_time 56.839086294174194
Test Epoch11 layer0 Acc 0.91, AUC 0.9780089855194092, avg_entr 0.05417470261454582
ep11_l0_test_time 0.11889171600341797
Test Epoch11 layer1 Acc 0.9097368421052632, AUC 0.9735082387924194, avg_entr 0.018716411665081978
ep11_l1_test_time 0.20586872100830078
Test Epoch11 layer2 Acc 0.9076315789473685, AUC 0.9735991358757019, avg_entr 0.013581588864326477
ep11_l2_test_time 0.2940638065338135
Test Epoch11 layer3 Acc 0.9084210526315789, AUC 0.9750867486000061, avg_entr 0.012161169201135635
ep11_l3_test_time 0.37798166275024414
Test Epoch11 layer4 Acc 0.9078947368421053, AUC 0.9751197695732117, avg_entr 0.01057785376906395
ep11_l4_test_time 0.4619309902191162
gc 0
Train Epoch12 Acc 0.9667333333333333 (116008/120000), AUC 0.9954341650009155
ep12_train_time 56.868080615997314
Test Epoch12 layer0 Acc 0.9084210526315789, AUC 0.9777020215988159, avg_entr 0.051751479506492615
ep12_l0_test_time 0.12213492393493652
Test Epoch12 layer1 Acc 0.9071052631578947, AUC 0.9739161729812622, avg_entr 0.018248064443469048
ep12_l1_test_time 0.20704913139343262
Test Epoch12 layer2 Acc 0.9073684210526316, AUC 0.9740282893180847, avg_entr 0.012858863919973373
ep12_l2_test_time 0.29431867599487305
Test Epoch12 layer3 Acc 0.906578947368421, AUC 0.9753202199935913, avg_entr 0.011683487333357334
ep12_l3_test_time 0.37803077697753906
Test Epoch12 layer4 Acc 0.9071052631578947, AUC 0.9750108122825623, avg_entr 0.010151736438274384
ep12_l4_test_time 0.46163463592529297
gc 0
Train Epoch13 Acc 0.9675583333333333 (116107/120000), AUC 0.9956344366073608
ep13_train_time 56.869101762771606
Test Epoch13 layer0 Acc 0.9086842105263158, AUC 0.9777048826217651, avg_entr 0.05039387196302414
ep13_l0_test_time 0.11970233917236328
Test Epoch13 layer1 Acc 0.9073684210526316, AUC 0.9734097719192505, avg_entr 0.018600916489958763
ep13_l1_test_time 0.20672345161437988
Test Epoch13 layer2 Acc 0.9068421052631579, AUC 0.9744069576263428, avg_entr 0.013811254873871803
ep13_l2_test_time 0.2946922779083252
Test Epoch13 layer3 Acc 0.9071052631578947, AUC 0.9752428531646729, avg_entr 0.012609160505235195
ep13_l3_test_time 0.37749576568603516
Test Epoch13 layer4 Acc 0.906578947368421, AUC 0.9747673869132996, avg_entr 0.010855695232748985
ep13_l4_test_time 0.46236610412597656
gc 0
Train Epoch14 Acc 0.9690666666666666 (116288/120000), AUC 0.9960466623306274
ep14_train_time 56.8233859539032
Test Epoch14 layer0 Acc 0.9076315789473685, AUC 0.9776946306228638, avg_entr 0.04864434152841568
ep14_l0_test_time 0.11985397338867188
Test Epoch14 layer1 Acc 0.9063157894736842, AUC 0.972150981426239, avg_entr 0.018596723675727844
ep14_l1_test_time 0.20627713203430176
Test Epoch14 layer2 Acc 0.9078947368421053, AUC 0.9723529815673828, avg_entr 0.013831998221576214
ep14_l2_test_time 0.29464125633239746
Test Epoch14 layer3 Acc 0.908157894736842, AUC 0.9731154441833496, avg_entr 0.012570121325552464
ep14_l3_test_time 0.3774876594543457
Test Epoch14 layer4 Acc 0.908157894736842, AUC 0.9729474186897278, avg_entr 0.01093740202486515
ep14_l4_test_time 0.4624495506286621
gc 0
Train Epoch15 Acc 0.9694916666666666 (116339/120000), AUC 0.995903730392456
ep15_train_time 56.91222047805786
Test Epoch15 layer0 Acc 0.9086842105263158, AUC 0.9776714444160461, avg_entr 0.04749508574604988
ep15_l0_test_time 0.11951899528503418
Test Epoch15 layer1 Acc 0.9063157894736842, AUC 0.9723832607269287, avg_entr 0.0182882621884346
ep15_l1_test_time 0.20564842224121094
Test Epoch15 layer2 Acc 0.9068421052631579, AUC 0.9730310440063477, avg_entr 0.013743027113378048
ep15_l2_test_time 0.2940835952758789
Test Epoch15 layer3 Acc 0.9063157894736842, AUC 0.9740486145019531, avg_entr 0.012227705679833889
ep15_l3_test_time 0.377216100692749
Test Epoch15 layer4 Acc 0.9068421052631579, AUC 0.9730603694915771, avg_entr 0.010625327005982399
ep15_l4_test_time 0.4646129608154297
gc 0
Train Epoch16 Acc 0.96985 (116382/120000), AUC 0.9961150884628296
ep16_train_time 56.89282703399658
Test Epoch16 layer0 Acc 0.9092105263157895, AUC 0.9775428771972656, avg_entr 0.047235164791345596
ep16_l0_test_time 0.11948823928833008
Test Epoch16 layer1 Acc 0.906578947368421, AUC 0.9717334508895874, avg_entr 0.016541054472327232
ep16_l1_test_time 0.20731067657470703
Test Epoch16 layer2 Acc 0.9060526315789473, AUC 0.9710764288902283, avg_entr 0.011535007506608963
ep16_l2_test_time 0.29465413093566895
Test Epoch16 layer3 Acc 0.906578947368421, AUC 0.9723299741744995, avg_entr 0.01005940418690443
ep16_l3_test_time 0.3788449764251709
Test Epoch16 layer4 Acc 0.9057894736842105, AUC 0.9714822173118591, avg_entr 0.008538380265235901
ep16_l4_test_time 0.461700439453125
gc 0
Train Epoch17 Acc 0.970275 (116433/120000), AUC 0.9962338209152222
ep17_train_time 56.86720514297485
Test Epoch17 layer0 Acc 0.9084210526315789, AUC 0.9775835275650024, avg_entr 0.04421297460794449
ep17_l0_test_time 0.11962771415710449
Test Epoch17 layer1 Acc 0.9060526315789473, AUC 0.9726098775863647, avg_entr 0.016590822488069534
ep17_l1_test_time 0.20658254623413086
Test Epoch17 layer2 Acc 0.9078947368421053, AUC 0.9719943404197693, avg_entr 0.012158197350800037
ep17_l2_test_time 0.29489612579345703
Test Epoch17 layer3 Acc 0.9073684210526316, AUC 0.9737257957458496, avg_entr 0.010905012488365173
ep17_l3_test_time 0.3780074119567871
Test Epoch17 layer4 Acc 0.9078947368421053, AUC 0.9721179008483887, avg_entr 0.009508968330919743
ep17_l4_test_time 0.46261048316955566
gc 0
Train Epoch18 Acc 0.971075 (116529/120000), AUC 0.9963696599006653
ep18_train_time 56.774880170822144
Test Epoch18 layer0 Acc 0.9076315789473685, AUC 0.977566123008728, avg_entr 0.043661899864673615
ep18_l0_test_time 0.11959457397460938
Test Epoch18 layer1 Acc 0.906578947368421, AUC 0.9719383120536804, avg_entr 0.016038957983255386
ep18_l1_test_time 0.2058391571044922
Test Epoch18 layer2 Acc 0.9063157894736842, AUC 0.9715059995651245, avg_entr 0.011649159714579582
ep18_l2_test_time 0.2943236827850342
Test Epoch18 layer3 Acc 0.9060526315789473, AUC 0.9721822738647461, avg_entr 0.010312564671039581
ep18_l3_test_time 0.3788015842437744
Test Epoch18 layer4 Acc 0.9057894736842105, AUC 0.9710506796836853, avg_entr 0.008829167112708092
ep18_l4_test_time 0.4618821144104004
gc 0
Train Epoch19 Acc 0.9712833333333334 (116554/120000), AUC 0.9962899684906006
ep19_train_time 56.932414531707764
Test Epoch19 layer0 Acc 0.9094736842105263, AUC 0.9775688648223877, avg_entr 0.042427562177181244
ep19_l0_test_time 0.12011075019836426
Test Epoch19 layer1 Acc 0.906578947368421, AUC 0.9720945358276367, avg_entr 0.015686774626374245
ep19_l1_test_time 0.20771241188049316
Test Epoch19 layer2 Acc 0.9068421052631579, AUC 0.9720849990844727, avg_entr 0.011507328599691391
ep19_l2_test_time 0.2952711582183838
Test Epoch19 layer3 Acc 0.9063157894736842, AUC 0.9716886878013611, avg_entr 0.010394684970378876
ep19_l3_test_time 0.3778536319732666
Test Epoch19 layer4 Acc 0.9068421052631579, AUC 0.970540463924408, avg_entr 0.008808023296296597
ep19_l4_test_time 0.4611225128173828
gc 0
Train Epoch20 Acc 0.9716083333333333 (116593/120000), AUC 0.9962959289550781
ep20_train_time 56.897544860839844
Test Epoch20 layer0 Acc 0.906578947368421, AUC 0.9775283336639404, avg_entr 0.04148562252521515
ep20_l0_test_time 0.11892986297607422
Test Epoch20 layer1 Acc 0.9052631578947369, AUC 0.9719356298446655, avg_entr 0.015341304242610931
ep20_l1_test_time 0.2054426670074463
Test Epoch20 layer2 Acc 0.9063157894736842, AUC 0.9716663360595703, avg_entr 0.011288754642009735
ep20_l2_test_time 0.2943556308746338
Test Epoch20 layer3 Acc 0.9068421052631579, AUC 0.971839189529419, avg_entr 0.01033818069845438
ep20_l3_test_time 0.37711071968078613
Test Epoch20 layer4 Acc 0.906578947368421, AUC 0.9707704186439514, avg_entr 0.008895005099475384
ep20_l4_test_time 0.4612612724304199
gc 0
Train Epoch21 Acc 0.9717083333333333 (116605/120000), AUC 0.9962893724441528
ep21_train_time 56.965044021606445
Test Epoch21 layer0 Acc 0.9057894736842105, AUC 0.9774600267410278, avg_entr 0.04098692908883095
ep21_l0_test_time 0.1190328598022461
Test Epoch21 layer1 Acc 0.9068421052631579, AUC 0.9719550013542175, avg_entr 0.015546910464763641
ep21_l1_test_time 0.20552587509155273
Test Epoch21 layer2 Acc 0.9060526315789473, AUC 0.9714820384979248, avg_entr 0.011387084610760212
ep21_l2_test_time 0.29399847984313965
Test Epoch21 layer3 Acc 0.9057894736842105, AUC 0.971084713935852, avg_entr 0.010166037827730179
ep21_l3_test_time 0.37692856788635254
Test Epoch21 layer4 Acc 0.9063157894736842, AUC 0.9703493118286133, avg_entr 0.009244365617632866
ep21_l4_test_time 0.46167469024658203
gc 0
Train Epoch22 Acc 0.9722166666666666 (116666/120000), AUC 0.9965099692344666
ep22_train_time 56.91987347602844
Test Epoch22 layer0 Acc 0.9078947368421053, AUC 0.9774819612503052, avg_entr 0.04015533626079559
ep22_l0_test_time 0.1200566291809082
Test Epoch22 layer1 Acc 0.906578947368421, AUC 0.971383810043335, avg_entr 0.014838815666735172
ep22_l1_test_time 0.206376314163208
Test Epoch22 layer2 Acc 0.906578947368421, AUC 0.9708894491195679, avg_entr 0.010873987339437008
ep22_l2_test_time 0.2945570945739746
Test Epoch22 layer3 Acc 0.9060526315789473, AUC 0.9704444408416748, avg_entr 0.009861502796411514
ep22_l3_test_time 0.37722277641296387
Test Epoch22 layer4 Acc 0.9055263157894737, AUC 0.9695900082588196, avg_entr 0.00848360825330019
ep22_l4_test_time 0.4612445831298828
gc 0
Train Epoch23 Acc 0.9719166666666667 (116630/120000), AUC 0.9964238405227661
ep23_train_time 56.90230417251587
Test Epoch23 layer0 Acc 0.906578947368421, AUC 0.9775035381317139, avg_entr 0.03991001471877098
ep23_l0_test_time 0.12021946907043457
Test Epoch23 layer1 Acc 0.9071052631578947, AUC 0.9714661836624146, avg_entr 0.015024575404822826
ep23_l1_test_time 0.2069077491760254
Test Epoch23 layer2 Acc 0.9057894736842105, AUC 0.9711432456970215, avg_entr 0.011098128743469715
ep23_l2_test_time 0.29583144187927246
Test Epoch23 layer3 Acc 0.9057894736842105, AUC 0.9701288938522339, avg_entr 0.010099646635353565
ep23_l3_test_time 0.37921905517578125
Test Epoch23 layer4 Acc 0.9060526315789473, AUC 0.9691148996353149, avg_entr 0.009027818217873573
ep23_l4_test_time 0.46218299865722656
gc 0
Train Epoch24 Acc 0.9721333333333333 (116656/120000), AUC 0.9965891242027283
ep24_train_time 56.89274835586548
Test Epoch24 layer0 Acc 0.9071052631578947, AUC 0.9774487614631653, avg_entr 0.03962042182683945
ep24_l0_test_time 0.11988306045532227
Test Epoch24 layer1 Acc 0.906578947368421, AUC 0.971480131149292, avg_entr 0.01449138019233942
ep24_l1_test_time 0.20602035522460938
Test Epoch24 layer2 Acc 0.906578947368421, AUC 0.9708573222160339, avg_entr 0.010711440816521645
ep24_l2_test_time 0.29431724548339844
Test Epoch24 layer3 Acc 0.906578947368421, AUC 0.970125675201416, avg_entr 0.009701225906610489
ep24_l3_test_time 0.37740612030029297
Test Epoch24 layer4 Acc 0.906578947368421, AUC 0.9694849252700806, avg_entr 0.00839016493409872
ep24_l4_test_time 0.4622488021850586
gc 0
Train Epoch25 Acc 0.9722083333333333 (116665/120000), AUC 0.9965159296989441
ep25_train_time 56.944140911102295
Test Epoch25 layer0 Acc 0.9071052631578947, AUC 0.9774526357650757, avg_entr 0.039079371839761734
ep25_l0_test_time 0.1200413703918457
Test Epoch25 layer1 Acc 0.9057894736842105, AUC 0.9714176654815674, avg_entr 0.014647649601101875
ep25_l1_test_time 0.20643091201782227
Test Epoch25 layer2 Acc 0.905, AUC 0.9707773923873901, avg_entr 0.010738210752606392
ep25_l2_test_time 0.2943704128265381
Test Epoch25 layer3 Acc 0.905, AUC 0.9701634645462036, avg_entr 0.00980603601783514
ep25_l3_test_time 0.3777916431427002
Test Epoch25 layer4 Acc 0.9052631578947369, AUC 0.9692137837409973, avg_entr 0.008430493995547295
ep25_l4_test_time 0.4619321823120117
gc 0
Train Epoch26 Acc 0.97275 (116730/120000), AUC 0.9966412782669067
ep26_train_time 56.88731861114502
Test Epoch26 layer0 Acc 0.908157894736842, AUC 0.977462887763977, avg_entr 0.03892688453197479
ep26_l0_test_time 0.1185600757598877
Test Epoch26 layer1 Acc 0.9063157894736842, AUC 0.9714398384094238, avg_entr 0.014465820044279099
ep26_l1_test_time 0.206162691116333
Test Epoch26 layer2 Acc 0.9060526315789473, AUC 0.970874547958374, avg_entr 0.01066551636904478
ep26_l2_test_time 0.29442501068115234
Test Epoch26 layer3 Acc 0.9047368421052632, AUC 0.9701489210128784, avg_entr 0.009581717662513256
ep26_l3_test_time 0.3771944046020508
Test Epoch26 layer4 Acc 0.9057894736842105, AUC 0.9695812463760376, avg_entr 0.008074399083852768
ep26_l4_test_time 0.4609034061431885
gc 0
Train Epoch27 Acc 0.9723583333333333 (116683/120000), AUC 0.9966011047363281
ep27_train_time 56.86568212509155
Test Epoch27 layer0 Acc 0.9078947368421053, AUC 0.9774448275566101, avg_entr 0.03878730908036232
ep27_l0_test_time 0.1191415786743164
Test Epoch27 layer1 Acc 0.906578947368421, AUC 0.9714566469192505, avg_entr 0.014430463314056396
ep27_l1_test_time 0.20664691925048828
Test Epoch27 layer2 Acc 0.9057894736842105, AUC 0.9716330766677856, avg_entr 0.010641226544976234
ep27_l2_test_time 0.29477953910827637
Test Epoch27 layer3 Acc 0.9055263157894737, AUC 0.9703996777534485, avg_entr 0.009638182818889618
ep27_l3_test_time 0.37949252128601074
Test Epoch27 layer4 Acc 0.9057894736842105, AUC 0.9693252444267273, avg_entr 0.008263313211500645
ep27_l4_test_time 0.46256136894226074
gc 0
Train Epoch28 Acc 0.9725666666666667 (116708/120000), AUC 0.9967043995857239
ep28_train_time 56.97095966339111
Test Epoch28 layer0 Acc 0.9068421052631579, AUC 0.977458119392395, avg_entr 0.038447119295597076
ep28_l0_test_time 0.11869478225708008
Test Epoch28 layer1 Acc 0.9071052631578947, AUC 0.971662163734436, avg_entr 0.01449876744300127
ep28_l1_test_time 0.20634031295776367
Test Epoch28 layer2 Acc 0.9063157894736842, AUC 0.9717402458190918, avg_entr 0.010687599889934063
ep28_l2_test_time 0.2950558662414551
Test Epoch28 layer3 Acc 0.9057894736842105, AUC 0.9708945155143738, avg_entr 0.009579785168170929
ep28_l3_test_time 0.37874460220336914
Test Epoch28 layer4 Acc 0.9063157894736842, AUC 0.9696096181869507, avg_entr 0.008497812785208225
ep28_l4_test_time 0.46106719970703125
gc 0
Train Epoch29 Acc 0.9725916666666666 (116711/120000), AUC 0.9966069459915161
ep29_train_time 56.926368951797485
Test Epoch29 layer0 Acc 0.906578947368421, AUC 0.9774458408355713, avg_entr 0.038311220705509186
ep29_l0_test_time 0.11888933181762695
Test Epoch29 layer1 Acc 0.9068421052631579, AUC 0.9714583158493042, avg_entr 0.01442410983145237
ep29_l1_test_time 0.20657062530517578
Test Epoch29 layer2 Acc 0.9052631578947369, AUC 0.9707892537117004, avg_entr 0.010679337196052074
ep29_l2_test_time 0.2947118282318115
Test Epoch29 layer3 Acc 0.9057894736842105, AUC 0.9697611927986145, avg_entr 0.009693359956145287
ep29_l3_test_time 0.37787961959838867
Test Epoch29 layer4 Acc 0.9052631578947369, AUC 0.9688068628311157, avg_entr 0.008528070524334908
ep29_l4_test_time 0.46247267723083496
gc 0
Train Epoch30 Acc 0.9729083333333334 (116749/120000), AUC 0.9967219829559326
ep30_train_time 56.93364477157593
Test Epoch30 layer0 Acc 0.9073684210526316, AUC 0.9774287939071655, avg_entr 0.03836136683821678
ep30_l0_test_time 0.11986780166625977
Test Epoch30 layer1 Acc 0.906578947368421, AUC 0.9714565277099609, avg_entr 0.014507206156849861
ep30_l1_test_time 0.20625519752502441
Test Epoch30 layer2 Acc 0.9044736842105263, AUC 0.9712567329406738, avg_entr 0.01082463376224041
ep30_l2_test_time 0.29410696029663086
Test Epoch30 layer3 Acc 0.9047368421052632, AUC 0.970099925994873, avg_entr 0.009746761992573738
ep30_l3_test_time 0.3773534297943115
Test Epoch30 layer4 Acc 0.9057894736842105, AUC 0.9690776467323303, avg_entr 0.008663658984005451
ep30_l4_test_time 0.4607973098754883
gc 0
Train Epoch31 Acc 0.9729 (116748/120000), AUC 0.9966832995414734
ep31_train_time 56.968687295913696
Test Epoch31 layer0 Acc 0.9078947368421053, AUC 0.9774473905563354, avg_entr 0.038145799189805984
ep31_l0_test_time 0.11955094337463379
Test Epoch31 layer1 Acc 0.906578947368421, AUC 0.9714810848236084, avg_entr 0.014464271254837513
ep31_l1_test_time 0.20612049102783203
Test Epoch31 layer2 Acc 0.9055263157894737, AUC 0.9713872075080872, avg_entr 0.010777187533676624
ep31_l2_test_time 0.29474687576293945
Test Epoch31 layer3 Acc 0.9063157894736842, AUC 0.9702879786491394, avg_entr 0.009627675637602806
ep31_l3_test_time 0.3762657642364502
Test Epoch31 layer4 Acc 0.9060526315789473, AUC 0.9693987965583801, avg_entr 0.008357844315469265
ep31_l4_test_time 0.46185970306396484
gc 0
Train Epoch32 Acc 0.9729666666666666 (116756/120000), AUC 0.9965285658836365
ep32_train_time 56.9513156414032
Test Epoch32 layer0 Acc 0.9073684210526316, AUC 0.9774383306503296, avg_entr 0.03817160800099373
ep32_l0_test_time 0.11991691589355469
Test Epoch32 layer1 Acc 0.9068421052631579, AUC 0.9713501930236816, avg_entr 0.01434336043894291
ep32_l1_test_time 0.2063610553741455
Test Epoch32 layer2 Acc 0.9052631578947369, AUC 0.9708358645439148, avg_entr 0.01064391527324915
ep32_l2_test_time 0.2948877811431885
Test Epoch32 layer3 Acc 0.9055263157894737, AUC 0.9694641828536987, avg_entr 0.009481402114033699
ep32_l3_test_time 0.377485990524292
Test Epoch32 layer4 Acc 0.905, AUC 0.9687877893447876, avg_entr 0.008131183683872223
ep32_l4_test_time 0.46133852005004883
gc 0
Train Epoch33 Acc 0.9726333333333333 (116716/120000), AUC 0.9966620206832886
ep33_train_time 56.984166860580444
Test Epoch33 layer0 Acc 0.9071052631578947, AUC 0.977435827255249, avg_entr 0.03802464157342911
ep33_l0_test_time 0.11997008323669434
Test Epoch33 layer1 Acc 0.906578947368421, AUC 0.9713408350944519, avg_entr 0.014391463249921799
ep33_l1_test_time 0.20566773414611816
Test Epoch33 layer2 Acc 0.9057894736842105, AUC 0.9710841774940491, avg_entr 0.010658523067831993
ep33_l2_test_time 0.29412364959716797
Test Epoch33 layer3 Acc 0.9060526315789473, AUC 0.969640851020813, avg_entr 0.009478437714278698
ep33_l3_test_time 0.3765404224395752
Test Epoch33 layer4 Acc 0.9057894736842105, AUC 0.9687904715538025, avg_entr 0.008208499290049076
ep33_l4_test_time 0.46181321144104004
gc 0
Train Epoch34 Acc 0.9728416666666667 (116741/120000), AUC 0.9966672658920288
ep34_train_time 56.981555461883545
Test Epoch34 layer0 Acc 0.9068421052631579, AUC 0.9774140119552612, avg_entr 0.03822512552142143
ep34_l0_test_time 0.1194908618927002
Test Epoch34 layer1 Acc 0.9068421052631579, AUC 0.9713994860649109, avg_entr 0.014335907064378262
ep34_l1_test_time 0.2057182788848877
Test Epoch34 layer2 Acc 0.905, AUC 0.9710766077041626, avg_entr 0.010598745197057724
ep34_l2_test_time 0.2942624092102051
Test Epoch34 layer3 Acc 0.9055263157894737, AUC 0.9699347019195557, avg_entr 0.009475464932620525
ep34_l3_test_time 0.37792420387268066
Test Epoch34 layer4 Acc 0.9052631578947369, AUC 0.9691022038459778, avg_entr 0.008153649978339672
ep34_l4_test_time 0.46186184883117676
gc 0
Train Epoch35 Acc 0.9728416666666667 (116741/120000), AUC 0.9967148900032043
ep35_train_time 56.90205240249634
Test Epoch35 layer0 Acc 0.9073684210526316, AUC 0.9774274826049805, avg_entr 0.038115471601486206
ep35_l0_test_time 0.119659423828125
Test Epoch35 layer1 Acc 0.906578947368421, AUC 0.9714031219482422, avg_entr 0.014378601685166359
ep35_l1_test_time 0.20638179779052734
Test Epoch35 layer2 Acc 0.9052631578947369, AUC 0.9709869027137756, avg_entr 0.010668808594346046
ep35_l2_test_time 0.29441356658935547
Test Epoch35 layer3 Acc 0.9057894736842105, AUC 0.9697883129119873, avg_entr 0.009478135965764523
ep35_l3_test_time 0.37659740447998047
Test Epoch35 layer4 Acc 0.9060526315789473, AUC 0.9689900875091553, avg_entr 0.008178011514246464
ep35_l4_test_time 0.46137428283691406
gc 0
Train Epoch36 Acc 0.9731333333333333 (116776/120000), AUC 0.9966619610786438
ep36_train_time 56.94502568244934
Test Epoch36 layer0 Acc 0.9078947368421053, AUC 0.9774186611175537, avg_entr 0.03810878470540047
ep36_l0_test_time 0.12027740478515625
Test Epoch36 layer1 Acc 0.9068421052631579, AUC 0.9714311361312866, avg_entr 0.014323205687105656
ep36_l1_test_time 0.20641636848449707
Test Epoch36 layer2 Acc 0.905, AUC 0.9709773063659668, avg_entr 0.010612191632390022
ep36_l2_test_time 0.2946300506591797
Test Epoch36 layer3 Acc 0.9057894736842105, AUC 0.9698229432106018, avg_entr 0.009394633583724499
ep36_l3_test_time 0.37879323959350586
Test Epoch36 layer4 Acc 0.9055263157894737, AUC 0.9691106081008911, avg_entr 0.008058369159698486
ep36_l4_test_time 0.4613668918609619
gc 0
Train Epoch37 Acc 0.9727333333333333 (116728/120000), AUC 0.9965628385543823
ep37_train_time 56.9355354309082
Test Epoch37 layer0 Acc 0.9076315789473685, AUC 0.9774136543273926, avg_entr 0.03805387392640114
ep37_l0_test_time 0.11937618255615234
Test Epoch37 layer1 Acc 0.9068421052631579, AUC 0.9712128639221191, avg_entr 0.014239642769098282
ep37_l1_test_time 0.20706558227539062
Test Epoch37 layer2 Acc 0.9055263157894737, AUC 0.9708715677261353, avg_entr 0.01054160762578249
ep37_l2_test_time 0.29482460021972656
Test Epoch37 layer3 Acc 0.905, AUC 0.969661295413971, avg_entr 0.009366506710648537
ep37_l3_test_time 0.37793397903442383
Test Epoch37 layer4 Acc 0.905, AUC 0.9689367413520813, avg_entr 0.00803382694721222
ep37_l4_test_time 0.46299266815185547
gc 0
Train Epoch38 Acc 0.9731666666666666 (116780/120000), AUC 0.9967571496963501
ep38_train_time 56.97604560852051
Test Epoch38 layer0 Acc 0.9073684210526316, AUC 0.9774158596992493, avg_entr 0.038000091910362244
ep38_l0_test_time 0.1194157600402832
Test Epoch38 layer1 Acc 0.9068421052631579, AUC 0.9713754653930664, avg_entr 0.014277562499046326
ep38_l1_test_time 0.20658063888549805
Test Epoch38 layer2 Acc 0.905, AUC 0.9710429906845093, avg_entr 0.01058942824602127
ep38_l2_test_time 0.29462480545043945
Test Epoch38 layer3 Acc 0.9055263157894737, AUC 0.9698728919029236, avg_entr 0.00940710213035345
ep38_l3_test_time 0.3772456645965576
Test Epoch38 layer4 Acc 0.9055263157894737, AUC 0.9691795706748962, avg_entr 0.008099354803562164
ep38_l4_test_time 0.46242523193359375
gc 0
Train Epoch39 Acc 0.97285 (116742/120000), AUC 0.9966644644737244
ep39_train_time 56.997989892959595
Test Epoch39 layer0 Acc 0.9073684210526316, AUC 0.9774124026298523, avg_entr 0.03805616497993469
ep39_l0_test_time 0.12052106857299805
Test Epoch39 layer1 Acc 0.9068421052631579, AUC 0.9714270830154419, avg_entr 0.014287324622273445
ep39_l1_test_time 0.20652127265930176
Test Epoch39 layer2 Acc 0.905, AUC 0.9710175395011902, avg_entr 0.010584845207631588
ep39_l2_test_time 0.29576897621154785
Test Epoch39 layer3 Acc 0.9055263157894737, AUC 0.9698523283004761, avg_entr 0.009409104473888874
ep39_l3_test_time 0.37844371795654297
Test Epoch39 layer4 Acc 0.9060526315789473, AUC 0.969153106212616, avg_entr 0.008092452771961689
ep39_l4_test_time 0.46251559257507324
gc 0
Train Epoch40 Acc 0.972875 (116745/120000), AUC 0.9966652393341064
ep40_train_time 56.9787073135376
Test Epoch40 layer0 Acc 0.9076315789473685, AUC 0.9774171113967896, avg_entr 0.038074783980846405
ep40_l0_test_time 0.11925172805786133
Test Epoch40 layer1 Acc 0.9068421052631579, AUC 0.9713694453239441, avg_entr 0.014264123514294624
ep40_l1_test_time 0.20523500442504883
Test Epoch40 layer2 Acc 0.905, AUC 0.9710063934326172, avg_entr 0.010563815012574196
ep40_l2_test_time 0.29377055168151855
Test Epoch40 layer3 Acc 0.9057894736842105, AUC 0.9696788191795349, avg_entr 0.00936840195208788
ep40_l3_test_time 0.3773813247680664
Test Epoch40 layer4 Acc 0.9055263157894737, AUC 0.9690202474594116, avg_entr 0.008049245923757553
ep40_l4_test_time 0.4612884521484375
gc 0
Train Epoch41 Acc 0.9731833333333333 (116782/120000), AUC 0.9965918064117432
ep41_train_time 57.0993709564209
Test Epoch41 layer0 Acc 0.9073684210526316, AUC 0.9774118065834045, avg_entr 0.037967901676893234
ep41_l0_test_time 0.11992239952087402
Test Epoch41 layer1 Acc 0.9068421052631579, AUC 0.971432626247406, avg_entr 0.014274992048740387
ep41_l1_test_time 0.20618939399719238
Test Epoch41 layer2 Acc 0.905, AUC 0.9710384011268616, avg_entr 0.010581382550299168
ep41_l2_test_time 0.2946655750274658
Test Epoch41 layer3 Acc 0.9055263157894737, AUC 0.9697704911231995, avg_entr 0.009384564124047756
ep41_l3_test_time 0.37744903564453125
Test Epoch41 layer4 Acc 0.9055263157894737, AUC 0.9690847396850586, avg_entr 0.008082211017608643
ep41_l4_test_time 0.46208906173706055
gc 0
Train Epoch42 Acc 0.972975 (116757/120000), AUC 0.9966230392456055
ep42_train_time 56.943997859954834
Test Epoch42 layer0 Acc 0.9071052631578947, AUC 0.9774235486984253, avg_entr 0.03796454891562462
ep42_l0_test_time 0.11907100677490234
Test Epoch42 layer1 Acc 0.9068421052631579, AUC 0.9714053869247437, avg_entr 0.014273226261138916
ep42_l1_test_time 0.2070326805114746
Test Epoch42 layer2 Acc 0.905, AUC 0.9710497856140137, avg_entr 0.010576690547168255
ep42_l2_test_time 0.29410672187805176
Test Epoch42 layer3 Acc 0.9055263157894737, AUC 0.9697549939155579, avg_entr 0.009374094195663929
ep42_l3_test_time 0.37820982933044434
Test Epoch42 layer4 Acc 0.9055263157894737, AUC 0.9691145420074463, avg_entr 0.00807291828095913
ep42_l4_test_time 0.4619314670562744
gc 0
Train Epoch43 Acc 0.9732416666666667 (116789/120000), AUC 0.9967484474182129
ep43_train_time 57.05501627922058
Test Epoch43 layer0 Acc 0.9073684210526316, AUC 0.9774116277694702, avg_entr 0.03792969137430191
ep43_l0_test_time 0.11917877197265625
Test Epoch43 layer1 Acc 0.9068421052631579, AUC 0.971402108669281, avg_entr 0.014275521039962769
ep43_l1_test_time 0.20535063743591309
Test Epoch43 layer2 Acc 0.9052631578947369, AUC 0.9709752202033997, avg_entr 0.010578867979347706
ep43_l2_test_time 0.2935616970062256
Test Epoch43 layer3 Acc 0.9057894736842105, AUC 0.9697396159172058, avg_entr 0.00937225203961134
ep43_l3_test_time 0.37784385681152344
Test Epoch43 layer4 Acc 0.9057894736842105, AUC 0.9690686464309692, avg_entr 0.008073834702372551
ep43_l4_test_time 0.46132349967956543
gc 0
Train Epoch44 Acc 0.9727666666666667 (116732/120000), AUC 0.9967422485351562
ep44_train_time 57.08893179893494
Test Epoch44 layer0 Acc 0.9073684210526316, AUC 0.9774087071418762, avg_entr 0.03798842057585716
ep44_l0_test_time 0.11971807479858398
Test Epoch44 layer1 Acc 0.9068421052631579, AUC 0.9714062213897705, avg_entr 0.014272378757596016
ep44_l1_test_time 0.2059192657470703
Test Epoch44 layer2 Acc 0.905, AUC 0.9710442423820496, avg_entr 0.010569199919700623
ep44_l2_test_time 0.29378795623779297
Test Epoch44 layer3 Acc 0.9055263157894737, AUC 0.9697874784469604, avg_entr 0.009367442689836025
ep44_l3_test_time 0.37706828117370605
Test Epoch44 layer4 Acc 0.9055263157894737, AUC 0.9691150188446045, avg_entr 0.008073010481894016
ep44_l4_test_time 0.46102213859558105
gc 0
Train Epoch45 Acc 0.973075 (116769/120000), AUC 0.9966570138931274
ep45_train_time 56.928488969802856
Test Epoch45 layer0 Acc 0.9076315789473685, AUC 0.9774152636528015, avg_entr 0.03790049999952316
ep45_l0_test_time 0.12024450302124023
Test Epoch45 layer1 Acc 0.9068421052631579, AUC 0.971430242061615, avg_entr 0.014266281388700008
ep45_l1_test_time 0.20675873756408691
Test Epoch45 layer2 Acc 0.9052631578947369, AUC 0.9710286259651184, avg_entr 0.010570879094302654
ep45_l2_test_time 0.2955811023712158
Test Epoch45 layer3 Acc 0.9057894736842105, AUC 0.9697492122650146, avg_entr 0.009341229684650898
ep45_l3_test_time 0.3782985210418701
Test Epoch45 layer4 Acc 0.9055263157894737, AUC 0.969030499458313, avg_entr 0.008036909624934196
ep45_l4_test_time 0.46143555641174316
gc 0
Train Epoch46 Acc 0.97295 (116754/120000), AUC 0.9967148303985596
ep46_train_time 57.02670240402222
Test Epoch46 layer0 Acc 0.9073684210526316, AUC 0.9774075746536255, avg_entr 0.03794116899371147
ep46_l0_test_time 0.11924099922180176
Test Epoch46 layer1 Acc 0.9068421052631579, AUC 0.9714105129241943, avg_entr 0.014263850636780262
ep46_l1_test_time 0.20647644996643066
Test Epoch46 layer2 Acc 0.905, AUC 0.9709773063659668, avg_entr 0.01055989507585764
ep46_l2_test_time 0.29435253143310547
Test Epoch46 layer3 Acc 0.9055263157894737, AUC 0.9696817398071289, avg_entr 0.009347912855446339
ep46_l3_test_time 0.37700629234313965
Test Epoch46 layer4 Acc 0.9055263157894737, AUC 0.969064474105835, avg_entr 0.008045829832553864
ep46_l4_test_time 0.46112918853759766
gc 0
Train Epoch47 Acc 0.9729166666666667 (116750/120000), AUC 0.9966438412666321
ep47_train_time 57.03192710876465
Test Epoch47 layer0 Acc 0.9071052631578947, AUC 0.9774214029312134, avg_entr 0.03792305290699005
ep47_l0_test_time 0.12041926383972168
Test Epoch47 layer1 Acc 0.9068421052631579, AUC 0.9714120030403137, avg_entr 0.014263970777392387
ep47_l1_test_time 0.20724225044250488
Test Epoch47 layer2 Acc 0.905, AUC 0.9709826707839966, avg_entr 0.010565916076302528
ep47_l2_test_time 0.2953939437866211
Test Epoch47 layer3 Acc 0.9055263157894737, AUC 0.9697443246841431, avg_entr 0.00934623647481203
ep47_l3_test_time 0.37790489196777344
Test Epoch47 layer4 Acc 0.9052631578947369, AUC 0.9690369367599487, avg_entr 0.008049778640270233
ep47_l4_test_time 0.4618535041809082
gc 0
Train Epoch48 Acc 0.9733416666666667 (116801/120000), AUC 0.9967302083969116
ep48_train_time 56.9875590801239
Test Epoch48 layer0 Acc 0.9071052631578947, AUC 0.9774090051651001, avg_entr 0.0379200205206871
ep48_l0_test_time 0.11965703964233398
Test Epoch48 layer1 Acc 0.9068421052631579, AUC 0.9714012742042542, avg_entr 0.01426111813634634
ep48_l1_test_time 0.20623183250427246
Test Epoch48 layer2 Acc 0.905, AUC 0.9709949493408203, avg_entr 0.010562888346612453
ep48_l2_test_time 0.29419565200805664
Test Epoch48 layer3 Acc 0.9055263157894737, AUC 0.9697530269622803, avg_entr 0.00934735219925642
ep48_l3_test_time 0.3775756359100342
Test Epoch48 layer4 Acc 0.9052631578947369, AUC 0.9690501093864441, avg_entr 0.00804905779659748
ep48_l4_test_time 0.461869478225708
gc 0
Train Epoch49 Acc 0.973025 (116763/120000), AUC 0.9966951608657837
ep49_train_time 56.991469860076904
Test Epoch49 layer0 Acc 0.9073684210526316, AUC 0.9774090647697449, avg_entr 0.037912096828222275
ep49_l0_test_time 0.12362098693847656
Test Epoch49 layer1 Acc 0.9068421052631579, AUC 0.9714051485061646, avg_entr 0.014255289919674397
ep49_l1_test_time 0.2095928192138672
Test Epoch49 layer2 Acc 0.905, AUC 0.9709891080856323, avg_entr 0.01055858749896288
ep49_l2_test_time 0.3006598949432373
Test Epoch49 layer3 Acc 0.9055263157894737, AUC 0.9697547554969788, avg_entr 0.009343519806861877
ep49_l3_test_time 0.37767553329467773
Test Epoch49 layer4 Acc 0.9052631578947369, AUC 0.9690467119216919, avg_entr 0.008043169043958187
ep49_l4_test_time 0.4616684913635254
Best AUC 0.9808801412582397
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train+valid_time 2922.7671711444855
Start Testing
Load ckpt at ckpt/ag_news_transformeral_l5_pad125//ag_news_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.9234210526315789, AUC 0.9849845170974731, avg_entr 0.09126321226358414
ep49_l0_test_time 0.11714458465576172
Test Epoch49 layer1 Acc 0.9255263157894736, AUC 0.9846883416175842, avg_entr 0.03711903840303421
ep49_l1_test_time 0.20641279220581055
Test Epoch49 layer2 Acc 0.9260526315789473, AUC 0.9858301877975464, avg_entr 0.03041502833366394
ep49_l2_test_time 0.29436659812927246
Test Epoch49 layer3 Acc 0.9260526315789473, AUC 0.984963059425354, avg_entr 0.027926724404096603
ep49_l3_test_time 0.3785266876220703
Test Epoch49 layer4 Acc 0.9260526315789473, AUC 0.9854158163070679, avg_entr 0.026517463847994804
ep49_l4_test_time 0.4617009162902832
