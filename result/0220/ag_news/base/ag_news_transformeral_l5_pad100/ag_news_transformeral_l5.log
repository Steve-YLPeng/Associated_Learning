total count words 102019
vocab size 30000
found 26754 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13672292
init_time 20.80044913291931
Start Training
gc 0
Train Epoch0 Acc 0.6385 (76620/120000), AUC 0.860136091709137
ep0_train_time 48.23153567314148
Test Epoch0 layer0 Acc 0.901578947368421, AUC 0.9735419154167175, avg_entr 0.23442846536636353
ep0_l0_test_time 0.10534238815307617
Save ckpt to ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9036842105263158, AUC 0.9754178524017334, avg_entr 0.1610887050628662
ep0_l1_test_time 0.17446422576904297
Save ckpt to ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.9007894736842105, AUC 0.9755089282989502, avg_entr 0.15535815060138702
ep0_l2_test_time 0.24775457382202148
Save ckpt to ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer3 Acc 0.9021052631578947, AUC 0.9750271439552307, avg_entr 0.15593451261520386
ep0_l3_test_time 0.31923604011535645
Test Epoch0 layer4 Acc 0.8968421052631579, AUC 0.9748309254646301, avg_entr 0.1733415722846985
ep0_l4_test_time 0.38647031784057617
gc 0
Train Epoch1 Acc 0.9229166666666667 (110750/120000), AUC 0.9823036193847656
ep1_train_time 47.85472750663757
Test Epoch1 layer0 Acc 0.9105263157894737, AUC 0.9772245287895203, avg_entr 0.1384134143590927
ep1_l0_test_time 0.10206222534179688
Save ckpt to ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.9126315789473685, AUC 0.9793407917022705, avg_entr 0.08272158354520798
ep1_l1_test_time 0.17632412910461426
Save ckpt to ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.9118421052631579, AUC 0.9794677495956421, avg_entr 0.07010385394096375
ep1_l2_test_time 0.24849486351013184
Save ckpt to ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer3 Acc 0.911578947368421, AUC 0.9789593815803528, avg_entr 0.06438979506492615
ep1_l3_test_time 0.31944847106933594
Test Epoch1 layer4 Acc 0.9110526315789473, AUC 0.9789944887161255, avg_entr 0.060349803417921066
ep1_l4_test_time 0.38738512992858887
gc 0
Train Epoch2 Acc 0.9374166666666667 (112490/120000), AUC 0.9873981475830078
ep2_train_time 47.75547647476196
Test Epoch2 layer0 Acc 0.9110526315789473, AUC 0.9784918427467346, avg_entr 0.10945812612771988
ep2_l0_test_time 0.10192346572875977
Test Epoch2 layer1 Acc 0.9134210526315789, AUC 0.9799442887306213, avg_entr 0.04502450302243233
ep2_l1_test_time 0.17378878593444824
Save ckpt to ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt  ,ep 2
Test Epoch2 layer2 Acc 0.9118421052631579, AUC 0.9795674085617065, avg_entr 0.03864603117108345
ep2_l2_test_time 0.24820351600646973
Test Epoch2 layer3 Acc 0.911578947368421, AUC 0.9797303676605225, avg_entr 0.03603887930512428
ep2_l3_test_time 0.31800103187561035
Test Epoch2 layer4 Acc 0.911578947368421, AUC 0.979293942451477, avg_entr 0.0334780290722847
ep2_l4_test_time 0.38726210594177246
gc 0
Train Epoch3 Acc 0.9455333333333333 (113464/120000), AUC 0.9898867607116699
ep3_train_time 47.8263623714447
Test Epoch3 layer0 Acc 0.9089473684210526, AUC 0.978516697883606, avg_entr 0.09553377330303192
ep3_l0_test_time 0.10257458686828613
Test Epoch3 layer1 Acc 0.9094736842105263, AUC 0.9779696464538574, avg_entr 0.033128175884485245
ep3_l1_test_time 0.173933744430542
Test Epoch3 layer2 Acc 0.9107894736842105, AUC 0.9789596796035767, avg_entr 0.027963168919086456
ep3_l2_test_time 0.2458655834197998
Test Epoch3 layer3 Acc 0.9105263157894737, AUC 0.9797128438949585, avg_entr 0.026259107515215874
ep3_l3_test_time 0.31710076332092285
Test Epoch3 layer4 Acc 0.9107894736842105, AUC 0.9797452092170715, avg_entr 0.023921623826026917
ep3_l4_test_time 0.3873155117034912
gc 0
Train Epoch4 Acc 0.9507833333333333 (114094/120000), AUC 0.9910632967948914
ep4_train_time 47.848957777023315
Test Epoch4 layer0 Acc 0.9063157894736842, AUC 0.9787102937698364, avg_entr 0.0852736309170723
ep4_l0_test_time 0.10229277610778809
Test Epoch4 layer1 Acc 0.9102631578947369, AUC 0.9760164022445679, avg_entr 0.027568627148866653
ep4_l1_test_time 0.17347145080566406
Test Epoch4 layer2 Acc 0.9094736842105263, AUC 0.9775336384773254, avg_entr 0.022656437009572983
ep4_l2_test_time 0.24550867080688477
Test Epoch4 layer3 Acc 0.9105263157894737, AUC 0.9787294268608093, avg_entr 0.021085185930132866
ep4_l3_test_time 0.3169517517089844
Test Epoch4 layer4 Acc 0.9110526315789473, AUC 0.978968620300293, avg_entr 0.019739845767617226
ep4_l4_test_time 0.38664937019348145
gc 0
Train Epoch5 Acc 0.9544083333333333 (114529/120000), AUC 0.9918280839920044
ep5_train_time 47.79733347892761
Test Epoch5 layer0 Acc 0.91, AUC 0.978488564491272, avg_entr 0.07440008968114853
ep5_l0_test_time 0.10246109962463379
Test Epoch5 layer1 Acc 0.9110526315789473, AUC 0.9743383526802063, avg_entr 0.025722475722432137
ep5_l1_test_time 0.17348480224609375
Test Epoch5 layer2 Acc 0.9128947368421053, AUC 0.9761888384819031, avg_entr 0.019947590306401253
ep5_l2_test_time 0.24578619003295898
Test Epoch5 layer3 Acc 0.911578947368421, AUC 0.9767844080924988, avg_entr 0.018251610919833183
ep5_l3_test_time 0.3167448043823242
Test Epoch5 layer4 Acc 0.9118421052631579, AUC 0.9767296314239502, avg_entr 0.016874227672815323
ep5_l4_test_time 0.38758277893066406
gc 0
Train Epoch6 Acc 0.9575166666666667 (114902/120000), AUC 0.9924662113189697
ep6_train_time 47.7981162071228
Test Epoch6 layer0 Acc 0.9089473684210526, AUC 0.978439211845398, avg_entr 0.06947758793830872
ep6_l0_test_time 0.10197591781616211
Test Epoch6 layer1 Acc 0.9084210526315789, AUC 0.9757369160652161, avg_entr 0.02353902906179428
ep6_l1_test_time 0.17315888404846191
Test Epoch6 layer2 Acc 0.9097368421052632, AUC 0.9767798185348511, avg_entr 0.018626976758241653
ep6_l2_test_time 0.24560880661010742
Test Epoch6 layer3 Acc 0.9094736842105263, AUC 0.9774673581123352, avg_entr 0.017116621136665344
ep6_l3_test_time 0.31714916229248047
Test Epoch6 layer4 Acc 0.9097368421052632, AUC 0.9770609140396118, avg_entr 0.015703538432717323
ep6_l4_test_time 0.38654637336730957
gc 0
Train Epoch7 Acc 0.9602583333333333 (115231/120000), AUC 0.9933632612228394
ep7_train_time 48.01020669937134
Test Epoch7 layer0 Acc 0.9105263157894737, AUC 0.978369951248169, avg_entr 0.06539902091026306
ep7_l0_test_time 0.10500264167785645
Test Epoch7 layer1 Acc 0.9086842105263158, AUC 0.9730756878852844, avg_entr 0.02144160494208336
ep7_l1_test_time 0.17303037643432617
Test Epoch7 layer2 Acc 0.9078947368421053, AUC 0.9751110672950745, avg_entr 0.01621335558593273
ep7_l2_test_time 0.24553680419921875
Test Epoch7 layer3 Acc 0.908157894736842, AUC 0.9753243923187256, avg_entr 0.014378410764038563
ep7_l3_test_time 0.3173093795776367
Test Epoch7 layer4 Acc 0.9086842105263158, AUC 0.973900318145752, avg_entr 0.013482160866260529
ep7_l4_test_time 0.38670849800109863
gc 0
Train Epoch8 Acc 0.9621666666666666 (115460/120000), AUC 0.9941422939300537
ep8_train_time 47.821534872055054
Test Epoch8 layer0 Acc 0.911578947368421, AUC 0.9781280755996704, avg_entr 0.060497965663671494
ep8_l0_test_time 0.10324525833129883
Test Epoch8 layer1 Acc 0.9073684210526316, AUC 0.9728838205337524, avg_entr 0.022031310945749283
ep8_l1_test_time 0.17417550086975098
Test Epoch8 layer2 Acc 0.9063157894736842, AUC 0.973286509513855, avg_entr 0.016599638387560844
ep8_l2_test_time 0.24620318412780762
Test Epoch8 layer3 Acc 0.906578947368421, AUC 0.9753764867782593, avg_entr 0.014020485803484917
ep8_l3_test_time 0.3169066905975342
Test Epoch8 layer4 Acc 0.906578947368421, AUC 0.975589394569397, avg_entr 0.012172809801995754
ep8_l4_test_time 0.3872098922729492
gc 0
Train Epoch9 Acc 0.9650333333333333 (115804/120000), AUC 0.9947730898857117
ep9_train_time 47.87400221824646
Test Epoch9 layer0 Acc 0.9107894736842105, AUC 0.9779711961746216, avg_entr 0.058534346520900726
ep9_l0_test_time 0.10137200355529785
Test Epoch9 layer1 Acc 0.906578947368421, AUC 0.9720349311828613, avg_entr 0.021016422659158707
ep9_l1_test_time 0.17340421676635742
Test Epoch9 layer2 Acc 0.9060526315789473, AUC 0.9745296835899353, avg_entr 0.015835585072636604
ep9_l2_test_time 0.24584436416625977
Test Epoch9 layer3 Acc 0.9057894736842105, AUC 0.9762976169586182, avg_entr 0.013344828970730305
ep9_l3_test_time 0.3164858818054199
Test Epoch9 layer4 Acc 0.9055263157894737, AUC 0.9752825498580933, avg_entr 0.011605198495090008
ep9_l4_test_time 0.3882629871368408
gc 0
Train Epoch10 Acc 0.9663333333333334 (115960/120000), AUC 0.9950374364852905
ep10_train_time 48.054107904434204
Test Epoch10 layer0 Acc 0.9097368421052632, AUC 0.9777355194091797, avg_entr 0.05714533478021622
ep10_l0_test_time 0.10184049606323242
Test Epoch10 layer1 Acc 0.9073684210526316, AUC 0.971437931060791, avg_entr 0.01884705200791359
ep10_l1_test_time 0.17378568649291992
Test Epoch10 layer2 Acc 0.9068421052631579, AUC 0.9734265208244324, avg_entr 0.013448921963572502
ep10_l2_test_time 0.24565362930297852
Test Epoch10 layer3 Acc 0.9063157894736842, AUC 0.9738819003105164, avg_entr 0.01091307308524847
ep10_l3_test_time 0.31684350967407227
Test Epoch10 layer4 Acc 0.9063157894736842, AUC 0.9741986989974976, avg_entr 0.009314577095210552
ep10_l4_test_time 0.38643479347229004
gc 0
Train Epoch11 Acc 0.9677666666666667 (116132/120000), AUC 0.9954023361206055
ep11_train_time 47.88046073913574
Test Epoch11 layer0 Acc 0.9092105263157895, AUC 0.9777678847312927, avg_entr 0.05448059365153313
ep11_l0_test_time 0.10213875770568848
Test Epoch11 layer1 Acc 0.9068421052631579, AUC 0.9702214598655701, avg_entr 0.01768839731812477
ep11_l1_test_time 0.17281627655029297
Test Epoch11 layer2 Acc 0.906578947368421, AUC 0.9720669388771057, avg_entr 0.01266161072999239
ep11_l2_test_time 0.24545550346374512
Test Epoch11 layer3 Acc 0.906578947368421, AUC 0.9731169939041138, avg_entr 0.010529602877795696
ep11_l3_test_time 0.3172311782836914
Test Epoch11 layer4 Acc 0.9063157894736842, AUC 0.9727627635002136, avg_entr 0.008938727900385857
ep11_l4_test_time 0.3869481086730957
gc 0
Train Epoch12 Acc 0.9682666666666667 (116192/120000), AUC 0.9955043196678162
ep12_train_time 47.87480878829956
Test Epoch12 layer0 Acc 0.9094736842105263, AUC 0.9776074290275574, avg_entr 0.052179500460624695
ep12_l0_test_time 0.10247015953063965
Test Epoch12 layer1 Acc 0.9068421052631579, AUC 0.9700204730033875, avg_entr 0.017589416354894638
ep12_l1_test_time 0.17355608940124512
Test Epoch12 layer2 Acc 0.9052631578947369, AUC 0.971828818321228, avg_entr 0.012509917840361595
ep12_l2_test_time 0.24574637413024902
Test Epoch12 layer3 Acc 0.9057894736842105, AUC 0.970344066619873, avg_entr 0.010360928252339363
ep12_l3_test_time 0.31693243980407715
Test Epoch12 layer4 Acc 0.9055263157894737, AUC 0.970660924911499, avg_entr 0.009115925058722496
ep12_l4_test_time 0.3889915943145752
gc 0
Train Epoch13 Acc 0.9697333333333333 (116368/120000), AUC 0.9958760738372803
ep13_train_time 47.90243339538574
Test Epoch13 layer0 Acc 0.9073684210526316, AUC 0.9774935245513916, avg_entr 0.05118001252412796
ep13_l0_test_time 0.10190653800964355
Test Epoch13 layer1 Acc 0.905, AUC 0.9694765210151672, avg_entr 0.016994135454297066
ep13_l1_test_time 0.17351245880126953
Test Epoch13 layer2 Acc 0.9047368421052632, AUC 0.9713997840881348, avg_entr 0.011538660153746605
ep13_l2_test_time 0.24619698524475098
Test Epoch13 layer3 Acc 0.9047368421052632, AUC 0.9715920090675354, avg_entr 0.009478963911533356
ep13_l3_test_time 0.31738710403442383
Test Epoch13 layer4 Acc 0.9047368421052632, AUC 0.9727376699447632, avg_entr 0.008204749785363674
ep13_l4_test_time 0.38651204109191895
gc 0
Train Epoch14 Acc 0.9704083333333333 (116449/120000), AUC 0.996050238609314
ep14_train_time 47.89998173713684
Test Epoch14 layer0 Acc 0.9089473684210526, AUC 0.9774738550186157, avg_entr 0.04992029070854187
ep14_l0_test_time 0.10135579109191895
Test Epoch14 layer1 Acc 0.9044736842105263, AUC 0.9700826406478882, avg_entr 0.016755329445004463
ep14_l1_test_time 0.17330217361450195
Test Epoch14 layer2 Acc 0.9036842105263158, AUC 0.9711467027664185, avg_entr 0.011598293669521809
ep14_l2_test_time 0.24535059928894043
Test Epoch14 layer3 Acc 0.9026315789473685, AUC 0.9704578518867493, avg_entr 0.009440811350941658
ep14_l3_test_time 0.316234827041626
Test Epoch14 layer4 Acc 0.9031578947368422, AUC 0.9703884720802307, avg_entr 0.008123612962663174
ep14_l4_test_time 0.3875997066497803
gc 0
Train Epoch15 Acc 0.97065 (116478/120000), AUC 0.9962002038955688
ep15_train_time 48.0167019367218
Test Epoch15 layer0 Acc 0.9094736842105263, AUC 0.9774650931358337, avg_entr 0.04750632122159004
ep15_l0_test_time 0.10214757919311523
Test Epoch15 layer1 Acc 0.905, AUC 0.9699565768241882, avg_entr 0.01609509065747261
ep15_l1_test_time 0.1735372543334961
Test Epoch15 layer2 Acc 0.9044736842105263, AUC 0.9708675146102905, avg_entr 0.011413057334721088
ep15_l2_test_time 0.24599146842956543
Test Epoch15 layer3 Acc 0.9039473684210526, AUC 0.9710604548454285, avg_entr 0.009452033787965775
ep15_l3_test_time 0.31670260429382324
Test Epoch15 layer4 Acc 0.9042105263157895, AUC 0.9711881279945374, avg_entr 0.008478247560560703
ep15_l4_test_time 0.3866138458251953
gc 0
Train Epoch16 Acc 0.9716166666666667 (116594/120000), AUC 0.9960769414901733
ep16_train_time 47.950459718704224
Test Epoch16 layer0 Acc 0.9086842105263158, AUC 0.9774532914161682, avg_entr 0.04631204158067703
ep16_l0_test_time 0.1043708324432373
Test Epoch16 layer1 Acc 0.9042105263157895, AUC 0.9698809385299683, avg_entr 0.015391688793897629
ep16_l1_test_time 0.17455005645751953
Test Epoch16 layer2 Acc 0.9028947368421053, AUC 0.9708110094070435, avg_entr 0.0109338304027915
ep16_l2_test_time 0.24590063095092773
Test Epoch16 layer3 Acc 0.9021052631578947, AUC 0.9711636900901794, avg_entr 0.008801245130598545
ep16_l3_test_time 0.3164639472961426
Test Epoch16 layer4 Acc 0.9028947368421053, AUC 0.9707210659980774, avg_entr 0.0076821898110210896
ep16_l4_test_time 0.38697028160095215
gc 0
Train Epoch17 Acc 0.9725 (116700/120000), AUC 0.9963933825492859
ep17_train_time 47.89986729621887
Test Epoch17 layer0 Acc 0.9071052631578947, AUC 0.9773698449134827, avg_entr 0.045823656022548676
ep17_l0_test_time 0.10236692428588867
Test Epoch17 layer1 Acc 0.9036842105263158, AUC 0.9685019850730896, avg_entr 0.015100275166332722
ep17_l1_test_time 0.1731722354888916
Test Epoch17 layer2 Acc 0.9023684210526316, AUC 0.9687521457672119, avg_entr 0.010234189219772816
ep17_l2_test_time 0.24559307098388672
Test Epoch17 layer3 Acc 0.9021052631578947, AUC 0.9667213559150696, avg_entr 0.008091799914836884
ep17_l3_test_time 0.3158252239227295
Test Epoch17 layer4 Acc 0.9023684210526316, AUC 0.9669690728187561, avg_entr 0.007241834420710802
ep17_l4_test_time 0.3859076499938965
gc 0
Train Epoch18 Acc 0.972325 (116679/120000), AUC 0.9964470863342285
ep18_train_time 47.997793674468994
Test Epoch18 layer0 Acc 0.9092105263157895, AUC 0.9773871898651123, avg_entr 0.04452011361718178
ep18_l0_test_time 0.10217499732971191
Test Epoch18 layer1 Acc 0.9036842105263158, AUC 0.9689807891845703, avg_entr 0.014746127650141716
ep18_l1_test_time 0.1736156940460205
Test Epoch18 layer2 Acc 0.9021052631578947, AUC 0.9704657196998596, avg_entr 0.010334010235965252
ep18_l2_test_time 0.24583983421325684
Test Epoch18 layer3 Acc 0.9023684210526316, AUC 0.9701473712921143, avg_entr 0.008342765271663666
ep18_l3_test_time 0.31711554527282715
Test Epoch18 layer4 Acc 0.9026315789473685, AUC 0.9697296619415283, avg_entr 0.007371596992015839
ep18_l4_test_time 0.38698720932006836
gc 0
Train Epoch19 Acc 0.9727583333333333 (116731/120000), AUC 0.9964051246643066
ep19_train_time 47.9427695274353
Test Epoch19 layer0 Acc 0.9068421052631579, AUC 0.9773343801498413, avg_entr 0.044015951454639435
ep19_l0_test_time 0.10242128372192383
Test Epoch19 layer1 Acc 0.9028947368421053, AUC 0.9687874913215637, avg_entr 0.014381072483956814
ep19_l1_test_time 0.172957181930542
Test Epoch19 layer2 Acc 0.9026315789473685, AUC 0.9697003364562988, avg_entr 0.010285391472280025
ep19_l2_test_time 0.24657726287841797
Test Epoch19 layer3 Acc 0.9021052631578947, AUC 0.9689326882362366, avg_entr 0.00827234797179699
ep19_l3_test_time 0.3166379928588867
Test Epoch19 layer4 Acc 0.9023684210526316, AUC 0.969375729560852, avg_entr 0.007273880299180746
ep19_l4_test_time 0.386655330657959
gc 0
Train Epoch20 Acc 0.9732333333333333 (116788/120000), AUC 0.996482253074646
ep20_train_time 47.93407225608826
Test Epoch20 layer0 Acc 0.9084210526315789, AUC 0.9773492813110352, avg_entr 0.041704680770635605
ep20_l0_test_time 0.10209178924560547
Test Epoch20 layer1 Acc 0.9034210526315789, AUC 0.9689385294914246, avg_entr 0.013840069994330406
ep20_l1_test_time 0.17310047149658203
Test Epoch20 layer2 Acc 0.9018421052631579, AUC 0.9694947600364685, avg_entr 0.009884631261229515
ep20_l2_test_time 0.2456645965576172
Test Epoch20 layer3 Acc 0.9018421052631579, AUC 0.9683586955070496, avg_entr 0.008153739385306835
ep20_l3_test_time 0.31603145599365234
Test Epoch20 layer4 Acc 0.9021052631578947, AUC 0.9684978127479553, avg_entr 0.007310299202799797
ep20_l4_test_time 0.3863534927368164
gc 0
Train Epoch21 Acc 0.973475 (116817/120000), AUC 0.9966583251953125
ep21_train_time 47.98582363128662
Test Epoch21 layer0 Acc 0.908157894736842, AUC 0.9773622155189514, avg_entr 0.04162004590034485
ep21_l0_test_time 0.10283493995666504
Test Epoch21 layer1 Acc 0.9031578947368422, AUC 0.9686101675033569, avg_entr 0.0136747220531106
ep21_l1_test_time 0.1731715202331543
Test Epoch21 layer2 Acc 0.9031578947368422, AUC 0.9694050550460815, avg_entr 0.00967077724635601
ep21_l2_test_time 0.24610137939453125
Test Epoch21 layer3 Acc 0.9039473684210526, AUC 0.9677898287773132, avg_entr 0.007865268737077713
ep21_l3_test_time 0.316864013671875
Test Epoch21 layer4 Acc 0.9039473684210526, AUC 0.9677762985229492, avg_entr 0.006931980140507221
ep21_l4_test_time 0.386821985244751
gc 0
Train Epoch22 Acc 0.9733833333333334 (116806/120000), AUC 0.9966368079185486
ep22_train_time 47.87817192077637
Test Epoch22 layer0 Acc 0.9094736842105263, AUC 0.9774230718612671, avg_entr 0.040823616087436676
ep22_l0_test_time 0.10210394859313965
Test Epoch22 layer1 Acc 0.9028947368421053, AUC 0.9690814018249512, avg_entr 0.01341693103313446
ep22_l1_test_time 0.17360806465148926
Test Epoch22 layer2 Acc 0.9023684210526316, AUC 0.9697107076644897, avg_entr 0.009903485886752605
ep22_l2_test_time 0.24574613571166992
Test Epoch22 layer3 Acc 0.9021052631578947, AUC 0.9693208336830139, avg_entr 0.008012997917830944
ep22_l3_test_time 0.3169271945953369
Test Epoch22 layer4 Acc 0.9023684210526316, AUC 0.9682683348655701, avg_entr 0.007118699606508017
ep22_l4_test_time 0.3861980438232422
gc 0
Train Epoch23 Acc 0.9739416666666667 (116873/120000), AUC 0.9965611696243286
ep23_train_time 47.97430610656738
Test Epoch23 layer0 Acc 0.9073684210526316, AUC 0.977359414100647, avg_entr 0.04044119641184807
ep23_l0_test_time 0.10230684280395508
Test Epoch23 layer1 Acc 0.9042105263157895, AUC 0.9689221978187561, avg_entr 0.013057295233011246
ep23_l1_test_time 0.17322254180908203
Test Epoch23 layer2 Acc 0.9013157894736842, AUC 0.9694026708602905, avg_entr 0.00949839036911726
ep23_l2_test_time 0.24574708938598633
Test Epoch23 layer3 Acc 0.9018421052631579, AUC 0.9672982692718506, avg_entr 0.007891261018812656
ep23_l3_test_time 0.3170442581176758
Test Epoch23 layer4 Acc 0.9018421052631579, AUC 0.9672526121139526, avg_entr 0.007188411895185709
ep23_l4_test_time 0.38631319999694824
gc 0
Train Epoch24 Acc 0.9738833333333333 (116866/120000), AUC 0.9966253042221069
ep24_train_time 47.87698674201965
Test Epoch24 layer0 Acc 0.906578947368421, AUC 0.9773536324501038, avg_entr 0.03998493403196335
ep24_l0_test_time 0.10161781311035156
Test Epoch24 layer1 Acc 0.9042105263157895, AUC 0.9690176248550415, avg_entr 0.012726323679089546
ep24_l1_test_time 0.17338204383850098
Test Epoch24 layer2 Acc 0.9021052631578947, AUC 0.9696718454360962, avg_entr 0.00904399435967207
ep24_l2_test_time 0.24584484100341797
Test Epoch24 layer3 Acc 0.9023684210526316, AUC 0.9684424996376038, avg_entr 0.007417755201458931
ep24_l3_test_time 0.3167757987976074
Test Epoch24 layer4 Acc 0.9023684210526316, AUC 0.9681987762451172, avg_entr 0.006645397283136845
ep24_l4_test_time 0.3862907886505127
gc 0
Train Epoch25 Acc 0.974325 (116919/120000), AUC 0.9966908693313599
ep25_train_time 47.949981927871704
Test Epoch25 layer0 Acc 0.906578947368421, AUC 0.9773393273353577, avg_entr 0.039916932582855225
ep25_l0_test_time 0.10230541229248047
Test Epoch25 layer1 Acc 0.9042105263157895, AUC 0.9686270356178284, avg_entr 0.01258262898772955
ep25_l1_test_time 0.1734154224395752
Test Epoch25 layer2 Acc 0.9018421052631579, AUC 0.9691569805145264, avg_entr 0.009209361858665943
ep25_l2_test_time 0.24580860137939453
Test Epoch25 layer3 Acc 0.9026315789473685, AUC 0.9676181077957153, avg_entr 0.007628331892192364
ep25_l3_test_time 0.3161449432373047
Test Epoch25 layer4 Acc 0.9031578947368422, AUC 0.9674797654151917, avg_entr 0.006907336879521608
ep25_l4_test_time 0.38695788383483887
gc 0
Train Epoch26 Acc 0.97435 (116922/120000), AUC 0.9966794848442078
ep26_train_time 47.907310485839844
Test Epoch26 layer0 Acc 0.9089473684210526, AUC 0.9773458242416382, avg_entr 0.03966812416911125
ep26_l0_test_time 0.10224604606628418
Test Epoch26 layer1 Acc 0.9036842105263158, AUC 0.9686696529388428, avg_entr 0.012547366321086884
ep26_l1_test_time 0.1753239631652832
Test Epoch26 layer2 Acc 0.9010526315789473, AUC 0.9695122241973877, avg_entr 0.009013892151415348
ep26_l2_test_time 0.2458648681640625
Test Epoch26 layer3 Acc 0.9010526315789473, AUC 0.9677445888519287, avg_entr 0.007479800842702389
ep26_l3_test_time 0.3163180351257324
Test Epoch26 layer4 Acc 0.9018421052631579, AUC 0.9682000875473022, avg_entr 0.00685339467599988
ep26_l4_test_time 0.3865220546722412
gc 0
Train Epoch27 Acc 0.9743833333333334 (116926/120000), AUC 0.9966834187507629
ep27_train_time 47.83955907821655
Test Epoch27 layer0 Acc 0.9068421052631579, AUC 0.9773311614990234, avg_entr 0.039350513368844986
ep27_l0_test_time 0.10293269157409668
Test Epoch27 layer1 Acc 0.9034210526315789, AUC 0.9686198234558105, avg_entr 0.01245813351124525
ep27_l1_test_time 0.17385649681091309
Test Epoch27 layer2 Acc 0.9007894736842105, AUC 0.9692983031272888, avg_entr 0.009093940258026123
ep27_l2_test_time 0.24617314338684082
Test Epoch27 layer3 Acc 0.901578947368421, AUC 0.967844545841217, avg_entr 0.007577712181955576
ep27_l3_test_time 0.3164045810699463
Test Epoch27 layer4 Acc 0.9013157894736842, AUC 0.9675101041793823, avg_entr 0.006946884095668793
ep27_l4_test_time 0.38643336296081543
gc 0
Train Epoch28 Acc 0.9743 (116916/120000), AUC 0.9967466592788696
ep28_train_time 47.850178241729736
Test Epoch28 layer0 Acc 0.9071052631578947, AUC 0.9773579835891724, avg_entr 0.038996074348688126
ep28_l0_test_time 0.1024467945098877
Test Epoch28 layer1 Acc 0.9036842105263158, AUC 0.9686216115951538, avg_entr 0.012300464324653149
ep28_l1_test_time 0.1733410358428955
Test Epoch28 layer2 Acc 0.9010526315789473, AUC 0.9692738652229309, avg_entr 0.008717458695173264
ep28_l2_test_time 0.24554014205932617
Test Epoch28 layer3 Acc 0.9013157894736842, AUC 0.9681737422943115, avg_entr 0.007219451945275068
ep28_l3_test_time 0.3171966075897217
Test Epoch28 layer4 Acc 0.9013157894736842, AUC 0.9679763317108154, avg_entr 0.006538545247167349
ep28_l4_test_time 0.38662004470825195
gc 0
Train Epoch29 Acc 0.9741916666666667 (116903/120000), AUC 0.9967314004898071
ep29_train_time 47.93530797958374
Test Epoch29 layer0 Acc 0.9071052631578947, AUC 0.9773550629615784, avg_entr 0.03893148899078369
ep29_l0_test_time 0.10294699668884277
Test Epoch29 layer1 Acc 0.9039473684210526, AUC 0.9686267375946045, avg_entr 0.01230171974748373
ep29_l1_test_time 0.17369389533996582
Test Epoch29 layer2 Acc 0.9013157894736842, AUC 0.9692864418029785, avg_entr 0.008784288540482521
ep29_l2_test_time 0.24567747116088867
Test Epoch29 layer3 Acc 0.9013157894736842, AUC 0.9677456021308899, avg_entr 0.007261991035193205
ep29_l3_test_time 0.31676745414733887
Test Epoch29 layer4 Acc 0.9010526315789473, AUC 0.9675458669662476, avg_entr 0.006548960693180561
ep29_l4_test_time 0.3867013454437256
gc 0
Train Epoch30 Acc 0.9742666666666666 (116912/120000), AUC 0.9968339204788208
ep30_train_time 48.05733323097229
Test Epoch30 layer0 Acc 0.9073684210526316, AUC 0.9773344993591309, avg_entr 0.03903021663427353
ep30_l0_test_time 0.10206103324890137
Test Epoch30 layer1 Acc 0.9034210526315789, AUC 0.9684228897094727, avg_entr 0.012282496318221092
ep30_l1_test_time 0.17299628257751465
Test Epoch30 layer2 Acc 0.9010526315789473, AUC 0.9691712856292725, avg_entr 0.009092572145164013
ep30_l2_test_time 0.24550437927246094
Test Epoch30 layer3 Acc 0.9018421052631579, AUC 0.9677348136901855, avg_entr 0.007519099861383438
ep30_l3_test_time 0.31540560722351074
Test Epoch30 layer4 Acc 0.901578947368421, AUC 0.9675553441047668, avg_entr 0.006850942503660917
ep30_l4_test_time 0.3858048915863037
gc 0
Train Epoch31 Acc 0.9744416666666667 (116933/120000), AUC 0.9967661499977112
ep31_train_time 48.059332847595215
Test Epoch31 layer0 Acc 0.9076315789473685, AUC 0.9773246645927429, avg_entr 0.038931578397750854
ep31_l0_test_time 0.1025705337524414
Test Epoch31 layer1 Acc 0.9034210526315789, AUC 0.9684903621673584, avg_entr 0.012268440797924995
ep31_l1_test_time 0.17355847358703613
Test Epoch31 layer2 Acc 0.9007894736842105, AUC 0.9690607190132141, avg_entr 0.008967933245003223
ep31_l2_test_time 0.24587225914001465
Test Epoch31 layer3 Acc 0.9013157894736842, AUC 0.9672971963882446, avg_entr 0.007385495118796825
ep31_l3_test_time 0.31603050231933594
Test Epoch31 layer4 Acc 0.9013157894736842, AUC 0.9671330451965332, avg_entr 0.0066971806809306145
ep31_l4_test_time 0.3862435817718506
gc 0
Train Epoch32 Acc 0.9744833333333334 (116938/120000), AUC 0.9968281984329224
ep32_train_time 47.984068870544434
Test Epoch32 layer0 Acc 0.9073684210526316, AUC 0.9773371815681458, avg_entr 0.038825489580631256
ep32_l0_test_time 0.10201406478881836
Test Epoch32 layer1 Acc 0.9034210526315789, AUC 0.9685962796211243, avg_entr 0.012222662568092346
ep32_l1_test_time 0.17307233810424805
Test Epoch32 layer2 Acc 0.9010526315789473, AUC 0.969321608543396, avg_entr 0.009135689586400986
ep32_l2_test_time 0.24554848670959473
Test Epoch32 layer3 Acc 0.9018421052631579, AUC 0.9681298732757568, avg_entr 0.007537138182669878
ep32_l3_test_time 0.31642675399780273
Test Epoch32 layer4 Acc 0.9018421052631579, AUC 0.9679564237594604, avg_entr 0.006863695103675127
ep32_l4_test_time 0.38632631301879883
gc 0
Train Epoch33 Acc 0.974425 (116931/120000), AUC 0.9968780279159546
ep33_train_time 47.911118030548096
Test Epoch33 layer0 Acc 0.9073684210526316, AUC 0.9773262739181519, avg_entr 0.0387846939265728
ep33_l0_test_time 0.10259246826171875
Test Epoch33 layer1 Acc 0.9034210526315789, AUC 0.9685871005058289, avg_entr 0.012209824286401272
ep33_l1_test_time 0.17330169677734375
Test Epoch33 layer2 Acc 0.9010526315789473, AUC 0.9694228768348694, avg_entr 0.008902179077267647
ep33_l2_test_time 0.2457268238067627
Test Epoch33 layer3 Acc 0.901578947368421, AUC 0.9679972529411316, avg_entr 0.007358189672231674
ep33_l3_test_time 0.31696200370788574
Test Epoch33 layer4 Acc 0.9010526315789473, AUC 0.9680562615394592, avg_entr 0.006694945506751537
ep33_l4_test_time 0.38631677627563477
gc 0
Train Epoch34 Acc 0.974525 (116943/120000), AUC 0.99677574634552
ep34_train_time 47.876097440719604
Test Epoch34 layer0 Acc 0.9073684210526316, AUC 0.9773348569869995, avg_entr 0.03867475315928459
ep34_l0_test_time 0.1022343635559082
Test Epoch34 layer1 Acc 0.9034210526315789, AUC 0.9684902429580688, avg_entr 0.012174254283308983
ep34_l1_test_time 0.17345142364501953
Test Epoch34 layer2 Acc 0.9010526315789473, AUC 0.9692497849464417, avg_entr 0.008926181122660637
ep34_l2_test_time 0.24600958824157715
Test Epoch34 layer3 Acc 0.901578947368421, AUC 0.9677713513374329, avg_entr 0.007363231852650642
ep34_l3_test_time 0.3163018226623535
Test Epoch34 layer4 Acc 0.9018421052631579, AUC 0.9678323268890381, avg_entr 0.0066930148750543594
ep34_l4_test_time 0.3867917060852051
gc 0
Train Epoch35 Acc 0.9746916666666666 (116963/120000), AUC 0.9967095851898193
ep35_train_time 47.99564814567566
Test Epoch35 layer0 Acc 0.9068421052631579, AUC 0.9773237705230713, avg_entr 0.03874477744102478
ep35_l0_test_time 0.10167574882507324
Test Epoch35 layer1 Acc 0.9034210526315789, AUC 0.9685397148132324, avg_entr 0.012166443280875683
ep35_l1_test_time 0.17345643043518066
Test Epoch35 layer2 Acc 0.9013157894736842, AUC 0.9692499041557312, avg_entr 0.00897314865142107
ep35_l2_test_time 0.24559974670410156
Test Epoch35 layer3 Acc 0.9018421052631579, AUC 0.9679917097091675, avg_entr 0.007409648038446903
ep35_l3_test_time 0.31674909591674805
Test Epoch35 layer4 Acc 0.9013157894736842, AUC 0.967828094959259, avg_entr 0.006746323779225349
ep35_l4_test_time 0.3868405818939209
gc 0
Train Epoch36 Acc 0.9745916666666666 (116951/120000), AUC 0.9967561364173889
ep36_train_time 48.061893939971924
Test Epoch36 layer0 Acc 0.9073684210526316, AUC 0.9773222208023071, avg_entr 0.03873346745967865
ep36_l0_test_time 0.10265374183654785
Test Epoch36 layer1 Acc 0.9034210526315789, AUC 0.9684737920761108, avg_entr 0.012196133844554424
ep36_l1_test_time 0.17407488822937012
Test Epoch36 layer2 Acc 0.9010526315789473, AUC 0.9691223502159119, avg_entr 0.009085345081984997
ep36_l2_test_time 0.24616169929504395
Test Epoch36 layer3 Acc 0.901578947368421, AUC 0.9675148725509644, avg_entr 0.007484369911253452
ep36_l3_test_time 0.3171498775482178
Test Epoch36 layer4 Acc 0.9013157894736842, AUC 0.9677112698554993, avg_entr 0.006814132444560528
ep36_l4_test_time 0.38695597648620605
gc 0
Train Epoch37 Acc 0.9748333333333333 (116980/120000), AUC 0.9967728853225708
ep37_train_time 48.11523628234863
Test Epoch37 layer0 Acc 0.9071052631578947, AUC 0.9773194789886475, avg_entr 0.038704875856637955
ep37_l0_test_time 0.10270500183105469
Test Epoch37 layer1 Acc 0.9034210526315789, AUC 0.9686020612716675, avg_entr 0.012181723490357399
ep37_l1_test_time 0.1739790439605713
Test Epoch37 layer2 Acc 0.901578947368421, AUC 0.9692897200584412, avg_entr 0.009008235298097134
ep37_l2_test_time 0.24611473083496094
Test Epoch37 layer3 Acc 0.9018421052631579, AUC 0.9678581953048706, avg_entr 0.007446557283401489
ep37_l3_test_time 0.31716132164001465
Test Epoch37 layer4 Acc 0.9018421052631579, AUC 0.9679546356201172, avg_entr 0.006788430269807577
ep37_l4_test_time 0.3863523006439209
gc 0
Train Epoch38 Acc 0.9746416666666666 (116957/120000), AUC 0.9967567324638367
ep38_train_time 48.058436155319214
Test Epoch38 layer0 Acc 0.9071052631578947, AUC 0.9773228764533997, avg_entr 0.03875117003917694
ep38_l0_test_time 0.10262799263000488
Test Epoch38 layer1 Acc 0.9034210526315789, AUC 0.9684733152389526, avg_entr 0.012179502286016941
ep38_l1_test_time 0.1737384796142578
Test Epoch38 layer2 Acc 0.901578947368421, AUC 0.9691981673240662, avg_entr 0.009054411202669144
ep38_l2_test_time 0.24601411819458008
Test Epoch38 layer3 Acc 0.901578947368421, AUC 0.9677027463912964, avg_entr 0.007492267061024904
ep38_l3_test_time 0.31702446937561035
Test Epoch38 layer4 Acc 0.901578947368421, AUC 0.9678313732147217, avg_entr 0.006844604387879372
ep38_l4_test_time 0.38652610778808594
gc 0
Train Epoch39 Acc 0.9746583333333333 (116959/120000), AUC 0.996749997138977
ep39_train_time 48.087913513183594
Test Epoch39 layer0 Acc 0.9073684210526316, AUC 0.9773224592208862, avg_entr 0.038604170083999634
ep39_l0_test_time 0.10213184356689453
Test Epoch39 layer1 Acc 0.9034210526315789, AUC 0.968513011932373, avg_entr 0.012141500599682331
ep39_l1_test_time 0.17320704460144043
Test Epoch39 layer2 Acc 0.901578947368421, AUC 0.969180703163147, avg_entr 0.008950438350439072
ep39_l2_test_time 0.24595403671264648
Test Epoch39 layer3 Acc 0.9018421052631579, AUC 0.9677647352218628, avg_entr 0.0073853544890880585
ep39_l3_test_time 0.31662726402282715
Test Epoch39 layer4 Acc 0.9018421052631579, AUC 0.9679373502731323, avg_entr 0.006722334306687117
ep39_l4_test_time 0.387423038482666
gc 0
Train Epoch40 Acc 0.9746833333333333 (116962/120000), AUC 0.9968440532684326
ep40_train_time 48.175124645233154
Test Epoch40 layer0 Acc 0.9071052631578947, AUC 0.9773250818252563, avg_entr 0.03862082213163376
ep40_l0_test_time 0.10263705253601074
Test Epoch40 layer1 Acc 0.9034210526315789, AUC 0.9684790968894958, avg_entr 0.012148535810410976
ep40_l1_test_time 0.17403745651245117
Test Epoch40 layer2 Acc 0.901578947368421, AUC 0.9691956043243408, avg_entr 0.008973401039838791
ep40_l2_test_time 0.2465829849243164
Test Epoch40 layer3 Acc 0.9018421052631579, AUC 0.9677420258522034, avg_entr 0.007408272009342909
ep40_l3_test_time 0.31575822830200195
Test Epoch40 layer4 Acc 0.9018421052631579, AUC 0.9678432941436768, avg_entr 0.006756406277418137
ep40_l4_test_time 0.38705921173095703
gc 0
Train Epoch41 Acc 0.9745666666666667 (116948/120000), AUC 0.9967417120933533
ep41_train_time 48.0701060295105
Test Epoch41 layer0 Acc 0.9071052631578947, AUC 0.97732013463974, avg_entr 0.03861067071557045
ep41_l0_test_time 0.10270333290100098
Test Epoch41 layer1 Acc 0.9034210526315789, AUC 0.9685556888580322, avg_entr 0.012126379646360874
ep41_l1_test_time 0.1736469268798828
Test Epoch41 layer2 Acc 0.9013157894736842, AUC 0.969200611114502, avg_entr 0.008924218825995922
ep41_l2_test_time 0.2456216812133789
Test Epoch41 layer3 Acc 0.9018421052631579, AUC 0.9677344560623169, avg_entr 0.007368043996393681
ep41_l3_test_time 0.31682658195495605
Test Epoch41 layer4 Acc 0.9013157894736842, AUC 0.9678008556365967, avg_entr 0.006711540278047323
ep41_l4_test_time 0.3870410919189453
gc 0
Train Epoch42 Acc 0.974675 (116961/120000), AUC 0.996802806854248
ep42_train_time 47.98672938346863
Test Epoch42 layer0 Acc 0.9071052631578947, AUC 0.9773210287094116, avg_entr 0.03863215446472168
ep42_l0_test_time 0.10176968574523926
Test Epoch42 layer1 Acc 0.9034210526315789, AUC 0.9685043096542358, avg_entr 0.012127671390771866
ep42_l1_test_time 0.17348623275756836
Test Epoch42 layer2 Acc 0.901578947368421, AUC 0.969180166721344, avg_entr 0.00892701093107462
ep42_l2_test_time 0.2451343536376953
Test Epoch42 layer3 Acc 0.9018421052631579, AUC 0.9677141904830933, avg_entr 0.00737522728741169
ep42_l3_test_time 0.31621432304382324
Test Epoch42 layer4 Acc 0.9018421052631579, AUC 0.9677826166152954, avg_entr 0.0067213899455964565
ep42_l4_test_time 0.38633084297180176
gc 0
Train Epoch43 Acc 0.9749083333333334 (116989/120000), AUC 0.9967638254165649
ep43_train_time 48.028424978256226
Test Epoch43 layer0 Acc 0.9073684210526316, AUC 0.9773189425468445, avg_entr 0.03858540952205658
ep43_l0_test_time 0.10167765617370605
Test Epoch43 layer1 Acc 0.9034210526315789, AUC 0.9684993028640747, avg_entr 0.012126395478844643
ep43_l1_test_time 0.1742701530456543
Test Epoch43 layer2 Acc 0.901578947368421, AUC 0.9692057371139526, avg_entr 0.008904996328055859
ep43_l2_test_time 0.24566364288330078
Test Epoch43 layer3 Acc 0.9018421052631579, AUC 0.9677159786224365, avg_entr 0.007362563628703356
ep43_l3_test_time 0.31699132919311523
Test Epoch43 layer4 Acc 0.901578947368421, AUC 0.9678488969802856, avg_entr 0.006708150263875723
ep43_l4_test_time 0.38615942001342773
gc 0
Train Epoch44 Acc 0.9747083333333333 (116965/120000), AUC 0.9967800378799438
ep44_train_time 48.00100016593933
Test Epoch44 layer0 Acc 0.9068421052631579, AUC 0.9773191809654236, avg_entr 0.038619209080934525
ep44_l0_test_time 0.10228133201599121
Test Epoch44 layer1 Acc 0.9034210526315789, AUC 0.9684908390045166, avg_entr 0.012128284201025963
ep44_l1_test_time 0.17337465286254883
Test Epoch44 layer2 Acc 0.901578947368421, AUC 0.9691862463951111, avg_entr 0.008927371352910995
ep44_l2_test_time 0.24534964561462402
Test Epoch44 layer3 Acc 0.9018421052631579, AUC 0.9677176475524902, avg_entr 0.007380655966699123
ep44_l3_test_time 0.31647539138793945
Test Epoch44 layer4 Acc 0.9018421052631579, AUC 0.9678435325622559, avg_entr 0.006726592313498259
ep44_l4_test_time 0.3873906135559082
gc 0
Train Epoch45 Acc 0.974675 (116961/120000), AUC 0.9967601299285889
ep45_train_time 48.02739095687866
Test Epoch45 layer0 Acc 0.9068421052631579, AUC 0.9773199558258057, avg_entr 0.03859278932213783
ep45_l0_test_time 0.10206365585327148
Test Epoch45 layer1 Acc 0.9034210526315789, AUC 0.9684913158416748, avg_entr 0.012126540765166283
ep45_l1_test_time 0.17343807220458984
Test Epoch45 layer2 Acc 0.901578947368421, AUC 0.9691747426986694, avg_entr 0.008919007144868374
ep45_l2_test_time 0.2455463409423828
Test Epoch45 layer3 Acc 0.9018421052631579, AUC 0.9677188396453857, avg_entr 0.007374762557446957
ep45_l3_test_time 0.3158864974975586
Test Epoch45 layer4 Acc 0.901578947368421, AUC 0.9678327441215515, avg_entr 0.00672102440148592
ep45_l4_test_time 0.3862760066986084
gc 0
Train Epoch46 Acc 0.9750333333333333 (117004/120000), AUC 0.9967933297157288
ep46_train_time 48.012587547302246
Test Epoch46 layer0 Acc 0.9071052631578947, AUC 0.9773200154304504, avg_entr 0.03859488666057587
ep46_l0_test_time 0.10219073295593262
Test Epoch46 layer1 Acc 0.9034210526315789, AUC 0.9684954285621643, avg_entr 0.012127389200031757
ep46_l1_test_time 0.1731863021850586
Test Epoch46 layer2 Acc 0.901578947368421, AUC 0.9691917896270752, avg_entr 0.008919469080865383
ep46_l2_test_time 0.24544310569763184
Test Epoch46 layer3 Acc 0.9018421052631579, AUC 0.967742919921875, avg_entr 0.007369349244982004
ep46_l3_test_time 0.3165435791015625
Test Epoch46 layer4 Acc 0.9018421052631579, AUC 0.9678675532341003, avg_entr 0.006714521907269955
ep46_l4_test_time 0.38649606704711914
gc 0
Train Epoch47 Acc 0.9744833333333334 (116938/120000), AUC 0.9967929720878601
ep47_train_time 47.966902017593384
Test Epoch47 layer0 Acc 0.9073684210526316, AUC 0.9773194193840027, avg_entr 0.038566313683986664
ep47_l0_test_time 0.10293149948120117
Test Epoch47 layer1 Acc 0.9034210526315789, AUC 0.9684907793998718, avg_entr 0.012128292582929134
ep47_l1_test_time 0.17447614669799805
Test Epoch47 layer2 Acc 0.901578947368421, AUC 0.9691872596740723, avg_entr 0.008919860236346722
ep47_l2_test_time 0.24565839767456055
Test Epoch47 layer3 Acc 0.9018421052631579, AUC 0.9677131175994873, avg_entr 0.007374393288046122
ep47_l3_test_time 0.3160724639892578
Test Epoch47 layer4 Acc 0.9018421052631579, AUC 0.9678734540939331, avg_entr 0.006723852828145027
ep47_l4_test_time 0.38892149925231934
gc 0
Train Epoch48 Acc 0.9747583333333333 (116971/120000), AUC 0.9967570304870605
ep48_train_time 48.02061605453491
Test Epoch48 layer0 Acc 0.9071052631578947, AUC 0.977317750453949, avg_entr 0.03856907784938812
ep48_l0_test_time 0.10361361503601074
Test Epoch48 layer1 Acc 0.9034210526315789, AUC 0.9684920310974121, avg_entr 0.012127137742936611
ep48_l1_test_time 0.17495274543762207
Test Epoch48 layer2 Acc 0.901578947368421, AUC 0.9691892266273499, avg_entr 0.008922380395233631
ep48_l2_test_time 0.24585366249084473
Test Epoch48 layer3 Acc 0.9018421052631579, AUC 0.9677088260650635, avg_entr 0.007374854758381844
ep48_l3_test_time 0.3173537254333496
Test Epoch48 layer4 Acc 0.9018421052631579, AUC 0.9678342938423157, avg_entr 0.006722612772136927
ep48_l4_test_time 0.38678407669067383
gc 0
Train Epoch49 Acc 0.9746833333333333 (116962/120000), AUC 0.9968461394309998
ep49_train_time 48.06344676017761
Test Epoch49 layer0 Acc 0.9071052631578947, AUC 0.9773176908493042, avg_entr 0.03857176750898361
ep49_l0_test_time 0.10245776176452637
Test Epoch49 layer1 Acc 0.9034210526315789, AUC 0.9684901833534241, avg_entr 0.012126067653298378
ep49_l1_test_time 0.17322778701782227
Test Epoch49 layer2 Acc 0.901578947368421, AUC 0.9691965579986572, avg_entr 0.00892004556953907
ep49_l2_test_time 0.2463376522064209
Test Epoch49 layer3 Acc 0.9018421052631579, AUC 0.9677081108093262, avg_entr 0.007370703388005495
ep49_l3_test_time 0.3174114227294922
Test Epoch49 layer4 Acc 0.9018421052631579, AUC 0.9678018093109131, avg_entr 0.006717716809362173
ep49_l4_test_time 0.3869938850402832
Best AUC 0.9799442887306213
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train+valid_time 2462.327095746994
Start Testing
Load ckpt at ckpt/ag_news_transformeral_l5_pad100//ag_news_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.9226315789473685, AUC 0.9845708608627319, avg_entr 0.10677725076675415
ep49_l0_test_time 0.1003119945526123
Test Epoch49 layer1 Acc 0.9252631578947368, AUC 0.9849033355712891, avg_entr 0.04404604434967041
ep49_l1_test_time 0.17372846603393555
Test Epoch49 layer2 Acc 0.9268421052631579, AUC 0.9850168228149414, avg_entr 0.0376054085791111
ep49_l2_test_time 0.24559950828552246
Test Epoch49 layer3 Acc 0.9260526315789473, AUC 0.9851776361465454, avg_entr 0.03496024012565613
ep49_l3_test_time 0.31705307960510254
Test Epoch49 layer4 Acc 0.9265789473684211, AUC 0.9849200248718262, avg_entr 0.03274259343743324
ep49_l4_test_time 0.38680410385131836
