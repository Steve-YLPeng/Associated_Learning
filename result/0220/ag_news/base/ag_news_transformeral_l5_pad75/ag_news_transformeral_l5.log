total count words 102019
vocab size 30000
found 26754 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13672292
init_time 24.51811933517456
Start Training
gc 0
Train Epoch0 Acc 0.6360333333333333 (76324/120000), AUC 0.8602018356323242
ep0_train_time 37.69165515899658
Test Epoch0 layer0 Acc 0.905, AUC 0.9742984771728516, avg_entr 0.22773055732250214
ep0_l0_test_time 0.08370256423950195
Save ckpt to ckpt/ag_news_transformeral_l5_pad75//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9076315789473685, AUC 0.9761025309562683, avg_entr 0.1575550138950348
ep0_l1_test_time 0.13466930389404297
Save ckpt to ckpt/ag_news_transformeral_l5_pad75//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.9060526315789473, AUC 0.9759553074836731, avg_entr 0.15229694545269012
ep0_l2_test_time 0.19037342071533203
Test Epoch0 layer3 Acc 0.9044736842105263, AUC 0.9757851362228394, avg_entr 0.15741033852100372
ep0_l3_test_time 0.24226951599121094
Test Epoch0 layer4 Acc 0.8992105263157895, AUC 0.9756666421890259, avg_entr 0.16772383451461792
ep0_l4_test_time 0.29653072357177734
gc 0
Train Epoch1 Acc 0.9257416666666667 (111089/120000), AUC 0.9826124906539917
ep1_train_time 37.50013208389282
Test Epoch1 layer0 Acc 0.911578947368421, AUC 0.9772897958755493, avg_entr 0.13752560317516327
ep1_l0_test_time 0.08097410202026367
Save ckpt to ckpt/ag_news_transformeral_l5_pad75//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.9136842105263158, AUC 0.9792134165763855, avg_entr 0.07928267121315002
ep1_l1_test_time 0.135040283203125
Save ckpt to ckpt/ag_news_transformeral_l5_pad75//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.9136842105263158, AUC 0.9779743552207947, avg_entr 0.06542807817459106
ep1_l2_test_time 0.18934869766235352
Test Epoch1 layer3 Acc 0.9131578947368421, AUC 0.9780213832855225, avg_entr 0.0607186034321785
ep1_l3_test_time 0.2412867546081543
Test Epoch1 layer4 Acc 0.9142105263157895, AUC 0.9783700704574585, avg_entr 0.05244574323296547
ep1_l4_test_time 0.29410600662231445
gc 0
Train Epoch2 Acc 0.9388583333333334 (112663/120000), AUC 0.9873360395431519
ep2_train_time 37.48087406158447
Test Epoch2 layer0 Acc 0.9128947368421053, AUC 0.9784849882125854, avg_entr 0.10770615190267563
ep2_l0_test_time 0.08152103424072266
Test Epoch2 layer1 Acc 0.9128947368421053, AUC 0.9801402688026428, avg_entr 0.04438658058643341
ep2_l1_test_time 0.1348414421081543
Save ckpt to ckpt/ag_news_transformeral_l5_pad75//ag_news_transformeral_l5.pt  ,ep 2
Test Epoch2 layer2 Acc 0.9131578947368421, AUC 0.9796767234802246, avg_entr 0.036684609949588776
ep2_l2_test_time 0.19026756286621094
Test Epoch2 layer3 Acc 0.9136842105263158, AUC 0.9799661040306091, avg_entr 0.034925200045108795
ep2_l3_test_time 0.24247241020202637
Test Epoch2 layer4 Acc 0.915, AUC 0.9801980257034302, avg_entr 0.03246690332889557
ep2_l4_test_time 0.2955145835876465
Save ckpt to ckpt/ag_news_transformeral_l5_pad75//ag_news_transformeral_l5.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.9463333333333334 (113560/120000), AUC 0.9893823266029358
ep3_train_time 37.55346393585205
Test Epoch3 layer0 Acc 0.9073684210526316, AUC 0.9785118699073792, avg_entr 0.0930299386382103
ep3_l0_test_time 0.08040785789489746
Test Epoch3 layer1 Acc 0.9102631578947369, AUC 0.9764512181282043, avg_entr 0.032343391329050064
ep3_l1_test_time 0.13361740112304688
Test Epoch3 layer2 Acc 0.9102631578947369, AUC 0.9761095643043518, avg_entr 0.02622494287788868
ep3_l2_test_time 0.1873171329498291
Test Epoch3 layer3 Acc 0.9094736842105263, AUC 0.9773937463760376, avg_entr 0.02420509047806263
ep3_l3_test_time 0.24082064628601074
Test Epoch3 layer4 Acc 0.9094736842105263, AUC 0.9762452840805054, avg_entr 0.021790441125631332
ep3_l4_test_time 0.2927849292755127
gc 0
Train Epoch4 Acc 0.9520416666666667 (114245/120000), AUC 0.9906719326972961
ep4_train_time 37.59090518951416
Test Epoch4 layer0 Acc 0.911578947368421, AUC 0.9784275889396667, avg_entr 0.08075031638145447
ep4_l0_test_time 0.08101677894592285
Test Epoch4 layer1 Acc 0.908157894736842, AUC 0.9776273965835571, avg_entr 0.028699437156319618
ep4_l1_test_time 0.1338660717010498
Test Epoch4 layer2 Acc 0.9084210526315789, AUC 0.9779584407806396, avg_entr 0.022352006286382675
ep4_l2_test_time 0.18769526481628418
Test Epoch4 layer3 Acc 0.9086842105263158, AUC 0.9781033396720886, avg_entr 0.020439643412828445
ep4_l3_test_time 0.24123358726501465
Test Epoch4 layer4 Acc 0.9084210526315789, AUC 0.9745801091194153, avg_entr 0.018454495817422867
ep4_l4_test_time 0.2942318916320801
gc 0
Train Epoch5 Acc 0.9557333333333333 (114688/120000), AUC 0.9918090105056763
ep5_train_time 37.53295373916626
Test Epoch5 layer0 Acc 0.9107894736842105, AUC 0.9783608913421631, avg_entr 0.0752703994512558
ep5_l0_test_time 0.08136439323425293
Test Epoch5 layer1 Acc 0.9097368421052632, AUC 0.9760849475860596, avg_entr 0.026254035532474518
ep5_l1_test_time 0.13394761085510254
Test Epoch5 layer2 Acc 0.9086842105263158, AUC 0.9763667583465576, avg_entr 0.02055024914443493
ep5_l2_test_time 0.1871025562286377
Test Epoch5 layer3 Acc 0.9078947368421053, AUC 0.978117823600769, avg_entr 0.018849318847060204
ep5_l3_test_time 0.2412114143371582
Test Epoch5 layer4 Acc 0.9078947368421053, AUC 0.9758269786834717, avg_entr 0.01739603653550148
ep5_l4_test_time 0.2940237522125244
gc 0
Train Epoch6 Acc 0.9579666666666666 (114956/120000), AUC 0.9923529028892517
ep6_train_time 37.50201773643494
Test Epoch6 layer0 Acc 0.9092105263157895, AUC 0.9782103300094604, avg_entr 0.06880688667297363
ep6_l0_test_time 0.08138632774353027
Test Epoch6 layer1 Acc 0.9076315789473685, AUC 0.9754258990287781, avg_entr 0.02482231706380844
ep6_l1_test_time 0.13401532173156738
Test Epoch6 layer2 Acc 0.9073684210526316, AUC 0.9764689207077026, avg_entr 0.019857218489050865
ep6_l2_test_time 0.18703389167785645
Test Epoch6 layer3 Acc 0.9073684210526316, AUC 0.976367712020874, avg_entr 0.018291868269443512
ep6_l3_test_time 0.2401714324951172
Test Epoch6 layer4 Acc 0.9073684210526316, AUC 0.9746809005737305, avg_entr 0.017411639913916588
ep6_l4_test_time 0.29258108139038086
gc 0
Train Epoch7 Acc 0.962525 (115503/120000), AUC 0.9936857223510742
ep7_train_time 37.527995586395264
Test Epoch7 layer0 Acc 0.9105263157894737, AUC 0.9781218767166138, avg_entr 0.06770503520965576
ep7_l0_test_time 0.08124852180480957
Test Epoch7 layer1 Acc 0.9084210526315789, AUC 0.9727531671524048, avg_entr 0.02336057275533676
ep7_l1_test_time 0.13365960121154785
Test Epoch7 layer2 Acc 0.9086842105263158, AUC 0.9743421673774719, avg_entr 0.016558406874537468
ep7_l2_test_time 0.1872572898864746
Test Epoch7 layer3 Acc 0.9092105263157895, AUC 0.9769147634506226, avg_entr 0.01468882616609335
ep7_l3_test_time 0.24021673202514648
Test Epoch7 layer4 Acc 0.9089473684210526, AUC 0.9768685102462769, avg_entr 0.013117259368300438
ep7_l4_test_time 0.2916743755340576
gc 0
Train Epoch8 Acc 0.9644333333333334 (115732/120000), AUC 0.994097113609314
ep8_train_time 37.523722410202026
Test Epoch8 layer0 Acc 0.9113157894736842, AUC 0.9780469536781311, avg_entr 0.06350643187761307
ep8_l0_test_time 0.08099699020385742
Test Epoch8 layer1 Acc 0.9063157894736842, AUC 0.9727616906166077, avg_entr 0.023771580308675766
ep8_l1_test_time 0.13408660888671875
Test Epoch8 layer2 Acc 0.905, AUC 0.9738908410072327, avg_entr 0.017252834513783455
ep8_l2_test_time 0.18771767616271973
Test Epoch8 layer3 Acc 0.9044736842105263, AUC 0.9741495847702026, avg_entr 0.015652073547244072
ep8_l3_test_time 0.24112153053283691
Test Epoch8 layer4 Acc 0.9042105263157895, AUC 0.9714143872261047, avg_entr 0.014326510950922966
ep8_l4_test_time 0.29233217239379883
gc 0
Train Epoch9 Acc 0.9654666666666667 (115856/120000), AUC 0.994318962097168
ep9_train_time 37.52416157722473
Test Epoch9 layer0 Acc 0.9092105263157895, AUC 0.9777684211730957, avg_entr 0.060466062277555466
ep9_l0_test_time 0.08058476448059082
Test Epoch9 layer1 Acc 0.9060526315789473, AUC 0.9725528955459595, avg_entr 0.022968444973230362
ep9_l1_test_time 0.1332228183746338
Test Epoch9 layer2 Acc 0.905, AUC 0.9746299386024475, avg_entr 0.016725579276680946
ep9_l2_test_time 0.18688416481018066
Test Epoch9 layer3 Acc 0.905, AUC 0.9766026735305786, avg_entr 0.015137862414121628
ep9_l3_test_time 0.24074387550354004
Test Epoch9 layer4 Acc 0.9055263157894737, AUC 0.9744055271148682, avg_entr 0.013353275135159492
ep9_l4_test_time 0.29205322265625
gc 0
Train Epoch10 Acc 0.96685 (116022/120000), AUC 0.9946503639221191
ep10_train_time 37.436896085739136
Test Epoch10 layer0 Acc 0.9092105263157895, AUC 0.9776280522346497, avg_entr 0.05739884451031685
ep10_l0_test_time 0.08111214637756348
Test Epoch10 layer1 Acc 0.9034210526315789, AUC 0.9708356857299805, avg_entr 0.02127200923860073
ep10_l1_test_time 0.13370037078857422
Test Epoch10 layer2 Acc 0.901578947368421, AUC 0.9717461466789246, avg_entr 0.015233567915856838
ep10_l2_test_time 0.18713617324829102
Test Epoch10 layer3 Acc 0.9010526315789473, AUC 0.9724386930465698, avg_entr 0.013831684365868568
ep10_l3_test_time 0.23980093002319336
Test Epoch10 layer4 Acc 0.9013157894736842, AUC 0.9711936116218567, avg_entr 0.012133232317864895
ep10_l4_test_time 0.2916688919067383
gc 0
Train Epoch11 Acc 0.9692333333333333 (116308/120000), AUC 0.9952987432479858
ep11_train_time 37.43652296066284
Test Epoch11 layer0 Acc 0.9092105263157895, AUC 0.9775780439376831, avg_entr 0.05653240159153938
ep11_l0_test_time 0.08079314231872559
Test Epoch11 layer1 Acc 0.9084210526315789, AUC 0.9698520302772522, avg_entr 0.020999131724238396
ep11_l1_test_time 0.1375124454498291
Test Epoch11 layer2 Acc 0.9073684210526316, AUC 0.9723187685012817, avg_entr 0.014867115765810013
ep11_l2_test_time 0.18774056434631348
Test Epoch11 layer3 Acc 0.9073684210526316, AUC 0.9723423719406128, avg_entr 0.012998471967875957
ep11_l3_test_time 0.24121642112731934
Test Epoch11 layer4 Acc 0.9084210526315789, AUC 0.9721909165382385, avg_entr 0.011577166616916656
ep11_l4_test_time 0.29166483879089355
gc 0
Train Epoch12 Acc 0.969875 (116385/120000), AUC 0.9955810308456421
ep12_train_time 37.48706674575806
Test Epoch12 layer0 Acc 0.9078947368421053, AUC 0.9775330424308777, avg_entr 0.05493347719311714
ep12_l0_test_time 0.08205628395080566
Test Epoch12 layer1 Acc 0.9055263157894737, AUC 0.9704411029815674, avg_entr 0.02074761502444744
ep12_l1_test_time 0.13410139083862305
Test Epoch12 layer2 Acc 0.9034210526315789, AUC 0.9723794460296631, avg_entr 0.013911200687289238
ep12_l2_test_time 0.1868114471435547
Test Epoch12 layer3 Acc 0.9031578947368422, AUC 0.9730372428894043, avg_entr 0.01218501664698124
ep12_l3_test_time 0.24066734313964844
Test Epoch12 layer4 Acc 0.9031578947368422, AUC 0.9728201627731323, avg_entr 0.011246862821280956
ep12_l4_test_time 0.2918052673339844
gc 0
Train Epoch13 Acc 0.970425 (116451/120000), AUC 0.9956858158111572
ep13_train_time 37.623127937316895
Test Epoch13 layer0 Acc 0.9078947368421053, AUC 0.9774020314216614, avg_entr 0.05293653905391693
ep13_l0_test_time 0.08183479309082031
Test Epoch13 layer1 Acc 0.9063157894736842, AUC 0.9703413248062134, avg_entr 0.01973850652575493
ep13_l1_test_time 0.13373923301696777
Test Epoch13 layer2 Acc 0.9063157894736842, AUC 0.9718323349952698, avg_entr 0.013743392191827297
ep13_l2_test_time 0.18720507621765137
Test Epoch13 layer3 Acc 0.9057894736842105, AUC 0.9711953401565552, avg_entr 0.012060611508786678
ep13_l3_test_time 0.24108338356018066
Test Epoch13 layer4 Acc 0.9047368421052632, AUC 0.9687443375587463, avg_entr 0.010866205208003521
ep13_l4_test_time 0.2929189205169678
gc 0
Train Epoch14 Acc 0.9710833333333333 (116530/120000), AUC 0.9956680536270142
ep14_train_time 37.476219177246094
Test Epoch14 layer0 Acc 0.9078947368421053, AUC 0.9774228930473328, avg_entr 0.05099334940314293
ep14_l0_test_time 0.08031606674194336
Test Epoch14 layer1 Acc 0.9036842105263158, AUC 0.9699175357818604, avg_entr 0.019670335575938225
ep14_l1_test_time 0.13379979133605957
Test Epoch14 layer2 Acc 0.9026315789473685, AUC 0.9703696966171265, avg_entr 0.012454492971301079
ep14_l2_test_time 0.18733739852905273
Test Epoch14 layer3 Acc 0.9023684210526316, AUC 0.9703229665756226, avg_entr 0.010598313994705677
ep14_l3_test_time 0.24103236198425293
Test Epoch14 layer4 Acc 0.9026315789473685, AUC 0.9690377116203308, avg_entr 0.009645151905715466
ep14_l4_test_time 0.29155850410461426
gc 0
Train Epoch15 Acc 0.97255 (116706/120000), AUC 0.996005654335022
ep15_train_time 37.647655963897705
Test Epoch15 layer0 Acc 0.9097368421052632, AUC 0.9774693250656128, avg_entr 0.049384698271751404
ep15_l0_test_time 0.08059811592102051
Test Epoch15 layer1 Acc 0.9052631578947369, AUC 0.9690792560577393, avg_entr 0.01892160438001156
ep15_l1_test_time 0.13300347328186035
Test Epoch15 layer2 Acc 0.9047368421052632, AUC 0.9697344899177551, avg_entr 0.012961309403181076
ep15_l2_test_time 0.18741250038146973
Test Epoch15 layer3 Acc 0.9047368421052632, AUC 0.9685202836990356, avg_entr 0.011097624897956848
ep15_l3_test_time 0.2407972812652588
Test Epoch15 layer4 Acc 0.905, AUC 0.9660826921463013, avg_entr 0.01017080433666706
ep15_l4_test_time 0.2933957576751709
gc 0
Train Epoch16 Acc 0.972575 (116709/120000), AUC 0.9962669610977173
ep16_train_time 37.44646716117859
Test Epoch16 layer0 Acc 0.9092105263157895, AUC 0.9774371385574341, avg_entr 0.048154767602682114
ep16_l0_test_time 0.08101487159729004
Test Epoch16 layer1 Acc 0.9057894736842105, AUC 0.9692848920822144, avg_entr 0.018796147778630257
ep16_l1_test_time 0.1338639259338379
Test Epoch16 layer2 Acc 0.9044736842105263, AUC 0.970717191696167, avg_entr 0.012703885324299335
ep16_l2_test_time 0.1870715618133545
Test Epoch16 layer3 Acc 0.9057894736842105, AUC 0.9692658185958862, avg_entr 0.010904617607593536
ep16_l3_test_time 0.24039006233215332
Test Epoch16 layer4 Acc 0.9052631578947369, AUC 0.9667856097221375, avg_entr 0.010022981092333794
ep16_l4_test_time 0.29215502738952637
gc 0
Train Epoch17 Acc 0.9732166666666666 (116786/120000), AUC 0.9961627721786499
ep17_train_time 37.50242733955383
Test Epoch17 layer0 Acc 0.9078947368421053, AUC 0.9773662686347961, avg_entr 0.04718891158699989
ep17_l0_test_time 0.08074355125427246
Test Epoch17 layer1 Acc 0.9055263157894737, AUC 0.9693317413330078, avg_entr 0.018560444936156273
ep17_l1_test_time 0.13354253768920898
Test Epoch17 layer2 Acc 0.9028947368421053, AUC 0.9699919819831848, avg_entr 0.012150360271334648
ep17_l2_test_time 0.1870579719543457
Test Epoch17 layer3 Acc 0.9028947368421053, AUC 0.9677925109863281, avg_entr 0.010372208431363106
ep17_l3_test_time 0.23934531211853027
Test Epoch17 layer4 Acc 0.9021052631578947, AUC 0.9665015935897827, avg_entr 0.009284078143537045
ep17_l4_test_time 0.2912712097167969
gc 0
Train Epoch18 Acc 0.9732666666666666 (116792/120000), AUC 0.9960190653800964
ep18_train_time 37.51687955856323
Test Epoch18 layer0 Acc 0.9073684210526316, AUC 0.9773298501968384, avg_entr 0.045755863189697266
ep18_l0_test_time 0.08042788505554199
Test Epoch18 layer1 Acc 0.9055263157894737, AUC 0.9693004488945007, avg_entr 0.017739281058311462
ep18_l1_test_time 0.13384127616882324
Test Epoch18 layer2 Acc 0.9034210526315789, AUC 0.9705737233161926, avg_entr 0.01163100078701973
ep18_l2_test_time 0.18758344650268555
Test Epoch18 layer3 Acc 0.9042105263157895, AUC 0.9692640900611877, avg_entr 0.010002738796174526
ep18_l3_test_time 0.2414720058441162
Test Epoch18 layer4 Acc 0.905, AUC 0.9694838523864746, avg_entr 0.00891838874667883
ep18_l4_test_time 0.2940821647644043
gc 0
Train Epoch19 Acc 0.9742083333333333 (116905/120000), AUC 0.9964033365249634
ep19_train_time 37.52049136161804
Test Epoch19 layer0 Acc 0.9086842105263158, AUC 0.9773751497268677, avg_entr 0.044682469218969345
ep19_l0_test_time 0.0810694694519043
Test Epoch19 layer1 Acc 0.9052631578947369, AUC 0.9686675667762756, avg_entr 0.017330527305603027
ep19_l1_test_time 0.13386917114257812
Test Epoch19 layer2 Acc 0.9047368421052632, AUC 0.9691135883331299, avg_entr 0.011449411511421204
ep19_l2_test_time 0.1866612434387207
Test Epoch19 layer3 Acc 0.9039473684210526, AUC 0.9678910970687866, avg_entr 0.009519231505692005
ep19_l3_test_time 0.24012970924377441
Test Epoch19 layer4 Acc 0.9042105263157895, AUC 0.9654393792152405, avg_entr 0.008830524049699306
ep19_l4_test_time 0.29148387908935547
gc 0
Train Epoch20 Acc 0.974125 (116895/120000), AUC 0.9962990283966064
ep20_train_time 37.490315437316895
Test Epoch20 layer0 Acc 0.9076315789473685, AUC 0.9773346185684204, avg_entr 0.044099751859903336
ep20_l0_test_time 0.08100724220275879
Test Epoch20 layer1 Acc 0.9052631578947369, AUC 0.9687187671661377, avg_entr 0.016987891867756844
ep20_l1_test_time 0.13359522819519043
Test Epoch20 layer2 Acc 0.9026315789473685, AUC 0.9695066213607788, avg_entr 0.011310650035738945
ep20_l2_test_time 0.18695545196533203
Test Epoch20 layer3 Acc 0.9026315789473685, AUC 0.9671728014945984, avg_entr 0.009618164971470833
ep20_l3_test_time 0.240753173828125
Test Epoch20 layer4 Acc 0.9023684210526316, AUC 0.9639565944671631, avg_entr 0.008339940570294857
ep20_l4_test_time 0.2913172245025635
gc 0
Train Epoch21 Acc 0.9742333333333333 (116908/120000), AUC 0.9962468147277832
ep21_train_time 37.44935727119446
Test Epoch21 layer0 Acc 0.9076315789473685, AUC 0.9774230718612671, avg_entr 0.04269230738282204
ep21_l0_test_time 0.08104205131530762
Test Epoch21 layer1 Acc 0.9052631578947369, AUC 0.9687535762786865, avg_entr 0.016668425872921944
ep21_l1_test_time 0.13386821746826172
Test Epoch21 layer2 Acc 0.9052631578947369, AUC 0.9695732593536377, avg_entr 0.010962620377540588
ep21_l2_test_time 0.1873035430908203
Test Epoch21 layer3 Acc 0.905, AUC 0.9662653803825378, avg_entr 0.009094790555536747
ep21_l3_test_time 0.24083352088928223
Test Epoch21 layer4 Acc 0.9044736842105263, AUC 0.9626224040985107, avg_entr 0.00839261431246996
ep21_l4_test_time 0.2909841537475586
gc 0
Train Epoch22 Acc 0.9744083333333333 (116929/120000), AUC 0.9962502121925354
ep22_train_time 37.593111991882324
Test Epoch22 layer0 Acc 0.9084210526315789, AUC 0.977439820766449, avg_entr 0.041739750653505325
ep22_l0_test_time 0.08121514320373535
Test Epoch22 layer1 Acc 0.9055263157894737, AUC 0.9692854881286621, avg_entr 0.016483666375279427
ep22_l1_test_time 0.13400745391845703
Test Epoch22 layer2 Acc 0.9039473684210526, AUC 0.9699708819389343, avg_entr 0.010609825141727924
ep22_l2_test_time 0.1877450942993164
Test Epoch22 layer3 Acc 0.9031578947368422, AUC 0.9677746295928955, avg_entr 0.008913686498999596
ep22_l3_test_time 0.24078989028930664
Test Epoch22 layer4 Acc 0.9028947368421053, AUC 0.96454918384552, avg_entr 0.008168230764567852
ep22_l4_test_time 0.2927408218383789
gc 0
Train Epoch23 Acc 0.9746666666666667 (116960/120000), AUC 0.9963686466217041
ep23_train_time 37.53666114807129
Test Epoch23 layer0 Acc 0.9078947368421053, AUC 0.977426290512085, avg_entr 0.04130873829126358
ep23_l0_test_time 0.08111929893493652
Test Epoch23 layer1 Acc 0.9055263157894737, AUC 0.9688348770141602, avg_entr 0.016314242035150528
ep23_l1_test_time 0.13375139236450195
Test Epoch23 layer2 Acc 0.9034210526315789, AUC 0.9698519706726074, avg_entr 0.01051986776292324
ep23_l2_test_time 0.18647527694702148
Test Epoch23 layer3 Acc 0.9039473684210526, AUC 0.9665971398353577, avg_entr 0.008829358033835888
ep23_l3_test_time 0.2401583194732666
Test Epoch23 layer4 Acc 0.9034210526315789, AUC 0.9632012248039246, avg_entr 0.008026402443647385
ep23_l4_test_time 0.2911956310272217
gc 0
Train Epoch24 Acc 0.9746083333333333 (116953/120000), AUC 0.9963116645812988
ep24_train_time 37.489116191864014
Test Epoch24 layer0 Acc 0.9089473684210526, AUC 0.9774110317230225, avg_entr 0.04070674628019333
ep24_l0_test_time 0.08058667182922363
Test Epoch24 layer1 Acc 0.9052631578947369, AUC 0.9687706232070923, avg_entr 0.01597730629146099
ep24_l1_test_time 0.1333446502685547
Test Epoch24 layer2 Acc 0.9042105263157895, AUC 0.9703274369239807, avg_entr 0.01038484089076519
ep24_l2_test_time 0.1867351531982422
Test Epoch24 layer3 Acc 0.9039473684210526, AUC 0.9672448635101318, avg_entr 0.008559620939195156
ep24_l3_test_time 0.24020791053771973
Test Epoch24 layer4 Acc 0.9034210526315789, AUC 0.9642189741134644, avg_entr 0.007811625488102436
ep24_l4_test_time 0.290557861328125
gc 0
Train Epoch25 Acc 0.9750333333333333 (117004/120000), AUC 0.9963377714157104
ep25_train_time 37.49835276603699
Test Epoch25 layer0 Acc 0.9078947368421053, AUC 0.9774160981178284, avg_entr 0.04056750237941742
ep25_l0_test_time 0.08157753944396973
Test Epoch25 layer1 Acc 0.9042105263157895, AUC 0.9689185619354248, avg_entr 0.015774570405483246
ep25_l1_test_time 0.13349604606628418
Test Epoch25 layer2 Acc 0.9039473684210526, AUC 0.970239520072937, avg_entr 0.01037588156759739
ep25_l2_test_time 0.18624567985534668
Test Epoch25 layer3 Acc 0.9034210526315789, AUC 0.967506468296051, avg_entr 0.008580234833061695
ep25_l3_test_time 0.238938570022583
Test Epoch25 layer4 Acc 0.9034210526315789, AUC 0.9644423723220825, avg_entr 0.007677285000681877
ep25_l4_test_time 0.29390835762023926
gc 0
Train Epoch26 Acc 0.9748333333333333 (116980/120000), AUC 0.9964880347251892
ep26_train_time 37.46523332595825
Test Epoch26 layer0 Acc 0.9078947368421053, AUC 0.9774144887924194, avg_entr 0.04023943096399307
ep26_l0_test_time 0.08100104331970215
Test Epoch26 layer1 Acc 0.9047368421052632, AUC 0.9691867828369141, avg_entr 0.015942871570587158
ep26_l1_test_time 0.13363099098205566
Test Epoch26 layer2 Acc 0.9036842105263158, AUC 0.9708756804466248, avg_entr 0.010155737400054932
ep26_l2_test_time 0.1863727569580078
Test Epoch26 layer3 Acc 0.9036842105263158, AUC 0.9683148860931396, avg_entr 0.00843673013150692
ep26_l3_test_time 0.24013829231262207
Test Epoch26 layer4 Acc 0.9034210526315789, AUC 0.964898407459259, avg_entr 0.0076599945314228535
ep26_l4_test_time 0.29285264015197754
gc 0
Train Epoch27 Acc 0.9749916666666667 (116999/120000), AUC 0.9965373873710632
ep27_train_time 37.57121920585632
Test Epoch27 layer0 Acc 0.908157894736842, AUC 0.9774222373962402, avg_entr 0.040053654462099075
ep27_l0_test_time 0.08193612098693848
Test Epoch27 layer1 Acc 0.9052631578947369, AUC 0.9689415693283081, avg_entr 0.01573052629828453
ep27_l1_test_time 0.1342175006866455
Test Epoch27 layer2 Acc 0.9042105263157895, AUC 0.9703518152236938, avg_entr 0.010115942917764187
ep27_l2_test_time 0.18755292892456055
Test Epoch27 layer3 Acc 0.9042105263157895, AUC 0.9674781560897827, avg_entr 0.008341243490576744
ep27_l3_test_time 0.24080681800842285
Test Epoch27 layer4 Acc 0.9036842105263158, AUC 0.9639419913291931, avg_entr 0.007535164710134268
ep27_l4_test_time 0.2944350242614746
gc 0
Train Epoch28 Acc 0.9751833333333333 (117022/120000), AUC 0.9966382384300232
ep28_train_time 37.485076904296875
Test Epoch28 layer0 Acc 0.9073684210526316, AUC 0.9774149060249329, avg_entr 0.04006699472665787
ep28_l0_test_time 0.08045315742492676
Test Epoch28 layer1 Acc 0.905, AUC 0.9689443111419678, avg_entr 0.01570085994899273
ep28_l1_test_time 0.13344931602478027
Test Epoch28 layer2 Acc 0.9031578947368422, AUC 0.9700065851211548, avg_entr 0.010294511914253235
ep28_l2_test_time 0.18678617477416992
Test Epoch28 layer3 Acc 0.9026315789473685, AUC 0.9672260284423828, avg_entr 0.00862360093742609
ep28_l3_test_time 0.24017810821533203
Test Epoch28 layer4 Acc 0.9023684210526316, AUC 0.9636135101318359, avg_entr 0.007653349544852972
ep28_l4_test_time 0.29406046867370605
gc 0
Train Epoch29 Acc 0.97515 (117018/120000), AUC 0.9965033531188965
ep29_train_time 37.56228041648865
Test Epoch29 layer0 Acc 0.908157894736842, AUC 0.9774191975593567, avg_entr 0.039833564311265945
ep29_l0_test_time 0.08175897598266602
Test Epoch29 layer1 Acc 0.9055263157894737, AUC 0.9688816070556641, avg_entr 0.015525683760643005
ep29_l1_test_time 0.13381600379943848
Test Epoch29 layer2 Acc 0.9042105263157895, AUC 0.9699306488037109, avg_entr 0.009995470754802227
ep29_l2_test_time 0.1869814395904541
Test Epoch29 layer3 Acc 0.9042105263157895, AUC 0.9671440720558167, avg_entr 0.00811800081282854
ep29_l3_test_time 0.23999619483947754
Test Epoch29 layer4 Acc 0.9036842105263158, AUC 0.9630188941955566, avg_entr 0.007320469710975885
ep29_l4_test_time 0.29212498664855957
gc 0
Train Epoch30 Acc 0.9753166666666667 (117038/120000), AUC 0.9965523481369019
ep30_train_time 37.5194525718689
Test Epoch30 layer0 Acc 0.9078947368421053, AUC 0.9774276614189148, avg_entr 0.03973889723420143
ep30_l0_test_time 0.08059382438659668
Test Epoch30 layer1 Acc 0.905, AUC 0.9690094590187073, avg_entr 0.015488138422369957
ep30_l1_test_time 0.13349056243896484
Test Epoch30 layer2 Acc 0.9039473684210526, AUC 0.9702650904655457, avg_entr 0.01013902947306633
ep30_l2_test_time 0.18686318397521973
Test Epoch30 layer3 Acc 0.9039473684210526, AUC 0.9675114750862122, avg_entr 0.00842886883765459
ep30_l3_test_time 0.24035120010375977
Test Epoch30 layer4 Acc 0.9034210526315789, AUC 0.9634883403778076, avg_entr 0.007626492530107498
ep30_l4_test_time 0.2932398319244385
gc 0
Train Epoch31 Acc 0.9753833333333334 (117046/120000), AUC 0.9965927004814148
ep31_train_time 37.55003213882446
Test Epoch31 layer0 Acc 0.9076315789473685, AUC 0.9774152636528015, avg_entr 0.03958482667803764
ep31_l0_test_time 0.08055520057678223
Test Epoch31 layer1 Acc 0.9047368421052632, AUC 0.9688432812690735, avg_entr 0.015423782169818878
ep31_l1_test_time 0.1332864761352539
Test Epoch31 layer2 Acc 0.9031578947368422, AUC 0.9700777530670166, avg_entr 0.010166848078370094
ep31_l2_test_time 0.18644022941589355
Test Epoch31 layer3 Acc 0.9031578947368422, AUC 0.9670970439910889, avg_entr 0.008375969715416431
ep31_l3_test_time 0.24022579193115234
Test Epoch31 layer4 Acc 0.9031578947368422, AUC 0.9630709290504456, avg_entr 0.007497772108763456
ep31_l4_test_time 0.2908608913421631
gc 0
Train Epoch32 Acc 0.975325 (117039/120000), AUC 0.9965869188308716
ep32_train_time 37.530468225479126
Test Epoch32 layer0 Acc 0.9086842105263158, AUC 0.9774160385131836, avg_entr 0.039574477821588516
ep32_l0_test_time 0.0808868408203125
Test Epoch32 layer1 Acc 0.9052631578947369, AUC 0.9689030051231384, avg_entr 0.015435425564646721
ep32_l1_test_time 0.13374066352844238
Test Epoch32 layer2 Acc 0.9034210526315789, AUC 0.9702962636947632, avg_entr 0.010019888170063496
ep32_l2_test_time 0.18712949752807617
Test Epoch32 layer3 Acc 0.9031578947368422, AUC 0.9673148393630981, avg_entr 0.008242483250796795
ep32_l3_test_time 0.24020957946777344
Test Epoch32 layer4 Acc 0.9034210526315789, AUC 0.9630656838417053, avg_entr 0.007410225924104452
ep32_l4_test_time 0.291445255279541
gc 0
Train Epoch33 Acc 0.97565 (117078/120000), AUC 0.9965605735778809
ep33_train_time 37.61714959144592
Test Epoch33 layer0 Acc 0.9078947368421053, AUC 0.9774150848388672, avg_entr 0.03957096114754677
ep33_l0_test_time 0.08148384094238281
Test Epoch33 layer1 Acc 0.9042105263157895, AUC 0.9686850309371948, avg_entr 0.015339500270783901
ep33_l1_test_time 0.1333320140838623
Test Epoch33 layer2 Acc 0.9031578947368422, AUC 0.9699087142944336, avg_entr 0.010144492611289024
ep33_l2_test_time 0.18707561492919922
Test Epoch33 layer3 Acc 0.9034210526315789, AUC 0.9672282934188843, avg_entr 0.008289813064038754
ep33_l3_test_time 0.24048686027526855
Test Epoch33 layer4 Acc 0.9031578947368422, AUC 0.9636573195457458, avg_entr 0.007392429281026125
ep33_l4_test_time 0.2923593521118164
gc 0
Train Epoch34 Acc 0.975425 (117051/120000), AUC 0.9965531826019287
ep34_train_time 37.543049335479736
Test Epoch34 layer0 Acc 0.9078947368421053, AUC 0.9774183630943298, avg_entr 0.039493221789598465
ep34_l0_test_time 0.08120250701904297
Test Epoch34 layer1 Acc 0.9047368421052632, AUC 0.9688888192176819, avg_entr 0.015361404977738857
ep34_l1_test_time 0.13379240036010742
Test Epoch34 layer2 Acc 0.9031578947368422, AUC 0.9702819585800171, avg_entr 0.010086888447403908
ep34_l2_test_time 0.18676137924194336
Test Epoch34 layer3 Acc 0.9026315789473685, AUC 0.9672971963882446, avg_entr 0.008293939754366875
ep34_l3_test_time 0.24022364616394043
Test Epoch34 layer4 Acc 0.9034210526315789, AUC 0.9635641574859619, avg_entr 0.007439444772899151
ep34_l4_test_time 0.29198598861694336
gc 0
Train Epoch35 Acc 0.975275 (117033/120000), AUC 0.9964861273765564
ep35_train_time 37.61592507362366
Test Epoch35 layer0 Acc 0.908157894736842, AUC 0.977419376373291, avg_entr 0.039441123604774475
ep35_l0_test_time 0.08053183555603027
Test Epoch35 layer1 Acc 0.905, AUC 0.9688965082168579, avg_entr 0.015358027070760727
ep35_l1_test_time 0.13344335556030273
Test Epoch35 layer2 Acc 0.9031578947368422, AUC 0.9701356887817383, avg_entr 0.01008646097034216
ep35_l2_test_time 0.18715405464172363
Test Epoch35 layer3 Acc 0.9023684210526316, AUC 0.9672192335128784, avg_entr 0.008317094296216965
ep35_l3_test_time 0.24036192893981934
Test Epoch35 layer4 Acc 0.9031578947368422, AUC 0.9632031321525574, avg_entr 0.0074622174724936485
ep35_l4_test_time 0.291471004486084
gc 0
Train Epoch36 Acc 0.9756666666666667 (117080/120000), AUC 0.9965454339981079
ep36_train_time 37.71104407310486
Test Epoch36 layer0 Acc 0.9084210526315789, AUC 0.9774208664894104, avg_entr 0.039395079016685486
ep36_l0_test_time 0.08135414123535156
Test Epoch36 layer1 Acc 0.905, AUC 0.9688503742218018, avg_entr 0.015333031304180622
ep36_l1_test_time 0.134077787399292
Test Epoch36 layer2 Acc 0.9034210526315789, AUC 0.9701636433601379, avg_entr 0.01000820379704237
ep36_l2_test_time 0.18666601181030273
Test Epoch36 layer3 Acc 0.9034210526315789, AUC 0.9672752618789673, avg_entr 0.008203990757465363
ep36_l3_test_time 0.24027514457702637
Test Epoch36 layer4 Acc 0.9034210526315789, AUC 0.9631521105766296, avg_entr 0.007357499096542597
ep36_l4_test_time 0.29184389114379883
gc 0
Train Epoch37 Acc 0.9755166666666667 (117062/120000), AUC 0.9964481592178345
ep37_train_time 37.567519426345825
Test Epoch37 layer0 Acc 0.9078947368421053, AUC 0.9774200320243835, avg_entr 0.03945094719529152
ep37_l0_test_time 0.08082437515258789
Test Epoch37 layer1 Acc 0.9047368421052632, AUC 0.9688701629638672, avg_entr 0.015340073965489864
ep37_l1_test_time 0.1339735984802246
Test Epoch37 layer2 Acc 0.9031578947368422, AUC 0.9700717926025391, avg_entr 0.01003114040941
ep37_l2_test_time 0.1872391700744629
Test Epoch37 layer3 Acc 0.9026315789473685, AUC 0.9670848250389099, avg_entr 0.008303931914269924
ep37_l3_test_time 0.2402963638305664
Test Epoch37 layer4 Acc 0.9026315789473685, AUC 0.9632896780967712, avg_entr 0.007479104679077864
ep37_l4_test_time 0.2912776470184326
gc 0
Train Epoch38 Acc 0.9755166666666667 (117062/120000), AUC 0.9966819882392883
ep38_train_time 37.398409366607666
Test Epoch38 layer0 Acc 0.908157894736842, AUC 0.9774194955825806, avg_entr 0.039374612271785736
ep38_l0_test_time 0.08123993873596191
Test Epoch38 layer1 Acc 0.9047368421052632, AUC 0.9689149856567383, avg_entr 0.015331115573644638
ep38_l1_test_time 0.1337122917175293
Test Epoch38 layer2 Acc 0.9031578947368422, AUC 0.9701457023620605, avg_entr 0.010003196075558662
ep38_l2_test_time 0.18751001358032227
Test Epoch38 layer3 Acc 0.9026315789473685, AUC 0.9672663807868958, avg_entr 0.008268824778497219
ep38_l3_test_time 0.2398548126220703
Test Epoch38 layer4 Acc 0.9026315789473685, AUC 0.9631179571151733, avg_entr 0.007440775632858276
ep38_l4_test_time 0.29164814949035645
gc 0
Train Epoch39 Acc 0.9755666666666667 (117068/120000), AUC 0.9965996146202087
ep39_train_time 37.46677327156067
Test Epoch39 layer0 Acc 0.908157894736842, AUC 0.9774191379547119, avg_entr 0.03936988115310669
ep39_l0_test_time 0.0803976058959961
Test Epoch39 layer1 Acc 0.9047368421052632, AUC 0.9688824415206909, avg_entr 0.01532211434096098
ep39_l1_test_time 0.13312077522277832
Test Epoch39 layer2 Acc 0.9031578947368422, AUC 0.9701485633850098, avg_entr 0.010039744898676872
ep39_l2_test_time 0.18666696548461914
Test Epoch39 layer3 Acc 0.9026315789473685, AUC 0.9673239588737488, avg_entr 0.008293669670820236
ep39_l3_test_time 0.23975872993469238
Test Epoch39 layer4 Acc 0.9031578947368422, AUC 0.9634764194488525, avg_entr 0.0074567669071257114
ep39_l4_test_time 0.29367995262145996
gc 0
Train Epoch40 Acc 0.975775 (117093/120000), AUC 0.9966198205947876
ep40_train_time 37.513402700424194
Test Epoch40 layer0 Acc 0.9076315789473685, AUC 0.9774168133735657, avg_entr 0.03937074914574623
ep40_l0_test_time 0.08053183555603027
Test Epoch40 layer1 Acc 0.9047368421052632, AUC 0.9688682556152344, avg_entr 0.015320103615522385
ep40_l1_test_time 0.13359951972961426
Test Epoch40 layer2 Acc 0.9031578947368422, AUC 0.9701557755470276, avg_entr 0.010055155493319035
ep40_l2_test_time 0.18698430061340332
Test Epoch40 layer3 Acc 0.9023684210526316, AUC 0.9673402905464172, avg_entr 0.008315962739288807
ep40_l3_test_time 0.2404158115386963
Test Epoch40 layer4 Acc 0.9028947368421053, AUC 0.9635318517684937, avg_entr 0.0074759856797754765
ep40_l4_test_time 0.2914316654205322
gc 0
Train Epoch41 Acc 0.9755583333333333 (117067/120000), AUC 0.9964278340339661
ep41_train_time 37.62030076980591
Test Epoch41 layer0 Acc 0.908157894736842, AUC 0.9774190187454224, avg_entr 0.03936422988772392
ep41_l0_test_time 0.08141279220581055
Test Epoch41 layer1 Acc 0.905, AUC 0.9688236713409424, avg_entr 0.015306010842323303
ep41_l1_test_time 0.13359546661376953
Test Epoch41 layer2 Acc 0.9031578947368422, AUC 0.9701290726661682, avg_entr 0.010063613764941692
ep41_l2_test_time 0.18690180778503418
Test Epoch41 layer3 Acc 0.9026315789473685, AUC 0.9672204256057739, avg_entr 0.008286923170089722
ep41_l3_test_time 0.2399156093597412
Test Epoch41 layer4 Acc 0.9034210526315789, AUC 0.9632736444473267, avg_entr 0.007435360457748175
ep41_l4_test_time 0.2909228801727295
gc 0
Train Epoch42 Acc 0.9756 (117072/120000), AUC 0.9966104626655579
ep42_train_time 37.53572487831116
Test Epoch42 layer0 Acc 0.9073684210526316, AUC 0.9774135947227478, avg_entr 0.039380114525556564
ep42_l0_test_time 0.08069372177124023
Test Epoch42 layer1 Acc 0.905, AUC 0.968856155872345, avg_entr 0.015309448353946209
ep42_l1_test_time 0.1335134506225586
Test Epoch42 layer2 Acc 0.9031578947368422, AUC 0.9701688885688782, avg_entr 0.010065278969705105
ep42_l2_test_time 0.1872265338897705
Test Epoch42 layer3 Acc 0.9023684210526316, AUC 0.9672765135765076, avg_entr 0.008309544064104557
ep42_l3_test_time 0.24074983596801758
Test Epoch42 layer4 Acc 0.9028947368421053, AUC 0.9635337591171265, avg_entr 0.007466859184205532
ep42_l4_test_time 0.29171252250671387
gc 0
Train Epoch43 Acc 0.9756916666666666 (117083/120000), AUC 0.9965852499008179
ep43_train_time 37.573312520980835
Test Epoch43 layer0 Acc 0.9078947368421053, AUC 0.9774179458618164, avg_entr 0.0393170490860939
ep43_l0_test_time 0.08151936531066895
Test Epoch43 layer1 Acc 0.905, AUC 0.9688513875007629, avg_entr 0.015305032953619957
ep43_l1_test_time 0.13351655006408691
Test Epoch43 layer2 Acc 0.9031578947368422, AUC 0.9702104330062866, avg_entr 0.010051526129245758
ep43_l2_test_time 0.18664312362670898
Test Epoch43 layer3 Acc 0.9023684210526316, AUC 0.9672555327415466, avg_entr 0.008290019817650318
ep43_l3_test_time 0.2401599884033203
Test Epoch43 layer4 Acc 0.9028947368421053, AUC 0.9634089469909668, avg_entr 0.0074495840817689896
ep43_l4_test_time 0.29082393646240234
gc 0
Train Epoch44 Acc 0.9756166666666667 (117074/120000), AUC 0.9965839385986328
ep44_train_time 37.54284930229187
Test Epoch44 layer0 Acc 0.9078947368421053, AUC 0.9774167537689209, avg_entr 0.039332613348960876
ep44_l0_test_time 0.08154463768005371
Test Epoch44 layer1 Acc 0.905, AUC 0.9688647389411926, avg_entr 0.01530318334698677
ep44_l1_test_time 0.1335749626159668
Test Epoch44 layer2 Acc 0.9031578947368422, AUC 0.9701842069625854, avg_entr 0.010049782693386078
ep44_l2_test_time 0.18694663047790527
Test Epoch44 layer3 Acc 0.9023684210526316, AUC 0.967246413230896, avg_entr 0.008290712721645832
ep44_l3_test_time 0.24012041091918945
Test Epoch44 layer4 Acc 0.9028947368421053, AUC 0.9634456038475037, avg_entr 0.0074476213194429874
ep44_l4_test_time 0.2935965061187744
gc 0
Train Epoch45 Acc 0.975525 (117063/120000), AUC 0.9964289665222168
ep45_train_time 37.57312273979187
Test Epoch45 layer0 Acc 0.908157894736842, AUC 0.9774174094200134, avg_entr 0.03932372108101845
ep45_l0_test_time 0.08101773262023926
Test Epoch45 layer1 Acc 0.9047368421052632, AUC 0.9688488245010376, avg_entr 0.015300210565328598
ep45_l1_test_time 0.13478803634643555
Test Epoch45 layer2 Acc 0.9034210526315789, AUC 0.9701582193374634, avg_entr 0.010033516213297844
ep45_l2_test_time 0.18752479553222656
Test Epoch45 layer3 Acc 0.9023684210526316, AUC 0.967249870300293, avg_entr 0.008276044391095638
ep45_l3_test_time 0.24013042449951172
Test Epoch45 layer4 Acc 0.9028947368421053, AUC 0.9632899165153503, avg_entr 0.007437724620103836
ep45_l4_test_time 0.294358491897583
gc 0
Train Epoch46 Acc 0.9757666666666667 (117092/120000), AUC 0.9965571165084839
ep46_train_time 37.61268854141235
Test Epoch46 layer0 Acc 0.908157894736842, AUC 0.9774159789085388, avg_entr 0.03932810574769974
ep46_l0_test_time 0.08134627342224121
Test Epoch46 layer1 Acc 0.9047368421052632, AUC 0.9688715934753418, avg_entr 0.015301263891160488
ep46_l1_test_time 0.13362360000610352
Test Epoch46 layer2 Acc 0.9034210526315789, AUC 0.9701673984527588, avg_entr 0.010046029463410378
ep46_l2_test_time 0.1875159740447998
Test Epoch46 layer3 Acc 0.9023684210526316, AUC 0.9672651886940002, avg_entr 0.00829321425408125
ep46_l3_test_time 0.2400529384613037
Test Epoch46 layer4 Acc 0.9028947368421053, AUC 0.9634898900985718, avg_entr 0.0074526299722492695
ep46_l4_test_time 0.29456019401550293
gc 0
Train Epoch47 Acc 0.975475 (117057/120000), AUC 0.996578574180603
ep47_train_time 37.67046046257019
Test Epoch47 layer0 Acc 0.9078947368421053, AUC 0.9774161577224731, avg_entr 0.039317794144153595
ep47_l0_test_time 0.0820302963256836
Test Epoch47 layer1 Acc 0.9047368421052632, AUC 0.968861997127533, avg_entr 0.015297725796699524
ep47_l1_test_time 0.13394474983215332
Test Epoch47 layer2 Acc 0.9034210526315789, AUC 0.9701343178749084, avg_entr 0.010040553286671638
ep47_l2_test_time 0.18733501434326172
Test Epoch47 layer3 Acc 0.9023684210526316, AUC 0.9672517776489258, avg_entr 0.00828449334949255
ep47_l3_test_time 0.24075746536254883
Test Epoch47 layer4 Acc 0.9028947368421053, AUC 0.9634568095207214, avg_entr 0.00744511466473341
ep47_l4_test_time 0.29289937019348145
gc 0
Train Epoch48 Acc 0.9757333333333333 (117088/120000), AUC 0.9965437650680542
ep48_train_time 37.540854692459106
Test Epoch48 layer0 Acc 0.9078947368421053, AUC 0.9774166345596313, avg_entr 0.039318185299634933
ep48_l0_test_time 0.08145976066589355
Test Epoch48 layer1 Acc 0.9047368421052632, AUC 0.9688518643379211, avg_entr 0.015295968391001225
ep48_l1_test_time 0.13406777381896973
Test Epoch48 layer2 Acc 0.9034210526315789, AUC 0.9701424241065979, avg_entr 0.010039393790066242
ep48_l2_test_time 0.18747735023498535
Test Epoch48 layer3 Acc 0.9023684210526316, AUC 0.9672593474388123, avg_entr 0.008283421397209167
ep48_l3_test_time 0.24069762229919434
Test Epoch48 layer4 Acc 0.9028947368421053, AUC 0.9634401202201843, avg_entr 0.00744330370798707
ep48_l4_test_time 0.29482221603393555
gc 0
Train Epoch49 Acc 0.97535 (117042/120000), AUC 0.9965052604675293
ep49_train_time 37.67085409164429
Test Epoch49 layer0 Acc 0.9078947368421053, AUC 0.9774158000946045, avg_entr 0.03931184113025665
ep49_l0_test_time 0.08165359497070312
Test Epoch49 layer1 Acc 0.9047368421052632, AUC 0.9688584804534912, avg_entr 0.015291533432900906
ep49_l1_test_time 0.13431882858276367
Test Epoch49 layer2 Acc 0.9031578947368422, AUC 0.970160186290741, avg_entr 0.010040879249572754
ep49_l2_test_time 0.18731951713562012
Test Epoch49 layer3 Acc 0.9026315789473685, AUC 0.9672547578811646, avg_entr 0.008277297019958496
ep49_l3_test_time 0.24129152297973633
Test Epoch49 layer4 Acc 0.9028947368421053, AUC 0.9633893370628357, avg_entr 0.007433791179209948
ep49_l4_test_time 0.2946028709411621
Best AUC 0.9801980257034302
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train+valid_time 1926.8270282745361
Start Testing
Load ckpt at ckpt/ag_news_transformeral_l5_pad75//ag_news_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.9221052631578948, AUC 0.9847716689109802, avg_entr 0.1064877063035965
ep49_l0_test_time 0.07928466796875
Test Epoch49 layer1 Acc 0.9234210526315789, AUC 0.985787034034729, avg_entr 0.045476801693439484
ep49_l1_test_time 0.13372564315795898
Test Epoch49 layer2 Acc 0.925, AUC 0.9860769510269165, avg_entr 0.03756106644868851
ep49_l2_test_time 0.18697428703308105
Test Epoch49 layer3 Acc 0.9244736842105263, AUC 0.9863410592079163, avg_entr 0.03601323440670967
ep49_l3_test_time 0.24048542976379395
Test Epoch49 layer4 Acc 0.9255263157894736, AUC 0.9861986041069031, avg_entr 0.03391275554895401
ep49_l4_test_time 0.2956833839416504
