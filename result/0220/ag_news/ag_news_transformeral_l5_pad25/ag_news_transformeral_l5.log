total count words 102019
vocab size 30000
found 26754 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13672292
init_time 19.50494885444641
Start Training
gc 0
Train Epoch0 Acc 0.6185083333333333 (74221/120000), AUC 0.8471985459327698
ep0_train_time 19.33432412147522
Test Epoch0 layer0 Acc 0.9044736842105263, AUC 0.9774036407470703, avg_entr 0.20948848128318787
ep0_l0_test_time 0.04617762565612793
Save ckpt to ckpt/ag_news_transformeral_l5_pad25//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9021052631578947, AUC 0.9764531254768372, avg_entr 0.16607201099395752
ep0_l1_test_time 0.06351828575134277
Test Epoch0 layer2 Acc 0.8984210526315789, AUC 0.9765245914459229, avg_entr 0.16667012870311737
ep0_l2_test_time 0.08288812637329102
Test Epoch0 layer3 Acc 0.9002631578947369, AUC 0.976840078830719, avg_entr 0.1633652150630951
ep0_l3_test_time 0.10297155380249023
Test Epoch0 layer4 Acc 0.9, AUC 0.9768205881118774, avg_entr 0.15973667800426483
ep0_l4_test_time 0.12337064743041992
gc 0
Train Epoch1 Acc 0.928425 (111411/120000), AUC 0.984409749507904
ep1_train_time 17.688090324401855
Test Epoch1 layer0 Acc 0.9076315789473685, AUC 0.9790559411048889, avg_entr 0.13473695516586304
ep1_l0_test_time 0.04385995864868164
Save ckpt to ckpt/ag_news_transformeral_l5_pad25//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.9102631578947369, AUC 0.9791235327720642, avg_entr 0.08818712830543518
ep1_l1_test_time 0.06486034393310547
Save ckpt to ckpt/ag_news_transformeral_l5_pad25//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.9105263157894737, AUC 0.9791239500045776, avg_entr 0.07282048463821411
ep1_l2_test_time 0.08583426475524902
Save ckpt to ckpt/ag_news_transformeral_l5_pad25//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer3 Acc 0.9097368421052632, AUC 0.9792985320091248, avg_entr 0.06330786645412445
ep1_l3_test_time 0.10585212707519531
Save ckpt to ckpt/ag_news_transformeral_l5_pad25//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer4 Acc 0.9123684210526316, AUC 0.9788602590560913, avg_entr 0.05720145255327225
ep1_l4_test_time 0.1268162727355957
gc 0
Train Epoch2 Acc 0.9401333333333334 (112816/120000), AUC 0.9880476593971252
ep2_train_time 18.363579750061035
Test Epoch2 layer0 Acc 0.9094736842105263, AUC 0.9795891046524048, avg_entr 0.10680517554283142
ep2_l0_test_time 0.0442500114440918
Save ckpt to ckpt/ag_news_transformeral_l5_pad25//ag_news_transformeral_l5.pt  ,ep 2
Test Epoch2 layer1 Acc 0.9105263157894737, AUC 0.9785216450691223, avg_entr 0.049689989537000656
ep2_l1_test_time 0.06507277488708496
Test Epoch2 layer2 Acc 0.9113157894736842, AUC 0.9793275594711304, avg_entr 0.038484811782836914
ep2_l2_test_time 0.08321285247802734
Test Epoch2 layer3 Acc 0.9110526315789473, AUC 0.9795092940330505, avg_entr 0.03581542149186134
ep2_l3_test_time 0.10347199440002441
Test Epoch2 layer4 Acc 0.9110526315789473, AUC 0.9791843891143799, avg_entr 0.0334840826690197
ep2_l4_test_time 0.12334632873535156
gc 0
Train Epoch3 Acc 0.9476666666666667 (113720/120000), AUC 0.9900271892547607
ep3_train_time 18.116713523864746
Test Epoch3 layer0 Acc 0.9107894736842105, AUC 0.979431688785553, avg_entr 0.09163909405469894
ep3_l0_test_time 0.04434370994567871
Test Epoch3 layer1 Acc 0.9107894736842105, AUC 0.9760286808013916, avg_entr 0.0360427163541317
ep3_l1_test_time 0.06290054321289062
Test Epoch3 layer2 Acc 0.9107894736842105, AUC 0.976147472858429, avg_entr 0.029223628342151642
ep3_l2_test_time 0.08263397216796875
Test Epoch3 layer3 Acc 0.9107894736842105, AUC 0.9775478839874268, avg_entr 0.027287034317851067
ep3_l3_test_time 0.10298824310302734
Test Epoch3 layer4 Acc 0.9118421052631579, AUC 0.9790292382240295, avg_entr 0.025598272681236267
ep3_l4_test_time 0.12320232391357422
gc 0
Train Epoch4 Acc 0.9526083333333333 (114313/120000), AUC 0.991071343421936
ep4_train_time 18.275177478790283
Test Epoch4 layer0 Acc 0.9078947368421053, AUC 0.9792143106460571, avg_entr 0.08335680514574051
ep4_l0_test_time 0.04473519325256348
Test Epoch4 layer1 Acc 0.9076315789473685, AUC 0.9782501459121704, avg_entr 0.03138649836182594
ep4_l1_test_time 0.0627756118774414
Test Epoch4 layer2 Acc 0.9057894736842105, AUC 0.9795122742652893, avg_entr 0.024783745408058167
ep4_l2_test_time 0.08275508880615234
Test Epoch4 layer3 Acc 0.9057894736842105, AUC 0.9805202484130859, avg_entr 0.022662876173853874
ep4_l3_test_time 0.10301017761230469
Save ckpt to ckpt/ag_news_transformeral_l5_pad25//ag_news_transformeral_l5.pt  ,ep 4
Test Epoch4 layer4 Acc 0.9052631578947369, AUC 0.9800345301628113, avg_entr 0.020967666059732437
ep4_l4_test_time 0.12744784355163574
gc 0
Train Epoch5 Acc 0.9556083333333333 (114673/120000), AUC 0.9921004772186279
ep5_train_time 18.188971281051636
Test Epoch5 layer0 Acc 0.9121052631578948, AUC 0.9789232611656189, avg_entr 0.0751253142952919
ep5_l0_test_time 0.04431557655334473
Test Epoch5 layer1 Acc 0.9123684210526316, AUC 0.9761402606964111, avg_entr 0.02674148418009281
ep5_l1_test_time 0.06291770935058594
Test Epoch5 layer2 Acc 0.9110526315789473, AUC 0.9779291749000549, avg_entr 0.020661013200879097
ep5_l2_test_time 0.08269262313842773
Test Epoch5 layer3 Acc 0.9102631578947369, AUC 0.9782384037971497, avg_entr 0.018763231113553047
ep5_l3_test_time 0.1030435562133789
Test Epoch5 layer4 Acc 0.9097368421052632, AUC 0.9787340760231018, avg_entr 0.017365798354148865
ep5_l4_test_time 0.1236109733581543
gc 0
Train Epoch6 Acc 0.95885 (115062/120000), AUC 0.9928827285766602
ep6_train_time 18.224730253219604
Test Epoch6 layer0 Acc 0.9102631578947369, AUC 0.9785680770874023, avg_entr 0.0694480761885643
ep6_l0_test_time 0.04382729530334473
Test Epoch6 layer1 Acc 0.9076315789473685, AUC 0.9753093719482422, avg_entr 0.024511180818080902
ep6_l1_test_time 0.062471628189086914
Test Epoch6 layer2 Acc 0.9089473684210526, AUC 0.9774622917175293, avg_entr 0.019071780145168304
ep6_l2_test_time 0.08266448974609375
Test Epoch6 layer3 Acc 0.9094736842105263, AUC 0.9785093069076538, avg_entr 0.01705211028456688
ep6_l3_test_time 0.10314011573791504
Test Epoch6 layer4 Acc 0.9105263157894737, AUC 0.9776937961578369, avg_entr 0.015272550284862518
ep6_l4_test_time 0.12299346923828125
gc 0
Train Epoch7 Acc 0.9622 (115464/120000), AUC 0.9941462278366089
ep7_train_time 18.250523328781128
Test Epoch7 layer0 Acc 0.9097368421052632, AUC 0.9781532883644104, avg_entr 0.06741633266210556
ep7_l0_test_time 0.04411125183105469
Test Epoch7 layer1 Acc 0.9076315789473685, AUC 0.9749202132225037, avg_entr 0.02315836399793625
ep7_l1_test_time 0.0631265640258789
Test Epoch7 layer2 Acc 0.9073684210526316, AUC 0.9738008379936218, avg_entr 0.01593778282403946
ep7_l2_test_time 0.08251523971557617
Test Epoch7 layer3 Acc 0.9076315789473685, AUC 0.9753038287162781, avg_entr 0.014692474156618118
ep7_l3_test_time 0.10285139083862305
Test Epoch7 layer4 Acc 0.9076315789473685, AUC 0.974391758441925, avg_entr 0.013275807723402977
ep7_l4_test_time 0.1233072280883789
gc 0
Train Epoch8 Acc 0.9635916666666666 (115631/120000), AUC 0.994346022605896
ep8_train_time 17.89168381690979
Test Epoch8 layer0 Acc 0.9102631578947369, AUC 0.9779085516929626, avg_entr 0.06469351053237915
ep8_l0_test_time 0.04404282569885254
Test Epoch8 layer1 Acc 0.9068421052631579, AUC 0.9742615818977356, avg_entr 0.021815912798047066
ep8_l1_test_time 0.06265425682067871
Test Epoch8 layer2 Acc 0.908157894736842, AUC 0.9767100811004639, avg_entr 0.0159596037119627
ep8_l2_test_time 0.08251810073852539
Test Epoch8 layer3 Acc 0.9071052631578947, AUC 0.9775630235671997, avg_entr 0.0144426878541708
ep8_l3_test_time 0.10294842720031738
Test Epoch8 layer4 Acc 0.9073684210526316, AUC 0.9762942790985107, avg_entr 0.012775573879480362
ep8_l4_test_time 0.12269854545593262
gc 0
Train Epoch9 Acc 0.9652583333333333 (115831/120000), AUC 0.9948012828826904
ep9_train_time 18.26363778114319
Test Epoch9 layer0 Acc 0.9068421052631579, AUC 0.9776039123535156, avg_entr 0.06193547695875168
ep9_l0_test_time 0.04433727264404297
Test Epoch9 layer1 Acc 0.9076315789473685, AUC 0.9724515080451965, avg_entr 0.021612122654914856
ep9_l1_test_time 0.0626363754272461
Test Epoch9 layer2 Acc 0.9071052631578947, AUC 0.9744202494621277, avg_entr 0.014622297137975693
ep9_l2_test_time 0.08319902420043945
Test Epoch9 layer3 Acc 0.9063157894736842, AUC 0.9757223129272461, avg_entr 0.013370404951274395
ep9_l3_test_time 0.10257196426391602
Test Epoch9 layer4 Acc 0.9063157894736842, AUC 0.9758105874061584, avg_entr 0.012105695903301239
ep9_l4_test_time 0.12337160110473633
gc 0
Train Epoch10 Acc 0.9663416666666667 (115961/120000), AUC 0.9949494004249573
ep10_train_time 18.43687415122986
Test Epoch10 layer0 Acc 0.906578947368421, AUC 0.9779074788093567, avg_entr 0.05879773199558258
ep10_l0_test_time 0.04458355903625488
Test Epoch10 layer1 Acc 0.9073684210526316, AUC 0.9739524126052856, avg_entr 0.019895970821380615
ep10_l1_test_time 0.06283187866210938
Test Epoch10 layer2 Acc 0.9071052631578947, AUC 0.9753258228302002, avg_entr 0.013621887192130089
ep10_l2_test_time 0.0824892520904541
Test Epoch10 layer3 Acc 0.906578947368421, AUC 0.9758715033531189, avg_entr 0.011949594132602215
ep10_l3_test_time 0.1030268669128418
Test Epoch10 layer4 Acc 0.9068421052631579, AUC 0.9764316082000732, avg_entr 0.010862206108868122
ep10_l4_test_time 0.12332487106323242
gc 0
Train Epoch11 Acc 0.9683 (116196/120000), AUC 0.9954639077186584
ep11_train_time 17.952354907989502
Test Epoch11 layer0 Acc 0.9073684210526316, AUC 0.977629542350769, avg_entr 0.056846074759960175
ep11_l0_test_time 0.044449567794799805
Test Epoch11 layer1 Acc 0.9057894736842105, AUC 0.9726796746253967, avg_entr 0.020023172721266747
ep11_l1_test_time 0.062412261962890625
Test Epoch11 layer2 Acc 0.905, AUC 0.9747496247291565, avg_entr 0.013772541657090187
ep11_l2_test_time 0.08273649215698242
Test Epoch11 layer3 Acc 0.9055263157894737, AUC 0.9752934575080872, avg_entr 0.011969225481152534
ep11_l3_test_time 0.1031503677368164
Test Epoch11 layer4 Acc 0.9057894736842105, AUC 0.9759669303894043, avg_entr 0.010897506959736347
ep11_l4_test_time 0.1234588623046875
gc 0
Train Epoch12 Acc 0.9691 (116292/120000), AUC 0.9953946471214294
ep12_train_time 17.899203300476074
Test Epoch12 layer0 Acc 0.9060526315789473, AUC 0.9774590730667114, avg_entr 0.055581673979759216
ep12_l0_test_time 0.04378223419189453
Test Epoch12 layer1 Acc 0.9055263157894737, AUC 0.9720228910446167, avg_entr 0.018747638911008835
ep12_l1_test_time 0.06291532516479492
Test Epoch12 layer2 Acc 0.9036842105263158, AUC 0.9738460183143616, avg_entr 0.012426143512129784
ep12_l2_test_time 0.08300948143005371
Test Epoch12 layer3 Acc 0.9031578947368422, AUC 0.9734787940979004, avg_entr 0.01070238184183836
ep12_l3_test_time 0.10375213623046875
Test Epoch12 layer4 Acc 0.9031578947368422, AUC 0.9736745357513428, avg_entr 0.00981859304010868
ep12_l4_test_time 0.12401103973388672
gc 0
Train Epoch13 Acc 0.9696083333333333 (116353/120000), AUC 0.995712399482727
ep13_train_time 18.195483684539795
Test Epoch13 layer0 Acc 0.9071052631578947, AUC 0.9773130416870117, avg_entr 0.05355965718626976
ep13_l0_test_time 0.04443001747131348
Test Epoch13 layer1 Acc 0.9055263157894737, AUC 0.9711066484451294, avg_entr 0.01783672347664833
ep13_l1_test_time 0.0625457763671875
Test Epoch13 layer2 Acc 0.9042105263157895, AUC 0.9724972248077393, avg_entr 0.011699185706675053
ep13_l2_test_time 0.08261585235595703
Test Epoch13 layer3 Acc 0.9042105263157895, AUC 0.9716126918792725, avg_entr 0.010439379140734673
ep13_l3_test_time 0.1027374267578125
Test Epoch13 layer4 Acc 0.9044736842105263, AUC 0.9717352986335754, avg_entr 0.009413941763341427
ep13_l4_test_time 0.1234889030456543
gc 0
Train Epoch14 Acc 0.9702083333333333 (116425/120000), AUC 0.9957999587059021
ep14_train_time 17.950188159942627
Test Epoch14 layer0 Acc 0.906578947368421, AUC 0.9772965908050537, avg_entr 0.051568467170000076
ep14_l0_test_time 0.04411053657531738
Test Epoch14 layer1 Acc 0.9052631578947369, AUC 0.9715495705604553, avg_entr 0.017475225031375885
ep14_l1_test_time 0.06304168701171875
Test Epoch14 layer2 Acc 0.9047368421052632, AUC 0.9739697575569153, avg_entr 0.011867337860167027
ep14_l2_test_time 0.08269119262695312
Test Epoch14 layer3 Acc 0.9039473684210526, AUC 0.9738103151321411, avg_entr 0.010273551568388939
ep14_l3_test_time 0.10286974906921387
Test Epoch14 layer4 Acc 0.9042105263157895, AUC 0.9724913835525513, avg_entr 0.009292039088904858
ep14_l4_test_time 0.12309622764587402
gc 0
Train Epoch15 Acc 0.9713583333333333 (116563/120000), AUC 0.9960362911224365
ep15_train_time 18.24806308746338
Test Epoch15 layer0 Acc 0.9063157894736842, AUC 0.9771655201911926, avg_entr 0.050268061459064484
ep15_l0_test_time 0.04434347152709961
Test Epoch15 layer1 Acc 0.9047368421052632, AUC 0.9707272052764893, avg_entr 0.01709182746708393
ep15_l1_test_time 0.06251049041748047
Test Epoch15 layer2 Acc 0.905, AUC 0.972928524017334, avg_entr 0.011422513984143734
ep15_l2_test_time 0.08246994018554688
Test Epoch15 layer3 Acc 0.9052631578947369, AUC 0.9730119705200195, avg_entr 0.009806780144572258
ep15_l3_test_time 0.10239911079406738
Test Epoch15 layer4 Acc 0.9052631578947369, AUC 0.9723461270332336, avg_entr 0.008773582987487316
ep15_l4_test_time 0.12308669090270996
gc 0
Train Epoch16 Acc 0.9719083333333334 (116629/120000), AUC 0.9960082173347473
ep16_train_time 18.210496425628662
Test Epoch16 layer0 Acc 0.9060526315789473, AUC 0.9770726561546326, avg_entr 0.048711925745010376
ep16_l0_test_time 0.04454946517944336
Test Epoch16 layer1 Acc 0.9044736842105263, AUC 0.9706844091415405, avg_entr 0.016622932627797127
ep16_l1_test_time 0.06293272972106934
Test Epoch16 layer2 Acc 0.9044736842105263, AUC 0.9717738628387451, avg_entr 0.010988379828631878
ep16_l2_test_time 0.08241820335388184
Test Epoch16 layer3 Acc 0.9044736842105263, AUC 0.9710078239440918, avg_entr 0.009639006108045578
ep16_l3_test_time 0.10264372825622559
Test Epoch16 layer4 Acc 0.9044736842105263, AUC 0.9712936878204346, avg_entr 0.008809931576251984
ep16_l4_test_time 0.12283110618591309
gc 0
Train Epoch17 Acc 0.9720583333333334 (116647/120000), AUC 0.996293842792511
ep17_train_time 18.104954719543457
Test Epoch17 layer0 Acc 0.9057894736842105, AUC 0.9770137071609497, avg_entr 0.04740730673074722
ep17_l0_test_time 0.044472694396972656
Test Epoch17 layer1 Acc 0.905, AUC 0.9711699485778809, avg_entr 0.016542358323931694
ep17_l1_test_time 0.0631875991821289
Test Epoch17 layer2 Acc 0.9036842105263158, AUC 0.9732496738433838, avg_entr 0.01090073212981224
ep17_l2_test_time 0.08271241188049316
Test Epoch17 layer3 Acc 0.9036842105263158, AUC 0.9726563096046448, avg_entr 0.009588757529854774
ep17_l3_test_time 0.10291099548339844
Test Epoch17 layer4 Acc 0.9036842105263158, AUC 0.9730017185211182, avg_entr 0.008865936659276485
ep17_l4_test_time 0.12325692176818848
gc 0
Train Epoch18 Acc 0.9722833333333334 (116674/120000), AUC 0.9963223934173584
ep18_train_time 18.148937940597534
Test Epoch18 layer0 Acc 0.9055263157894737, AUC 0.9770072102546692, avg_entr 0.045662760734558105
ep18_l0_test_time 0.04360508918762207
Test Epoch18 layer1 Acc 0.9047368421052632, AUC 0.9700518846511841, avg_entr 0.015734286978840828
ep18_l1_test_time 0.06287932395935059
Test Epoch18 layer2 Acc 0.9018421052631579, AUC 0.9714629054069519, avg_entr 0.010366900824010372
ep18_l2_test_time 0.08272123336791992
Test Epoch18 layer3 Acc 0.9023684210526316, AUC 0.9716165065765381, avg_entr 0.009107008576393127
ep18_l3_test_time 0.10293698310852051
Test Epoch18 layer4 Acc 0.9028947368421053, AUC 0.9704376459121704, avg_entr 0.008398374542593956
ep18_l4_test_time 0.12281632423400879
gc 0
Train Epoch19 Acc 0.972875 (116745/120000), AUC 0.9963632225990295
ep19_train_time 18.380746603012085
Test Epoch19 layer0 Acc 0.9060526315789473, AUC 0.9769428372383118, avg_entr 0.045022327452898026
ep19_l0_test_time 0.04396414756774902
Test Epoch19 layer1 Acc 0.905, AUC 0.9694911241531372, avg_entr 0.01558033749461174
ep19_l1_test_time 0.06278252601623535
Test Epoch19 layer2 Acc 0.9031578947368422, AUC 0.9711257815361023, avg_entr 0.010444876737892628
ep19_l2_test_time 0.0823664665222168
Test Epoch19 layer3 Acc 0.9031578947368422, AUC 0.9709895253181458, avg_entr 0.009228788316249847
ep19_l3_test_time 0.10262703895568848
Test Epoch19 layer4 Acc 0.9031578947368422, AUC 0.9704124927520752, avg_entr 0.008409655652940273
ep19_l4_test_time 0.12352490425109863
gc 0
Train Epoch20 Acc 0.973 (116760/120000), AUC 0.9963180422782898
ep20_train_time 18.73230481147766
Test Epoch20 layer0 Acc 0.9060526315789473, AUC 0.9769521951675415, avg_entr 0.0439227931201458
ep20_l0_test_time 0.044637441635131836
Test Epoch20 layer1 Acc 0.9036842105263158, AUC 0.9695407748222351, avg_entr 0.01534251868724823
ep20_l1_test_time 0.0628819465637207
Test Epoch20 layer2 Acc 0.9031578947368422, AUC 0.9712725281715393, avg_entr 0.010305472649633884
ep20_l2_test_time 0.08281636238098145
Test Epoch20 layer3 Acc 0.9028947368421053, AUC 0.9717144966125488, avg_entr 0.009041119366884232
ep20_l3_test_time 0.10246634483337402
Test Epoch20 layer4 Acc 0.9031578947368422, AUC 0.9702533483505249, avg_entr 0.008296029642224312
ep20_l4_test_time 0.12302851676940918
gc 0
Train Epoch21 Acc 0.973625 (116835/120000), AUC 0.9964304566383362
ep21_train_time 18.672117233276367
Test Epoch21 layer0 Acc 0.905, AUC 0.9769633412361145, avg_entr 0.042781002819538116
ep21_l0_test_time 0.04440593719482422
Test Epoch21 layer1 Acc 0.9047368421052632, AUC 0.9699279069900513, avg_entr 0.01499147154390812
ep21_l1_test_time 0.06340384483337402
Test Epoch21 layer2 Acc 0.9034210526315789, AUC 0.9711236357688904, avg_entr 0.009924141690135002
ep21_l2_test_time 0.08266234397888184
Test Epoch21 layer3 Acc 0.9034210526315789, AUC 0.9709551334381104, avg_entr 0.008649414405226707
ep21_l3_test_time 0.10257554054260254
Test Epoch21 layer4 Acc 0.9039473684210526, AUC 0.9709624648094177, avg_entr 0.007935049943625927
ep21_l4_test_time 0.12334156036376953
gc 0
Train Epoch22 Acc 0.9734333333333334 (116812/120000), AUC 0.9964191317558289
ep22_train_time 18.572148323059082
Test Epoch22 layer0 Acc 0.9055263157894737, AUC 0.9769202470779419, avg_entr 0.04183286428451538
ep22_l0_test_time 0.04422903060913086
Test Epoch22 layer1 Acc 0.9039473684210526, AUC 0.9698868989944458, avg_entr 0.014610177837312222
ep22_l1_test_time 0.06248116493225098
Test Epoch22 layer2 Acc 0.9034210526315789, AUC 0.9715172052383423, avg_entr 0.009615329094231129
ep22_l2_test_time 0.08205294609069824
Test Epoch22 layer3 Acc 0.9031578947368422, AUC 0.9706550240516663, avg_entr 0.008354034274816513
ep22_l3_test_time 0.10232686996459961
Test Epoch22 layer4 Acc 0.9031578947368422, AUC 0.9701535701751709, avg_entr 0.007641225587576628
ep22_l4_test_time 0.12264704704284668
gc 0
Train Epoch23 Acc 0.97375 (116850/120000), AUC 0.9964780807495117
ep23_train_time 18.351116180419922
Test Epoch23 layer0 Acc 0.9055263157894737, AUC 0.9768795967102051, avg_entr 0.041124507784843445
ep23_l0_test_time 0.044178009033203125
Test Epoch23 layer1 Acc 0.9044736842105263, AUC 0.9694815874099731, avg_entr 0.014434363692998886
ep23_l1_test_time 0.06300044059753418
Test Epoch23 layer2 Acc 0.9034210526315789, AUC 0.9710569977760315, avg_entr 0.009666992351412773
ep23_l2_test_time 0.08233261108398438
Test Epoch23 layer3 Acc 0.9026315789473685, AUC 0.9699831008911133, avg_entr 0.00847871508449316
ep23_l3_test_time 0.1028289794921875
Test Epoch23 layer4 Acc 0.9023684210526316, AUC 0.9694883823394775, avg_entr 0.007678018882870674
ep23_l4_test_time 0.12332391738891602
gc 0
Train Epoch24 Acc 0.9738833333333333 (116866/120000), AUC 0.996455729007721
ep24_train_time 18.029646158218384
Test Epoch24 layer0 Acc 0.9060526315789473, AUC 0.9769017696380615, avg_entr 0.04051588848233223
ep24_l0_test_time 0.0444796085357666
Test Epoch24 layer1 Acc 0.9036842105263158, AUC 0.9697467088699341, avg_entr 0.014413734897971153
ep24_l1_test_time 0.06258392333984375
Test Epoch24 layer2 Acc 0.9026315789473685, AUC 0.9699881076812744, avg_entr 0.009581285528838634
ep24_l2_test_time 0.08215117454528809
Test Epoch24 layer3 Acc 0.9026315789473685, AUC 0.9688854813575745, avg_entr 0.00824742205440998
ep24_l3_test_time 0.10252714157104492
Test Epoch24 layer4 Acc 0.9023684210526316, AUC 0.9683489799499512, avg_entr 0.007491419091820717
ep24_l4_test_time 0.1224675178527832
gc 0
Train Epoch25 Acc 0.9741166666666666 (116894/120000), AUC 0.9963885545730591
ep25_train_time 18.311725616455078
Test Epoch25 layer0 Acc 0.9052631578947369, AUC 0.976848840713501, avg_entr 0.0400824248790741
ep25_l0_test_time 0.04400157928466797
Test Epoch25 layer1 Acc 0.9039473684210526, AUC 0.9694327116012573, avg_entr 0.014254487119615078
ep25_l1_test_time 0.062369585037231445
Test Epoch25 layer2 Acc 0.901578947368421, AUC 0.9705601334571838, avg_entr 0.009522061794996262
ep25_l2_test_time 0.08233833312988281
Test Epoch25 layer3 Acc 0.9021052631578947, AUC 0.9693762063980103, avg_entr 0.008387059904634953
ep25_l3_test_time 0.10270500183105469
Test Epoch25 layer4 Acc 0.9018421052631579, AUC 0.9688940048217773, avg_entr 0.007667439989745617
ep25_l4_test_time 0.12362504005432129
gc 0
Train Epoch26 Acc 0.9738666666666667 (116864/120000), AUC 0.9965659379959106
ep26_train_time 18.157873392105103
Test Epoch26 layer0 Acc 0.905, AUC 0.9768140912055969, avg_entr 0.03978487849235535
ep26_l0_test_time 0.04421520233154297
Test Epoch26 layer1 Acc 0.9039473684210526, AUC 0.9694962501525879, avg_entr 0.014213466085493565
ep26_l1_test_time 0.0627748966217041
Test Epoch26 layer2 Acc 0.9021052631578947, AUC 0.9703801870346069, avg_entr 0.009385021403431892
ep26_l2_test_time 0.08204460144042969
Test Epoch26 layer3 Acc 0.9018421052631579, AUC 0.9696049094200134, avg_entr 0.008022711612284184
ep26_l3_test_time 0.1022787094116211
Test Epoch26 layer4 Acc 0.901578947368421, AUC 0.9697012305259705, avg_entr 0.00739579601213336
ep26_l4_test_time 0.12255144119262695
gc 0
Train Epoch27 Acc 0.9742333333333333 (116908/120000), AUC 0.9965240955352783
ep27_train_time 17.936280488967896
Test Epoch27 layer0 Acc 0.9047368421052632, AUC 0.9768282175064087, avg_entr 0.03950260207056999
ep27_l0_test_time 0.0435943603515625
Test Epoch27 layer1 Acc 0.9034210526315789, AUC 0.9695430994033813, avg_entr 0.014149810187518597
ep27_l1_test_time 0.06233406066894531
Test Epoch27 layer2 Acc 0.9018421052631579, AUC 0.9706548452377319, avg_entr 0.009368057362735271
ep27_l2_test_time 0.08197426795959473
Test Epoch27 layer3 Acc 0.9018421052631579, AUC 0.9692965745925903, avg_entr 0.008062003180384636
ep27_l3_test_time 0.10192012786865234
Test Epoch27 layer4 Acc 0.9021052631578947, AUC 0.9694455862045288, avg_entr 0.007459786720573902
ep27_l4_test_time 0.12253308296203613
gc 0
Train Epoch28 Acc 0.974125 (116895/120000), AUC 0.9966039061546326
ep28_train_time 18.620686531066895
Test Epoch28 layer0 Acc 0.9057894736842105, AUC 0.9768139123916626, avg_entr 0.03923768922686577
ep28_l0_test_time 0.04444694519042969
Test Epoch28 layer1 Acc 0.9034210526315789, AUC 0.969570517539978, avg_entr 0.014045570977032185
ep28_l1_test_time 0.06265687942504883
Test Epoch28 layer2 Acc 0.9028947368421053, AUC 0.9706400632858276, avg_entr 0.009311535395681858
ep28_l2_test_time 0.08225846290588379
Test Epoch28 layer3 Acc 0.9018421052631579, AUC 0.9700833559036255, avg_entr 0.007909737527370453
ep28_l3_test_time 0.10264468193054199
Test Epoch28 layer4 Acc 0.9018421052631579, AUC 0.9698240756988525, avg_entr 0.0073746582493186
ep28_l4_test_time 0.12292194366455078
gc 0
Train Epoch29 Acc 0.9743916666666667 (116927/120000), AUC 0.9965840578079224
ep29_train_time 19.016164779663086
Test Epoch29 layer0 Acc 0.905, AUC 0.9768012166023254, avg_entr 0.039001692086458206
ep29_l0_test_time 0.04447579383850098
Test Epoch29 layer1 Acc 0.9034210526315789, AUC 0.9693673849105835, avg_entr 0.013906479813158512
ep29_l1_test_time 0.06270265579223633
Test Epoch29 layer2 Acc 0.9023684210526316, AUC 0.9701303243637085, avg_entr 0.009173635393381119
ep29_l2_test_time 0.08242630958557129
Test Epoch29 layer3 Acc 0.901578947368421, AUC 0.9689012765884399, avg_entr 0.00779965054243803
ep29_l3_test_time 0.1030116081237793
Test Epoch29 layer4 Acc 0.9018421052631579, AUC 0.9685554504394531, avg_entr 0.0072588748298585415
ep29_l4_test_time 0.12317585945129395
gc 0
Train Epoch30 Acc 0.974475 (116937/120000), AUC 0.9965694546699524
ep30_train_time 18.547208786010742
Test Epoch30 layer0 Acc 0.9052631578947369, AUC 0.9768041968345642, avg_entr 0.03893810883164406
ep30_l0_test_time 0.04421854019165039
Test Epoch30 layer1 Acc 0.9034210526315789, AUC 0.9692767262458801, avg_entr 0.01390348095446825
ep30_l1_test_time 0.06268572807312012
Test Epoch30 layer2 Acc 0.9021052631578947, AUC 0.9701422452926636, avg_entr 0.00917709432542324
ep30_l2_test_time 0.08241009712219238
Test Epoch30 layer3 Acc 0.901578947368421, AUC 0.9689913392066956, avg_entr 0.007814232259988785
ep30_l3_test_time 0.10259389877319336
Test Epoch30 layer4 Acc 0.901578947368421, AUC 0.9688881039619446, avg_entr 0.007284596096724272
ep30_l4_test_time 0.12315201759338379
gc 0
Train Epoch31 Acc 0.9745083333333333 (116941/120000), AUC 0.9964837431907654
ep31_train_time 18.293328046798706
Test Epoch31 layer0 Acc 0.905, AUC 0.9767950773239136, avg_entr 0.03879750519990921
ep31_l0_test_time 0.04375052452087402
Test Epoch31 layer1 Acc 0.9034210526315789, AUC 0.9691697359085083, avg_entr 0.013832448050379753
ep31_l1_test_time 0.06293082237243652
Test Epoch31 layer2 Acc 0.9023684210526316, AUC 0.9702582955360413, avg_entr 0.00913193728774786
ep31_l2_test_time 0.08253073692321777
Test Epoch31 layer3 Acc 0.9018421052631579, AUC 0.9693354368209839, avg_entr 0.007767348550260067
ep31_l3_test_time 0.10222434997558594
Test Epoch31 layer4 Acc 0.9021052631578947, AUC 0.9688988924026489, avg_entr 0.007188693154603243
ep31_l4_test_time 0.12271523475646973
gc 0
Train Epoch32 Acc 0.9745166666666667 (116942/120000), AUC 0.9966228604316711
ep32_train_time 18.574795484542847
Test Epoch32 layer0 Acc 0.9052631578947369, AUC 0.9767841696739197, avg_entr 0.038679249584674835
ep32_l0_test_time 0.044090986251831055
Test Epoch32 layer1 Acc 0.9036842105263158, AUC 0.9694173336029053, avg_entr 0.013852550648152828
ep32_l1_test_time 0.06307387351989746
Test Epoch32 layer2 Acc 0.9028947368421053, AUC 0.9706827998161316, avg_entr 0.009207545779645443
ep32_l2_test_time 0.0827028751373291
Test Epoch32 layer3 Acc 0.9018421052631579, AUC 0.9696158766746521, avg_entr 0.007693880703300238
ep32_l3_test_time 0.10282063484191895
Test Epoch32 layer4 Acc 0.9018421052631579, AUC 0.9688058495521545, avg_entr 0.007179789245128632
ep32_l4_test_time 0.12317967414855957
gc 0
Train Epoch33 Acc 0.9746083333333333 (116953/120000), AUC 0.9965366125106812
ep33_train_time 18.119504690170288
Test Epoch33 layer0 Acc 0.9052631578947369, AUC 0.9767869710922241, avg_entr 0.038607899099588394
ep33_l0_test_time 0.04486227035522461
Test Epoch33 layer1 Acc 0.9036842105263158, AUC 0.9691491723060608, avg_entr 0.013795255683362484
ep33_l1_test_time 0.06309866905212402
Test Epoch33 layer2 Acc 0.9028947368421053, AUC 0.9697526693344116, avg_entr 0.00913246814161539
ep33_l2_test_time 0.0826876163482666
Test Epoch33 layer3 Acc 0.9018421052631579, AUC 0.9686217904090881, avg_entr 0.00761762447655201
ep33_l3_test_time 0.10256075859069824
Test Epoch33 layer4 Acc 0.9018421052631579, AUC 0.9678109288215637, avg_entr 0.007119097281247377
ep33_l4_test_time 0.12309646606445312
gc 0
Train Epoch34 Acc 0.9744666666666667 (116936/120000), AUC 0.9964523911476135
ep34_train_time 18.12941288948059
Test Epoch34 layer0 Acc 0.9057894736842105, AUC 0.9767828583717346, avg_entr 0.038567714393138885
ep34_l0_test_time 0.04416513442993164
Test Epoch34 layer1 Acc 0.9034210526315789, AUC 0.9693215489387512, avg_entr 0.013831237331032753
ep34_l1_test_time 0.0628969669342041
Test Epoch34 layer2 Acc 0.9026315789473685, AUC 0.9703691005706787, avg_entr 0.009155463427305222
ep34_l2_test_time 0.08246040344238281
Test Epoch34 layer3 Acc 0.9018421052631579, AUC 0.969379186630249, avg_entr 0.0076362499967217445
ep34_l3_test_time 0.10273456573486328
Test Epoch34 layer4 Acc 0.901578947368421, AUC 0.9691697359085083, avg_entr 0.007170618046075106
ep34_l4_test_time 0.12315869331359863
gc 0
Train Epoch35 Acc 0.9745333333333334 (116944/120000), AUC 0.9964888095855713
ep35_train_time 18.667881965637207
Test Epoch35 layer0 Acc 0.9052631578947369, AUC 0.976781964302063, avg_entr 0.0384882427752018
ep35_l0_test_time 0.044268131256103516
Test Epoch35 layer1 Acc 0.9034210526315789, AUC 0.9692896008491516, avg_entr 0.013792695477604866
ep35_l1_test_time 0.06256318092346191
Test Epoch35 layer2 Acc 0.9026315789473685, AUC 0.970184326171875, avg_entr 0.00909296702593565
ep35_l2_test_time 0.08228373527526855
Test Epoch35 layer3 Acc 0.9013157894736842, AUC 0.9690559506416321, avg_entr 0.00757190166041255
ep35_l3_test_time 0.10275626182556152
Test Epoch35 layer4 Acc 0.901578947368421, AUC 0.9681920409202576, avg_entr 0.007077984511852264
ep35_l4_test_time 0.12299966812133789
gc 0
Train Epoch36 Acc 0.974675 (116961/120000), AUC 0.9966193437576294
ep36_train_time 18.307363748550415
Test Epoch36 layer0 Acc 0.9052631578947369, AUC 0.9767820835113525, avg_entr 0.0384722538292408
ep36_l0_test_time 0.0435030460357666
Test Epoch36 layer1 Acc 0.9034210526315789, AUC 0.9692624807357788, avg_entr 0.013809039257466793
ep36_l1_test_time 0.062222957611083984
Test Epoch36 layer2 Acc 0.9026315789473685, AUC 0.970110297203064, avg_entr 0.009093399159610271
ep36_l2_test_time 0.08219051361083984
Test Epoch36 layer3 Acc 0.9013157894736842, AUC 0.9690831899642944, avg_entr 0.007575104478746653
ep36_l3_test_time 0.10275125503540039
Test Epoch36 layer4 Acc 0.901578947368421, AUC 0.968474805355072, avg_entr 0.007119219750165939
ep36_l4_test_time 0.12263298034667969
gc 0
Train Epoch37 Acc 0.9745416666666666 (116945/120000), AUC 0.9964990615844727
ep37_train_time 17.938181400299072
Test Epoch37 layer0 Acc 0.9052631578947369, AUC 0.9767760634422302, avg_entr 0.03844073787331581
ep37_l0_test_time 0.04463768005371094
Test Epoch37 layer1 Acc 0.9036842105263158, AUC 0.9692910313606262, avg_entr 0.013814675621688366
ep37_l1_test_time 0.06523466110229492
Test Epoch37 layer2 Acc 0.9026315789473685, AUC 0.970024824142456, avg_entr 0.009110512211918831
ep37_l2_test_time 0.08234977722167969
Test Epoch37 layer3 Acc 0.901578947368421, AUC 0.968940019607544, avg_entr 0.00757897412404418
ep37_l3_test_time 0.10234260559082031
Test Epoch37 layer4 Acc 0.901578947368421, AUC 0.9681733250617981, avg_entr 0.007120141293853521
ep37_l4_test_time 0.12270808219909668
gc 0
Train Epoch38 Acc 0.97465 (116958/120000), AUC 0.9966614246368408
ep38_train_time 18.152265310287476
Test Epoch38 layer0 Acc 0.905, AUC 0.9767682552337646, avg_entr 0.03840293362736702
ep38_l0_test_time 0.0439453125
Test Epoch38 layer1 Acc 0.9034210526315789, AUC 0.9692324995994568, avg_entr 0.013775133527815342
ep38_l1_test_time 0.06266093254089355
Test Epoch38 layer2 Acc 0.9028947368421053, AUC 0.9699958562850952, avg_entr 0.009085692465305328
ep38_l2_test_time 0.08188867568969727
Test Epoch38 layer3 Acc 0.9021052631578947, AUC 0.9687677621841431, avg_entr 0.007518742233514786
ep38_l3_test_time 0.1023261547088623
Test Epoch38 layer4 Acc 0.901578947368421, AUC 0.9678555727005005, avg_entr 0.007037841249257326
ep38_l4_test_time 0.12259411811828613
gc 0
Train Epoch39 Acc 0.974575 (116949/120000), AUC 0.9966669678688049
ep39_train_time 18.786767959594727
Test Epoch39 layer0 Acc 0.9052631578947369, AUC 0.9767681360244751, avg_entr 0.03839525207877159
ep39_l0_test_time 0.04403090476989746
Test Epoch39 layer1 Acc 0.9034210526315789, AUC 0.9692748188972473, avg_entr 0.01380623783916235
ep39_l1_test_time 0.06273388862609863
Test Epoch39 layer2 Acc 0.9023684210526316, AUC 0.9701295495033264, avg_entr 0.009105254895985126
ep39_l2_test_time 0.08241462707519531
Test Epoch39 layer3 Acc 0.901578947368421, AUC 0.9689773917198181, avg_entr 0.00755884125828743
ep39_l3_test_time 0.1027226448059082
Test Epoch39 layer4 Acc 0.901578947368421, AUC 0.9687517881393433, avg_entr 0.007100233342498541
ep39_l4_test_time 0.12278246879577637
gc 0
Train Epoch40 Acc 0.97465 (116958/120000), AUC 0.9967012405395508
ep40_train_time 18.206169843673706
Test Epoch40 layer0 Acc 0.9052631578947369, AUC 0.976767897605896, avg_entr 0.038381896913051605
ep40_l0_test_time 0.04409337043762207
Test Epoch40 layer1 Acc 0.9034210526315789, AUC 0.9692518711090088, avg_entr 0.013790551573038101
ep40_l1_test_time 0.06267714500427246
Test Epoch40 layer2 Acc 0.9023684210526316, AUC 0.9699552059173584, avg_entr 0.009066932834684849
ep40_l2_test_time 0.08256173133850098
Test Epoch40 layer3 Acc 0.901578947368421, AUC 0.9688745737075806, avg_entr 0.0075183748267591
ep40_l3_test_time 0.10267066955566406
Test Epoch40 layer4 Acc 0.901578947368421, AUC 0.968485951423645, avg_entr 0.007046178448945284
ep40_l4_test_time 0.1232137680053711
gc 0
Train Epoch41 Acc 0.9748166666666667 (116978/120000), AUC 0.9965419769287109
ep41_train_time 18.347675800323486
Test Epoch41 layer0 Acc 0.9052631578947369, AUC 0.9767687320709229, avg_entr 0.03835916146636009
ep41_l0_test_time 0.043866872787475586
Test Epoch41 layer1 Acc 0.9034210526315789, AUC 0.9692968130111694, avg_entr 0.0138016939163208
ep41_l1_test_time 0.0625917911529541
Test Epoch41 layer2 Acc 0.9023684210526316, AUC 0.9700092673301697, avg_entr 0.00909609254449606
ep41_l2_test_time 0.08250880241394043
Test Epoch41 layer3 Acc 0.9013157894736842, AUC 0.9689205288887024, avg_entr 0.007539955899119377
ep41_l3_test_time 0.10300064086914062
Test Epoch41 layer4 Acc 0.901578947368421, AUC 0.9683787822723389, avg_entr 0.007085115648806095
ep41_l4_test_time 0.1228334903717041
gc 0
Train Epoch42 Acc 0.9746 (116952/120000), AUC 0.9966192245483398
ep42_train_time 18.53241276741028
Test Epoch42 layer0 Acc 0.9052631578947369, AUC 0.9767669439315796, avg_entr 0.038335151970386505
ep42_l0_test_time 0.04372906684875488
Test Epoch42 layer1 Acc 0.9034210526315789, AUC 0.9692558646202087, avg_entr 0.01379275694489479
ep42_l1_test_time 0.062278032302856445
Test Epoch42 layer2 Acc 0.9026315789473685, AUC 0.9700282216072083, avg_entr 0.009094109758734703
ep42_l2_test_time 0.08233261108398438
Test Epoch42 layer3 Acc 0.901578947368421, AUC 0.9687964916229248, avg_entr 0.007520368788391352
ep42_l3_test_time 0.10198211669921875
Test Epoch42 layer4 Acc 0.901578947368421, AUC 0.9682837724685669, avg_entr 0.0070655457675457
ep42_l4_test_time 0.12254905700683594
gc 0
Train Epoch43 Acc 0.9746416666666666 (116957/120000), AUC 0.996511697769165
ep43_train_time 18.09059166908264
Test Epoch43 layer0 Acc 0.9052631578947369, AUC 0.9767665863037109, avg_entr 0.03833337128162384
ep43_l0_test_time 0.04621767997741699
Test Epoch43 layer1 Acc 0.9034210526315789, AUC 0.9692525863647461, avg_entr 0.013792143203318119
ep43_l1_test_time 0.06360936164855957
Test Epoch43 layer2 Acc 0.9023684210526316, AUC 0.9699705243110657, avg_entr 0.009084314107894897
ep43_l2_test_time 0.0836176872253418
Test Epoch43 layer3 Acc 0.9013157894736842, AUC 0.9688832759857178, avg_entr 0.007519182749092579
ep43_l3_test_time 0.10340380668640137
Test Epoch43 layer4 Acc 0.901578947368421, AUC 0.9682829976081848, avg_entr 0.007061364594846964
ep43_l4_test_time 0.12316775321960449
gc 0
Train Epoch44 Acc 0.9746666666666667 (116960/120000), AUC 0.9965120553970337
ep44_train_time 18.38382339477539
Test Epoch44 layer0 Acc 0.9052631578947369, AUC 0.9767664670944214, avg_entr 0.03832758963108063
ep44_l0_test_time 0.04431629180908203
Test Epoch44 layer1 Acc 0.9034210526315789, AUC 0.9692588448524475, avg_entr 0.013795999810099602
ep44_l1_test_time 0.06250119209289551
Test Epoch44 layer2 Acc 0.9023684210526316, AUC 0.9700501561164856, avg_entr 0.009076127782464027
ep44_l2_test_time 0.08240222930908203
Test Epoch44 layer3 Acc 0.9013157894736842, AUC 0.9689381122589111, avg_entr 0.007515514735132456
ep44_l3_test_time 0.1024925708770752
Test Epoch44 layer4 Acc 0.901578947368421, AUC 0.968409538269043, avg_entr 0.007056668866425753
ep44_l4_test_time 0.12288665771484375
gc 0
Train Epoch45 Acc 0.9747166666666667 (116966/120000), AUC 0.9965211153030396
ep45_train_time 18.143617153167725
Test Epoch45 layer0 Acc 0.9052631578947369, AUC 0.976766049861908, avg_entr 0.03831872344017029
ep45_l0_test_time 0.04385972023010254
Test Epoch45 layer1 Acc 0.9034210526315789, AUC 0.9692449569702148, avg_entr 0.013788662850856781
ep45_l1_test_time 0.06314373016357422
Test Epoch45 layer2 Acc 0.9023684210526316, AUC 0.9700409173965454, avg_entr 0.009075340814888477
ep45_l2_test_time 0.08235740661621094
Test Epoch45 layer3 Acc 0.901578947368421, AUC 0.9689185619354248, avg_entr 0.007504596374928951
ep45_l3_test_time 0.10257983207702637
Test Epoch45 layer4 Acc 0.901578947368421, AUC 0.9682223200798035, avg_entr 0.007045792881399393
ep45_l4_test_time 0.12279653549194336
gc 0
Train Epoch46 Acc 0.97485 (116982/120000), AUC 0.9965502619743347
ep46_train_time 18.086272716522217
Test Epoch46 layer0 Acc 0.9052631578947369, AUC 0.976763129234314, avg_entr 0.0383128896355629
ep46_l0_test_time 0.04441714286804199
Test Epoch46 layer1 Acc 0.9034210526315789, AUC 0.9692471027374268, avg_entr 0.013788141310214996
ep46_l1_test_time 0.06301331520080566
Test Epoch46 layer2 Acc 0.9021052631578947, AUC 0.9700088500976562, avg_entr 0.009068198502063751
ep46_l2_test_time 0.08262491226196289
Test Epoch46 layer3 Acc 0.901578947368421, AUC 0.9688607454299927, avg_entr 0.0074975923635065556
ep46_l3_test_time 0.10259795188903809
Test Epoch46 layer4 Acc 0.901578947368421, AUC 0.9682580828666687, avg_entr 0.0070343841798603535
ep46_l4_test_time 0.12315177917480469
gc 0
Train Epoch47 Acc 0.9746083333333333 (116953/120000), AUC 0.9966135025024414
ep47_train_time 18.201860427856445
Test Epoch47 layer0 Acc 0.9052631578947369, AUC 0.9767624139785767, avg_entr 0.038309041410684586
ep47_l0_test_time 0.04431009292602539
Test Epoch47 layer1 Acc 0.9034210526315789, AUC 0.9692514538764954, avg_entr 0.013788668438792229
ep47_l1_test_time 0.06311464309692383
Test Epoch47 layer2 Acc 0.9021052631578947, AUC 0.9700016379356384, avg_entr 0.009072763845324516
ep47_l2_test_time 0.08254146575927734
Test Epoch47 layer3 Acc 0.901578947368421, AUC 0.9688659906387329, avg_entr 0.007501673419028521
ep47_l3_test_time 0.10262632369995117
Test Epoch47 layer4 Acc 0.901578947368421, AUC 0.9682633876800537, avg_entr 0.0070417155511677265
ep47_l4_test_time 0.12279033660888672
gc 0
Train Epoch48 Acc 0.9747416666666666 (116969/120000), AUC 0.9966540932655334
ep48_train_time 18.234964847564697
Test Epoch48 layer0 Acc 0.9052631578947369, AUC 0.9767624139785767, avg_entr 0.03830549493432045
ep48_l0_test_time 0.04387354850769043
Test Epoch48 layer1 Acc 0.9034210526315789, AUC 0.9692518711090088, avg_entr 0.01379168126732111
ep48_l1_test_time 0.06294655799865723
Test Epoch48 layer2 Acc 0.9023684210526316, AUC 0.9699962735176086, avg_entr 0.009083283133804798
ep48_l2_test_time 0.08245015144348145
Test Epoch48 layer3 Acc 0.9013157894736842, AUC 0.9688815474510193, avg_entr 0.007511084899306297
ep48_l3_test_time 0.10300016403198242
Test Epoch48 layer4 Acc 0.901578947368421, AUC 0.9682514667510986, avg_entr 0.007058309391140938
ep48_l4_test_time 0.12374138832092285
gc 0
Train Epoch49 Acc 0.9747333333333333 (116968/120000), AUC 0.9966374635696411
ep49_train_time 18.425488710403442
Test Epoch49 layer0 Acc 0.9052631578947369, AUC 0.9767622351646423, avg_entr 0.038301993161439896
ep49_l0_test_time 0.04383397102355957
Test Epoch49 layer1 Acc 0.9034210526315789, AUC 0.9692499041557312, avg_entr 0.01379147358238697
ep49_l1_test_time 0.06278443336486816
Test Epoch49 layer2 Acc 0.9023684210526316, AUC 0.9699953198432922, avg_entr 0.009081710129976273
ep49_l2_test_time 0.08271360397338867
Test Epoch49 layer3 Acc 0.9013157894736842, AUC 0.9688923358917236, avg_entr 0.007508695591241121
ep49_l3_test_time 0.10289239883422852
Test Epoch49 layer4 Acc 0.901578947368421, AUC 0.9682431221008301, avg_entr 0.0070543717592954636
ep49_l4_test_time 0.12317180633544922
Best AUC 0.9805202484130859
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train+valid_time 938.6370282173157
Start Testing
Load ckpt at ckpt/ag_news_transformeral_l5_pad25//ag_news_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.9181578947368421, AUC 0.9839982986450195, avg_entr 0.08142668753862381
ep49_l0_test_time 0.04261970520019531
Test Epoch49 layer1 Acc 0.9207894736842105, AUC 0.9829131960868835, avg_entr 0.031509339809417725
ep49_l1_test_time 0.06291460990905762
Test Epoch49 layer2 Acc 0.9218421052631579, AUC 0.9845013618469238, avg_entr 0.02518308535218239
ep49_l2_test_time 0.08270096778869629
Test Epoch49 layer3 Acc 0.9213157894736842, AUC 0.9845064878463745, avg_entr 0.02284087799489498
ep49_l3_test_time 0.10321164131164551
Test Epoch49 layer4 Acc 0.9221052631578948, AUC 0.9846252799034119, avg_entr 0.02128390036523342
ep49_l4_test_time 0.12396121025085449
