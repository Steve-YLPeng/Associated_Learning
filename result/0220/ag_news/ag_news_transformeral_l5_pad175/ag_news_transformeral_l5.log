total count words 102019
vocab size 30000
found 26754 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13672292
init_time 20.125808715820312
Start Training
gc 0
Train Epoch0 Acc 0.6437916666666667 (77255/120000), AUC 0.8623883128166199
ep0_train_time 80.477609872818
Test Epoch0 layer0 Acc 0.8934210526315789, AUC 0.9713807702064514, avg_entr 0.25126004219055176
ep0_l0_test_time 0.1674811840057373
Save ckpt to ckpt/ag_news_transformeral_l5_pad175//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9005263157894737, AUC 0.9745413064956665, avg_entr 0.16424740850925446
ep0_l1_test_time 0.2863459587097168
Save ckpt to ckpt/ag_news_transformeral_l5_pad175//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.8978947368421053, AUC 0.9747341275215149, avg_entr 0.1510162651538849
ep0_l2_test_time 0.41391444206237793
Save ckpt to ckpt/ag_news_transformeral_l5_pad175//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer3 Acc 0.9005263157894737, AUC 0.9749045372009277, avg_entr 0.14731155335903168
ep0_l3_test_time 0.539201021194458
Save ckpt to ckpt/ag_news_transformeral_l5_pad175//ag_news_transformeral_l5.pt  ,ep 0
Test Epoch0 layer4 Acc 0.8960526315789473, AUC 0.974976658821106, avg_entr 0.14975112676620483
ep0_l4_test_time 0.6640372276306152
Save ckpt to ckpt/ag_news_transformeral_l5_pad175//ag_news_transformeral_l5.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.919225 (110307/120000), AUC 0.9811350107192993
ep1_train_time 80.02481961250305
Test Epoch1 layer0 Acc 0.9060526315789473, AUC 0.9758592844009399, avg_entr 0.14599476754665375
ep1_l0_test_time 0.15622949600219727
Save ckpt to ckpt/ag_news_transformeral_l5_pad175//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.9118421052631579, AUC 0.9791170358657837, avg_entr 0.0815398171544075
ep1_l1_test_time 0.2884092330932617
Save ckpt to ckpt/ag_news_transformeral_l5_pad175//ag_news_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.9113157894736842, AUC 0.9782290458679199, avg_entr 0.06936553120613098
ep1_l2_test_time 0.41614198684692383
Test Epoch1 layer3 Acc 0.9126315789473685, AUC 0.9783289432525635, avg_entr 0.060166262090206146
ep1_l3_test_time 0.5391736030578613
Test Epoch1 layer4 Acc 0.9113157894736842, AUC 0.9785887002944946, avg_entr 0.06056416407227516
ep1_l4_test_time 0.6642279624938965
gc 0
Train Epoch2 Acc 0.9347333333333333 (112168/120000), AUC 0.9866864681243896
ep2_train_time 80.18176484107971
Test Epoch2 layer0 Acc 0.9094736842105263, AUC 0.9777663350105286, avg_entr 0.11089234799146652
ep2_l0_test_time 0.16029953956604004
Test Epoch2 layer1 Acc 0.9136842105263158, AUC 0.9806704521179199, avg_entr 0.04550084099173546
ep2_l1_test_time 0.28594136238098145
Save ckpt to ckpt/ag_news_transformeral_l5_pad175//ag_news_transformeral_l5.pt  ,ep 2
Test Epoch2 layer2 Acc 0.9136842105263158, AUC 0.9805094003677368, avg_entr 0.03871773183345795
ep2_l2_test_time 0.41513800621032715
Test Epoch2 layer3 Acc 0.9144736842105263, AUC 0.9800945520401001, avg_entr 0.0348413847386837
ep2_l3_test_time 0.5384016036987305
Test Epoch2 layer4 Acc 0.9144736842105263, AUC 0.9806180596351624, avg_entr 0.03352222591638565
ep2_l4_test_time 0.6624248027801514
gc 0
Train Epoch3 Acc 0.9423083333333333 (113077/120000), AUC 0.9887939691543579
ep3_train_time 80.00927114486694
Test Epoch3 layer0 Acc 0.9134210526315789, AUC 0.9785750508308411, avg_entr 0.0939328670501709
ep3_l0_test_time 0.15745806694030762
Test Epoch3 layer1 Acc 0.9147368421052632, AUC 0.9792890548706055, avg_entr 0.03337975963950157
ep3_l1_test_time 0.2867090702056885
Test Epoch3 layer2 Acc 0.9155263157894736, AUC 0.9810423851013184, avg_entr 0.0278164129704237
ep3_l2_test_time 0.4132506847381592
Save ckpt to ckpt/ag_news_transformeral_l5_pad175//ag_news_transformeral_l5.pt  ,ep 3
Test Epoch3 layer3 Acc 0.9157894736842105, AUC 0.9801995754241943, avg_entr 0.025194484740495682
ep3_l3_test_time 0.5431272983551025
Test Epoch3 layer4 Acc 0.9160526315789473, AUC 0.9814496040344238, avg_entr 0.02460610121488571
ep3_l4_test_time 0.6628997325897217
Save ckpt to ckpt/ag_news_transformeral_l5_pad175//ag_news_transformeral_l5.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.9481583333333333 (113779/120000), AUC 0.9902772903442383
ep4_train_time 80.05929160118103
Test Epoch4 layer0 Acc 0.9086842105263158, AUC 0.9787164926528931, avg_entr 0.08364924043416977
ep4_l0_test_time 0.157501220703125
Test Epoch4 layer1 Acc 0.9121052631578948, AUC 0.9766147136688232, avg_entr 0.028640806674957275
ep4_l1_test_time 0.28609466552734375
Test Epoch4 layer2 Acc 0.9121052631578948, AUC 0.9774043560028076, avg_entr 0.023235265165567398
ep4_l2_test_time 0.4132096767425537
Test Epoch4 layer3 Acc 0.9121052631578948, AUC 0.9765118360519409, avg_entr 0.021601641550660133
ep4_l3_test_time 0.5388126373291016
Test Epoch4 layer4 Acc 0.9121052631578948, AUC 0.9776930212974548, avg_entr 0.020973483100533485
ep4_l4_test_time 0.6625633239746094
gc 0
Train Epoch5 Acc 0.951775 (114213/120000), AUC 0.9914594888687134
ep5_train_time 80.03327751159668
Test Epoch5 layer0 Acc 0.9118421052631579, AUC 0.9789286255836487, avg_entr 0.07328081876039505
ep5_l0_test_time 0.15707898139953613
Test Epoch5 layer1 Acc 0.9123684210526316, AUC 0.9797905683517456, avg_entr 0.027374712750315666
ep5_l1_test_time 0.28687334060668945
Test Epoch5 layer2 Acc 0.9113157894736842, AUC 0.9805132150650024, avg_entr 0.022322217002511024
ep5_l2_test_time 0.4121274948120117
Test Epoch5 layer3 Acc 0.9102631578947369, AUC 0.98026442527771, avg_entr 0.020671997219324112
ep5_l3_test_time 0.5384056568145752
Test Epoch5 layer4 Acc 0.9102631578947369, AUC 0.9807760715484619, avg_entr 0.019335715100169182
ep5_l4_test_time 0.6632258892059326
gc 0
Train Epoch6 Acc 0.9552916666666667 (114635/120000), AUC 0.9921197891235352
ep6_train_time 80.05741548538208
Test Epoch6 layer0 Acc 0.9094736842105263, AUC 0.9787483215332031, avg_entr 0.07062990963459015
ep6_l0_test_time 0.15616536140441895
Test Epoch6 layer1 Acc 0.9121052631578948, AUC 0.9772669076919556, avg_entr 0.024612393230199814
ep6_l1_test_time 0.286304235458374
Test Epoch6 layer2 Acc 0.9118421052631579, AUC 0.9780385494232178, avg_entr 0.01920698955655098
ep6_l2_test_time 0.41251325607299805
Test Epoch6 layer3 Acc 0.9113157894736842, AUC 0.9776259660720825, avg_entr 0.01771899126470089
ep6_l3_test_time 0.5386719703674316
Test Epoch6 layer4 Acc 0.9105263157894737, AUC 0.9792122840881348, avg_entr 0.016309987753629684
ep6_l4_test_time 0.6616921424865723
gc 0
Train Epoch7 Acc 0.9581833333333334 (114982/120000), AUC 0.9929686188697815
ep7_train_time 80.03239035606384
Test Epoch7 layer0 Acc 0.9092105263157895, AUC 0.9789301753044128, avg_entr 0.06419687718153
ep7_l0_test_time 0.1571054458618164
Test Epoch7 layer1 Acc 0.91, AUC 0.9777042865753174, avg_entr 0.02343761920928955
ep7_l1_test_time 0.28618717193603516
Test Epoch7 layer2 Acc 0.9094736842105263, AUC 0.978520929813385, avg_entr 0.01783699356019497
ep7_l2_test_time 0.41210412979125977
Test Epoch7 layer3 Acc 0.908157894736842, AUC 0.9780487418174744, avg_entr 0.01647375524044037
ep7_l3_test_time 0.5373141765594482
Test Epoch7 layer4 Acc 0.9078947368421053, AUC 0.9784858226776123, avg_entr 0.015414993278682232
ep7_l4_test_time 0.662100076675415
gc 0
Train Epoch8 Acc 0.9601333333333333 (115216/120000), AUC 0.993712306022644
ep8_train_time 80.11666107177734
Test Epoch8 layer0 Acc 0.9110526315789473, AUC 0.9789023399353027, avg_entr 0.05990726500749588
ep8_l0_test_time 0.15778565406799316
Test Epoch8 layer1 Acc 0.9110526315789473, AUC 0.975426197052002, avg_entr 0.021928610280156136
ep8_l1_test_time 0.28681397438049316
Test Epoch8 layer2 Acc 0.91, AUC 0.9764986038208008, avg_entr 0.01625591143965721
ep8_l2_test_time 0.41374969482421875
Test Epoch8 layer3 Acc 0.9094736842105263, AUC 0.9769504070281982, avg_entr 0.014596124179661274
ep8_l3_test_time 0.5384891033172607
Test Epoch8 layer4 Acc 0.9097368421052632, AUC 0.9768822193145752, avg_entr 0.013527840375900269
ep8_l4_test_time 0.6641380786895752
gc 0
Train Epoch9 Acc 0.961875 (115425/120000), AUC 0.9940623044967651
ep9_train_time 80.22775363922119
Test Epoch9 layer0 Acc 0.908157894736842, AUC 0.9786388278007507, avg_entr 0.05683830752968788
ep9_l0_test_time 0.15714526176452637
Test Epoch9 layer1 Acc 0.9094736842105263, AUC 0.9756689071655273, avg_entr 0.021382533013820648
ep9_l1_test_time 0.2857327461242676
Test Epoch9 layer2 Acc 0.9092105263157895, AUC 0.9763557314872742, avg_entr 0.015605313703417778
ep9_l2_test_time 0.41200852394104004
Test Epoch9 layer3 Acc 0.9086842105263158, AUC 0.9758831262588501, avg_entr 0.014406627975404263
ep9_l3_test_time 0.5372943878173828
Test Epoch9 layer4 Acc 0.9086842105263158, AUC 0.9771977663040161, avg_entr 0.013137067668139935
ep9_l4_test_time 0.6621608734130859
gc 0
Train Epoch10 Acc 0.9646 (115752/120000), AUC 0.9947465062141418
ep10_train_time 80.11147117614746
Test Epoch10 layer0 Acc 0.9102631578947369, AUC 0.9786189794540405, avg_entr 0.055410128086805344
ep10_l0_test_time 0.15677976608276367
Test Epoch10 layer1 Acc 0.906578947368421, AUC 0.9742062091827393, avg_entr 0.021354831755161285
ep10_l1_test_time 0.28601717948913574
Test Epoch10 layer2 Acc 0.906578947368421, AUC 0.9752436280250549, avg_entr 0.015250681899487972
ep10_l2_test_time 0.4131202697753906
Test Epoch10 layer3 Acc 0.9073684210526316, AUC 0.9757369756698608, avg_entr 0.013513317331671715
ep10_l3_test_time 0.5379586219787598
Test Epoch10 layer4 Acc 0.9071052631578947, AUC 0.9758241176605225, avg_entr 0.012250607833266258
ep10_l4_test_time 0.662956714630127
gc 0
Train Epoch11 Acc 0.96585 (115902/120000), AUC 0.9948951601982117
ep11_train_time 80.23536562919617
Test Epoch11 layer0 Acc 0.9118421052631579, AUC 0.9783099889755249, avg_entr 0.0527128204703331
ep11_l0_test_time 0.15627646446228027
Test Epoch11 layer1 Acc 0.9086842105263158, AUC 0.9734755754470825, avg_entr 0.019435949623584747
ep11_l1_test_time 0.28580808639526367
Test Epoch11 layer2 Acc 0.9068421052631579, AUC 0.9748387336730957, avg_entr 0.014244151301681995
ep11_l2_test_time 0.41248464584350586
Test Epoch11 layer3 Acc 0.9068421052631579, AUC 0.9735090732574463, avg_entr 0.013427664525806904
ep11_l3_test_time 0.5379452705383301
Test Epoch11 layer4 Acc 0.9076315789473685, AUC 0.9730914235115051, avg_entr 0.012132407166063786
ep11_l4_test_time 0.662578821182251
gc 0
Train Epoch12 Acc 0.9664333333333334 (115972/120000), AUC 0.9952490329742432
ep12_train_time 80.11927843093872
Test Epoch12 layer0 Acc 0.9113157894736842, AUC 0.9783159494400024, avg_entr 0.05067538470029831
ep12_l0_test_time 0.15827059745788574
Test Epoch12 layer1 Acc 0.9060526315789473, AUC 0.9730077981948853, avg_entr 0.01901533454656601
ep12_l1_test_time 0.2875490188598633
Test Epoch12 layer2 Acc 0.9055263157894737, AUC 0.9736436009407043, avg_entr 0.013258003629744053
ep12_l2_test_time 0.4142158031463623
Test Epoch12 layer3 Acc 0.9055263157894737, AUC 0.9742785096168518, avg_entr 0.012334580533206463
ep12_l3_test_time 0.539370059967041
Test Epoch12 layer4 Acc 0.905, AUC 0.9750868678092957, avg_entr 0.010975305922329426
ep12_l4_test_time 0.6628191471099854
gc 0
Train Epoch13 Acc 0.9672666666666667 (116072/120000), AUC 0.9953417778015137
ep13_train_time 80.22519874572754
Test Epoch13 layer0 Acc 0.91, AUC 0.9783185124397278, avg_entr 0.0482846200466156
ep13_l0_test_time 0.15996003150939941
Test Epoch13 layer1 Acc 0.9063157894736842, AUC 0.9725797772407532, avg_entr 0.018273858353495598
ep13_l1_test_time 0.2860889434814453
Test Epoch13 layer2 Acc 0.9073684210526316, AUC 0.9732521176338196, avg_entr 0.011939211748540401
ep13_l2_test_time 0.4124603271484375
Test Epoch13 layer3 Acc 0.9068421052631579, AUC 0.9733552932739258, avg_entr 0.011244087480008602
ep13_l3_test_time 0.539661169052124
Test Epoch13 layer4 Acc 0.9068421052631579, AUC 0.974389910697937, avg_entr 0.01050457265228033
ep13_l4_test_time 0.6617224216461182
gc 0
Train Epoch14 Acc 0.968525 (116223/120000), AUC 0.9957621097564697
ep14_train_time 80.10731649398804
Test Epoch14 layer0 Acc 0.9110526315789473, AUC 0.9781756401062012, avg_entr 0.04777584224939346
ep14_l0_test_time 0.1565406322479248
Test Epoch14 layer1 Acc 0.905, AUC 0.9720383286476135, avg_entr 0.01800517365336418
ep14_l1_test_time 0.28572773933410645
Test Epoch14 layer2 Acc 0.9026315789473685, AUC 0.9724686741828918, avg_entr 0.01194599736481905
ep14_l2_test_time 0.4121408462524414
Test Epoch14 layer3 Acc 0.9026315789473685, AUC 0.9710668325424194, avg_entr 0.010717038065195084
ep14_l3_test_time 0.5374486446380615
Test Epoch14 layer4 Acc 0.9023684210526316, AUC 0.9727487564086914, avg_entr 0.009708092547953129
ep14_l4_test_time 0.661888837814331
gc 0
Train Epoch15 Acc 0.9692 (116304/120000), AUC 0.9956051111221313
ep15_train_time 80.08279800415039
Test Epoch15 layer0 Acc 0.91, AUC 0.9781588315963745, avg_entr 0.04611825570464134
ep15_l0_test_time 0.15627837181091309
Test Epoch15 layer1 Acc 0.905, AUC 0.9716458320617676, avg_entr 0.01739903911948204
ep15_l1_test_time 0.285830020904541
Test Epoch15 layer2 Acc 0.905, AUC 0.9720994234085083, avg_entr 0.011845548637211323
ep15_l2_test_time 0.4123806953430176
Test Epoch15 layer3 Acc 0.905, AUC 0.9710437059402466, avg_entr 0.010576908476650715
ep15_l3_test_time 0.538029670715332
Test Epoch15 layer4 Acc 0.9044736842105263, AUC 0.9736344218254089, avg_entr 0.009773035533726215
ep15_l4_test_time 0.6615509986877441
gc 0
Train Epoch16 Acc 0.9695583333333333 (116347/120000), AUC 0.9959485530853271
ep16_train_time 80.20746850967407
Test Epoch16 layer0 Acc 0.9097368421052632, AUC 0.9781404733657837, avg_entr 0.04537871852517128
ep16_l0_test_time 0.15718555450439453
Test Epoch16 layer1 Acc 0.9055263157894737, AUC 0.971306324005127, avg_entr 0.017230184748768806
ep16_l1_test_time 0.28601670265197754
Test Epoch16 layer2 Acc 0.9047368421052632, AUC 0.9711595177650452, avg_entr 0.01027931459248066
ep16_l2_test_time 0.41217875480651855
Test Epoch16 layer3 Acc 0.9044736842105263, AUC 0.9704152941703796, avg_entr 0.008923312649130821
ep16_l3_test_time 0.537667989730835
Test Epoch16 layer4 Acc 0.9044736842105263, AUC 0.970824658870697, avg_entr 0.007966144010424614
ep16_l4_test_time 0.6619901657104492
gc 0
Train Epoch17 Acc 0.9698833333333333 (116386/120000), AUC 0.9958405494689941
ep17_train_time 80.09222102165222
Test Epoch17 layer0 Acc 0.9089473684210526, AUC 0.97807776927948, avg_entr 0.04431208595633507
ep17_l0_test_time 0.15739989280700684
Test Epoch17 layer1 Acc 0.9047368421052632, AUC 0.9708661437034607, avg_entr 0.017015118151903152
ep17_l1_test_time 0.28691935539245605
Test Epoch17 layer2 Acc 0.9036842105263158, AUC 0.9711329936981201, avg_entr 0.00994067545980215
ep17_l2_test_time 0.41362428665161133
Test Epoch17 layer3 Acc 0.9039473684210526, AUC 0.9688528776168823, avg_entr 0.008718396537005901
ep17_l3_test_time 0.5389246940612793
Test Epoch17 layer4 Acc 0.9039473684210526, AUC 0.9690173268318176, avg_entr 0.007791256997734308
ep17_l4_test_time 0.6631028652191162
gc 0
Train Epoch18 Acc 0.9705833333333334 (116470/120000), AUC 0.9961200952529907
ep18_train_time 80.1189215183258
Test Epoch18 layer0 Acc 0.9105263157894737, AUC 0.9780783653259277, avg_entr 0.04276799410581589
ep18_l0_test_time 0.16068363189697266
Test Epoch18 layer1 Acc 0.9047368421052632, AUC 0.9695978760719299, avg_entr 0.01618974655866623
ep18_l1_test_time 0.287306547164917
Test Epoch18 layer2 Acc 0.9047368421052632, AUC 0.9689900875091553, avg_entr 0.009519846178591251
ep18_l2_test_time 0.4134507179260254
Test Epoch18 layer3 Acc 0.9044736842105263, AUC 0.9678406119346619, avg_entr 0.008013108745217323
ep18_l3_test_time 0.538740873336792
Test Epoch18 layer4 Acc 0.9036842105263158, AUC 0.9678938388824463, avg_entr 0.00706613389775157
ep18_l4_test_time 0.6624631881713867
gc 0
Train Epoch19 Acc 0.9713 (116556/120000), AUC 0.9959889650344849
ep19_train_time 80.14433097839355
Test Epoch19 layer0 Acc 0.91, AUC 0.9781400561332703, avg_entr 0.04155595228075981
ep19_l0_test_time 0.1568889617919922
Test Epoch19 layer1 Acc 0.9042105263157895, AUC 0.9708336591720581, avg_entr 0.016039837151765823
ep19_l1_test_time 0.28593969345092773
Test Epoch19 layer2 Acc 0.9036842105263158, AUC 0.9704467058181763, avg_entr 0.009482108056545258
ep19_l2_test_time 0.4125378131866455
Test Epoch19 layer3 Acc 0.9039473684210526, AUC 0.9688172936439514, avg_entr 0.008303256705403328
ep19_l3_test_time 0.5378894805908203
Test Epoch19 layer4 Acc 0.9036842105263158, AUC 0.9695935249328613, avg_entr 0.007748656906187534
ep19_l4_test_time 0.6621768474578857
gc 0
Train Epoch20 Acc 0.9710166666666666 (116522/120000), AUC 0.9961154460906982
ep20_train_time 80.21258568763733
Test Epoch20 layer0 Acc 0.9105263157894737, AUC 0.9781050086021423, avg_entr 0.04062410071492195
ep20_l0_test_time 0.1569502353668213
Test Epoch20 layer1 Acc 0.9039473684210526, AUC 0.9709675312042236, avg_entr 0.016048049554228783
ep20_l1_test_time 0.28717517852783203
Test Epoch20 layer2 Acc 0.9034210526315789, AUC 0.9714254140853882, avg_entr 0.009192803874611855
ep20_l2_test_time 0.412947416305542
Test Epoch20 layer3 Acc 0.9034210526315789, AUC 0.9695045948028564, avg_entr 0.00801871158182621
ep20_l3_test_time 0.5377986431121826
Test Epoch20 layer4 Acc 0.9031578947368422, AUC 0.9685066938400269, avg_entr 0.007402641233056784
ep20_l4_test_time 0.6618239879608154
gc 0
Train Epoch21 Acc 0.971225 (116547/120000), AUC 0.996147871017456
ep21_train_time 80.13998436927795
Test Epoch21 layer0 Acc 0.9097368421052632, AUC 0.9780563116073608, avg_entr 0.039786677807569504
ep21_l0_test_time 0.15646672248840332
Test Epoch21 layer1 Acc 0.9047368421052632, AUC 0.970736026763916, avg_entr 0.015824895352125168
ep21_l1_test_time 0.2859506607055664
Test Epoch21 layer2 Acc 0.9031578947368422, AUC 0.9715859889984131, avg_entr 0.010314062237739563
ep21_l2_test_time 0.4117162227630615
Test Epoch21 layer3 Acc 0.9031578947368422, AUC 0.9709165096282959, avg_entr 0.008711088448762894
ep21_l3_test_time 0.5373497009277344
Test Epoch21 layer4 Acc 0.9036842105263158, AUC 0.9700803160667419, avg_entr 0.007929041050374508
ep21_l4_test_time 0.6620993614196777
gc 0
Train Epoch22 Acc 0.9715916666666666 (116591/120000), AUC 0.9961874485015869
ep22_train_time 80.1668004989624
Test Epoch22 layer0 Acc 0.9094736842105263, AUC 0.9780776500701904, avg_entr 0.039473406970500946
ep22_l0_test_time 0.16193079948425293
Test Epoch22 layer1 Acc 0.9042105263157895, AUC 0.9706448912620544, avg_entr 0.015600874088704586
ep22_l1_test_time 0.2866504192352295
Test Epoch22 layer2 Acc 0.9028947368421053, AUC 0.9718313813209534, avg_entr 0.009253574535250664
ep22_l2_test_time 0.4123106002807617
Test Epoch22 layer3 Acc 0.9026315789473685, AUC 0.9705921411514282, avg_entr 0.007854655385017395
ep22_l3_test_time 0.5377490520477295
Test Epoch22 layer4 Acc 0.9028947368421053, AUC 0.9700738191604614, avg_entr 0.007085680495947599
ep22_l4_test_time 0.6618244647979736
gc 0
Train Epoch23 Acc 0.9717666666666667 (116612/120000), AUC 0.9963608980178833
ep23_train_time 80.13770031929016
Test Epoch23 layer0 Acc 0.9097368421052632, AUC 0.9780504703521729, avg_entr 0.039088986814022064
ep23_l0_test_time 0.1604022979736328
Test Epoch23 layer1 Acc 0.9036842105263158, AUC 0.9705450534820557, avg_entr 0.015549946576356888
ep23_l1_test_time 0.2864041328430176
Test Epoch23 layer2 Acc 0.9023684210526316, AUC 0.9714840054512024, avg_entr 0.008463126607239246
ep23_l2_test_time 0.4133720397949219
Test Epoch23 layer3 Acc 0.9018421052631579, AUC 0.968975305557251, avg_entr 0.006730691995471716
ep23_l3_test_time 0.5379652976989746
Test Epoch23 layer4 Acc 0.9023684210526316, AUC 0.9686792492866516, avg_entr 0.006041292566806078
ep23_l4_test_time 0.6631009578704834
gc 0
Train Epoch24 Acc 0.9717916666666667 (116615/120000), AUC 0.9964020848274231
ep24_train_time 80.16669130325317
Test Epoch24 layer0 Acc 0.9097368421052632, AUC 0.9780457019805908, avg_entr 0.03862784802913666
ep24_l0_test_time 0.1570148468017578
Test Epoch24 layer1 Acc 0.9047368421052632, AUC 0.9701265692710876, avg_entr 0.015276949852705002
ep24_l1_test_time 0.28560423851013184
Test Epoch24 layer2 Acc 0.9034210526315789, AUC 0.9705897569656372, avg_entr 0.008786674588918686
ep24_l2_test_time 0.41256070137023926
Test Epoch24 layer3 Acc 0.9031578947368422, AUC 0.9685010313987732, avg_entr 0.00750011345371604
ep24_l3_test_time 0.5383036136627197
Test Epoch24 layer4 Acc 0.9028947368421053, AUC 0.9677574634552002, avg_entr 0.007017530966550112
ep24_l4_test_time 0.6619677543640137
gc 0
Train Epoch25 Acc 0.9719 (116628/120000), AUC 0.9963238835334778
ep25_train_time 80.11675262451172
Test Epoch25 layer0 Acc 0.9092105263157895, AUC 0.9780640602111816, avg_entr 0.03844747692346573
ep25_l0_test_time 0.15744900703430176
Test Epoch25 layer1 Acc 0.9036842105263158, AUC 0.9705761671066284, avg_entr 0.015340530313551426
ep25_l1_test_time 0.2859630584716797
Test Epoch25 layer2 Acc 0.901578947368421, AUC 0.9716212153434753, avg_entr 0.008584894239902496
ep25_l2_test_time 0.4126574993133545
Test Epoch25 layer3 Acc 0.9018421052631579, AUC 0.970098614692688, avg_entr 0.00681066419929266
ep25_l3_test_time 0.5383908748626709
Test Epoch25 layer4 Acc 0.9021052631578947, AUC 0.9690638184547424, avg_entr 0.00610096612945199
ep25_l4_test_time 0.6626796722412109
gc 0
Train Epoch26 Acc 0.9722833333333334 (116674/120000), AUC 0.9963550567626953
ep26_train_time 80.14732027053833
Test Epoch26 layer0 Acc 0.9089473684210526, AUC 0.9780614972114563, avg_entr 0.038210295140743256
ep26_l0_test_time 0.15665793418884277
Test Epoch26 layer1 Acc 0.9039473684210526, AUC 0.9703206419944763, avg_entr 0.015154814347624779
ep26_l1_test_time 0.28565096855163574
Test Epoch26 layer2 Acc 0.9023684210526316, AUC 0.9712037444114685, avg_entr 0.008591972291469574
ep26_l2_test_time 0.4118521213531494
Test Epoch26 layer3 Acc 0.9021052631578947, AUC 0.9694914817810059, avg_entr 0.006871894001960754
ep26_l3_test_time 0.5377767086029053
Test Epoch26 layer4 Acc 0.9021052631578947, AUC 0.9684348702430725, avg_entr 0.006053050979971886
ep26_l4_test_time 0.6623334884643555
gc 0
Train Epoch27 Acc 0.9722666666666666 (116672/120000), AUC 0.9964588284492493
ep27_train_time 80.16473531723022
Test Epoch27 layer0 Acc 0.9094736842105263, AUC 0.97804856300354, avg_entr 0.03805896267294884
ep27_l0_test_time 0.15756916999816895
Test Epoch27 layer1 Acc 0.9036842105263158, AUC 0.9703539609909058, avg_entr 0.015267811715602875
ep27_l1_test_time 0.28673744201660156
Test Epoch27 layer2 Acc 0.9021052631578947, AUC 0.9710119962692261, avg_entr 0.009120797738432884
ep27_l2_test_time 0.4123537540435791
Test Epoch27 layer3 Acc 0.9026315789473685, AUC 0.9691694974899292, avg_entr 0.007667948957532644
ep27_l3_test_time 0.5418169498443604
Test Epoch27 layer4 Acc 0.9031578947368422, AUC 0.9678844213485718, avg_entr 0.007058339659124613
ep27_l4_test_time 0.662606954574585
gc 0
Train Epoch28 Acc 0.9723083333333333 (116677/120000), AUC 0.996425986289978
ep28_train_time 80.23993110656738
Test Epoch28 layer0 Acc 0.9097368421052632, AUC 0.9780569076538086, avg_entr 0.03794417157769203
ep28_l0_test_time 0.15734624862670898
Test Epoch28 layer1 Acc 0.9036842105263158, AUC 0.9701259136199951, avg_entr 0.014986060559749603
ep28_l1_test_time 0.286099910736084
Test Epoch28 layer2 Acc 0.9021052631578947, AUC 0.9708462953567505, avg_entr 0.008237412199378014
ep28_l2_test_time 0.41298413276672363
Test Epoch28 layer3 Acc 0.9023684210526316, AUC 0.9687115550041199, avg_entr 0.006578401662409306
ep28_l3_test_time 0.5388989448547363
Test Epoch28 layer4 Acc 0.9023684210526316, AUC 0.9676205515861511, avg_entr 0.00591246597468853
ep28_l4_test_time 0.6626341342926025
gc 0
Train Epoch29 Acc 0.9723416666666667 (116681/120000), AUC 0.9964263439178467
ep29_train_time 80.16510391235352
Test Epoch29 layer0 Acc 0.9097368421052632, AUC 0.9780343770980835, avg_entr 0.03773195669054985
ep29_l0_test_time 0.1572723388671875
Test Epoch29 layer1 Acc 0.9023684210526316, AUC 0.9702808856964111, avg_entr 0.015016901306807995
ep29_l1_test_time 0.2866790294647217
Test Epoch29 layer2 Acc 0.901578947368421, AUC 0.9709697961807251, avg_entr 0.008462092839181423
ep29_l2_test_time 0.4122309684753418
Test Epoch29 layer3 Acc 0.901578947368421, AUC 0.9693803191184998, avg_entr 0.006581286899745464
ep29_l3_test_time 0.5377810001373291
Test Epoch29 layer4 Acc 0.901578947368421, AUC 0.9680732488632202, avg_entr 0.005846579559147358
ep29_l4_test_time 0.6622424125671387
gc 0
Train Epoch30 Acc 0.9723083333333333 (116677/120000), AUC 0.9965332746505737
ep30_train_time 80.14944553375244
Test Epoch30 layer0 Acc 0.9097368421052632, AUC 0.9780440926551819, avg_entr 0.03774060308933258
ep30_l0_test_time 0.15787625312805176
Test Epoch30 layer1 Acc 0.9031578947368422, AUC 0.9702173471450806, avg_entr 0.014976762235164642
ep30_l1_test_time 0.28726816177368164
Test Epoch30 layer2 Acc 0.9023684210526316, AUC 0.9708796739578247, avg_entr 0.008274012245237827
ep30_l2_test_time 0.4136347770690918
Test Epoch30 layer3 Acc 0.901578947368421, AUC 0.9687389135360718, avg_entr 0.0066704642958939075
ep30_l3_test_time 0.5377366542816162
Test Epoch30 layer4 Acc 0.901578947368421, AUC 0.967536211013794, avg_entr 0.006089838221669197
ep30_l4_test_time 0.6623470783233643
gc 0
Train Epoch31 Acc 0.9726666666666667 (116720/120000), AUC 0.9964020848274231
ep31_train_time 80.17749238014221
Test Epoch31 layer0 Acc 0.9092105263157895, AUC 0.97804856300354, avg_entr 0.03777020424604416
ep31_l0_test_time 0.15746498107910156
Test Epoch31 layer1 Acc 0.9034210526315789, AUC 0.9701404571533203, avg_entr 0.014913796447217464
ep31_l1_test_time 0.2869865894317627
Test Epoch31 layer2 Acc 0.9023684210526316, AUC 0.9709773659706116, avg_entr 0.008503668941557407
ep31_l2_test_time 0.4128899574279785
Test Epoch31 layer3 Acc 0.9018421052631579, AUC 0.9693664908409119, avg_entr 0.006765827536582947
ep31_l3_test_time 0.5387575626373291
Test Epoch31 layer4 Acc 0.9021052631578947, AUC 0.9682314395904541, avg_entr 0.006059500388801098
ep31_l4_test_time 0.6634368896484375
gc 0
Train Epoch32 Acc 0.9721333333333333 (116656/120000), AUC 0.9963818788528442
ep32_train_time 80.17759394645691
Test Epoch32 layer0 Acc 0.9092105263157895, AUC 0.9780417084693909, avg_entr 0.03759094327688217
ep32_l0_test_time 0.1577434539794922
Test Epoch32 layer1 Acc 0.9034210526315789, AUC 0.9701967835426331, avg_entr 0.014914227649569511
ep32_l1_test_time 0.2872304916381836
Test Epoch32 layer2 Acc 0.9018421052631579, AUC 0.9709807634353638, avg_entr 0.008433530107140541
ep32_l2_test_time 0.4165506362915039
Test Epoch32 layer3 Acc 0.9021052631578947, AUC 0.9689555764198303, avg_entr 0.006766263861209154
ep32_l3_test_time 0.5387592315673828
Test Epoch32 layer4 Acc 0.9018421052631579, AUC 0.9677438735961914, avg_entr 0.006183347664773464
ep32_l4_test_time 0.6655051708221436
gc 0
Train Epoch33 Acc 0.9725333333333334 (116704/120000), AUC 0.9964699745178223
ep33_train_time 80.20178174972534
Test Epoch33 layer0 Acc 0.9084210526315789, AUC 0.9780374765396118, avg_entr 0.03748650476336479
ep33_l0_test_time 0.15667080879211426
Test Epoch33 layer1 Acc 0.9036842105263158, AUC 0.970052182674408, avg_entr 0.014873542822897434
ep33_l1_test_time 0.28609156608581543
Test Epoch33 layer2 Acc 0.9023684210526316, AUC 0.9706085324287415, avg_entr 0.0084490105509758
ep33_l2_test_time 0.4120488166809082
Test Epoch33 layer3 Acc 0.9021052631578947, AUC 0.968476414680481, avg_entr 0.006857509259134531
ep33_l3_test_time 0.538036584854126
Test Epoch33 layer4 Acc 0.9021052631578947, AUC 0.9670448303222656, avg_entr 0.006359556224197149
ep33_l4_test_time 0.6618368625640869
gc 0
Train Epoch34 Acc 0.9724833333333334 (116698/120000), AUC 0.9964141845703125
ep34_train_time 80.24878478050232
Test Epoch34 layer0 Acc 0.9092105263157895, AUC 0.9780327677726746, avg_entr 0.03757135570049286
ep34_l0_test_time 0.15735268592834473
Test Epoch34 layer1 Acc 0.9026315789473685, AUC 0.9700832366943359, avg_entr 0.01480617094784975
ep34_l1_test_time 0.2862887382507324
Test Epoch34 layer2 Acc 0.9026315789473685, AUC 0.9708272814750671, avg_entr 0.008348816074430943
ep34_l2_test_time 0.4122202396392822
Test Epoch34 layer3 Acc 0.9018421052631579, AUC 0.9688512682914734, avg_entr 0.006550958845764399
ep34_l3_test_time 0.5382406711578369
Test Epoch34 layer4 Acc 0.9018421052631579, AUC 0.9673676490783691, avg_entr 0.005831881891936064
ep34_l4_test_time 0.6619060039520264
gc 0
Train Epoch35 Acc 0.9729833333333333 (116758/120000), AUC 0.9965192079544067
ep35_train_time 80.14624500274658
Test Epoch35 layer0 Acc 0.9094736842105263, AUC 0.978050708770752, avg_entr 0.037547167390584946
ep35_l0_test_time 0.15648388862609863
Test Epoch35 layer1 Acc 0.9031578947368422, AUC 0.9700542688369751, avg_entr 0.014821646735072136
ep35_l1_test_time 0.2861793041229248
Test Epoch35 layer2 Acc 0.9023684210526316, AUC 0.970651388168335, avg_entr 0.008272729814052582
ep35_l2_test_time 0.41332054138183594
Test Epoch35 layer3 Acc 0.901578947368421, AUC 0.9682120084762573, avg_entr 0.006556518841534853
ep35_l3_test_time 0.5377819538116455
Test Epoch35 layer4 Acc 0.9018421052631579, AUC 0.9668588042259216, avg_entr 0.005943814292550087
ep35_l4_test_time 0.6620051860809326
gc 0
Train Epoch36 Acc 0.9726583333333333 (116719/120000), AUC 0.9964767098426819
ep36_train_time 80.1494607925415
Test Epoch36 layer0 Acc 0.9094736842105263, AUC 0.9780434966087341, avg_entr 0.0375220961868763
ep36_l0_test_time 0.15786361694335938
Test Epoch36 layer1 Acc 0.9028947368421053, AUC 0.9701502323150635, avg_entr 0.014791552908718586
ep36_l1_test_time 0.2867574691772461
Test Epoch36 layer2 Acc 0.9023684210526316, AUC 0.9708396792411804, avg_entr 0.00833242479711771
ep36_l2_test_time 0.41344404220581055
Test Epoch36 layer3 Acc 0.9018421052631579, AUC 0.9689203500747681, avg_entr 0.006538973189890385
ep36_l3_test_time 0.5387630462646484
Test Epoch36 layer4 Acc 0.9018421052631579, AUC 0.9675241708755493, avg_entr 0.005863904487341642
ep36_l4_test_time 0.6625564098358154
gc 0
Train Epoch37 Acc 0.9728416666666667 (116741/120000), AUC 0.9964886903762817
ep37_train_time 80.32531476020813
Test Epoch37 layer0 Acc 0.9094736842105263, AUC 0.978043794631958, avg_entr 0.03755835443735123
ep37_l0_test_time 0.1580486297607422
Test Epoch37 layer1 Acc 0.9026315789473685, AUC 0.9701804518699646, avg_entr 0.01480135228484869
ep37_l1_test_time 0.28639841079711914
Test Epoch37 layer2 Acc 0.9023684210526316, AUC 0.9709128141403198, avg_entr 0.008321232162415981
ep37_l2_test_time 0.4125828742980957
Test Epoch37 layer3 Acc 0.9018421052631579, AUC 0.968897819519043, avg_entr 0.0065275076776742935
ep37_l3_test_time 0.5386543273925781
Test Epoch37 layer4 Acc 0.9018421052631579, AUC 0.9675177335739136, avg_entr 0.005882201716303825
ep37_l4_test_time 0.6620452404022217
gc 0
Train Epoch38 Acc 0.9726666666666667 (116720/120000), AUC 0.9964936375617981
ep38_train_time 80.27606868743896
Test Epoch38 layer0 Acc 0.9089473684210526, AUC 0.9780310392379761, avg_entr 0.037447232753038406
ep38_l0_test_time 0.15688633918762207
Test Epoch38 layer1 Acc 0.9031578947368422, AUC 0.9701653718948364, avg_entr 0.014826535247266293
ep38_l1_test_time 0.28606176376342773
Test Epoch38 layer2 Acc 0.9021052631578947, AUC 0.9710128307342529, avg_entr 0.008386933244764805
ep38_l2_test_time 0.4128420352935791
Test Epoch38 layer3 Acc 0.9018421052631579, AUC 0.968906044960022, avg_entr 0.0066306861117482185
ep38_l3_test_time 0.5372960567474365
Test Epoch38 layer4 Acc 0.9018421052631579, AUC 0.9675568342208862, avg_entr 0.006055058445781469
ep38_l4_test_time 0.6623237133026123
gc 0
Train Epoch39 Acc 0.9725666666666667 (116708/120000), AUC 0.9964434504508972
ep39_train_time 80.19473385810852
Test Epoch39 layer0 Acc 0.9094736842105263, AUC 0.9780390858650208, avg_entr 0.03747430816292763
ep39_l0_test_time 0.1571826934814453
Test Epoch39 layer1 Acc 0.9031578947368422, AUC 0.9701635241508484, avg_entr 0.014787557534873486
ep39_l1_test_time 0.2860283851623535
Test Epoch39 layer2 Acc 0.9021052631578947, AUC 0.9707552790641785, avg_entr 0.008353234268724918
ep39_l2_test_time 0.41182589530944824
Test Epoch39 layer3 Acc 0.9018421052631579, AUC 0.9687066078186035, avg_entr 0.006553011480718851
ep39_l3_test_time 0.5378916263580322
Test Epoch39 layer4 Acc 0.9018421052631579, AUC 0.9673048257827759, avg_entr 0.005906440783292055
ep39_l4_test_time 0.6619088649749756
gc 0
Train Epoch40 Acc 0.972725 (116727/120000), AUC 0.9964973330497742
ep40_train_time 80.2113184928894
Test Epoch40 layer0 Acc 0.9089473684210526, AUC 0.9780299663543701, avg_entr 0.037397969514131546
ep40_l0_test_time 0.15579009056091309
Test Epoch40 layer1 Acc 0.9031578947368422, AUC 0.9701535701751709, avg_entr 0.014795776456594467
ep40_l1_test_time 0.28512024879455566
Test Epoch40 layer2 Acc 0.9021052631578947, AUC 0.9708173274993896, avg_entr 0.008379013277590275
ep40_l2_test_time 0.4115123748779297
Test Epoch40 layer3 Acc 0.9018421052631579, AUC 0.9688143730163574, avg_entr 0.00660709897056222
ep40_l3_test_time 0.5374796390533447
Test Epoch40 layer4 Acc 0.9018421052631579, AUC 0.9673483371734619, avg_entr 0.0060242037288844585
ep40_l4_test_time 0.6615235805511475
gc 0
Train Epoch41 Acc 0.9726916666666666 (116723/120000), AUC 0.9964942336082458
ep41_train_time 80.17005109786987
Test Epoch41 layer0 Acc 0.9094736842105263, AUC 0.9780464172363281, avg_entr 0.037457987666130066
ep41_l0_test_time 0.15757060050964355
Test Epoch41 layer1 Acc 0.9031578947368422, AUC 0.9701826572418213, avg_entr 0.014792166650295258
ep41_l1_test_time 0.28562211990356445
Test Epoch41 layer2 Acc 0.9021052631578947, AUC 0.9708782434463501, avg_entr 0.00837271474301815
ep41_l2_test_time 0.4129962921142578
Test Epoch41 layer3 Acc 0.9018421052631579, AUC 0.968982994556427, avg_entr 0.006565741263329983
ep41_l3_test_time 0.5378398895263672
Test Epoch41 layer4 Acc 0.9018421052631579, AUC 0.9675168991088867, avg_entr 0.005938245914876461
ep41_l4_test_time 0.663193941116333
gc 0
Train Epoch42 Acc 0.9728583333333334 (116743/120000), AUC 0.996427059173584
ep42_train_time 80.2596127986908
Test Epoch42 layer0 Acc 0.9092105263157895, AUC 0.9780420064926147, avg_entr 0.03746197745203972
ep42_l0_test_time 0.15747523307800293
Test Epoch42 layer1 Acc 0.9031578947368422, AUC 0.9701805114746094, avg_entr 0.01478292141109705
ep42_l1_test_time 0.28559088706970215
Test Epoch42 layer2 Acc 0.9021052631578947, AUC 0.9708266258239746, avg_entr 0.008369715884327888
ep42_l2_test_time 0.4119532108306885
Test Epoch42 layer3 Acc 0.9018421052631579, AUC 0.9689230918884277, avg_entr 0.006553611718118191
ep42_l3_test_time 0.537630558013916
Test Epoch42 layer4 Acc 0.9018421052631579, AUC 0.9674686193466187, avg_entr 0.005911353975534439
ep42_l4_test_time 0.6612794399261475
gc 0
Train Epoch43 Acc 0.9724666666666667 (116696/120000), AUC 0.9965156316757202
ep43_train_time 80.17789316177368
Test Epoch43 layer0 Acc 0.9094736842105263, AUC 0.9780426025390625, avg_entr 0.03744801506400108
ep43_l0_test_time 0.15641427040100098
Test Epoch43 layer1 Acc 0.9028947368421053, AUC 0.9701781272888184, avg_entr 0.01478319987654686
ep43_l1_test_time 0.2859230041503906
Test Epoch43 layer2 Acc 0.9021052631578947, AUC 0.9708566665649414, avg_entr 0.008367108181118965
ep43_l2_test_time 0.41219592094421387
Test Epoch43 layer3 Acc 0.9018421052631579, AUC 0.968869686126709, avg_entr 0.006582655478268862
ep43_l3_test_time 0.5378708839416504
Test Epoch43 layer4 Acc 0.9018421052631579, AUC 0.9673439860343933, avg_entr 0.005970001220703125
ep43_l4_test_time 0.6620934009552002
gc 0
Train Epoch44 Acc 0.972675 (116721/120000), AUC 0.996538519859314
ep44_train_time 80.18151998519897
Test Epoch44 layer0 Acc 0.9092105263157895, AUC 0.9780397415161133, avg_entr 0.03745757415890694
ep44_l0_test_time 0.15741276741027832
Test Epoch44 layer1 Acc 0.9031578947368422, AUC 0.9701641798019409, avg_entr 0.01477397046983242
ep44_l1_test_time 0.28586912155151367
Test Epoch44 layer2 Acc 0.9021052631578947, AUC 0.9708483219146729, avg_entr 0.008367499336600304
ep44_l2_test_time 0.412109375
Test Epoch44 layer3 Acc 0.9018421052631579, AUC 0.9689091444015503, avg_entr 0.006573453079909086
ep44_l3_test_time 0.5379674434661865
Test Epoch44 layer4 Acc 0.9018421052631579, AUC 0.9674021601676941, avg_entr 0.005951069761067629
ep44_l4_test_time 0.662339448928833
gc 0
Train Epoch45 Acc 0.97285 (116742/120000), AUC 0.9964406490325928
ep45_train_time 80.16301107406616
Test Epoch45 layer0 Acc 0.9092105263157895, AUC 0.9780397415161133, avg_entr 0.03744647279381752
ep45_l0_test_time 0.15684747695922852
Test Epoch45 layer1 Acc 0.9028947368421053, AUC 0.9701724648475647, avg_entr 0.014771169982850552
ep45_l1_test_time 0.28555989265441895
Test Epoch45 layer2 Acc 0.9021052631578947, AUC 0.9708625078201294, avg_entr 0.008362160995602608
ep45_l2_test_time 0.4121520519256592
Test Epoch45 layer3 Acc 0.9018421052631579, AUC 0.9688872694969177, avg_entr 0.006580357439815998
ep45_l3_test_time 0.5373091697692871
Test Epoch45 layer4 Acc 0.9018421052631579, AUC 0.9674372673034668, avg_entr 0.005972478073090315
ep45_l4_test_time 0.6614081859588623
gc 0
Train Epoch46 Acc 0.9727916666666667 (116735/120000), AUC 0.9964233636856079
ep46_train_time 80.22345280647278
Test Epoch46 layer0 Acc 0.9092105263157895, AUC 0.9780407547950745, avg_entr 0.03741439804434776
ep46_l0_test_time 0.1561121940612793
Test Epoch46 layer1 Acc 0.9028947368421053, AUC 0.9701390862464905, avg_entr 0.01475989818572998
ep46_l1_test_time 0.2857944965362549
Test Epoch46 layer2 Acc 0.9023684210526316, AUC 0.97085040807724, avg_entr 0.008355214260518551
ep46_l2_test_time 0.41173648834228516
Test Epoch46 layer3 Acc 0.9018421052631579, AUC 0.9688984751701355, avg_entr 0.006580726243555546
ep46_l3_test_time 0.5373713970184326
Test Epoch46 layer4 Acc 0.9018421052631579, AUC 0.9673694968223572, avg_entr 0.005977583583444357
ep46_l4_test_time 0.6621644496917725
gc 0
Train Epoch47 Acc 0.9727 (116724/120000), AUC 0.9964607357978821
ep47_train_time 80.25305819511414
Test Epoch47 layer0 Acc 0.9092105263157895, AUC 0.9780406951904297, avg_entr 0.03743058815598488
ep47_l0_test_time 0.15703105926513672
Test Epoch47 layer1 Acc 0.9028947368421053, AUC 0.9701359868049622, avg_entr 0.014761017635464668
ep47_l1_test_time 0.2858614921569824
Test Epoch47 layer2 Acc 0.9023684210526316, AUC 0.9708387851715088, avg_entr 0.00836183037608862
ep47_l2_test_time 0.41270995140075684
Test Epoch47 layer3 Acc 0.9018421052631579, AUC 0.9688990712165833, avg_entr 0.006577875930815935
ep47_l3_test_time 0.5375092029571533
Test Epoch47 layer4 Acc 0.9018421052631579, AUC 0.9673734903335571, avg_entr 0.005964494310319424
ep47_l4_test_time 0.6623194217681885
gc 0
Train Epoch48 Acc 0.9728583333333334 (116743/120000), AUC 0.9965423941612244
ep48_train_time 80.19207501411438
Test Epoch48 layer0 Acc 0.9092105263157895, AUC 0.9780404567718506, avg_entr 0.037404865026474
ep48_l0_test_time 0.1564931869506836
Test Epoch48 layer1 Acc 0.9028947368421053, AUC 0.9701614379882812, avg_entr 0.014761336147785187
ep48_l1_test_time 0.28624773025512695
Test Epoch48 layer2 Acc 0.9021052631578947, AUC 0.970855176448822, avg_entr 0.008362236432731152
ep48_l2_test_time 0.4121284484863281
Test Epoch48 layer3 Acc 0.9018421052631579, AUC 0.9689221382141113, avg_entr 0.006576779298484325
ep48_l3_test_time 0.5375595092773438
Test Epoch48 layer4 Acc 0.9018421052631579, AUC 0.967404842376709, avg_entr 0.005966937635093927
ep48_l4_test_time 0.6617090702056885
gc 0
Train Epoch49 Acc 0.97285 (116742/120000), AUC 0.9965065121650696
ep49_train_time 80.43164849281311
Test Epoch49 layer0 Acc 0.9092105263157895, AUC 0.9780371785163879, avg_entr 0.03743383288383484
ep49_l0_test_time 0.15674614906311035
Test Epoch49 layer1 Acc 0.9028947368421053, AUC 0.9701747894287109, avg_entr 0.014763059094548225
ep49_l1_test_time 0.28608083724975586
Test Epoch49 layer2 Acc 0.9021052631578947, AUC 0.9708250761032104, avg_entr 0.008364425040781498
ep49_l2_test_time 0.41243958473205566
Test Epoch49 layer3 Acc 0.9018421052631579, AUC 0.9688663482666016, avg_entr 0.006570024415850639
ep49_l3_test_time 0.5399243831634521
Test Epoch49 layer4 Acc 0.9018421052631579, AUC 0.967410683631897, avg_entr 0.005951622501015663
ep49_l4_test_time 0.6633336544036865
Best AUC 0.9814496040344238
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train+valid_time 4114.949911832809
Start Testing
Load ckpt at ckpt/ag_news_transformeral_l5_pad175//ag_news_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.9236842105263158, AUC 0.9847332239151001, avg_entr 0.09238533675670624
ep49_l0_test_time 0.15445566177368164
Test Epoch49 layer1 Acc 0.9265789473684211, AUC 0.9848476648330688, avg_entr 0.034761615097522736
ep49_l1_test_time 0.2868349552154541
Test Epoch49 layer2 Acc 0.9257894736842105, AUC 0.9858580231666565, avg_entr 0.02924741618335247
ep49_l2_test_time 0.41275501251220703
Test Epoch49 layer3 Acc 0.9255263157894736, AUC 0.9850513935089111, avg_entr 0.026745866984128952
ep49_l3_test_time 0.5396223068237305
Test Epoch49 layer4 Acc 0.9265789473684211, AUC 0.9855186343193054, avg_entr 0.0260273739695549
ep49_l4_test_time 0.6626338958740234
