total count words 887881
vocab size 30000
found 28354 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=14, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=14, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 1792
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 1792
layers.0.ae.h.0.bias 14
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13674862
init_time 58.32081389427185
Start Training
gc 0
Train Epoch0 Acc 0.83565 (467964/560000), AUC 0.9806041717529297
ep0_train_time 120.98829174041748
Test Epoch0 layer0 Acc 0.9643428571428572, AUC 0.49864068627357483, avg_entr 0.0912778452038765
ep0_l0_test_time 0.5580263137817383
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad40//dbpedia_14_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9638285714285715, AUC 0.49881526827812195, avg_entr 0.048255641013383865
ep0_l1_test_time 0.8431398868560791
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad40//dbpedia_14_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.9668, AUC 0.498652845621109, avg_entr 0.03224676474928856
ep0_l2_test_time 1.152024269104004
Test Epoch0 layer3 Acc 0.9678, AUC 0.4985559582710266, avg_entr 0.026599500328302383
ep0_l3_test_time 1.4472711086273193
Test Epoch0 layer4 Acc 0.9682571428571428, AUC 0.49855703115463257, avg_entr 0.02561274915933609
ep0_l4_test_time 1.7056636810302734
gc 0
Train Epoch1 Acc 0.98005 (548828/560000), AUC 0.9976258873939514
ep1_train_time 118.69187951087952
Test Epoch1 layer0 Acc 0.9656, AUC 0.4986748695373535, avg_entr 0.05202111601829529
ep1_l0_test_time 0.5566539764404297
Test Epoch1 layer1 Acc 0.973, AUC 0.4985143840312958, avg_entr 0.013047882355749607
ep1_l1_test_time 0.8519761562347412
Test Epoch1 layer2 Acc 0.9739142857142857, AUC 0.49839478731155396, avg_entr 0.008571406826376915
ep1_l2_test_time 1.1396985054016113
Test Epoch1 layer3 Acc 0.9742857142857143, AUC 0.49845272302627563, avg_entr 0.00699192937463522
ep1_l3_test_time 1.459890604019165
Test Epoch1 layer4 Acc 0.9742857142857143, AUC 0.49820682406425476, avg_entr 0.006281612906605005
ep1_l4_test_time 1.7132234573364258
gc 0
Train Epoch2 Acc 0.9840196428571428 (551051/560000), AUC 0.9980164766311646
ep2_train_time 118.7962110042572
Test Epoch2 layer0 Acc 0.9659428571428571, AUC 0.49871382117271423, avg_entr 0.03775598481297493
ep2_l0_test_time 0.5706515312194824
Test Epoch2 layer1 Acc 0.9720857142857143, AUC 0.4983390271663666, avg_entr 0.008695120923221111
ep2_l1_test_time 0.8495357036590576
Test Epoch2 layer2 Acc 0.9727714285714286, AUC 0.49820438027381897, avg_entr 0.005652132909744978
ep2_l2_test_time 1.1426177024841309
Test Epoch2 layer3 Acc 0.9727428571428571, AUC 0.4981296956539154, avg_entr 0.0047548389993608
ep2_l3_test_time 1.4514305591583252
Test Epoch2 layer4 Acc 0.9725714285714285, AUC 0.49794015288352966, avg_entr 0.004027047194540501
ep2_l4_test_time 1.6988844871520996
gc 0
Train Epoch3 Acc 0.9856678571428571 (551974/560000), AUC 0.9981923699378967
ep3_train_time 118.86905670166016
Test Epoch3 layer0 Acc 0.9646571428571429, AUC 0.49871954321861267, avg_entr 0.03110947273671627
ep3_l0_test_time 0.557396411895752
Test Epoch3 layer1 Acc 0.9716857142857143, AUC 0.4984442889690399, avg_entr 0.006884715985506773
ep3_l1_test_time 0.8572969436645508
Test Epoch3 layer2 Acc 0.9714857142857143, AUC 0.49836674332618713, avg_entr 0.004574430175125599
ep3_l2_test_time 1.1826934814453125
Test Epoch3 layer3 Acc 0.9713714285714286, AUC 0.49829310178756714, avg_entr 0.0039780898950994015
ep3_l3_test_time 1.458000659942627
Test Epoch3 layer4 Acc 0.9710571428571428, AUC 0.4981386959552765, avg_entr 0.0034217468928545713
ep3_l4_test_time 1.7032990455627441
gc 0
Train Epoch4 Acc 0.9869625 (552699/560000), AUC 0.9983113408088684
ep4_train_time 119.0511703491211
Test Epoch4 layer0 Acc 0.9651714285714286, AUC 0.4987153708934784, avg_entr 0.02890038676559925
ep4_l0_test_time 0.5474369525909424
Test Epoch4 layer1 Acc 0.9729428571428571, AUC 0.4984160363674164, avg_entr 0.005921607371419668
ep4_l1_test_time 0.8372771739959717
Test Epoch4 layer2 Acc 0.9731428571428572, AUC 0.4983106553554535, avg_entr 0.004054994322359562
ep4_l2_test_time 1.1405119895935059
Test Epoch4 layer3 Acc 0.9730857142857143, AUC 0.49811747670173645, avg_entr 0.0035562103148549795
ep4_l3_test_time 1.4640889167785645
Test Epoch4 layer4 Acc 0.9728285714285714, AUC 0.49800747632980347, avg_entr 0.00303553300909698
ep4_l4_test_time 1.7098164558410645
gc 0
Train Epoch5 Acc 0.9880375 (553301/560000), AUC 0.9985775351524353
ep5_train_time 119.02401423454285
Test Epoch5 layer0 Acc 0.9649714285714286, AUC 0.4987336993217468, avg_entr 0.02793722413480282
ep5_l0_test_time 0.5510296821594238
Test Epoch5 layer1 Acc 0.9726285714285714, AUC 0.49824681878089905, avg_entr 0.005449394695460796
ep5_l1_test_time 0.8445498943328857
Test Epoch5 layer2 Acc 0.9728571428571429, AUC 0.49805954098701477, avg_entr 0.003443797118961811
ep5_l2_test_time 1.1363604068756104
Test Epoch5 layer3 Acc 0.9726285714285714, AUC 0.49784794449806213, avg_entr 0.0029406773392111063
ep5_l3_test_time 1.448754072189331
Test Epoch5 layer4 Acc 0.9726857142857143, AUC 0.4976823627948761, avg_entr 0.0024837080854922533
ep5_l4_test_time 1.7050151824951172
gc 0
Train Epoch6 Acc 0.9887 (553672/560000), AUC 0.9987772107124329
ep6_train_time 118.95297145843506
Test Epoch6 layer0 Acc 0.9652, AUC 0.4987257421016693, avg_entr 0.027230072766542435
ep6_l0_test_time 0.554215669631958
Test Epoch6 layer1 Acc 0.9730285714285715, AUC 0.49826744198799133, avg_entr 0.005259816534817219
ep6_l1_test_time 0.8425729274749756
Test Epoch6 layer2 Acc 0.9736571428571429, AUC 0.49830058217048645, avg_entr 0.0032631175126880407
ep6_l2_test_time 1.153669834136963
Test Epoch6 layer3 Acc 0.9737428571428571, AUC 0.4981510043144226, avg_entr 0.0029480690136551857
ep6_l3_test_time 1.4401376247406006
Test Epoch6 layer4 Acc 0.9736571428571429, AUC 0.4980016350746155, avg_entr 0.002488439902663231
ep6_l4_test_time 1.6905317306518555
gc 0
Train Epoch7 Acc 0.9896214285714285 (554188/560000), AUC 0.9989282488822937
ep7_train_time 118.7036349773407
Test Epoch7 layer0 Acc 0.9658, AUC 0.4987392723560333, avg_entr 0.027150655165314674
ep7_l0_test_time 0.5596408843994141
Test Epoch7 layer1 Acc 0.9728, AUC 0.49823808670043945, avg_entr 0.0050776321440935135
ep7_l1_test_time 0.8522393703460693
Test Epoch7 layer2 Acc 0.9728285714285714, AUC 0.4982934296131134, avg_entr 0.003238882403820753
ep7_l2_test_time 1.1380703449249268
Test Epoch7 layer3 Acc 0.9726285714285714, AUC 0.4980614185333252, avg_entr 0.002876554848626256
ep7_l3_test_time 1.4399168491363525
Test Epoch7 layer4 Acc 0.9726857142857143, AUC 0.497862845659256, avg_entr 0.0025151947047561407
ep7_l4_test_time 1.7009775638580322
gc 0
Train Epoch8 Acc 0.9901017857142858 (554457/560000), AUC 0.9989486336708069
ep8_train_time 118.75403714179993
Test Epoch8 layer0 Acc 0.9653714285714285, AUC 0.49876877665519714, avg_entr 0.027226321399211884
ep8_l0_test_time 0.5519640445709229
Test Epoch8 layer1 Acc 0.9718857142857142, AUC 0.49811679124832153, avg_entr 0.005309884436428547
ep8_l1_test_time 0.8412926197052002
Test Epoch8 layer2 Acc 0.9721428571428572, AUC 0.49814799427986145, avg_entr 0.003503514686599374
ep8_l2_test_time 1.1516532897949219
Test Epoch8 layer3 Acc 0.9719714285714286, AUC 0.49789851903915405, avg_entr 0.0030428192112594843
ep8_l3_test_time 1.4447047710418701
Test Epoch8 layer4 Acc 0.9719428571428571, AUC 0.4975854456424713, avg_entr 0.0025375017430633307
ep8_l4_test_time 1.710996150970459
gc 0
Train Epoch9 Acc 0.9905803571428572 (554725/560000), AUC 0.9989551901817322
ep9_train_time 119.27343201637268
Test Epoch9 layer0 Acc 0.9656571428571429, AUC 0.49874797463417053, avg_entr 0.026841193437576294
ep9_l0_test_time 0.5481576919555664
Test Epoch9 layer1 Acc 0.9716571428571429, AUC 0.49814099073410034, avg_entr 0.004868912044912577
ep9_l1_test_time 0.8459553718566895
Test Epoch9 layer2 Acc 0.972, AUC 0.4980284571647644, avg_entr 0.003162247594445944
ep9_l2_test_time 1.1338419914245605
Test Epoch9 layer3 Acc 0.9718571428571429, AUC 0.4979400932788849, avg_entr 0.002736529102548957
ep9_l3_test_time 1.432178258895874
Test Epoch9 layer4 Acc 0.9719428571428571, AUC 0.4976813793182373, avg_entr 0.002361536957323551
ep9_l4_test_time 1.7081339359283447
gc 0
Train Epoch10 Acc 0.9908035714285715 (554850/560000), AUC 0.999009907245636
ep10_train_time 118.94862866401672
Test Epoch10 layer0 Acc 0.9650857142857143, AUC 0.4987446367740631, avg_entr 0.026912419125437737
ep10_l0_test_time 0.5478818416595459
Test Epoch10 layer1 Acc 0.9720285714285715, AUC 0.4981493353843689, avg_entr 0.004974172916263342
ep10_l1_test_time 0.8492259979248047
Test Epoch10 layer2 Acc 0.9722857142857143, AUC 0.49803662300109863, avg_entr 0.0031676487997174263
ep10_l2_test_time 1.1383264064788818
Test Epoch10 layer3 Acc 0.9725428571428572, AUC 0.49797576665878296, avg_entr 0.002755258232355118
ep10_l3_test_time 1.475602149963379
Test Epoch10 layer4 Acc 0.9726, AUC 0.4977463185787201, avg_entr 0.002452378161251545
ep10_l4_test_time 1.7199981212615967
gc 0
Train Epoch11 Acc 0.9911285714285715 (555032/560000), AUC 0.9989644885063171
ep11_train_time 119.01778793334961
Test Epoch11 layer0 Acc 0.9647714285714286, AUC 0.49875396490097046, avg_entr 0.02675246074795723
ep11_l0_test_time 0.5603823661804199
Test Epoch11 layer1 Acc 0.9717714285714286, AUC 0.4980984330177307, avg_entr 0.005289087072014809
ep11_l1_test_time 0.8449304103851318
Test Epoch11 layer2 Acc 0.9716285714285714, AUC 0.49787262082099915, avg_entr 0.003377072513103485
ep11_l2_test_time 1.151271104812622
Test Epoch11 layer3 Acc 0.9716285714285714, AUC 0.49765104055404663, avg_entr 0.002784460550174117
ep11_l3_test_time 1.445432186126709
Test Epoch11 layer4 Acc 0.9716571428571429, AUC 0.49749231338500977, avg_entr 0.0024554107803851366
ep11_l4_test_time 1.7177073955535889
gc 0
Train Epoch12 Acc 0.9912821428571429 (555118/560000), AUC 0.9989745020866394
ep12_train_time 118.74573254585266
Test Epoch12 layer0 Acc 0.9661714285714286, AUC 0.49877622723579407, avg_entr 0.026110362261533737
ep12_l0_test_time 0.5513508319854736
Test Epoch12 layer1 Acc 0.9734857142857143, AUC 0.49820834398269653, avg_entr 0.004639226011931896
ep12_l1_test_time 0.8431103229522705
Test Epoch12 layer2 Acc 0.9738285714285714, AUC 0.4981103539466858, avg_entr 0.002883472014218569
ep12_l2_test_time 1.1350390911102295
Test Epoch12 layer3 Acc 0.9740285714285715, AUC 0.4978375732898712, avg_entr 0.002451627515256405
ep12_l3_test_time 1.4432063102722168
Test Epoch12 layer4 Acc 0.9741142857142857, AUC 0.4976850152015686, avg_entr 0.0021303470712155104
ep12_l4_test_time 1.701827049255371
gc 0
Train Epoch13 Acc 0.9918732142857143 (555449/560000), AUC 0.999002993106842
ep13_train_time 118.56851148605347
Test Epoch13 layer0 Acc 0.9658857142857142, AUC 0.4987715184688568, avg_entr 0.026329314336180687
ep13_l0_test_time 0.548532247543335
Test Epoch13 layer1 Acc 0.9725714285714285, AUC 0.49814239144325256, avg_entr 0.005031062755733728
ep13_l1_test_time 0.8490514755249023
Test Epoch13 layer2 Acc 0.9725428571428572, AUC 0.4980650246143341, avg_entr 0.0031649526208639145
ep13_l2_test_time 1.1381933689117432
Test Epoch13 layer3 Acc 0.9725714285714285, AUC 0.49775537848472595, avg_entr 0.0026461922097951174
ep13_l3_test_time 1.4426665306091309
Test Epoch13 layer4 Acc 0.9724285714285714, AUC 0.49768301844596863, avg_entr 0.0023273215629160404
ep13_l4_test_time 1.7131338119506836
gc 0
Train Epoch14 Acc 0.9919482142857143 (555491/560000), AUC 0.9990239143371582
ep14_train_time 119.12193822860718
Test Epoch14 layer0 Acc 0.9656285714285714, AUC 0.49875587224960327, avg_entr 0.02649148367345333
ep14_l0_test_time 0.5526061058044434
Test Epoch14 layer1 Acc 0.9724285714285714, AUC 0.49810323119163513, avg_entr 0.004897830542176962
ep14_l1_test_time 0.8491830825805664
Test Epoch14 layer2 Acc 0.9727714285714286, AUC 0.49794915318489075, avg_entr 0.003024376928806305
ep14_l2_test_time 1.1362247467041016
Test Epoch14 layer3 Acc 0.9727142857142858, AUC 0.49782878160476685, avg_entr 0.002650447655469179
ep14_l3_test_time 1.4350214004516602
Test Epoch14 layer4 Acc 0.9728285714285714, AUC 0.49754032492637634, avg_entr 0.002364480635151267
ep14_l4_test_time 1.6970512866973877
gc 0
Train Epoch15 Acc 0.9920857142857142 (555568/560000), AUC 0.9990218281745911
ep15_train_time 119.04307675361633
Test Epoch15 layer0 Acc 0.9661142857142857, AUC 0.49876150488853455, avg_entr 0.026247946545481682
ep15_l0_test_time 0.549868106842041
Test Epoch15 layer1 Acc 0.9726857142857143, AUC 0.49808749556541443, avg_entr 0.00506674125790596
ep15_l1_test_time 0.8446605205535889
Test Epoch15 layer2 Acc 0.9727714285714286, AUC 0.4978511333465576, avg_entr 0.0032047475688159466
ep15_l2_test_time 1.140866756439209
Test Epoch15 layer3 Acc 0.9727428571428571, AUC 0.4976787269115448, avg_entr 0.0027035835664719343
ep15_l3_test_time 1.441498041152954
Test Epoch15 layer4 Acc 0.9728, AUC 0.4974730908870697, avg_entr 0.0023081256076693535
ep15_l4_test_time 1.6981201171875
gc 0
Train Epoch16 Acc 0.9921767857142857 (555619/560000), AUC 0.9989930987358093
ep16_train_time 118.62080955505371
Test Epoch16 layer0 Acc 0.9663142857142857, AUC 0.4987587332725525, avg_entr 0.02603893354535103
ep16_l0_test_time 0.545051097869873
Test Epoch16 layer1 Acc 0.9724571428571429, AUC 0.49803176522254944, avg_entr 0.004928319249302149
ep16_l1_test_time 0.8354034423828125
Test Epoch16 layer2 Acc 0.9732571428571428, AUC 0.49785616993904114, avg_entr 0.003053109860047698
ep16_l2_test_time 1.1380696296691895
Test Epoch16 layer3 Acc 0.9731428571428572, AUC 0.4976034462451935, avg_entr 0.0025064300280064344
ep16_l3_test_time 1.4599788188934326
Test Epoch16 layer4 Acc 0.9732, AUC 0.49736160039901733, avg_entr 0.002132599940523505
ep16_l4_test_time 1.7009954452514648
gc 0
Train Epoch17 Acc 0.9924839285714285 (555791/560000), AUC 0.9990519881248474
ep17_train_time 118.89554166793823
Test Epoch17 layer0 Acc 0.9657428571428571, AUC 0.4987543523311615, avg_entr 0.026392042636871338
ep17_l0_test_time 0.5545909404754639
Test Epoch17 layer1 Acc 0.9722, AUC 0.4980364739894867, avg_entr 0.005052600521594286
ep17_l1_test_time 0.834204912185669
Test Epoch17 layer2 Acc 0.9724857142857143, AUC 0.4978785514831543, avg_entr 0.003013297915458679
ep17_l2_test_time 1.1389551162719727
Test Epoch17 layer3 Acc 0.9725142857142857, AUC 0.4976896345615387, avg_entr 0.0023886384442448616
ep17_l3_test_time 1.4404902458190918
Test Epoch17 layer4 Acc 0.9726, AUC 0.49732181429862976, avg_entr 0.0020781089551746845
ep17_l4_test_time 1.7957100868225098
gc 0
Train Epoch18 Acc 0.9925464285714286 (555826/560000), AUC 0.9990411400794983
ep18_train_time 119.32656741142273
Test Epoch18 layer0 Acc 0.9659142857142857, AUC 0.49875664710998535, avg_entr 0.026202606037259102
ep18_l0_test_time 0.5581140518188477
Test Epoch18 layer1 Acc 0.9721428571428572, AUC 0.49808409810066223, avg_entr 0.005004286300390959
ep18_l1_test_time 0.8515644073486328
Test Epoch18 layer2 Acc 0.9724, AUC 0.4978971481323242, avg_entr 0.003002145094797015
ep18_l2_test_time 1.1359214782714844
Test Epoch18 layer3 Acc 0.9724857142857143, AUC 0.4976366460323334, avg_entr 0.002467160578817129
ep18_l3_test_time 1.4413652420043945
Test Epoch18 layer4 Acc 0.9726, AUC 0.4974166452884674, avg_entr 0.0021304800175130367
ep18_l4_test_time 1.6954097747802734
gc 0
Train Epoch19 Acc 0.9925982142857143 (555855/560000), AUC 0.9990730881690979
ep19_train_time 119.5992362499237
Test Epoch19 layer0 Acc 0.9654571428571429, AUC 0.49875369668006897, avg_entr 0.026529841125011444
ep19_l0_test_time 0.5491597652435303
Test Epoch19 layer1 Acc 0.9715714285714285, AUC 0.4980009198188782, avg_entr 0.005029143299907446
ep19_l1_test_time 0.8443140983581543
Test Epoch19 layer2 Acc 0.9714285714285714, AUC 0.4977341592311859, avg_entr 0.003001860808581114
ep19_l2_test_time 1.173973798751831
Test Epoch19 layer3 Acc 0.9713714285714286, AUC 0.49747011065483093, avg_entr 0.0024706062395125628
ep19_l3_test_time 1.4560325145721436
Test Epoch19 layer4 Acc 0.9716285714285714, AUC 0.4972350299358368, avg_entr 0.002209432190284133
ep19_l4_test_time 1.7030880451202393
gc 0
Train Epoch20 Acc 0.9926964285714286 (555910/560000), AUC 0.999066948890686
ep20_train_time 119.49907541275024
Test Epoch20 layer0 Acc 0.9656, AUC 0.4987497925758362, avg_entr 0.026228131726384163
ep20_l0_test_time 0.5551061630249023
Test Epoch20 layer1 Acc 0.9719714285714286, AUC 0.49800509214401245, avg_entr 0.005075063556432724
ep20_l1_test_time 0.8550326824188232
Test Epoch20 layer2 Acc 0.9723142857142857, AUC 0.4977075159549713, avg_entr 0.0030204642098397017
ep20_l2_test_time 1.1389777660369873
Test Epoch20 layer3 Acc 0.9724857142857143, AUC 0.497475802898407, avg_entr 0.002480418886989355
ep20_l3_test_time 1.4461338520050049
Test Epoch20 layer4 Acc 0.9725428571428572, AUC 0.49717944860458374, avg_entr 0.0022276027593761683
ep20_l4_test_time 1.6995112895965576
gc 0
Train Epoch21 Acc 0.9928464285714286 (555994/560000), AUC 0.9990571737289429
ep21_train_time 120.0618085861206
Test Epoch21 layer0 Acc 0.9656857142857143, AUC 0.49875280261039734, avg_entr 0.026340972632169724
ep21_l0_test_time 0.5590107440948486
Test Epoch21 layer1 Acc 0.9718, AUC 0.49802330136299133, avg_entr 0.005080345086753368
ep21_l1_test_time 0.8406834602355957
Test Epoch21 layer2 Acc 0.9720285714285715, AUC 0.49771255254745483, avg_entr 0.0030475312378257513
ep21_l2_test_time 1.1333396434783936
Test Epoch21 layer3 Acc 0.9719428571428571, AUC 0.4975065588951111, avg_entr 0.002525844145566225
ep21_l3_test_time 1.4468357563018799
Test Epoch21 layer4 Acc 0.9720571428571428, AUC 0.4972202479839325, avg_entr 0.0021963876206427813
ep21_l4_test_time 1.7063748836517334
gc 0
Train Epoch22 Acc 0.9928696428571429 (556007/560000), AUC 0.9990875124931335
ep22_train_time 119.32630491256714
Test Epoch22 layer0 Acc 0.9659428571428571, AUC 0.49875375628471375, avg_entr 0.02614198811352253
ep22_l0_test_time 0.5509073734283447
Test Epoch22 layer1 Acc 0.9722571428571428, AUC 0.4980442523956299, avg_entr 0.004989450331777334
ep22_l1_test_time 0.8498597145080566
Test Epoch22 layer2 Acc 0.9724571428571429, AUC 0.49780699610710144, avg_entr 0.00297269644215703
ep22_l2_test_time 1.1749320030212402
Test Epoch22 layer3 Acc 0.9724285714285714, AUC 0.49755170941352844, avg_entr 0.0024425871670246124
ep22_l3_test_time 1.444258213043213
Test Epoch22 layer4 Acc 0.9724, AUC 0.4972711503505707, avg_entr 0.002169420011341572
ep22_l4_test_time 1.703336238861084
gc 0
Train Epoch23 Acc 0.9929053571428571 (556027/560000), AUC 0.9990683794021606
ep23_train_time 118.96644854545593
Test Epoch23 layer0 Acc 0.9658571428571429, AUC 0.4987573027610779, avg_entr 0.02605426125228405
ep23_l0_test_time 0.556321382522583
Test Epoch23 layer1 Acc 0.9718571428571429, AUC 0.498014897108078, avg_entr 0.005017418880015612
ep23_l1_test_time 0.8460555076599121
Test Epoch23 layer2 Acc 0.9722285714285714, AUC 0.49770593643188477, avg_entr 0.0029420529026538134
ep23_l2_test_time 1.1415300369262695
Test Epoch23 layer3 Acc 0.9720857142857143, AUC 0.49746185541152954, avg_entr 0.0023485394194722176
ep23_l3_test_time 1.4432239532470703
Test Epoch23 layer4 Acc 0.9722285714285714, AUC 0.4971185028553009, avg_entr 0.0020618995185941458
ep23_l4_test_time 1.706655740737915
gc 0
Train Epoch24 Acc 0.9929232142857143 (556037/560000), AUC 0.9990710020065308
ep24_train_time 119.03707075119019
Test Epoch24 layer0 Acc 0.9657142857142857, AUC 0.4987528324127197, avg_entr 0.026320723816752434
ep24_l0_test_time 0.5586011409759521
Test Epoch24 layer1 Acc 0.9715714285714285, AUC 0.4979921877384186, avg_entr 0.005092182196676731
ep24_l1_test_time 0.8466522693634033
Test Epoch24 layer2 Acc 0.9715714285714285, AUC 0.49762648344039917, avg_entr 0.002992955269291997
ep24_l2_test_time 1.13572359085083
Test Epoch24 layer3 Acc 0.9717142857142858, AUC 0.4974214434623718, avg_entr 0.002452707849442959
ep24_l3_test_time 1.4545161724090576
Test Epoch24 layer4 Acc 0.9717142857142858, AUC 0.497151643037796, avg_entr 0.0021207681857049465
ep24_l4_test_time 1.7038764953613281
gc 0
Train Epoch25 Acc 0.9929875 (556073/560000), AUC 0.9991016983985901
ep25_train_time 119.10678720474243
Test Epoch25 layer0 Acc 0.9658, AUC 0.49875059723854065, avg_entr 0.026226844638586044
ep25_l0_test_time 0.5975925922393799
Test Epoch25 layer1 Acc 0.9718, AUC 0.4980161190032959, avg_entr 0.004973375238478184
ep25_l1_test_time 0.8360402584075928
Test Epoch25 layer2 Acc 0.972, AUC 0.49768003821372986, avg_entr 0.00299882423132658
ep25_l2_test_time 1.1411325931549072
Test Epoch25 layer3 Acc 0.972, AUC 0.49745386838912964, avg_entr 0.00238673179410398
ep25_l3_test_time 1.4672987461090088
Test Epoch25 layer4 Acc 0.9720571428571428, AUC 0.49710613489151, avg_entr 0.0020489306189119816
ep25_l4_test_time 1.7188925743103027
gc 0
Train Epoch26 Acc 0.9930446428571429 (556105/560000), AUC 0.999082088470459
ep26_train_time 119.43765711784363
Test Epoch26 layer0 Acc 0.9658, AUC 0.49875161051750183, avg_entr 0.026206420734524727
ep26_l0_test_time 0.5548648834228516
Test Epoch26 layer1 Acc 0.9718857142857142, AUC 0.49802321195602417, avg_entr 0.005027579143643379
ep26_l1_test_time 0.8489174842834473
Test Epoch26 layer2 Acc 0.9721714285714286, AUC 0.4976791739463806, avg_entr 0.002950242953374982
ep26_l2_test_time 1.1412057876586914
Test Epoch26 layer3 Acc 0.9721142857142857, AUC 0.4974733293056488, avg_entr 0.002382143633440137
ep26_l3_test_time 1.4669699668884277
Test Epoch26 layer4 Acc 0.9721714285714286, AUC 0.49710869789123535, avg_entr 0.0021217891480773687
ep26_l4_test_time 1.734431505203247
gc 0
Train Epoch27 Acc 0.9930535714285714 (556110/560000), AUC 0.9990699887275696
ep27_train_time 119.34698247909546
Test Epoch27 layer0 Acc 0.9656, AUC 0.49875110387802124, avg_entr 0.02625136449933052
ep27_l0_test_time 0.5485742092132568
Test Epoch27 layer1 Acc 0.9716285714285714, AUC 0.49800512194633484, avg_entr 0.005083874333649874
ep27_l1_test_time 0.8525159358978271
Test Epoch27 layer2 Acc 0.9718, AUC 0.49765095114707947, avg_entr 0.002996548544615507
ep27_l2_test_time 1.1333255767822266
Test Epoch27 layer3 Acc 0.9719142857142857, AUC 0.49742263555526733, avg_entr 0.0024280801881104708
ep27_l3_test_time 1.4390416145324707
Test Epoch27 layer4 Acc 0.9719428571428571, AUC 0.4970925450325012, avg_entr 0.0021442417055368423
ep27_l4_test_time 1.6995658874511719
gc 0
Train Epoch28 Acc 0.993075 (556122/560000), AUC 0.9990888833999634
ep28_train_time 118.98933935165405
Test Epoch28 layer0 Acc 0.9657428571428571, AUC 0.4987506866455078, avg_entr 0.02621118165552616
ep28_l0_test_time 0.5564751625061035
Test Epoch28 layer1 Acc 0.9717142857142858, AUC 0.4980103671550751, avg_entr 0.004997872281819582
ep28_l1_test_time 0.840834379196167
Test Epoch28 layer2 Acc 0.9719714285714286, AUC 0.49768275022506714, avg_entr 0.0029923832044005394
ep28_l2_test_time 1.1317486763000488
Test Epoch28 layer3 Acc 0.9719142857142857, AUC 0.4974852204322815, avg_entr 0.0024599784519523382
ep28_l3_test_time 1.4379146099090576
Test Epoch28 layer4 Acc 0.9720285714285715, AUC 0.49716219305992126, avg_entr 0.0021130400709807873
ep28_l4_test_time 1.7773597240447998
gc 0
Train Epoch29 Acc 0.9930964285714285 (556134/560000), AUC 0.9990782737731934
ep29_train_time 119.12172651290894
Test Epoch29 layer0 Acc 0.9658285714285715, AUC 0.4987518787384033, avg_entr 0.026163961738348007
ep29_l0_test_time 0.5602846145629883
Test Epoch29 layer1 Acc 0.9718285714285714, AUC 0.4980130195617676, avg_entr 0.0050690253265202045
ep29_l1_test_time 0.9132394790649414
Test Epoch29 layer2 Acc 0.9721142857142857, AUC 0.497667521238327, avg_entr 0.00302330800332129
ep29_l2_test_time 1.1539547443389893
Test Epoch29 layer3 Acc 0.9721714285714286, AUC 0.49743708968162537, avg_entr 0.0024919509887695312
ep29_l3_test_time 1.4607954025268555
Test Epoch29 layer4 Acc 0.9721428571428572, AUC 0.4971327781677246, avg_entr 0.002186771482229233
ep29_l4_test_time 1.7207000255584717
gc 0
Train Epoch30 Acc 0.99305 (556108/560000), AUC 0.9990735054016113
ep30_train_time 119.44832134246826
Test Epoch30 layer0 Acc 0.9658857142857142, AUC 0.4987522065639496, avg_entr 0.026130853220820427
ep30_l0_test_time 0.5461187362670898
Test Epoch30 layer1 Acc 0.9717428571428571, AUC 0.49800410866737366, avg_entr 0.005075038410723209
ep30_l1_test_time 0.9120633602142334
Test Epoch30 layer2 Acc 0.9720285714285715, AUC 0.4976447522640228, avg_entr 0.0030361306853592396
ep30_l2_test_time 1.1439356803894043
Test Epoch30 layer3 Acc 0.9719714285714286, AUC 0.4974369704723358, avg_entr 0.0025012388359755278
ep30_l3_test_time 1.4339251518249512
Test Epoch30 layer4 Acc 0.9720857142857143, AUC 0.49713334441185, avg_entr 0.0021940774749964476
ep30_l4_test_time 1.7330799102783203
gc 0
Train Epoch31 Acc 0.9930839285714286 (556127/560000), AUC 0.9990676641464233
ep31_train_time 119.31290483474731
Test Epoch31 layer0 Acc 0.9658571428571429, AUC 0.49875327944755554, avg_entr 0.026169568300247192
ep31_l0_test_time 0.549980640411377
Test Epoch31 layer1 Acc 0.9718, AUC 0.4979986548423767, avg_entr 0.005077791400253773
ep31_l1_test_time 0.8408277034759521
Test Epoch31 layer2 Acc 0.9720571428571428, AUC 0.4976436197757721, avg_entr 0.002974224044010043
ep31_l2_test_time 1.1359844207763672
Test Epoch31 layer3 Acc 0.9721714285714286, AUC 0.4974670112133026, avg_entr 0.0024124085903167725
ep31_l3_test_time 1.4315295219421387
Test Epoch31 layer4 Acc 0.9722, AUC 0.4971245229244232, avg_entr 0.0021421043202281
ep31_l4_test_time 1.6957683563232422
gc 0
Train Epoch32 Acc 0.9930892857142857 (556130/560000), AUC 0.9990813136100769
ep32_train_time 119.23242807388306
Test Epoch32 layer0 Acc 0.9657714285714286, AUC 0.4987526535987854, avg_entr 0.026170196011662483
ep32_l0_test_time 0.5481624603271484
Test Epoch32 layer1 Acc 0.9718571428571429, AUC 0.4980106055736542, avg_entr 0.005085780750960112
ep32_l1_test_time 0.8472371101379395
Test Epoch32 layer2 Acc 0.9719714285714286, AUC 0.4976451098918915, avg_entr 0.0029985145665705204
ep32_l2_test_time 1.1374170780181885
Test Epoch32 layer3 Acc 0.9721428571428572, AUC 0.49744266271591187, avg_entr 0.0024749471340328455
ep32_l3_test_time 1.4516513347625732
Test Epoch32 layer4 Acc 0.9721142857142857, AUC 0.4971197545528412, avg_entr 0.002203237498179078
ep32_l4_test_time 1.7337491512298584
gc 0
Train Epoch33 Acc 0.9930892857142857 (556130/560000), AUC 0.9990736246109009
ep33_train_time 119.11191153526306
Test Epoch33 layer0 Acc 0.9657428571428571, AUC 0.49875137209892273, avg_entr 0.026175331324338913
ep33_l0_test_time 0.5537230968475342
Test Epoch33 layer1 Acc 0.9717714285714286, AUC 0.4980032742023468, avg_entr 0.00508500961586833
ep33_l1_test_time 0.8399741649627686
Test Epoch33 layer2 Acc 0.9719714285714286, AUC 0.4976503849029541, avg_entr 0.0030031322967261076
ep33_l2_test_time 1.1262211799621582
Test Epoch33 layer3 Acc 0.9719428571428571, AUC 0.49746593832969666, avg_entr 0.002502463525161147
ep33_l3_test_time 1.4591460227966309
Test Epoch33 layer4 Acc 0.9720571428571428, AUC 0.4971778690814972, avg_entr 0.002181750489398837
ep33_l4_test_time 1.7067184448242188
gc 0
Train Epoch34 Acc 0.9931392857142857 (556158/560000), AUC 0.9990935325622559
ep34_train_time 119.44328808784485
Test Epoch34 layer0 Acc 0.9657142857142857, AUC 0.49875110387802124, avg_entr 0.02619936503469944
ep34_l0_test_time 0.5598037242889404
Test Epoch34 layer1 Acc 0.9717142857142858, AUC 0.498004674911499, avg_entr 0.005070469342172146
ep34_l1_test_time 0.8491995334625244
Test Epoch34 layer2 Acc 0.972, AUC 0.49764636158943176, avg_entr 0.002999131102114916
ep34_l2_test_time 1.1415729522705078
Test Epoch34 layer3 Acc 0.972, AUC 0.4974690079689026, avg_entr 0.002504010684788227
ep34_l3_test_time 1.4440019130706787
Test Epoch34 layer4 Acc 0.9721142857142857, AUC 0.49714550375938416, avg_entr 0.0021748109720647335
ep34_l4_test_time 1.7405023574829102
gc 0
Train Epoch35 Acc 0.9931553571428572 (556167/560000), AUC 0.999088704586029
ep35_train_time 119.38610029220581
Test Epoch35 layer0 Acc 0.9658, AUC 0.49875134229660034, avg_entr 0.026168063282966614
ep35_l0_test_time 0.5478332042694092
Test Epoch35 layer1 Acc 0.9717142857142858, AUC 0.49799755215644836, avg_entr 0.005070187617093325
ep35_l1_test_time 0.8432621955871582
Test Epoch35 layer2 Acc 0.9719142857142857, AUC 0.49763089418411255, avg_entr 0.0029933720361441374
ep35_l2_test_time 1.1410338878631592
Test Epoch35 layer3 Acc 0.9720285714285715, AUC 0.497452974319458, avg_entr 0.002492697676643729
ep35_l3_test_time 1.4418554306030273
Test Epoch35 layer4 Acc 0.9720285714285715, AUC 0.4971493184566498, avg_entr 0.0021613293793052435
ep35_l4_test_time 1.7442870140075684
gc 0
Train Epoch36 Acc 0.9931446428571429 (556161/560000), AUC 0.999083399772644
ep36_train_time 119.3334846496582
Test Epoch36 layer0 Acc 0.9657714285714286, AUC 0.4987519681453705, avg_entr 0.026159601286053658
ep36_l0_test_time 0.5523622035980225
Test Epoch36 layer1 Acc 0.9717428571428571, AUC 0.497998982667923, avg_entr 0.005070383660495281
ep36_l1_test_time 0.8492038249969482
Test Epoch36 layer2 Acc 0.9719714285714286, AUC 0.4976319670677185, avg_entr 0.0029840078204870224
ep36_l2_test_time 1.1525089740753174
Test Epoch36 layer3 Acc 0.9721142857142857, AUC 0.49743935465812683, avg_entr 0.0025000907480716705
ep36_l3_test_time 1.4546873569488525
Test Epoch36 layer4 Acc 0.9721142857142857, AUC 0.49713173508644104, avg_entr 0.002185524208471179
ep36_l4_test_time 1.6967496871948242
gc 0
Train Epoch37 Acc 0.9931946428571429 (556189/560000), AUC 0.9990791082382202
ep37_train_time 119.35453367233276
Test Epoch37 layer0 Acc 0.9658, AUC 0.49875161051750183, avg_entr 0.02615564689040184
ep37_l0_test_time 0.5498623847961426
Test Epoch37 layer1 Acc 0.9717428571428571, AUC 0.4979991614818573, avg_entr 0.005069737788289785
ep37_l1_test_time 0.838191032409668
Test Epoch37 layer2 Acc 0.972, AUC 0.49763283133506775, avg_entr 0.002993776695802808
ep37_l2_test_time 1.1352612972259521
Test Epoch37 layer3 Acc 0.9719714285714286, AUC 0.4974490702152252, avg_entr 0.0025041752960532904
ep37_l3_test_time 1.4378056526184082
Test Epoch37 layer4 Acc 0.9721714285714286, AUC 0.49715104699134827, avg_entr 0.002186739118769765
ep37_l4_test_time 1.6963818073272705
gc 0
Train Epoch38 Acc 0.9931339285714286 (556155/560000), AUC 0.9990769624710083
ep38_train_time 119.48523712158203
Test Epoch38 layer0 Acc 0.9658, AUC 0.4987516403198242, avg_entr 0.02616398222744465
ep38_l0_test_time 0.5492606163024902
Test Epoch38 layer1 Acc 0.9717428571428571, AUC 0.49800723791122437, avg_entr 0.005075556226074696
ep38_l1_test_time 0.8436660766601562
Test Epoch38 layer2 Acc 0.9720571428571428, AUC 0.49762997031211853, avg_entr 0.002999529941007495
ep38_l2_test_time 1.1364333629608154
Test Epoch38 layer3 Acc 0.9720285714285715, AUC 0.4974442422389984, avg_entr 0.002513719955459237
ep38_l3_test_time 1.4346811771392822
Test Epoch38 layer4 Acc 0.9721142857142857, AUC 0.4971405565738678, avg_entr 0.002209952799603343
ep38_l4_test_time 1.715862512588501
gc 0
Train Epoch39 Acc 0.9931589285714286 (556169/560000), AUC 0.9990879893302917
ep39_train_time 118.90437340736389
Test Epoch39 layer0 Acc 0.9658, AUC 0.4987514019012451, avg_entr 0.026159238070249557
ep39_l0_test_time 0.5950896739959717
Test Epoch39 layer1 Acc 0.9717428571428571, AUC 0.49799904227256775, avg_entr 0.005079749505966902
ep39_l1_test_time 0.8824477195739746
Test Epoch39 layer2 Acc 0.972, AUC 0.49762916564941406, avg_entr 0.00300302030518651
ep39_l2_test_time 1.147212266921997
Test Epoch39 layer3 Acc 0.9719428571428571, AUC 0.49743959307670593, avg_entr 0.0025110049173235893
ep39_l3_test_time 1.4401755332946777
Test Epoch39 layer4 Acc 0.9721142857142857, AUC 0.49713993072509766, avg_entr 0.002205529250204563
ep39_l4_test_time 1.6963038444519043
gc 0
Train Epoch40 Acc 0.9931303571428571 (556153/560000), AUC 0.9990988969802856
ep40_train_time 119.7531201839447
Test Epoch40 layer0 Acc 0.9658285714285715, AUC 0.4987512528896332, avg_entr 0.026151143014431
ep40_l0_test_time 0.556586503982544
Test Epoch40 layer1 Acc 0.9717428571428571, AUC 0.4980039894580841, avg_entr 0.005079807713627815
ep40_l1_test_time 0.8609147071838379
Test Epoch40 layer2 Acc 0.9720571428571428, AUC 0.49762800335884094, avg_entr 0.0029981271363794804
ep40_l2_test_time 1.1341826915740967
Test Epoch40 layer3 Acc 0.972, AUC 0.4974396228790283, avg_entr 0.0025097676552832127
ep40_l3_test_time 1.452155590057373
Test Epoch40 layer4 Acc 0.9721142857142857, AUC 0.4971317648887634, avg_entr 0.0022017844021320343
ep40_l4_test_time 1.695298194885254
gc 0
Train Epoch41 Acc 0.9931428571428571 (556160/560000), AUC 0.9991037249565125
ep41_train_time 119.5660126209259
Test Epoch41 layer0 Acc 0.9658, AUC 0.49875137209892273, avg_entr 0.026159128174185753
ep41_l0_test_time 0.5557584762573242
Test Epoch41 layer1 Acc 0.9717428571428571, AUC 0.498002827167511, avg_entr 0.005078283604234457
ep41_l1_test_time 0.846642255783081
Test Epoch41 layer2 Acc 0.9720571428571428, AUC 0.49763330817222595, avg_entr 0.002997965319082141
ep41_l2_test_time 1.1721045970916748
Test Epoch41 layer3 Acc 0.9718857142857142, AUC 0.49744313955307007, avg_entr 0.002508643316105008
ep41_l3_test_time 1.4547162055969238
Test Epoch41 layer4 Acc 0.9720571428571428, AUC 0.4971437454223633, avg_entr 0.0022009694948792458
ep41_l4_test_time 1.747642993927002
gc 0
Train Epoch42 Acc 0.99315 (556164/560000), AUC 0.9990612864494324
ep42_train_time 119.43133687973022
Test Epoch42 layer0 Acc 0.9658285714285715, AUC 0.4987514019012451, avg_entr 0.026150161400437355
ep42_l0_test_time 0.5690751075744629
Test Epoch42 layer1 Acc 0.9717428571428571, AUC 0.4980017840862274, avg_entr 0.005080518312752247
ep42_l1_test_time 0.8462603092193604
Test Epoch42 layer2 Acc 0.9720285714285715, AUC 0.4976302683353424, avg_entr 0.0030003308784216642
ep42_l2_test_time 1.1317775249481201
Test Epoch42 layer3 Acc 0.9718857142857142, AUC 0.49744078516960144, avg_entr 0.0025112859439104795
ep42_l3_test_time 1.4521775245666504
Test Epoch42 layer4 Acc 0.9720857142857143, AUC 0.49713757634162903, avg_entr 0.00220823148265481
ep42_l4_test_time 1.6903355121612549
gc 0
Train Epoch43 Acc 0.9931589285714286 (556169/560000), AUC 0.9991122484207153
ep43_train_time 119.60049414634705
Test Epoch43 layer0 Acc 0.9658, AUC 0.49875158071517944, avg_entr 0.026169510558247566
ep43_l0_test_time 0.5559132099151611
Test Epoch43 layer1 Acc 0.9717428571428571, AUC 0.49800166487693787, avg_entr 0.005080633331090212
ep43_l1_test_time 0.8500850200653076
Test Epoch43 layer2 Acc 0.9719714285714286, AUC 0.497629851102829, avg_entr 0.0029953517951071262
ep43_l2_test_time 1.1352827548980713
Test Epoch43 layer3 Acc 0.9719142857142857, AUC 0.4974386394023895, avg_entr 0.0025066938251256943
ep43_l3_test_time 1.5305109024047852
Test Epoch43 layer4 Acc 0.9721142857142857, AUC 0.49713101983070374, avg_entr 0.002204005839303136
ep43_l4_test_time 1.7157537937164307
gc 0
Train Epoch44 Acc 0.9931267857142857 (556151/560000), AUC 0.9990905523300171
ep44_train_time 119.53432297706604
Test Epoch44 layer0 Acc 0.9658285714285715, AUC 0.49875131249427795, avg_entr 0.02616201899945736
ep44_l0_test_time 0.5499248504638672
Test Epoch44 layer1 Acc 0.9717428571428571, AUC 0.4980025589466095, avg_entr 0.005080284085124731
ep44_l1_test_time 0.8464243412017822
Test Epoch44 layer2 Acc 0.972, AUC 0.4976290762424469, avg_entr 0.0029955061618238688
ep44_l2_test_time 1.1425886154174805
Test Epoch44 layer3 Acc 0.9719142857142857, AUC 0.4974355101585388, avg_entr 0.002508664270862937
ep44_l3_test_time 1.4488811492919922
Test Epoch44 layer4 Acc 0.9720857142857143, AUC 0.4971294403076172, avg_entr 0.0022047741804271936
ep44_l4_test_time 1.7025282382965088
gc 0
Train Epoch45 Acc 0.9931517857142858 (556165/560000), AUC 0.999089777469635
ep45_train_time 119.63661575317383
Test Epoch45 layer0 Acc 0.9658285714285715, AUC 0.49875137209892273, avg_entr 0.02615697868168354
ep45_l0_test_time 0.5681612491607666
Test Epoch45 layer1 Acc 0.9717428571428571, AUC 0.49800270795822144, avg_entr 0.005079749505966902
ep45_l1_test_time 0.8418915271759033
Test Epoch45 layer2 Acc 0.9720285714285715, AUC 0.4976278841495514, avg_entr 0.0029927766881883144
ep45_l2_test_time 1.135387897491455
Test Epoch45 layer3 Acc 0.9719142857142857, AUC 0.4974351227283478, avg_entr 0.0025059618055820465
ep45_l3_test_time 1.4424631595611572
Test Epoch45 layer4 Acc 0.9721142857142857, AUC 0.4971327781677246, avg_entr 0.002204230520874262
ep45_l4_test_time 1.7213208675384521
gc 0
Train Epoch46 Acc 0.9931589285714286 (556169/560000), AUC 0.9990873336791992
ep46_train_time 119.59437918663025
Test Epoch46 layer0 Acc 0.9658, AUC 0.4987514317035675, avg_entr 0.026158936321735382
ep46_l0_test_time 0.552771806716919
Test Epoch46 layer1 Acc 0.9717428571428571, AUC 0.49800318479537964, avg_entr 0.005079678259789944
ep46_l1_test_time 0.8360412120819092
Test Epoch46 layer2 Acc 0.9720571428571428, AUC 0.49762699007987976, avg_entr 0.002991955727338791
ep46_l2_test_time 1.1381328105926514
Test Epoch46 layer3 Acc 0.9719714285714286, AUC 0.4974338114261627, avg_entr 0.0025050423573702574
ep46_l3_test_time 1.4454100131988525
Test Epoch46 layer4 Acc 0.9720857142857143, AUC 0.49713239073753357, avg_entr 0.0022051206324249506
ep46_l4_test_time 1.7031846046447754
gc 0
Train Epoch47 Acc 0.9931821428571429 (556182/560000), AUC 0.9990630745887756
ep47_train_time 119.01648712158203
Test Epoch47 layer0 Acc 0.9658, AUC 0.4987514913082123, avg_entr 0.026157274842262268
ep47_l0_test_time 0.5570147037506104
Test Epoch47 layer1 Acc 0.9717428571428571, AUC 0.49800270795822144, avg_entr 0.0050796023570001125
ep47_l1_test_time 0.8568449020385742
Test Epoch47 layer2 Acc 0.9720285714285715, AUC 0.49762699007987976, avg_entr 0.002991702174767852
ep47_l2_test_time 1.1394541263580322
Test Epoch47 layer3 Acc 0.9719428571428571, AUC 0.4974338710308075, avg_entr 0.002505895448848605
ep47_l3_test_time 1.4356262683868408
Test Epoch47 layer4 Acc 0.9720857142857143, AUC 0.4971332252025604, avg_entr 0.00220575206913054
ep47_l4_test_time 1.6991875171661377
gc 0
Train Epoch48 Acc 0.9931892857142857 (556186/560000), AUC 0.9991028904914856
ep48_train_time 119.91033673286438
Test Epoch48 layer0 Acc 0.9658, AUC 0.49875158071517944, avg_entr 0.026156418025493622
ep48_l0_test_time 0.5519363880157471
Test Epoch48 layer1 Acc 0.9717428571428571, AUC 0.49800220131874084, avg_entr 0.005079156253486872
ep48_l1_test_time 0.8480532169342041
Test Epoch48 layer2 Acc 0.972, AUC 0.4976271986961365, avg_entr 0.00299038365483284
ep48_l2_test_time 1.1319935321807861
Test Epoch48 layer3 Acc 0.9720285714285715, AUC 0.4974326491355896, avg_entr 0.0025029946118593216
ep48_l3_test_time 1.4415507316589355
Test Epoch48 layer4 Acc 0.9721142857142857, AUC 0.4971333146095276, avg_entr 0.002202595816925168
ep48_l4_test_time 1.7080905437469482
gc 0
Train Epoch49 Acc 0.9931946428571429 (556189/560000), AUC 0.9990906715393066
ep49_train_time 120.34118127822876
Test Epoch49 layer0 Acc 0.9658, AUC 0.49875158071517944, avg_entr 0.02615896426141262
ep49_l0_test_time 0.5503337383270264
Test Epoch49 layer1 Acc 0.9717428571428571, AUC 0.49800214171409607, avg_entr 0.005079090129584074
ep49_l1_test_time 0.8435602188110352
Test Epoch49 layer2 Acc 0.972, AUC 0.49762678146362305, avg_entr 0.0029905110131949186
ep49_l2_test_time 1.1853866577148438
Test Epoch49 layer3 Acc 0.972, AUC 0.4974321722984314, avg_entr 0.00250237132422626
ep49_l3_test_time 1.467289686203003
Test Epoch49 layer4 Acc 0.9721142857142857, AUC 0.4971329867839813, avg_entr 0.002202376024797559
ep49_l4_test_time 1.6843080520629883
Best AUC 0.49881526827812195
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train+valid_time 6251.841206550598
Start Testing
Load ckpt at ckpt/dbpedia_14_transformeral_l5_pad40//dbpedia_14_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.9835142857142857, AUC 0.4994746744632721, avg_entr 0.07013442367315292
ep49_l0_test_time 0.5399889945983887
Test Epoch49 layer1 Acc 0.9836857142857143, AUC 0.4995746910572052, avg_entr 0.03260056674480438
ep49_l1_test_time 0.8478560447692871
Test Epoch49 layer2 Acc 0.9821142857142857, AUC 0.49948278069496155, avg_entr 0.02517296001315117
ep49_l2_test_time 1.1340174674987793
Test Epoch49 layer3 Acc 0.9815714285714285, AUC 0.4994480311870575, avg_entr 0.02236754447221756
ep49_l3_test_time 1.4607083797454834
Test Epoch49 layer4 Acc 0.9811142857142857, AUC 0.49937301874160767, avg_entr 0.02256144769489765
ep49_l4_test_time 1.7142624855041504
