total count words 887881
vocab size 30000
found 28354 words in glove
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=14, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=14, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 1792
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 1792
layers.0.ae.h.0.bias 14
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17267662
init_time 58.6826171875
Start Training
train_mask {0} False
gc 0
Train Epoch0 Acc 0.08489464285714286 (47541/560000), AUC 0.5132188200950623
ep0_train_time 47.811136960983276
Test Epoch0 threshold 0.7 Acc 0.9647428571428571, AUC 0.4986012578010559, avg_entr 0.029802201315760612
ep0_t0.7_test_time 0.41106152534484863
Save ckpt to ckpt/dbpedia_14_lstmal_l5adf_pad20_t0.7_m1//dbpedia_14_lstmal_l5.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.0885875 (49609/560000), AUC 0.5203480124473572
ep1_train_time 46.38708853721619
Test Epoch1 threshold 0.7 Acc 0.9644571428571429, AUC 0.49866199493408203, avg_entr 0.01691446267068386
ep1_t0.7_test_time 0.4185762405395508
Save ckpt to ckpt/dbpedia_14_lstmal_l5adf_pad20_t0.7_m1//dbpedia_14_lstmal_l5.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.08988571428571429 (50336/560000), AUC 0.5240303874015808
ep2_train_time 46.54896521568298
Test Epoch2 threshold 0.7 Acc 0.9646285714285714, AUC 0.4986949861049652, avg_entr 0.012236706912517548
ep2_t0.7_test_time 0.4110374450683594
Save ckpt to ckpt/dbpedia_14_lstmal_l5adf_pad20_t0.7_m1//dbpedia_14_lstmal_l5.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.09094464285714286 (50929/560000), AUC 0.5278033018112183
ep3_train_time 46.444313526153564
Test Epoch3 threshold 0.7 Acc 0.9651142857142857, AUC 0.4987207353115082, avg_entr 0.009602105244994164
ep3_t0.7_test_time 0.40999937057495117
Save ckpt to ckpt/dbpedia_14_lstmal_l5adf_pad20_t0.7_m1//dbpedia_14_lstmal_l5.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.09141785714285715 (51194/560000), AUC 0.5315135717391968
ep4_train_time 46.431217670440674
Test Epoch4 threshold 0.7 Acc 0.9648857142857142, AUC 0.4986932575702667, avg_entr 0.008875391446053982
ep4_t0.7_test_time 0.41435766220092773
gc 0
Train Epoch5 Acc 0.0913375 (51149/560000), AUC 0.5349948406219482
ep5_train_time 46.57271409034729
Test Epoch5 threshold 0.7 Acc 0.9645714285714285, AUC 0.49868959188461304, avg_entr 0.008788016624748707
ep5_t0.7_test_time 0.4112837314605713
gc 0
Train Epoch6 Acc 0.09095 (50932/560000), AUC 0.538703978061676
ep6_train_time 46.61930751800537
Test Epoch6 threshold 0.7 Acc 0.9646857142857143, AUC 0.49872779846191406, avg_entr 0.008496075868606567
ep6_t0.7_test_time 0.4148745536804199
Save ckpt to ckpt/dbpedia_14_lstmal_l5adf_pad20_t0.7_m1//dbpedia_14_lstmal_l5.pt  ,ep 6
gc 0
Train Epoch7 Acc 0.09061785714285714 (50746/560000), AUC 0.5420525670051575
ep7_train_time 46.5963613986969
Test Epoch7 threshold 0.7 Acc 0.9646, AUC 0.49871954321861267, avg_entr 0.008452828973531723
ep7_t0.7_test_time 0.415463924407959
gc 0
Train Epoch8 Acc 0.0903125 (50575/560000), AUC 0.5436801314353943
ep8_train_time 46.589601039886475
Test Epoch8 threshold 0.7 Acc 0.9648, AUC 0.49871349334716797, avg_entr 0.008298391476273537
ep8_t0.7_test_time 0.42000818252563477
gc 0
Train Epoch9 Acc 0.090375 (50610/560000), AUC 0.5442910194396973
ep9_train_time 46.524988412857056
Test Epoch9 threshold 0.7 Acc 0.9647428571428571, AUC 0.4987289011478424, avg_entr 0.008413697592914104
ep9_t0.7_test_time 0.41472530364990234
Save ckpt to ckpt/dbpedia_14_lstmal_l5adf_pad20_t0.7_m1//dbpedia_14_lstmal_l5.pt  ,ep 9
Best AUC 0.4987289011478424
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train/valid_time 471.91137742996216
Start Testing
Load ckpt at ckpt/dbpedia_14_lstmal_l5adf_pad20_t0.7_m1//dbpedia_14_lstmal_l5.pt
Test threshold 0.7 Acc 0.9849428571428571, AUC 0.4997006952762604, avg_entr 0.005782724358141422
t0.7_test_time 0.4156157970428467
