total count words 887881
vocab size 30000
train size 560000, valid size 35000, test size 35000
found 28354 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=14, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=14, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 1792
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 1792
layers.0.ae.h.0.bias 14
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13674862
init_time 54.3864586353302
Start Training
gc 0
Train Epoch0 Acc 0.8359875 (468153/560000), AUC 0.9805504679679871
ep0_train_time 154.87176513671875
Test Epoch0 layer0 Acc 0.9720857142857143, AUC 0.9981609582901001, avg_entr 0.08625059574842453
ep0_l0_test_time 0.7018675804138184
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad60//dbpedia_14_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9726571428571429, AUC 0.9983156323432922, avg_entr 0.039712224155664444
ep0_l1_test_time 1.1269381046295166
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad60//dbpedia_14_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.9723714285714286, AUC 0.9976142644882202, avg_entr 0.02747678942978382
ep0_l2_test_time 1.5483381748199463
Test Epoch0 layer3 Acc 0.9718857142857142, AUC 0.9976115226745605, avg_entr 0.02434883639216423
ep0_l3_test_time 1.9477288722991943
Test Epoch0 layer4 Acc 0.9722857142857143, AUC 0.9975036978721619, avg_entr 0.024153418838977814
ep0_l4_test_time 2.342482805252075
gc 0
Train Epoch1 Acc 0.9796785714285714 (548620/560000), AUC 0.9973330497741699
ep1_train_time 153.49063730239868
Test Epoch1 layer0 Acc 0.9733142857142857, AUC 0.9983194470405579, avg_entr 0.04593570902943611
ep1_l0_test_time 0.705223560333252
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad60//dbpedia_14_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.9770285714285715, AUC 0.9978973269462585, avg_entr 0.01137473713606596
ep1_l1_test_time 1.1379683017730713
Test Epoch1 layer2 Acc 0.9771142857142857, AUC 0.9973829388618469, avg_entr 0.007974360138177872
ep1_l2_test_time 1.539003610610962
Test Epoch1 layer3 Acc 0.9766, AUC 0.9975207448005676, avg_entr 0.006700683385133743
ep1_l3_test_time 1.9282467365264893
Test Epoch1 layer4 Acc 0.9766, AUC 0.9970826506614685, avg_entr 0.006044492125511169
ep1_l4_test_time 2.338876247406006
gc 0
Train Epoch2 Acc 0.9838839285714286 (550975/560000), AUC 0.9977594614028931
ep2_train_time 153.86803007125854
Test Epoch2 layer0 Acc 0.9744857142857143, AUC 0.9984090924263, avg_entr 0.03317735716700554
ep2_l0_test_time 1.1600675582885742
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad60//dbpedia_14_transformeral_l5.pt  ,ep 2
Test Epoch2 layer1 Acc 0.9782571428571428, AUC 0.9975824952125549, avg_entr 0.006842691916972399
ep2_l1_test_time 1.3165040016174316
Test Epoch2 layer2 Acc 0.9788857142857142, AUC 0.9970701932907104, avg_entr 0.004751452710479498
ep2_l2_test_time 1.597374677658081
Test Epoch2 layer3 Acc 0.9788571428571429, AUC 0.9969258904457092, avg_entr 0.003995938692241907
ep2_l3_test_time 2.019221544265747
Test Epoch2 layer4 Acc 0.9786857142857143, AUC 0.9965983033180237, avg_entr 0.003586422186344862
ep2_l4_test_time 2.530306339263916
gc 0
Train Epoch3 Acc 0.9856785714285714 (551980/560000), AUC 0.9979974031448364
ep3_train_time 155.68853974342346
Test Epoch3 layer0 Acc 0.9743428571428572, AUC 0.9984250664710999, avg_entr 0.026429172605276108
ep3_l0_test_time 0.9380462169647217
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad60//dbpedia_14_transformeral_l5.pt  ,ep 3
Test Epoch3 layer1 Acc 0.9785142857142857, AUC 0.9977749586105347, avg_entr 0.00536262197420001
ep3_l1_test_time 1.2078742980957031
Test Epoch3 layer2 Acc 0.9784571428571428, AUC 0.9971279501914978, avg_entr 0.0034040515311062336
ep3_l2_test_time 1.7044446468353271
Test Epoch3 layer3 Acc 0.9781428571428571, AUC 0.99681556224823, avg_entr 0.002891282783821225
ep3_l3_test_time 2.0200769901275635
Test Epoch3 layer4 Acc 0.9781714285714286, AUC 0.9965587854385376, avg_entr 0.0025195369962602854
ep3_l4_test_time 2.4351983070373535
gc 0
Train Epoch4 Acc 0.9868660714285714 (552645/560000), AUC 0.9980064630508423
ep4_train_time 163.4332253932953
Test Epoch4 layer0 Acc 0.9746, AUC 0.998401939868927, avg_entr 0.0255126953125
ep4_l0_test_time 1.0673940181732178
Test Epoch4 layer1 Acc 0.9786571428571429, AUC 0.9976336359977722, avg_entr 0.004561142064630985
ep4_l1_test_time 1.3661761283874512
Test Epoch4 layer2 Acc 0.9786, AUC 0.9970391988754272, avg_entr 0.0029798541218042374
ep4_l2_test_time 1.8299026489257812
Test Epoch4 layer3 Acc 0.9785714285714285, AUC 0.996554970741272, avg_entr 0.002479125512763858
ep4_l3_test_time 2.3757598400115967
Test Epoch4 layer4 Acc 0.9784857142857143, AUC 0.9964447021484375, avg_entr 0.002180960029363632
ep4_l4_test_time 2.8068599700927734
gc 0
Train Epoch5 Acc 0.9880714285714286 (553320/560000), AUC 0.998406708240509
ep5_train_time 176.76071500778198
Test Epoch5 layer0 Acc 0.9744285714285714, AUC 0.9984338879585266, avg_entr 0.02474088966846466
ep5_l0_test_time 0.9043302536010742
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad60//dbpedia_14_transformeral_l5.pt  ,ep 5
Test Epoch5 layer1 Acc 0.9787428571428571, AUC 0.9974942803382874, avg_entr 0.004110424779355526
ep5_l1_test_time 1.328165054321289
Test Epoch5 layer2 Acc 0.9786857142857143, AUC 0.9970127940177917, avg_entr 0.0028576701879501343
ep5_l2_test_time 1.8005082607269287
Test Epoch5 layer3 Acc 0.9788, AUC 0.9968768954277039, avg_entr 0.002406563377007842
ep5_l3_test_time 2.28548002243042
Test Epoch5 layer4 Acc 0.9789142857142857, AUC 0.9964565634727478, avg_entr 0.002118772594258189
ep5_l4_test_time 2.927309989929199
gc 0
Train Epoch6 Acc 0.9886107142857142 (553622/560000), AUC 0.9985328912734985
ep6_train_time 177.82344436645508
Test Epoch6 layer0 Acc 0.9746571428571429, AUC 0.9984560012817383, avg_entr 0.02430281788110733
ep6_l0_test_time 0.9170103073120117
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad60//dbpedia_14_transformeral_l5.pt  ,ep 6
Test Epoch6 layer1 Acc 0.9793714285714286, AUC 0.9973602890968323, avg_entr 0.003959105350077152
ep6_l1_test_time 1.3447561264038086
Test Epoch6 layer2 Acc 0.9791428571428571, AUC 0.9967522621154785, avg_entr 0.002572473371401429
ep6_l2_test_time 1.810701608657837
Test Epoch6 layer3 Acc 0.9790285714285715, AUC 0.9966705441474915, avg_entr 0.002188680926337838
ep6_l3_test_time 2.4749674797058105
Test Epoch6 layer4 Acc 0.9790571428571428, AUC 0.9963498711585999, avg_entr 0.0019371660891920328
ep6_l4_test_time 2.8454360961914062
gc 0
Train Epoch7 Acc 0.98905 (553868/560000), AUC 0.9985976815223694
ep7_train_time 177.68853974342346
Test Epoch7 layer0 Acc 0.9744571428571429, AUC 0.9984256029129028, avg_entr 0.023862987756729126
ep7_l0_test_time 1.061445713043213
Test Epoch7 layer1 Acc 0.9785714285714285, AUC 0.9975099563598633, avg_entr 0.00394453015178442
ep7_l1_test_time 1.6078500747680664
Test Epoch7 layer2 Acc 0.9785428571428572, AUC 0.9968889951705933, avg_entr 0.002480470109730959
ep7_l2_test_time 1.9835700988769531
Test Epoch7 layer3 Acc 0.9785428571428572, AUC 0.9965550303459167, avg_entr 0.00210196478292346
ep7_l3_test_time 2.4342799186706543
Test Epoch7 layer4 Acc 0.9784857142857143, AUC 0.9959316253662109, avg_entr 0.001876966911368072
ep7_l4_test_time 2.645200252532959
gc 0
Train Epoch8 Acc 0.990075 (554442/560000), AUC 0.9986911416053772
ep8_train_time 178.29451656341553
Test Epoch8 layer0 Acc 0.9749428571428571, AUC 0.9984398484230042, avg_entr 0.023843590170145035
ep8_l0_test_time 1.2576649188995361
Test Epoch8 layer1 Acc 0.9783428571428572, AUC 0.9972679018974304, avg_entr 0.00421988544985652
ep8_l1_test_time 1.346635341644287
Test Epoch8 layer2 Acc 0.9783142857142857, AUC 0.9970160126686096, avg_entr 0.0026152695063501596
ep8_l2_test_time 1.7991974353790283
Test Epoch8 layer3 Acc 0.9784, AUC 0.996775209903717, avg_entr 0.0022470492403954268
ep8_l3_test_time 2.2930140495300293
Test Epoch8 layer4 Acc 0.9783142857142857, AUC 0.9960007667541504, avg_entr 0.0020403610542416573
ep8_l4_test_time 2.846113920211792
gc 0
Train Epoch9 Acc 0.9905339285714285 (554699/560000), AUC 0.9987444281578064
ep9_train_time 176.69752025604248
Test Epoch9 layer0 Acc 0.9743714285714286, AUC 0.9984175562858582, avg_entr 0.023502549156546593
ep9_l0_test_time 1.1745531558990479
Test Epoch9 layer1 Acc 0.9793142857142857, AUC 0.9972737431526184, avg_entr 0.004035656806081533
ep9_l1_test_time 1.3468265533447266
Test Epoch9 layer2 Acc 0.9787428571428571, AUC 0.996719241142273, avg_entr 0.002482079202309251
ep9_l2_test_time 1.7889559268951416
Test Epoch9 layer3 Acc 0.9787428571428571, AUC 0.9964075088500977, avg_entr 0.002045449335128069
ep9_l3_test_time 2.571122407913208
Test Epoch9 layer4 Acc 0.9786285714285714, AUC 0.9957262277603149, avg_entr 0.0018128096126019955
ep9_l4_test_time 2.973076105117798
gc 0
Train Epoch10 Acc 0.9907642857142858 (554828/560000), AUC 0.998741626739502
ep10_train_time 177.44099283218384
Test Epoch10 layer0 Acc 0.9747142857142858, AUC 0.9984337687492371, avg_entr 0.023669207468628883
ep10_l0_test_time 1.1902353763580322
Test Epoch10 layer1 Acc 0.9789142857142857, AUC 0.9972234964370728, avg_entr 0.003658309578895569
ep10_l1_test_time 1.600290298461914
Test Epoch10 layer2 Acc 0.9789428571428571, AUC 0.9967638850212097, avg_entr 0.0021630378905683756
ep10_l2_test_time 2.1673007011413574
Test Epoch10 layer3 Acc 0.9788571428571429, AUC 0.9963374733924866, avg_entr 0.0017647240310907364
ep10_l3_test_time 2.6373910903930664
Test Epoch10 layer4 Acc 0.9789142857142857, AUC 0.9957473874092102, avg_entr 0.001549278269521892
ep10_l4_test_time 2.844348907470703
gc 0
Train Epoch11 Acc 0.991025 (554974/560000), AUC 0.998752772808075
ep11_train_time 178.26540422439575
Test Epoch11 layer0 Acc 0.9746571428571429, AUC 0.9984543919563293, avg_entr 0.02354968525469303
ep11_l0_test_time 1.054908275604248
Test Epoch11 layer1 Acc 0.9789714285714286, AUC 0.9972897171974182, avg_entr 0.0038939365185797215
ep11_l1_test_time 1.3629324436187744
Test Epoch11 layer2 Acc 0.9789428571428571, AUC 0.996436595916748, avg_entr 0.0023360562045127153
ep11_l2_test_time 1.894794225692749
Test Epoch11 layer3 Acc 0.979, AUC 0.9961486458778381, avg_entr 0.002049495931714773
ep11_l3_test_time 2.524585247039795
Test Epoch11 layer4 Acc 0.9787428571428571, AUC 0.9956995248794556, avg_entr 0.0018411865457892418
ep11_l4_test_time 2.874238967895508
gc 0
Train Epoch12 Acc 0.9915571428571428 (555272/560000), AUC 0.9987911581993103
ep12_train_time 177.8801465034485
Test Epoch12 layer0 Acc 0.9747428571428571, AUC 0.9984357953071594, avg_entr 0.0234515517950058
ep12_l0_test_time 0.9381849765777588
Test Epoch12 layer1 Acc 0.9786857142857143, AUC 0.997098982334137, avg_entr 0.003979624714702368
ep12_l1_test_time 1.302034854888916
Test Epoch12 layer2 Acc 0.9784571428571428, AUC 0.9964030385017395, avg_entr 0.0023304573260247707
ep12_l2_test_time 1.7883930206298828
Test Epoch12 layer3 Acc 0.9783714285714286, AUC 0.9962169528007507, avg_entr 0.0019039210164919496
ep12_l3_test_time 2.3896868228912354
Test Epoch12 layer4 Acc 0.9784285714285714, AUC 0.9956187009811401, avg_entr 0.0017102067358791828
ep12_l4_test_time 2.9686062335968018
gc 0
Train Epoch13 Acc 0.9918339285714286 (555427/560000), AUC 0.9987918734550476
ep13_train_time 176.90975141525269
Test Epoch13 layer0 Acc 0.9748, AUC 0.9984257817268372, avg_entr 0.02312145009636879
ep13_l0_test_time 0.6899089813232422
Test Epoch13 layer1 Acc 0.9788285714285714, AUC 0.9970765709877014, avg_entr 0.003662253264337778
ep13_l1_test_time 1.1196599006652832
Test Epoch13 layer2 Acc 0.9784285714285714, AUC 0.9964896440505981, avg_entr 0.0022551300935447216
ep13_l2_test_time 1.5308716297149658
Test Epoch13 layer3 Acc 0.9784285714285714, AUC 0.9961463809013367, avg_entr 0.0018650614656507969
ep13_l3_test_time 1.936629295349121
Test Epoch13 layer4 Acc 0.9784285714285714, AUC 0.9955758452415466, avg_entr 0.0017276238650083542
ep13_l4_test_time 2.3360276222229004
gc 0
Train Epoch14 Acc 0.9918714285714286 (555448/560000), AUC 0.9987859725952148
ep14_train_time 153.76252627372742
Test Epoch14 layer0 Acc 0.9747428571428571, AUC 0.9984355568885803, avg_entr 0.023360738530755043
ep14_l0_test_time 0.6924662590026855
Test Epoch14 layer1 Acc 0.9788857142857142, AUC 0.997105062007904, avg_entr 0.003700441215187311
ep14_l1_test_time 1.111905574798584
Test Epoch14 layer2 Acc 0.9785428571428572, AUC 0.9962655901908875, avg_entr 0.0021428957115858793
ep14_l2_test_time 1.511275053024292
Test Epoch14 layer3 Acc 0.9785428571428572, AUC 0.9959677457809448, avg_entr 0.0017009095754474401
ep14_l3_test_time 1.9161970615386963
Test Epoch14 layer4 Acc 0.9785142857142857, AUC 0.9953774213790894, avg_entr 0.0015990778338164091
ep14_l4_test_time 2.3610432147979736
gc 0
Train Epoch15 Acc 0.991975 (555506/560000), AUC 0.9987862706184387
ep15_train_time 153.7937273979187
Test Epoch15 layer0 Acc 0.9748285714285714, AUC 0.9984311461448669, avg_entr 0.023401997983455658
ep15_l0_test_time 0.6928298473358154
Test Epoch15 layer1 Acc 0.9787142857142858, AUC 0.9971324801445007, avg_entr 0.003603503806516528
ep15_l1_test_time 1.1123020648956299
Test Epoch15 layer2 Acc 0.9785714285714285, AUC 0.9962831139564514, avg_entr 0.002204194897785783
ep15_l2_test_time 1.5362565517425537
Test Epoch15 layer3 Acc 0.9786571428571429, AUC 0.9960704445838928, avg_entr 0.0017990912310779095
ep15_l3_test_time 1.9343972206115723
Test Epoch15 layer4 Acc 0.9786571428571429, AUC 0.9952417016029358, avg_entr 0.0015725826378911734
ep15_l4_test_time 2.3330862522125244
gc 0
Train Epoch16 Acc 0.9922767857142857 (555675/560000), AUC 0.9988027215003967
ep16_train_time 153.7250394821167
Test Epoch16 layer0 Acc 0.9746285714285714, AUC 0.9984248876571655, avg_entr 0.02323705330491066
ep16_l0_test_time 0.7128500938415527
Test Epoch16 layer1 Acc 0.9786285714285714, AUC 0.9970764517784119, avg_entr 0.003666179021820426
ep16_l1_test_time 1.111001968383789
Test Epoch16 layer2 Acc 0.9786, AUC 0.9961881041526794, avg_entr 0.0020558165851980448
ep16_l2_test_time 1.528959035873413
Test Epoch16 layer3 Acc 0.9785428571428572, AUC 0.995822548866272, avg_entr 0.0016791094094514847
ep16_l3_test_time 1.928514003753662
Test Epoch16 layer4 Acc 0.9785428571428572, AUC 0.9951428771018982, avg_entr 0.0014659860171377659
ep16_l4_test_time 2.3525373935699463
gc 0
Train Epoch17 Acc 0.9924107142857143 (555750/560000), AUC 0.9987936019897461
ep17_train_time 153.7424919605255
Test Epoch17 layer0 Acc 0.9747714285714286, AUC 0.9984234571456909, avg_entr 0.02330949902534485
ep17_l0_test_time 0.7208423614501953
Test Epoch17 layer1 Acc 0.9788571428571429, AUC 0.9970881342887878, avg_entr 0.003806982422247529
ep17_l1_test_time 1.1106555461883545
Test Epoch17 layer2 Acc 0.9786857142857143, AUC 0.9962848424911499, avg_entr 0.0022250155452638865
ep17_l2_test_time 1.5280349254608154
Test Epoch17 layer3 Acc 0.9786285714285714, AUC 0.9960843920707703, avg_entr 0.0017273497069254518
ep17_l3_test_time 1.953688383102417
Test Epoch17 layer4 Acc 0.9785428571428572, AUC 0.9954106211662292, avg_entr 0.0015581337502226233
ep17_l4_test_time 2.339664936065674
gc 0
Train Epoch18 Acc 0.9924535714285714 (555774/560000), AUC 0.9987955689430237
ep18_train_time 153.76179099082947
Test Epoch18 layer0 Acc 0.9745142857142857, AUC 0.9984212517738342, avg_entr 0.023123724386096
ep18_l0_test_time 0.6936242580413818
Test Epoch18 layer1 Acc 0.9785428571428572, AUC 0.9970573782920837, avg_entr 0.003792485222220421
ep18_l1_test_time 1.1520814895629883
Test Epoch18 layer2 Acc 0.9783142857142857, AUC 0.9961796402931213, avg_entr 0.002155289286747575
ep18_l2_test_time 1.5304405689239502
Test Epoch18 layer3 Acc 0.9783714285714286, AUC 0.995884120464325, avg_entr 0.0017633915413171053
ep18_l3_test_time 1.9437882900238037
Test Epoch18 layer4 Acc 0.9783714285714286, AUC 0.9952877759933472, avg_entr 0.0015616117743775249
ep18_l4_test_time 2.334364891052246
gc 0
Train Epoch19 Acc 0.9925267857142858 (555815/560000), AUC 0.9988260865211487
ep19_train_time 154.00410532951355
Test Epoch19 layer0 Acc 0.9746285714285714, AUC 0.9984201192855835, avg_entr 0.023202037438750267
ep19_l0_test_time 0.6913378238677979
Test Epoch19 layer1 Acc 0.9788, AUC 0.9970652461051941, avg_entr 0.0037153002340346575
ep19_l1_test_time 1.1605350971221924
Test Epoch19 layer2 Acc 0.9784571428571428, AUC 0.9960665702819824, avg_entr 0.0022011578548699617
ep19_l2_test_time 1.5247845649719238
Test Epoch19 layer3 Acc 0.9783714285714286, AUC 0.9958076477050781, avg_entr 0.0017489951569586992
ep19_l3_test_time 1.934814453125
Test Epoch19 layer4 Acc 0.9782857142857143, AUC 0.9952064156532288, avg_entr 0.0015645488165318966
ep19_l4_test_time 2.4204814434051514
gc 0
Train Epoch20 Acc 0.9926767857142857 (555899/560000), AUC 0.9988246560096741
ep20_train_time 154.46684408187866
Test Epoch20 layer0 Acc 0.9746285714285714, AUC 0.998418390750885, avg_entr 0.023113086819648743
ep20_l0_test_time 0.6975626945495605
Test Epoch20 layer1 Acc 0.9786285714285714, AUC 0.9970136284828186, avg_entr 0.0037998813204467297
ep20_l1_test_time 1.1326851844787598
Test Epoch20 layer2 Acc 0.9784857142857143, AUC 0.9960929155349731, avg_entr 0.0021718156058341265
ep20_l2_test_time 1.5210423469543457
Test Epoch20 layer3 Acc 0.9784857142857143, AUC 0.9957694411277771, avg_entr 0.0017463155090808868
ep20_l3_test_time 1.9262454509735107
Test Epoch20 layer4 Acc 0.9784, AUC 0.99512779712677, avg_entr 0.0015967014478519559
ep20_l4_test_time 2.349440336227417
gc 0
Train Epoch21 Acc 0.9927821428571428 (555958/560000), AUC 0.9987853169441223
ep21_train_time 152.77394437789917
Test Epoch21 layer0 Acc 0.9746571428571429, AUC 0.9984227418899536, avg_entr 0.023116450756788254
ep21_l0_test_time 0.687711238861084
Test Epoch21 layer1 Acc 0.9785714285714285, AUC 0.9970216751098633, avg_entr 0.003809452522546053
ep21_l1_test_time 1.1196362972259521
Test Epoch21 layer2 Acc 0.9785142857142857, AUC 0.9961413145065308, avg_entr 0.0021566865034401417
ep21_l2_test_time 1.519902229309082
Test Epoch21 layer3 Acc 0.9784571428571428, AUC 0.9958482384681702, avg_entr 0.0016988194547593594
ep21_l3_test_time 1.926360845565796
Test Epoch21 layer4 Acc 0.9784, AUC 0.9952017664909363, avg_entr 0.0015206782845780253
ep21_l4_test_time 2.338620901107788
gc 0
Train Epoch22 Acc 0.9927571428571429 (555944/560000), AUC 0.9988083243370056
ep22_train_time 159.69064044952393
Test Epoch22 layer0 Acc 0.9747428571428571, AUC 0.9984185099601746, avg_entr 0.023089950904250145
ep22_l0_test_time 0.6938345432281494
Test Epoch22 layer1 Acc 0.9785428571428572, AUC 0.9969854950904846, avg_entr 0.0037417171988636255
ep22_l1_test_time 1.1264402866363525
Test Epoch22 layer2 Acc 0.9784285714285714, AUC 0.9961156845092773, avg_entr 0.0020547127351164818
ep22_l2_test_time 1.5219793319702148
Test Epoch22 layer3 Acc 0.9784, AUC 0.9957734942436218, avg_entr 0.0015986643265932798
ep22_l3_test_time 1.9283719062805176
Test Epoch22 layer4 Acc 0.9784, AUC 0.9951011538505554, avg_entr 0.001467403955757618
ep22_l4_test_time 2.3629980087280273
gc 0
Train Epoch23 Acc 0.9928017857142857 (555969/560000), AUC 0.998829185962677
ep23_train_time 153.14907383918762
Test Epoch23 layer0 Acc 0.9746857142857143, AUC 0.9984232187271118, avg_entr 0.023249594494700432
ep23_l0_test_time 0.7074611186981201
Test Epoch23 layer1 Acc 0.9787142857142858, AUC 0.9970589876174927, avg_entr 0.00376415834762156
ep23_l1_test_time 1.1566357612609863
Test Epoch23 layer2 Acc 0.9785142857142857, AUC 0.9960651993751526, avg_entr 0.0021638760808855295
ep23_l2_test_time 1.5460281372070312
Test Epoch23 layer3 Acc 0.9785142857142857, AUC 0.9957674145698547, avg_entr 0.0017235708655789495
ep23_l3_test_time 1.9550151824951172
Test Epoch23 layer4 Acc 0.9784571428571428, AUC 0.995128333568573, avg_entr 0.0016055102460086346
ep23_l4_test_time 2.287663221359253
gc 0
Train Epoch24 Acc 0.9928732142857143 (556009/560000), AUC 0.998860239982605
ep24_train_time 152.7232630252838
Test Epoch24 layer0 Acc 0.9746285714285714, AUC 0.9984248876571655, avg_entr 0.02321053482592106
ep24_l0_test_time 0.6864464282989502
Test Epoch24 layer1 Acc 0.9786, AUC 0.9970470070838928, avg_entr 0.003721721936017275
ep24_l1_test_time 1.1543128490447998
Test Epoch24 layer2 Acc 0.9786571428571429, AUC 0.9960819482803345, avg_entr 0.0021305428817868233
ep24_l2_test_time 1.5413031578063965
Test Epoch24 layer3 Acc 0.9785714285714285, AUC 0.9957152009010315, avg_entr 0.0016639061504974961
ep24_l3_test_time 1.9401354789733887
Test Epoch24 layer4 Acc 0.9786285714285714, AUC 0.9949883818626404, avg_entr 0.0015083776088431478
ep24_l4_test_time 2.334679126739502
gc 0
Train Epoch25 Acc 0.9929089285714285 (556029/560000), AUC 0.9988378882408142
ep25_train_time 152.92530822753906
Test Epoch25 layer0 Acc 0.9746571428571429, AUC 0.9984199404716492, avg_entr 0.02316024713218212
ep25_l0_test_time 0.7033381462097168
Test Epoch25 layer1 Acc 0.9787428571428571, AUC 0.9970307350158691, avg_entr 0.003760978812351823
ep25_l1_test_time 1.1321852207183838
Test Epoch25 layer2 Acc 0.9784857142857143, AUC 0.9960693717002869, avg_entr 0.0021470917854458094
ep25_l2_test_time 1.5397424697875977
Test Epoch25 layer3 Acc 0.9783714285714286, AUC 0.9957478642463684, avg_entr 0.0016881467308849096
ep25_l3_test_time 1.9654474258422852
Test Epoch25 layer4 Acc 0.9783714285714286, AUC 0.9950724244117737, avg_entr 0.001565836719237268
ep25_l4_test_time 2.355703830718994
gc 0
Train Epoch26 Acc 0.9929839285714286 (556071/560000), AUC 0.9988037943840027
ep26_train_time 152.78586387634277
Test Epoch26 layer0 Acc 0.9747428571428571, AUC 0.9984230399131775, avg_entr 0.023131316527724266
ep26_l0_test_time 0.6918370723724365
Test Epoch26 layer1 Acc 0.9786, AUC 0.9970288276672363, avg_entr 0.003748561255633831
ep26_l1_test_time 1.164358377456665
Test Epoch26 layer2 Acc 0.9784571428571428, AUC 0.9960501790046692, avg_entr 0.0021815975196659565
ep26_l2_test_time 1.5302433967590332
Test Epoch26 layer3 Acc 0.9784285714285714, AUC 0.9957097172737122, avg_entr 0.001739600906148553
ep26_l3_test_time 1.940352439880371
Test Epoch26 layer4 Acc 0.9784, AUC 0.9949190020561218, avg_entr 0.001607754616998136
ep26_l4_test_time 2.3320152759552
gc 0
Train Epoch27 Acc 0.9929625 (556059/560000), AUC 0.9988343119621277
ep27_train_time 157.84457230567932
Test Epoch27 layer0 Acc 0.9746285714285714, AUC 0.9984211325645447, avg_entr 0.02318309061229229
ep27_l0_test_time 0.8185205459594727
Test Epoch27 layer1 Acc 0.9785714285714285, AUC 0.9970100522041321, avg_entr 0.0037612286396324635
ep27_l1_test_time 1.32621431350708
Test Epoch27 layer2 Acc 0.9784571428571428, AUC 0.9960756897926331, avg_entr 0.0021883221343159676
ep27_l2_test_time 1.699805736541748
Test Epoch27 layer3 Acc 0.9783714285714286, AUC 0.9956927299499512, avg_entr 0.0017278462182730436
ep27_l3_test_time 2.052183151245117
Test Epoch27 layer4 Acc 0.9783428571428572, AUC 0.9949997663497925, avg_entr 0.0015474235406145453
ep27_l4_test_time 2.3152902126312256
gc 0
Train Epoch28 Acc 0.9929642857142857 (556060/560000), AUC 0.9988284111022949
ep28_train_time 154.6873996257782
Test Epoch28 layer0 Acc 0.9747428571428571, AUC 0.9984206557273865, avg_entr 0.023148922249674797
ep28_l0_test_time 0.6954195499420166
Test Epoch28 layer1 Acc 0.9787428571428571, AUC 0.9970269799232483, avg_entr 0.003780924715101719
ep28_l1_test_time 1.2290873527526855
Test Epoch28 layer2 Acc 0.9785142857142857, AUC 0.9960960745811462, avg_entr 0.0021578625310212374
ep28_l2_test_time 1.5295639038085938
Test Epoch28 layer3 Acc 0.9785714285714285, AUC 0.9957331418991089, avg_entr 0.0016418989980593324
ep28_l3_test_time 1.9612574577331543
Test Epoch28 layer4 Acc 0.9784571428571428, AUC 0.995014488697052, avg_entr 0.0015154174761846662
ep28_l4_test_time 2.3304238319396973
gc 0
Train Epoch29 Acc 0.9930625 (556115/560000), AUC 0.9988412261009216
ep29_train_time 152.84356260299683
Test Epoch29 layer0 Acc 0.9746857142857143, AUC 0.998420238494873, avg_entr 0.023130785673856735
ep29_l0_test_time 0.7040071487426758
Test Epoch29 layer1 Acc 0.9787428571428571, AUC 0.997035562992096, avg_entr 0.003730506170541048
ep29_l1_test_time 1.1079485416412354
Test Epoch29 layer2 Acc 0.9784285714285714, AUC 0.9960278868675232, avg_entr 0.002173920627683401
ep29_l2_test_time 1.5322813987731934
Test Epoch29 layer3 Acc 0.9784571428571428, AUC 0.9956461191177368, avg_entr 0.0016326617915183306
ep29_l3_test_time 1.956374168395996
Test Epoch29 layer4 Acc 0.9784285714285714, AUC 0.9949807524681091, avg_entr 0.0015161684714257717
ep29_l4_test_time 2.3170993328094482
gc 0
Train Epoch30 Acc 0.993 (556080/560000), AUC 0.9988483786582947
ep30_train_time 153.07506275177002
Test Epoch30 layer0 Acc 0.9748, AUC 0.998421311378479, avg_entr 0.023170320317149162
ep30_l0_test_time 0.696772575378418
Test Epoch30 layer1 Acc 0.9786571428571429, AUC 0.9970169067382812, avg_entr 0.0037538334727287292
ep30_l1_test_time 1.1192083358764648
Test Epoch30 layer2 Acc 0.9784571428571428, AUC 0.9960336685180664, avg_entr 0.002159276744350791
ep30_l2_test_time 1.5921001434326172
Test Epoch30 layer3 Acc 0.9784857142857143, AUC 0.9956530928611755, avg_entr 0.0016545464750379324
ep30_l3_test_time 1.9597134590148926
Test Epoch30 layer4 Acc 0.9784571428571428, AUC 0.9949489831924438, avg_entr 0.0015302782412618399
ep30_l4_test_time 2.295416831970215
gc 0
Train Epoch31 Acc 0.9930160714285714 (556089/560000), AUC 0.9988390207290649
ep31_train_time 152.8952066898346
Test Epoch31 layer0 Acc 0.9746285714285714, AUC 0.9984196424484253, avg_entr 0.023130355402827263
ep31_l0_test_time 0.6921935081481934
Test Epoch31 layer1 Acc 0.9786857142857143, AUC 0.9970117211341858, avg_entr 0.0037387555930763483
ep31_l1_test_time 1.1157667636871338
Test Epoch31 layer2 Acc 0.9784571428571428, AUC 0.9960346817970276, avg_entr 0.002151022432371974
ep31_l2_test_time 1.631826400756836
Test Epoch31 layer3 Acc 0.9784857142857143, AUC 0.9956516623497009, avg_entr 0.0016553921159356833
ep31_l3_test_time 1.9677917957305908
Test Epoch31 layer4 Acc 0.9784857142857143, AUC 0.9949529767036438, avg_entr 0.001524479826912284
ep31_l4_test_time 2.3244128227233887
gc 0
Train Epoch32 Acc 0.9930410714285715 (556103/560000), AUC 0.9988117218017578
ep32_train_time 152.8942973613739
Test Epoch32 layer0 Acc 0.9746571428571429, AUC 0.9984200596809387, avg_entr 0.023146439343690872
ep32_l0_test_time 0.6976757049560547
Test Epoch32 layer1 Acc 0.9786, AUC 0.9970183968544006, avg_entr 0.003743119537830353
ep32_l1_test_time 1.1014008522033691
Test Epoch32 layer2 Acc 0.9783142857142857, AUC 0.9960227012634277, avg_entr 0.002160599222406745
ep32_l2_test_time 1.5686509609222412
Test Epoch32 layer3 Acc 0.9783142857142857, AUC 0.9956476092338562, avg_entr 0.001657710294239223
ep32_l3_test_time 1.9959795475006104
Test Epoch32 layer4 Acc 0.9783428571428572, AUC 0.9950260519981384, avg_entr 0.0015348440501838923
ep32_l4_test_time 2.3270421028137207
gc 0
Train Epoch33 Acc 0.9930303571428571 (556097/560000), AUC 0.9988192319869995
ep33_train_time 153.16224098205566
Test Epoch33 layer0 Acc 0.9746857142857143, AUC 0.9984199404716492, avg_entr 0.023135581985116005
ep33_l0_test_time 0.7040243148803711
Test Epoch33 layer1 Acc 0.9786285714285714, AUC 0.9970139861106873, avg_entr 0.0037335772067308426
ep33_l1_test_time 1.1004633903503418
Test Epoch33 layer2 Acc 0.9784, AUC 0.9960299730300903, avg_entr 0.002148379571735859
ep33_l2_test_time 1.5193946361541748
Test Epoch33 layer3 Acc 0.9784571428571428, AUC 0.9956508874893188, avg_entr 0.0016440909821540117
ep33_l3_test_time 1.9768261909484863
Test Epoch33 layer4 Acc 0.9784285714285714, AUC 0.9949867129325867, avg_entr 0.001525431638583541
ep33_l4_test_time 2.3427016735076904
gc 0
Train Epoch34 Acc 0.9930392857142857 (556102/560000), AUC 0.998837411403656
ep34_train_time 153.90701413154602
Test Epoch34 layer0 Acc 0.9746857142857143, AUC 0.9984201192855835, avg_entr 0.02312556654214859
ep34_l0_test_time 0.703941822052002
Test Epoch34 layer1 Acc 0.9786, AUC 0.9970236420631409, avg_entr 0.0037458513397723436
ep34_l1_test_time 1.1379735469818115
Test Epoch34 layer2 Acc 0.9783714285714286, AUC 0.9960338473320007, avg_entr 0.0021466014441102743
ep34_l2_test_time 1.5264792442321777
Test Epoch34 layer3 Acc 0.9783714285714286, AUC 0.9956395030021667, avg_entr 0.0016412759432569146
ep34_l3_test_time 1.9454667568206787
Test Epoch34 layer4 Acc 0.9784285714285714, AUC 0.9949933290481567, avg_entr 0.0015037086559459567
ep34_l4_test_time 2.326447010040283
gc 0
Train Epoch35 Acc 0.9931071428571429 (556140/560000), AUC 0.9988361597061157
ep35_train_time 153.57463884353638
Test Epoch35 layer0 Acc 0.9747142857142858, AUC 0.9984189867973328, avg_entr 0.02312285825610161
ep35_l0_test_time 0.6960997581481934
Test Epoch35 layer1 Acc 0.9786285714285714, AUC 0.9970220327377319, avg_entr 0.003736731829121709
ep35_l1_test_time 1.1077523231506348
Test Epoch35 layer2 Acc 0.9785428571428572, AUC 0.9960430860519409, avg_entr 0.00215801945887506
ep35_l2_test_time 1.5239765644073486
Test Epoch35 layer3 Acc 0.9784571428571428, AUC 0.9956420063972473, avg_entr 0.0016381951281800866
ep35_l3_test_time 1.9361567497253418
Test Epoch35 layer4 Acc 0.9785142857142857, AUC 0.994949996471405, avg_entr 0.0014951300108805299
ep35_l4_test_time 2.321477174758911
gc 0
Train Epoch36 Acc 0.9930196428571428 (556091/560000), AUC 0.9988692402839661
ep36_train_time 153.50236701965332
Test Epoch36 layer0 Acc 0.9746571428571429, AUC 0.998420238494873, avg_entr 0.023110849782824516
ep36_l0_test_time 0.7008368968963623
Test Epoch36 layer1 Acc 0.9787142857142858, AUC 0.997013509273529, avg_entr 0.003739353269338608
ep36_l1_test_time 1.1554598808288574
Test Epoch36 layer2 Acc 0.9784, AUC 0.9960313439369202, avg_entr 0.0021483171731233597
ep36_l2_test_time 1.5755579471588135
Test Epoch36 layer3 Acc 0.9784571428571428, AUC 0.9956268668174744, avg_entr 0.0016414435813203454
ep36_l3_test_time 1.9580445289611816
Test Epoch36 layer4 Acc 0.9784, AUC 0.9949661493301392, avg_entr 0.0015168108511716127
ep36_l4_test_time 2.322601318359375
gc 0
Train Epoch37 Acc 0.9930285714285715 (556096/560000), AUC 0.9988228678703308
ep37_train_time 152.01568365097046
Test Epoch37 layer0 Acc 0.9746285714285714, AUC 0.9984193444252014, avg_entr 0.023119080811738968
ep37_l0_test_time 0.6889510154724121
Test Epoch37 layer1 Acc 0.9787142857142858, AUC 0.9970146417617798, avg_entr 0.003739665960893035
ep37_l1_test_time 1.1611237525939941
Test Epoch37 layer2 Acc 0.9783714285714286, AUC 0.996026873588562, avg_entr 0.0021518399007618427
ep37_l2_test_time 1.5253632068634033
Test Epoch37 layer3 Acc 0.9784, AUC 0.9956453442573547, avg_entr 0.0016414510319009423
ep37_l3_test_time 1.9349761009216309
Test Epoch37 layer4 Acc 0.9783714285714286, AUC 0.9949707388877869, avg_entr 0.0015209525590762496
ep37_l4_test_time 2.2823712825775146
gc 0
Train Epoch38 Acc 0.9930660714285714 (556117/560000), AUC 0.9988159537315369
ep38_train_time 153.17599773406982
Test Epoch38 layer0 Acc 0.9746571428571429, AUC 0.9984195828437805, avg_entr 0.023120859637856483
ep38_l0_test_time 0.6893227100372314
Test Epoch38 layer1 Acc 0.9787142857142858, AUC 0.9970102906227112, avg_entr 0.003737484337761998
ep38_l1_test_time 1.1094846725463867
Test Epoch38 layer2 Acc 0.9784, AUC 0.9960350394248962, avg_entr 0.002160019241273403
ep38_l2_test_time 1.5188355445861816
Test Epoch38 layer3 Acc 0.9784, AUC 0.9956332445144653, avg_entr 0.0016470790142193437
ep38_l3_test_time 1.9385995864868164
Test Epoch38 layer4 Acc 0.9784285714285714, AUC 0.9949694871902466, avg_entr 0.0015217316104099154
ep38_l4_test_time 2.313037395477295
gc 0
Train Epoch39 Acc 0.9931071428571429 (556140/560000), AUC 0.9988521933555603
ep39_train_time 153.53361773490906
Test Epoch39 layer0 Acc 0.9746857142857143, AUC 0.998420238494873, avg_entr 0.023126129060983658
ep39_l0_test_time 0.6901066303253174
Test Epoch39 layer1 Acc 0.9786571428571429, AUC 0.9970169067382812, avg_entr 0.0037462960463017225
ep39_l1_test_time 1.1175975799560547
Test Epoch39 layer2 Acc 0.9784, AUC 0.9960383772850037, avg_entr 0.002152531174942851
ep39_l2_test_time 1.5871798992156982
Test Epoch39 layer3 Acc 0.9783142857142857, AUC 0.9956391453742981, avg_entr 0.0016449777176603675
ep39_l3_test_time 1.927682638168335
Test Epoch39 layer4 Acc 0.9783142857142857, AUC 0.9949855208396912, avg_entr 0.0015181847847998142
ep39_l4_test_time 2.342761516571045
gc 0
Train Epoch40 Acc 0.99305 (556108/560000), AUC 0.9988447427749634
ep40_train_time 153.33807277679443
Test Epoch40 layer0 Acc 0.9746571428571429, AUC 0.9984199404716492, avg_entr 0.023116741329431534
ep40_l0_test_time 0.6906800270080566
Test Epoch40 layer1 Acc 0.9787428571428571, AUC 0.9970076680183411, avg_entr 0.0037339809350669384
ep40_l1_test_time 1.1410019397735596
Test Epoch40 layer2 Acc 0.9784, AUC 0.9960339665412903, avg_entr 0.002157646929845214
ep40_l2_test_time 1.5238747596740723
Test Epoch40 layer3 Acc 0.9783142857142857, AUC 0.995638370513916, avg_entr 0.001646265503950417
ep40_l3_test_time 1.9540693759918213
Test Epoch40 layer4 Acc 0.9784, AUC 0.9949900507926941, avg_entr 0.0015184941003099084
ep40_l4_test_time 2.2986230850219727
gc 0
Train Epoch41 Acc 0.9930964285714285 (556134/560000), AUC 0.9988551139831543
ep41_train_time 153.35542678833008
Test Epoch41 layer0 Acc 0.9746857142857143, AUC 0.9984198212623596, avg_entr 0.023122094571590424
ep41_l0_test_time 0.6925501823425293
Test Epoch41 layer1 Acc 0.9787428571428571, AUC 0.9970076680183411, avg_entr 0.0037336251698434353
ep41_l1_test_time 1.120288610458374
Test Epoch41 layer2 Acc 0.9784285714285714, AUC 0.9960370659828186, avg_entr 0.0021589722018688917
ep41_l2_test_time 1.5498886108398438
Test Epoch41 layer3 Acc 0.9783428571428572, AUC 0.9956339597702026, avg_entr 0.00164572533685714
ep41_l3_test_time 1.974421739578247
Test Epoch41 layer4 Acc 0.9784, AUC 0.9949824213981628, avg_entr 0.0015182809438556433
ep41_l4_test_time 2.322843551635742
gc 0
Train Epoch42 Acc 0.9931142857142857 (556144/560000), AUC 0.9988365173339844
ep42_train_time 153.7175223827362
Test Epoch42 layer0 Acc 0.9746571428571429, AUC 0.9984198212623596, avg_entr 0.023131290450692177
ep42_l0_test_time 0.694087028503418
Test Epoch42 layer1 Acc 0.9787428571428571, AUC 0.9970064759254456, avg_entr 0.003735082922503352
ep42_l1_test_time 1.1316719055175781
Test Epoch42 layer2 Acc 0.9784, AUC 0.9960423707962036, avg_entr 0.002156861126422882
ep42_l2_test_time 1.5332095623016357
Test Epoch42 layer3 Acc 0.9783428571428572, AUC 0.9956369400024414, avg_entr 0.001645133481360972
ep42_l3_test_time 1.959961175918579
Test Epoch42 layer4 Acc 0.9784285714285714, AUC 0.9949796795845032, avg_entr 0.001516642514616251
ep42_l4_test_time 2.3505032062530518
gc 0
Train Epoch43 Acc 0.9931160714285714 (556145/560000), AUC 0.9988566040992737
ep43_train_time 153.67767333984375
Test Epoch43 layer0 Acc 0.9746571428571429, AUC 0.9984197616577148, avg_entr 0.023117024451494217
ep43_l0_test_time 0.6919410228729248
Test Epoch43 layer1 Acc 0.9787428571428571, AUC 0.9970076680183411, avg_entr 0.0037345837336033583
ep43_l1_test_time 1.189713478088379
Test Epoch43 layer2 Acc 0.9784285714285714, AUC 0.9960395097732544, avg_entr 0.0021563097834587097
ep43_l2_test_time 1.5483767986297607
Test Epoch43 layer3 Acc 0.9783142857142857, AUC 0.9956305623054504, avg_entr 0.0016416554572060704
ep43_l3_test_time 1.9447946548461914
Test Epoch43 layer4 Acc 0.9784, AUC 0.9949811100959778, avg_entr 0.001511388923972845
ep43_l4_test_time 2.3150219917297363
gc 0
Train Epoch44 Acc 0.9930803571428571 (556125/560000), AUC 0.99884033203125
ep44_train_time 153.65594744682312
Test Epoch44 layer0 Acc 0.9746571428571429, AUC 0.9984197616577148, avg_entr 0.023126007989048958
ep44_l0_test_time 0.7013978958129883
Test Epoch44 layer1 Acc 0.9787428571428571, AUC 0.9970079660415649, avg_entr 0.003736661747097969
ep44_l1_test_time 1.1727943420410156
Test Epoch44 layer2 Acc 0.9784, AUC 0.9960306882858276, avg_entr 0.002155716996639967
ep44_l2_test_time 1.5463838577270508
Test Epoch44 layer3 Acc 0.9783142857142857, AUC 0.9956254959106445, avg_entr 0.0016416412545368075
ep44_l3_test_time 1.9623935222625732
Test Epoch44 layer4 Acc 0.9783714285714286, AUC 0.9949759244918823, avg_entr 0.0015145515790209174
ep44_l4_test_time 2.315631151199341
gc 0
Train Epoch45 Acc 0.9930464285714286 (556106/560000), AUC 0.9988577961921692
ep45_train_time 153.3912889957428
Test Epoch45 layer0 Acc 0.9746857142857143, AUC 0.9984197020530701, avg_entr 0.023127738386392593
ep45_l0_test_time 0.6908457279205322
Test Epoch45 layer1 Acc 0.9787428571428571, AUC 0.9970071911811829, avg_entr 0.0037360996939241886
ep45_l1_test_time 1.1086766719818115
Test Epoch45 layer2 Acc 0.9784, AUC 0.9960320591926575, avg_entr 0.002156500704586506
ep45_l2_test_time 1.550539255142212
Test Epoch45 layer3 Acc 0.9782857142857143, AUC 0.9956294298171997, avg_entr 0.0016419972525909543
ep45_l3_test_time 1.9456677436828613
Test Epoch45 layer4 Acc 0.9783714285714286, AUC 0.9949811697006226, avg_entr 0.0015147920930758119
ep45_l4_test_time 2.285881519317627
gc 0
Train Epoch46 Acc 0.9930535714285714 (556110/560000), AUC 0.9988517761230469
ep46_train_time 153.55973148345947
Test Epoch46 layer0 Acc 0.9746857142857143, AUC 0.9984197616577148, avg_entr 0.02312356047332287
ep46_l0_test_time 0.699073076248169
Test Epoch46 layer1 Acc 0.9786857142857143, AUC 0.9970056414604187, avg_entr 0.0037350712809711695
ep46_l1_test_time 1.148486614227295
Test Epoch46 layer2 Acc 0.9784, AUC 0.996032178401947, avg_entr 0.0021564217749983072
ep46_l2_test_time 1.533463716506958
Test Epoch46 layer3 Acc 0.9782857142857143, AUC 0.9956259727478027, avg_entr 0.0016417927108705044
ep46_l3_test_time 1.9548523426055908
Test Epoch46 layer4 Acc 0.9783714285714286, AUC 0.9949756264686584, avg_entr 0.0015130412066355348
ep46_l4_test_time 2.353381633758545
gc 0
Train Epoch47 Acc 0.9931446428571429 (556161/560000), AUC 0.998844563961029
ep47_train_time 153.52306628227234
Test Epoch47 layer0 Acc 0.9746571428571429, AUC 0.9984197616577148, avg_entr 0.02312425896525383
ep47_l0_test_time 0.6954967975616455
Test Epoch47 layer1 Acc 0.9787142857142858, AUC 0.9970067143440247, avg_entr 0.003735730890184641
ep47_l1_test_time 1.1179192066192627
Test Epoch47 layer2 Acc 0.9784285714285714, AUC 0.9960341453552246, avg_entr 0.0021553633268922567
ep47_l2_test_time 1.5197043418884277
Test Epoch47 layer3 Acc 0.9783142857142857, AUC 0.9956270456314087, avg_entr 0.0016406623180955648
ep47_l3_test_time 1.9583697319030762
Test Epoch47 layer4 Acc 0.9783714285714286, AUC 0.994975745677948, avg_entr 0.0015112890396267176
ep47_l4_test_time 2.2882704734802246
gc 0
Train Epoch48 Acc 0.9931642857142857 (556172/560000), AUC 0.9988564252853394
ep48_train_time 153.38919281959534
Test Epoch48 layer0 Acc 0.9746857142857143, AUC 0.9984197020530701, avg_entr 0.02312474511563778
ep48_l0_test_time 0.6878724098205566
Test Epoch48 layer1 Acc 0.9786857142857143, AUC 0.997005820274353, avg_entr 0.0037351197097450495
ep48_l1_test_time 1.133713960647583
Test Epoch48 layer2 Acc 0.9784285714285714, AUC 0.9960323572158813, avg_entr 0.0021554145496338606
ep48_l2_test_time 1.5264885425567627
Test Epoch48 layer3 Acc 0.9783142857142857, AUC 0.9956234097480774, avg_entr 0.0016401151660829782
ep48_l3_test_time 1.9259922504425049
Test Epoch48 layer4 Acc 0.9783714285714286, AUC 0.9949786067008972, avg_entr 0.0015100152231752872
ep48_l4_test_time 2.299492120742798
gc 0
Train Epoch49 Acc 0.9930660714285714 (556117/560000), AUC 0.998839259147644
ep49_train_time 153.4244303703308
Test Epoch49 layer0 Acc 0.9746857142857143, AUC 0.9984197616577148, avg_entr 0.023125059902668
ep49_l0_test_time 0.687730073928833
Test Epoch49 layer1 Acc 0.9786857142857143, AUC 0.9970059990882874, avg_entr 0.0037356785032898188
ep49_l1_test_time 1.11722731590271
Test Epoch49 layer2 Acc 0.9784285714285714, AUC 0.9960323572158813, avg_entr 0.0021558073349297047
ep49_l2_test_time 1.544527530670166
Test Epoch49 layer3 Acc 0.9782857142857143, AUC 0.9956256151199341, avg_entr 0.0016401474131271243
ep49_l3_test_time 1.988929271697998
Test Epoch49 layer4 Acc 0.9783714285714286, AUC 0.9949773550033569, avg_entr 0.0015099785523489118
ep49_l4_test_time 2.328368902206421
Best AUC 0.9984560012817383
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train+valid_time 8318.811660766602
Start Testing
Load ckpt at ckpt/dbpedia_14_transformeral_l5_pad60//dbpedia_14_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.9742285714285714, AUC 0.9982638955116272, avg_entr 0.023813430219888687
ep49_l0_test_time 0.6896164417266846
Test Epoch49 layer1 Acc 0.9805142857142857, AUC 0.9973267316818237, avg_entr 0.003983336500823498
ep49_l1_test_time 1.1556010246276855
Test Epoch49 layer2 Acc 0.9805142857142857, AUC 0.9970654845237732, avg_entr 0.002563064219430089
ep49_l2_test_time 1.5416412353515625
Test Epoch49 layer3 Acc 0.9805714285714285, AUC 0.9967643022537231, avg_entr 0.002182150725275278
ep49_l3_test_time 1.925168752670288
Test Epoch49 layer4 Acc 0.9804571428571428, AUC 0.9964063763618469, avg_entr 0.0018959350418299437
ep49_l4_test_time 2.351166009902954
