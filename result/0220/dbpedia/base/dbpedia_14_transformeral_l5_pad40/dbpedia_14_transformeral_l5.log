total count words 887881
vocab size 30000
train size 560000, valid size 35000, test size 35000
found 28354 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=14, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=14, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 1792
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 1792
layers.0.ae.h.0.bias 14
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13674862
init_time 54.227707624435425
Start Training
gc 0
Train Epoch0 Acc 0.8324178571428571 (466154/560000), AUC 0.979932963848114
ep0_train_time 120.22405552864075
Test Epoch0 layer0 Acc 0.9734571428571429, AUC 0.9982972145080566, avg_entr 0.080784372985363
ep0_l0_test_time 0.5548968315124512
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad40//dbpedia_14_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9721142857142857, AUC 0.9983701705932617, avg_entr 0.03927416354417801
ep0_l1_test_time 0.8394989967346191
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad40//dbpedia_14_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.9726571428571429, AUC 0.9979414939880371, avg_entr 0.028525592759251595
ep0_l2_test_time 1.1345865726470947
Test Epoch0 layer3 Acc 0.9730571428571428, AUC 0.997823178768158, avg_entr 0.025559140369296074
ep0_l3_test_time 1.4045698642730713
Test Epoch0 layer4 Acc 0.9728, AUC 0.9977926015853882, avg_entr 0.02265516296029091
ep0_l4_test_time 1.6841447353363037
gc 0
Train Epoch1 Acc 0.9793642857142857 (548444/560000), AUC 0.9975925087928772
ep1_train_time 118.23477458953857
Test Epoch1 layer0 Acc 0.9752285714285714, AUC 0.9984108805656433, avg_entr 0.04415878280997276
ep1_l0_test_time 0.557075023651123
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad40//dbpedia_14_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.9781428571428571, AUC 0.998245120048523, avg_entr 0.011167829856276512
ep1_l1_test_time 0.837965726852417
Test Epoch1 layer2 Acc 0.9778857142857142, AUC 0.9980352520942688, avg_entr 0.007874016650021076
ep1_l2_test_time 1.128617286682129
Test Epoch1 layer3 Acc 0.9776571428571429, AUC 0.9982367753982544, avg_entr 0.006413782946765423
ep1_l3_test_time 1.402777910232544
Test Epoch1 layer4 Acc 0.9776285714285714, AUC 0.9978323578834534, avg_entr 0.005663814954459667
ep1_l4_test_time 1.7054426670074463
gc 0
Train Epoch2 Acc 0.9839053571428571 (550987/560000), AUC 0.997978687286377
ep2_train_time 118.83260560035706
Test Epoch2 layer0 Acc 0.9748857142857142, AUC 0.9983847737312317, avg_entr 0.03189718350768089
ep2_l0_test_time 0.5515995025634766
Test Epoch2 layer1 Acc 0.9786857142857143, AUC 0.9980642199516296, avg_entr 0.00651951227337122
ep2_l1_test_time 0.8454763889312744
Test Epoch2 layer2 Acc 0.9787714285714286, AUC 0.9979523420333862, avg_entr 0.004156086128205061
ep2_l2_test_time 1.1317129135131836
Test Epoch2 layer3 Acc 0.9788285714285714, AUC 0.998123824596405, avg_entr 0.00329408748075366
ep2_l3_test_time 1.4703960418701172
Test Epoch2 layer4 Acc 0.9788285714285714, AUC 0.9978795647621155, avg_entr 0.0028871241956949234
ep2_l4_test_time 1.7294156551361084
gc 0
Train Epoch3 Acc 0.9856928571428571 (551988/560000), AUC 0.9982289671897888
ep3_train_time 118.74307584762573
Test Epoch3 layer0 Acc 0.9753142857142857, AUC 0.9984568953514099, avg_entr 0.025722431018948555
ep3_l0_test_time 0.5642251968383789
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad40//dbpedia_14_transformeral_l5.pt  ,ep 3
Test Epoch3 layer1 Acc 0.9790571428571428, AUC 0.9978064298629761, avg_entr 0.005072337109595537
ep3_l1_test_time 0.8418722152709961
Test Epoch3 layer2 Acc 0.9792571428571428, AUC 0.9976205825805664, avg_entr 0.00325970072299242
ep3_l2_test_time 1.1260311603546143
Test Epoch3 layer3 Acc 0.9792571428571428, AUC 0.9976569414138794, avg_entr 0.0026967700105160475
ep3_l3_test_time 1.4074373245239258
Test Epoch3 layer4 Acc 0.9792571428571428, AUC 0.9975826144218445, avg_entr 0.0024374937638640404
ep3_l4_test_time 1.6886658668518066
gc 0
Train Epoch4 Acc 0.9869357142857142 (552684/560000), AUC 0.9983782768249512
ep4_train_time 118.61734676361084
Test Epoch4 layer0 Acc 0.9756285714285714, AUC 0.9984771013259888, avg_entr 0.024257788434624672
ep4_l0_test_time 0.5513298511505127
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad40//dbpedia_14_transformeral_l5.pt  ,ep 4
Test Epoch4 layer1 Acc 0.9793428571428572, AUC 0.9977073073387146, avg_entr 0.004177585244178772
ep4_l1_test_time 0.8312225341796875
Test Epoch4 layer2 Acc 0.9795428571428572, AUC 0.9975630044937134, avg_entr 0.002798246219754219
ep4_l2_test_time 1.1479227542877197
Test Epoch4 layer3 Acc 0.9793428571428572, AUC 0.9975500702857971, avg_entr 0.002372663002461195
ep4_l3_test_time 1.4180517196655273
Test Epoch4 layer4 Acc 0.9793714285714286, AUC 0.9972197413444519, avg_entr 0.0020438646897673607
ep4_l4_test_time 1.6815125942230225
gc 0
Train Epoch5 Acc 0.9879410714285715 (553247/560000), AUC 0.9987088441848755
ep5_train_time 118.41597366333008
Test Epoch5 layer0 Acc 0.9754, AUC 0.9984851479530334, avg_entr 0.02326151542365551
ep5_l0_test_time 0.5447816848754883
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad40//dbpedia_14_transformeral_l5.pt  ,ep 5
Test Epoch5 layer1 Acc 0.9797428571428571, AUC 0.9974832534790039, avg_entr 0.004350944422185421
ep5_l1_test_time 0.8396642208099365
Test Epoch5 layer2 Acc 0.9796571428571429, AUC 0.9974761009216309, avg_entr 0.002995453542098403
ep5_l2_test_time 1.1283588409423828
Test Epoch5 layer3 Acc 0.9796857142857143, AUC 0.9975400567054749, avg_entr 0.0026100114919245243
ep5_l3_test_time 1.4176812171936035
Test Epoch5 layer4 Acc 0.9796571428571429, AUC 0.9974012970924377, avg_entr 0.0021991576068103313
ep5_l4_test_time 1.685225009918213
gc 0
Train Epoch6 Acc 0.9892571428571428 (553984/560000), AUC 0.9989420175552368
ep6_train_time 118.08260750770569
Test Epoch6 layer0 Acc 0.9759714285714286, AUC 0.9984753727912903, avg_entr 0.022879209369421005
ep6_l0_test_time 0.5571126937866211
Test Epoch6 layer1 Acc 0.9796, AUC 0.9973492622375488, avg_entr 0.004202582873404026
ep6_l1_test_time 0.843489408493042
Test Epoch6 layer2 Acc 0.9794, AUC 0.9973798394203186, avg_entr 0.002640137216076255
ep6_l2_test_time 1.1367261409759521
Test Epoch6 layer3 Acc 0.9794285714285714, AUC 0.9973324537277222, avg_entr 0.0022938994225114584
ep6_l3_test_time 1.417435646057129
Test Epoch6 layer4 Acc 0.9794571428571428, AUC 0.9973105788230896, avg_entr 0.002018563449382782
ep6_l4_test_time 1.718876600265503
gc 0
Train Epoch7 Acc 0.9896714285714285 (554216/560000), AUC 0.9989537596702576
ep7_train_time 118.55325841903687
Test Epoch7 layer0 Acc 0.9758, AUC 0.99844890832901, avg_entr 0.023046504706144333
ep7_l0_test_time 0.5443830490112305
Test Epoch7 layer1 Acc 0.9792, AUC 0.9973084330558777, avg_entr 0.003905569901689887
ep7_l1_test_time 0.8420250415802002
Test Epoch7 layer2 Acc 0.9793142857142857, AUC 0.9973704218864441, avg_entr 0.0024573905393481255
ep7_l2_test_time 1.1172780990600586
Test Epoch7 layer3 Acc 0.9794857142857143, AUC 0.9972160458564758, avg_entr 0.0021179430186748505
ep7_l3_test_time 1.4088225364685059
Test Epoch7 layer4 Acc 0.9794857142857143, AUC 0.9970248341560364, avg_entr 0.001855134847573936
ep7_l4_test_time 1.6888787746429443
gc 0
Train Epoch8 Acc 0.9900410714285715 (554423/560000), AUC 0.998984158039093
ep8_train_time 118.72673964500427
Test Epoch8 layer0 Acc 0.9757714285714286, AUC 0.9984744787216187, avg_entr 0.022266695275902748
ep8_l0_test_time 0.5571691989898682
Test Epoch8 layer1 Acc 0.9791428571428571, AUC 0.9973443150520325, avg_entr 0.004193082917481661
ep8_l1_test_time 0.8579885959625244
Test Epoch8 layer2 Acc 0.9787428571428571, AUC 0.9974090456962585, avg_entr 0.002605245914310217
ep8_l2_test_time 1.1277310848236084
Test Epoch8 layer3 Acc 0.9787142857142858, AUC 0.9973238110542297, avg_entr 0.002313113771378994
ep8_l3_test_time 1.4164893627166748
Test Epoch8 layer4 Acc 0.9787714285714286, AUC 0.997270405292511, avg_entr 0.002051976742222905
ep8_l4_test_time 1.6943778991699219
gc 0
Train Epoch9 Acc 0.9904857142857143 (554672/560000), AUC 0.9990288615226746
ep9_train_time 118.48533010482788
Test Epoch9 layer0 Acc 0.9757428571428571, AUC 0.998460590839386, avg_entr 0.02283806912600994
ep9_l0_test_time 0.5566141605377197
Test Epoch9 layer1 Acc 0.9792, AUC 0.9971836805343628, avg_entr 0.0040521081537008286
ep9_l1_test_time 0.8333630561828613
Test Epoch9 layer2 Acc 0.9791714285714286, AUC 0.9972917437553406, avg_entr 0.0024845502339303493
ep9_l2_test_time 1.1315906047821045
Test Epoch9 layer3 Acc 0.9789714285714286, AUC 0.9970027804374695, avg_entr 0.0020526472944766283
ep9_l3_test_time 1.4372916221618652
Test Epoch9 layer4 Acc 0.9791142857142857, AUC 0.9969626069068909, avg_entr 0.0017776329768821597
ep9_l4_test_time 1.7301719188690186
gc 0
Train Epoch10 Acc 0.991175 (555058/560000), AUC 0.9990389943122864
ep10_train_time 118.62958669662476
Test Epoch10 layer0 Acc 0.9758285714285714, AUC 0.9984686970710754, avg_entr 0.02252914011478424
ep10_l0_test_time 0.5420956611633301
Test Epoch10 layer1 Acc 0.9788, AUC 0.9970803260803223, avg_entr 0.0038955083582550287
ep10_l1_test_time 0.8393049240112305
Test Epoch10 layer2 Acc 0.9787714285714286, AUC 0.9971563220024109, avg_entr 0.0025039848405867815
ep10_l2_test_time 1.1295475959777832
Test Epoch10 layer3 Acc 0.9788, AUC 0.9971357583999634, avg_entr 0.0021729711443185806
ep10_l3_test_time 1.4213502407073975
Test Epoch10 layer4 Acc 0.9788857142857142, AUC 0.996980607509613, avg_entr 0.001919233938679099
ep10_l4_test_time 1.6849925518035889
gc 0
Train Epoch11 Acc 0.9914107142857143 (555190/560000), AUC 0.9990482926368713
ep11_train_time 118.5595223903656
Test Epoch11 layer0 Acc 0.9761142857142857, AUC 0.9984508156776428, avg_entr 0.02261735498905182
ep11_l0_test_time 0.5537266731262207
Test Epoch11 layer1 Acc 0.9789428571428571, AUC 0.9971039891242981, avg_entr 0.003944729920476675
ep11_l1_test_time 0.8563838005065918
Test Epoch11 layer2 Acc 0.9787428571428571, AUC 0.9970965385437012, avg_entr 0.002555872779339552
ep11_l2_test_time 1.132922649383545
Test Epoch11 layer3 Acc 0.9787428571428571, AUC 0.997040331363678, avg_entr 0.0021927189081907272
ep11_l3_test_time 1.4396510124206543
Test Epoch11 layer4 Acc 0.9786285714285714, AUC 0.9967171549797058, avg_entr 0.0018635228043422103
ep11_l4_test_time 1.6888236999511719
gc 0
Train Epoch12 Acc 0.9915589285714286 (555273/560000), AUC 0.9990856051445007
ep12_train_time 118.3993992805481
Test Epoch12 layer0 Acc 0.9759714285714286, AUC 0.9984537363052368, avg_entr 0.022444352507591248
ep12_l0_test_time 0.5542788505554199
Test Epoch12 layer1 Acc 0.9790571428571428, AUC 0.9969956278800964, avg_entr 0.003980031702667475
ep12_l1_test_time 0.850696325302124
Test Epoch12 layer2 Acc 0.979, AUC 0.9968819618225098, avg_entr 0.002352367155253887
ep12_l2_test_time 1.1299359798431396
Test Epoch12 layer3 Acc 0.9789428571428571, AUC 0.9966453909873962, avg_entr 0.00191007019020617
ep12_l3_test_time 1.4083571434020996
Test Epoch12 layer4 Acc 0.979, AUC 0.9965447187423706, avg_entr 0.0016634828643873334
ep12_l4_test_time 1.6836528778076172
gc 0
Train Epoch13 Acc 0.9918767857142857 (555451/560000), AUC 0.9990644454956055
ep13_train_time 118.61608028411865
Test Epoch13 layer0 Acc 0.9759714285714286, AUC 0.9984442591667175, avg_entr 0.022500060498714447
ep13_l0_test_time 0.546367883682251
Test Epoch13 layer1 Acc 0.9786857142857143, AUC 0.9969283938407898, avg_entr 0.003925121854990721
ep13_l1_test_time 0.8489189147949219
Test Epoch13 layer2 Acc 0.9787428571428571, AUC 0.9970499277114868, avg_entr 0.002460553077980876
ep13_l2_test_time 1.162684679031372
Test Epoch13 layer3 Acc 0.9787428571428571, AUC 0.997027575969696, avg_entr 0.0019691619090735912
ep13_l3_test_time 1.4048693180084229
Test Epoch13 layer4 Acc 0.9786, AUC 0.9966535568237305, avg_entr 0.0016819116426631808
ep13_l4_test_time 1.6893980503082275
gc 0
Train Epoch14 Acc 0.9921982142857143 (555631/560000), AUC 0.9991095662117004
ep14_train_time 119.21919631958008
Test Epoch14 layer0 Acc 0.9760285714285715, AUC 0.9984573125839233, avg_entr 0.022474169731140137
ep14_l0_test_time 0.5438122749328613
Test Epoch14 layer1 Acc 0.9787714285714286, AUC 0.9969564080238342, avg_entr 0.0039015572983771563
ep14_l1_test_time 0.8462169170379639
Test Epoch14 layer2 Acc 0.9786571428571429, AUC 0.996776282787323, avg_entr 0.002402168931439519
ep14_l2_test_time 1.1388216018676758
Test Epoch14 layer3 Acc 0.9786, AUC 0.9965534806251526, avg_entr 0.001962941139936447
ep14_l3_test_time 1.4195055961608887
Test Epoch14 layer4 Acc 0.9786, AUC 0.9963427782058716, avg_entr 0.0017162002623081207
ep14_l4_test_time 1.6966280937194824
gc 0
Train Epoch15 Acc 0.9922803571428571 (555677/560000), AUC 0.999099612236023
ep15_train_time 118.67853879928589
Test Epoch15 layer0 Acc 0.9759142857142857, AUC 0.9984593987464905, avg_entr 0.022425319999456406
ep15_l0_test_time 0.5514914989471436
Test Epoch15 layer1 Acc 0.9786, AUC 0.9969456791877747, avg_entr 0.003862349083647132
ep15_l1_test_time 0.849311113357544
Test Epoch15 layer2 Acc 0.9784857142857143, AUC 0.9968054890632629, avg_entr 0.002385570202022791
ep15_l2_test_time 1.1506893634796143
Test Epoch15 layer3 Acc 0.9785714285714285, AUC 0.9965869784355164, avg_entr 0.0020137380342930555
ep15_l3_test_time 1.4731872081756592
Test Epoch15 layer4 Acc 0.9785142857142857, AUC 0.9964928030967712, avg_entr 0.001842527068220079
ep15_l4_test_time 1.6919949054718018
gc 0
Train Epoch16 Acc 0.9924160714285715 (555753/560000), AUC 0.9990898966789246
ep16_train_time 119.04860520362854
Test Epoch16 layer0 Acc 0.9758857142857142, AUC 0.9984502792358398, avg_entr 0.022332439199090004
ep16_l0_test_time 0.5648298263549805
Test Epoch16 layer1 Acc 0.9788571428571429, AUC 0.996830403804779, avg_entr 0.0037471666000783443
ep16_l1_test_time 0.8748409748077393
Test Epoch16 layer2 Acc 0.9783714285714286, AUC 0.9968771934509277, avg_entr 0.0023983323480933905
ep16_l2_test_time 1.1275067329406738
Test Epoch16 layer3 Acc 0.9783428571428572, AUC 0.9965925812721252, avg_entr 0.001978852553293109
ep16_l3_test_time 1.4313902854919434
Test Epoch16 layer4 Acc 0.9782857142857143, AUC 0.9964195489883423, avg_entr 0.0017166425241157413
ep16_l4_test_time 1.7097032070159912
gc 0
Train Epoch17 Acc 0.9924946428571428 (555797/560000), AUC 0.9991093277931213
ep17_train_time 118.8351833820343
Test Epoch17 layer0 Acc 0.9758857142857142, AUC 0.9984633326530457, avg_entr 0.022316087037324905
ep17_l0_test_time 0.5477199554443359
Test Epoch17 layer1 Acc 0.9787142857142858, AUC 0.9968310594558716, avg_entr 0.003733083140105009
ep17_l1_test_time 0.8611655235290527
Test Epoch17 layer2 Acc 0.9783714285714286, AUC 0.9968363046646118, avg_entr 0.0022681753616780043
ep17_l2_test_time 1.135937213897705
Test Epoch17 layer3 Acc 0.9784, AUC 0.996849000453949, avg_entr 0.0018311361782252789
ep17_l3_test_time 1.4083092212677002
Test Epoch17 layer4 Acc 0.9783714285714286, AUC 0.9966141581535339, avg_entr 0.0015882053412497044
ep17_l4_test_time 1.6908042430877686
gc 0
Train Epoch18 Acc 0.9927517857142857 (555941/560000), AUC 0.9991095662117004
ep18_train_time 118.40640044212341
Test Epoch18 layer0 Acc 0.9759142857142857, AUC 0.9984546303749084, avg_entr 0.02241748757660389
ep18_l0_test_time 0.544036865234375
Test Epoch18 layer1 Acc 0.9786857142857143, AUC 0.996778666973114, avg_entr 0.0037218532525002956
ep18_l1_test_time 0.8418834209442139
Test Epoch18 layer2 Acc 0.9782285714285714, AUC 0.996703565120697, avg_entr 0.0022750149946659803
ep18_l2_test_time 1.1355223655700684
Test Epoch18 layer3 Acc 0.9781714285714286, AUC 0.996617317199707, avg_entr 0.001860083662904799
ep18_l3_test_time 1.4035968780517578
Test Epoch18 layer4 Acc 0.9782571428571428, AUC 0.9964331388473511, avg_entr 0.0015952482353895903
ep18_l4_test_time 1.6845581531524658
gc 0
Train Epoch19 Acc 0.9927321428571428 (555930/560000), AUC 0.999108612537384
ep19_train_time 118.46895503997803
Test Epoch19 layer0 Acc 0.9758857142857142, AUC 0.9984503388404846, avg_entr 0.022345608100295067
ep19_l0_test_time 0.5634744167327881
Test Epoch19 layer1 Acc 0.9787428571428571, AUC 0.9967537522315979, avg_entr 0.003733049612492323
ep19_l1_test_time 0.8495078086853027
Test Epoch19 layer2 Acc 0.9781714285714286, AUC 0.9966326951980591, avg_entr 0.0022416082210838795
ep19_l2_test_time 1.1293554306030273
Test Epoch19 layer3 Acc 0.9781714285714286, AUC 0.9964037537574768, avg_entr 0.001791785703971982
ep19_l3_test_time 1.4146525859832764
Test Epoch19 layer4 Acc 0.9781428571428571, AUC 0.9963214993476868, avg_entr 0.001516795251518488
ep19_l4_test_time 1.6907567977905273
gc 0
Train Epoch20 Acc 0.9928035714285715 (555970/560000), AUC 0.9991206526756287
ep20_train_time 119.03064775466919
Test Epoch20 layer0 Acc 0.9760571428571428, AUC 0.9984565377235413, avg_entr 0.022368907928466797
ep20_l0_test_time 0.5739314556121826
Test Epoch20 layer1 Acc 0.9785428571428572, AUC 0.9967490434646606, avg_entr 0.003698639804497361
ep20_l1_test_time 0.832587480545044
Test Epoch20 layer2 Acc 0.9781714285714286, AUC 0.9967988729476929, avg_entr 0.0023262212052941322
ep20_l2_test_time 1.1286463737487793
Test Epoch20 layer3 Acc 0.9780857142857143, AUC 0.9966306686401367, avg_entr 0.0018626756500452757
ep20_l3_test_time 1.4108824729919434
Test Epoch20 layer4 Acc 0.9780857142857143, AUC 0.9965015053749084, avg_entr 0.0015789271565154195
ep20_l4_test_time 1.68949556350708
gc 0
Train Epoch21 Acc 0.9928303571428572 (555985/560000), AUC 0.99910968542099
ep21_train_time 118.93370270729065
Test Epoch21 layer0 Acc 0.9759428571428571, AUC 0.9984593987464905, avg_entr 0.022361882030963898
ep21_l0_test_time 0.5437314510345459
Test Epoch21 layer1 Acc 0.9787428571428571, AUC 0.9966986775398254, avg_entr 0.0037853263784199953
ep21_l1_test_time 0.8533642292022705
Test Epoch21 layer2 Acc 0.9781428571428571, AUC 0.9966434836387634, avg_entr 0.002318301470950246
ep21_l2_test_time 1.1348776817321777
Test Epoch21 layer3 Acc 0.9781714285714286, AUC 0.9964583516120911, avg_entr 0.0018709306605160236
ep21_l3_test_time 1.4108152389526367
Test Epoch21 layer4 Acc 0.9780857142857143, AUC 0.9962272644042969, avg_entr 0.0016025463119149208
ep21_l4_test_time 1.7171850204467773
gc 0
Train Epoch22 Acc 0.9929357142857143 (556044/560000), AUC 0.9991143345832825
ep22_train_time 118.85849189758301
Test Epoch22 layer0 Acc 0.9760285714285715, AUC 0.9984517097473145, avg_entr 0.022282246500253677
ep22_l0_test_time 0.5778408050537109
Test Epoch22 layer1 Acc 0.9785428571428572, AUC 0.9967089891433716, avg_entr 0.0037558916956186295
ep22_l1_test_time 0.8442718982696533
Test Epoch22 layer2 Acc 0.978, AUC 0.9966405630111694, avg_entr 0.002335258759558201
ep22_l2_test_time 1.1295957565307617
Test Epoch22 layer3 Acc 0.9779714285714286, AUC 0.9965776801109314, avg_entr 0.0018367946613579988
ep22_l3_test_time 1.4057190418243408
Test Epoch22 layer4 Acc 0.9779428571428571, AUC 0.9962472319602966, avg_entr 0.001604326069355011
ep22_l4_test_time 1.7234745025634766
gc 0
Train Epoch23 Acc 0.9929803571428572 (556069/560000), AUC 0.9991124868392944
ep23_train_time 118.59308791160583
Test Epoch23 layer0 Acc 0.9760857142857143, AUC 0.9984555840492249, avg_entr 0.022322069853544235
ep23_l0_test_time 0.5472311973571777
Test Epoch23 layer1 Acc 0.9788285714285714, AUC 0.9966793060302734, avg_entr 0.003661259775981307
ep23_l1_test_time 0.8321056365966797
Test Epoch23 layer2 Acc 0.9783714285714286, AUC 0.9966745376586914, avg_entr 0.002208978170529008
ep23_l2_test_time 1.1122426986694336
Test Epoch23 layer3 Acc 0.9782, AUC 0.9964724183082581, avg_entr 0.001801602658815682
ep23_l3_test_time 1.4051241874694824
Test Epoch23 layer4 Acc 0.9782571428571428, AUC 0.9962783455848694, avg_entr 0.0015894692623987794
ep23_l4_test_time 1.685159683227539
gc 0
Train Epoch24 Acc 0.9929535714285714 (556054/560000), AUC 0.9991346001625061
ep24_train_time 118.7032265663147
Test Epoch24 layer0 Acc 0.976, AUC 0.9984530806541443, avg_entr 0.022290736436843872
ep24_l0_test_time 0.5528137683868408
Test Epoch24 layer1 Acc 0.9783714285714286, AUC 0.9966965317726135, avg_entr 0.0036629813257604837
ep24_l1_test_time 0.8348374366760254
Test Epoch24 layer2 Acc 0.9781428571428571, AUC 0.9966195225715637, avg_entr 0.00227279681712389
ep24_l2_test_time 1.1309354305267334
Test Epoch24 layer3 Acc 0.9782, AUC 0.9965786933898926, avg_entr 0.0018462208099663258
ep24_l3_test_time 1.4093544483184814
Test Epoch24 layer4 Acc 0.9782, AUC 0.9962385892868042, avg_entr 0.0015875711105763912
ep24_l4_test_time 1.7119524478912354
gc 0
Train Epoch25 Acc 0.9930857142857142 (556128/560000), AUC 0.9991250038146973
ep25_train_time 118.35848736763
Test Epoch25 layer0 Acc 0.9760285714285715, AUC 0.9984513521194458, avg_entr 0.022290252149105072
ep25_l0_test_time 0.5458266735076904
Test Epoch25 layer1 Acc 0.9787428571428571, AUC 0.9966659545898438, avg_entr 0.0036903093568980694
ep25_l1_test_time 0.845015287399292
Test Epoch25 layer2 Acc 0.9781142857142857, AUC 0.996636688709259, avg_entr 0.002286698203533888
ep25_l2_test_time 1.1383123397827148
Test Epoch25 layer3 Acc 0.9780857142857143, AUC 0.9965124726295471, avg_entr 0.0018507430795580149
ep25_l3_test_time 1.54201078414917
Test Epoch25 layer4 Acc 0.9780571428571428, AUC 0.9962432980537415, avg_entr 0.0016376046696677804
ep25_l4_test_time 1.7846989631652832
gc 0
Train Epoch26 Acc 0.9930678571428572 (556118/560000), AUC 0.9991316795349121
ep26_train_time 118.43808269500732
Test Epoch26 layer0 Acc 0.976, AUC 0.9984505772590637, avg_entr 0.02231007255613804
ep26_l0_test_time 0.5459938049316406
Test Epoch26 layer1 Acc 0.9788285714285714, AUC 0.9966619610786438, avg_entr 0.00371388322673738
ep26_l1_test_time 0.8673045635223389
Test Epoch26 layer2 Acc 0.9780285714285715, AUC 0.9966245293617249, avg_entr 0.002316271886229515
ep26_l2_test_time 1.127878189086914
Test Epoch26 layer3 Acc 0.9778571428571429, AUC 0.9964573979377747, avg_entr 0.0019014424178749323
ep26_l3_test_time 1.4106926918029785
Test Epoch26 layer4 Acc 0.9779428571428571, AUC 0.9962610602378845, avg_entr 0.0016495833406224847
ep26_l4_test_time 1.6858952045440674
gc 0
Train Epoch27 Acc 0.9930767857142857 (556123/560000), AUC 0.9991244077682495
ep27_train_time 118.74684166908264
Test Epoch27 layer0 Acc 0.9759714285714286, AUC 0.9984527826309204, avg_entr 0.022284792736172676
ep27_l0_test_time 0.5618374347686768
Test Epoch27 layer1 Acc 0.9787142857142858, AUC 0.9966670274734497, avg_entr 0.0037064761854708195
ep27_l1_test_time 0.8288848400115967
Test Epoch27 layer2 Acc 0.9781714285714286, AUC 0.9966234564781189, avg_entr 0.0023043781984597445
ep27_l2_test_time 1.2058868408203125
Test Epoch27 layer3 Acc 0.9779428571428571, AUC 0.9964666962623596, avg_entr 0.0018686227267608047
ep27_l3_test_time 1.4159467220306396
Test Epoch27 layer4 Acc 0.9780285714285715, AUC 0.9962031245231628, avg_entr 0.0016432193806394935
ep27_l4_test_time 1.7224102020263672
gc 0
Train Epoch28 Acc 0.9931464285714285 (556162/560000), AUC 0.9991353154182434
ep28_train_time 120.11876368522644
Test Epoch28 layer0 Acc 0.9760285714285715, AUC 0.9984530210494995, avg_entr 0.022290293127298355
ep28_l0_test_time 0.6383647918701172
Test Epoch28 layer1 Acc 0.9785428571428572, AUC 0.9966368079185486, avg_entr 0.0037181624211370945
ep28_l1_test_time 0.9092814922332764
Test Epoch28 layer2 Acc 0.978, AUC 0.996636688709259, avg_entr 0.0023134429939091206
ep28_l2_test_time 1.1997637748718262
Test Epoch28 layer3 Acc 0.9779428571428571, AUC 0.9965049624443054, avg_entr 0.0018772640032693744
ep28_l3_test_time 1.4768307209014893
Test Epoch28 layer4 Acc 0.9779428571428571, AUC 0.9962307810783386, avg_entr 0.001663261791691184
ep28_l4_test_time 1.7528870105743408
gc 0
Train Epoch29 Acc 0.9931232142857143 (556149/560000), AUC 0.9991198182106018
ep29_train_time 121.40339684486389
Test Epoch29 layer0 Acc 0.976, AUC 0.9984502792358398, avg_entr 0.02230863831937313
ep29_l0_test_time 0.5435230731964111
Test Epoch29 layer1 Acc 0.9787142857142858, AUC 0.9966684579849243, avg_entr 0.003714742138981819
ep29_l1_test_time 0.858647346496582
Test Epoch29 layer2 Acc 0.9779428571428571, AUC 0.9966144561767578, avg_entr 0.0022562239319086075
ep29_l2_test_time 1.1265759468078613
Test Epoch29 layer3 Acc 0.9780285714285715, AUC 0.9964821934700012, avg_entr 0.0017856620252132416
ep29_l3_test_time 1.437011480331421
Test Epoch29 layer4 Acc 0.9780857142857143, AUC 0.9962447285652161, avg_entr 0.0015831334749236703
ep29_l4_test_time 1.6817920207977295
gc 0
Train Epoch30 Acc 0.9931660714285714 (556173/560000), AUC 0.9991220831871033
ep30_train_time 118.51911616325378
Test Epoch30 layer0 Acc 0.9759714285714286, AUC 0.9984508156776428, avg_entr 0.02231689728796482
ep30_l0_test_time 0.5417070388793945
Test Epoch30 layer1 Acc 0.9785714285714285, AUC 0.9966352581977844, avg_entr 0.0037456892896443605
ep30_l1_test_time 0.8349480628967285
Test Epoch30 layer2 Acc 0.9781142857142857, AUC 0.9966238141059875, avg_entr 0.0023083246778696775
ep30_l2_test_time 1.1539514064788818
Test Epoch30 layer3 Acc 0.9779714285714286, AUC 0.9964823722839355, avg_entr 0.0018455669051036239
ep30_l3_test_time 1.410634994506836
Test Epoch30 layer4 Acc 0.978, AUC 0.9962259531021118, avg_entr 0.0016169473528862
ep30_l4_test_time 1.7219233512878418
gc 0
Train Epoch31 Acc 0.9931678571428572 (556174/560000), AUC 0.9991145730018616
ep31_train_time 118.89208102226257
Test Epoch31 layer0 Acc 0.9759428571428571, AUC 0.9984506368637085, avg_entr 0.022278284654021263
ep31_l0_test_time 0.554497241973877
Test Epoch31 layer1 Acc 0.9785428571428572, AUC 0.9966416358947754, avg_entr 0.003744549583643675
ep31_l1_test_time 0.8481326103210449
Test Epoch31 layer2 Acc 0.978, AUC 0.9966346025466919, avg_entr 0.002299902494996786
ep31_l2_test_time 1.131371259689331
Test Epoch31 layer3 Acc 0.9780571428571428, AUC 0.9964414834976196, avg_entr 0.0018355572829023004
ep31_l3_test_time 1.407210350036621
Test Epoch31 layer4 Acc 0.9780571428571428, AUC 0.996222972869873, avg_entr 0.001584056532010436
ep31_l4_test_time 1.6861350536346436
gc 0
Train Epoch32 Acc 0.9931089285714285 (556141/560000), AUC 0.9991334080696106
ep32_train_time 119.33588862419128
Test Epoch32 layer0 Acc 0.9760857142857143, AUC 0.9984516501426697, avg_entr 0.022289268672466278
ep32_l0_test_time 0.5512466430664062
Test Epoch32 layer1 Acc 0.9785428571428572, AUC 0.9966358542442322, avg_entr 0.003746878821402788
ep32_l1_test_time 0.8362991809844971
Test Epoch32 layer2 Acc 0.9780571428571428, AUC 0.9965819716453552, avg_entr 0.0023239655420184135
ep32_l2_test_time 1.1297457218170166
Test Epoch32 layer3 Acc 0.9778285714285714, AUC 0.9964718222618103, avg_entr 0.0018903093878179789
ep32_l3_test_time 1.4053966999053955
Test Epoch32 layer4 Acc 0.9778857142857142, AUC 0.9962047934532166, avg_entr 0.001651338185183704
ep32_l4_test_time 1.7083721160888672
gc 0
Train Epoch33 Acc 0.9931214285714286 (556148/560000), AUC 0.9991425275802612
ep33_train_time 118.41648983955383
Test Epoch33 layer0 Acc 0.9759714285714286, AUC 0.9984501600265503, avg_entr 0.02229703590273857
ep33_l0_test_time 0.561861515045166
Test Epoch33 layer1 Acc 0.9786, AUC 0.9966362118721008, avg_entr 0.0037405823823064566
ep33_l1_test_time 0.84403395652771
Test Epoch33 layer2 Acc 0.978, AUC 0.9966132044792175, avg_entr 0.0023198011331260204
ep33_l2_test_time 1.1251416206359863
Test Epoch33 layer3 Acc 0.9779714285714286, AUC 0.9964615106582642, avg_entr 0.0018959317822009325
ep33_l3_test_time 1.4018800258636475
Test Epoch33 layer4 Acc 0.9780857142857143, AUC 0.9962040781974792, avg_entr 0.0016677320236340165
ep33_l4_test_time 1.689140796661377
gc 0
Train Epoch34 Acc 0.9931535714285714 (556166/560000), AUC 0.9991297721862793
ep34_train_time 118.9278781414032
Test Epoch34 layer0 Acc 0.9760285714285715, AUC 0.9984513521194458, avg_entr 0.022295260801911354
ep34_l0_test_time 0.5433328151702881
Test Epoch34 layer1 Acc 0.9785714285714285, AUC 0.9966286420822144, avg_entr 0.0037486995570361614
ep34_l1_test_time 0.8396542072296143
Test Epoch34 layer2 Acc 0.9780571428571428, AUC 0.9965882301330566, avg_entr 0.0023200134746730328
ep34_l2_test_time 1.1302845478057861
Test Epoch34 layer3 Acc 0.9779428571428571, AUC 0.9964208602905273, avg_entr 0.0018850049236789346
ep34_l3_test_time 1.4228875637054443
Test Epoch34 layer4 Acc 0.9780571428571428, AUC 0.9961570501327515, avg_entr 0.0016576105263084173
ep34_l4_test_time 1.7320582866668701
gc 0
Train Epoch35 Acc 0.9931714285714286 (556176/560000), AUC 0.9991211295127869
ep35_train_time 118.97775197029114
Test Epoch35 layer0 Acc 0.9760285714285715, AUC 0.9984505772590637, avg_entr 0.022288307547569275
ep35_l0_test_time 0.5646064281463623
Test Epoch35 layer1 Acc 0.9787428571428571, AUC 0.9966313242912292, avg_entr 0.0037151293363422155
ep35_l1_test_time 0.8302321434020996
Test Epoch35 layer2 Acc 0.9780285714285715, AUC 0.996609628200531, avg_entr 0.0023030659649521112
ep35_l2_test_time 1.1194500923156738
Test Epoch35 layer3 Acc 0.9778571428571429, AUC 0.9964457750320435, avg_entr 0.0018799316603690386
ep35_l3_test_time 1.4027631282806396
Test Epoch35 layer4 Acc 0.9779142857142857, AUC 0.9961852431297302, avg_entr 0.0016474227886646986
ep35_l4_test_time 1.6861722469329834
gc 0
Train Epoch36 Acc 0.9931446428571429 (556161/560000), AUC 0.999122142791748
ep36_train_time 118.89090514183044
Test Epoch36 layer0 Acc 0.9760571428571428, AUC 0.9984509348869324, avg_entr 0.02229747176170349
ep36_l0_test_time 0.589057207107544
Test Epoch36 layer1 Acc 0.9786285714285714, AUC 0.9966323971748352, avg_entr 0.003740348620340228
ep36_l1_test_time 0.8888726234436035
Test Epoch36 layer2 Acc 0.9780571428571428, AUC 0.9965961575508118, avg_entr 0.0023111288901418447
ep36_l2_test_time 1.1290919780731201
Test Epoch36 layer3 Acc 0.9779714285714286, AUC 0.9964438676834106, avg_entr 0.0018813657807186246
ep36_l3_test_time 1.408841609954834
Test Epoch36 layer4 Acc 0.9779428571428571, AUC 0.9961965680122375, avg_entr 0.0016502899816259742
ep36_l4_test_time 1.7059884071350098
gc 0
Train Epoch37 Acc 0.9931839285714286 (556183/560000), AUC 0.9991188049316406
ep37_train_time 122.87277460098267
Test Epoch37 layer0 Acc 0.9760285714285715, AUC 0.9984508156776428, avg_entr 0.02229458838701248
ep37_l0_test_time 0.6329772472381592
Test Epoch37 layer1 Acc 0.9786, AUC 0.9966343641281128, avg_entr 0.00373067450709641
ep37_l1_test_time 0.9210894107818604
Test Epoch37 layer2 Acc 0.9781142857142857, AUC 0.9966074824333191, avg_entr 0.002313700271770358
ep37_l2_test_time 1.2094049453735352
Test Epoch37 layer3 Acc 0.9779714285714286, AUC 0.9964460730552673, avg_entr 0.0018724084366112947
ep37_l3_test_time 1.4818024635314941
Test Epoch37 layer4 Acc 0.9779428571428571, AUC 0.9962044954299927, avg_entr 0.0016495331656187773
ep37_l4_test_time 1.7585575580596924
gc 0
Train Epoch38 Acc 0.9931303571428571 (556153/560000), AUC 0.9991552233695984
ep38_train_time 119.41311550140381
Test Epoch38 layer0 Acc 0.9760571428571428, AUC 0.9984512329101562, avg_entr 0.022287143394351006
ep38_l0_test_time 0.5408787727355957
Test Epoch38 layer1 Acc 0.9786285714285714, AUC 0.9966346621513367, avg_entr 0.003736325539648533
ep38_l1_test_time 0.8486895561218262
Test Epoch38 layer2 Acc 0.9780571428571428, AUC 0.9965961575508118, avg_entr 0.002312716096639633
ep38_l2_test_time 1.1472251415252686
Test Epoch38 layer3 Acc 0.9778857142857142, AUC 0.9964286684989929, avg_entr 0.0018691002624109387
ep38_l3_test_time 1.4754905700683594
Test Epoch38 layer4 Acc 0.9779428571428571, AUC 0.9961977601051331, avg_entr 0.001645652111619711
ep38_l4_test_time 1.780513048171997
gc 0
Train Epoch39 Acc 0.9931517857142858 (556165/560000), AUC 0.9991244077682495
ep39_train_time 122.63097333908081
Test Epoch39 layer0 Acc 0.9760285714285715, AUC 0.9984509348869324, avg_entr 0.022295743227005005
ep39_l0_test_time 0.9923875331878662
Test Epoch39 layer1 Acc 0.9786, AUC 0.9966297149658203, avg_entr 0.003737139981240034
ep39_l1_test_time 1.2741987705230713
Test Epoch39 layer2 Acc 0.9781428571428571, AUC 0.9966008067131042, avg_entr 0.0023128176108002663
ep39_l2_test_time 1.2418601512908936
Test Epoch39 layer3 Acc 0.9779428571428571, AUC 0.9964298009872437, avg_entr 0.0018695781473070383
ep39_l3_test_time 1.489823579788208
Test Epoch39 layer4 Acc 0.9779428571428571, AUC 0.9961944222450256, avg_entr 0.0016465520020574331
ep39_l4_test_time 1.7443575859069824
gc 0
Train Epoch40 Acc 0.9932482142857143 (556219/560000), AUC 0.9991338849067688
ep40_train_time 119.02518630027771
Test Epoch40 layer0 Acc 0.9760285714285715, AUC 0.9984508156776428, avg_entr 0.02229532040655613
ep40_l0_test_time 0.5491271018981934
Test Epoch40 layer1 Acc 0.9785714285714285, AUC 0.9966259002685547, avg_entr 0.0037374685052782297
ep40_l1_test_time 0.8338170051574707
Test Epoch40 layer2 Acc 0.9781142857142857, AUC 0.9966076016426086, avg_entr 0.002310961950570345
ep40_l2_test_time 1.1366689205169678
Test Epoch40 layer3 Acc 0.9779142857142857, AUC 0.9964241981506348, avg_entr 0.0018638191977515817
ep40_l3_test_time 1.4207277297973633
Test Epoch40 layer4 Acc 0.9779142857142857, AUC 0.9961983561515808, avg_entr 0.001632899628020823
ep40_l4_test_time 1.697610855102539
gc 0
Train Epoch41 Acc 0.9931982142857143 (556191/560000), AUC 0.9991313219070435
ep41_train_time 119.09417295455933
Test Epoch41 layer0 Acc 0.9760571428571428, AUC 0.9984508156776428, avg_entr 0.02228950895369053
ep41_l0_test_time 0.5482616424560547
Test Epoch41 layer1 Acc 0.9786, AUC 0.9966272115707397, avg_entr 0.003738545114174485
ep41_l1_test_time 0.8727788925170898
Test Epoch41 layer2 Acc 0.9780857142857143, AUC 0.9965977072715759, avg_entr 0.002312232041731477
ep41_l2_test_time 1.140634298324585
Test Epoch41 layer3 Acc 0.9778857142857142, AUC 0.996418297290802, avg_entr 0.0018668476259335876
ep41_l3_test_time 1.405247688293457
Test Epoch41 layer4 Acc 0.9779428571428571, AUC 0.9961918592453003, avg_entr 0.0016383440233767033
ep41_l4_test_time 1.6923022270202637
gc 0
Train Epoch42 Acc 0.9931910714285714 (556187/560000), AUC 0.9991225004196167
ep42_train_time 118.8566529750824
Test Epoch42 layer0 Acc 0.9760285714285715, AUC 0.9984508752822876, avg_entr 0.022293660789728165
ep42_l0_test_time 0.5618243217468262
Test Epoch42 layer1 Acc 0.9786, AUC 0.9966265559196472, avg_entr 0.0037387905176728964
ep42_l1_test_time 0.8353743553161621
Test Epoch42 layer2 Acc 0.9780571428571428, AUC 0.9965928792953491, avg_entr 0.0023114727810025215
ep42_l2_test_time 1.1294264793395996
Test Epoch42 layer3 Acc 0.9779142857142857, AUC 0.9964113235473633, avg_entr 0.0018661950016394258
ep42_l3_test_time 1.4057908058166504
Test Epoch42 layer4 Acc 0.9779714285714286, AUC 0.9961827397346497, avg_entr 0.0016401931643486023
ep42_l4_test_time 1.698777437210083
gc 0
Train Epoch43 Acc 0.9931857142857143 (556184/560000), AUC 0.9991393089294434
ep43_train_time 118.83190727233887
Test Epoch43 layer0 Acc 0.9760571428571428, AUC 0.9984508752822876, avg_entr 0.022290484979748726
ep43_l0_test_time 0.5439333915710449
Test Epoch43 layer1 Acc 0.9786285714285714, AUC 0.9966291785240173, avg_entr 0.0037364810705184937
ep43_l1_test_time 0.8353571891784668
Test Epoch43 layer2 Acc 0.9780571428571428, AUC 0.9965907335281372, avg_entr 0.002309994539245963
ep43_l2_test_time 1.1262974739074707
Test Epoch43 layer3 Acc 0.9779142857142857, AUC 0.9964166879653931, avg_entr 0.0018649952253326774
ep43_l3_test_time 1.4083821773529053
Test Epoch43 layer4 Acc 0.9779714285714286, AUC 0.9961857795715332, avg_entr 0.0016390493838116527
ep43_l4_test_time 1.7155230045318604
gc 0
Train Epoch44 Acc 0.9931910714285714 (556187/560000), AUC 0.999152660369873
ep44_train_time 118.93177008628845
Test Epoch44 layer0 Acc 0.9760285714285715, AUC 0.9984508156776428, avg_entr 0.022287335246801376
ep44_l0_test_time 0.5476939678192139
Test Epoch44 layer1 Acc 0.9786285714285714, AUC 0.9966291189193726, avg_entr 0.003739534644410014
ep44_l1_test_time 0.8330113887786865
Test Epoch44 layer2 Acc 0.9780571428571428, AUC 0.9965885877609253, avg_entr 0.0023101535625755787
ep44_l2_test_time 1.121713399887085
Test Epoch44 layer3 Acc 0.9779428571428571, AUC 0.996422290802002, avg_entr 0.001865520142018795
ep44_l3_test_time 1.4154884815216064
Test Epoch44 layer4 Acc 0.9780285714285715, AUC 0.99619060754776, avg_entr 0.0016422428889200091
ep44_l4_test_time 1.6904621124267578
gc 0
Train Epoch45 Acc 0.9931910714285714 (556187/560000), AUC 0.9991291761398315
ep45_train_time 118.95208358764648
Test Epoch45 layer0 Acc 0.9760571428571428, AUC 0.9984509348869324, avg_entr 0.022288784384727478
ep45_l0_test_time 0.5469338893890381
Test Epoch45 layer1 Acc 0.9786285714285714, AUC 0.9966292381286621, avg_entr 0.003740770509466529
ep45_l1_test_time 0.8276669979095459
Test Epoch45 layer2 Acc 0.9780571428571428, AUC 0.9965886473655701, avg_entr 0.0023110010661184788
ep45_l2_test_time 1.1452751159667969
Test Epoch45 layer3 Acc 0.9779142857142857, AUC 0.9964179396629333, avg_entr 0.001866845297627151
ep45_l3_test_time 1.4433794021606445
Test Epoch45 layer4 Acc 0.9779714285714286, AUC 0.9961848855018616, avg_entr 0.0016431863186880946
ep45_l4_test_time 1.7238030433654785
gc 0
Train Epoch46 Acc 0.9931678571428572 (556174/560000), AUC 0.9991332292556763
ep46_train_time 118.86338663101196
Test Epoch46 layer0 Acc 0.9760285714285715, AUC 0.9984508752822876, avg_entr 0.02228749357163906
ep46_l0_test_time 0.5538609027862549
Test Epoch46 layer1 Acc 0.9786, AUC 0.996627688407898, avg_entr 0.003740255255252123
ep46_l1_test_time 0.8400888442993164
Test Epoch46 layer2 Acc 0.9780571428571428, AUC 0.9965919852256775, avg_entr 0.0023111982736736536
ep46_l2_test_time 1.1480090618133545
Test Epoch46 layer3 Acc 0.9778857142857142, AUC 0.9964064955711365, avg_entr 0.0018684761598706245
ep46_l3_test_time 1.4299321174621582
Test Epoch46 layer4 Acc 0.9779428571428571, AUC 0.9961786270141602, avg_entr 0.0016433269483968616
ep46_l4_test_time 1.7009048461914062
gc 0
Train Epoch47 Acc 0.9931767857142857 (556179/560000), AUC 0.9991448521614075
ep47_train_time 119.06443500518799
Test Epoch47 layer0 Acc 0.9760285714285715, AUC 0.9984509348869324, avg_entr 0.02228805050253868
ep47_l0_test_time 0.5453784465789795
Test Epoch47 layer1 Acc 0.9786285714285714, AUC 0.9966274499893188, avg_entr 0.0037410431541502476
ep47_l1_test_time 0.8460853099822998
Test Epoch47 layer2 Acc 0.9780857142857143, AUC 0.9965932965278625, avg_entr 0.00231026578694582
ep47_l2_test_time 1.1259846687316895
Test Epoch47 layer3 Acc 0.9779142857142857, AUC 0.9964156150817871, avg_entr 0.0018675463506951928
ep47_l3_test_time 1.4290533065795898
Test Epoch47 layer4 Acc 0.9779428571428571, AUC 0.9961860775947571, avg_entr 0.0016426235670223832
ep47_l4_test_time 1.7100200653076172
gc 0
Train Epoch48 Acc 0.9931892857142857 (556186/560000), AUC 0.9991403818130493
ep48_train_time 118.94514417648315
Test Epoch48 layer0 Acc 0.9760571428571428, AUC 0.998450756072998, avg_entr 0.022288702428340912
ep48_l0_test_time 0.5573270320892334
Test Epoch48 layer1 Acc 0.9786285714285714, AUC 0.9966282248497009, avg_entr 0.0037405819166451693
ep48_l1_test_time 0.8355627059936523
Test Epoch48 layer2 Acc 0.9780857142857143, AUC 0.9965915679931641, avg_entr 0.0023099472746253014
ep48_l2_test_time 1.2123806476593018
Test Epoch48 layer3 Acc 0.9779142857142857, AUC 0.9964142441749573, avg_entr 0.0018678167834877968
ep48_l3_test_time 1.411449909210205
Test Epoch48 layer4 Acc 0.9779428571428571, AUC 0.9961885809898376, avg_entr 0.0016424196073785424
ep48_l4_test_time 1.6826601028442383
gc 0
Train Epoch49 Acc 0.9932107142857143 (556198/560000), AUC 0.9991279244422913
ep49_train_time 118.56401109695435
Test Epoch49 layer0 Acc 0.9760285714285715, AUC 0.9984506368637085, avg_entr 0.022287534549832344
ep49_l0_test_time 0.5421092510223389
Test Epoch49 layer1 Acc 0.9786285714285714, AUC 0.9966274499893188, avg_entr 0.0037404836621135473
ep49_l1_test_time 0.8269715309143066
Test Epoch49 layer2 Acc 0.9780857142857143, AUC 0.9965920448303223, avg_entr 0.0023101100232452154
ep49_l2_test_time 1.1414148807525635
Test Epoch49 layer3 Acc 0.9779142857142857, AUC 0.9964128732681274, avg_entr 0.0018676243489608169
ep49_l3_test_time 1.4162092208862305
Test Epoch49 layer4 Acc 0.9779428571428571, AUC 0.9961842894554138, avg_entr 0.0016421397449448705
ep49_l4_test_time 1.6986403465270996
Best AUC 0.9984851479530334
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train+valid_time 6239.0218822956085
Start Testing
Load ckpt at ckpt/dbpedia_14_transformeral_l5_pad40//dbpedia_14_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.9752571428571428, AUC 0.9984368681907654, avg_entr 0.022469904273748398
ep49_l0_test_time 0.548734188079834
Test Epoch49 layer1 Acc 0.9809714285714286, AUC 0.9979403614997864, avg_entr 0.004333612509071827
ep49_l1_test_time 0.839566707611084
Test Epoch49 layer2 Acc 0.9809428571428571, AUC 0.9978071451187134, avg_entr 0.002758231945335865
ep49_l2_test_time 1.1305949687957764
Test Epoch49 layer3 Acc 0.9808285714285714, AUC 0.9978318810462952, avg_entr 0.0023306915536522865
ep49_l3_test_time 1.4297528266906738
Test Epoch49 layer4 Acc 0.9807714285714285, AUC 0.9976224899291992, avg_entr 0.002014999743551016
ep49_l4_test_time 1.7238447666168213
