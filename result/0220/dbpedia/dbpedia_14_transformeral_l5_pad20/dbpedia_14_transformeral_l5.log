total count words 887881
vocab size 30000
found 28354 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=14, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=14, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 1792
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 1792
layers.0.ae.h.0.bias 14
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13674862
init_time 57.50278568267822
Start Training
gc 0
Train Epoch0 Acc 0.8287357142857142 (464092/560000), AUC 0.9790902733802795
ep0_train_time 81.23678207397461
Test Epoch0 layer0 Acc 0.9639142857142857, AUC 0.4985843598842621, avg_entr 0.08049929887056351
ep0_l0_test_time 0.39644694328308105
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad20//dbpedia_14_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9605714285714285, AUC 0.498572438955307, avg_entr 0.04652757570147514
ep0_l1_test_time 0.5528042316436768
Test Epoch0 layer2 Acc 0.9616857142857143, AUC 0.4983508288860321, avg_entr 0.03420110046863556
ep0_l2_test_time 0.7281739711761475
Test Epoch0 layer3 Acc 0.9624, AUC 0.49841490387916565, avg_entr 0.02982001192867756
ep0_l3_test_time 0.8622872829437256
Test Epoch0 layer4 Acc 0.9628857142857142, AUC 0.49832266569137573, avg_entr 0.02816373109817505
ep0_l4_test_time 1.0377063751220703
gc 0
Train Epoch1 Acc 0.9783946428571428 (547901/560000), AUC 0.9973680377006531
ep1_train_time 79.60165858268738
Test Epoch1 layer0 Acc 0.9639428571428571, AUC 0.4986581802368164, avg_entr 0.04412466660141945
ep1_l0_test_time 0.3914659023284912
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad20//dbpedia_14_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.9675142857142857, AUC 0.4983740746974945, avg_entr 0.014725938439369202
ep1_l1_test_time 0.559725284576416
Test Epoch1 layer2 Acc 0.9679714285714286, AUC 0.4981745779514313, avg_entr 0.010147720575332642
ep1_l2_test_time 0.7161173820495605
Test Epoch1 layer3 Acc 0.9684285714285714, AUC 0.49823522567749023, avg_entr 0.008073556236922741
ep1_l3_test_time 0.8836817741394043
Test Epoch1 layer4 Acc 0.9682285714285714, AUC 0.497997909784317, avg_entr 0.00704227713868022
ep1_l4_test_time 1.037766456604004
gc 0
Train Epoch2 Acc 0.9825928571428572 (550252/560000), AUC 0.9977520704269409
ep2_train_time 80.77273058891296
Test Epoch2 layer0 Acc 0.9647142857142857, AUC 0.4986477494239807, avg_entr 0.03133581578731537
ep2_l0_test_time 0.38503193855285645
Test Epoch2 layer1 Acc 0.9698857142857142, AUC 0.4983392357826233, avg_entr 0.009211139753460884
ep2_l1_test_time 0.5513749122619629
Test Epoch2 layer2 Acc 0.9705428571428572, AUC 0.4981701970100403, avg_entr 0.0064043947495520115
ep2_l2_test_time 0.7160301208496094
Test Epoch2 layer3 Acc 0.9704857142857143, AUC 0.4980755150318146, avg_entr 0.0053218649700284
ep2_l3_test_time 0.8655333518981934
Test Epoch2 layer4 Acc 0.9706, AUC 0.4978126585483551, avg_entr 0.004448365420103073
ep2_l4_test_time 1.0594627857208252
gc 0
Train Epoch3 Acc 0.9847303571428572 (551449/560000), AUC 0.9979422688484192
ep3_train_time 80.38007736206055
Test Epoch3 layer0 Acc 0.9642857142857143, AUC 0.4986959397792816, avg_entr 0.02614663541316986
ep3_l0_test_time 0.3918735980987549
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad20//dbpedia_14_transformeral_l5.pt  ,ep 3
Test Epoch3 layer1 Acc 0.9698, AUC 0.4982406795024872, avg_entr 0.0071987491101026535
ep3_l1_test_time 0.5482213497161865
Test Epoch3 layer2 Acc 0.9703428571428572, AUC 0.49810001254081726, avg_entr 0.004839280620217323
ep3_l2_test_time 0.7027590274810791
Test Epoch3 layer3 Acc 0.9700571428571428, AUC 0.4979160726070404, avg_entr 0.004149678163230419
ep3_l3_test_time 0.8657150268554688
Test Epoch3 layer4 Acc 0.9699142857142857, AUC 0.4973544180393219, avg_entr 0.0036436275113373995
ep3_l4_test_time 1.0367529392242432
gc 0
Train Epoch4 Acc 0.9861714285714286 (552256/560000), AUC 0.9980205297470093
ep4_train_time 79.82074666023254
Test Epoch4 layer0 Acc 0.9642571428571428, AUC 0.49866703152656555, avg_entr 0.023697828873991966
ep4_l0_test_time 0.38443565368652344
Test Epoch4 layer1 Acc 0.9712285714285714, AUC 0.49812671542167664, avg_entr 0.006228935439139605
ep4_l1_test_time 0.5504505634307861
Test Epoch4 layer2 Acc 0.9715428571428572, AUC 0.49790439009666443, avg_entr 0.003963921219110489
ep4_l2_test_time 0.7009124755859375
Test Epoch4 layer3 Acc 0.9714571428571429, AUC 0.4977055490016937, avg_entr 0.0035162989515811205
ep4_l3_test_time 0.8588850498199463
Test Epoch4 layer4 Acc 0.9716285714285714, AUC 0.49724406003952026, avg_entr 0.0031170768197625875
ep4_l4_test_time 1.03291654586792
gc 0
Train Epoch5 Acc 0.9874035714285714 (552946/560000), AUC 0.9983658790588379
ep5_train_time 80.12092351913452
Test Epoch5 layer0 Acc 0.9646, AUC 0.4987141788005829, avg_entr 0.02245240844786167
ep5_l0_test_time 0.38628697395324707
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad20//dbpedia_14_transformeral_l5.pt  ,ep 5
Test Epoch5 layer1 Acc 0.9721428571428572, AUC 0.4981934130191803, avg_entr 0.005989094730466604
ep5_l1_test_time 0.5500433444976807
Test Epoch5 layer2 Acc 0.9725142857142857, AUC 0.498036652803421, avg_entr 0.0038149941246956587
ep5_l2_test_time 0.709181547164917
Test Epoch5 layer3 Acc 0.9724571428571429, AUC 0.49786466360092163, avg_entr 0.0032643291633576155
ep5_l3_test_time 0.8692615032196045
Test Epoch5 layer4 Acc 0.9726571428571429, AUC 0.49764320254325867, avg_entr 0.002796453656628728
ep5_l4_test_time 1.0126099586486816
gc 0
Train Epoch6 Acc 0.9879767857142857 (553267/560000), AUC 0.9985173344612122
ep6_train_time 79.8517394065857
Test Epoch6 layer0 Acc 0.9644571428571429, AUC 0.49871858954429626, avg_entr 0.022609876468777657
ep6_l0_test_time 0.391326904296875
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad20//dbpedia_14_transformeral_l5.pt  ,ep 6
Test Epoch6 layer1 Acc 0.9717714285714286, AUC 0.4979574382305145, avg_entr 0.0056364224292337894
ep6_l1_test_time 0.5544021129608154
Test Epoch6 layer2 Acc 0.972, AUC 0.49771833419799805, avg_entr 0.0036380982492119074
ep6_l2_test_time 0.7176077365875244
Test Epoch6 layer3 Acc 0.9719142857142857, AUC 0.4974363148212433, avg_entr 0.003161188680678606
ep6_l3_test_time 0.8551590442657471
Test Epoch6 layer4 Acc 0.9719714285714286, AUC 0.49693164229393005, avg_entr 0.0027686399407684803
ep6_l4_test_time 1.0467183589935303
gc 0
Train Epoch7 Acc 0.9885982142857143 (553615/560000), AUC 0.9986110329627991
ep7_train_time 79.53461742401123
Test Epoch7 layer0 Acc 0.9644, AUC 0.4986998736858368, avg_entr 0.022297928109765053
ep7_l0_test_time 0.3932991027832031
Test Epoch7 layer1 Acc 0.9719428571428571, AUC 0.4979904592037201, avg_entr 0.005526718217879534
ep7_l1_test_time 0.5676901340484619
Test Epoch7 layer2 Acc 0.9724285714285714, AUC 0.4974420368671417, avg_entr 0.003618764691054821
ep7_l2_test_time 0.7108466625213623
Test Epoch7 layer3 Acc 0.9722, AUC 0.497332900762558, avg_entr 0.0030620021279901266
ep7_l3_test_time 0.8702635765075684
Test Epoch7 layer4 Acc 0.9722571428571428, AUC 0.4969085156917572, avg_entr 0.0025913205463439226
ep7_l4_test_time 1.059051513671875
gc 0
Train Epoch8 Acc 0.9889892857142857 (553834/560000), AUC 0.9986338019371033
ep8_train_time 79.51447701454163
Test Epoch8 layer0 Acc 0.9647142857142857, AUC 0.4987088143825531, avg_entr 0.021790238097310066
ep8_l0_test_time 0.3853743076324463
Test Epoch8 layer1 Acc 0.9713714285714286, AUC 0.49797770380973816, avg_entr 0.005439272616058588
ep8_l1_test_time 0.5530169010162354
Test Epoch8 layer2 Acc 0.9717714285714286, AUC 0.497789204120636, avg_entr 0.003709625219926238
ep8_l2_test_time 0.702756404876709
Test Epoch8 layer3 Acc 0.9716857142857143, AUC 0.49788782000541687, avg_entr 0.0032907461281865835
ep8_l3_test_time 0.8929891586303711
Test Epoch8 layer4 Acc 0.9717714285714286, AUC 0.49745383858680725, avg_entr 0.0028079061303287745
ep8_l4_test_time 1.0217630863189697
gc 0
Train Epoch9 Acc 0.9894982142857143 (554119/560000), AUC 0.9986748695373535
ep9_train_time 79.61817359924316
Test Epoch9 layer0 Acc 0.9644, AUC 0.4987311363220215, avg_entr 0.021810315549373627
ep9_l0_test_time 0.3843545913696289
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad20//dbpedia_14_transformeral_l5.pt  ,ep 9
Test Epoch9 layer1 Acc 0.9717428571428571, AUC 0.49785563349723816, avg_entr 0.005250483751296997
ep9_l1_test_time 0.5501174926757812
Test Epoch9 layer2 Acc 0.972, AUC 0.4975859820842743, avg_entr 0.0034441885072737932
ep9_l2_test_time 0.7062277793884277
Test Epoch9 layer3 Acc 0.9718285714285714, AUC 0.49756699800491333, avg_entr 0.0028731697238981724
ep9_l3_test_time 0.8598370552062988
Test Epoch9 layer4 Acc 0.9719428571428571, AUC 0.4970703125, avg_entr 0.0024426328018307686
ep9_l4_test_time 1.1030304431915283
gc 0
Train Epoch10 Acc 0.9902982142857143 (554567/560000), AUC 0.9987289309501648
ep10_train_time 79.58041477203369
Test Epoch10 layer0 Acc 0.9647142857142857, AUC 0.4987160265445709, avg_entr 0.021351033821702003
ep10_l0_test_time 0.3857109546661377
Test Epoch10 layer1 Acc 0.9712571428571428, AUC 0.49767017364501953, avg_entr 0.005498457700014114
ep10_l1_test_time 0.5496795177459717
Test Epoch10 layer2 Acc 0.9714857142857143, AUC 0.49750447273254395, avg_entr 0.0035262969322502613
ep10_l2_test_time 0.7009716033935547
Test Epoch10 layer3 Acc 0.9713428571428572, AUC 0.497384637594223, avg_entr 0.002950390102341771
ep10_l3_test_time 0.8621110916137695
Test Epoch10 layer4 Acc 0.9714285714285714, AUC 0.4966573119163513, avg_entr 0.0025140440557152033
ep10_l4_test_time 1.0212597846984863
gc 0
Train Epoch11 Acc 0.9905428571428572 (554704/560000), AUC 0.9987365007400513
ep11_train_time 79.50852537155151
Test Epoch11 layer0 Acc 0.9647428571428571, AUC 0.4987194240093231, avg_entr 0.02173059806227684
ep11_l0_test_time 0.38523221015930176
Test Epoch11 layer1 Acc 0.9707714285714286, AUC 0.49769705533981323, avg_entr 0.00543542206287384
ep11_l1_test_time 0.5575604438781738
Test Epoch11 layer2 Acc 0.9712571428571428, AUC 0.49745306372642517, avg_entr 0.003326971549540758
ep11_l2_test_time 0.7049744129180908
Test Epoch11 layer3 Acc 0.9711142857142857, AUC 0.49740511178970337, avg_entr 0.0028071198612451553
ep11_l3_test_time 0.9181208610534668
Test Epoch11 layer4 Acc 0.9712285714285714, AUC 0.49650734663009644, avg_entr 0.002442611614242196
ep11_l4_test_time 1.020695686340332
gc 0
Train Epoch12 Acc 0.9907839285714286 (554839/560000), AUC 0.9987614750862122
ep12_train_time 79.63726663589478
Test Epoch12 layer0 Acc 0.9647714285714286, AUC 0.4987161159515381, avg_entr 0.021337416023015976
ep12_l0_test_time 0.38738369941711426
Test Epoch12 layer1 Acc 0.9707714285714286, AUC 0.4976666271686554, avg_entr 0.005193713586777449
ep12_l1_test_time 0.5544390678405762
Test Epoch12 layer2 Acc 0.9713142857142857, AUC 0.4974178671836853, avg_entr 0.0034399875439703465
ep12_l2_test_time 0.7072231769561768
Test Epoch12 layer3 Acc 0.971, AUC 0.49737730622291565, avg_entr 0.0028596017509698868
ep12_l3_test_time 0.8655812740325928
Test Epoch12 layer4 Acc 0.9711714285714286, AUC 0.4965892732143402, avg_entr 0.002503642113879323
ep12_l4_test_time 1.0694148540496826
gc 0
Train Epoch13 Acc 0.9911142857142857 (555024/560000), AUC 0.9987310171127319
ep13_train_time 80.02911233901978
Test Epoch13 layer0 Acc 0.9652857142857143, AUC 0.4987165033817291, avg_entr 0.02147381752729416
ep13_l0_test_time 0.38764333724975586
Test Epoch13 layer1 Acc 0.9707428571428571, AUC 0.49763235449790955, avg_entr 0.005066865589469671
ep13_l1_test_time 0.5455684661865234
Test Epoch13 layer2 Acc 0.9714571428571429, AUC 0.4973006844520569, avg_entr 0.003325261175632477
ep13_l2_test_time 0.6987819671630859
Test Epoch13 layer3 Acc 0.9714285714285714, AUC 0.49727821350097656, avg_entr 0.00284438650123775
ep13_l3_test_time 0.8661613464355469
Test Epoch13 layer4 Acc 0.9714285714285714, AUC 0.4965311586856842, avg_entr 0.002466112608090043
ep13_l4_test_time 1.0537352561950684
gc 0
Train Epoch14 Acc 0.9915196428571429 (555251/560000), AUC 0.9987982511520386
ep14_train_time 79.80410122871399
Test Epoch14 layer0 Acc 0.9653142857142857, AUC 0.498722642660141, avg_entr 0.021473664790391922
ep14_l0_test_time 0.39128589630126953
Test Epoch14 layer1 Acc 0.9711714285714286, AUC 0.49760904908180237, avg_entr 0.005152796395123005
ep14_l1_test_time 0.5499885082244873
Test Epoch14 layer2 Acc 0.9716571428571429, AUC 0.49722570180892944, avg_entr 0.0032515251077711582
ep14_l2_test_time 0.7042810916900635
Test Epoch14 layer3 Acc 0.9715714285714285, AUC 0.49728110432624817, avg_entr 0.002698848256841302
ep14_l3_test_time 0.8540866374969482
Test Epoch14 layer4 Acc 0.9715428571428572, AUC 0.49657127261161804, avg_entr 0.0023308845702558756
ep14_l4_test_time 1.0208463668823242
gc 0
Train Epoch15 Acc 0.9916857142857143 (555344/560000), AUC 0.9988288283348083
ep15_train_time 79.88789129257202
Test Epoch15 layer0 Acc 0.9654571428571429, AUC 0.4987170100212097, avg_entr 0.02141142264008522
ep15_l0_test_time 0.38959622383117676
Test Epoch15 layer1 Acc 0.9707428571428571, AUC 0.497486412525177, avg_entr 0.005154783371835947
ep15_l1_test_time 0.5536623001098633
Test Epoch15 layer2 Acc 0.9712571428571428, AUC 0.4972112476825714, avg_entr 0.0034098217729479074
ep15_l2_test_time 0.7139601707458496
Test Epoch15 layer3 Acc 0.9711428571428572, AUC 0.49714526534080505, avg_entr 0.0029006667900830507
ep15_l3_test_time 0.8556435108184814
Test Epoch15 layer4 Acc 0.9712, AUC 0.49636712670326233, avg_entr 0.0025801360607147217
ep15_l4_test_time 1.0205719470977783
gc 0
Train Epoch16 Acc 0.991925 (555478/560000), AUC 0.9988242983818054
ep16_train_time 79.63760375976562
Test Epoch16 layer0 Acc 0.9654285714285714, AUC 0.4987225830554962, avg_entr 0.02133611962199211
ep16_l0_test_time 0.38691091537475586
Test Epoch16 layer1 Acc 0.9706, AUC 0.4973906874656677, avg_entr 0.005011501722037792
ep16_l1_test_time 0.5464167594909668
Test Epoch16 layer2 Acc 0.9709714285714286, AUC 0.49710842967033386, avg_entr 0.003161592409014702
ep16_l2_test_time 0.6991498470306396
Test Epoch16 layer3 Acc 0.9708857142857142, AUC 0.4970742166042328, avg_entr 0.002655408112332225
ep16_l3_test_time 0.8690512180328369
Test Epoch16 layer4 Acc 0.9708285714285714, AUC 0.49621137976646423, avg_entr 0.0023661137092858553
ep16_l4_test_time 1.030435562133789
gc 0
Train Epoch17 Acc 0.9919428571428571 (555488/560000), AUC 0.9988265633583069
ep17_train_time 79.57811784744263
Test Epoch17 layer0 Acc 0.9653142857142857, AUC 0.4987304210662842, avg_entr 0.02123582921922207
ep17_l0_test_time 0.38587141036987305
Test Epoch17 layer1 Acc 0.9710571428571428, AUC 0.4974671006202698, avg_entr 0.0051264893263578415
ep17_l1_test_time 0.5520477294921875
Test Epoch17 layer2 Acc 0.9714571428571429, AUC 0.49707794189453125, avg_entr 0.003290208289399743
ep17_l2_test_time 0.7083663940429688
Test Epoch17 layer3 Acc 0.9713428571428572, AUC 0.49715784192085266, avg_entr 0.002793398220092058
ep17_l3_test_time 0.8692209720611572
Test Epoch17 layer4 Acc 0.9714571428571429, AUC 0.49644312262535095, avg_entr 0.0024835183285176754
ep17_l4_test_time 1.0621511936187744
gc 0
Train Epoch18 Acc 0.9922107142857143 (555638/560000), AUC 0.9988342523574829
ep18_train_time 80.13162660598755
Test Epoch18 layer0 Acc 0.9652571428571428, AUC 0.4987184405326843, avg_entr 0.02131984382867813
ep18_l0_test_time 0.38781309127807617
Test Epoch18 layer1 Acc 0.9709142857142857, AUC 0.4974671006202698, avg_entr 0.00517340237274766
ep18_l1_test_time 0.5512380599975586
Test Epoch18 layer2 Acc 0.9712571428571428, AUC 0.4970254898071289, avg_entr 0.0032518645748496056
ep18_l2_test_time 0.7144434452056885
Test Epoch18 layer3 Acc 0.971, AUC 0.49700090289115906, avg_entr 0.0027728891000151634
ep18_l3_test_time 0.864901065826416
Test Epoch18 layer4 Acc 0.9710285714285715, AUC 0.49627867341041565, avg_entr 0.002536509884521365
ep18_l4_test_time 1.0315711498260498
gc 0
Train Epoch19 Acc 0.9921964285714285 (555630/560000), AUC 0.998824417591095
ep19_train_time 79.83603620529175
Test Epoch19 layer0 Acc 0.9654285714285714, AUC 0.49872323870658875, avg_entr 0.02110070176422596
ep19_l0_test_time 0.38944125175476074
Test Epoch19 layer1 Acc 0.9706285714285714, AUC 0.4974142014980316, avg_entr 0.005126635078340769
ep19_l1_test_time 0.5536468029022217
Test Epoch19 layer2 Acc 0.9707142857142858, AUC 0.4969792366027832, avg_entr 0.0031401088926941156
ep19_l2_test_time 0.6978230476379395
Test Epoch19 layer3 Acc 0.9705142857142857, AUC 0.49694687128067017, avg_entr 0.002581358887255192
ep19_l3_test_time 0.856687068939209
Test Epoch19 layer4 Acc 0.9706, AUC 0.4961770176887512, avg_entr 0.0022859666496515274
ep19_l4_test_time 1.0203628540039062
gc 0
Train Epoch20 Acc 0.9923196428571428 (555699/560000), AUC 0.9988449215888977
ep20_train_time 80.42816758155823
Test Epoch20 layer0 Acc 0.9650857142857143, AUC 0.49872130155563354, avg_entr 0.02142394334077835
ep20_l0_test_time 0.3857560157775879
Test Epoch20 layer1 Acc 0.9706, AUC 0.49739131331443787, avg_entr 0.005032970104366541
ep20_l1_test_time 0.5472643375396729
Test Epoch20 layer2 Acc 0.9706, AUC 0.496995210647583, avg_entr 0.003112326841801405
ep20_l2_test_time 0.7044389247894287
Test Epoch20 layer3 Acc 0.9704857142857143, AUC 0.4969750940799713, avg_entr 0.0026199943386018276
ep20_l3_test_time 0.8723828792572021
Test Epoch20 layer4 Acc 0.9703428571428572, AUC 0.496219664812088, avg_entr 0.00238925963640213
ep20_l4_test_time 1.0267291069030762
gc 0
Train Epoch21 Acc 0.9924089285714286 (555749/560000), AUC 0.9988454580307007
ep21_train_time 79.45615005493164
Test Epoch21 layer0 Acc 0.9653142857142857, AUC 0.49872690439224243, avg_entr 0.021281400695443153
ep21_l0_test_time 0.39497852325439453
Test Epoch21 layer1 Acc 0.9705428571428572, AUC 0.497409850358963, avg_entr 0.005016574636101723
ep21_l1_test_time 0.5485663414001465
Test Epoch21 layer2 Acc 0.9712285714285714, AUC 0.49699297547340393, avg_entr 0.003164267400279641
ep21_l2_test_time 0.7080745697021484
Test Epoch21 layer3 Acc 0.9712, AUC 0.49703890085220337, avg_entr 0.002655011834576726
ep21_l3_test_time 0.8638181686401367
Test Epoch21 layer4 Acc 0.9713142857142857, AUC 0.4961569309234619, avg_entr 0.0023859923239797354
ep21_l4_test_time 1.0248370170593262
gc 0
Train Epoch22 Acc 0.992525 (555814/560000), AUC 0.998879611492157
ep22_train_time 80.11514711380005
Test Epoch22 layer0 Acc 0.9651428571428572, AUC 0.49871811270713806, avg_entr 0.02144385129213333
ep22_l0_test_time 0.39980268478393555
Test Epoch22 layer1 Acc 0.9704, AUC 0.497342586517334, avg_entr 0.005061900243163109
ep22_l1_test_time 0.5537745952606201
Test Epoch22 layer2 Acc 0.9706285714285714, AUC 0.49686315655708313, avg_entr 0.003154434496536851
ep22_l2_test_time 0.7088522911071777
Test Epoch22 layer3 Acc 0.9704857142857143, AUC 0.49694809317588806, avg_entr 0.0026389705017209053
ep22_l3_test_time 0.8550822734832764
Test Epoch22 layer4 Acc 0.9706571428571429, AUC 0.4960145354270935, avg_entr 0.0023513007909059525
ep22_l4_test_time 1.0098042488098145
gc 0
Train Epoch23 Acc 0.9925857142857143 (555848/560000), AUC 0.9988671541213989
ep23_train_time 80.28277325630188
Test Epoch23 layer0 Acc 0.9651714285714286, AUC 0.49872252345085144, avg_entr 0.02123713679611683
ep23_l0_test_time 0.3900003433227539
Test Epoch23 layer1 Acc 0.9705714285714285, AUC 0.4973641335964203, avg_entr 0.005108253564685583
ep23_l1_test_time 0.5519680976867676
Test Epoch23 layer2 Acc 0.9707428571428571, AUC 0.49693727493286133, avg_entr 0.0030505654867738485
ep23_l2_test_time 0.7078464031219482
Test Epoch23 layer3 Acc 0.9706857142857143, AUC 0.49691030383110046, avg_entr 0.002514822408556938
ep23_l3_test_time 0.8623559474945068
Test Epoch23 layer4 Acc 0.9708, AUC 0.49606043100357056, avg_entr 0.0023195166140794754
ep23_l4_test_time 1.0423448085784912
gc 0
Train Epoch24 Acc 0.9925910714285714 (555851/560000), AUC 0.9988340139389038
ep24_train_time 80.40746665000916
Test Epoch24 layer0 Acc 0.9652571428571428, AUC 0.4987223446369171, avg_entr 0.021265758201479912
ep24_l0_test_time 0.3896918296813965
Test Epoch24 layer1 Acc 0.9707142857142858, AUC 0.49735385179519653, avg_entr 0.005029877182096243
ep24_l1_test_time 0.5522892475128174
Test Epoch24 layer2 Acc 0.9707142857142858, AUC 0.49689796566963196, avg_entr 0.0030986168421804905
ep24_l2_test_time 0.7066256999969482
Test Epoch24 layer3 Acc 0.9706, AUC 0.4969275891780853, avg_entr 0.0025926355738192797
ep24_l3_test_time 0.8646399974822998
Test Epoch24 layer4 Acc 0.9707142857142858, AUC 0.4960628151893616, avg_entr 0.0023106448352336884
ep24_l4_test_time 1.012000322341919
gc 0
Train Epoch25 Acc 0.9926464285714286 (555882/560000), AUC 0.9988474249839783
ep25_train_time 79.86173224449158
Test Epoch25 layer0 Acc 0.9650285714285715, AUC 0.49871930480003357, avg_entr 0.02131998911499977
ep25_l0_test_time 0.39502716064453125
Test Epoch25 layer1 Acc 0.9704857142857143, AUC 0.4973641037940979, avg_entr 0.005067688878625631
ep25_l1_test_time 0.5510425567626953
Test Epoch25 layer2 Acc 0.9706285714285714, AUC 0.4968978464603424, avg_entr 0.003126035910099745
ep25_l2_test_time 0.7057652473449707
Test Epoch25 layer3 Acc 0.9706285714285714, AUC 0.4969150125980377, avg_entr 0.002570526674389839
ep25_l3_test_time 0.8694560527801514
Test Epoch25 layer4 Acc 0.9705714285714285, AUC 0.4960215091705322, avg_entr 0.0023256835993379354
ep25_l4_test_time 1.0635559558868408
gc 0
Train Epoch26 Acc 0.9927178571428571 (555922/560000), AUC 0.9989032745361328
ep26_train_time 80.21605443954468
Test Epoch26 layer0 Acc 0.9652571428571428, AUC 0.4987218379974365, avg_entr 0.02122148498892784
ep26_l0_test_time 0.38747262954711914
Test Epoch26 layer1 Acc 0.9706571428571429, AUC 0.4973563849925995, avg_entr 0.0050493706949055195
ep26_l1_test_time 0.5513150691986084
Test Epoch26 layer2 Acc 0.9707142857142858, AUC 0.49691304564476013, avg_entr 0.0030918570701032877
ep26_l2_test_time 0.7020730972290039
Test Epoch26 layer3 Acc 0.9705714285714285, AUC 0.49688711762428284, avg_entr 0.0025691520422697067
ep26_l3_test_time 0.9255778789520264
Test Epoch26 layer4 Acc 0.9707142857142858, AUC 0.4961257874965668, avg_entr 0.0022902139462530613
ep26_l4_test_time 1.0465617179870605
gc 0
Train Epoch27 Acc 0.9927285714285714 (555928/560000), AUC 0.9988614916801453
ep27_train_time 80.18651223182678
Test Epoch27 layer0 Acc 0.9652, AUC 0.49872297048568726, avg_entr 0.021292543038725853
ep27_l0_test_time 0.39057064056396484
Test Epoch27 layer1 Acc 0.9703142857142857, AUC 0.4973700940608978, avg_entr 0.0050757634453475475
ep27_l1_test_time 0.5552365779876709
Test Epoch27 layer2 Acc 0.9707142857142858, AUC 0.4969613254070282, avg_entr 0.0031029777601361275
ep27_l2_test_time 0.7008423805236816
Test Epoch27 layer3 Acc 0.9706857142857143, AUC 0.49695760011672974, avg_entr 0.002600407227873802
ep27_l3_test_time 0.862553596496582
Test Epoch27 layer4 Acc 0.9707714285714286, AUC 0.4960869252681732, avg_entr 0.0024094420950859785
ep27_l4_test_time 1.027630090713501
gc 0
Train Epoch28 Acc 0.9927142857142857 (555920/560000), AUC 0.9988831877708435
ep28_train_time 80.30487179756165
Test Epoch28 layer0 Acc 0.9650571428571428, AUC 0.49871739745140076, avg_entr 0.021220602095127106
ep28_l0_test_time 0.3847472667694092
Test Epoch28 layer1 Acc 0.9704571428571429, AUC 0.49732527136802673, avg_entr 0.00506287906318903
ep28_l1_test_time 0.5524811744689941
Test Epoch28 layer2 Acc 0.9707142857142858, AUC 0.4968350827693939, avg_entr 0.003038956318050623
ep28_l2_test_time 0.701744794845581
Test Epoch28 layer3 Acc 0.9706571428571429, AUC 0.49683767557144165, avg_entr 0.002551132347434759
ep28_l3_test_time 0.8658123016357422
Test Epoch28 layer4 Acc 0.9707142857142858, AUC 0.4959660470485687, avg_entr 0.0023461533710360527
ep28_l4_test_time 1.0153849124908447
gc 0
Train Epoch29 Acc 0.9927285714285714 (555928/560000), AUC 0.9988528490066528
ep29_train_time 79.68153643608093
Test Epoch29 layer0 Acc 0.9652857142857143, AUC 0.4987199604511261, avg_entr 0.021228211000561714
ep29_l0_test_time 0.3871431350708008
Test Epoch29 layer1 Acc 0.9703714285714286, AUC 0.4973349869251251, avg_entr 0.005074150860309601
ep29_l1_test_time 0.5604188442230225
Test Epoch29 layer2 Acc 0.9707428571428571, AUC 0.49687808752059937, avg_entr 0.003060142509639263
ep29_l2_test_time 0.7109191417694092
Test Epoch29 layer3 Acc 0.9708, AUC 0.4968656599521637, avg_entr 0.0025684365537017584
ep29_l3_test_time 0.8606421947479248
Test Epoch29 layer4 Acc 0.9708285714285714, AUC 0.4960290789604187, avg_entr 0.0023812639992684126
ep29_l4_test_time 1.0330071449279785
gc 0
Train Epoch30 Acc 0.9927589285714286 (555945/560000), AUC 0.9988740086555481
ep30_train_time 80.86046433448792
Test Epoch30 layer0 Acc 0.9651428571428572, AUC 0.4987179636955261, avg_entr 0.021251719444990158
ep30_l0_test_time 0.38994407653808594
Test Epoch30 layer1 Acc 0.9703428571428572, AUC 0.4973231256008148, avg_entr 0.005083659663796425
ep30_l1_test_time 0.5508475303649902
Test Epoch30 layer2 Acc 0.9704571428571429, AUC 0.4968400001525879, avg_entr 0.003083552001044154
ep30_l2_test_time 0.7044851779937744
Test Epoch30 layer3 Acc 0.9706285714285714, AUC 0.49689850211143494, avg_entr 0.002540928777307272
ep30_l3_test_time 0.8599855899810791
Test Epoch30 layer4 Acc 0.9705142857142857, AUC 0.49600285291671753, avg_entr 0.002281575696542859
ep30_l4_test_time 1.0234100818634033
gc 0
Train Epoch31 Acc 0.9928696428571429 (556007/560000), AUC 0.9988535046577454
ep31_train_time 80.6342523097992
Test Epoch31 layer0 Acc 0.965, AUC 0.4987182319164276, avg_entr 0.021252818405628204
ep31_l0_test_time 0.3893263339996338
Test Epoch31 layer1 Acc 0.9704857142857143, AUC 0.49731916189193726, avg_entr 0.005040974821895361
ep31_l1_test_time 0.5485846996307373
Test Epoch31 layer2 Acc 0.9706571428571429, AUC 0.4968252182006836, avg_entr 0.0030540451407432556
ep31_l2_test_time 0.7057242393493652
Test Epoch31 layer3 Acc 0.9706, AUC 0.4968327581882477, avg_entr 0.0025100854691118
ep31_l3_test_time 0.8656766414642334
Test Epoch31 layer4 Acc 0.9706857142857143, AUC 0.49600866436958313, avg_entr 0.002290416741743684
ep31_l4_test_time 1.0344746112823486
gc 0
Train Epoch32 Acc 0.9927625 (555947/560000), AUC 0.9988670945167542
ep32_train_time 79.62264227867126
Test Epoch32 layer0 Acc 0.9649714285714286, AUC 0.4987177848815918, avg_entr 0.021282464265823364
ep32_l0_test_time 0.3849465847015381
Test Epoch32 layer1 Acc 0.9704285714285714, AUC 0.49732398986816406, avg_entr 0.005085052456706762
ep32_l1_test_time 0.5527317523956299
Test Epoch32 layer2 Acc 0.9706, AUC 0.49681928753852844, avg_entr 0.003053213469684124
ep32_l2_test_time 0.7075514793395996
Test Epoch32 layer3 Acc 0.9705428571428572, AUC 0.49686673283576965, avg_entr 0.002523314207792282
ep32_l3_test_time 0.8712902069091797
Test Epoch32 layer4 Acc 0.9706285714285714, AUC 0.4960078299045563, avg_entr 0.0022767111659049988
ep32_l4_test_time 1.0480997562408447
gc 0
Train Epoch33 Acc 0.9928375 (555989/560000), AUC 0.9988402724266052
ep33_train_time 79.50694465637207
Test Epoch33 layer0 Acc 0.9650857142857143, AUC 0.4987187683582306, avg_entr 0.021229460835456848
ep33_l0_test_time 0.3913838863372803
Test Epoch33 layer1 Acc 0.9705428571428572, AUC 0.4973248839378357, avg_entr 0.005096858367323875
ep33_l1_test_time 0.5502705574035645
Test Epoch33 layer2 Acc 0.9706571428571429, AUC 0.4968417286872864, avg_entr 0.003065112279728055
ep33_l2_test_time 0.7022373676300049
Test Epoch33 layer3 Acc 0.9706571428571429, AUC 0.49687448143959045, avg_entr 0.0025314134545624256
ep33_l3_test_time 0.8705856800079346
Test Epoch33 layer4 Acc 0.9706, AUC 0.4960018992424011, avg_entr 0.002281793160364032
ep33_l4_test_time 1.030442476272583
gc 0
Train Epoch34 Acc 0.99285 (555996/560000), AUC 0.9988588094711304
ep34_train_time 80.09395599365234
Test Epoch34 layer0 Acc 0.9651142857142857, AUC 0.49871882796287537, avg_entr 0.02124166488647461
ep34_l0_test_time 0.38751220703125
Test Epoch34 layer1 Acc 0.9705428571428572, AUC 0.497321218252182, avg_entr 0.005066939629614353
ep34_l1_test_time 0.550915002822876
Test Epoch34 layer2 Acc 0.9707428571428571, AUC 0.4968336224555969, avg_entr 0.0030588919762521982
ep34_l2_test_time 0.709740161895752
Test Epoch34 layer3 Acc 0.9705714285714285, AUC 0.4968743622303009, avg_entr 0.0025221339892596006
ep34_l3_test_time 0.8821911811828613
Test Epoch34 layer4 Acc 0.9706, AUC 0.49600768089294434, avg_entr 0.002265481511130929
ep34_l4_test_time 1.0510118007659912
gc 0
Train Epoch35 Acc 0.9928607142857143 (556002/560000), AUC 0.9988496899604797
ep35_train_time 79.3582694530487
Test Epoch35 layer0 Acc 0.9650857142857143, AUC 0.4987192749977112, avg_entr 0.021239865571260452
ep35_l0_test_time 0.38977527618408203
Test Epoch35 layer1 Acc 0.9705142857142857, AUC 0.49732139706611633, avg_entr 0.00506824953481555
ep35_l1_test_time 0.5539557933807373
Test Epoch35 layer2 Acc 0.9706857142857143, AUC 0.49683642387390137, avg_entr 0.0030616410076618195
ep35_l2_test_time 0.7131772041320801
Test Epoch35 layer3 Acc 0.9706571428571429, AUC 0.49688223004341125, avg_entr 0.002534249797463417
ep35_l3_test_time 0.871720552444458
Test Epoch35 layer4 Acc 0.9706857142857143, AUC 0.4960027039051056, avg_entr 0.002302588429301977
ep35_l4_test_time 1.0289056301116943
gc 0
Train Epoch36 Acc 0.9928053571428571 (555971/560000), AUC 0.9988624453544617
ep36_train_time 79.54675078392029
Test Epoch36 layer0 Acc 0.965, AUC 0.4987192153930664, avg_entr 0.021276207640767097
ep36_l0_test_time 0.3923673629760742
Test Epoch36 layer1 Acc 0.9705142857142857, AUC 0.4973136782646179, avg_entr 0.005058984272181988
ep36_l1_test_time 0.5529670715332031
Test Epoch36 layer2 Acc 0.9707714285714286, AUC 0.4968154728412628, avg_entr 0.0030601797625422478
ep36_l2_test_time 0.7031552791595459
Test Epoch36 layer3 Acc 0.9706857142857143, AUC 0.49685972929000854, avg_entr 0.0025330919306725264
ep36_l3_test_time 0.882805347442627
Test Epoch36 layer4 Acc 0.9706571428571429, AUC 0.4959959089756012, avg_entr 0.0023015711922198534
ep36_l4_test_time 1.0328843593597412
gc 0
Train Epoch37 Acc 0.9928857142857143 (556016/560000), AUC 0.9988789558410645
ep37_train_time 79.76914978027344
Test Epoch37 layer0 Acc 0.9650571428571428, AUC 0.4987178444862366, avg_entr 0.021246301010251045
ep37_l0_test_time 0.3910708427429199
Test Epoch37 layer1 Acc 0.9705142857142857, AUC 0.49731701612472534, avg_entr 0.005057267379015684
ep37_l1_test_time 0.5603532791137695
Test Epoch37 layer2 Acc 0.9708, AUC 0.49681830406188965, avg_entr 0.003054593224078417
ep37_l2_test_time 0.7107234001159668
Test Epoch37 layer3 Acc 0.9707142857142858, AUC 0.49684885144233704, avg_entr 0.002534379716962576
ep37_l3_test_time 0.9034287929534912
Test Epoch37 layer4 Acc 0.9707142857142858, AUC 0.4959876537322998, avg_entr 0.0023026394192129374
ep37_l4_test_time 1.0221223831176758
gc 0
Train Epoch38 Acc 0.9928875 (556017/560000), AUC 0.9988647103309631
ep38_train_time 80.0079255104065
Test Epoch38 layer0 Acc 0.9650285714285715, AUC 0.49871882796287537, avg_entr 0.02124040573835373
ep38_l0_test_time 0.38765668869018555
Test Epoch38 layer1 Acc 0.9704571428571429, AUC 0.4973185360431671, avg_entr 0.005066755227744579
ep38_l1_test_time 0.5457150936126709
Test Epoch38 layer2 Acc 0.9706285714285714, AUC 0.49681854248046875, avg_entr 0.003055065404623747
ep38_l2_test_time 0.7032825946807861
Test Epoch38 layer3 Acc 0.9707428571428571, AUC 0.4968562424182892, avg_entr 0.002540108747780323
ep38_l3_test_time 0.8572893142700195
Test Epoch38 layer4 Acc 0.9706571428571429, AUC 0.49600377678871155, avg_entr 0.002310198498889804
ep38_l4_test_time 1.0303707122802734
gc 0
Train Epoch39 Acc 0.9928642857142858 (556004/560000), AUC 0.9988555908203125
ep39_train_time 79.71747255325317
Test Epoch39 layer0 Acc 0.9650857142857143, AUC 0.4987185299396515, avg_entr 0.02126108668744564
ep39_l0_test_time 0.3871467113494873
Test Epoch39 layer1 Acc 0.9704857142857143, AUC 0.4973112940788269, avg_entr 0.0050667948089540005
ep39_l1_test_time 0.5497736930847168
Test Epoch39 layer2 Acc 0.9706285714285714, AUC 0.4968189299106598, avg_entr 0.003054586937651038
ep39_l2_test_time 0.6980195045471191
Test Epoch39 layer3 Acc 0.9706571428571429, AUC 0.49683037400245667, avg_entr 0.0025377031415700912
ep39_l3_test_time 0.8573966026306152
Test Epoch39 layer4 Acc 0.9706857142857143, AUC 0.49598509073257446, avg_entr 0.0023048410657793283
ep39_l4_test_time 1.0483441352844238
gc 0
Train Epoch40 Acc 0.9928589285714285 (556001/560000), AUC 0.9988638758659363
ep40_train_time 80.47229290008545
Test Epoch40 layer0 Acc 0.9651142857142857, AUC 0.4987182915210724, avg_entr 0.021246837452054024
ep40_l0_test_time 0.38326001167297363
Test Epoch40 layer1 Acc 0.9704857142857143, AUC 0.4973149001598358, avg_entr 0.005070619285106659
ep40_l1_test_time 0.5532636642456055
Test Epoch40 layer2 Acc 0.9705428571428572, AUC 0.496815949678421, avg_entr 0.0030581883620470762
ep40_l2_test_time 0.7006528377532959
Test Epoch40 layer3 Acc 0.9706571428571429, AUC 0.4968429505825043, avg_entr 0.002543579088523984
ep40_l3_test_time 0.8704288005828857
Test Epoch40 layer4 Acc 0.9706571428571429, AUC 0.49599090218544006, avg_entr 0.0023073425982147455
ep40_l4_test_time 1.059215784072876
gc 0
Train Epoch41 Acc 0.992875 (556010/560000), AUC 0.9988515973091125
ep41_train_time 79.65203714370728
Test Epoch41 layer0 Acc 0.9650285714285715, AUC 0.49871841073036194, avg_entr 0.021270187571644783
ep41_l0_test_time 0.3881804943084717
Test Epoch41 layer1 Acc 0.9704857142857143, AUC 0.4973128139972687, avg_entr 0.005070889368653297
ep41_l1_test_time 0.5585594177246094
Test Epoch41 layer2 Acc 0.9705428571428572, AUC 0.4968208372592926, avg_entr 0.0030577597208321095
ep41_l2_test_time 0.744084358215332
Test Epoch41 layer3 Acc 0.9706285714285714, AUC 0.49685171246528625, avg_entr 0.002537339460104704
ep41_l3_test_time 0.8906595706939697
Test Epoch41 layer4 Acc 0.9706285714285714, AUC 0.4959976077079773, avg_entr 0.002294903388246894
ep41_l4_test_time 1.0535547733306885
gc 0
Train Epoch42 Acc 0.9929267857142857 (556039/560000), AUC 0.9988590478897095
ep42_train_time 79.97886490821838
Test Epoch42 layer0 Acc 0.9650571428571428, AUC 0.49871858954429626, avg_entr 0.021252553910017014
ep42_l0_test_time 0.3895838260650635
Test Epoch42 layer1 Acc 0.9704571428571429, AUC 0.4973146915435791, avg_entr 0.00507024209946394
ep42_l1_test_time 0.5477995872497559
Test Epoch42 layer2 Acc 0.9705714285714285, AUC 0.4968193471431732, avg_entr 0.0030538414139300585
ep42_l2_test_time 0.7043018341064453
Test Epoch42 layer3 Acc 0.9706, AUC 0.4968542456626892, avg_entr 0.0025345119647681713
ep42_l3_test_time 0.8691470623016357
Test Epoch42 layer4 Acc 0.9705714285714285, AUC 0.49599483609199524, avg_entr 0.0022933247964829206
ep42_l4_test_time 1.0286939144134521
gc 0
Train Epoch43 Acc 0.9928446428571429 (555993/560000), AUC 0.9988812208175659
ep43_train_time 80.35976576805115
Test Epoch43 layer0 Acc 0.9650571428571428, AUC 0.4987185299396515, avg_entr 0.021244464442133904
ep43_l0_test_time 0.3867478370666504
Test Epoch43 layer1 Acc 0.9704571428571429, AUC 0.4973151981830597, avg_entr 0.005069232080131769
ep43_l1_test_time 0.5494062900543213
Test Epoch43 layer2 Acc 0.9706, AUC 0.4968228042125702, avg_entr 0.0030575019773095846
ep43_l2_test_time 0.7018461227416992
Test Epoch43 layer3 Acc 0.9706285714285714, AUC 0.49684932827949524, avg_entr 0.0025447229854762554
ep43_l3_test_time 0.8604638576507568
Test Epoch43 layer4 Acc 0.9706285714285714, AUC 0.49601131677627563, avg_entr 0.002307465998455882
ep43_l4_test_time 1.0054395198822021
gc 0
Train Epoch44 Acc 0.9928321428571428 (555986/560000), AUC 0.9988752007484436
ep44_train_time 80.08099627494812
Test Epoch44 layer0 Acc 0.9650857142857143, AUC 0.4987185001373291, avg_entr 0.021249989047646523
ep44_l0_test_time 0.3869004249572754
Test Epoch44 layer1 Acc 0.9704571428571429, AUC 0.4973152279853821, avg_entr 0.005073395557701588
ep44_l1_test_time 0.5469839572906494
Test Epoch44 layer2 Acc 0.9705428571428572, AUC 0.49682432413101196, avg_entr 0.003057512454688549
ep44_l2_test_time 0.7022464275360107
Test Epoch44 layer3 Acc 0.9706571428571429, AUC 0.49685773253440857, avg_entr 0.002545170485973358
ep44_l3_test_time 0.8821225166320801
Test Epoch44 layer4 Acc 0.9706285714285714, AUC 0.49600332975387573, avg_entr 0.002306531649082899
ep44_l4_test_time 1.0256755352020264
gc 0
Train Epoch45 Acc 0.9929053571428571 (556027/560000), AUC 0.9988648295402527
ep45_train_time 79.88971328735352
Test Epoch45 layer0 Acc 0.9650571428571428, AUC 0.4987184703350067, avg_entr 0.02125096134841442
ep45_l0_test_time 0.3943197727203369
Test Epoch45 layer1 Acc 0.9704571428571429, AUC 0.4973144233226776, avg_entr 0.005070326384156942
ep45_l1_test_time 0.5465922355651855
Test Epoch45 layer2 Acc 0.9705428571428572, AUC 0.4968232810497284, avg_entr 0.003056806279346347
ep45_l2_test_time 0.7014591693878174
Test Epoch45 layer3 Acc 0.9706285714285714, AUC 0.4968489110469818, avg_entr 0.0025444035418331623
ep45_l3_test_time 0.8973057270050049
Test Epoch45 layer4 Acc 0.9706, AUC 0.496002733707428, avg_entr 0.002307640854269266
ep45_l4_test_time 1.1538159847259521
gc 0
Train Epoch46 Acc 0.9929089285714285 (556029/560000), AUC 0.9988675713539124
ep46_train_time 80.13721513748169
Test Epoch46 layer0 Acc 0.9650857142857143, AUC 0.4987184703350067, avg_entr 0.0212485883384943
ep46_l0_test_time 0.38719868659973145
Test Epoch46 layer1 Acc 0.9704285714285714, AUC 0.49731332063674927, avg_entr 0.00506951380521059
ep46_l1_test_time 0.5531728267669678
Test Epoch46 layer2 Acc 0.9705714285714285, AUC 0.4968225657939911, avg_entr 0.003057264955714345
ep46_l2_test_time 0.7021777629852295
Test Epoch46 layer3 Acc 0.9706285714285714, AUC 0.496847003698349, avg_entr 0.0025437481235712767
ep46_l3_test_time 0.905472993850708
Test Epoch46 layer4 Acc 0.9705714285714285, AUC 0.49600648880004883, avg_entr 0.0023066310677677393
ep46_l4_test_time 1.0282633304595947
gc 0
Train Epoch47 Acc 0.9928553571428571 (555999/560000), AUC 0.9988353848457336
ep47_train_time 80.37067723274231
Test Epoch47 layer0 Acc 0.9650857142857143, AUC 0.49871841073036194, avg_entr 0.02124525047838688
ep47_l0_test_time 0.38666272163391113
Test Epoch47 layer1 Acc 0.9704571428571429, AUC 0.4973134994506836, avg_entr 0.005070017650723457
ep47_l1_test_time 0.5499520301818848
Test Epoch47 layer2 Acc 0.9705714285714285, AUC 0.49682196974754333, avg_entr 0.003056730143725872
ep47_l2_test_time 0.7056639194488525
Test Epoch47 layer3 Acc 0.9706571428571429, AUC 0.4968491494655609, avg_entr 0.002543980721384287
ep47_l3_test_time 0.8813130855560303
Test Epoch47 layer4 Acc 0.9706285714285714, AUC 0.4960024058818817, avg_entr 0.002305317437276244
ep47_l4_test_time 1.0439503192901611
gc 0
Train Epoch48 Acc 0.9928553571428571 (555999/560000), AUC 0.9988760352134705
ep48_train_time 80.63830757141113
Test Epoch48 layer0 Acc 0.9650571428571428, AUC 0.49871841073036194, avg_entr 0.021247098222374916
ep48_l0_test_time 0.3856821060180664
Test Epoch48 layer1 Acc 0.9704285714285714, AUC 0.49731311202049255, avg_entr 0.005069951061159372
ep48_l1_test_time 0.5651895999908447
Test Epoch48 layer2 Acc 0.9705714285714285, AUC 0.4968218505382538, avg_entr 0.003057359019294381
ep48_l2_test_time 0.7116148471832275
Test Epoch48 layer3 Acc 0.9706571428571429, AUC 0.49684470891952515, avg_entr 0.002547555835917592
ep48_l3_test_time 0.8554182052612305
Test Epoch48 layer4 Acc 0.9705714285714285, AUC 0.49600711464881897, avg_entr 0.00231021991930902
ep48_l4_test_time 1.0235819816589355
gc 0
Train Epoch49 Acc 0.9929196428571428 (556035/560000), AUC 0.9988711476325989
ep49_train_time 81.21152758598328
Test Epoch49 layer0 Acc 0.9650571428571428, AUC 0.49871841073036194, avg_entr 0.021242516115307808
ep49_l0_test_time 0.3830704689025879
Test Epoch49 layer1 Acc 0.9704285714285714, AUC 0.4973127543926239, avg_entr 0.005069106817245483
ep49_l1_test_time 0.5554308891296387
Test Epoch49 layer2 Acc 0.9705714285714285, AUC 0.4968215525150299, avg_entr 0.003057357855141163
ep49_l2_test_time 0.705329179763794
Test Epoch49 layer3 Acc 0.9706571428571429, AUC 0.49684613943099976, avg_entr 0.002546044997870922
ep49_l3_test_time 0.8471512794494629
Test Epoch49 layer4 Acc 0.9705428571428572, AUC 0.4960031509399414, avg_entr 0.002307927468791604
ep49_l4_test_time 1.021019458770752
Best AUC 0.4987311363220215
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train+valid_time 4182.231746912003
Start Testing
Load ckpt at ckpt/dbpedia_14_transformeral_l5_pad20//dbpedia_14_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.9850571428571429, AUC 0.4996783435344696, avg_entr 0.015138835646212101
ep49_l0_test_time 0.3840184211730957
Test Epoch49 layer1 Acc 0.9876857142857143, AUC 0.4992390275001526, avg_entr 0.002698534866794944
ep49_l1_test_time 0.5626974105834961
Test Epoch49 layer2 Acc 0.9872285714285715, AUC 0.49913790822029114, avg_entr 0.001717853476293385
ep49_l2_test_time 0.7080917358398438
Test Epoch49 layer3 Acc 0.9871714285714286, AUC 0.4990365505218506, avg_entr 0.0015108544612303376
ep49_l3_test_time 0.8722190856933594
Test Epoch49 layer4 Acc 0.9871428571428571, AUC 0.4987778663635254, avg_entr 0.0013686950551345944
ep49_l4_test_time 1.0171523094177246
