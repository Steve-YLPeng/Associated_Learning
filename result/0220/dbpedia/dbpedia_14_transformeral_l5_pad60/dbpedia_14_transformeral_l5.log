total count words 887881
vocab size 30000
found 28354 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=14, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=14, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 1792
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 1792
layers.0.ae.h.0.bias 14
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13674862
init_time 58.62228226661682
Start Training
gc 0
Train Epoch0 Acc 0.8409267857142857 (470919/560000), AUC 0.9815438389778137
ep0_train_time 155.57557272911072
Test Epoch0 layer0 Acc 0.9646285714285714, AUC 0.4985335171222687, avg_entr 0.09175979346036911
ep0_l0_test_time 0.7073440551757812
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad60//dbpedia_14_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9651428571428572, AUC 0.49863141775131226, avg_entr 0.045096155256032944
ep0_l1_test_time 1.1270008087158203
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad60//dbpedia_14_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.9664857142857143, AUC 0.49833300709724426, avg_entr 0.031640950590372086
ep0_l2_test_time 1.5551035404205322
Test Epoch0 layer3 Acc 0.9666, AUC 0.4983994960784912, avg_entr 0.027642400935292244
ep0_l3_test_time 1.9301888942718506
Test Epoch0 layer4 Acc 0.9661714285714286, AUC 0.49825143814086914, avg_entr 0.024163993075489998
ep0_l4_test_time 2.3315021991729736
gc 0
Train Epoch1 Acc 0.9800214285714286 (548812/560000), AUC 0.9974378943443298
ep1_train_time 153.56684398651123
Test Epoch1 layer0 Acc 0.9649142857142857, AUC 0.49863776564598083, avg_entr 0.05314062908291817
ep1_l0_test_time 0.7053372859954834
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad60//dbpedia_14_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.9713428571428572, AUC 0.49845147132873535, avg_entr 0.01313864067196846
ep1_l1_test_time 1.1492772102355957
Test Epoch1 layer2 Acc 0.9727714285714286, AUC 0.4983173906803131, avg_entr 0.008720055222511292
ep1_l2_test_time 1.5728847980499268
Test Epoch1 layer3 Acc 0.9726285714285714, AUC 0.49833589792251587, avg_entr 0.00750689534470439
ep1_l3_test_time 1.933692216873169
Test Epoch1 layer4 Acc 0.9727428571428571, AUC 0.49824902415275574, avg_entr 0.0064747822470963
ep1_l4_test_time 2.409613847732544
gc 0
Train Epoch2 Acc 0.9838892857142857 (550978/560000), AUC 0.9977997541427612
ep2_train_time 153.81447315216064
Test Epoch2 layer0 Acc 0.9647142857142857, AUC 0.49867719411849976, avg_entr 0.03914354369044304
ep2_l0_test_time 0.7053098678588867
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad60//dbpedia_14_transformeral_l5.pt  ,ep 2
Test Epoch2 layer1 Acc 0.9715428571428572, AUC 0.49843165278434753, avg_entr 0.008726954460144043
ep2_l1_test_time 1.17720627784729
Test Epoch2 layer2 Acc 0.9726571428571429, AUC 0.49847254157066345, avg_entr 0.005713893100619316
ep2_l2_test_time 1.5551636219024658
Test Epoch2 layer3 Acc 0.9726285714285714, AUC 0.4984098970890045, avg_entr 0.004895553458482027
ep2_l3_test_time 2.038562059402466
Test Epoch2 layer4 Acc 0.9725142857142857, AUC 0.49814897775650024, avg_entr 0.004208312835544348
ep2_l4_test_time 2.3580291271209717
gc 0
Train Epoch3 Acc 0.9856178571428571 (551946/560000), AUC 0.9980630278587341
ep3_train_time 153.86807322502136
Test Epoch3 layer0 Acc 0.9650857142857143, AUC 0.4986833930015564, avg_entr 0.031600214540958405
ep3_l0_test_time 0.688072919845581
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad60//dbpedia_14_transformeral_l5.pt  ,ep 3
Test Epoch3 layer1 Acc 0.9718571428571429, AUC 0.4982917606830597, avg_entr 0.006731519941240549
ep3_l1_test_time 1.1882095336914062
Test Epoch3 layer2 Acc 0.9723714285714286, AUC 0.49828964471817017, avg_entr 0.004415151663124561
ep3_l2_test_time 1.5455787181854248
Test Epoch3 layer3 Acc 0.9723428571428572, AUC 0.4980425238609314, avg_entr 0.0038128697779029608
ep3_l3_test_time 1.9413325786590576
Test Epoch3 layer4 Acc 0.9723714285714286, AUC 0.49795740842819214, avg_entr 0.003364809323102236
ep3_l4_test_time 2.3352699279785156
gc 0
Train Epoch4 Acc 0.9869071428571429 (552668/560000), AUC 0.9981072545051575
ep4_train_time 153.48251366615295
Test Epoch4 layer0 Acc 0.9646571428571429, AUC 0.4987019896507263, avg_entr 0.029877351596951485
ep4_l0_test_time 0.7112054824829102
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad60//dbpedia_14_transformeral_l5.pt  ,ep 4
Test Epoch4 layer1 Acc 0.9726285714285714, AUC 0.49809530377388, avg_entr 0.0054911053739488125
ep4_l1_test_time 1.1214516162872314
Test Epoch4 layer2 Acc 0.9731714285714286, AUC 0.49812188744544983, avg_entr 0.0037432319950312376
ep4_l2_test_time 1.5507080554962158
Test Epoch4 layer3 Acc 0.9731714285714286, AUC 0.497952938079834, avg_entr 0.0032619242556393147
ep4_l3_test_time 1.9309747219085693
Test Epoch4 layer4 Acc 0.9732857142857143, AUC 0.49755099415779114, avg_entr 0.002815854735672474
ep4_l4_test_time 2.3444108963012695
gc 0
Train Epoch5 Acc 0.987825 (553182/560000), AUC 0.998365581035614
ep5_train_time 153.84881234169006
Test Epoch5 layer0 Acc 0.9653714285714285, AUC 0.49870795011520386, avg_entr 0.028821321204304695
ep5_l0_test_time 0.7135889530181885
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad60//dbpedia_14_transformeral_l5.pt  ,ep 5
Test Epoch5 layer1 Acc 0.9737142857142858, AUC 0.4983343183994293, avg_entr 0.005472036078572273
ep5_l1_test_time 1.113224744796753
Test Epoch5 layer2 Acc 0.9746, AUC 0.4981313645839691, avg_entr 0.003410864155739546
ep5_l2_test_time 1.5439937114715576
Test Epoch5 layer3 Acc 0.9744571428571429, AUC 0.49804142117500305, avg_entr 0.0029258436989039183
ep5_l3_test_time 1.9344213008880615
Test Epoch5 layer4 Acc 0.9745142857142857, AUC 0.4976717531681061, avg_entr 0.0026173784863203764
ep5_l4_test_time 2.4376909732818604
gc 0
Train Epoch6 Acc 0.9885946428571428 (553613/560000), AUC 0.9985528588294983
ep6_train_time 153.79397821426392
Test Epoch6 layer0 Acc 0.9655142857142858, AUC 0.49872055649757385, avg_entr 0.028007684275507927
ep6_l0_test_time 0.7015800476074219
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad60//dbpedia_14_transformeral_l5.pt  ,ep 6
Test Epoch6 layer1 Acc 0.9724, AUC 0.4981226325035095, avg_entr 0.005344708915799856
ep6_l1_test_time 1.1102397441864014
Test Epoch6 layer2 Acc 0.9720857142857143, AUC 0.49799853563308716, avg_entr 0.0035021428484469652
ep6_l2_test_time 1.5739271640777588
Test Epoch6 layer3 Acc 0.972, AUC 0.49774619936943054, avg_entr 0.0031619558576494455
ep6_l3_test_time 1.9556117057800293
Test Epoch6 layer4 Acc 0.9718857142857142, AUC 0.4972594380378723, avg_entr 0.0029248336795717478
ep6_l4_test_time 2.3310706615448
gc 0
Train Epoch7 Acc 0.98925 (553980/560000), AUC 0.9986216425895691
ep7_train_time 154.08859944343567
Test Epoch7 layer0 Acc 0.9644857142857143, AUC 0.49869564175605774, avg_entr 0.02784024551510811
ep7_l0_test_time 0.6850478649139404
Test Epoch7 layer1 Acc 0.9732857142857143, AUC 0.49807578325271606, avg_entr 0.005086018703877926
ep7_l1_test_time 1.10227370262146
Test Epoch7 layer2 Acc 0.973, AUC 0.4978039562702179, avg_entr 0.0033023229334503412
ep7_l2_test_time 1.5558199882507324
Test Epoch7 layer3 Acc 0.9730571428571428, AUC 0.4975597560405731, avg_entr 0.0029243675526231527
ep7_l3_test_time 1.9417896270751953
Test Epoch7 layer4 Acc 0.9731142857142857, AUC 0.49731189012527466, avg_entr 0.0026303676422685385
ep7_l4_test_time 2.4313156604766846
gc 0
Train Epoch8 Acc 0.9896285714285714 (554192/560000), AUC 0.9986606240272522
ep8_train_time 153.95968198776245
Test Epoch8 layer0 Acc 0.9652285714285714, AUC 0.4987356662750244, avg_entr 0.027313657104969025
ep8_l0_test_time 0.7047231197357178
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad60//dbpedia_14_transformeral_l5.pt  ,ep 8
Test Epoch8 layer1 Acc 0.9726285714285714, AUC 0.4980495572090149, avg_entr 0.005041788332164288
ep8_l1_test_time 1.1579511165618896
Test Epoch8 layer2 Acc 0.9731428571428572, AUC 0.49806782603263855, avg_entr 0.003286306746304035
ep8_l2_test_time 1.5381009578704834
Test Epoch8 layer3 Acc 0.9728857142857142, AUC 0.4979805052280426, avg_entr 0.002801122609525919
ep8_l3_test_time 1.9622783660888672
Test Epoch8 layer4 Acc 0.973, AUC 0.497480183839798, avg_entr 0.0024190079420804977
ep8_l4_test_time 2.361616611480713
gc 0
Train Epoch9 Acc 0.9905785714285714 (554724/560000), AUC 0.9987474679946899
ep9_train_time 153.93598294258118
Test Epoch9 layer0 Acc 0.9652, AUC 0.49871084094047546, avg_entr 0.02714155986905098
ep9_l0_test_time 0.6898303031921387
Test Epoch9 layer1 Acc 0.9727142857142858, AUC 0.49800586700439453, avg_entr 0.0049298773519694805
ep9_l1_test_time 1.1169579029083252
Test Epoch9 layer2 Acc 0.9729142857142857, AUC 0.49770230054855347, avg_entr 0.0031814100220799446
ep9_l2_test_time 1.5348501205444336
Test Epoch9 layer3 Acc 0.9728571428571429, AUC 0.49766460061073303, avg_entr 0.0028182638343423605
ep9_l3_test_time 1.9237897396087646
Test Epoch9 layer4 Acc 0.9730285714285715, AUC 0.49722033739089966, avg_entr 0.0025912700220942497
ep9_l4_test_time 2.328092098236084
gc 0
Train Epoch10 Acc 0.9908196428571429 (554859/560000), AUC 0.9987384676933289
ep10_train_time 154.05014896392822
Test Epoch10 layer0 Acc 0.9648571428571429, AUC 0.4987165629863739, avg_entr 0.027537284418940544
ep10_l0_test_time 0.7064471244812012
Test Epoch10 layer1 Acc 0.9721428571428572, AUC 0.4980091452598572, avg_entr 0.005069423001259565
ep10_l1_test_time 1.1405985355377197
Test Epoch10 layer2 Acc 0.9727142857142858, AUC 0.497681200504303, avg_entr 0.003131832228973508
ep10_l2_test_time 1.5626304149627686
Test Epoch10 layer3 Acc 0.9727142857142858, AUC 0.497482568025589, avg_entr 0.0027338271029293537
ep10_l3_test_time 1.9213273525238037
Test Epoch10 layer4 Acc 0.9726571428571429, AUC 0.4970332086086273, avg_entr 0.0025109469424933195
ep10_l4_test_time 2.3543930053710938
gc 0
Train Epoch11 Acc 0.9910071428571429 (554964/560000), AUC 0.998773455619812
ep11_train_time 154.09372520446777
Test Epoch11 layer0 Acc 0.9648, AUC 0.49871325492858887, avg_entr 0.027559462934732437
ep11_l0_test_time 0.6978459358215332
Test Epoch11 layer1 Acc 0.9722, AUC 0.4979563057422638, avg_entr 0.004853385500609875
ep11_l1_test_time 1.1525213718414307
Test Epoch11 layer2 Acc 0.9724857142857143, AUC 0.4977504312992096, avg_entr 0.003054814413189888
ep11_l2_test_time 1.5552592277526855
Test Epoch11 layer3 Acc 0.9726571428571429, AUC 0.49758201837539673, avg_entr 0.0026771423872560263
ep11_l3_test_time 1.9272680282592773
Test Epoch11 layer4 Acc 0.9727714285714286, AUC 0.4972114861011505, avg_entr 0.0024519257713109255
ep11_l4_test_time 2.327819585800171
gc 0
Train Epoch12 Acc 0.9912946428571429 (555125/560000), AUC 0.9987726211547852
ep12_train_time 153.86992597579956
Test Epoch12 layer0 Acc 0.9648571428571429, AUC 0.49872419238090515, avg_entr 0.027668900787830353
ep12_l0_test_time 0.7007358074188232
Test Epoch12 layer1 Acc 0.9719142857142857, AUC 0.49791207909584045, avg_entr 0.004727876279503107
ep12_l1_test_time 1.124492883682251
Test Epoch12 layer2 Acc 0.9721142857142857, AUC 0.4977092444896698, avg_entr 0.0030509093776345253
ep12_l2_test_time 1.5366535186767578
Test Epoch12 layer3 Acc 0.9722571428571428, AUC 0.4973618984222412, avg_entr 0.0025941459462046623
ep12_l3_test_time 1.9253134727478027
Test Epoch12 layer4 Acc 0.9722, AUC 0.4969758987426758, avg_entr 0.0022315920796245337
ep12_l4_test_time 2.331882953643799
gc 0
Train Epoch13 Acc 0.9918589285714285 (555441/560000), AUC 0.9987666010856628
ep13_train_time 154.33476448059082
Test Epoch13 layer0 Acc 0.9655142857142858, AUC 0.4987342655658722, avg_entr 0.027041539549827576
ep13_l0_test_time 0.7037148475646973
Test Epoch13 layer1 Acc 0.9729714285714286, AUC 0.4979564845561981, avg_entr 0.004740373231470585
ep13_l1_test_time 1.1367998123168945
Test Epoch13 layer2 Acc 0.9736857142857143, AUC 0.4977351725101471, avg_entr 0.003052863059565425
ep13_l2_test_time 1.5627598762512207
Test Epoch13 layer3 Acc 0.9736857142857143, AUC 0.49750033020973206, avg_entr 0.002543508540838957
ep13_l3_test_time 1.9213738441467285
Test Epoch13 layer4 Acc 0.9738, AUC 0.49695488810539246, avg_entr 0.002254834631457925
ep13_l4_test_time 2.3261091709136963
gc 0
Train Epoch14 Acc 0.992 (555520/560000), AUC 0.9987936019897461
ep14_train_time 154.1881697177887
Test Epoch14 layer0 Acc 0.9653142857142857, AUC 0.4987232983112335, avg_entr 0.02724655345082283
ep14_l0_test_time 0.6954042911529541
Test Epoch14 layer1 Acc 0.9721428571428572, AUC 0.4978572428226471, avg_entr 0.004630104172974825
ep14_l1_test_time 1.1791620254516602
Test Epoch14 layer2 Acc 0.9724571428571429, AUC 0.4976850152015686, avg_entr 0.003070075763389468
ep14_l2_test_time 1.568655014038086
Test Epoch14 layer3 Acc 0.9726285714285714, AUC 0.4975336492061615, avg_entr 0.0026939192321151495
ep14_l3_test_time 1.9633288383483887
Test Epoch14 layer4 Acc 0.9726857142857143, AUC 0.4970807433128357, avg_entr 0.0023726513609290123
ep14_l4_test_time 2.3535637855529785
gc 0
Train Epoch15 Acc 0.9921017857142858 (555577/560000), AUC 0.9987974762916565
ep15_train_time 153.97342014312744
Test Epoch15 layer0 Acc 0.9650571428571428, AUC 0.4987203776836395, avg_entr 0.027164550498127937
ep15_l0_test_time 0.7325737476348877
Test Epoch15 layer1 Acc 0.9720857142857143, AUC 0.4977641701698303, avg_entr 0.004881765227764845
ep15_l1_test_time 1.120845079421997
Test Epoch15 layer2 Acc 0.9724285714285714, AUC 0.49756377935409546, avg_entr 0.0030905804596841335
ep15_l2_test_time 1.5540814399719238
Test Epoch15 layer3 Acc 0.9724285714285714, AUC 0.49736303091049194, avg_entr 0.002721602562814951
ep15_l3_test_time 1.9485561847686768
Test Epoch15 layer4 Acc 0.9724571428571429, AUC 0.4970548450946808, avg_entr 0.002518552588298917
ep15_l4_test_time 2.3735861778259277
gc 0
Train Epoch16 Acc 0.9921589285714286 (555609/560000), AUC 0.9988325238227844
ep16_train_time 154.12684726715088
Test Epoch16 layer0 Acc 0.9651142857142857, AUC 0.498712956905365, avg_entr 0.027093660086393356
ep16_l0_test_time 0.6917665004730225
Test Epoch16 layer1 Acc 0.9717714285714286, AUC 0.4977115988731384, avg_entr 0.004858388099819422
ep16_l1_test_time 1.1084015369415283
Test Epoch16 layer2 Acc 0.9716571428571429, AUC 0.4974934756755829, avg_entr 0.0031258384697139263
ep16_l2_test_time 1.564685583114624
Test Epoch16 layer3 Acc 0.9718, AUC 0.4972526729106903, avg_entr 0.0027306631673127413
ep16_l3_test_time 1.9176628589630127
Test Epoch16 layer4 Acc 0.9718, AUC 0.4970082640647888, avg_entr 0.0024868121836334467
ep16_l4_test_time 2.3252806663513184
gc 0
Train Epoch17 Acc 0.9924892857142857 (555794/560000), AUC 0.9988131523132324
ep17_train_time 154.32796120643616
Test Epoch17 layer0 Acc 0.9654285714285714, AUC 0.4987163245677948, avg_entr 0.02694828063249588
ep17_l0_test_time 0.6905913352966309
Test Epoch17 layer1 Acc 0.9721142857142857, AUC 0.4977404773235321, avg_entr 0.004783594515174627
ep17_l1_test_time 1.1667449474334717
Test Epoch17 layer2 Acc 0.9716571428571429, AUC 0.497535765171051, avg_entr 0.0031420926097780466
ep17_l2_test_time 1.530491828918457
Test Epoch17 layer3 Acc 0.9718, AUC 0.4972460865974426, avg_entr 0.002637359546497464
ep17_l3_test_time 1.9228622913360596
Test Epoch17 layer4 Acc 0.9717142857142858, AUC 0.49697938561439514, avg_entr 0.0024264741223305464
ep17_l4_test_time 2.3406243324279785
gc 0
Train Epoch18 Acc 0.9925589285714286 (555833/560000), AUC 0.9988151788711548
ep18_train_time 154.14352083206177
Test Epoch18 layer0 Acc 0.9649428571428571, AUC 0.4987167418003082, avg_entr 0.02711532823741436
ep18_l0_test_time 0.6910641193389893
Test Epoch18 layer1 Acc 0.9720857142857143, AUC 0.4977218508720398, avg_entr 0.004891745280474424
ep18_l1_test_time 1.1066060066223145
Test Epoch18 layer2 Acc 0.9718857142857142, AUC 0.49744829535484314, avg_entr 0.003045958699658513
ep18_l2_test_time 1.5426604747772217
Test Epoch18 layer3 Acc 0.9719142857142857, AUC 0.497202605009079, avg_entr 0.002714602742344141
ep18_l3_test_time 1.9576349258422852
Test Epoch18 layer4 Acc 0.9719428571428571, AUC 0.496826708316803, avg_entr 0.002495135646313429
ep18_l4_test_time 2.3418524265289307
gc 0
Train Epoch19 Acc 0.9926339285714286 (555875/560000), AUC 0.998809814453125
ep19_train_time 154.2067368030548
Test Epoch19 layer0 Acc 0.9654, AUC 0.49871858954429626, avg_entr 0.02695208042860031
ep19_l0_test_time 0.6818370819091797
Test Epoch19 layer1 Acc 0.9718571428571429, AUC 0.49768295884132385, avg_entr 0.004798763431608677
ep19_l1_test_time 1.117034912109375
Test Epoch19 layer2 Acc 0.9714285714285714, AUC 0.4973852038383484, avg_entr 0.0030704368837177753
ep19_l2_test_time 1.5404846668243408
Test Epoch19 layer3 Acc 0.9712571428571428, AUC 0.49714088439941406, avg_entr 0.0026122045237571
ep19_l3_test_time 1.928208351135254
Test Epoch19 layer4 Acc 0.9712571428571428, AUC 0.4968332350254059, avg_entr 0.002347340574488044
ep19_l4_test_time 2.2974541187286377
gc 0
Train Epoch20 Acc 0.9927089285714286 (555917/560000), AUC 0.9988176226615906
ep20_train_time 153.45938110351562
Test Epoch20 layer0 Acc 0.9654, AUC 0.4987238347530365, avg_entr 0.026847388595342636
ep20_l0_test_time 0.7002546787261963
Test Epoch20 layer1 Acc 0.9722285714285714, AUC 0.4977538287639618, avg_entr 0.004838445223867893
ep20_l1_test_time 1.119854211807251
Test Epoch20 layer2 Acc 0.9718285714285714, AUC 0.49747681617736816, avg_entr 0.003165191737934947
ep20_l2_test_time 1.550074577331543
Test Epoch20 layer3 Acc 0.9719428571428571, AUC 0.49717918038368225, avg_entr 0.0026406387332826853
ep20_l3_test_time 1.9235637187957764
Test Epoch20 layer4 Acc 0.9720285714285715, AUC 0.4969373047351837, avg_entr 0.002458818955346942
ep20_l4_test_time 2.313535451889038
gc 0
Train Epoch21 Acc 0.992875 (556010/560000), AUC 0.9988560080528259
ep21_train_time 153.47284579277039
Test Epoch21 layer0 Acc 0.9651142857142857, AUC 0.4987204968929291, avg_entr 0.026905449107289314
ep21_l0_test_time 0.7068724632263184
Test Epoch21 layer1 Acc 0.9719714285714286, AUC 0.4976978898048401, avg_entr 0.004832085222005844
ep21_l1_test_time 1.160921335220337
Test Epoch21 layer2 Acc 0.9713142857142857, AUC 0.49734750390052795, avg_entr 0.0030601073522120714
ep21_l2_test_time 1.531360149383545
Test Epoch21 layer3 Acc 0.9712857142857143, AUC 0.49709710478782654, avg_entr 0.0024649272672832012
ep21_l3_test_time 1.915250301361084
Test Epoch21 layer4 Acc 0.9712571428571428, AUC 0.4967504143714905, avg_entr 0.0022228118032217026
ep21_l4_test_time 2.333986282348633
gc 0
Train Epoch22 Acc 0.9929035714285714 (556026/560000), AUC 0.9988504648208618
ep22_train_time 154.26294898986816
Test Epoch22 layer0 Acc 0.9653714285714285, AUC 0.4987204670906067, avg_entr 0.02683001197874546
ep22_l0_test_time 0.6848361492156982
Test Epoch22 layer1 Acc 0.9723142857142857, AUC 0.4977095425128937, avg_entr 0.00476237665861845
ep22_l1_test_time 1.1702795028686523
Test Epoch22 layer2 Acc 0.9720857142857143, AUC 0.4973796010017395, avg_entr 0.003113364102318883
ep22_l2_test_time 1.54081392288208
Test Epoch22 layer3 Acc 0.9719714285714286, AUC 0.497124582529068, avg_entr 0.0025165248662233353
ep22_l3_test_time 1.9400444030761719
Test Epoch22 layer4 Acc 0.972, AUC 0.49677518010139465, avg_entr 0.00227674120105803
ep22_l4_test_time 2.389274835586548
gc 0
Train Epoch23 Acc 0.9929625 (556059/560000), AUC 0.9988245368003845
ep23_train_time 154.64839839935303
Test Epoch23 layer0 Acc 0.9652857142857143, AUC 0.4987199604511261, avg_entr 0.026831336319446564
ep23_l0_test_time 0.6886529922485352
Test Epoch23 layer1 Acc 0.9723428571428572, AUC 0.497739315032959, avg_entr 0.004714552313089371
ep23_l1_test_time 1.108198642730713
Test Epoch23 layer2 Acc 0.9721428571428572, AUC 0.4973759651184082, avg_entr 0.0030415330547839403
ep23_l2_test_time 1.5517535209655762
Test Epoch23 layer3 Acc 0.9722, AUC 0.4971681237220764, avg_entr 0.002554366597905755
ep23_l3_test_time 1.9279975891113281
Test Epoch23 layer4 Acc 0.972, AUC 0.4968855082988739, avg_entr 0.002345600165426731
ep23_l4_test_time 2.3012466430664062
gc 0
Train Epoch24 Acc 0.9929928571428571 (556076/560000), AUC 0.9988554120063782
ep24_train_time 153.6978566646576
Test Epoch24 layer0 Acc 0.9651714285714286, AUC 0.49872007966041565, avg_entr 0.026989543810486794
ep24_l0_test_time 0.6906445026397705
Test Epoch24 layer1 Acc 0.9719428571428571, AUC 0.49770593643188477, avg_entr 0.004814147017896175
ep24_l1_test_time 1.1478617191314697
Test Epoch24 layer2 Acc 0.9716, AUC 0.49732735753059387, avg_entr 0.0032243970781564713
ep24_l2_test_time 1.5565564632415771
Test Epoch24 layer3 Acc 0.9715428571428572, AUC 0.4971185326576233, avg_entr 0.0027954864781349897
ep24_l3_test_time 1.9216091632843018
Test Epoch24 layer4 Acc 0.9716285714285714, AUC 0.496869295835495, avg_entr 0.0024757329374551773
ep24_l4_test_time 2.336881637573242
gc 0
Train Epoch25 Acc 0.9930446428571429 (556105/560000), AUC 0.9988447427749634
ep25_train_time 154.18647599220276
Test Epoch25 layer0 Acc 0.9654571428571429, AUC 0.49872106313705444, avg_entr 0.02683747187256813
ep25_l0_test_time 0.7050433158874512
Test Epoch25 layer1 Acc 0.9722285714285714, AUC 0.4977334141731262, avg_entr 0.004793091211467981
ep25_l1_test_time 1.178968906402588
Test Epoch25 layer2 Acc 0.9720285714285715, AUC 0.4974055886268616, avg_entr 0.0031087365932762623
ep25_l2_test_time 1.559180498123169
Test Epoch25 layer3 Acc 0.972, AUC 0.4971749186515808, avg_entr 0.0026580002158880234
ep25_l3_test_time 1.9655237197875977
Test Epoch25 layer4 Acc 0.9721428571428572, AUC 0.4968978762626648, avg_entr 0.0023982462007552385
ep25_l4_test_time 2.352877140045166
gc 0
Train Epoch26 Acc 0.99305 (556108/560000), AUC 0.9988550543785095
ep26_train_time 154.54578638076782
Test Epoch26 layer0 Acc 0.9653428571428572, AUC 0.49872133135795593, avg_entr 0.02684512548148632
ep26_l0_test_time 0.6906909942626953
Test Epoch26 layer1 Acc 0.9724857142857143, AUC 0.4977060854434967, avg_entr 0.0047732084058225155
ep26_l1_test_time 1.1168501377105713
Test Epoch26 layer2 Acc 0.9720857142857143, AUC 0.49734458327293396, avg_entr 0.0030419277027249336
ep26_l2_test_time 1.5562820434570312
Test Epoch26 layer3 Acc 0.9720285714285715, AUC 0.49711665511131287, avg_entr 0.002555728191509843
ep26_l3_test_time 1.9215593338012695
Test Epoch26 layer4 Acc 0.9721428571428572, AUC 0.49678659439086914, avg_entr 0.0022907943930476904
ep26_l4_test_time 2.3219048976898193
gc 0
Train Epoch27 Acc 0.9931160714285714 (556145/560000), AUC 0.9988649487495422
ep27_train_time 154.2080135345459
Test Epoch27 layer0 Acc 0.9652285714285714, AUC 0.49871963262557983, avg_entr 0.02687809057533741
ep27_l0_test_time 0.6905386447906494
Test Epoch27 layer1 Acc 0.9722, AUC 0.4977096617221832, avg_entr 0.00476608332246542
ep27_l1_test_time 1.1174414157867432
Test Epoch27 layer2 Acc 0.9720285714285715, AUC 0.49730873107910156, avg_entr 0.0031333966180682182
ep27_l2_test_time 1.5503346920013428
Test Epoch27 layer3 Acc 0.972, AUC 0.4971592426300049, avg_entr 0.0026086457073688507
ep27_l3_test_time 1.9267666339874268
Test Epoch27 layer4 Acc 0.9720571428571428, AUC 0.49681708216667175, avg_entr 0.002342779655009508
ep27_l4_test_time 2.3884692192077637
gc 0
Train Epoch28 Acc 0.9931107142857143 (556142/560000), AUC 0.9988589286804199
ep28_train_time 154.41442275047302
Test Epoch28 layer0 Acc 0.9650857142857143, AUC 0.4987185597419739, avg_entr 0.02685360237956047
ep28_l0_test_time 0.7004969120025635
Test Epoch28 layer1 Acc 0.9723714285714286, AUC 0.49772128462791443, avg_entr 0.004777032416313887
ep28_l1_test_time 1.1946017742156982
Test Epoch28 layer2 Acc 0.9719714285714286, AUC 0.49733445048332214, avg_entr 0.003017583629116416
ep28_l2_test_time 1.5557141304016113
Test Epoch28 layer3 Acc 0.972, AUC 0.49710559844970703, avg_entr 0.0025113390292972326
ep28_l3_test_time 2.0172414779663086
Test Epoch28 layer4 Acc 0.9720571428571428, AUC 0.4967202842235565, avg_entr 0.0022902190685272217
ep28_l4_test_time 2.385838508605957
gc 0
Train Epoch29 Acc 0.9931285714285715 (556152/560000), AUC 0.9988599419593811
ep29_train_time 154.2992799282074
Test Epoch29 layer0 Acc 0.9653428571428572, AUC 0.49872025847435, avg_entr 0.02687801979482174
ep29_l0_test_time 0.6875307559967041
Test Epoch29 layer1 Acc 0.9722, AUC 0.497709721326828, avg_entr 0.004779480863362551
ep29_l1_test_time 1.132490873336792
Test Epoch29 layer2 Acc 0.9719428571428571, AUC 0.49733254313468933, avg_entr 0.003089173464104533
ep29_l2_test_time 1.5375518798828125
Test Epoch29 layer3 Acc 0.9717714285714286, AUC 0.49713045358657837, avg_entr 0.0025685764849185944
ep29_l3_test_time 1.9785265922546387
Test Epoch29 layer4 Acc 0.9718285714285714, AUC 0.4967997074127197, avg_entr 0.002325661713257432
ep29_l4_test_time 2.436856985092163
gc 0
Train Epoch30 Acc 0.9930821428571428 (556126/560000), AUC 0.998829185962677
ep30_train_time 154.49239015579224
Test Epoch30 layer0 Acc 0.9653428571428572, AUC 0.4987200200557709, avg_entr 0.026843925938010216
ep30_l0_test_time 0.6845855712890625
Test Epoch30 layer1 Acc 0.9723142857142857, AUC 0.4977093040943146, avg_entr 0.00478271534666419
ep30_l1_test_time 1.135549783706665
Test Epoch30 layer2 Acc 0.9719714285714286, AUC 0.49734506011009216, avg_entr 0.00311041297391057
ep30_l2_test_time 1.5901188850402832
Test Epoch30 layer3 Acc 0.9718571428571429, AUC 0.49713045358657837, avg_entr 0.0025404717307537794
ep30_l3_test_time 1.993114948272705
Test Epoch30 layer4 Acc 0.9718857142857142, AUC 0.49675846099853516, avg_entr 0.00226983823813498
ep30_l4_test_time 2.370089530944824
gc 0
Train Epoch31 Acc 0.9931178571428572 (556146/560000), AUC 0.9988278746604919
ep31_train_time 154.55073070526123
Test Epoch31 layer0 Acc 0.9652, AUC 0.49872058629989624, avg_entr 0.026883073151111603
ep31_l0_test_time 0.6936864852905273
Test Epoch31 layer1 Acc 0.9724, AUC 0.49771806597709656, avg_entr 0.004785045515745878
ep31_l1_test_time 1.1335134506225586
Test Epoch31 layer2 Acc 0.972, AUC 0.4973483979701996, avg_entr 0.003102098358795047
ep31_l2_test_time 1.5426924228668213
Test Epoch31 layer3 Acc 0.9718, AUC 0.49710530042648315, avg_entr 0.002581255277618766
ep31_l3_test_time 1.946692943572998
Test Epoch31 layer4 Acc 0.9718571428571429, AUC 0.49674198031425476, avg_entr 0.0023409442510455847
ep31_l4_test_time 2.3691182136535645
gc 0
Train Epoch32 Acc 0.9931571428571428 (556168/560000), AUC 0.9988466501235962
ep32_train_time 154.71980595588684
Test Epoch32 layer0 Acc 0.9651142857142857, AUC 0.49871963262557983, avg_entr 0.02680934965610504
ep32_l0_test_time 0.6980900764465332
Test Epoch32 layer1 Acc 0.9723428571428572, AUC 0.4977179169654846, avg_entr 0.004770936444401741
ep32_l1_test_time 1.1201951503753662
Test Epoch32 layer2 Acc 0.9720285714285715, AUC 0.4973282516002655, avg_entr 0.003048341954126954
ep32_l2_test_time 1.546252965927124
Test Epoch32 layer3 Acc 0.9719428571428571, AUC 0.4970780313014984, avg_entr 0.002558107255026698
ep32_l3_test_time 1.9177656173706055
Test Epoch32 layer4 Acc 0.972, AUC 0.4967074990272522, avg_entr 0.002301364904269576
ep32_l4_test_time 2.3499577045440674
gc 0
Train Epoch33 Acc 0.9932107142857143 (556198/560000), AUC 0.9988889694213867
ep33_train_time 154.41393208503723
Test Epoch33 layer0 Acc 0.9653428571428572, AUC 0.49871984124183655, avg_entr 0.026850951835513115
ep33_l0_test_time 0.7067079544067383
Test Epoch33 layer1 Acc 0.9723714285714286, AUC 0.49770399928092957, avg_entr 0.004782358184456825
ep33_l1_test_time 1.1564791202545166
Test Epoch33 layer2 Acc 0.9718285714285714, AUC 0.4973269999027252, avg_entr 0.003100928384810686
ep33_l2_test_time 1.5481507778167725
Test Epoch33 layer3 Acc 0.9718285714285714, AUC 0.49708202481269836, avg_entr 0.0025567617267370224
ep33_l3_test_time 1.91756272315979
Test Epoch33 layer4 Acc 0.9718285714285714, AUC 0.4967428147792816, avg_entr 0.0023109859321266413
ep33_l4_test_time 2.3268041610717773
gc 0
Train Epoch34 Acc 0.99315 (556164/560000), AUC 0.9988419413566589
ep34_train_time 154.3460750579834
Test Epoch34 layer0 Acc 0.9652, AUC 0.4987201690673828, avg_entr 0.026860002428293228
ep34_l0_test_time 0.6981768608093262
Test Epoch34 layer1 Acc 0.9723428571428572, AUC 0.4977071285247803, avg_entr 0.004780265502631664
ep34_l1_test_time 1.139695644378662
Test Epoch34 layer2 Acc 0.9719142857142857, AUC 0.49729734659194946, avg_entr 0.003059911308810115
ep34_l2_test_time 1.5472545623779297
Test Epoch34 layer3 Acc 0.9717142857142858, AUC 0.49707213044166565, avg_entr 0.00253771198913455
ep34_l3_test_time 1.9264495372772217
Test Epoch34 layer4 Acc 0.9717714285714286, AUC 0.49672451615333557, avg_entr 0.0023008272983133793
ep34_l4_test_time 2.3496155738830566
gc 0
Train Epoch35 Acc 0.9931803571428571 (556181/560000), AUC 0.9988493919372559
ep35_train_time 154.29389119148254
Test Epoch35 layer0 Acc 0.9652285714285714, AUC 0.4987199008464813, avg_entr 0.02684147283434868
ep35_l0_test_time 0.7022504806518555
Test Epoch35 layer1 Acc 0.9723142857142857, AUC 0.49769964814186096, avg_entr 0.0047811777330935
ep35_l1_test_time 1.1086723804473877
Test Epoch35 layer2 Acc 0.9718857142857142, AUC 0.4973077178001404, avg_entr 0.003084935247898102
ep35_l2_test_time 1.5550363063812256
Test Epoch35 layer3 Acc 0.9717142857142858, AUC 0.4970877766609192, avg_entr 0.002545751165598631
ep35_l3_test_time 1.9269015789031982
Test Epoch35 layer4 Acc 0.9717428571428571, AUC 0.4967788755893707, avg_entr 0.0022948964033275843
ep35_l4_test_time 2.333110809326172
gc 0
Train Epoch36 Acc 0.9932107142857143 (556198/560000), AUC 0.9988486170768738
ep36_train_time 154.35676407814026
Test Epoch36 layer0 Acc 0.9652285714285714, AUC 0.49872031807899475, avg_entr 0.026870867237448692
ep36_l0_test_time 0.6862630844116211
Test Epoch36 layer1 Acc 0.9723428571428572, AUC 0.49770021438598633, avg_entr 0.0047885961830616
ep36_l1_test_time 1.1060268878936768
Test Epoch36 layer2 Acc 0.9719142857142857, AUC 0.49732938408851624, avg_entr 0.0030699344351887703
ep36_l2_test_time 1.547454833984375
Test Epoch36 layer3 Acc 0.9717714285714286, AUC 0.49708014726638794, avg_entr 0.002528488403186202
ep36_l3_test_time 1.9292027950286865
Test Epoch36 layer4 Acc 0.9718285714285714, AUC 0.4967481195926666, avg_entr 0.002278683241456747
ep36_l4_test_time 2.335996627807617
gc 0
Train Epoch37 Acc 0.9931857142857143 (556184/560000), AUC 0.9988357424736023
ep37_train_time 154.3467240333557
Test Epoch37 layer0 Acc 0.9652571428571428, AUC 0.49871984124183655, avg_entr 0.02686767280101776
ep37_l0_test_time 0.6916882991790771
Test Epoch37 layer1 Acc 0.9723428571428572, AUC 0.4977090358734131, avg_entr 0.004785278346389532
ep37_l1_test_time 1.1246840953826904
Test Epoch37 layer2 Acc 0.972, AUC 0.4973174035549164, avg_entr 0.0030677595641463995
ep37_l2_test_time 1.5428807735443115
Test Epoch37 layer3 Acc 0.9717142857142858, AUC 0.49707990884780884, avg_entr 0.002532408107072115
ep37_l3_test_time 1.932715654373169
Test Epoch37 layer4 Acc 0.9717428571428571, AUC 0.4967363774776459, avg_entr 0.0022883291821926832
ep37_l4_test_time 2.333244800567627
gc 0
Train Epoch38 Acc 0.9932089285714286 (556197/560000), AUC 0.9988359808921814
ep38_train_time 154.56474614143372
Test Epoch38 layer0 Acc 0.9651714285714286, AUC 0.4987196922302246, avg_entr 0.026855245232582092
ep38_l0_test_time 0.7052276134490967
Test Epoch38 layer1 Acc 0.9723142857142857, AUC 0.4977029263973236, avg_entr 0.004785592667758465
ep38_l1_test_time 1.1567749977111816
Test Epoch38 layer2 Acc 0.9719142857142857, AUC 0.4973176121711731, avg_entr 0.0030751805752515793
ep38_l2_test_time 1.563659429550171
Test Epoch38 layer3 Acc 0.9718, AUC 0.4970859885215759, avg_entr 0.002531936625018716
ep38_l3_test_time 1.9847328662872314
Test Epoch38 layer4 Acc 0.9717428571428571, AUC 0.49674299359321594, avg_entr 0.002277681138366461
ep38_l4_test_time 2.36431622505188
gc 0
Train Epoch39 Acc 0.9932196428571428 (556203/560000), AUC 0.9988453984260559
ep39_train_time 154.5510697364807
Test Epoch39 layer0 Acc 0.9652285714285714, AUC 0.4987199008464813, avg_entr 0.02686486206948757
ep39_l0_test_time 0.7059483528137207
Test Epoch39 layer1 Acc 0.9723428571428572, AUC 0.49770674109458923, avg_entr 0.004784258082509041
ep39_l1_test_time 1.121570348739624
Test Epoch39 layer2 Acc 0.9719714285714286, AUC 0.4973239600658417, avg_entr 0.003066473873332143
ep39_l2_test_time 1.5340166091918945
Test Epoch39 layer3 Acc 0.9717428571428571, AUC 0.4970753490924835, avg_entr 0.002528199227526784
ep39_l3_test_time 1.9227430820465088
Test Epoch39 layer4 Acc 0.9717714285714286, AUC 0.49674415588378906, avg_entr 0.002275963546708226
ep39_l4_test_time 2.330930471420288
gc 0
Train Epoch40 Acc 0.9932196428571428 (556203/560000), AUC 0.9988747239112854
ep40_train_time 154.75471782684326
Test Epoch40 layer0 Acc 0.9652571428571428, AUC 0.4987204074859619, avg_entr 0.026833439245820045
ep40_l0_test_time 0.6899673938751221
Test Epoch40 layer1 Acc 0.9723714285714286, AUC 0.4977048337459564, avg_entr 0.004786876030266285
ep40_l1_test_time 1.2077884674072266
Test Epoch40 layer2 Acc 0.972, AUC 0.49731776118278503, avg_entr 0.0030674536246806383
ep40_l2_test_time 1.5613582134246826
Test Epoch40 layer3 Acc 0.9717428571428571, AUC 0.4970739483833313, avg_entr 0.0025286092422902584
ep40_l3_test_time 1.9168064594268799
Test Epoch40 layer4 Acc 0.9717428571428571, AUC 0.49675577878952026, avg_entr 0.0022735814563930035
ep40_l4_test_time 2.3504273891448975
gc 0
Train Epoch41 Acc 0.9932053571428572 (556195/560000), AUC 0.9988501667976379
ep41_train_time 154.81724381446838
Test Epoch41 layer0 Acc 0.9652285714285714, AUC 0.4987200200557709, avg_entr 0.02685551717877388
ep41_l0_test_time 0.6861310005187988
Test Epoch41 layer1 Acc 0.9723714285714286, AUC 0.4977031350135803, avg_entr 0.004788751248270273
ep41_l1_test_time 1.1413121223449707
Test Epoch41 layer2 Acc 0.972, AUC 0.49732306599617004, avg_entr 0.0030734266620129347
ep41_l2_test_time 1.5369219779968262
Test Epoch41 layer3 Acc 0.9717428571428571, AUC 0.4970855414867401, avg_entr 0.002533928956836462
ep41_l3_test_time 1.9201042652130127
Test Epoch41 layer4 Acc 0.9717428571428571, AUC 0.49675726890563965, avg_entr 0.0022816541604697704
ep41_l4_test_time 2.3205552101135254
gc 0
Train Epoch42 Acc 0.9931839285714286 (556183/560000), AUC 0.9988577961921692
ep42_train_time 154.5193555355072
Test Epoch42 layer0 Acc 0.9652285714285714, AUC 0.49872007966041565, avg_entr 0.026850340887904167
ep42_l0_test_time 0.7034056186676025
Test Epoch42 layer1 Acc 0.9723714285714286, AUC 0.49770164489746094, avg_entr 0.004789706785231829
ep42_l1_test_time 1.126685619354248
Test Epoch42 layer2 Acc 0.9719714285714286, AUC 0.49732187390327454, avg_entr 0.0030678955372422934
ep42_l2_test_time 1.5390806198120117
Test Epoch42 layer3 Acc 0.9717714285714286, AUC 0.4970811903476715, avg_entr 0.002527744509279728
ep42_l3_test_time 1.9224708080291748
Test Epoch42 layer4 Acc 0.9717428571428571, AUC 0.49675044417381287, avg_entr 0.0022711241617798805
ep42_l4_test_time 2.33566951751709
gc 0
Train Epoch43 Acc 0.9932357142857143 (556212/560000), AUC 0.9988344311714172
ep43_train_time 154.55405497550964
Test Epoch43 layer0 Acc 0.9652285714285714, AUC 0.4987199902534485, avg_entr 0.02684413455426693
ep43_l0_test_time 0.6819474697113037
Test Epoch43 layer1 Acc 0.9723714285714286, AUC 0.49770548939704895, avg_entr 0.004787788726389408
ep43_l1_test_time 1.1101796627044678
Test Epoch43 layer2 Acc 0.9719714285714286, AUC 0.49732324481010437, avg_entr 0.0030715507455170155
ep43_l2_test_time 1.5985112190246582
Test Epoch43 layer3 Acc 0.9717714285714286, AUC 0.4970812201499939, avg_entr 0.002529104007408023
ep43_l3_test_time 1.9283952713012695
Test Epoch43 layer4 Acc 0.9717428571428571, AUC 0.49675440788269043, avg_entr 0.002271387493237853
ep43_l4_test_time 2.350076198577881
gc 0
Train Epoch44 Acc 0.9932160714285714 (556201/560000), AUC 0.9988616108894348
ep44_train_time 154.6154112815857
Test Epoch44 layer0 Acc 0.9652285714285714, AUC 0.4987199902534485, avg_entr 0.026848042383790016
ep44_l0_test_time 0.6924500465393066
Test Epoch44 layer1 Acc 0.9724285714285714, AUC 0.49770522117614746, avg_entr 0.004787369165569544
ep44_l1_test_time 1.1086528301239014
Test Epoch44 layer2 Acc 0.9719428571428571, AUC 0.4973240792751312, avg_entr 0.003069514874368906
ep44_l2_test_time 1.5384149551391602
Test Epoch44 layer3 Acc 0.9717428571428571, AUC 0.49707716703414917, avg_entr 0.0025276506785303354
ep44_l3_test_time 1.9181771278381348
Test Epoch44 layer4 Acc 0.9717428571428571, AUC 0.49675115942955017, avg_entr 0.0022689199540764093
ep44_l4_test_time 2.3351621627807617
gc 0
Train Epoch45 Acc 0.9932678571428571 (556230/560000), AUC 0.9988595843315125
ep45_train_time 154.5794336795807
Test Epoch45 layer0 Acc 0.9652857142857143, AUC 0.4987199008464813, avg_entr 0.026856141164898872
ep45_l0_test_time 0.7050211429595947
Test Epoch45 layer1 Acc 0.9724, AUC 0.4977051317691803, avg_entr 0.004787660203874111
ep45_l1_test_time 1.163649082183838
Test Epoch45 layer2 Acc 0.9719714285714286, AUC 0.49732303619384766, avg_entr 0.003068831516429782
ep45_l2_test_time 1.5391244888305664
Test Epoch45 layer3 Acc 0.9717428571428571, AUC 0.497077614068985, avg_entr 0.0025273228529840708
ep45_l3_test_time 1.9312386512756348
Test Epoch45 layer4 Acc 0.9717714285714286, AUC 0.49674275517463684, avg_entr 0.0022695395164191723
ep45_l4_test_time 2.3469045162200928
gc 0
Train Epoch46 Acc 0.99325 (556220/560000), AUC 0.9988352060317993
ep46_train_time 154.9435474872589
Test Epoch46 layer0 Acc 0.9652857142857143, AUC 0.4987199008464813, avg_entr 0.02685258537530899
ep46_l0_test_time 0.6886041164398193
Test Epoch46 layer1 Acc 0.9724, AUC 0.4977058470249176, avg_entr 0.004787921439856291
ep46_l1_test_time 1.1352663040161133
Test Epoch46 layer2 Acc 0.972, AUC 0.49732181429862976, avg_entr 0.0030691898427903652
ep46_l2_test_time 1.5505187511444092
Test Epoch46 layer3 Acc 0.9717428571428571, AUC 0.49707746505737305, avg_entr 0.0025282802525907755
ep46_l3_test_time 1.978144645690918
Test Epoch46 layer4 Acc 0.9717714285714286, AUC 0.49674192070961, avg_entr 0.0022715218365192413
ep46_l4_test_time 2.367095708847046
gc 0
Train Epoch47 Acc 0.9932 (556192/560000), AUC 0.9988263249397278
ep47_train_time 155.12066888809204
Test Epoch47 layer0 Acc 0.9652571428571428, AUC 0.4987199008464813, avg_entr 0.026855573058128357
ep47_l0_test_time 0.7054932117462158
Test Epoch47 layer1 Acc 0.9724, AUC 0.49770504236221313, avg_entr 0.004787679761648178
ep47_l1_test_time 1.1368329524993896
Test Epoch47 layer2 Acc 0.9719714285714286, AUC 0.4973216950893402, avg_entr 0.0030681348871439695
ep47_l2_test_time 1.5593397617340088
Test Epoch47 layer3 Acc 0.9717428571428571, AUC 0.4970792233943939, avg_entr 0.0025271663907915354
ep47_l3_test_time 1.9643750190734863
Test Epoch47 layer4 Acc 0.9717714285714286, AUC 0.4967444837093353, avg_entr 0.002269194694235921
ep47_l4_test_time 2.3439998626708984
gc 0
Train Epoch48 Acc 0.9932125 (556199/560000), AUC 0.9988316893577576
ep48_train_time 154.98137402534485
Test Epoch48 layer0 Acc 0.9652857142857143, AUC 0.4987197816371918, avg_entr 0.026856375858187675
ep48_l0_test_time 0.7047910690307617
Test Epoch48 layer1 Acc 0.9724, AUC 0.49770402908325195, avg_entr 0.004788672085851431
ep48_l1_test_time 1.1881647109985352
Test Epoch48 layer2 Acc 0.972, AUC 0.4973200857639313, avg_entr 0.0030714289750903845
ep48_l2_test_time 1.5481681823730469
Test Epoch48 layer3 Acc 0.9717428571428571, AUC 0.49707895517349243, avg_entr 0.002530193654820323
ep48_l3_test_time 1.9923934936523438
Test Epoch48 layer4 Acc 0.9717142857142858, AUC 0.4967433512210846, avg_entr 0.002272981218993664
ep48_l4_test_time 2.3453688621520996
gc 0
Train Epoch49 Acc 0.9931857142857143 (556184/560000), AUC 0.9988327622413635
ep49_train_time 154.9355583190918
Test Epoch49 layer0 Acc 0.9652571428571428, AUC 0.4987199008464813, avg_entr 0.02685798704624176
ep49_l0_test_time 0.7271866798400879
Test Epoch49 layer1 Acc 0.9724, AUC 0.49770355224609375, avg_entr 0.004788905847817659
ep49_l1_test_time 1.150892972946167
Test Epoch49 layer2 Acc 0.9719714285714286, AUC 0.4973175823688507, avg_entr 0.0030710906721651554
ep49_l2_test_time 1.5452990531921387
Test Epoch49 layer3 Acc 0.9717428571428571, AUC 0.49707695841789246, avg_entr 0.0025299922563135624
ep49_l3_test_time 1.9320693016052246
Test Epoch49 layer4 Acc 0.9717428571428571, AUC 0.49674350023269653, avg_entr 0.002272607060149312
ep49_l4_test_time 2.343878984451294
Best AUC 0.4987356662750244
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train+valid_time 8102.6884870529175
Start Testing
Load ckpt at ckpt/dbpedia_14_transformeral_l5_pad60//dbpedia_14_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.9841714285714286, AUC 0.49960198998451233, avg_entr 0.01928022876381874
ep49_l0_test_time 0.6918127536773682
Test Epoch49 layer1 Acc 0.987, AUC 0.49921661615371704, avg_entr 0.002850897144526243
ep49_l1_test_time 1.116515874862671
Test Epoch49 layer2 Acc 0.9869142857142857, AUC 0.4991624057292938, avg_entr 0.001792282797396183
ep49_l2_test_time 1.5731990337371826
Test Epoch49 layer3 Acc 0.9868571428571429, AUC 0.4990955889225006, avg_entr 0.0015199558110907674
ep49_l3_test_time 1.9304168224334717
Test Epoch49 layer4 Acc 0.9868285714285714, AUC 0.4990597665309906, avg_entr 0.0013446151278913021
ep49_l4_test_time 2.4012503623962402
