total count words 887881
vocab size 30000
train size 560000, valid size 35000, test size 35000
found 28354 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=14, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=14, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 1792
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 1792
layers.0.ae.h.0.bias 14
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13674862
init_time 54.91313147544861
Start Training
gc 0
Train Epoch0 Acc 0.8267696428571428 (462991/560000), AUC 0.9784919023513794
ep0_train_time 80.90140628814697
Test Epoch0 layer0 Acc 0.9742, AUC 0.9984525442123413, avg_entr 0.0684276893734932
ep0_l0_test_time 0.39814090728759766
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad20//dbpedia_14_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.9722, AUC 0.9981756806373596, avg_entr 0.03682570531964302
ep0_l1_test_time 0.5509481430053711
Test Epoch0 layer2 Acc 0.9719142857142857, AUC 0.9977974891662598, avg_entr 0.02831314131617546
ep0_l2_test_time 0.7011690139770508
Test Epoch0 layer3 Acc 0.972, AUC 0.9976243376731873, avg_entr 0.02464853785932064
ep0_l3_test_time 0.8526313304901123
Test Epoch0 layer4 Acc 0.9716571428571429, AUC 0.9974960684776306, avg_entr 0.022777134552598
ep0_l4_test_time 1.013852596282959
gc 0
Train Epoch1 Acc 0.9785482142857143 (547987/560000), AUC 0.9973907470703125
ep1_train_time 79.77362942695618
Test Epoch1 layer0 Acc 0.9742571428571428, AUC 0.9985685348510742, avg_entr 0.03692226856946945
ep1_l0_test_time 0.3945622444152832
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad20//dbpedia_14_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.9767142857142858, AUC 0.99797123670578, avg_entr 0.011194886639714241
ep1_l1_test_time 0.5511400699615479
Test Epoch1 layer2 Acc 0.9766285714285714, AUC 0.99786776304245, avg_entr 0.00776224210858345
ep1_l2_test_time 0.7065794467926025
Test Epoch1 layer3 Acc 0.9767428571428571, AUC 0.997813880443573, avg_entr 0.006564049050211906
ep1_l3_test_time 0.8736264705657959
Test Epoch1 layer4 Acc 0.9767142857142858, AUC 0.9975976943969727, avg_entr 0.0060446304269135
ep1_l4_test_time 1.0234012603759766
gc 0
Train Epoch2 Acc 0.9828160714285714 (550377/560000), AUC 0.9977442622184753
ep2_train_time 79.31435656547546
Test Epoch2 layer0 Acc 0.9753428571428572, AUC 0.9985621571540833, avg_entr 0.02655022032558918
ep2_l0_test_time 0.3837594985961914
Test Epoch2 layer1 Acc 0.9776285714285714, AUC 0.9976305365562439, avg_entr 0.006931292358785868
ep2_l1_test_time 0.5513279438018799
Test Epoch2 layer2 Acc 0.9775714285714285, AUC 0.9976508021354675, avg_entr 0.004726733546704054
ep2_l2_test_time 0.6988604068756104
Test Epoch2 layer3 Acc 0.9775428571428572, AUC 0.9975582361221313, avg_entr 0.003966986667364836
ep2_l3_test_time 0.8627667427062988
Test Epoch2 layer4 Acc 0.9775142857142857, AUC 0.9969748854637146, avg_entr 0.0035544447600841522
ep2_l4_test_time 1.0576045513153076
gc 0
Train Epoch3 Acc 0.984675 (551418/560000), AUC 0.9979276061058044
ep3_train_time 79.60446429252625
Test Epoch3 layer0 Acc 0.9749142857142857, AUC 0.9985866546630859, avg_entr 0.021152183413505554
ep3_l0_test_time 0.38290905952453613
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad20//dbpedia_14_transformeral_l5.pt  ,ep 3
Test Epoch3 layer1 Acc 0.9782285714285714, AUC 0.9976204633712769, avg_entr 0.005110991653054953
ep3_l1_test_time 0.5523550510406494
Test Epoch3 layer2 Acc 0.9780285714285715, AUC 0.9975563287734985, avg_entr 0.0034838817082345486
ep3_l2_test_time 0.7044050693511963
Test Epoch3 layer3 Acc 0.9779714285714286, AUC 0.9973320364952087, avg_entr 0.002881963737308979
ep3_l3_test_time 0.8639929294586182
Test Epoch3 layer4 Acc 0.9781142857142857, AUC 0.996573269367218, avg_entr 0.0025000092573463917
ep3_l4_test_time 1.0494778156280518
gc 0
Train Epoch4 Acc 0.9861017857142858 (552217/560000), AUC 0.9980059862136841
ep4_train_time 79.45029091835022
Test Epoch4 layer0 Acc 0.9754, AUC 0.9985869526863098, avg_entr 0.019755123183131218
ep4_l0_test_time 0.3824014663696289
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad20//dbpedia_14_transformeral_l5.pt  ,ep 4
Test Epoch4 layer1 Acc 0.9786285714285714, AUC 0.9972882866859436, avg_entr 0.004679113160818815
ep4_l1_test_time 0.5513567924499512
Test Epoch4 layer2 Acc 0.9792571428571428, AUC 0.9974358677864075, avg_entr 0.002983770566061139
ep4_l2_test_time 0.7014331817626953
Test Epoch4 layer3 Acc 0.979, AUC 0.9972161054611206, avg_entr 0.002619450446218252
ep4_l3_test_time 0.8909754753112793
Test Epoch4 layer4 Acc 0.9792285714285714, AUC 0.9962396621704102, avg_entr 0.0023657309357076883
ep4_l4_test_time 1.0200812816619873
gc 0
Train Epoch5 Acc 0.9872696428571428 (552871/560000), AUC 0.9982870817184448
ep5_train_time 79.20060157775879
Test Epoch5 layer0 Acc 0.9748857142857142, AUC 0.9985836744308472, avg_entr 0.01946067065000534
ep5_l0_test_time 0.38419580459594727
Test Epoch5 layer1 Acc 0.9786857142857143, AUC 0.9972882866859436, avg_entr 0.004107844550162554
ep5_l1_test_time 0.553368330001831
Test Epoch5 layer2 Acc 0.9782857142857143, AUC 0.9972143769264221, avg_entr 0.0025162880774587393
ep5_l2_test_time 0.701279878616333
Test Epoch5 layer3 Acc 0.9783714285714286, AUC 0.9968788027763367, avg_entr 0.0022504902444779873
ep5_l3_test_time 0.8708348274230957
Test Epoch5 layer4 Acc 0.9782857142857143, AUC 0.9958787560462952, avg_entr 0.0019867760129272938
ep5_l4_test_time 1.074131727218628
gc 0
Train Epoch6 Acc 0.9884767857142858 (553547/560000), AUC 0.9986047744750977
ep6_train_time 79.62742924690247
Test Epoch6 layer0 Acc 0.9752571428571428, AUC 0.9986311793327332, avg_entr 0.01884322427213192
ep6_l0_test_time 0.3905162811279297
Save ckpt to ckpt/dbpedia_14_transformeral_l5_pad20//dbpedia_14_transformeral_l5.pt  ,ep 6
Test Epoch6 layer1 Acc 0.9785428571428572, AUC 0.9970177412033081, avg_entr 0.004173372872173786
ep6_l1_test_time 0.5579025745391846
Test Epoch6 layer2 Acc 0.9786, AUC 0.9971296191215515, avg_entr 0.0027049104683101177
ep6_l2_test_time 0.7100751399993896
Test Epoch6 layer3 Acc 0.9786285714285714, AUC 0.9969359636306763, avg_entr 0.002323609311133623
ep6_l3_test_time 0.862166166305542
Test Epoch6 layer4 Acc 0.9787142857142858, AUC 0.9956417083740234, avg_entr 0.0020691044628620148
ep6_l4_test_time 1.0040481090545654
gc 0
Train Epoch7 Acc 0.9889482142857143 (553811/560000), AUC 0.9986233711242676
ep7_train_time 79.62025022506714
Test Epoch7 layer0 Acc 0.9752571428571428, AUC 0.9986103773117065, avg_entr 0.01882418431341648
ep7_l0_test_time 0.38387036323547363
Test Epoch7 layer1 Acc 0.9784857142857143, AUC 0.9971261024475098, avg_entr 0.004305486101657152
ep7_l1_test_time 0.5480668544769287
Test Epoch7 layer2 Acc 0.9781428571428571, AUC 0.9972324371337891, avg_entr 0.0028094779700040817
ep7_l2_test_time 0.6994781494140625
Test Epoch7 layer3 Acc 0.9783428571428572, AUC 0.9968476891517639, avg_entr 0.002462751464918256
ep7_l3_test_time 0.8793954849243164
Test Epoch7 layer4 Acc 0.9783714285714286, AUC 0.9955620169639587, avg_entr 0.002173539251089096
ep7_l4_test_time 1.0208330154418945
gc 0
Train Epoch8 Acc 0.9895446428571428 (554145/560000), AUC 0.9986189007759094
ep8_train_time 79.39397096633911
Test Epoch8 layer0 Acc 0.9750571428571428, AUC 0.9986093640327454, avg_entr 0.018897810950875282
ep8_l0_test_time 0.38589024543762207
Test Epoch8 layer1 Acc 0.9789428571428571, AUC 0.9966469407081604, avg_entr 0.004010212607681751
ep8_l1_test_time 0.5450348854064941
Test Epoch8 layer2 Acc 0.9788, AUC 0.996488094329834, avg_entr 0.0027413531206548214
ep8_l2_test_time 0.7000532150268555
Test Epoch8 layer3 Acc 0.9787428571428571, AUC 0.9958320260047913, avg_entr 0.0023505163844674826
ep8_l3_test_time 0.8767533302307129
Test Epoch8 layer4 Acc 0.9786285714285714, AUC 0.994993269443512, avg_entr 0.002082805149257183
ep8_l4_test_time 1.0411443710327148
gc 0
Train Epoch9 Acc 0.9899428571428571 (554368/560000), AUC 0.99868243932724
ep9_train_time 79.29477334022522
Test Epoch9 layer0 Acc 0.9752, AUC 0.9985917806625366, avg_entr 0.01881665736436844
ep9_l0_test_time 0.38315248489379883
Test Epoch9 layer1 Acc 0.9782857142857143, AUC 0.9966763257980347, avg_entr 0.004166256170719862
ep9_l1_test_time 0.5502128601074219
Test Epoch9 layer2 Acc 0.9782571428571428, AUC 0.9965267777442932, avg_entr 0.002681385725736618
ep9_l2_test_time 0.7065927982330322
Test Epoch9 layer3 Acc 0.9782285714285714, AUC 0.996343731880188, avg_entr 0.0023038173094391823
ep9_l3_test_time 0.865833044052124
Test Epoch9 layer4 Acc 0.9782571428571428, AUC 0.9952555894851685, avg_entr 0.0020541613921523094
ep9_l4_test_time 1.0269851684570312
gc 0
Train Epoch10 Acc 0.990625 (554750/560000), AUC 0.9987257719039917
ep10_train_time 80.42918133735657
Test Epoch10 layer0 Acc 0.9754, AUC 0.9986031651496887, avg_entr 0.018532469868659973
ep10_l0_test_time 0.38262033462524414
Test Epoch10 layer1 Acc 0.9782857142857143, AUC 0.9967208504676819, avg_entr 0.004161353223025799
ep10_l1_test_time 0.5486936569213867
Test Epoch10 layer2 Acc 0.9782571428571428, AUC 0.9966797828674316, avg_entr 0.002629987196996808
ep10_l2_test_time 0.7095580101013184
Test Epoch10 layer3 Acc 0.9783428571428572, AUC 0.9963222742080688, avg_entr 0.002236083149909973
ep10_l3_test_time 0.8733479976654053
Test Epoch10 layer4 Acc 0.9784285714285714, AUC 0.9950553774833679, avg_entr 0.0019890402909368277
ep10_l4_test_time 1.0291383266448975
gc 0
Train Epoch11 Acc 0.9908589285714285 (554881/560000), AUC 0.9987106323242188
ep11_train_time 79.62260818481445
Test Epoch11 layer0 Acc 0.9753142857142857, AUC 0.998630702495575, avg_entr 0.018350867554545403
ep11_l0_test_time 0.38461756706237793
Test Epoch11 layer1 Acc 0.9784285714285714, AUC 0.9966384768486023, avg_entr 0.0038950233720242977
ep11_l1_test_time 0.5512347221374512
Test Epoch11 layer2 Acc 0.9781714285714286, AUC 0.9966133236885071, avg_entr 0.0022919310722500086
ep11_l2_test_time 0.6973917484283447
Test Epoch11 layer3 Acc 0.9784, AUC 0.9962942004203796, avg_entr 0.001914727734401822
ep11_l3_test_time 0.8560731410980225
Test Epoch11 layer4 Acc 0.9785142857142857, AUC 0.9951985478401184, avg_entr 0.0017531575867906213
ep11_l4_test_time 1.0280237197875977
gc 0
Train Epoch12 Acc 0.9910607142857143 (554994/560000), AUC 0.9987358450889587
ep12_train_time 79.16593408584595
Test Epoch12 layer0 Acc 0.9753428571428572, AUC 0.9986229538917542, avg_entr 0.018370937556028366
ep12_l0_test_time 0.3814888000488281
Test Epoch12 layer1 Acc 0.9784857142857143, AUC 0.9965581297874451, avg_entr 0.004002186935395002
ep12_l1_test_time 0.5448644161224365
Test Epoch12 layer2 Acc 0.9780285714285715, AUC 0.996407151222229, avg_entr 0.0024099138099700212
ep12_l2_test_time 0.6944551467895508
Test Epoch12 layer3 Acc 0.9781428571428571, AUC 0.9961246252059937, avg_entr 0.002013130346313119
ep12_l3_test_time 0.8692779541015625
Test Epoch12 layer4 Acc 0.9780857142857143, AUC 0.9948522448539734, avg_entr 0.0017296787118539214
ep12_l4_test_time 1.0280404090881348
gc 0
Train Epoch13 Acc 0.9914125 (555191/560000), AUC 0.9987652897834778
ep13_train_time 80.41569828987122
Test Epoch13 layer0 Acc 0.9752857142857143, AUC 0.998619556427002, avg_entr 0.018455440178513527
ep13_l0_test_time 0.383408784866333
Test Epoch13 layer1 Acc 0.9785142857142857, AUC 0.9964562058448792, avg_entr 0.003882944118231535
ep13_l1_test_time 0.5545783042907715
Test Epoch13 layer2 Acc 0.9783714285714286, AUC 0.9964293241500854, avg_entr 0.002358827041462064
ep13_l2_test_time 0.7049925327301025
Test Epoch13 layer3 Acc 0.9784285714285714, AUC 0.996063768863678, avg_entr 0.0018318239599466324
ep13_l3_test_time 0.8644475936889648
Test Epoch13 layer4 Acc 0.9784571428571428, AUC 0.994988739490509, avg_entr 0.001640003058128059
ep13_l4_test_time 1.0303466320037842
gc 0
Train Epoch14 Acc 0.9917071428571429 (555356/560000), AUC 0.9987573027610779
ep14_train_time 79.45381760597229
Test Epoch14 layer0 Acc 0.9753142857142857, AUC 0.9986151456832886, avg_entr 0.018454659730196
ep14_l0_test_time 0.38343071937561035
Test Epoch14 layer1 Acc 0.9784571428571428, AUC 0.9964376091957092, avg_entr 0.004037649370729923
ep14_l1_test_time 0.5490751266479492
Test Epoch14 layer2 Acc 0.9778285714285714, AUC 0.9961640238761902, avg_entr 0.0024336266797035933
ep14_l2_test_time 0.7077693939208984
Test Epoch14 layer3 Acc 0.9777714285714286, AUC 0.9958009123802185, avg_entr 0.00202497118152678
ep14_l3_test_time 0.8708655834197998
Test Epoch14 layer4 Acc 0.9778, AUC 0.9946407675743103, avg_entr 0.0018552145920693874
ep14_l4_test_time 1.0228631496429443
gc 0
Train Epoch15 Acc 0.9918392857142857 (555430/560000), AUC 0.9987807273864746
ep15_train_time 79.26380038261414
Test Epoch15 layer0 Acc 0.9754, AUC 0.9986138939857483, avg_entr 0.018358726054430008
ep15_l0_test_time 0.38231635093688965
Test Epoch15 layer1 Acc 0.9783714285714286, AUC 0.9963522553443909, avg_entr 0.003814790630713105
ep15_l1_test_time 0.549034595489502
Test Epoch15 layer2 Acc 0.9782285714285714, AUC 0.9961771965026855, avg_entr 0.0023295751307159662
ep15_l2_test_time 0.7032785415649414
Test Epoch15 layer3 Acc 0.9784285714285714, AUC 0.9958381056785583, avg_entr 0.0019267373718321323
ep15_l3_test_time 0.8569674491882324
Test Epoch15 layer4 Acc 0.9783714285714286, AUC 0.994593620300293, avg_entr 0.0017375590978190303
ep15_l4_test_time 1.0307536125183105
gc 0
Train Epoch16 Acc 0.9919446428571429 (555489/560000), AUC 0.9988015294075012
ep16_train_time 79.39218521118164
Test Epoch16 layer0 Acc 0.9754285714285714, AUC 0.9986168742179871, avg_entr 0.018434863537549973
ep16_l0_test_time 0.37982892990112305
Test Epoch16 layer1 Acc 0.9784571428571428, AUC 0.9963659644126892, avg_entr 0.003820707555860281
ep16_l1_test_time 0.5479271411895752
Test Epoch16 layer2 Acc 0.9782571428571428, AUC 0.9960355758666992, avg_entr 0.0023338617756962776
ep16_l2_test_time 0.6961066722869873
Test Epoch16 layer3 Acc 0.9782285714285714, AUC 0.9958006739616394, avg_entr 0.00186779978685081
ep16_l3_test_time 0.8649969100952148
Test Epoch16 layer4 Acc 0.9782571428571428, AUC 0.9946542978286743, avg_entr 0.0016955472528934479
ep16_l4_test_time 1.0409047603607178
gc 0
Train Epoch17 Acc 0.9920589285714285 (555553/560000), AUC 0.9987837672233582
ep17_train_time 79.31951117515564
Test Epoch17 layer0 Acc 0.9752, AUC 0.9986191987991333, avg_entr 0.018497373908758163
ep17_l0_test_time 0.38193392753601074
Test Epoch17 layer1 Acc 0.9782, AUC 0.996330201625824, avg_entr 0.003834282513707876
ep17_l1_test_time 0.5481946468353271
Test Epoch17 layer2 Acc 0.9780571428571428, AUC 0.9960513710975647, avg_entr 0.002448959741741419
ep17_l2_test_time 0.6983473300933838
Test Epoch17 layer3 Acc 0.9780285714285715, AUC 0.9958080649375916, avg_entr 0.0020231117960065603
ep17_l3_test_time 0.8863270282745361
Test Epoch17 layer4 Acc 0.978, AUC 0.9943747520446777, avg_entr 0.001806817133910954
ep17_l4_test_time 1.0226860046386719
gc 0
Train Epoch18 Acc 0.9922875 (555681/560000), AUC 0.9987989664077759
ep18_train_time 80.22384095191956
Test Epoch18 layer0 Acc 0.9752571428571428, AUC 0.998616635799408, avg_entr 0.018345817923545837
ep18_l0_test_time 0.38209962844848633
Test Epoch18 layer1 Acc 0.9783142857142857, AUC 0.996336042881012, avg_entr 0.0038175720255821943
ep18_l1_test_time 0.5514984130859375
Test Epoch18 layer2 Acc 0.9779714285714286, AUC 0.9960988163948059, avg_entr 0.0024739219807088375
ep18_l2_test_time 0.707679033279419
Test Epoch18 layer3 Acc 0.9780857142857143, AUC 0.9957519769668579, avg_entr 0.00199448736384511
ep18_l3_test_time 0.8809683322906494
Test Epoch18 layer4 Acc 0.9779714285714286, AUC 0.9944877624511719, avg_entr 0.0018591430271044374
ep18_l4_test_time 1.0241971015930176
gc 0
Train Epoch19 Acc 0.9923571428571428 (555720/560000), AUC 0.9987923502922058
ep19_train_time 80.76015257835388
Test Epoch19 layer0 Acc 0.9753142857142857, AUC 0.9986129403114319, avg_entr 0.018366120755672455
ep19_l0_test_time 0.3804788589477539
Test Epoch19 layer1 Acc 0.9780571428571428, AUC 0.996272087097168, avg_entr 0.0037468147929757833
ep19_l1_test_time 0.5462982654571533
Test Epoch19 layer2 Acc 0.9777142857142858, AUC 0.9960060715675354, avg_entr 0.002309325849637389
ep19_l2_test_time 0.700817346572876
Test Epoch19 layer3 Acc 0.9778571428571429, AUC 0.9957945942878723, avg_entr 0.001860094373114407
ep19_l3_test_time 0.8575799465179443
Test Epoch19 layer4 Acc 0.9778571428571429, AUC 0.9944227933883667, avg_entr 0.001694010104984045
ep19_l4_test_time 1.0264763832092285
gc 0
Train Epoch20 Acc 0.9923589285714286 (555721/560000), AUC 0.9987921714782715
ep20_train_time 79.81074857711792
Test Epoch20 layer0 Acc 0.9752857142857143, AUC 0.9986116290092468, avg_entr 0.018280765041708946
ep20_l0_test_time 0.3847062587738037
Test Epoch20 layer1 Acc 0.9780571428571428, AUC 0.9962193369865417, avg_entr 0.0037405265029519796
ep20_l1_test_time 0.5446429252624512
Test Epoch20 layer2 Acc 0.9779428571428571, AUC 0.9958595037460327, avg_entr 0.002252034144476056
ep20_l2_test_time 0.7021112442016602
Test Epoch20 layer3 Acc 0.9779142857142857, AUC 0.9956662058830261, avg_entr 0.001878428622148931
ep20_l3_test_time 0.8839786052703857
Test Epoch20 layer4 Acc 0.9778285714285714, AUC 0.9943432807922363, avg_entr 0.001701650326140225
ep20_l4_test_time 1.0635225772857666
gc 0
Train Epoch21 Acc 0.9924982142857143 (555799/560000), AUC 0.9988031983375549
ep21_train_time 80.45497369766235
Test Epoch21 layer0 Acc 0.9752857142857143, AUC 0.9986127614974976, avg_entr 0.018334737047553062
ep21_l0_test_time 0.3832721710205078
Test Epoch21 layer1 Acc 0.9780857142857143, AUC 0.9963094592094421, avg_entr 0.0037392708472907543
ep21_l1_test_time 0.5491769313812256
Test Epoch21 layer2 Acc 0.9780571428571428, AUC 0.9960423111915588, avg_entr 0.0023436422925442457
ep21_l2_test_time 0.7008810043334961
Test Epoch21 layer3 Acc 0.9779714285714286, AUC 0.9957370162010193, avg_entr 0.0019240303663536906
ep21_l3_test_time 0.9288432598114014
Test Epoch21 layer4 Acc 0.9778857142857142, AUC 0.9945975542068481, avg_entr 0.0017724517965689301
ep21_l4_test_time 1.0437119007110596
gc 0
Train Epoch22 Acc 0.9925464285714286 (555826/560000), AUC 0.9988119006156921
ep22_train_time 79.43062567710876
Test Epoch22 layer0 Acc 0.9753142857142857, AUC 0.9986158013343811, avg_entr 0.018334679305553436
ep22_l0_test_time 0.38077354431152344
Test Epoch22 layer1 Acc 0.9779714285714286, AUC 0.9963151812553406, avg_entr 0.0037735500372946262
ep22_l1_test_time 0.5507991313934326
Test Epoch22 layer2 Acc 0.9777428571428571, AUC 0.9960373044013977, avg_entr 0.0023457668721675873
ep22_l2_test_time 0.7028844356536865
Test Epoch22 layer3 Acc 0.9777714285714286, AUC 0.9957062005996704, avg_entr 0.001897513633593917
ep22_l3_test_time 0.8631443977355957
Test Epoch22 layer4 Acc 0.9777428571428571, AUC 0.9943751692771912, avg_entr 0.001737134181894362
ep22_l4_test_time 1.0435686111450195
gc 0
Train Epoch23 Acc 0.9926196428571429 (555867/560000), AUC 0.9988498687744141
ep23_train_time 79.16245150566101
Test Epoch23 layer0 Acc 0.9753428571428572, AUC 0.9986153244972229, avg_entr 0.01833254098892212
ep23_l0_test_time 0.38027381896972656
Test Epoch23 layer1 Acc 0.9778571428571429, AUC 0.9962655305862427, avg_entr 0.0037248830776661634
ep23_l1_test_time 0.5499210357666016
Test Epoch23 layer2 Acc 0.978, AUC 0.9959380030632019, avg_entr 0.0022029047831892967
ep23_l2_test_time 0.7048876285552979
Test Epoch23 layer3 Acc 0.9778857142857142, AUC 0.9957138895988464, avg_entr 0.0018013310618698597
ep23_l3_test_time 0.8706767559051514
Test Epoch23 layer4 Acc 0.9779142857142857, AUC 0.994471549987793, avg_entr 0.0016381448367610574
ep23_l4_test_time 1.0222761631011963
gc 0
Train Epoch24 Acc 0.9926892857142857 (555906/560000), AUC 0.9988284111022949
ep24_train_time 79.63259649276733
Test Epoch24 layer0 Acc 0.9751142857142857, AUC 0.9986084699630737, avg_entr 0.018309054896235466
ep24_l0_test_time 0.37989354133605957
Test Epoch24 layer1 Acc 0.9779428571428571, AUC 0.9962437748908997, avg_entr 0.003729324322193861
ep24_l1_test_time 0.5446162223815918
Test Epoch24 layer2 Acc 0.9777142857142858, AUC 0.995970606803894, avg_entr 0.0023064292035996914
ep24_l2_test_time 0.6968138217926025
Test Epoch24 layer3 Acc 0.9776857142857143, AUC 0.9956282377243042, avg_entr 0.001875163521617651
ep24_l3_test_time 0.8694803714752197
Test Epoch24 layer4 Acc 0.9777714285714286, AUC 0.9943488240242004, avg_entr 0.0016920993803068995
ep24_l4_test_time 1.02815842628479
gc 0
Train Epoch25 Acc 0.99275 (555940/560000), AUC 0.998814582824707
ep25_train_time 79.79126143455505
Test Epoch25 layer0 Acc 0.9752857142857143, AUC 0.998615562915802, avg_entr 0.01831849478185177
ep25_l0_test_time 0.3829004764556885
Test Epoch25 layer1 Acc 0.9778571428571429, AUC 0.9962540864944458, avg_entr 0.003716453444212675
ep25_l1_test_time 0.5577318668365479
Test Epoch25 layer2 Acc 0.9777714285714286, AUC 0.9959129691123962, avg_entr 0.002307754009962082
ep25_l2_test_time 0.7091574668884277
Test Epoch25 layer3 Acc 0.9777428571428571, AUC 0.9956895112991333, avg_entr 0.0018162928754463792
ep25_l3_test_time 0.8598721027374268
Test Epoch25 layer4 Acc 0.9777428571428571, AUC 0.9943298101425171, avg_entr 0.0016297631664201617
ep25_l4_test_time 1.0103960037231445
gc 0
Train Epoch26 Acc 0.9927178571428571 (555922/560000), AUC 0.9988528490066528
ep26_train_time 80.80407762527466
Test Epoch26 layer0 Acc 0.9752571428571428, AUC 0.9986129999160767, avg_entr 0.018302887678146362
ep26_l0_test_time 0.38192176818847656
Test Epoch26 layer1 Acc 0.9782285714285714, AUC 0.9962496161460876, avg_entr 0.003714845050126314
ep26_l1_test_time 0.5733709335327148
Test Epoch26 layer2 Acc 0.9777714285714286, AUC 0.9958944320678711, avg_entr 0.0023050641175359488
ep26_l2_test_time 0.7028708457946777
Test Epoch26 layer3 Acc 0.978, AUC 0.9955734610557556, avg_entr 0.0018114774720743299
ep26_l3_test_time 0.8593301773071289
Test Epoch26 layer4 Acc 0.9778857142857142, AUC 0.994368851184845, avg_entr 0.001629661419428885
ep26_l4_test_time 1.0395503044128418
gc 0
Train Epoch27 Acc 0.9927875 (555961/560000), AUC 0.9988343119621277
ep27_train_time 79.61176323890686
Test Epoch27 layer0 Acc 0.9753142857142857, AUC 0.9986129403114319, avg_entr 0.018301496282219887
ep27_l0_test_time 0.3833889961242676
Test Epoch27 layer1 Acc 0.978, AUC 0.996256411075592, avg_entr 0.003716630395501852
ep27_l1_test_time 0.5493791103363037
Test Epoch27 layer2 Acc 0.9779714285714286, AUC 0.9958949089050293, avg_entr 0.002351495437324047
ep27_l2_test_time 0.7067222595214844
Test Epoch27 layer3 Acc 0.9778285714285714, AUC 0.9955659508705139, avg_entr 0.0019089695997536182
ep27_l3_test_time 0.8941066265106201
Test Epoch27 layer4 Acc 0.9777714285714286, AUC 0.994325578212738, avg_entr 0.0017063822597265244
ep27_l4_test_time 1.0204923152923584
gc 0
Train Epoch28 Acc 0.9927535714285715 (555942/560000), AUC 0.9988219141960144
ep28_train_time 79.70286250114441
Test Epoch28 layer0 Acc 0.9753428571428572, AUC 0.9986147284507751, avg_entr 0.018312757834792137
ep28_l0_test_time 0.38455986976623535
Test Epoch28 layer1 Acc 0.9779142857142857, AUC 0.9962438941001892, avg_entr 0.0037293387576937675
ep28_l1_test_time 0.5511882305145264
Test Epoch28 layer2 Acc 0.9778285714285714, AUC 0.9958680868148804, avg_entr 0.002347033005207777
ep28_l2_test_time 0.7085838317871094
Test Epoch28 layer3 Acc 0.9778, AUC 0.9955117106437683, avg_entr 0.0018825688166543841
ep28_l3_test_time 0.8797895908355713
Test Epoch28 layer4 Acc 0.9777428571428571, AUC 0.9942482113838196, avg_entr 0.0017194789834320545
ep28_l4_test_time 1.024855136871338
gc 0
Train Epoch29 Acc 0.992825 (555982/560000), AUC 0.9988387227058411
ep29_train_time 79.21013975143433
Test Epoch29 layer0 Acc 0.9752857142857143, AUC 0.9986130595207214, avg_entr 0.018314644694328308
ep29_l0_test_time 0.38151097297668457
Test Epoch29 layer1 Acc 0.9780857142857143, AUC 0.9962267279624939, avg_entr 0.003720272332429886
ep29_l1_test_time 0.5468606948852539
Test Epoch29 layer2 Acc 0.9778285714285714, AUC 0.9958497285842896, avg_entr 0.002319183200597763
ep29_l2_test_time 0.7050216197967529
Test Epoch29 layer3 Acc 0.9777714285714286, AUC 0.995569109916687, avg_entr 0.0018641641363501549
ep29_l3_test_time 0.875964879989624
Test Epoch29 layer4 Acc 0.9776285714285714, AUC 0.9942705035209656, avg_entr 0.0016715015517547727
ep29_l4_test_time 1.0267267227172852
gc 0
Train Epoch30 Acc 0.9928107142857143 (555974/560000), AUC 0.9988559484481812
ep30_train_time 79.73440098762512
Test Epoch30 layer0 Acc 0.9752857142857143, AUC 0.9986132979393005, avg_entr 0.018325181677937508
ep30_l0_test_time 0.3859827518463135
Test Epoch30 layer1 Acc 0.978, AUC 0.996231734752655, avg_entr 0.0037098221946507692
ep30_l1_test_time 0.5514583587646484
Test Epoch30 layer2 Acc 0.9779428571428571, AUC 0.9958487749099731, avg_entr 0.002331357216462493
ep30_l2_test_time 0.712660551071167
Test Epoch30 layer3 Acc 0.9777142857142858, AUC 0.9955582618713379, avg_entr 0.0018896405817940831
ep30_l3_test_time 0.8606805801391602
Test Epoch30 layer4 Acc 0.9777428571428571, AUC 0.994216799736023, avg_entr 0.0016968229319900274
ep30_l4_test_time 1.0145800113677979
gc 0
Train Epoch31 Acc 0.9928142857142858 (555976/560000), AUC 0.9988368153572083
ep31_train_time 80.04322457313538
Test Epoch31 layer0 Acc 0.9752571428571428, AUC 0.998613178730011, avg_entr 0.018302151933312416
ep31_l0_test_time 0.39111328125
Test Epoch31 layer1 Acc 0.9779428571428571, AUC 0.9962244629859924, avg_entr 0.0037169833667576313
ep31_l1_test_time 0.5522089004516602
Test Epoch31 layer2 Acc 0.9778857142857142, AUC 0.9958691000938416, avg_entr 0.0023301064502447844
ep31_l2_test_time 0.7042298316955566
Test Epoch31 layer3 Acc 0.9777714285714286, AUC 0.9955747723579407, avg_entr 0.00187100435141474
ep31_l3_test_time 1.0549795627593994
Test Epoch31 layer4 Acc 0.9777428571428571, AUC 0.9942335486412048, avg_entr 0.0016675249207764864
ep31_l4_test_time 1.0770070552825928
gc 0
Train Epoch32 Acc 0.9928196428571429 (555979/560000), AUC 0.9988324046134949
ep32_train_time 79.67364573478699
Test Epoch32 layer0 Acc 0.9752571428571428, AUC 0.9986135363578796, avg_entr 0.018321823328733444
ep32_l0_test_time 0.3817007541656494
Test Epoch32 layer1 Acc 0.9780571428571428, AUC 0.9962224960327148, avg_entr 0.003688178723677993
ep32_l1_test_time 0.5516927242279053
Test Epoch32 layer2 Acc 0.9779428571428571, AUC 0.9958092570304871, avg_entr 0.0023187543265521526
ep32_l2_test_time 0.7034080028533936
Test Epoch32 layer3 Acc 0.9778857142857142, AUC 0.9955205917358398, avg_entr 0.0018560712924227118
ep32_l3_test_time 0.8540334701538086
Test Epoch32 layer4 Acc 0.9778571428571429, AUC 0.9942144751548767, avg_entr 0.0016349024372175336
ep32_l4_test_time 1.024003505706787
gc 0
Train Epoch33 Acc 0.9928392857142857 (555990/560000), AUC 0.9988389015197754
ep33_train_time 79.48876905441284
Test Epoch33 layer0 Acc 0.9752857142857143, AUC 0.9986132979393005, avg_entr 0.018316155299544334
ep33_l0_test_time 0.39028358459472656
Test Epoch33 layer1 Acc 0.9780571428571428, AUC 0.9962162971496582, avg_entr 0.0036990251392126083
ep33_l1_test_time 0.5429162979125977
Test Epoch33 layer2 Acc 0.9779142857142857, AUC 0.9958142638206482, avg_entr 0.002294166712090373
ep33_l2_test_time 0.6938316822052002
Test Epoch33 layer3 Acc 0.9779428571428571, AUC 0.99558025598526, avg_entr 0.0018257948104292154
ep33_l3_test_time 0.8635847568511963
Test Epoch33 layer4 Acc 0.9779428571428571, AUC 0.9942514300346375, avg_entr 0.0016206379514187574
ep33_l4_test_time 1.0367982387542725
gc 0
Train Epoch34 Acc 0.9928714285714285 (556008/560000), AUC 0.9988393783569336
ep34_train_time 79.81895685195923
Test Epoch34 layer0 Acc 0.9752285714285714, AUC 0.998613178730011, avg_entr 0.01832580380141735
ep34_l0_test_time 0.3828456401824951
Test Epoch34 layer1 Acc 0.9780285714285715, AUC 0.9962164759635925, avg_entr 0.0036978446878492832
ep34_l1_test_time 0.5435981750488281
Test Epoch34 layer2 Acc 0.9778857142857142, AUC 0.9958237409591675, avg_entr 0.0022965697571635246
ep34_l2_test_time 0.7000269889831543
Test Epoch34 layer3 Acc 0.9778285714285714, AUC 0.9955738186836243, avg_entr 0.001848169369623065
ep34_l3_test_time 0.873100996017456
Test Epoch34 layer4 Acc 0.9778285714285714, AUC 0.9942265748977661, avg_entr 0.0016487736720591784
ep34_l4_test_time 1.0247342586517334
gc 0
Train Epoch35 Acc 0.9928428571428571 (555992/560000), AUC 0.9988423585891724
ep35_train_time 78.93367981910706
Test Epoch35 layer0 Acc 0.9752571428571428, AUC 0.9986127614974976, avg_entr 0.01831960119307041
ep35_l0_test_time 0.380373477935791
Test Epoch35 layer1 Acc 0.978, AUC 0.9962161183357239, avg_entr 0.00369637506082654
ep35_l1_test_time 0.5545413494110107
Test Epoch35 layer2 Acc 0.9779142857142857, AUC 0.9958196878433228, avg_entr 0.0022919904440641403
ep35_l2_test_time 0.7113757133483887
Test Epoch35 layer3 Acc 0.9778571428571429, AUC 0.9955540895462036, avg_entr 0.001855196082033217
ep35_l3_test_time 0.8726420402526855
Test Epoch35 layer4 Acc 0.9778571428571429, AUC 0.9942482709884644, avg_entr 0.0016388188814744353
ep35_l4_test_time 1.0704824924468994
gc 0
Train Epoch36 Acc 0.9928553571428571 (555999/560000), AUC 0.9988228678703308
ep36_train_time 79.45527672767639
Test Epoch36 layer0 Acc 0.9752285714285714, AUC 0.9986127018928528, avg_entr 0.01832706667482853
ep36_l0_test_time 0.38141632080078125
Test Epoch36 layer1 Acc 0.9780571428571428, AUC 0.9962124824523926, avg_entr 0.0036968423519283533
ep36_l1_test_time 0.5523169040679932
Test Epoch36 layer2 Acc 0.9779428571428571, AUC 0.9957872629165649, avg_entr 0.002298579551279545
ep36_l2_test_time 0.7532250881195068
Test Epoch36 layer3 Acc 0.9778285714285714, AUC 0.9955146908760071, avg_entr 0.0018593876156955957
ep36_l3_test_time 0.8621814250946045
Test Epoch36 layer4 Acc 0.9778285714285714, AUC 0.9941973686218262, avg_entr 0.001633564825169742
ep36_l4_test_time 1.0300171375274658
gc 0
Train Epoch37 Acc 0.9928553571428571 (555999/560000), AUC 0.9988530874252319
ep37_train_time 80.27695155143738
Test Epoch37 layer0 Acc 0.9752571428571428, AUC 0.9986128211021423, avg_entr 0.018313350155949593
ep37_l0_test_time 0.38139939308166504
Test Epoch37 layer1 Acc 0.9780571428571428, AUC 0.996208131313324, avg_entr 0.003693182719871402
ep37_l1_test_time 0.5433762073516846
Test Epoch37 layer2 Acc 0.978, AUC 0.9957942962646484, avg_entr 0.0022941550705581903
ep37_l2_test_time 0.7034087181091309
Test Epoch37 layer3 Acc 0.9778857142857142, AUC 0.9955156445503235, avg_entr 0.0018546447390690446
ep37_l3_test_time 0.9114372730255127
Test Epoch37 layer4 Acc 0.9778285714285714, AUC 0.9941958785057068, avg_entr 0.0016357892891392112
ep37_l4_test_time 1.0188868045806885
gc 0
Train Epoch38 Acc 0.9928446428571429 (555993/560000), AUC 0.9988546371459961
ep38_train_time 79.67415070533752
Test Epoch38 layer0 Acc 0.9752857142857143, AUC 0.9986127018928528, avg_entr 0.01831773854792118
ep38_l0_test_time 0.38098978996276855
Test Epoch38 layer1 Acc 0.9780571428571428, AUC 0.9962040781974792, avg_entr 0.0036956816911697388
ep38_l1_test_time 0.554919958114624
Test Epoch38 layer2 Acc 0.9779428571428571, AUC 0.9958090782165527, avg_entr 0.0022901573684066534
ep38_l2_test_time 0.7099051475524902
Test Epoch38 layer3 Acc 0.9778571428571429, AUC 0.9955362677574158, avg_entr 0.0018538541626185179
ep38_l3_test_time 0.8633348941802979
Test Epoch38 layer4 Acc 0.9778285714285714, AUC 0.9942060708999634, avg_entr 0.0016373617108911276
ep38_l4_test_time 1.0848591327667236
gc 0
Train Epoch39 Acc 0.9928732142857143 (556009/560000), AUC 0.9988255500793457
ep39_train_time 80.45632076263428
Test Epoch39 layer0 Acc 0.9752571428571428, AUC 0.9986128807067871, avg_entr 0.01832270808517933
ep39_l0_test_time 0.38182544708251953
Test Epoch39 layer1 Acc 0.978, AUC 0.996208131313324, avg_entr 0.0036945221945643425
ep39_l1_test_time 0.5526530742645264
Test Epoch39 layer2 Acc 0.9779428571428571, AUC 0.9958082437515259, avg_entr 0.0022971979342401028
ep39_l2_test_time 0.698420524597168
Test Epoch39 layer3 Acc 0.9778285714285714, AUC 0.9955347776412964, avg_entr 0.0018464390886947513
ep39_l3_test_time 0.8644635677337646
Test Epoch39 layer4 Acc 0.9778571428571429, AUC 0.9942036271095276, avg_entr 0.0016382483299821615
ep39_l4_test_time 1.0489776134490967
gc 0
Train Epoch40 Acc 0.9928839285714286 (556015/560000), AUC 0.9988278150558472
ep40_train_time 79.73103189468384
Test Epoch40 layer0 Acc 0.9752285714285714, AUC 0.9986127018928528, avg_entr 0.018322395160794258
ep40_l0_test_time 0.38464784622192383
Test Epoch40 layer1 Acc 0.978, AUC 0.9962071180343628, avg_entr 0.003692405065521598
ep40_l1_test_time 0.5587267875671387
Test Epoch40 layer2 Acc 0.9779142857142857, AUC 0.9957977533340454, avg_entr 0.0022958312183618546
ep40_l2_test_time 0.7001917362213135
Test Epoch40 layer3 Acc 0.9778, AUC 0.995528519153595, avg_entr 0.001843916717916727
ep40_l3_test_time 0.8618254661560059
Test Epoch40 layer4 Acc 0.9778285714285714, AUC 0.9941960573196411, avg_entr 0.0016326656332239509
ep40_l4_test_time 1.0244340896606445
gc 0
Train Epoch41 Acc 0.9929071428571429 (556028/560000), AUC 0.9988455772399902
ep41_train_time 80.3917510509491
Test Epoch41 layer0 Acc 0.9752857142857143, AUC 0.9986129403114319, avg_entr 0.018317097797989845
ep41_l0_test_time 0.38280367851257324
Test Epoch41 layer1 Acc 0.978, AUC 0.9962047338485718, avg_entr 0.0036926320753991604
ep41_l1_test_time 0.5485360622406006
Test Epoch41 layer2 Acc 0.9779428571428571, AUC 0.9957991242408752, avg_entr 0.0022983772214502096
ep41_l2_test_time 0.6993274688720703
Test Epoch41 layer3 Acc 0.9778285714285714, AUC 0.9955182075500488, avg_entr 0.0018449212657287717
ep41_l3_test_time 0.8717608451843262
Test Epoch41 layer4 Acc 0.9778571428571429, AUC 0.9941901564598083, avg_entr 0.0016389968805015087
ep41_l4_test_time 1.0212111473083496
gc 0
Train Epoch42 Acc 0.9928589285714285 (556001/560000), AUC 0.9988436698913574
ep42_train_time 80.4206178188324
Test Epoch42 layer0 Acc 0.9752857142857143, AUC 0.9986127614974976, avg_entr 0.01831917278468609
ep42_l0_test_time 0.38162708282470703
Test Epoch42 layer1 Acc 0.9780285714285715, AUC 0.9962033629417419, avg_entr 0.0036917305551469326
ep42_l1_test_time 0.5504388809204102
Test Epoch42 layer2 Acc 0.9779714285714286, AUC 0.9958009123802185, avg_entr 0.0022951909340918064
ep42_l2_test_time 0.7003138065338135
Test Epoch42 layer3 Acc 0.9778285714285714, AUC 0.9955349564552307, avg_entr 0.0018484449246898293
ep42_l3_test_time 0.8646862506866455
Test Epoch42 layer4 Acc 0.9778571428571429, AUC 0.9941974878311157, avg_entr 0.001638871501199901
ep42_l4_test_time 1.0383327007293701
gc 0
Train Epoch43 Acc 0.9928821428571428 (556014/560000), AUC 0.9988521337509155
ep43_train_time 79.84657025337219
Test Epoch43 layer0 Acc 0.9752857142857143, AUC 0.9986128211021423, avg_entr 0.018321247771382332
ep43_l0_test_time 0.3859684467315674
Test Epoch43 layer1 Acc 0.9780285714285715, AUC 0.9962013363838196, avg_entr 0.0036884548608213663
ep43_l1_test_time 0.5693261623382568
Test Epoch43 layer2 Acc 0.9779142857142857, AUC 0.9957991242408752, avg_entr 0.0022968121338635683
ep43_l2_test_time 0.7123639583587646
Test Epoch43 layer3 Acc 0.9778285714285714, AUC 0.9955323338508606, avg_entr 0.0018497462151572108
ep43_l3_test_time 0.8584964275360107
Test Epoch43 layer4 Acc 0.9778285714285714, AUC 0.9942037463188171, avg_entr 0.0016355859115719795
ep43_l4_test_time 1.0196380615234375
gc 0
Train Epoch44 Acc 0.9928821428571428 (556014/560000), AUC 0.998835027217865
ep44_train_time 79.85511875152588
Test Epoch44 layer0 Acc 0.9752857142857143, AUC 0.9986128211021423, avg_entr 0.018317878246307373
ep44_l0_test_time 0.38393306732177734
Test Epoch44 layer1 Acc 0.9780571428571428, AUC 0.9962015151977539, avg_entr 0.0036888252943754196
ep44_l1_test_time 0.5483410358428955
Test Epoch44 layer2 Acc 0.9779714285714286, AUC 0.9957990646362305, avg_entr 0.0022938523907214403
ep44_l2_test_time 0.7023587226867676
Test Epoch44 layer3 Acc 0.9778285714285714, AUC 0.995529055595398, avg_entr 0.0018488647183403373
ep44_l3_test_time 0.8530020713806152
Test Epoch44 layer4 Acc 0.9778285714285714, AUC 0.9941985011100769, avg_entr 0.0016354775289073586
ep44_l4_test_time 1.024244785308838
gc 0
Train Epoch45 Acc 0.9928607142857143 (556002/560000), AUC 0.9988312721252441
ep45_train_time 80.2446506023407
Test Epoch45 layer0 Acc 0.9752857142857143, AUC 0.9986127614974976, avg_entr 0.01831628754734993
ep45_l0_test_time 0.38399744033813477
Test Epoch45 layer1 Acc 0.9780571428571428, AUC 0.9962028861045837, avg_entr 0.0036888353060930967
ep45_l1_test_time 0.5536284446716309
Test Epoch45 layer2 Acc 0.9779428571428571, AUC 0.9957977533340454, avg_entr 0.002294273115694523
ep45_l2_test_time 0.7051315307617188
Test Epoch45 layer3 Acc 0.9778, AUC 0.9955211877822876, avg_entr 0.001851156004704535
ep45_l3_test_time 0.8702831268310547
Test Epoch45 layer4 Acc 0.9778, AUC 0.9941944479942322, avg_entr 0.001640617148950696
ep45_l4_test_time 1.0376534461975098
gc 0
Train Epoch46 Acc 0.9928375 (555989/560000), AUC 0.9988595843315125
ep46_train_time 79.64821076393127
Test Epoch46 layer0 Acc 0.9752857142857143, AUC 0.9986128211021423, avg_entr 0.018318455666303635
ep46_l0_test_time 0.385483980178833
Test Epoch46 layer1 Acc 0.9780285714285715, AUC 0.9962018728256226, avg_entr 0.0036878888495266438
ep46_l1_test_time 0.5487382411956787
Test Epoch46 layer2 Acc 0.9779428571428571, AUC 0.9957913756370544, avg_entr 0.002295781159773469
ep46_l2_test_time 0.7019839286804199
Test Epoch46 layer3 Acc 0.9778, AUC 0.9955220222473145, avg_entr 0.0018526751082390547
ep46_l3_test_time 0.8764824867248535
Test Epoch46 layer4 Acc 0.9778, AUC 0.9941919445991516, avg_entr 0.0016416074940934777
ep46_l4_test_time 1.0245776176452637
gc 0
Train Epoch47 Acc 0.9929089285714285 (556029/560000), AUC 0.9988570809364319
ep47_train_time 80.62664008140564
Test Epoch47 layer0 Acc 0.9752857142857143, AUC 0.9986127614974976, avg_entr 0.018317455425858498
ep47_l0_test_time 0.38358068466186523
Test Epoch47 layer1 Acc 0.9780285714285715, AUC 0.9962027668952942, avg_entr 0.0036879703402519226
ep47_l1_test_time 0.550055742263794
Test Epoch47 layer2 Acc 0.9779142857142857, AUC 0.9957923293113708, avg_entr 0.0022956947796046734
ep47_l2_test_time 0.7039401531219482
Test Epoch47 layer3 Acc 0.9778, AUC 0.9955238699913025, avg_entr 0.0018530151573941112
ep47_l3_test_time 0.8746209144592285
Test Epoch47 layer4 Acc 0.9778, AUC 0.9941908717155457, avg_entr 0.001643833122216165
ep47_l4_test_time 1.0392155647277832
gc 0
Train Epoch48 Acc 0.9929392857142857 (556046/560000), AUC 0.9988311529159546
ep48_train_time 80.7726218700409
Test Epoch48 layer0 Acc 0.9752857142857143, AUC 0.9986127018928528, avg_entr 0.018317850306630135
ep48_l0_test_time 0.38101744651794434
Test Epoch48 layer1 Acc 0.9780285714285715, AUC 0.9962015748023987, avg_entr 0.0036866331938654184
ep48_l1_test_time 0.5493776798248291
Test Epoch48 layer2 Acc 0.9778857142857142, AUC 0.9957939982414246, avg_entr 0.002295029116794467
ep48_l2_test_time 0.6961574554443359
Test Epoch48 layer3 Acc 0.9778, AUC 0.995522141456604, avg_entr 0.0018513801041990519
ep48_l3_test_time 0.8579862117767334
Test Epoch48 layer4 Acc 0.9778, AUC 0.9941889643669128, avg_entr 0.00164152798242867
ep48_l4_test_time 1.0539367198944092
gc 0
Train Epoch49 Acc 0.9928571428571429 (556000/560000), AUC 0.9988657236099243
ep49_train_time 80.60837292671204
Test Epoch49 layer0 Acc 0.9752857142857143, AUC 0.9986127614974976, avg_entr 0.018319357186555862
ep49_l0_test_time 0.38707947731018066
Test Epoch49 layer1 Acc 0.9780285714285715, AUC 0.9962010979652405, avg_entr 0.00368669256567955
ep49_l1_test_time 0.5602574348449707
Test Epoch49 layer2 Acc 0.9779142857142857, AUC 0.9957950711250305, avg_entr 0.0022946379613131285
ep49_l2_test_time 0.7091450691223145
Test Epoch49 layer3 Acc 0.9778, AUC 0.9955248236656189, avg_entr 0.001851366483606398
ep49_l3_test_time 0.8563876152038574
Test Epoch49 layer4 Acc 0.9778, AUC 0.9941891431808472, avg_entr 0.0016411093529313803
ep49_l4_test_time 1.0115480422973633
Best AUC 0.9986311793327332
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train+valid_time 4172.144226312637
Start Testing
Load ckpt at ckpt/dbpedia_14_transformeral_l5_pad20//dbpedia_14_transformeral_l5.pt
Test Epoch49 layer0 Acc 0.9746571428571429, AUC 0.9984516501426697, avg_entr 0.019393544644117355
ep49_l0_test_time 0.3808605670928955
Test Epoch49 layer1 Acc 0.9795142857142857, AUC 0.9975217580795288, avg_entr 0.004249846562743187
ep49_l1_test_time 0.5478911399841309
Test Epoch49 layer2 Acc 0.9796571428571429, AUC 0.9973253607749939, avg_entr 0.0029641056898981333
ep49_l2_test_time 0.6993353366851807
Test Epoch49 layer3 Acc 0.9795714285714285, AUC 0.9972459077835083, avg_entr 0.0025305075105279684
ep49_l3_test_time 0.8564140796661377
Test Epoch49 layer4 Acc 0.9796285714285714, AUC 0.9962253570556641, avg_entr 0.0022697187960147858
ep49_l4_test_time 1.0352346897125244
