total count words 222751
vocab size 30000
train size 40000, valid size 5000, test size 5000
found 27937 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=2, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=2, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 256
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 256
layers.0.ae.h.0.bias 2
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13671778
init_time 21.852720975875854
Start Training
gc 0
Train Epoch0 Acc 0.53795 (21518/40000), AUC 0.5481107234954834
ep0_train_time 70.81695938110352
Test Epoch0 layer0 Acc 0.8216, AUC 0.9043796062469482, avg_entr 0.49866294860839844
ep0_l0_test_time 0.4543147087097168
Save ckpt to ckpt/imdb_transformeral_l5_pad400//imdb_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.838, AUC 0.9153776168823242, avg_entr 0.34069371223449707
ep0_l1_test_time 0.9360365867614746
Save ckpt to ckpt/imdb_transformeral_l5_pad400//imdb_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.8314, AUC 0.9164872765541077, avg_entr 0.4704151451587677
ep0_l2_test_time 1.414597988128662
Save ckpt to ckpt/imdb_transformeral_l5_pad400//imdb_transformeral_l5.pt  ,ep 0
Test Epoch0 layer3 Acc 0.8282, AUC 0.9154251217842102, avg_entr 0.6008921265602112
ep0_l3_test_time 1.8849420547485352
Test Epoch0 layer4 Acc 0.835, AUC 0.9147790670394897, avg_entr 0.6797603964805603
ep0_l4_test_time 2.3625025749206543
gc 0
Train Epoch1 Acc 0.86925 (34770/40000), AUC 0.9350216388702393
ep1_train_time 70.48092436790466
Test Epoch1 layer0 Acc 0.873, AUC 0.9474647641181946, avg_entr 0.2655993700027466
ep1_l0_test_time 0.45943307876586914
Save ckpt to ckpt/imdb_transformeral_l5_pad400//imdb_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.8924, AUC 0.9561747312545776, avg_entr 0.1849740892648697
ep1_l1_test_time 0.9349825382232666
Save ckpt to ckpt/imdb_transformeral_l5_pad400//imdb_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.8894, AUC 0.9562332034111023, avg_entr 0.16038157045841217
ep1_l2_test_time 1.4093036651611328
Save ckpt to ckpt/imdb_transformeral_l5_pad400//imdb_transformeral_l5.pt  ,ep 1
Test Epoch1 layer3 Acc 0.8846, AUC 0.956314206123352, avg_entr 0.1382817029953003
ep1_l3_test_time 1.8870701789855957
Save ckpt to ckpt/imdb_transformeral_l5_pad400//imdb_transformeral_l5.pt  ,ep 1
Test Epoch1 layer4 Acc 0.8844, AUC 0.9560644626617432, avg_entr 0.12206046283245087
ep1_l4_test_time 2.3697919845581055
gc 0
Train Epoch2 Acc 0.92035 (36814/40000), AUC 0.9719609022140503
ep2_train_time 70.61317229270935
Test Epoch2 layer0 Acc 0.89, AUC 0.9558955430984497, avg_entr 0.214311420917511
ep2_l0_test_time 0.45272016525268555
Test Epoch2 layer1 Acc 0.8834, AUC 0.958290696144104, avg_entr 0.128360778093338
ep2_l1_test_time 0.9346575736999512
Save ckpt to ckpt/imdb_transformeral_l5_pad400//imdb_transformeral_l5.pt  ,ep 2
Test Epoch2 layer2 Acc 0.8894, AUC 0.9570831060409546, avg_entr 0.07848360389471054
ep2_l2_test_time 1.406517744064331
Test Epoch2 layer3 Acc 0.8888, AUC 0.9577661752700806, avg_entr 0.057726770639419556
ep2_l3_test_time 1.8866002559661865
Test Epoch2 layer4 Acc 0.8878, AUC 0.9578282833099365, avg_entr 0.05387769266963005
ep2_l4_test_time 2.3669962882995605
gc 0
Train Epoch3 Acc 0.942975 (37719/40000), AUC 0.9814200401306152
ep3_train_time 70.49472570419312
Test Epoch3 layer0 Acc 0.8968, AUC 0.9580937623977661, avg_entr 0.19066199660301208
ep3_l0_test_time 0.4511299133300781
Test Epoch3 layer1 Acc 0.889, AUC 0.9539451599121094, avg_entr 0.0772838294506073
ep3_l1_test_time 0.9368851184844971
Test Epoch3 layer2 Acc 0.8908, AUC 0.9532648324966431, avg_entr 0.04474686458706856
ep3_l2_test_time 1.4051260948181152
Test Epoch3 layer3 Acc 0.8908, AUC 0.9544656276702881, avg_entr 0.03908225893974304
ep3_l3_test_time 1.8846042156219482
Test Epoch3 layer4 Acc 0.8904, AUC 0.9546539187431335, avg_entr 0.036099132150411606
ep3_l4_test_time 2.3627963066101074
gc 0
Train Epoch4 Acc 0.952525 (38101/40000), AUC 0.9839655160903931
ep4_train_time 70.50500893592834
Test Epoch4 layer0 Acc 0.8962, AUC 0.9575830698013306, avg_entr 0.1731470674276352
ep4_l0_test_time 0.45570826530456543
Test Epoch4 layer1 Acc 0.8862, AUC 0.9504207372665405, avg_entr 0.04890744760632515
ep4_l1_test_time 0.9317734241485596
Test Epoch4 layer2 Acc 0.8856, AUC 0.9523004293441772, avg_entr 0.032495152205228806
ep4_l2_test_time 1.407520055770874
Test Epoch4 layer3 Acc 0.8858, AUC 0.9533474445343018, avg_entr 0.030764179304242134
ep4_l3_test_time 1.8834733963012695
Test Epoch4 layer4 Acc 0.8854, AUC 0.9537695646286011, avg_entr 0.028729096055030823
ep4_l4_test_time 2.361694097518921
gc 0
Train Epoch5 Acc 0.958675 (38347/40000), AUC 0.9876610040664673
ep5_train_time 70.4860463142395
Test Epoch5 layer0 Acc 0.8952, AUC 0.9561033844947815, avg_entr 0.16140224039554596
ep5_l0_test_time 0.45093798637390137
Test Epoch5 layer1 Acc 0.8846, AUC 0.9460418820381165, avg_entr 0.04264543578028679
ep5_l1_test_time 0.9320416450500488
Test Epoch5 layer2 Acc 0.885, AUC 0.9499469995498657, avg_entr 0.033193085342645645
ep5_l2_test_time 1.4087872505187988
Test Epoch5 layer3 Acc 0.8852, AUC 0.9504950046539307, avg_entr 0.031532883644104004
ep5_l3_test_time 1.8873796463012695
Test Epoch5 layer4 Acc 0.8848, AUC 0.9508528113365173, avg_entr 0.029433997347950935
ep5_l4_test_time 2.3624682426452637
gc 0
Train Epoch6 Acc 0.964225 (38569/40000), AUC 0.9893951416015625
ep6_train_time 70.49548673629761
Test Epoch6 layer0 Acc 0.8942, AUC 0.9548661112785339, avg_entr 0.1504342406988144
ep6_l0_test_time 0.4526355266571045
Test Epoch6 layer1 Acc 0.882, AUC 0.9434709548950195, avg_entr 0.035921063274145126
ep6_l1_test_time 0.9322240352630615
Test Epoch6 layer2 Acc 0.8814, AUC 0.948529064655304, avg_entr 0.030492153018712997
ep6_l2_test_time 1.4146077632904053
Test Epoch6 layer3 Acc 0.8802, AUC 0.9485915899276733, avg_entr 0.029992571100592613
ep6_l3_test_time 1.892167568206787
Test Epoch6 layer4 Acc 0.8796, AUC 0.9488346576690674, avg_entr 0.02815704606473446
ep6_l4_test_time 2.3650381565093994
gc 0
Train Epoch7 Acc 0.969325 (38773/40000), AUC 0.992047905921936
ep7_train_time 70.6594386100769
Test Epoch7 layer0 Acc 0.8916, AUC 0.9526982307434082, avg_entr 0.14127276837825775
ep7_l0_test_time 0.4527256488800049
Test Epoch7 layer1 Acc 0.8792, AUC 0.9371035099029541, avg_entr 0.031840577721595764
ep7_l1_test_time 0.9335334300994873
Test Epoch7 layer2 Acc 0.8792, AUC 0.9450471997261047, avg_entr 0.02509416453540325
ep7_l2_test_time 1.4061224460601807
Test Epoch7 layer3 Acc 0.8792, AUC 0.9457162618637085, avg_entr 0.024672554805874825
ep7_l3_test_time 1.8888347148895264
Test Epoch7 layer4 Acc 0.8794, AUC 0.946323037147522, avg_entr 0.02334091067314148
ep7_l4_test_time 2.3679189682006836
gc 0
Train Epoch8 Acc 0.97355 (38942/40000), AUC 0.9934901595115662
ep8_train_time 70.52573537826538
Test Epoch8 layer0 Acc 0.8864, AUC 0.9516622424125671, avg_entr 0.13628841936588287
ep8_l0_test_time 0.45499110221862793
Test Epoch8 layer1 Acc 0.8748, AUC 0.9333633184432983, avg_entr 0.029436416923999786
ep8_l1_test_time 0.9445929527282715
Test Epoch8 layer2 Acc 0.875, AUC 0.9422988891601562, avg_entr 0.022632669657468796
ep8_l2_test_time 1.4069206714630127
Test Epoch8 layer3 Acc 0.875, AUC 0.9436772465705872, avg_entr 0.021873418241739273
ep8_l3_test_time 1.8813092708587646
Test Epoch8 layer4 Acc 0.875, AUC 0.9445229768753052, avg_entr 0.02045385353267193
ep8_l4_test_time 2.3605122566223145
gc 0
Train Epoch9 Acc 0.974975 (38999/40000), AUC 0.9936251640319824
ep9_train_time 70.47751975059509
Test Epoch9 layer0 Acc 0.8808, AUC 0.9498182535171509, avg_entr 0.13792721927165985
ep9_l0_test_time 0.4571564197540283
Test Epoch9 layer1 Acc 0.874, AUC 0.9319878816604614, avg_entr 0.02914186753332615
ep9_l1_test_time 0.931771993637085
Test Epoch9 layer2 Acc 0.8756, AUC 0.9399099349975586, avg_entr 0.02343972772359848
ep9_l2_test_time 1.4107775688171387
Test Epoch9 layer3 Acc 0.8752, AUC 0.9426321387290955, avg_entr 0.022752737626433372
ep9_l3_test_time 1.884093999862671
Test Epoch9 layer4 Acc 0.8748, AUC 0.9437751770019531, avg_entr 0.021597199141979218
ep9_l4_test_time 2.3618016242980957
gc 0
Train Epoch10 Acc 0.9761 (39044/40000), AUC 0.993752121925354
ep10_train_time 70.53158617019653
Test Epoch10 layer0 Acc 0.8844, AUC 0.9486716985702515, avg_entr 0.1331396847963333
ep10_l0_test_time 0.4530799388885498
Test Epoch10 layer1 Acc 0.8752, AUC 0.9295783042907715, avg_entr 0.027520935982465744
ep10_l1_test_time 0.9313380718231201
Test Epoch10 layer2 Acc 0.8762, AUC 0.9361812472343445, avg_entr 0.02222313918173313
ep10_l2_test_time 1.407369613647461
Test Epoch10 layer3 Acc 0.8762, AUC 0.9402009844779968, avg_entr 0.021609202027320862
ep10_l3_test_time 1.8828496932983398
Test Epoch10 layer4 Acc 0.8764, AUC 0.9425783753395081, avg_entr 0.020481927320361137
ep10_l4_test_time 2.363999366760254
gc 0
Train Epoch11 Acc 0.9777 (39108/40000), AUC 0.9945721626281738
ep11_train_time 70.60374641418457
Test Epoch11 layer0 Acc 0.885, AUC 0.9475035667419434, avg_entr 0.12764005362987518
ep11_l0_test_time 0.4523756504058838
Test Epoch11 layer1 Acc 0.8738, AUC 0.9235000610351562, avg_entr 0.02503049373626709
ep11_l1_test_time 0.9325239658355713
Test Epoch11 layer2 Acc 0.8734, AUC 0.9364944696426392, avg_entr 0.018830468878149986
ep11_l2_test_time 1.4103517532348633
Test Epoch11 layer3 Acc 0.874, AUC 0.9381328821182251, avg_entr 0.018343999981880188
ep11_l3_test_time 1.8922080993652344
Test Epoch11 layer4 Acc 0.874, AUC 0.9406113028526306, avg_entr 0.017216617241501808
ep11_l4_test_time 2.3626537322998047
gc 0
Train Epoch12 Acc 0.979175 (39167/40000), AUC 0.9949935078620911
ep12_train_time 70.51315665245056
Test Epoch12 layer0 Acc 0.8828, AUC 0.9468379616737366, avg_entr 0.12873417139053345
ep12_l0_test_time 0.45435667037963867
Test Epoch12 layer1 Acc 0.871, AUC 0.9223742485046387, avg_entr 0.02413564920425415
ep12_l1_test_time 0.932016134262085
Test Epoch12 layer2 Acc 0.8706, AUC 0.9301700592041016, avg_entr 0.017372917383909225
ep12_l2_test_time 1.4061899185180664
Test Epoch12 layer3 Acc 0.8704, AUC 0.933741569519043, avg_entr 0.016818303614854813
ep12_l3_test_time 1.8817546367645264
Test Epoch12 layer4 Acc 0.8704, AUC 0.9390975832939148, avg_entr 0.01578015275299549
ep12_l4_test_time 2.3625712394714355
gc 0
Train Epoch13 Acc 0.97975 (39190/40000), AUC 0.995330810546875
ep13_train_time 70.51007270812988
Test Epoch13 layer0 Acc 0.8816, AUC 0.9462564587593079, avg_entr 0.12493162602186203
ep13_l0_test_time 0.4510526657104492
Test Epoch13 layer1 Acc 0.871, AUC 0.9221974015235901, avg_entr 0.025063060224056244
ep13_l1_test_time 0.9354100227355957
Test Epoch13 layer2 Acc 0.8714, AUC 0.9309705495834351, avg_entr 0.017762470990419388
ep13_l2_test_time 1.4056951999664307
Test Epoch13 layer3 Acc 0.871, AUC 0.9351761341094971, avg_entr 0.017411936074495316
ep13_l3_test_time 1.8833749294281006
Test Epoch13 layer4 Acc 0.8712, AUC 0.9393190741539001, avg_entr 0.016329413279891014
ep13_l4_test_time 2.3622984886169434
gc 0
Train Epoch14 Acc 0.980925 (39237/40000), AUC 0.9952367544174194
ep14_train_time 70.49541020393372
Test Epoch14 layer0 Acc 0.881, AUC 0.9454920291900635, avg_entr 0.12305431067943573
ep14_l0_test_time 0.4505126476287842
Test Epoch14 layer1 Acc 0.8696, AUC 0.918799877166748, avg_entr 0.024058301001787186
ep14_l1_test_time 0.930626392364502
Test Epoch14 layer2 Acc 0.8688, AUC 0.9290845394134521, avg_entr 0.017857026308774948
ep14_l2_test_time 1.4111905097961426
Test Epoch14 layer3 Acc 0.8688, AUC 0.9329184293746948, avg_entr 0.01728297397494316
ep14_l3_test_time 1.8917622566223145
Test Epoch14 layer4 Acc 0.8686, AUC 0.9373453855514526, avg_entr 0.016172775998711586
ep14_l4_test_time 2.359388589859009
gc 0
Train Epoch15 Acc 0.9811 (39244/40000), AUC 0.9958480596542358
ep15_train_time 70.49539756774902
Test Epoch15 layer0 Acc 0.8816, AUC 0.9447792768478394, avg_entr 0.1228618398308754
ep15_l0_test_time 0.4509139060974121
Test Epoch15 layer1 Acc 0.8696, AUC 0.9200294017791748, avg_entr 0.02440623939037323
ep15_l1_test_time 0.9317269325256348
Test Epoch15 layer2 Acc 0.8696, AUC 0.9270323514938354, avg_entr 0.017522316426038742
ep15_l2_test_time 1.4062550067901611
Test Epoch15 layer3 Acc 0.8694, AUC 0.9318514466285706, avg_entr 0.017146755009889603
ep15_l3_test_time 1.8842854499816895
Test Epoch15 layer4 Acc 0.8696, AUC 0.9369202852249146, avg_entr 0.016107803210616112
ep15_l4_test_time 2.3625476360321045
gc 0
Train Epoch16 Acc 0.98205 (39282/40000), AUC 0.9962570667266846
ep16_train_time 70.49652099609375
Test Epoch16 layer0 Acc 0.8804, AUC 0.9444605112075806, avg_entr 0.12099644541740417
ep16_l0_test_time 0.45001864433288574
Test Epoch16 layer1 Acc 0.8716, AUC 0.9173220992088318, avg_entr 0.023982888087630272
ep16_l1_test_time 0.9339723587036133
Test Epoch16 layer2 Acc 0.8698, AUC 0.923222541809082, avg_entr 0.017717204988002777
ep16_l2_test_time 1.4049053192138672
Test Epoch16 layer3 Acc 0.8696, AUC 0.929732084274292, avg_entr 0.017336396500468254
ep16_l3_test_time 1.8812370300292969
Test Epoch16 layer4 Acc 0.8694, AUC 0.9359965324401855, avg_entr 0.016346193850040436
ep16_l4_test_time 2.363903045654297
gc 0
Train Epoch17 Acc 0.982275 (39291/40000), AUC 0.9960929155349731
ep17_train_time 70.59217953681946
Test Epoch17 layer0 Acc 0.8808, AUC 0.9441131353378296, avg_entr 0.12112919986248016
ep17_l0_test_time 0.45186710357666016
Test Epoch17 layer1 Acc 0.8678, AUC 0.9167368412017822, avg_entr 0.022964566946029663
ep17_l1_test_time 0.931079626083374
Test Epoch17 layer2 Acc 0.868, AUC 0.919881284236908, avg_entr 0.016835058107972145
ep17_l2_test_time 1.4065115451812744
Test Epoch17 layer3 Acc 0.8678, AUC 0.9275674819946289, avg_entr 0.016411850228905678
ep17_l3_test_time 1.8866007328033447
Test Epoch17 layer4 Acc 0.8674, AUC 0.9349652528762817, avg_entr 0.015481308102607727
ep17_l4_test_time 2.3660213947296143
gc 0
Train Epoch18 Acc 0.9828 (39312/40000), AUC 0.9962079524993896
ep18_train_time 70.52779006958008
Test Epoch18 layer0 Acc 0.8812, AUC 0.94378662109375, avg_entr 0.1201476901769638
ep18_l0_test_time 0.45282435417175293
Test Epoch18 layer1 Acc 0.8668, AUC 0.9168038964271545, avg_entr 0.022265272215008736
ep18_l1_test_time 0.9324984550476074
Test Epoch18 layer2 Acc 0.8676, AUC 0.9215042591094971, avg_entr 0.01728266291320324
ep18_l2_test_time 1.4056496620178223
Test Epoch18 layer3 Acc 0.8676, AUC 0.9285341501235962, avg_entr 0.016749218106269836
ep18_l3_test_time 1.8816468715667725
Test Epoch18 layer4 Acc 0.8664, AUC 0.9351568818092346, avg_entr 0.01570187509059906
ep18_l4_test_time 2.3632490634918213
gc 0
Train Epoch19 Acc 0.982725 (39309/40000), AUC 0.9962184429168701
ep19_train_time 70.53183650970459
Test Epoch19 layer0 Acc 0.88, AUC 0.9434434175491333, avg_entr 0.11889122426509857
ep19_l0_test_time 0.4509906768798828
Test Epoch19 layer1 Acc 0.8684, AUC 0.9158355593681335, avg_entr 0.022141536697745323
ep19_l1_test_time 0.9321484565734863
Test Epoch19 layer2 Acc 0.8686, AUC 0.9168484807014465, avg_entr 0.01624925620853901
ep19_l2_test_time 1.4036285877227783
Test Epoch19 layer3 Acc 0.8674, AUC 0.9252640008926392, avg_entr 0.015758775174617767
ep19_l3_test_time 1.8832964897155762
Test Epoch19 layer4 Acc 0.8676, AUC 0.933440089225769, avg_entr 0.014839953742921352
ep19_l4_test_time 2.361624002456665
gc 0
Train Epoch20 Acc 0.983125 (39325/40000), AUC 0.9962953925132751
ep20_train_time 70.53408575057983
Test Epoch20 layer0 Acc 0.8798, AUC 0.9432163834571838, avg_entr 0.11837059259414673
ep20_l0_test_time 0.4510371685028076
Test Epoch20 layer1 Acc 0.869, AUC 0.9148626327514648, avg_entr 0.022352872416377068
ep20_l1_test_time 0.9332611560821533
Test Epoch20 layer2 Acc 0.869, AUC 0.9176649451255798, avg_entr 0.01688711903989315
ep20_l2_test_time 1.4079606533050537
Test Epoch20 layer3 Acc 0.8686, AUC 0.9262950420379639, avg_entr 0.016503430902957916
ep20_l3_test_time 1.8829452991485596
Test Epoch20 layer4 Acc 0.8686, AUC 0.9336248636245728, avg_entr 0.015526759438216686
ep20_l4_test_time 2.3648500442504883
gc 0
Train Epoch21 Acc 0.9833 (39332/40000), AUC 0.9961345195770264
ep21_train_time 70.5894672870636
Test Epoch21 layer0 Acc 0.8794, AUC 0.9430460929870605, avg_entr 0.11794617772102356
ep21_l0_test_time 0.4665541648864746
Test Epoch21 layer1 Acc 0.8684, AUC 0.9146981239318848, avg_entr 0.022174205631017685
ep21_l1_test_time 0.9331991672515869
Test Epoch21 layer2 Acc 0.8676, AUC 0.9172037839889526, avg_entr 0.016459940001368523
ep21_l2_test_time 1.4073843955993652
Test Epoch21 layer3 Acc 0.8674, AUC 0.9254037141799927, avg_entr 0.016020240262150764
ep21_l3_test_time 1.8831219673156738
Test Epoch21 layer4 Acc 0.8674, AUC 0.9332056045532227, avg_entr 0.015078074298799038
ep21_l4_test_time 2.3572826385498047
gc 0
Train Epoch22 Acc 0.983775 (39351/40000), AUC 0.9961221814155579
ep22_train_time 70.50719022750854
Test Epoch22 layer0 Acc 0.8794, AUC 0.942908763885498, avg_entr 0.11698037385940552
ep22_l0_test_time 0.4501655101776123
Test Epoch22 layer1 Acc 0.8656, AUC 0.913910984992981, avg_entr 0.020776862278580666
ep22_l1_test_time 0.9303414821624756
Test Epoch22 layer2 Acc 0.8654, AUC 0.9141325950622559, avg_entr 0.015571757219731808
ep22_l2_test_time 1.404329538345337
Test Epoch22 layer3 Acc 0.8652, AUC 0.9215297102928162, avg_entr 0.015157398767769337
ep22_l3_test_time 1.8832480907440186
Test Epoch22 layer4 Acc 0.8654, AUC 0.9312080144882202, avg_entr 0.014325053431093693
ep22_l4_test_time 2.358078956604004
gc 0
Train Epoch23 Acc 0.983625 (39345/40000), AUC 0.9965384006500244
ep23_train_time 70.51071214675903
Test Epoch23 layer0 Acc 0.8784, AUC 0.9427452087402344, avg_entr 0.11597958952188492
ep23_l0_test_time 0.4547708034515381
Test Epoch23 layer1 Acc 0.868, AUC 0.9143556356430054, avg_entr 0.02150077186524868
ep23_l1_test_time 0.941845178604126
Test Epoch23 layer2 Acc 0.8656, AUC 0.9148139953613281, avg_entr 0.015742553398013115
ep23_l2_test_time 1.4065251350402832
Test Epoch23 layer3 Acc 0.8656, AUC 0.9239287376403809, avg_entr 0.015294442884624004
ep23_l3_test_time 1.885427474975586
Test Epoch23 layer4 Acc 0.8656, AUC 0.9322044849395752, avg_entr 0.014378175139427185
ep23_l4_test_time 2.363138437271118
gc 0
Train Epoch24 Acc 0.98395 (39358/40000), AUC 0.9964320063591003
ep24_train_time 70.50142359733582
Test Epoch24 layer0 Acc 0.8784, AUC 0.9426610469818115, avg_entr 0.11595979332923889
ep24_l0_test_time 0.45026159286499023
Test Epoch24 layer1 Acc 0.8674, AUC 0.9137576818466187, avg_entr 0.021060923114418983
ep24_l1_test_time 0.9330534934997559
Test Epoch24 layer2 Acc 0.8658, AUC 0.9127852916717529, avg_entr 0.015171151608228683
ep24_l2_test_time 1.4087636470794678
Test Epoch24 layer3 Acc 0.866, AUC 0.921924352645874, avg_entr 0.014614518731832504
ep24_l3_test_time 1.880812644958496
Test Epoch24 layer4 Acc 0.866, AUC 0.9311221837997437, avg_entr 0.013719795271754265
ep24_l4_test_time 2.3710477352142334
gc 0
Train Epoch25 Acc 0.983775 (39351/40000), AUC 0.9965404272079468
ep25_train_time 70.56570267677307
Test Epoch25 layer0 Acc 0.8794, AUC 0.9425930380821228, avg_entr 0.11588575690984726
ep25_l0_test_time 0.45656871795654297
Test Epoch25 layer1 Acc 0.8668, AUC 0.9133229851722717, avg_entr 0.020861316472291946
ep25_l1_test_time 0.9354569911956787
Test Epoch25 layer2 Acc 0.866, AUC 0.9119899868965149, avg_entr 0.014965035952627659
ep25_l2_test_time 1.4081780910491943
Test Epoch25 layer3 Acc 0.866, AUC 0.921483039855957, avg_entr 0.014446604996919632
ep25_l3_test_time 1.8853001594543457
Test Epoch25 layer4 Acc 0.8662, AUC 0.9309672713279724, avg_entr 0.013577369973063469
ep25_l4_test_time 2.361992835998535
gc 0
Train Epoch26 Acc 0.98395 (39358/40000), AUC 0.9963688850402832
ep26_train_time 70.50525188446045
Test Epoch26 layer0 Acc 0.879, AUC 0.9425193667411804, avg_entr 0.11577688157558441
ep26_l0_test_time 0.45406627655029297
Test Epoch26 layer1 Acc 0.8678, AUC 0.9132277965545654, avg_entr 0.020795749500393867
ep26_l1_test_time 0.933037519454956
Test Epoch26 layer2 Acc 0.8664, AUC 0.9105795621871948, avg_entr 0.014828897081315517
ep26_l2_test_time 1.406461477279663
Test Epoch26 layer3 Acc 0.8662, AUC 0.9202577471733093, avg_entr 0.014292578212916851
ep26_l3_test_time 1.8807728290557861
Test Epoch26 layer4 Acc 0.866, AUC 0.930249810218811, avg_entr 0.01342193316668272
ep26_l4_test_time 2.3689281940460205
gc 0
Train Epoch27 Acc 0.984075 (39363/40000), AUC 0.996580183506012
ep27_train_time 70.51082372665405
Test Epoch27 layer0 Acc 0.879, AUC 0.9424698352813721, avg_entr 0.11465875059366226
ep27_l0_test_time 0.45096564292907715
Test Epoch27 layer1 Acc 0.8672, AUC 0.9129998683929443, avg_entr 0.02086537331342697
ep27_l1_test_time 0.9322433471679688
Test Epoch27 layer2 Acc 0.8654, AUC 0.9097754955291748, avg_entr 0.014609220437705517
ep27_l2_test_time 1.4031805992126465
Test Epoch27 layer3 Acc 0.8658, AUC 0.919676661491394, avg_entr 0.014122317545115948
ep27_l3_test_time 1.8811030387878418
Test Epoch27 layer4 Acc 0.866, AUC 0.9300113916397095, avg_entr 0.013217657804489136
ep27_l4_test_time 2.3599491119384766
gc 0
Train Epoch28 Acc 0.984175 (39367/40000), AUC 0.9966078400611877
ep28_train_time 70.5486831665039
Test Epoch28 layer0 Acc 0.8788, AUC 0.9424313306808472, avg_entr 0.11447890847921371
ep28_l0_test_time 0.4524843692779541
Test Epoch28 layer1 Acc 0.868, AUC 0.9126248359680176, avg_entr 0.020449459552764893
ep28_l1_test_time 0.9376413822174072
Test Epoch28 layer2 Acc 0.8662, AUC 0.9100144505500793, avg_entr 0.014116533100605011
ep28_l2_test_time 1.4148828983306885
Test Epoch28 layer3 Acc 0.866, AUC 0.9191336631774902, avg_entr 0.013575947843492031
ep28_l3_test_time 1.8918695449829102
Test Epoch28 layer4 Acc 0.8662, AUC 0.9293811321258545, avg_entr 0.012700404040515423
ep28_l4_test_time 2.3717615604400635
gc 0
Train Epoch29 Acc 0.98415 (39366/40000), AUC 0.9964814782142639
ep29_train_time 70.65781497955322
Test Epoch29 layer0 Acc 0.8792, AUC 0.9423906803131104, avg_entr 0.11418044567108154
ep29_l0_test_time 0.45420408248901367
Test Epoch29 layer1 Acc 0.8672, AUC 0.9127526879310608, avg_entr 0.020627886056900024
ep29_l1_test_time 0.932852029800415
Test Epoch29 layer2 Acc 0.8656, AUC 0.9095219373703003, avg_entr 0.014480671845376492
ep29_l2_test_time 1.4070930480957031
Test Epoch29 layer3 Acc 0.8654, AUC 0.919174313545227, avg_entr 0.014011540450155735
ep29_l3_test_time 1.8842434883117676
Test Epoch29 layer4 Acc 0.8658, AUC 0.9295450448989868, avg_entr 0.013148322701454163
ep29_l4_test_time 2.3626277446746826
gc 0
Train Epoch30 Acc 0.984325 (39373/40000), AUC 0.9966081976890564
ep30_train_time 70.52773118019104
Test Epoch30 layer0 Acc 0.8782, AUC 0.942378044128418, avg_entr 0.11365249007940292
ep30_l0_test_time 0.4518702030181885
Test Epoch30 layer1 Acc 0.868, AUC 0.9126407504081726, avg_entr 0.020375382155179977
ep30_l1_test_time 0.9397704601287842
Test Epoch30 layer2 Acc 0.8652, AUC 0.9099475145339966, avg_entr 0.014397651888430119
ep30_l2_test_time 1.4070332050323486
Test Epoch30 layer3 Acc 0.8652, AUC 0.9194765090942383, avg_entr 0.01394136343151331
ep30_l3_test_time 1.8846871852874756
Test Epoch30 layer4 Acc 0.8654, AUC 0.9296150207519531, avg_entr 0.013118626549839973
ep30_l4_test_time 2.3737356662750244
gc 0
Train Epoch31 Acc 0.98435 (39374/40000), AUC 0.9966877698898315
ep31_train_time 70.69486331939697
Test Epoch31 layer0 Acc 0.878, AUC 0.9423466920852661, avg_entr 0.11313487589359283
ep31_l0_test_time 0.45632243156433105
Test Epoch31 layer1 Acc 0.8674, AUC 0.9127250909805298, avg_entr 0.020129429176449776
ep31_l1_test_time 0.9357161521911621
Test Epoch31 layer2 Acc 0.8652, AUC 0.9101581573486328, avg_entr 0.014393921010196209
ep31_l2_test_time 1.4087564945220947
Test Epoch31 layer3 Acc 0.8654, AUC 0.9196131229400635, avg_entr 0.01391042210161686
ep31_l3_test_time 1.8927123546600342
Test Epoch31 layer4 Acc 0.8654, AUC 0.9296765327453613, avg_entr 0.013105181977152824
ep31_l4_test_time 2.357473373413086
gc 0
Train Epoch32 Acc 0.984275 (39371/40000), AUC 0.9966190457344055
ep32_train_time 70.5127968788147
Test Epoch32 layer0 Acc 0.8776, AUC 0.9423317313194275, avg_entr 0.11295107752084732
ep32_l0_test_time 0.45119810104370117
Test Epoch32 layer1 Acc 0.8672, AUC 0.9125546216964722, avg_entr 0.0205182284116745
ep32_l1_test_time 0.9313080310821533
Test Epoch32 layer2 Acc 0.866, AUC 0.9092062711715698, avg_entr 0.014662056230008602
ep32_l2_test_time 1.4042072296142578
Test Epoch32 layer3 Acc 0.866, AUC 0.9189459085464478, avg_entr 0.014296636916697025
ep32_l3_test_time 1.887700080871582
Test Epoch32 layer4 Acc 0.866, AUC 0.9293231964111328, avg_entr 0.013519994914531708
ep32_l4_test_time 2.3639819622039795
gc 0
Train Epoch33 Acc 0.9844 (39376/40000), AUC 0.9966806173324585
ep33_train_time 70.54447317123413
Test Epoch33 layer0 Acc 0.8778, AUC 0.9423232078552246, avg_entr 0.11278160661458969
ep33_l0_test_time 0.4600541591644287
Test Epoch33 layer1 Acc 0.868, AUC 0.9124963283538818, avg_entr 0.02053949050605297
ep33_l1_test_time 0.9324049949645996
Test Epoch33 layer2 Acc 0.8668, AUC 0.9087477922439575, avg_entr 0.014897425659000874
ep33_l2_test_time 1.4144792556762695
Test Epoch33 layer3 Acc 0.8668, AUC 0.9187390804290771, avg_entr 0.01458986196666956
ep33_l3_test_time 1.8905799388885498
Test Epoch33 layer4 Acc 0.867, AUC 0.9292569160461426, avg_entr 0.013857501558959484
ep33_l4_test_time 2.3570199012756348
gc 0
Train Epoch34 Acc 0.984625 (39385/40000), AUC 0.9966371059417725
ep34_train_time 70.53624033927917
Test Epoch34 layer0 Acc 0.8774, AUC 0.9423096776008606, avg_entr 0.11246805638074875
ep34_l0_test_time 0.4512646198272705
Test Epoch34 layer1 Acc 0.867, AUC 0.9126669764518738, avg_entr 0.020150603726506233
ep34_l1_test_time 0.9310586452484131
Test Epoch34 layer2 Acc 0.8658, AUC 0.9093687534332275, avg_entr 0.014292202889919281
ep34_l2_test_time 1.4045584201812744
Test Epoch34 layer3 Acc 0.8656, AUC 0.9188183546066284, avg_entr 0.0138397216796875
ep34_l3_test_time 1.8845243453979492
Test Epoch34 layer4 Acc 0.8656, AUC 0.9291072487831116, avg_entr 0.013026800937950611
ep34_l4_test_time 2.3629510402679443
gc 0
Train Epoch35 Acc 0.9842 (39368/40000), AUC 0.9966033697128296
ep35_train_time 70.55337142944336
Test Epoch35 layer0 Acc 0.8776, AUC 0.9423011541366577, avg_entr 0.1121470183134079
ep35_l0_test_time 0.4524879455566406
Test Epoch35 layer1 Acc 0.867, AUC 0.9124852418899536, avg_entr 0.020093843340873718
ep35_l1_test_time 0.9332106113433838
Test Epoch35 layer2 Acc 0.8662, AUC 0.9092419147491455, avg_entr 0.014208993874490261
ep35_l2_test_time 1.4038519859313965
Test Epoch35 layer3 Acc 0.866, AUC 0.9187636375427246, avg_entr 0.013758458197116852
ep35_l3_test_time 1.8823127746582031
Test Epoch35 layer4 Acc 0.866, AUC 0.9290509223937988, avg_entr 0.012958290055394173
ep35_l4_test_time 2.3702762126922607
gc 0
Train Epoch36 Acc 0.984475 (39379/40000), AUC 0.9967392683029175
ep36_train_time 70.54446625709534
Test Epoch36 layer0 Acc 0.8786, AUC 0.9422979354858398, avg_entr 0.11233475059270859
ep36_l0_test_time 0.4527573585510254
Test Epoch36 layer1 Acc 0.8678, AUC 0.912409782409668, avg_entr 0.01989818550646305
ep36_l1_test_time 0.9384934902191162
Test Epoch36 layer2 Acc 0.8662, AUC 0.909350574016571, avg_entr 0.013940049335360527
ep36_l2_test_time 1.4159090518951416
Test Epoch36 layer3 Acc 0.866, AUC 0.9185062646865845, avg_entr 0.013438737951219082
ep36_l3_test_time 1.8833470344543457
Test Epoch36 layer4 Acc 0.8662, AUC 0.9288327693939209, avg_entr 0.01261971890926361
ep36_l4_test_time 2.3594629764556885
gc 0
Train Epoch37 Acc 0.984275 (39371/40000), AUC 0.9967072010040283
ep37_train_time 70.53321576118469
Test Epoch37 layer0 Acc 0.8776, AUC 0.9423015117645264, avg_entr 0.11204531043767929
ep37_l0_test_time 0.4503457546234131
Test Epoch37 layer1 Acc 0.868, AUC 0.9125469326972961, avg_entr 0.019814226776361465
ep37_l1_test_time 0.9297127723693848
Test Epoch37 layer2 Acc 0.8652, AUC 0.9094505310058594, avg_entr 0.01398127619177103
ep37_l2_test_time 1.4064764976501465
Test Epoch37 layer3 Acc 0.8654, AUC 0.9185752868652344, avg_entr 0.013492577709257603
ep37_l3_test_time 1.8829607963562012
Test Epoch37 layer4 Acc 0.8656, AUC 0.9288876056671143, avg_entr 0.012688258662819862
ep37_l4_test_time 2.363184690475464
gc 0
Train Epoch38 Acc 0.984525 (39381/40000), AUC 0.9968889951705933
ep38_train_time 70.52338337898254
Test Epoch38 layer0 Acc 0.878, AUC 0.9422954320907593, avg_entr 0.11180267482995987
ep38_l0_test_time 0.4566829204559326
Test Epoch38 layer1 Acc 0.8668, AUC 0.9125025868415833, avg_entr 0.019963081926107407
ep38_l1_test_time 0.9311342239379883
Test Epoch38 layer2 Acc 0.866, AUC 0.90898597240448, avg_entr 0.014135642908513546
ep38_l2_test_time 1.4085485935211182
Test Epoch38 layer3 Acc 0.8658, AUC 0.9184157848358154, avg_entr 0.01369436364620924
ep38_l3_test_time 1.8863089084625244
Test Epoch38 layer4 Acc 0.8662, AUC 0.9288432598114014, avg_entr 0.012906881980597973
ep38_l4_test_time 2.360232353210449
gc 0
Train Epoch39 Acc 0.9843 (39372/40000), AUC 0.9966577291488647
ep39_train_time 70.52870035171509
Test Epoch39 layer0 Acc 0.8784, AUC 0.9422910213470459, avg_entr 0.11171770095825195
ep39_l0_test_time 0.45319151878356934
Test Epoch39 layer1 Acc 0.8676, AUC 0.9125551581382751, avg_entr 0.019811181351542473
ep39_l1_test_time 0.9334120750427246
Test Epoch39 layer2 Acc 0.865, AUC 0.9091416001319885, avg_entr 0.01398895401507616
ep39_l2_test_time 1.4054384231567383
Test Epoch39 layer3 Acc 0.8656, AUC 0.918400764465332, avg_entr 0.013522808440029621
ep39_l3_test_time 1.8867011070251465
Test Epoch39 layer4 Acc 0.8656, AUC 0.9288032054901123, avg_entr 0.012727169319987297
ep39_l4_test_time 2.3605566024780273
gc 0
Train Epoch40 Acc 0.984325 (39373/40000), AUC 0.9967736601829529
ep40_train_time 70.64325499534607
Test Epoch40 layer0 Acc 0.8782, AUC 0.9422912001609802, avg_entr 0.11159294098615646
ep40_l0_test_time 0.4772379398345947
Test Epoch40 layer1 Acc 0.8672, AUC 0.9125730991363525, avg_entr 0.01981380023062229
ep40_l1_test_time 0.9340705871582031
Test Epoch40 layer2 Acc 0.8656, AUC 0.9091305732727051, avg_entr 0.014001124538481236
ep40_l2_test_time 1.4068174362182617
Test Epoch40 layer3 Acc 0.8656, AUC 0.9183915257453918, avg_entr 0.013533910736441612
ep40_l3_test_time 1.891848087310791
Test Epoch40 layer4 Acc 0.8656, AUC 0.928727388381958, avg_entr 0.012742447666823864
ep40_l4_test_time 2.3607287406921387
gc 0
Train Epoch41 Acc 0.984575 (39383/40000), AUC 0.9964390397071838
ep41_train_time 70.61518001556396
Test Epoch41 layer0 Acc 0.8782, AUC 0.9422911405563354, avg_entr 0.11138667911291122
ep41_l0_test_time 0.4529900550842285
Test Epoch41 layer1 Acc 0.8672, AUC 0.9125678539276123, avg_entr 0.019799958914518356
ep41_l1_test_time 0.93603515625
Test Epoch41 layer2 Acc 0.8658, AUC 0.9089822769165039, avg_entr 0.013989065773785114
ep41_l2_test_time 1.4158010482788086
Test Epoch41 layer3 Acc 0.8656, AUC 0.9182939529418945, avg_entr 0.013521615415811539
ep41_l3_test_time 1.8920023441314697
Test Epoch41 layer4 Acc 0.8656, AUC 0.9287261366844177, avg_entr 0.012730582617223263
ep41_l4_test_time 2.3625268936157227
gc 0
Train Epoch42 Acc 0.984675 (39387/40000), AUC 0.9966517686843872
ep42_train_time 70.54117965698242
Test Epoch42 layer0 Acc 0.8774, AUC 0.9422826170921326, avg_entr 0.11114346981048584
ep42_l0_test_time 0.45137810707092285
Test Epoch42 layer1 Acc 0.8668, AUC 0.912594199180603, avg_entr 0.019885243847966194
ep42_l1_test_time 0.9331796169281006
Test Epoch42 layer2 Acc 0.8656, AUC 0.9086568355560303, avg_entr 0.014124568551778793
ep42_l2_test_time 1.4058761596679688
Test Epoch42 layer3 Acc 0.866, AUC 0.9181822538375854, avg_entr 0.013693694956600666
ep42_l3_test_time 1.885282278060913
Test Epoch42 layer4 Acc 0.866, AUC 0.9286695718765259, avg_entr 0.012934713624417782
ep42_l4_test_time 2.3607370853424072
gc 0
Train Epoch43 Acc 0.984475 (39379/40000), AUC 0.996712327003479
ep43_train_time 70.5810854434967
Test Epoch43 layer0 Acc 0.8778, AUC 0.9422786831855774, avg_entr 0.11112114042043686
ep43_l0_test_time 0.4893302917480469
Test Epoch43 layer1 Acc 0.8672, AUC 0.9126007556915283, avg_entr 0.01977626048028469
ep43_l1_test_time 0.9549155235290527
Test Epoch43 layer2 Acc 0.8656, AUC 0.908801257610321, avg_entr 0.014009756036102772
ep43_l2_test_time 1.4063925743103027
Test Epoch43 layer3 Acc 0.8656, AUC 0.9181926846504211, avg_entr 0.013545825146138668
ep43_l3_test_time 1.882211685180664
Test Epoch43 layer4 Acc 0.8656, AUC 0.9286295175552368, avg_entr 0.012764569371938705
ep43_l4_test_time 2.3622820377349854
gc 0
Train Epoch44 Acc 0.984475 (39379/40000), AUC 0.996805727481842
ep44_train_time 70.53943490982056
Test Epoch44 layer0 Acc 0.8778, AUC 0.9422785043716431, avg_entr 0.11107002198696136
ep44_l0_test_time 0.45188450813293457
Test Epoch44 layer1 Acc 0.8674, AUC 0.9125981330871582, avg_entr 0.019714076071977615
ep44_l1_test_time 0.9301517009735107
Test Epoch44 layer2 Acc 0.8654, AUC 0.9087974429130554, avg_entr 0.013934238813817501
ep44_l2_test_time 1.4056236743927002
Test Epoch44 layer3 Acc 0.8656, AUC 0.9181035161018372, avg_entr 0.013459838926792145
ep44_l3_test_time 1.8883826732635498
Test Epoch44 layer4 Acc 0.8656, AUC 0.9286249876022339, avg_entr 0.012677179649472237
ep44_l4_test_time 2.3647003173828125
gc 0
Train Epoch45 Acc 0.984725 (39389/40000), AUC 0.9965137243270874
ep45_train_time 70.54857516288757
Test Epoch45 layer0 Acc 0.878, AUC 0.9422785043716431, avg_entr 0.11101939529180527
ep45_l0_test_time 0.5160140991210938
Test Epoch45 layer1 Acc 0.8674, AUC 0.9126297831535339, avg_entr 0.019693082198500633
ep45_l1_test_time 0.9341368675231934
Test Epoch45 layer2 Acc 0.8654, AUC 0.9087748527526855, avg_entr 0.013914198614656925
ep45_l2_test_time 1.4094390869140625
Test Epoch45 layer3 Acc 0.8656, AUC 0.91802978515625, avg_entr 0.013442575000226498
ep45_l3_test_time 1.883913278579712
Test Epoch45 layer4 Acc 0.8656, AUC 0.9285831451416016, avg_entr 0.01266071479767561
ep45_l4_test_time 2.367053508758545
gc 0
Train Epoch46 Acc 0.98445 (39378/40000), AUC 0.9966742992401123
ep46_train_time 70.62076997756958
Test Epoch46 layer0 Acc 0.8778, AUC 0.9422793388366699, avg_entr 0.11088462918996811
ep46_l0_test_time 0.45404529571533203
Test Epoch46 layer1 Acc 0.8672, AUC 0.9126517176628113, avg_entr 0.01966932974755764
ep46_l1_test_time 0.9340603351593018
Test Epoch46 layer2 Acc 0.8654, AUC 0.9086970090866089, avg_entr 0.013898268342018127
ep46_l2_test_time 1.4053969383239746
Test Epoch46 layer3 Acc 0.8656, AUC 0.9180768728256226, avg_entr 0.013428247533738613
ep46_l3_test_time 1.8833024501800537
Test Epoch46 layer4 Acc 0.8656, AUC 0.9285567402839661, avg_entr 0.01264969352632761
ep46_l4_test_time 2.359699249267578
gc 0
Train Epoch47 Acc 0.984825 (39393/40000), AUC 0.9967867732048035
ep47_train_time 70.60545206069946
Test Epoch47 layer0 Acc 0.8778, AUC 0.9422787427902222, avg_entr 0.11079104989767075
ep47_l0_test_time 0.4524979591369629
Test Epoch47 layer1 Acc 0.8672, AUC 0.9126384258270264, avg_entr 0.019656313583254814
ep47_l1_test_time 0.9425101280212402
Test Epoch47 layer2 Acc 0.8654, AUC 0.9086775183677673, avg_entr 0.013888757675886154
ep47_l2_test_time 1.4096426963806152
Test Epoch47 layer3 Acc 0.8656, AUC 0.9180317521095276, avg_entr 0.013420773670077324
ep47_l3_test_time 1.8874564170837402
Test Epoch47 layer4 Acc 0.8656, AUC 0.9285584688186646, avg_entr 0.012643212452530861
ep47_l4_test_time 2.3662428855895996
gc 0
Train Epoch48 Acc 0.98475 (39390/40000), AUC 0.9966652989387512
ep48_train_time 70.5581042766571
Test Epoch48 layer0 Acc 0.8778, AUC 0.9422783255577087, avg_entr 0.11074810475111008
ep48_l0_test_time 0.4512324333190918
Test Epoch48 layer1 Acc 0.8672, AUC 0.9126686453819275, avg_entr 0.01963038556277752
ep48_l1_test_time 0.9386365413665771
Test Epoch48 layer2 Acc 0.8654, AUC 0.9086666107177734, avg_entr 0.013851870782673359
ep48_l2_test_time 1.4115772247314453
Test Epoch48 layer3 Acc 0.8656, AUC 0.9179903268814087, avg_entr 0.013380082324147224
ep48_l3_test_time 1.8935396671295166
Test Epoch48 layer4 Acc 0.8656, AUC 0.9285300970077515, avg_entr 0.01259986124932766
ep48_l4_test_time 2.3643393516540527
gc 0
Train Epoch49 Acc 0.984575 (39383/40000), AUC 0.9966550469398499
ep49_train_time 70.5665590763092
Test Epoch49 layer0 Acc 0.8776, AUC 0.9422785043716431, avg_entr 0.110714852809906
ep49_l0_test_time 0.45934104919433594
Test Epoch49 layer1 Acc 0.8672, AUC 0.9126715660095215, avg_entr 0.01961243338882923
ep49_l1_test_time 0.9319167137145996
Test Epoch49 layer2 Acc 0.8654, AUC 0.9086815714836121, avg_entr 0.013836758211255074
ep49_l2_test_time 1.4112403392791748
Test Epoch49 layer3 Acc 0.8656, AUC 0.918016791343689, avg_entr 0.013361262157559395
ep49_l3_test_time 1.8865644931793213
Test Epoch49 layer4 Acc 0.8656, AUC 0.9285576343536377, avg_entr 0.012581049464643002
ep49_l4_test_time 2.3733086585998535
Best AUC 0.958290696144104
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train+valid_time 3883.0554666519165
Start Testing
Load ckpt at ckpt/imdb_transformeral_l5_pad400//imdb_transformeral_l5.pt
Test layer0 Acc 0.8872, AUC 0.9538405537605286, avg_entr 0.2137240469455719
l0_test_time 0.47332024574279785
Test layer1 Acc 0.8804, AUC 0.9567083716392517, avg_entr 0.13028404116630554
l1_test_time 0.9327690601348877
Test layer2 Acc 0.881, AUC 0.9556262493133545, avg_entr 0.08111090958118439
l2_test_time 1.409172534942627
Test layer3 Acc 0.8808, AUC 0.955693781375885, avg_entr 0.06010492518544197
l3_test_time 1.8927290439605713
Test layer4 Acc 0.8786, AUC 0.955773115158081, avg_entr 0.05546459183096886
l4_test_time 2.3628013134002686
