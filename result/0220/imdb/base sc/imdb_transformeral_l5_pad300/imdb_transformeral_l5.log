total count words 222751
vocab size 30000
train size 40000, valid size 5000, test size 5000
found 27937 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=2, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=2, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 256
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 256
layers.0.ae.h.0.bias 2
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13671778
init_time 21.53067636489868
Start Training
gc 0
Train Epoch0 Acc 0.541575 (21663/40000), AUC 0.5688042044639587
ep0_train_time 49.30599546432495
Test Epoch0 layer0 Acc 0.8404, AUC 0.9165984392166138, avg_entr 0.45127323269844055
ep0_l0_test_time 0.3522188663482666
Save ckpt to ckpt/imdb_transformeral_l5_pad300//imdb_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.8268, AUC 0.9193429946899414, avg_entr 0.36123907566070557
ep0_l1_test_time 0.68330979347229
Save ckpt to ckpt/imdb_transformeral_l5_pad300//imdb_transformeral_l5.pt  ,ep 0
Test Epoch0 layer2 Acc 0.8102, AUC 0.9264425039291382, avg_entr 0.34033438563346863
ep0_l2_test_time 1.0110912322998047
Save ckpt to ckpt/imdb_transformeral_l5_pad300//imdb_transformeral_l5.pt  ,ep 0
Test Epoch0 layer3 Acc 0.8192, AUC 0.9250739812850952, avg_entr 0.47002193331718445
ep0_l3_test_time 1.3387396335601807
Test Epoch0 layer4 Acc 0.8446, AUC 0.9233322143554688, avg_entr 0.6219484210014343
ep0_l4_test_time 1.6568763256072998
gc 0
Train Epoch1 Acc 0.856325 (34253/40000), AUC 0.9274672865867615
ep1_train_time 49.07300806045532
Test Epoch1 layer0 Acc 0.8836, AUC 0.9498463869094849, avg_entr 0.25673890113830566
ep1_l0_test_time 0.35189247131347656
Save ckpt to ckpt/imdb_transformeral_l5_pad300//imdb_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.8884, AUC 0.9538895487785339, avg_entr 0.19231583178043365
ep1_l1_test_time 0.6833536624908447
Save ckpt to ckpt/imdb_transformeral_l5_pad300//imdb_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.8858, AUC 0.9538187384605408, avg_entr 0.16870562732219696
ep1_l2_test_time 1.0100398063659668
Test Epoch1 layer3 Acc 0.8858, AUC 0.9528168439865112, avg_entr 0.13937579095363617
ep1_l3_test_time 1.3333687782287598
Test Epoch1 layer4 Acc 0.8868, AUC 0.9526253938674927, avg_entr 0.12456103414297104
ep1_l4_test_time 1.660149335861206
gc 0
Train Epoch2 Acc 0.92125 (36850/40000), AUC 0.9721267223358154
ep2_train_time 49.06105637550354
Test Epoch2 layer0 Acc 0.8918, AUC 0.9554856419563293, avg_entr 0.2051243931055069
ep2_l0_test_time 0.35018372535705566
Save ckpt to ckpt/imdb_transformeral_l5_pad300//imdb_transformeral_l5.pt  ,ep 2
Test Epoch2 layer1 Acc 0.8878, AUC 0.9554054737091064, avg_entr 0.1440703421831131
ep2_l1_test_time 0.682591438293457
Test Epoch2 layer2 Acc 0.8906, AUC 0.9557709097862244, avg_entr 0.08862404525279999
ep2_l2_test_time 1.0035789012908936
Save ckpt to ckpt/imdb_transformeral_l5_pad300//imdb_transformeral_l5.pt  ,ep 2
Test Epoch2 layer3 Acc 0.8888, AUC 0.9553207159042358, avg_entr 0.06374234706163406
ep2_l3_test_time 1.338019609451294
Test Epoch2 layer4 Acc 0.8894, AUC 0.9552467465400696, avg_entr 0.0552532896399498
ep2_l4_test_time 1.6589150428771973
gc 0
Train Epoch3 Acc 0.9411 (37644/40000), AUC 0.9796746969223022
ep3_train_time 49.02669644355774
Test Epoch3 layer0 Acc 0.8912, AUC 0.955632209777832, avg_entr 0.18161256611347198
ep3_l0_test_time 0.3619399070739746
Test Epoch3 layer1 Acc 0.853, AUC 0.9507217407226562, avg_entr 0.10670024156570435
ep3_l1_test_time 0.683800458908081
Test Epoch3 layer2 Acc 0.8542, AUC 0.9442034959793091, avg_entr 0.05855128914117813
ep3_l2_test_time 1.000675916671753
Test Epoch3 layer3 Acc 0.8516, AUC 0.9450796842575073, avg_entr 0.05111318454146385
ep3_l3_test_time 1.3287816047668457
Test Epoch3 layer4 Acc 0.8504, AUC 0.9513481855392456, avg_entr 0.04657786339521408
ep3_l4_test_time 1.6603713035583496
gc 0
Train Epoch4 Acc 0.95305 (38122/40000), AUC 0.9855440855026245
ep4_train_time 49.059887409210205
Test Epoch4 layer0 Acc 0.8946, AUC 0.9547913074493408, avg_entr 0.1664622575044632
ep4_l0_test_time 0.35111451148986816
Test Epoch4 layer1 Acc 0.8834, AUC 0.9476306438446045, avg_entr 0.06464359164237976
ep4_l1_test_time 0.6818046569824219
Test Epoch4 layer2 Acc 0.8816, AUC 0.9415386915206909, avg_entr 0.041098762303590775
ep4_l2_test_time 1.006507396697998
Test Epoch4 layer3 Acc 0.8818, AUC 0.9475832581520081, avg_entr 0.03590213507413864
ep4_l3_test_time 1.3322734832763672
Test Epoch4 layer4 Acc 0.8816, AUC 0.9473910331726074, avg_entr 0.03260762616991997
ep4_l4_test_time 1.653320074081421
gc 0
Train Epoch5 Acc 0.96065 (38426/40000), AUC 0.9883874654769897
ep5_train_time 49.04716515541077
Test Epoch5 layer0 Acc 0.8876, AUC 0.9523676633834839, avg_entr 0.15178176760673523
ep5_l0_test_time 0.35199809074401855
Test Epoch5 layer1 Acc 0.8592, AUC 0.9399539828300476, avg_entr 0.04851733148097992
ep5_l1_test_time 0.6775143146514893
Test Epoch5 layer2 Acc 0.8632, AUC 0.94342041015625, avg_entr 0.03900054842233658
ep5_l2_test_time 1.0011844635009766
Test Epoch5 layer3 Acc 0.8616, AUC 0.9423867464065552, avg_entr 0.037027496844530106
ep5_l3_test_time 1.322103500366211
Test Epoch5 layer4 Acc 0.8582, AUC 0.9451314210891724, avg_entr 0.03510669618844986
ep5_l4_test_time 1.649643898010254
gc 0
Train Epoch6 Acc 0.965575 (38623/40000), AUC 0.9897292852401733
ep6_train_time 49.02139687538147
Test Epoch6 layer0 Acc 0.8862, AUC 0.9504756927490234, avg_entr 0.14507925510406494
ep6_l0_test_time 0.3571956157684326
Test Epoch6 layer1 Acc 0.8698, AUC 0.9337965250015259, avg_entr 0.03730573132634163
ep6_l1_test_time 0.6827356815338135
Test Epoch6 layer2 Acc 0.8708, AUC 0.9416950345039368, avg_entr 0.0304021704941988
ep6_l2_test_time 1.000281810760498
Test Epoch6 layer3 Acc 0.8708, AUC 0.9401553869247437, avg_entr 0.028774475678801537
ep6_l3_test_time 1.3295137882232666
Test Epoch6 layer4 Acc 0.8708, AUC 0.9415403008460999, avg_entr 0.026757897809147835
ep6_l4_test_time 1.6532738208770752
gc 0
Train Epoch7 Acc 0.9703 (38812/40000), AUC 0.9924136996269226
ep7_train_time 49.04526233673096
Test Epoch7 layer0 Acc 0.8828, AUC 0.9481453895568848, avg_entr 0.13655243813991547
ep7_l0_test_time 0.35231995582580566
Test Epoch7 layer1 Acc 0.8722, AUC 0.9311748147010803, avg_entr 0.031954243779182434
ep7_l1_test_time 0.6807475090026855
Test Epoch7 layer2 Acc 0.8716, AUC 0.9394641518592834, avg_entr 0.02452078089118004
ep7_l2_test_time 1.0049164295196533
Test Epoch7 layer3 Acc 0.8722, AUC 0.9383999109268188, avg_entr 0.023155976086854935
ep7_l3_test_time 1.3280067443847656
Test Epoch7 layer4 Acc 0.8708, AUC 0.9401947855949402, avg_entr 0.02156651020050049
ep7_l4_test_time 1.652219295501709
gc 0
Train Epoch8 Acc 0.9754 (39016/40000), AUC 0.9937162399291992
ep8_train_time 49.01030087471008
Test Epoch8 layer0 Acc 0.8786, AUC 0.9466879367828369, avg_entr 0.1344176083803177
ep8_l0_test_time 0.3597099781036377
Test Epoch8 layer1 Acc 0.868, AUC 0.9272727370262146, avg_entr 0.03102492354810238
ep8_l1_test_time 0.6797831058502197
Test Epoch8 layer2 Acc 0.8674, AUC 0.936240553855896, avg_entr 0.022046755999326706
ep8_l2_test_time 1.0036985874176025
Test Epoch8 layer3 Acc 0.8688, AUC 0.9310877323150635, avg_entr 0.02044566720724106
ep8_l3_test_time 1.3282670974731445
Test Epoch8 layer4 Acc 0.868, AUC 0.9379675388336182, avg_entr 0.018986308947205544
ep8_l4_test_time 1.654010534286499
gc 0
Train Epoch9 Acc 0.97675 (39070/40000), AUC 0.994360625743866
ep9_train_time 49.02862906455994
Test Epoch9 layer0 Acc 0.8788, AUC 0.9451518058776855, avg_entr 0.13274091482162476
ep9_l0_test_time 0.35241055488586426
Test Epoch9 layer1 Acc 0.8672, AUC 0.9250180125236511, avg_entr 0.027114303782582283
ep9_l1_test_time 0.6968762874603271
Test Epoch9 layer2 Acc 0.8658, AUC 0.9360733032226562, avg_entr 0.020230596885085106
ep9_l2_test_time 1.0018906593322754
Test Epoch9 layer3 Acc 0.8658, AUC 0.9313478469848633, avg_entr 0.018876777961850166
ep9_l3_test_time 1.3288154602050781
Test Epoch9 layer4 Acc 0.8658, AUC 0.937240481376648, avg_entr 0.017458952963352203
ep9_l4_test_time 1.6534130573272705
gc 0
Train Epoch10 Acc 0.977675 (39107/40000), AUC 0.9943220019340515
ep10_train_time 49.08160614967346
Test Epoch10 layer0 Acc 0.8776, AUC 0.9437563419342041, avg_entr 0.12906311452388763
ep10_l0_test_time 0.3921191692352295
Test Epoch10 layer1 Acc 0.866, AUC 0.923168420791626, avg_entr 0.027477173134684563
ep10_l1_test_time 0.6907780170440674
Test Epoch10 layer2 Acc 0.8676, AUC 0.9350720643997192, avg_entr 0.02188713476061821
ep10_l2_test_time 1.007171869277954
Test Epoch10 layer3 Acc 0.8676, AUC 0.9328069686889648, avg_entr 0.021243251860141754
ep10_l3_test_time 1.3279430866241455
Test Epoch10 layer4 Acc 0.867, AUC 0.9362043142318726, avg_entr 0.020009053871035576
ep10_l4_test_time 1.6525297164916992
gc 0
Train Epoch11 Acc 0.979625 (39185/40000), AUC 0.9949419498443604
ep11_train_time 49.08978271484375
Test Epoch11 layer0 Acc 0.8714, AUC 0.9425458908081055, avg_entr 0.12715911865234375
ep11_l0_test_time 0.3543405532836914
Test Epoch11 layer1 Acc 0.8662, AUC 0.920119047164917, avg_entr 0.024987079203128815
ep11_l1_test_time 0.6827404499053955
Test Epoch11 layer2 Acc 0.8678, AUC 0.9331144690513611, avg_entr 0.019267704337835312
ep11_l2_test_time 1.0234415531158447
Test Epoch11 layer3 Acc 0.8672, AUC 0.9279227256774902, avg_entr 0.018142007291316986
ep11_l3_test_time 1.3331053256988525
Test Epoch11 layer4 Acc 0.8672, AUC 0.9343709945678711, avg_entr 0.01720798946917057
ep11_l4_test_time 1.6564640998840332
gc 0
Train Epoch12 Acc 0.981325 (39253/40000), AUC 0.9956165552139282
ep12_train_time 48.99872064590454
Test Epoch12 layer0 Acc 0.872, AUC 0.9416251182556152, avg_entr 0.12478923052549362
ep12_l0_test_time 0.3512606620788574
Test Epoch12 layer1 Acc 0.8628, AUC 0.9172173738479614, avg_entr 0.024241207167506218
ep12_l1_test_time 0.6844823360443115
Test Epoch12 layer2 Acc 0.8628, AUC 0.9295026063919067, avg_entr 0.01691891811788082
ep12_l2_test_time 1.0061962604522705
Test Epoch12 layer3 Acc 0.8628, AUC 0.9237667918205261, avg_entr 0.015926625579595566
ep12_l3_test_time 1.3335192203521729
Test Epoch12 layer4 Acc 0.8622, AUC 0.9320477843284607, avg_entr 0.014882802963256836
ep12_l4_test_time 1.659045696258545
gc 0
Train Epoch13 Acc 0.9821 (39284/40000), AUC 0.9957858324050903
ep13_train_time 49.025938987731934
Test Epoch13 layer0 Acc 0.871, AUC 0.9407915472984314, avg_entr 0.12414480000734329
ep13_l0_test_time 0.3533759117126465
Test Epoch13 layer1 Acc 0.8644, AUC 0.9167642593383789, avg_entr 0.024447038769721985
ep13_l1_test_time 0.678870677947998
Test Epoch13 layer2 Acc 0.864, AUC 0.9322527647018433, avg_entr 0.019744228571653366
ep13_l2_test_time 1.0105149745941162
Test Epoch13 layer3 Acc 0.8622, AUC 0.9264053106307983, avg_entr 0.018697313964366913
ep13_l3_test_time 1.32637619972229
Test Epoch13 layer4 Acc 0.8626, AUC 0.9324793815612793, avg_entr 0.017618916928768158
ep13_l4_test_time 1.6559815406799316
gc 0
Train Epoch14 Acc 0.9825 (39300/40000), AUC 0.996148407459259
ep14_train_time 49.032315731048584
Test Epoch14 layer0 Acc 0.8708, AUC 0.9396630525588989, avg_entr 0.12175573408603668
ep14_l0_test_time 0.3540472984313965
Test Epoch14 layer1 Acc 0.8634, AUC 0.9130869507789612, avg_entr 0.021354982629418373
ep14_l1_test_time 0.6833541393280029
Test Epoch14 layer2 Acc 0.8638, AUC 0.9264587759971619, avg_entr 0.015995535999536514
ep14_l2_test_time 1.0047199726104736
Test Epoch14 layer3 Acc 0.8634, AUC 0.9221822023391724, avg_entr 0.0149781359359622
ep14_l3_test_time 1.329063892364502
Test Epoch14 layer4 Acc 0.864, AUC 0.9301762580871582, avg_entr 0.014030282385647297
ep14_l4_test_time 1.6554327011108398
gc 0
Train Epoch15 Acc 0.9837 (39348/40000), AUC 0.996039628982544
ep15_train_time 49.01317524909973
Test Epoch15 layer0 Acc 0.8682, AUC 0.9392790794372559, avg_entr 0.12012580782175064
ep15_l0_test_time 0.35301804542541504
Test Epoch15 layer1 Acc 0.8632, AUC 0.9147663712501526, avg_entr 0.022970395162701607
ep15_l1_test_time 0.6812598705291748
Test Epoch15 layer2 Acc 0.8636, AUC 0.9283137321472168, avg_entr 0.01799614168703556
ep15_l2_test_time 1.0008869171142578
Test Epoch15 layer3 Acc 0.8632, AUC 0.923480212688446, avg_entr 0.017026387155056
ep15_l3_test_time 1.3301517963409424
Test Epoch15 layer4 Acc 0.8632, AUC 0.9296197891235352, avg_entr 0.01625613495707512
ep15_l4_test_time 1.6546452045440674
gc 0
Train Epoch16 Acc 0.98455 (39382/40000), AUC 0.9962646961212158
ep16_train_time 49.045498847961426
Test Epoch16 layer0 Acc 0.8684, AUC 0.9388550519943237, avg_entr 0.11938896775245667
ep16_l0_test_time 0.3534739017486572
Test Epoch16 layer1 Acc 0.8612, AUC 0.9131221771240234, avg_entr 0.022166265174746513
ep16_l1_test_time 0.6788513660430908
Test Epoch16 layer2 Acc 0.8632, AUC 0.9264076948165894, avg_entr 0.01685609668493271
ep16_l2_test_time 1.0057704448699951
Test Epoch16 layer3 Acc 0.8628, AUC 0.9204065799713135, avg_entr 0.015770738944411278
ep16_l3_test_time 1.3335840702056885
Test Epoch16 layer4 Acc 0.8632, AUC 0.9283543825149536, avg_entr 0.015112747438251972
ep16_l4_test_time 1.655442714691162
gc 0
Train Epoch17 Acc 0.984575 (39383/40000), AUC 0.9966175556182861
ep17_train_time 49.016899824142456
Test Epoch17 layer0 Acc 0.8686, AUC 0.938399076461792, avg_entr 0.11842094361782074
ep17_l0_test_time 0.3567500114440918
Test Epoch17 layer1 Acc 0.8614, AUC 0.9112983345985413, avg_entr 0.02120966464281082
ep17_l1_test_time 0.6862719058990479
Test Epoch17 layer2 Acc 0.8618, AUC 0.9228445291519165, avg_entr 0.015372907742857933
ep17_l2_test_time 1.0075819492340088
Test Epoch17 layer3 Acc 0.8616, AUC 0.9157769680023193, avg_entr 0.014351623132824898
ep17_l3_test_time 1.332923173904419
Test Epoch17 layer4 Acc 0.8616, AUC 0.9263074994087219, avg_entr 0.013813501223921776
ep17_l4_test_time 1.657560110092163
gc 0
Train Epoch18 Acc 0.9848 (39392/40000), AUC 0.9966962337493896
ep18_train_time 49.02404522895813
Test Epoch18 layer0 Acc 0.8668, AUC 0.9380550384521484, avg_entr 0.11739472299814224
ep18_l0_test_time 0.35149621963500977
Test Epoch18 layer1 Acc 0.8598, AUC 0.9088109731674194, avg_entr 0.02125392109155655
ep18_l1_test_time 0.6823711395263672
Test Epoch18 layer2 Acc 0.8616, AUC 0.9181692600250244, avg_entr 0.015350828878581524
ep18_l2_test_time 1.0012128353118896
Test Epoch18 layer3 Acc 0.8616, AUC 0.9118182063102722, avg_entr 0.014406581409275532
ep18_l3_test_time 1.3266732692718506
Test Epoch18 layer4 Acc 0.8624, AUC 0.9244486093521118, avg_entr 0.013916880823671818
ep18_l4_test_time 1.6522729396820068
gc 0
Train Epoch19 Acc 0.985 (39400/40000), AUC 0.9967322945594788
ep19_train_time 49.02314639091492
Test Epoch19 layer0 Acc 0.8688, AUC 0.9376142621040344, avg_entr 0.11677530407905579
ep19_l0_test_time 0.35726475715637207
Test Epoch19 layer1 Acc 0.8604, AUC 0.9092850089073181, avg_entr 0.020863519981503487
ep19_l1_test_time 0.6796166896820068
Test Epoch19 layer2 Acc 0.861, AUC 0.9219886064529419, avg_entr 0.016442960128188133
ep19_l2_test_time 1.0055103302001953
Test Epoch19 layer3 Acc 0.8614, AUC 0.916513204574585, avg_entr 0.01566656120121479
ep19_l3_test_time 1.3277552127838135
Test Epoch19 layer4 Acc 0.8606, AUC 0.9256014227867126, avg_entr 0.0148646654561162
ep19_l4_test_time 1.652519941329956
gc 0
Train Epoch20 Acc 0.985625 (39425/40000), AUC 0.9968388676643372
ep20_train_time 49.04223299026489
Test Epoch20 layer0 Acc 0.866, AUC 0.9374608993530273, avg_entr 0.11593930423259735
ep20_l0_test_time 0.35275816917419434
Test Epoch20 layer1 Acc 0.8618, AUC 0.9092327356338501, avg_entr 0.020125268027186394
ep20_l1_test_time 0.6787858009338379
Test Epoch20 layer2 Acc 0.8612, AUC 0.9187017679214478, avg_entr 0.014256551861763
ep20_l2_test_time 1.0037651062011719
Test Epoch20 layer3 Acc 0.8614, AUC 0.9134647846221924, avg_entr 0.013261446729302406
ep20_l3_test_time 1.3313488960266113
Test Epoch20 layer4 Acc 0.8616, AUC 0.9246467351913452, avg_entr 0.012546899728477001
ep20_l4_test_time 1.6536860466003418
gc 0
Train Epoch21 Acc 0.98545 (39418/40000), AUC 0.9966031312942505
ep21_train_time 49.05477523803711
Test Epoch21 layer0 Acc 0.8668, AUC 0.9372448325157166, avg_entr 0.11553832143545151
ep21_l0_test_time 0.352297306060791
Test Epoch21 layer1 Acc 0.8614, AUC 0.9095867276191711, avg_entr 0.019924897700548172
ep21_l1_test_time 0.6820881366729736
Test Epoch21 layer2 Acc 0.8608, AUC 0.9187256693840027, avg_entr 0.01443579699844122
ep21_l2_test_time 1.0010457038879395
Test Epoch21 layer3 Acc 0.8614, AUC 0.9131367802619934, avg_entr 0.01354349683970213
ep21_l3_test_time 1.3356678485870361
Test Epoch21 layer4 Acc 0.8612, AUC 0.9244194030761719, avg_entr 0.012815876863896847
ep21_l4_test_time 1.6522314548492432
gc 0
Train Epoch22 Acc 0.985775 (39431/40000), AUC 0.9971417784690857
ep22_train_time 49.02359366416931
Test Epoch22 layer0 Acc 0.8668, AUC 0.9370884299278259, avg_entr 0.11456388235092163
ep22_l0_test_time 0.3526628017425537
Test Epoch22 layer1 Acc 0.8616, AUC 0.9075683951377869, avg_entr 0.020076174288988113
ep22_l1_test_time 0.6803157329559326
Test Epoch22 layer2 Acc 0.8616, AUC 0.9158980250358582, avg_entr 0.014602795243263245
ep22_l2_test_time 1.0025484561920166
Test Epoch22 layer3 Acc 0.862, AUC 0.9105082750320435, avg_entr 0.013739921152591705
ep22_l3_test_time 1.3272199630737305
Test Epoch22 layer4 Acc 0.862, AUC 0.9228320121765137, avg_entr 0.013165087439119816
ep22_l4_test_time 1.6532914638519287
gc 0
Train Epoch23 Acc 0.9858 (39432/40000), AUC 0.9970532655715942
ep23_train_time 49.028013944625854
Test Epoch23 layer0 Acc 0.8666, AUC 0.9368743896484375, avg_entr 0.1142323836684227
ep23_l0_test_time 0.35857510566711426
Test Epoch23 layer1 Acc 0.8604, AUC 0.9079121351242065, avg_entr 0.019808107987046242
ep23_l1_test_time 0.6794948577880859
Test Epoch23 layer2 Acc 0.8614, AUC 0.9164476990699768, avg_entr 0.014552493579685688
ep23_l2_test_time 1.0161762237548828
Test Epoch23 layer3 Acc 0.8616, AUC 0.9105759859085083, avg_entr 0.0137161361053586
ep23_l3_test_time 1.3299684524536133
Test Epoch23 layer4 Acc 0.862, AUC 0.9228437542915344, avg_entr 0.01309899426996708
ep23_l4_test_time 1.6574676036834717
gc 0
Train Epoch24 Acc 0.985875 (39435/40000), AUC 0.9971083998680115
ep24_train_time 49.03257894515991
Test Epoch24 layer0 Acc 0.865, AUC 0.9367804527282715, avg_entr 0.11367885768413544
ep24_l0_test_time 0.3561220169067383
Test Epoch24 layer1 Acc 0.8622, AUC 0.9072884321212769, avg_entr 0.019862143322825432
ep24_l1_test_time 0.6841616630554199
Test Epoch24 layer2 Acc 0.861, AUC 0.9156534671783447, avg_entr 0.014673696830868721
ep24_l2_test_time 1.0037026405334473
Test Epoch24 layer3 Acc 0.8608, AUC 0.9101810455322266, avg_entr 0.013911033980548382
ep24_l3_test_time 1.3348636627197266
Test Epoch24 layer4 Acc 0.8606, AUC 0.9224671125411987, avg_entr 0.01329584326595068
ep24_l4_test_time 1.6606981754302979
gc 0
Train Epoch25 Acc 0.98605 (39442/40000), AUC 0.9969788193702698
ep25_train_time 49.05310344696045
Test Epoch25 layer0 Acc 0.8666, AUC 0.9367369413375854, avg_entr 0.11326505988836288
ep25_l0_test_time 0.3511025905609131
Test Epoch25 layer1 Acc 0.86, AUC 0.9073338508605957, avg_entr 0.019460348412394524
ep25_l1_test_time 0.679816484451294
Test Epoch25 layer2 Acc 0.8622, AUC 0.9161921739578247, avg_entr 0.014155433513224125
ep25_l2_test_time 1.0046186447143555
Test Epoch25 layer3 Acc 0.8614, AUC 0.9111342430114746, avg_entr 0.013255296275019646
ep25_l3_test_time 1.3322279453277588
Test Epoch25 layer4 Acc 0.8622, AUC 0.9226338863372803, avg_entr 0.012630045413970947
ep25_l4_test_time 1.6566352844238281
gc 0
Train Epoch26 Acc 0.9859 (39436/40000), AUC 0.9970852136611938
ep26_train_time 49.053322315216064
Test Epoch26 layer0 Acc 0.8654, AUC 0.9366585612297058, avg_entr 0.1126362755894661
ep26_l0_test_time 0.35445261001586914
Test Epoch26 layer1 Acc 0.86, AUC 0.90620356798172, avg_entr 0.01930825412273407
ep26_l1_test_time 0.6803007125854492
Test Epoch26 layer2 Acc 0.8608, AUC 0.9137324094772339, avg_entr 0.013911375775933266
ep26_l2_test_time 1.0030241012573242
Test Epoch26 layer3 Acc 0.8602, AUC 0.9084649085998535, avg_entr 0.013115751557052135
ep26_l3_test_time 1.3414649963378906
Test Epoch26 layer4 Acc 0.8606, AUC 0.9213581085205078, avg_entr 0.012515944428741932
ep26_l4_test_time 1.6582155227661133
gc 0
Train Epoch27 Acc 0.98615 (39446/40000), AUC 0.9972692728042603
ep27_train_time 49.03471779823303
Test Epoch27 layer0 Acc 0.8652, AUC 0.9366137385368347, avg_entr 0.11213500052690506
ep27_l0_test_time 0.35327816009521484
Test Epoch27 layer1 Acc 0.8608, AUC 0.9066112041473389, avg_entr 0.019068777561187744
ep27_l1_test_time 0.6813747882843018
Test Epoch27 layer2 Acc 0.8604, AUC 0.9140691757202148, avg_entr 0.013784179463982582
ep27_l2_test_time 1.001762866973877
Test Epoch27 layer3 Acc 0.8604, AUC 0.9085936546325684, avg_entr 0.012971146032214165
ep27_l3_test_time 1.3308184146881104
Test Epoch27 layer4 Acc 0.8604, AUC 0.921377420425415, avg_entr 0.012367196381092072
ep27_l4_test_time 1.6587722301483154
gc 0
Train Epoch28 Acc 0.986275 (39451/40000), AUC 0.9970579147338867
ep28_train_time 49.021852016448975
Test Epoch28 layer0 Acc 0.8648, AUC 0.9365571737289429, avg_entr 0.11185289174318314
ep28_l0_test_time 0.35695886611938477
Test Epoch28 layer1 Acc 0.8606, AUC 0.9065992832183838, avg_entr 0.019281670451164246
ep28_l1_test_time 0.6798808574676514
Test Epoch28 layer2 Acc 0.8604, AUC 0.9143731594085693, avg_entr 0.014125450514256954
ep28_l2_test_time 1.0075459480285645
Test Epoch28 layer3 Acc 0.8606, AUC 0.9090979099273682, avg_entr 0.0133905578404665
ep28_l3_test_time 1.3303794860839844
Test Epoch28 layer4 Acc 0.8604, AUC 0.9216184616088867, avg_entr 0.0128099974244833
ep28_l4_test_time 1.6530826091766357
gc 0
Train Epoch29 Acc 0.986375 (39455/40000), AUC 0.9971473813056946
ep29_train_time 49.0259165763855
Test Epoch29 layer0 Acc 0.8652, AUC 0.9365121126174927, avg_entr 0.11166481673717499
ep29_l0_test_time 0.35671210289001465
Test Epoch29 layer1 Acc 0.86, AUC 0.9069971442222595, avg_entr 0.019181305542588234
ep29_l1_test_time 0.6804687976837158
Test Epoch29 layer2 Acc 0.8608, AUC 0.9144732356071472, avg_entr 0.013982577249407768
ep29_l2_test_time 1.0040202140808105
Test Epoch29 layer3 Acc 0.8614, AUC 0.909240186214447, avg_entr 0.013165646232664585
ep29_l3_test_time 1.3266394138336182
Test Epoch29 layer4 Acc 0.8612, AUC 0.9215471148490906, avg_entr 0.012570592574775219
ep29_l4_test_time 1.6543927192687988
gc 0
Train Epoch30 Acc 0.98595 (39438/40000), AUC 0.9973442554473877
ep30_train_time 49.02585411071777
Test Epoch30 layer0 Acc 0.8662, AUC 0.9364778995513916, avg_entr 0.11133718490600586
ep30_l0_test_time 0.3528759479522705
Test Epoch30 layer1 Acc 0.86, AUC 0.9066193103790283, avg_entr 0.018981868401169777
ep30_l1_test_time 0.680436372756958
Test Epoch30 layer2 Acc 0.8612, AUC 0.9136393070220947, avg_entr 0.013824056833982468
ep30_l2_test_time 1.0004053115844727
Test Epoch30 layer3 Acc 0.861, AUC 0.9085755348205566, avg_entr 0.012960218824446201
ep30_l3_test_time 1.331913948059082
Test Epoch30 layer4 Acc 0.8614, AUC 0.9213168621063232, avg_entr 0.01238055620342493
ep30_l4_test_time 1.6563167572021484
gc 0
Train Epoch31 Acc 0.98625 (39450/40000), AUC 0.9973509907722473
ep31_train_time 49.096216440200806
Test Epoch31 layer0 Acc 0.8654, AUC 0.9364287853240967, avg_entr 0.11098095774650574
ep31_l0_test_time 0.35281872749328613
Test Epoch31 layer1 Acc 0.86, AUC 0.9062867164611816, avg_entr 0.01883670687675476
ep31_l1_test_time 0.676037073135376
Test Epoch31 layer2 Acc 0.8604, AUC 0.9126768708229065, avg_entr 0.01364551205188036
ep31_l2_test_time 1.0119190216064453
Test Epoch31 layer3 Acc 0.86, AUC 0.9079151153564453, avg_entr 0.012876116670668125
ep31_l3_test_time 1.324753999710083
Test Epoch31 layer4 Acc 0.8604, AUC 0.9208488464355469, avg_entr 0.012333479709923267
ep31_l4_test_time 1.6522045135498047
gc 0
Train Epoch32 Acc 0.986375 (39455/40000), AUC 0.9970515966415405
ep32_train_time 49.05076622962952
Test Epoch32 layer0 Acc 0.8648, AUC 0.9364216327667236, avg_entr 0.11082983762025833
ep32_l0_test_time 0.35438108444213867
Test Epoch32 layer1 Acc 0.86, AUC 0.906650185585022, avg_entr 0.01896580122411251
ep32_l1_test_time 0.6790063381195068
Test Epoch32 layer2 Acc 0.86, AUC 0.9131380915641785, avg_entr 0.013896395452320576
ep32_l2_test_time 1.0027985572814941
Test Epoch32 layer3 Acc 0.8606, AUC 0.9080657362937927, avg_entr 0.013139220885932446
ep32_l3_test_time 1.3263845443725586
Test Epoch32 layer4 Acc 0.8602, AUC 0.9210125207901001, avg_entr 0.012571176514029503
ep32_l4_test_time 1.6523964405059814
gc 0
Train Epoch33 Acc 0.9864 (39456/40000), AUC 0.9972279071807861
ep33_train_time 49.11471223831177
Test Epoch33 layer0 Acc 0.8648, AUC 0.9364134073257446, avg_entr 0.11050113290548325
ep33_l0_test_time 0.35401201248168945
Test Epoch33 layer1 Acc 0.86, AUC 0.9065736532211304, avg_entr 0.018823323771357536
ep33_l1_test_time 0.6821010112762451
Test Epoch33 layer2 Acc 0.8608, AUC 0.9128433465957642, avg_entr 0.013719848357141018
ep33_l2_test_time 1.0096867084503174
Test Epoch33 layer3 Acc 0.861, AUC 0.9077267646789551, avg_entr 0.012903187423944473
ep33_l3_test_time 1.3340604305267334
Test Epoch33 layer4 Acc 0.8608, AUC 0.920917272567749, avg_entr 0.012367106974124908
ep33_l4_test_time 1.6537466049194336
gc 0
Train Epoch34 Acc 0.986925 (39477/40000), AUC 0.9972693920135498
ep34_train_time 49.04250621795654
Test Epoch34 layer0 Acc 0.8654, AUC 0.9364000558853149, avg_entr 0.11025863885879517
ep34_l0_test_time 0.35405898094177246
Test Epoch34 layer1 Acc 0.8604, AUC 0.9066566228866577, avg_entr 0.01876642368733883
ep34_l1_test_time 0.6842067241668701
Test Epoch34 layer2 Acc 0.8602, AUC 0.9126788377761841, avg_entr 0.013629200868308544
ep34_l2_test_time 1.0172536373138428
Test Epoch34 layer3 Acc 0.86, AUC 0.9077163338661194, avg_entr 0.01287506427615881
ep34_l3_test_time 1.3499224185943604
Test Epoch34 layer4 Acc 0.8604, AUC 0.9207404255867004, avg_entr 0.012322762049734592
ep34_l4_test_time 1.6595821380615234
gc 0
Train Epoch35 Acc 0.98645 (39458/40000), AUC 0.9973843097686768
ep35_train_time 49.1340696811676
Test Epoch35 layer0 Acc 0.8644, AUC 0.9363852739334106, avg_entr 0.1100226566195488
ep35_l0_test_time 0.3526017665863037
Test Epoch35 layer1 Acc 0.8596, AUC 0.9066216945648193, avg_entr 0.018711237236857414
ep35_l1_test_time 0.6787493228912354
Test Epoch35 layer2 Acc 0.8602, AUC 0.9126067161560059, avg_entr 0.013616346754133701
ep35_l2_test_time 1.002011775970459
Test Epoch35 layer3 Acc 0.861, AUC 0.9075325131416321, avg_entr 0.012859511189162731
ep35_l3_test_time 1.3288731575012207
Test Epoch35 layer4 Acc 0.8608, AUC 0.9206715822219849, avg_entr 0.012304182164371014
ep35_l4_test_time 1.6653130054473877
gc 0
Train Epoch36 Acc 0.98675 (39470/40000), AUC 0.9972547888755798
ep36_train_time 49.17091774940491
Test Epoch36 layer0 Acc 0.8646, AUC 0.9363794326782227, avg_entr 0.10988081246614456
ep36_l0_test_time 0.35549187660217285
Test Epoch36 layer1 Acc 0.8606, AUC 0.9067672491073608, avg_entr 0.01846330240368843
ep36_l1_test_time 0.691544771194458
Test Epoch36 layer2 Acc 0.8604, AUC 0.913114070892334, avg_entr 0.013173827901482582
ep36_l2_test_time 1.0071189403533936
Test Epoch36 layer3 Acc 0.8604, AUC 0.907944917678833, avg_entr 0.012339901179075241
ep36_l3_test_time 1.3287651538848877
Test Epoch36 layer4 Acc 0.8602, AUC 0.9208805561065674, avg_entr 0.011703931726515293
ep36_l4_test_time 1.6536955833435059
gc 0
Train Epoch37 Acc 0.986275 (39451/40000), AUC 0.9969693422317505
ep37_train_time 49.04458165168762
Test Epoch37 layer0 Acc 0.8654, AUC 0.9363749027252197, avg_entr 0.10966955870389938
ep37_l0_test_time 0.3527686595916748
Test Epoch37 layer1 Acc 0.8598, AUC 0.9064757823944092, avg_entr 0.018617786467075348
ep37_l1_test_time 0.6784670352935791
Test Epoch37 layer2 Acc 0.8602, AUC 0.9122612476348877, avg_entr 0.013474847190082073
ep37_l2_test_time 1.0075595378875732
Test Epoch37 layer3 Acc 0.8596, AUC 0.9071367383003235, avg_entr 0.012753918766975403
ep37_l3_test_time 1.3313713073730469
Test Epoch37 layer4 Acc 0.86, AUC 0.9205626249313354, avg_entr 0.012209080159664154
ep37_l4_test_time 1.6578469276428223
gc 0
Train Epoch38 Acc 0.98665 (39466/40000), AUC 0.997412919998169
ep38_train_time 49.08213925361633
Test Epoch38 layer0 Acc 0.8658, AUC 0.9363768100738525, avg_entr 0.1094956174492836
ep38_l0_test_time 0.35239553451538086
Test Epoch38 layer1 Acc 0.8598, AUC 0.9065564870834351, avg_entr 0.018554463982582092
ep38_l1_test_time 0.6785757541656494
Test Epoch38 layer2 Acc 0.86, AUC 0.9122858047485352, avg_entr 0.013468216173350811
ep38_l2_test_time 1.0031988620758057
Test Epoch38 layer3 Acc 0.8606, AUC 0.9071288108825684, avg_entr 0.012721346691250801
ep38_l3_test_time 1.325749397277832
Test Epoch38 layer4 Acc 0.8602, AUC 0.9205449223518372, avg_entr 0.0121857775375247
ep38_l4_test_time 1.657975435256958
gc 0
Train Epoch39 Acc 0.986825 (39473/40000), AUC 0.9973514080047607
ep39_train_time 49.16466689109802
Test Epoch39 layer0 Acc 0.8658, AUC 0.9363716840744019, avg_entr 0.10929643362760544
ep39_l0_test_time 0.35230183601379395
Test Epoch39 layer1 Acc 0.8596, AUC 0.9065583944320679, avg_entr 0.018508557230234146
ep39_l1_test_time 0.6985676288604736
Test Epoch39 layer2 Acc 0.8608, AUC 0.912317156791687, avg_entr 0.013470867648720741
ep39_l2_test_time 1.0057272911071777
Test Epoch39 layer3 Acc 0.8604, AUC 0.9071776270866394, avg_entr 0.012696442194283009
ep39_l3_test_time 1.3450171947479248
Test Epoch39 layer4 Acc 0.8608, AUC 0.9205482602119446, avg_entr 0.012167690321803093
ep39_l4_test_time 1.674938678741455
gc 0
Train Epoch40 Acc 0.986775 (39471/40000), AUC 0.9972161054611206
ep40_train_time 49.12671160697937
Test Epoch40 layer0 Acc 0.8656, AUC 0.936373233795166, avg_entr 0.10918009281158447
ep40_l0_test_time 0.361053466796875
Test Epoch40 layer1 Acc 0.8598, AUC 0.9065366387367249, avg_entr 0.018491938710212708
ep40_l1_test_time 0.6829309463500977
Test Epoch40 layer2 Acc 0.8602, AUC 0.9121854901313782, avg_entr 0.013459068723022938
ep40_l2_test_time 1.0033214092254639
Test Epoch40 layer3 Acc 0.861, AUC 0.9071167707443237, avg_entr 0.012710045091807842
ep40_l3_test_time 1.3320567607879639
Test Epoch40 layer4 Acc 0.8604, AUC 0.9204964637756348, avg_entr 0.012186462990939617
ep40_l4_test_time 1.6538748741149902
gc 0
Train Epoch41 Acc 0.9865 (39460/40000), AUC 0.9969595670700073
ep41_train_time 49.09022068977356
Test Epoch41 layer0 Acc 0.8648, AUC 0.9363687038421631, avg_entr 0.10908680409193039
ep41_l0_test_time 0.35547685623168945
Test Epoch41 layer1 Acc 0.8598, AUC 0.9065757393836975, avg_entr 0.018459971994161606
ep41_l1_test_time 0.6813457012176514
Test Epoch41 layer2 Acc 0.8598, AUC 0.9122457504272461, avg_entr 0.0134330615401268
ep41_l2_test_time 1.0024645328521729
Test Epoch41 layer3 Acc 0.8608, AUC 0.9071756601333618, avg_entr 0.012686677277088165
ep41_l3_test_time 1.3298113346099854
Test Epoch41 layer4 Acc 0.8604, AUC 0.9205464720726013, avg_entr 0.012160785496234894
ep41_l4_test_time 1.6553211212158203
gc 0
Train Epoch42 Acc 0.98685 (39474/40000), AUC 0.9973656535148621
ep42_train_time 49.07754063606262
Test Epoch42 layer0 Acc 0.8658, AUC 0.9363768696784973, avg_entr 0.10893061757087708
ep42_l0_test_time 0.358121395111084
Test Epoch42 layer1 Acc 0.8598, AUC 0.906555712223053, avg_entr 0.018424997106194496
ep42_l1_test_time 0.6783537864685059
Test Epoch42 layer2 Acc 0.8598, AUC 0.9121414422988892, avg_entr 0.013403215445578098
ep42_l2_test_time 1.0064380168914795
Test Epoch42 layer3 Acc 0.8608, AUC 0.907056987285614, avg_entr 0.01265638880431652
ep42_l3_test_time 1.3314664363861084
Test Epoch42 layer4 Acc 0.8604, AUC 0.9205138683319092, avg_entr 0.012126578949391842
ep42_l4_test_time 1.66241455078125
gc 0
Train Epoch43 Acc 0.986525 (39461/40000), AUC 0.9973447322845459
ep43_train_time 49.12088084220886
Test Epoch43 layer0 Acc 0.8648, AUC 0.9363754987716675, avg_entr 0.10880883783102036
ep43_l0_test_time 0.352628231048584
Test Epoch43 layer1 Acc 0.8596, AUC 0.9065704345703125, avg_entr 0.01839527301490307
ep43_l1_test_time 0.682506799697876
Test Epoch43 layer2 Acc 0.86, AUC 0.9121520519256592, avg_entr 0.013394164852797985
ep43_l2_test_time 1.0025343894958496
Test Epoch43 layer3 Acc 0.8606, AUC 0.9070422649383545, avg_entr 0.012644556351006031
ep43_l3_test_time 1.3282175064086914
Test Epoch43 layer4 Acc 0.8606, AUC 0.9204922318458557, avg_entr 0.012112995609641075
ep43_l4_test_time 1.6547586917877197
gc 0
Train Epoch44 Acc 0.986625 (39465/40000), AUC 0.997267484664917
ep44_train_time 49.05425214767456
Test Epoch44 layer0 Acc 0.8656, AUC 0.9363774061203003, avg_entr 0.10872378200292587
ep44_l0_test_time 0.3525104522705078
Test Epoch44 layer1 Acc 0.8598, AUC 0.906589686870575, avg_entr 0.018387267366051674
ep44_l1_test_time 0.6853411197662354
Test Epoch44 layer2 Acc 0.8598, AUC 0.9121878743171692, avg_entr 0.013376663438975811
ep44_l2_test_time 1.00864577293396
Test Epoch44 layer3 Acc 0.861, AUC 0.9070284366607666, avg_entr 0.01263708807528019
ep44_l3_test_time 1.3367037773132324
Test Epoch44 layer4 Acc 0.86, AUC 0.9205199480056763, avg_entr 0.01210564561188221
ep44_l4_test_time 1.658358097076416
gc 0
Train Epoch45 Acc 0.986675 (39467/40000), AUC 0.9972145557403564
ep45_train_time 49.07592153549194
Test Epoch45 layer0 Acc 0.8658, AUC 0.9363763928413391, avg_entr 0.10862603783607483
ep45_l0_test_time 0.36328673362731934
Test Epoch45 layer1 Acc 0.8596, AUC 0.9065390825271606, avg_entr 0.01836804673075676
ep45_l1_test_time 0.6791152954101562
Test Epoch45 layer2 Acc 0.86, AUC 0.9120105504989624, avg_entr 0.013299117796123028
ep45_l2_test_time 1.0122466087341309
Test Epoch45 layer3 Acc 0.8596, AUC 0.9069545269012451, avg_entr 0.012576006352901459
ep45_l3_test_time 1.3364017009735107
Test Epoch45 layer4 Acc 0.8598, AUC 0.9204465746879578, avg_entr 0.012039963155984879
ep45_l4_test_time 1.6634852886199951
gc 0
Train Epoch46 Acc 0.9867 (39468/40000), AUC 0.9972772598266602
ep46_train_time 49.04847240447998
Test Epoch46 layer0 Acc 0.8658, AUC 0.9363758563995361, avg_entr 0.1085502952337265
ep46_l0_test_time 0.3526315689086914
Test Epoch46 layer1 Acc 0.8596, AUC 0.9066367745399475, avg_entr 0.018341049551963806
ep46_l1_test_time 0.6834981441497803
Test Epoch46 layer2 Acc 0.86, AUC 0.9122196435928345, avg_entr 0.01335496362298727
ep46_l2_test_time 1.0036866664886475
Test Epoch46 layer3 Acc 0.8606, AUC 0.9069716930389404, avg_entr 0.01260742824524641
ep46_l3_test_time 1.331622838973999
Test Epoch46 layer4 Acc 0.8606, AUC 0.9205024242401123, avg_entr 0.012072065845131874
ep46_l4_test_time 1.6524629592895508
gc 0
Train Epoch47 Acc 0.986525 (39461/40000), AUC 0.9974889159202576
ep47_train_time 49.05069303512573
Test Epoch47 layer0 Acc 0.8658, AUC 0.9363797903060913, avg_entr 0.10844213515520096
ep47_l0_test_time 0.3602738380432129
Test Epoch47 layer1 Acc 0.8598, AUC 0.9066364765167236, avg_entr 0.018326779827475548
ep47_l1_test_time 0.6791718006134033
Test Epoch47 layer2 Acc 0.8598, AUC 0.912146806716919, avg_entr 0.013324443250894547
ep47_l2_test_time 1.0047307014465332
Test Epoch47 layer3 Acc 0.861, AUC 0.9070184230804443, avg_entr 0.012586950324475765
ep47_l3_test_time 1.3247451782226562
Test Epoch47 layer4 Acc 0.86, AUC 0.9204658269882202, avg_entr 0.012054329738020897
ep47_l4_test_time 1.6529200077056885
gc 0
Train Epoch48 Acc 0.986575 (39463/40000), AUC 0.9975115060806274
ep48_train_time 49.08836245536804
Test Epoch48 layer0 Acc 0.8658, AUC 0.9363812208175659, avg_entr 0.10839218646287918
ep48_l0_test_time 0.35259127616882324
Test Epoch48 layer1 Acc 0.8598, AUC 0.9066445827484131, avg_entr 0.018313536420464516
ep48_l1_test_time 0.6789679527282715
Test Epoch48 layer2 Acc 0.8598, AUC 0.9121816158294678, avg_entr 0.01330727431923151
ep48_l2_test_time 1.0055925846099854
Test Epoch48 layer3 Acc 0.8608, AUC 0.9069876074790955, avg_entr 0.012571492232382298
ep48_l3_test_time 1.3335819244384766
Test Epoch48 layer4 Acc 0.86, AUC 0.9204456210136414, avg_entr 0.01204043161123991
ep48_l4_test_time 1.658825397491455
gc 0
Train Epoch49 Acc 0.98645 (39458/40000), AUC 0.9972960948944092
ep49_train_time 49.20736575126648
Test Epoch49 layer0 Acc 0.8658, AUC 0.9363809823989868, avg_entr 0.10834074765443802
ep49_l0_test_time 0.35064053535461426
Test Epoch49 layer1 Acc 0.8598, AUC 0.9066553711891174, avg_entr 0.01830260269343853
ep49_l1_test_time 0.6813740730285645
Test Epoch49 layer2 Acc 0.8598, AUC 0.9121366143226624, avg_entr 0.01329129934310913
ep49_l2_test_time 1.0004115104675293
Test Epoch49 layer3 Acc 0.8608, AUC 0.906906008720398, avg_entr 0.012556069530546665
ep49_l3_test_time 1.325772762298584
Test Epoch49 layer4 Acc 0.8598, AUC 0.9204123020172119, avg_entr 0.012024521827697754
ep49_l4_test_time 1.6528170108795166
Best AUC 0.9557709097862244
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train+valid_time 2707.758717775345
Start Testing
Load ckpt at ckpt/imdb_transformeral_l5_pad300//imdb_transformeral_l5.pt
Test layer0 Acc 0.8868, AUC 0.9514070749282837, avg_entr 0.20724418759346008
l0_test_time 0.35047149658203125
Test layer1 Acc 0.8776, AUC 0.9528443813323975, avg_entr 0.15004591643810272
l1_test_time 0.6785550117492676
Test layer2 Acc 0.8796, AUC 0.9527602791786194, avg_entr 0.09412309527397156
l2_test_time 1.0005810260772705
Test layer3 Acc 0.8786, AUC 0.9528218507766724, avg_entr 0.06825345754623413
l3_test_time 1.3243861198425293
Test layer4 Acc 0.8786, AUC 0.952979326248169, avg_entr 0.05896356329321861
l4_test_time 1.6599376201629639
