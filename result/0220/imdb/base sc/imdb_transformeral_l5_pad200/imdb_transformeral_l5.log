total count words 222751
vocab size 30000
train size 40000, valid size 5000, test size 5000
found 27937 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=2, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=2, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 256
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 256
layers.0.ae.h.0.bias 2
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13671778
init_time 21.503822088241577
Start Training
gc 0
Train Epoch0 Acc 0.48935 (19574/40000), AUC 0.48742514848709106
ep0_train_time 31.08670687675476
Test Epoch0 layer0 Acc 0.8344, AUC 0.9144690632820129, avg_entr 0.4296453595161438
ep0_l0_test_time 0.24688434600830078
Save ckpt to ckpt/imdb_transformeral_l5_pad200//imdb_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.802, AUC 0.9074357748031616, avg_entr 0.3731432259082794
ep0_l1_test_time 0.4461708068847656
Test Epoch0 layer2 Acc 0.7846, AUC 0.9053677320480347, avg_entr 0.5591539144515991
ep0_l2_test_time 0.6399502754211426
Test Epoch0 layer3 Acc 0.7086, AUC 0.8928828239440918, avg_entr 0.6552714705467224
ep0_l3_test_time 0.8327932357788086
Test Epoch0 layer4 Acc 0.4772, AUC 0.37685757875442505, avg_entr 0.685905396938324
ep0_l4_test_time 1.0222527980804443
gc 0
Train Epoch1 Acc 0.84385 (33754/40000), AUC 0.9204222559928894
ep1_train_time 30.74578595161438
Test Epoch1 layer0 Acc 0.8752, AUC 0.9436925053596497, avg_entr 0.2501777112483978
ep1_l0_test_time 0.24506068229675293
Save ckpt to ckpt/imdb_transformeral_l5_pad200//imdb_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.8828, AUC 0.9480276107788086, avg_entr 0.197963684797287
ep1_l1_test_time 0.4471743106842041
Save ckpt to ckpt/imdb_transformeral_l5_pad200//imdb_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.8838, AUC 0.9484465718269348, avg_entr 0.17298714816570282
ep1_l2_test_time 0.6433510780334473
Save ckpt to ckpt/imdb_transformeral_l5_pad200//imdb_transformeral_l5.pt  ,ep 1
Test Epoch1 layer3 Acc 0.8716, AUC 0.9483036994934082, avg_entr 0.16142958402633667
ep1_l3_test_time 0.8306519985198975
Test Epoch1 layer4 Acc 0.872, AUC 0.9483938217163086, avg_entr 0.15710534155368805
ep1_l4_test_time 1.0260963439941406
gc 0
Train Epoch2 Acc 0.914875 (36595/40000), AUC 0.9699193239212036
ep2_train_time 30.741360425949097
Test Epoch2 layer0 Acc 0.8796, AUC 0.9483493566513062, avg_entr 0.20466557145118713
ep2_l0_test_time 0.2492663860321045
Test Epoch2 layer1 Acc 0.8778, AUC 0.948338508605957, avg_entr 0.1574084609746933
ep2_l1_test_time 0.44359683990478516
Test Epoch2 layer2 Acc 0.878, AUC 0.9488769769668579, avg_entr 0.10322872549295425
ep2_l2_test_time 0.6420798301696777
Save ckpt to ckpt/imdb_transformeral_l5_pad200//imdb_transformeral_l5.pt  ,ep 2
Test Epoch2 layer3 Acc 0.8802, AUC 0.9481523036956787, avg_entr 0.07807642221450806
ep2_l3_test_time 0.8337435722351074
Test Epoch2 layer4 Acc 0.8776, AUC 0.9482245445251465, avg_entr 0.06713058799505234
ep2_l4_test_time 1.0270390510559082
gc 0
Train Epoch3 Acc 0.94025 (37610/40000), AUC 0.9825307130813599
ep3_train_time 30.68213939666748
Test Epoch3 layer0 Acc 0.8802, AUC 0.9481234550476074, avg_entr 0.17803840339183807
ep3_l0_test_time 0.24373173713684082
Test Epoch3 layer1 Acc 0.8636, AUC 0.9434876441955566, avg_entr 0.12335172295570374
ep3_l1_test_time 0.4416320323944092
Test Epoch3 layer2 Acc 0.8602, AUC 0.9428019523620605, avg_entr 0.062091510742902756
ep3_l2_test_time 0.6404826641082764
Test Epoch3 layer3 Acc 0.861, AUC 0.9425939321517944, avg_entr 0.05239522084593773
ep3_l3_test_time 0.8288712501525879
Test Epoch3 layer4 Acc 0.8584, AUC 0.9428882002830505, avg_entr 0.04685099050402641
ep3_l4_test_time 1.023789405822754
gc 0
Train Epoch4 Acc 0.953775 (38151/40000), AUC 0.9871941804885864
ep4_train_time 30.68697714805603
Test Epoch4 layer0 Acc 0.8752, AUC 0.9456822872161865, avg_entr 0.16006602346897125
ep4_l0_test_time 0.2441112995147705
Test Epoch4 layer1 Acc 0.8674, AUC 0.9387297630310059, avg_entr 0.07041676342487335
ep4_l1_test_time 0.4418604373931885
Test Epoch4 layer2 Acc 0.8664, AUC 0.9387910962104797, avg_entr 0.044844139367341995
ep4_l2_test_time 0.6392819881439209
Test Epoch4 layer3 Acc 0.8658, AUC 0.9402698278427124, avg_entr 0.04328387230634689
ep4_l3_test_time 0.8312335014343262
Test Epoch4 layer4 Acc 0.8664, AUC 0.9402076005935669, avg_entr 0.04032463952898979
ep4_l4_test_time 1.0232856273651123
gc 0
Train Epoch5 Acc 0.961425 (38457/40000), AUC 0.9896855354309082
ep5_train_time 30.679810523986816
Test Epoch5 layer0 Acc 0.8762, AUC 0.9425055980682373, avg_entr 0.15252520143985748
ep5_l0_test_time 0.24440765380859375
Test Epoch5 layer1 Acc 0.8628, AUC 0.9291961193084717, avg_entr 0.050778113305568695
ep5_l1_test_time 0.4440586566925049
Test Epoch5 layer2 Acc 0.8618, AUC 0.9338139295578003, avg_entr 0.03660682216286659
ep5_l2_test_time 0.6417679786682129
Test Epoch5 layer3 Acc 0.8618, AUC 0.9355985522270203, avg_entr 0.03556736558675766
ep5_l3_test_time 0.8301753997802734
Test Epoch5 layer4 Acc 0.8618, AUC 0.935815155506134, avg_entr 0.033626992255449295
ep5_l4_test_time 1.0256664752960205
gc 0
Train Epoch6 Acc 0.9666 (38664/40000), AUC 0.9909592866897583
ep6_train_time 30.691360235214233
Test Epoch6 layer0 Acc 0.8698, AUC 0.9383935332298279, avg_entr 0.14398311078548431
ep6_l0_test_time 0.24351716041564941
Test Epoch6 layer1 Acc 0.8582, AUC 0.9213619232177734, avg_entr 0.044759709388017654
ep6_l1_test_time 0.4427671432495117
Test Epoch6 layer2 Acc 0.8586, AUC 0.9304642677307129, avg_entr 0.03320755064487457
ep6_l2_test_time 0.6408736705780029
Test Epoch6 layer3 Acc 0.859, AUC 0.9314483404159546, avg_entr 0.031418152153491974
ep6_l3_test_time 0.828834056854248
Test Epoch6 layer4 Acc 0.8588, AUC 0.9318162798881531, avg_entr 0.029882848262786865
ep6_l4_test_time 1.0247228145599365
gc 0
Train Epoch7 Acc 0.973325 (38933/40000), AUC 0.994424045085907
ep7_train_time 30.68138360977173
Test Epoch7 layer0 Acc 0.8674, AUC 0.9370713233947754, avg_entr 0.13919682800769806
ep7_l0_test_time 0.2451169490814209
Test Epoch7 layer1 Acc 0.857, AUC 0.9169074296951294, avg_entr 0.041278112679719925
ep7_l1_test_time 0.4427025318145752
Test Epoch7 layer2 Acc 0.8572, AUC 0.9261617660522461, avg_entr 0.031155813485383987
ep7_l2_test_time 0.6385197639465332
Test Epoch7 layer3 Acc 0.8572, AUC 0.9290675520896912, avg_entr 0.028831012547016144
ep7_l3_test_time 0.8305633068084717
Test Epoch7 layer4 Acc 0.8568, AUC 0.9295576810836792, avg_entr 0.02768726833164692
ep7_l4_test_time 1.0234472751617432
gc 0
Train Epoch8 Acc 0.975725 (39029/40000), AUC 0.9948607087135315
ep8_train_time 30.68824028968811
Test Epoch8 layer0 Acc 0.8612, AUC 0.9345465898513794, avg_entr 0.13526533544063568
ep8_l0_test_time 0.24539685249328613
Test Epoch8 layer1 Acc 0.853, AUC 0.9129247665405273, avg_entr 0.03795159235596657
ep8_l1_test_time 0.4423637390136719
Test Epoch8 layer2 Acc 0.8524, AUC 0.922941267490387, avg_entr 0.028031302616000175
ep8_l2_test_time 0.6397349834442139
Test Epoch8 layer3 Acc 0.8524, AUC 0.9262636303901672, avg_entr 0.025764334946870804
ep8_l3_test_time 0.8291902542114258
Test Epoch8 layer4 Acc 0.8526, AUC 0.9269696474075317, avg_entr 0.024927476420998573
ep8_l4_test_time 1.024233341217041
gc 0
Train Epoch9 Acc 0.97775 (39110/40000), AUC 0.995374858379364
ep9_train_time 30.680604219436646
Test Epoch9 layer0 Acc 0.8618, AUC 0.932900071144104, avg_entr 0.13123536109924316
ep9_l0_test_time 0.24409699440002441
Test Epoch9 layer1 Acc 0.852, AUC 0.908225417137146, avg_entr 0.034919608384370804
ep9_l1_test_time 0.4422643184661865
Test Epoch9 layer2 Acc 0.8514, AUC 0.9188625812530518, avg_entr 0.025007804855704308
ep9_l2_test_time 0.6418254375457764
Test Epoch9 layer3 Acc 0.852, AUC 0.9246791005134583, avg_entr 0.02239287458360195
ep9_l3_test_time 0.8308463096618652
Test Epoch9 layer4 Acc 0.852, AUC 0.9261418581008911, avg_entr 0.021531715989112854
ep9_l4_test_time 1.025749921798706
gc 0
Train Epoch10 Acc 0.97925 (39170/40000), AUC 0.9958493709564209
ep10_train_time 30.68395471572876
Test Epoch10 layer0 Acc 0.8588, AUC 0.9308357238769531, avg_entr 0.12986043095588684
ep10_l0_test_time 0.24429559707641602
Test Epoch10 layer1 Acc 0.8492, AUC 0.9074665307998657, avg_entr 0.035337600857019424
ep10_l1_test_time 0.4421970844268799
Test Epoch10 layer2 Acc 0.8498, AUC 0.9187003374099731, avg_entr 0.02567525953054428
ep10_l2_test_time 0.6391372680664062
Test Epoch10 layer3 Acc 0.8496, AUC 0.9221146106719971, avg_entr 0.022959209978580475
ep10_l3_test_time 0.8319413661956787
Test Epoch10 layer4 Acc 0.8494, AUC 0.9233770370483398, avg_entr 0.022267667576670647
ep10_l4_test_time 1.024893045425415
gc 0
Train Epoch11 Acc 0.9818 (39272/40000), AUC 0.9967724084854126
ep11_train_time 30.6680908203125
Test Epoch11 layer0 Acc 0.8564, AUC 0.9295840263366699, avg_entr 0.1270768940448761
ep11_l0_test_time 0.24424505233764648
Test Epoch11 layer1 Acc 0.8466, AUC 0.9044075608253479, avg_entr 0.033126100897789
ep11_l1_test_time 0.4417099952697754
Test Epoch11 layer2 Acc 0.8458, AUC 0.915232241153717, avg_entr 0.024093344807624817
ep11_l2_test_time 0.6393702030181885
Test Epoch11 layer3 Acc 0.846, AUC 0.919430136680603, avg_entr 0.02135423757135868
ep11_l3_test_time 0.8311460018157959
Test Epoch11 layer4 Acc 0.846, AUC 0.9213516712188721, avg_entr 0.020686404779553413
ep11_l4_test_time 1.0237812995910645
gc 0
Train Epoch12 Acc 0.98235 (39294/40000), AUC 0.9964455962181091
ep12_train_time 30.696287870407104
Test Epoch12 layer0 Acc 0.8564, AUC 0.9285151958465576, avg_entr 0.1252991259098053
ep12_l0_test_time 0.24479889869689941
Test Epoch12 layer1 Acc 0.8474, AUC 0.9034252762794495, avg_entr 0.0320885106921196
ep12_l1_test_time 0.4447355270385742
Test Epoch12 layer2 Acc 0.846, AUC 0.914630651473999, avg_entr 0.02333832159638405
ep12_l2_test_time 0.6400654315948486
Test Epoch12 layer3 Acc 0.846, AUC 0.9186956882476807, avg_entr 0.020948272198438644
ep12_l3_test_time 0.8291721343994141
Test Epoch12 layer4 Acc 0.8458, AUC 0.9212642908096313, avg_entr 0.02025494910776615
ep12_l4_test_time 1.025437355041504
gc 0
Train Epoch13 Acc 0.9831 (39324/40000), AUC 0.9968287944793701
ep13_train_time 30.675058364868164
Test Epoch13 layer0 Acc 0.8552, AUC 0.9274076223373413, avg_entr 0.12376386672258377
ep13_l0_test_time 0.24355340003967285
Test Epoch13 layer1 Acc 0.8446, AUC 0.8992648124694824, avg_entr 0.029869921505451202
ep13_l1_test_time 0.44243788719177246
Test Epoch13 layer2 Acc 0.8446, AUC 0.9094666838645935, avg_entr 0.02142353169620037
ep13_l2_test_time 0.6409215927124023
Test Epoch13 layer3 Acc 0.8442, AUC 0.9147794842720032, avg_entr 0.01888761669397354
ep13_l3_test_time 0.8403646945953369
Test Epoch13 layer4 Acc 0.8442, AUC 0.9182655811309814, avg_entr 0.01821415312588215
ep13_l4_test_time 1.0230803489685059
gc 0
Train Epoch14 Acc 0.983575 (39343/40000), AUC 0.9970219135284424
ep14_train_time 30.673779010772705
Test Epoch14 layer0 Acc 0.853, AUC 0.9265311360359192, avg_entr 0.12182209640741348
ep14_l0_test_time 0.24538826942443848
Test Epoch14 layer1 Acc 0.8444, AUC 0.8976889848709106, avg_entr 0.028021562844514847
ep14_l1_test_time 0.44342994689941406
Test Epoch14 layer2 Acc 0.8436, AUC 0.9057791233062744, avg_entr 0.01952228881418705
ep14_l2_test_time 0.6403350830078125
Test Epoch14 layer3 Acc 0.8438, AUC 0.9115148186683655, avg_entr 0.016772814095020294
ep14_l3_test_time 0.8330821990966797
Test Epoch14 layer4 Acc 0.8438, AUC 0.9158719182014465, avg_entr 0.01607624441385269
ep14_l4_test_time 1.022965669631958
gc 0
Train Epoch15 Acc 0.984875 (39395/40000), AUC 0.9972729682922363
ep15_train_time 30.682589530944824
Test Epoch15 layer0 Acc 0.8524, AUC 0.9259086847305298, avg_entr 0.12095817923545837
ep15_l0_test_time 0.24463272094726562
Test Epoch15 layer1 Acc 0.8438, AUC 0.8959184885025024, avg_entr 0.02749793790280819
ep15_l1_test_time 0.44414472579956055
Test Epoch15 layer2 Acc 0.8444, AUC 0.9039971828460693, avg_entr 0.019213223829865456
ep15_l2_test_time 0.6395308971405029
Test Epoch15 layer3 Acc 0.8442, AUC 0.9099123477935791, avg_entr 0.01650412008166313
ep15_l3_test_time 0.8291640281677246
Test Epoch15 layer4 Acc 0.844, AUC 0.9153475165367126, avg_entr 0.01586657389998436
ep15_l4_test_time 1.0252292156219482
gc 0
Train Epoch16 Acc 0.985175 (39407/40000), AUC 0.9974557757377625
ep16_train_time 30.696369886398315
Test Epoch16 layer0 Acc 0.8512, AUC 0.9254043102264404, avg_entr 0.12013091146945953
ep16_l0_test_time 0.24469399452209473
Test Epoch16 layer1 Acc 0.8428, AUC 0.8940816521644592, avg_entr 0.027129998430609703
ep16_l1_test_time 0.4427783489227295
Test Epoch16 layer2 Acc 0.8426, AUC 0.9019913673400879, avg_entr 0.01909635402262211
ep16_l2_test_time 0.6412200927734375
Test Epoch16 layer3 Acc 0.8434, AUC 0.9084905982017517, avg_entr 0.016918335109949112
ep16_l3_test_time 0.8288438320159912
Test Epoch16 layer4 Acc 0.8434, AUC 0.9140758514404297, avg_entr 0.016351932659745216
ep16_l4_test_time 1.025566816329956
gc 0
Train Epoch17 Acc 0.98545 (39418/40000), AUC 0.9973490834236145
ep17_train_time 30.71031641960144
Test Epoch17 layer0 Acc 0.854, AUC 0.9248348474502563, avg_entr 0.11850620061159134
ep17_l0_test_time 0.24419426918029785
Test Epoch17 layer1 Acc 0.8446, AUC 0.8928117752075195, avg_entr 0.026184502989053726
ep17_l1_test_time 0.4426894187927246
Test Epoch17 layer2 Acc 0.8422, AUC 0.8997724056243896, avg_entr 0.018697336316108704
ep17_l2_test_time 0.6393165588378906
Test Epoch17 layer3 Acc 0.8424, AUC 0.9063464403152466, avg_entr 0.0163608118891716
ep17_l3_test_time 0.8306162357330322
Test Epoch17 layer4 Acc 0.8424, AUC 0.912880003452301, avg_entr 0.015826372429728508
ep17_l4_test_time 1.0238115787506104
gc 0
Train Epoch18 Acc 0.985975 (39439/40000), AUC 0.9973710775375366
ep18_train_time 30.69071888923645
Test Epoch18 layer0 Acc 0.8522, AUC 0.9242064356803894, avg_entr 0.11758483946323395
ep18_l0_test_time 0.24416351318359375
Test Epoch18 layer1 Acc 0.843, AUC 0.8923946619033813, avg_entr 0.024842195212841034
ep18_l1_test_time 0.44127440452575684
Test Epoch18 layer2 Acc 0.8426, AUC 0.8988046050071716, avg_entr 0.016886495053768158
ep18_l2_test_time 0.6392648220062256
Test Epoch18 layer3 Acc 0.8428, AUC 0.9049124121665955, avg_entr 0.014411118812859058
ep18_l3_test_time 0.8296055793762207
Test Epoch18 layer4 Acc 0.8428, AUC 0.9116433262825012, avg_entr 0.013849017210304737
ep18_l4_test_time 1.0238397121429443
gc 0
Train Epoch19 Acc 0.986425 (39457/40000), AUC 0.9978255033493042
ep19_train_time 30.701809406280518
Test Epoch19 layer0 Acc 0.8518, AUC 0.9239346981048584, avg_entr 0.11709173768758774
ep19_l0_test_time 0.24355578422546387
Test Epoch19 layer1 Acc 0.8426, AUC 0.8915950655937195, avg_entr 0.024423858150839806
ep19_l1_test_time 0.4429514408111572
Test Epoch19 layer2 Acc 0.8418, AUC 0.8966579437255859, avg_entr 0.016562137752771378
ep19_l2_test_time 0.6402807235717773
Test Epoch19 layer3 Acc 0.8416, AUC 0.9038509130477905, avg_entr 0.01418602280318737
ep19_l3_test_time 0.8307116031646729
Test Epoch19 layer4 Acc 0.8416, AUC 0.9107663035392761, avg_entr 0.013625474646687508
ep19_l4_test_time 1.026839017868042
gc 0
Train Epoch20 Acc 0.9864 (39456/40000), AUC 0.9976940751075745
ep20_train_time 30.681347608566284
Test Epoch20 layer0 Acc 0.8508, AUC 0.9237451553344727, avg_entr 0.11615998297929764
ep20_l0_test_time 0.24367690086364746
Test Epoch20 layer1 Acc 0.8412, AUC 0.8904197812080383, avg_entr 0.02403096854686737
ep20_l1_test_time 0.4411509037017822
Test Epoch20 layer2 Acc 0.8412, AUC 0.8942128419876099, avg_entr 0.015928491950035095
ep20_l2_test_time 0.6400094032287598
Test Epoch20 layer3 Acc 0.8406, AUC 0.9013493657112122, avg_entr 0.013588957488536835
ep20_l3_test_time 0.8292758464813232
Test Epoch20 layer4 Acc 0.8408, AUC 0.909536600112915, avg_entr 0.013031878508627415
ep20_l4_test_time 1.0220739841461182
gc 0
Train Epoch21 Acc 0.986625 (39465/40000), AUC 0.9975566864013672
ep21_train_time 30.683454036712646
Test Epoch21 layer0 Acc 0.8492, AUC 0.9234415888786316, avg_entr 0.1154422014951706
ep21_l0_test_time 0.24352407455444336
Test Epoch21 layer1 Acc 0.8412, AUC 0.8901851773262024, avg_entr 0.02339305356144905
ep21_l1_test_time 0.44203686714172363
Test Epoch21 layer2 Acc 0.8414, AUC 0.893878698348999, avg_entr 0.015421750955283642
ep21_l2_test_time 0.6383533477783203
Test Epoch21 layer3 Acc 0.841, AUC 0.9007790684700012, avg_entr 0.013155707158148289
ep21_l3_test_time 0.8325135707855225
Test Epoch21 layer4 Acc 0.8408, AUC 0.9089905619621277, avg_entr 0.012578828260302544
ep21_l4_test_time 1.0255529880523682
gc 0
Train Epoch22 Acc 0.986775 (39471/40000), AUC 0.9979177713394165
ep22_train_time 30.687068700790405
Test Epoch22 layer0 Acc 0.8508, AUC 0.9232823848724365, avg_entr 0.11464469134807587
ep22_l0_test_time 0.24385333061218262
Test Epoch22 layer1 Acc 0.842, AUC 0.8896748423576355, avg_entr 0.022955087944865227
ep22_l1_test_time 0.44377589225769043
Test Epoch22 layer2 Acc 0.841, AUC 0.8930491209030151, avg_entr 0.015069320797920227
ep22_l2_test_time 0.6410906314849854
Test Epoch22 layer3 Acc 0.8418, AUC 0.9000344276428223, avg_entr 0.012923997826874256
ep22_l3_test_time 0.8290634155273438
Test Epoch22 layer4 Acc 0.8414, AUC 0.908100962638855, avg_entr 0.012392898090183735
ep22_l4_test_time 1.0244696140289307
gc 0
Train Epoch23 Acc 0.986775 (39471/40000), AUC 0.9976340532302856
ep23_train_time 30.68143057823181
Test Epoch23 layer0 Acc 0.8496, AUC 0.9231029152870178, avg_entr 0.11431685835123062
ep23_l0_test_time 0.24326777458190918
Test Epoch23 layer1 Acc 0.8424, AUC 0.8887763023376465, avg_entr 0.02277451939880848
ep23_l1_test_time 0.4413487911224365
Test Epoch23 layer2 Acc 0.8416, AUC 0.891780436038971, avg_entr 0.015353202819824219
ep23_l2_test_time 0.639702558517456
Test Epoch23 layer3 Acc 0.8414, AUC 0.8991701602935791, avg_entr 0.013138658367097378
ep23_l3_test_time 0.8275728225708008
Test Epoch23 layer4 Acc 0.8412, AUC 0.9073749780654907, avg_entr 0.012623203918337822
ep23_l4_test_time 1.02370285987854
gc 0
Train Epoch24 Acc 0.986825 (39473/40000), AUC 0.9977915287017822
ep24_train_time 30.69581913948059
Test Epoch24 layer0 Acc 0.8496, AUC 0.9229600429534912, avg_entr 0.11385022103786469
ep24_l0_test_time 0.24401378631591797
Test Epoch24 layer1 Acc 0.842, AUC 0.8887979984283447, avg_entr 0.022733261808753014
ep24_l1_test_time 0.4416487216949463
Test Epoch24 layer2 Acc 0.8412, AUC 0.8907877206802368, avg_entr 0.015225560404360294
ep24_l2_test_time 0.638275146484375
Test Epoch24 layer3 Acc 0.8406, AUC 0.8983725309371948, avg_entr 0.013101144693791866
ep24_l3_test_time 0.8321974277496338
Test Epoch24 layer4 Acc 0.8406, AUC 0.9069688320159912, avg_entr 0.012599235400557518
ep24_l4_test_time 1.0226690769195557
gc 0
Train Epoch25 Acc 0.987375 (39495/40000), AUC 0.9979937076568604
ep25_train_time 30.71444535255432
Test Epoch25 layer0 Acc 0.8496, AUC 0.9229071736335754, avg_entr 0.11329300701618195
ep25_l0_test_time 0.24555015563964844
Test Epoch25 layer1 Acc 0.8432, AUC 0.8882182836532593, avg_entr 0.022920498624444008
ep25_l1_test_time 0.44193339347839355
Test Epoch25 layer2 Acc 0.8404, AUC 0.8888545036315918, avg_entr 0.01610638201236725
ep25_l2_test_time 0.6392114162445068
Test Epoch25 layer3 Acc 0.8402, AUC 0.8970425128936768, avg_entr 0.014158760197460651
ep25_l3_test_time 0.8270907402038574
Test Epoch25 layer4 Acc 0.8402, AUC 0.9051019549369812, avg_entr 0.013671444728970528
ep25_l4_test_time 1.0234627723693848
gc 0
Train Epoch26 Acc 0.9872 (39488/40000), AUC 0.9979217052459717
ep26_train_time 30.6801438331604
Test Epoch26 layer0 Acc 0.8506, AUC 0.9227997660636902, avg_entr 0.11274778097867966
ep26_l0_test_time 0.2433028221130371
Test Epoch26 layer1 Acc 0.843, AUC 0.8877146244049072, avg_entr 0.022580068558454514
ep26_l1_test_time 0.44214391708374023
Test Epoch26 layer2 Acc 0.84, AUC 0.8862282633781433, avg_entr 0.015205209143459797
ep26_l2_test_time 0.6411819458007812
Test Epoch26 layer3 Acc 0.8406, AUC 0.894706130027771, avg_entr 0.013236746191978455
ep26_l3_test_time 0.8291499614715576
Test Epoch26 layer4 Acc 0.841, AUC 0.9036038517951965, avg_entr 0.012762686237692833
ep26_l4_test_time 1.0239427089691162
gc 0
Train Epoch27 Acc 0.987075 (39483/40000), AUC 0.9978713989257812
ep27_train_time 30.6870436668396
Test Epoch27 layer0 Acc 0.8494, AUC 0.9227312803268433, avg_entr 0.11243720352649689
ep27_l0_test_time 0.24460291862487793
Test Epoch27 layer1 Acc 0.841, AUC 0.8877766728401184, avg_entr 0.021912984549999237
ep27_l1_test_time 0.4416365623474121
Test Epoch27 layer2 Acc 0.8402, AUC 0.8856223821640015, avg_entr 0.013822660781443119
ep27_l2_test_time 0.6400697231292725
Test Epoch27 layer3 Acc 0.8406, AUC 0.8940871953964233, avg_entr 0.011875872500240803
ep27_l3_test_time 0.8318545818328857
Test Epoch27 layer4 Acc 0.8408, AUC 0.9044781923294067, avg_entr 0.011367613449692726
ep27_l4_test_time 1.022242546081543
gc 0
Train Epoch28 Acc 0.9873 (39492/40000), AUC 0.9977980852127075
ep28_train_time 30.694162368774414
Test Epoch28 layer0 Acc 0.8496, AUC 0.9226900339126587, avg_entr 0.11208420246839523
ep28_l0_test_time 0.24332833290100098
Test Epoch28 layer1 Acc 0.8412, AUC 0.8874996900558472, avg_entr 0.021912692114710808
ep28_l1_test_time 0.44146251678466797
Test Epoch28 layer2 Acc 0.8402, AUC 0.8853254318237305, avg_entr 0.014443880878388882
ep28_l2_test_time 0.6382608413696289
Test Epoch28 layer3 Acc 0.8402, AUC 0.8937497735023499, avg_entr 0.012386062182486057
ep28_l3_test_time 0.8294737339019775
Test Epoch28 layer4 Acc 0.84, AUC 0.903439998626709, avg_entr 0.011942765675485134
ep28_l4_test_time 1.0225591659545898
gc 0
Train Epoch29 Acc 0.9874 (39496/40000), AUC 0.9980640411376953
ep29_train_time 30.70529556274414
Test Epoch29 layer0 Acc 0.849, AUC 0.9226601123809814, avg_entr 0.11170660704374313
ep29_l0_test_time 0.24316072463989258
Test Epoch29 layer1 Acc 0.8404, AUC 0.8874132037162781, avg_entr 0.021609211340546608
ep29_l1_test_time 0.4429666996002197
Test Epoch29 layer2 Acc 0.8402, AUC 0.8851958513259888, avg_entr 0.013862794265151024
ep29_l2_test_time 0.6383674144744873
Test Epoch29 layer3 Acc 0.8402, AUC 0.8931688070297241, avg_entr 0.011865831911563873
ep29_l3_test_time 0.8259711265563965
Test Epoch29 layer4 Acc 0.8402, AUC 0.9034885168075562, avg_entr 0.01138016302138567
ep29_l4_test_time 1.0234589576721191
gc 0
Train Epoch30 Acc 0.987175 (39487/40000), AUC 0.9977899193763733
ep30_train_time 30.678285837173462
Test Epoch30 layer0 Acc 0.8492, AUC 0.9226087331771851, avg_entr 0.11131276935338974
ep30_l0_test_time 0.2433159351348877
Test Epoch30 layer1 Acc 0.8412, AUC 0.887278139591217, avg_entr 0.02154974825680256
ep30_l1_test_time 0.44137048721313477
Test Epoch30 layer2 Acc 0.84, AUC 0.8843146562576294, avg_entr 0.013499367982149124
ep30_l2_test_time 0.6398138999938965
Test Epoch30 layer3 Acc 0.8396, AUC 0.8924468755722046, avg_entr 0.01169222965836525
ep30_l3_test_time 0.8280725479125977
Test Epoch30 layer4 Acc 0.8396, AUC 0.9034563302993774, avg_entr 0.011161941103637218
ep30_l4_test_time 1.023414134979248
gc 0
Train Epoch31 Acc 0.987225 (39489/40000), AUC 0.9979381561279297
ep31_train_time 30.720541954040527
Test Epoch31 layer0 Acc 0.8492, AUC 0.9225997924804688, avg_entr 0.11107844114303589
ep31_l0_test_time 0.24399805068969727
Test Epoch31 layer1 Acc 0.8406, AUC 0.887238621711731, avg_entr 0.021380621939897537
ep31_l1_test_time 0.44197630882263184
Test Epoch31 layer2 Acc 0.8404, AUC 0.8842555284500122, avg_entr 0.013563426211476326
ep31_l2_test_time 0.6382739543914795
Test Epoch31 layer3 Acc 0.8402, AUC 0.8922003507614136, avg_entr 0.011632462032139301
ep31_l3_test_time 0.8311562538146973
Test Epoch31 layer4 Acc 0.8402, AUC 0.9028493762016296, avg_entr 0.011111000552773476
ep31_l4_test_time 1.02327561378479
gc 0
Train Epoch32 Acc 0.9876 (39504/40000), AUC 0.9980907440185547
ep32_train_time 30.68771266937256
Test Epoch32 layer0 Acc 0.8494, AUC 0.9225828647613525, avg_entr 0.11084521561861038
ep32_l0_test_time 0.24437737464904785
Test Epoch32 layer1 Acc 0.8402, AUC 0.8871237635612488, avg_entr 0.02141859196126461
ep32_l1_test_time 0.4444894790649414
Test Epoch32 layer2 Acc 0.8406, AUC 0.8838876485824585, avg_entr 0.013819990679621696
ep32_l2_test_time 0.6393475532531738
Test Epoch32 layer3 Acc 0.8406, AUC 0.8921190500259399, avg_entr 0.011832104995846748
ep32_l3_test_time 0.8304705619812012
Test Epoch32 layer4 Acc 0.84, AUC 0.9024872183799744, avg_entr 0.011348833329975605
ep32_l4_test_time 1.0258443355560303
gc 0
Train Epoch33 Acc 0.987325 (39493/40000), AUC 0.9979415535926819
ep33_train_time 30.694475412368774
Test Epoch33 layer0 Acc 0.8492, AUC 0.922589898109436, avg_entr 0.11055279523134232
ep33_l0_test_time 0.2443065643310547
Test Epoch33 layer1 Acc 0.8404, AUC 0.8869514465332031, avg_entr 0.021432897076010704
ep33_l1_test_time 0.44229650497436523
Test Epoch33 layer2 Acc 0.8406, AUC 0.8832004070281982, avg_entr 0.013935545459389687
ep33_l2_test_time 0.6416614055633545
Test Epoch33 layer3 Acc 0.8396, AUC 0.8916935920715332, avg_entr 0.011961092241108418
ep33_l3_test_time 0.8305811882019043
Test Epoch33 layer4 Acc 0.8396, AUC 0.9021608829498291, avg_entr 0.011519055813550949
ep33_l4_test_time 1.0245819091796875
gc 0
Train Epoch34 Acc 0.987475 (39499/40000), AUC 0.9980805516242981
ep34_train_time 30.68518877029419
Test Epoch34 layer0 Acc 0.849, AUC 0.9225385785102844, avg_entr 0.11029559373855591
ep34_l0_test_time 0.2446753978729248
Test Epoch34 layer1 Acc 0.8416, AUC 0.8869414329528809, avg_entr 0.02152767963707447
ep34_l1_test_time 0.44217801094055176
Test Epoch34 layer2 Acc 0.8402, AUC 0.8831572532653809, avg_entr 0.014340762048959732
ep34_l2_test_time 0.6392416954040527
Test Epoch34 layer3 Acc 0.8394, AUC 0.8914093971252441, avg_entr 0.012347523123025894
ep34_l3_test_time 0.8306384086608887
Test Epoch34 layer4 Acc 0.8394, AUC 0.9016344547271729, avg_entr 0.011899949982762337
ep34_l4_test_time 1.0234498977661133
gc 0
Train Epoch35 Acc 0.987625 (39505/40000), AUC 0.9980534911155701
ep35_train_time 30.699025630950928
Test Epoch35 layer0 Acc 0.8494, AUC 0.9225513339042664, avg_entr 0.11010051518678665
ep35_l0_test_time 0.24504470825195312
Test Epoch35 layer1 Acc 0.8404, AUC 0.8868726491928101, avg_entr 0.021174117922782898
ep35_l1_test_time 0.44107842445373535
Test Epoch35 layer2 Acc 0.8402, AUC 0.8829208612442017, avg_entr 0.013744086027145386
ep35_l2_test_time 0.6382150650024414
Test Epoch35 layer3 Acc 0.84, AUC 0.8911789655685425, avg_entr 0.011732243001461029
ep35_l3_test_time 0.8302645683288574
Test Epoch35 layer4 Acc 0.8398, AUC 0.9017257690429688, avg_entr 0.011261013336479664
ep35_l4_test_time 1.0230481624603271
gc 0
Train Epoch36 Acc 0.9878 (39512/40000), AUC 0.9981193542480469
ep36_train_time 30.697715759277344
Test Epoch36 layer0 Acc 0.8494, AUC 0.9225492477416992, avg_entr 0.10992155969142914
ep36_l0_test_time 0.24445819854736328
Test Epoch36 layer1 Acc 0.84, AUC 0.8868552446365356, avg_entr 0.021121863275766373
ep36_l1_test_time 0.44356703758239746
Test Epoch36 layer2 Acc 0.8402, AUC 0.8829144239425659, avg_entr 0.013636520132422447
ep36_l2_test_time 0.6394748687744141
Test Epoch36 layer3 Acc 0.8402, AUC 0.8910926580429077, avg_entr 0.011645563878118992
ep36_l3_test_time 0.8406949043273926
Test Epoch36 layer4 Acc 0.8402, AUC 0.9016841650009155, avg_entr 0.011166614480316639
ep36_l4_test_time 1.0261194705963135
gc 0
Train Epoch37 Acc 0.9875 (39500/40000), AUC 0.9979931712150574
ep37_train_time 30.708780765533447
Test Epoch37 layer0 Acc 0.8496, AUC 0.9225488901138306, avg_entr 0.1097225472331047
ep37_l0_test_time 0.2450089454650879
Test Epoch37 layer1 Acc 0.84, AUC 0.8868584036827087, avg_entr 0.021108824759721756
ep37_l1_test_time 0.44289255142211914
Test Epoch37 layer2 Acc 0.8402, AUC 0.8828520774841309, avg_entr 0.013705454766750336
ep37_l2_test_time 0.6486756801605225
Test Epoch37 layer3 Acc 0.8402, AUC 0.8910049200057983, avg_entr 0.011705723591148853
ep37_l3_test_time 0.8318889141082764
Test Epoch37 layer4 Acc 0.84, AUC 0.9015724658966064, avg_entr 0.011242235079407692
ep37_l4_test_time 1.0240695476531982
gc 0
Train Epoch38 Acc 0.98755 (39502/40000), AUC 0.998106062412262
ep38_train_time 30.68436598777771
Test Epoch38 layer0 Acc 0.8492, AUC 0.9225345849990845, avg_entr 0.10950617492198944
ep38_l0_test_time 0.2440023422241211
Test Epoch38 layer1 Acc 0.84, AUC 0.8869215250015259, avg_entr 0.02108166180551052
ep38_l1_test_time 0.44147181510925293
Test Epoch38 layer2 Acc 0.8402, AUC 0.8828426003456116, avg_entr 0.013799932785332203
ep38_l2_test_time 0.6393001079559326
Test Epoch38 layer3 Acc 0.8398, AUC 0.8909404277801514, avg_entr 0.01181140635162592
ep38_l3_test_time 0.8304634094238281
Test Epoch38 layer4 Acc 0.8396, AUC 0.9013640880584717, avg_entr 0.011359297670423985
ep38_l4_test_time 1.0224559307098389
gc 0
Train Epoch39 Acc 0.987375 (39495/40000), AUC 0.9982671141624451
ep39_train_time 30.690807104110718
Test Epoch39 layer0 Acc 0.8492, AUC 0.9225398302078247, avg_entr 0.1093832403421402
ep39_l0_test_time 0.24438095092773438
Test Epoch39 layer1 Acc 0.8402, AUC 0.8868483901023865, avg_entr 0.02098200097680092
ep39_l1_test_time 0.44379162788391113
Test Epoch39 layer2 Acc 0.8404, AUC 0.8827283978462219, avg_entr 0.013659766875207424
ep39_l2_test_time 0.6389970779418945
Test Epoch39 layer3 Acc 0.84, AUC 0.8908393383026123, avg_entr 0.01167214009910822
ep39_l3_test_time 0.8298931121826172
Test Epoch39 layer4 Acc 0.84, AUC 0.9014455676078796, avg_entr 0.01121321227401495
ep39_l4_test_time 1.0256249904632568
gc 0
Train Epoch40 Acc 0.98735 (39494/40000), AUC 0.998133659362793
ep40_train_time 30.693198204040527
Test Epoch40 layer0 Acc 0.8494, AUC 0.9225425720214844, avg_entr 0.10924803465604782
ep40_l0_test_time 0.24425888061523438
Test Epoch40 layer1 Acc 0.8402, AUC 0.8868834376335144, avg_entr 0.020966781303286552
ep40_l1_test_time 0.4426398277282715
Test Epoch40 layer2 Acc 0.8406, AUC 0.8827261924743652, avg_entr 0.01368850376456976
ep40_l2_test_time 0.6411693096160889
Test Epoch40 layer3 Acc 0.8398, AUC 0.8908706307411194, avg_entr 0.011700505390763283
ep40_l3_test_time 0.8298847675323486
Test Epoch40 layer4 Acc 0.8396, AUC 0.9014203548431396, avg_entr 0.011246050707995892
ep40_l4_test_time 1.025399923324585
gc 0
Train Epoch41 Acc 0.987625 (39505/40000), AUC 0.9981362223625183
ep41_train_time 30.684056758880615
Test Epoch41 layer0 Acc 0.849, AUC 0.9225478172302246, avg_entr 0.10910429805517197
ep41_l0_test_time 0.24344444274902344
Test Epoch41 layer1 Acc 0.8402, AUC 0.8868827819824219, avg_entr 0.02096456103026867
ep41_l1_test_time 0.4419565200805664
Test Epoch41 layer2 Acc 0.8406, AUC 0.8827171921730042, avg_entr 0.013741870410740376
ep41_l2_test_time 0.6390366554260254
Test Epoch41 layer3 Acc 0.8398, AUC 0.8908623456954956, avg_entr 0.011750335805118084
ep41_l3_test_time 0.831552267074585
Test Epoch41 layer4 Acc 0.8396, AUC 0.9013692140579224, avg_entr 0.011297967284917831
ep41_l4_test_time 1.0234315395355225
gc 0
Train Epoch42 Acc 0.987825 (39513/40000), AUC 0.998062252998352
ep42_train_time 30.69157910346985
Test Epoch42 layer0 Acc 0.8496, AUC 0.9225495457649231, avg_entr 0.10895228385925293
ep42_l0_test_time 0.2450864315032959
Test Epoch42 layer1 Acc 0.8402, AUC 0.8869059085845947, avg_entr 0.02092234417796135
ep42_l1_test_time 0.44241905212402344
Test Epoch42 layer2 Acc 0.8404, AUC 0.8826541900634766, avg_entr 0.013696292415261269
ep42_l2_test_time 0.6390342712402344
Test Epoch42 layer3 Acc 0.8398, AUC 0.8907581567764282, avg_entr 0.01171587873250246
ep42_l3_test_time 0.8307769298553467
Test Epoch42 layer4 Acc 0.8396, AUC 0.9013360738754272, avg_entr 0.011265117675065994
ep42_l4_test_time 1.023576259613037
gc 0
Train Epoch43 Acc 0.9876 (39504/40000), AUC 0.9980986714363098
ep43_train_time 30.680060148239136
Test Epoch43 layer0 Acc 0.8494, AUC 0.9225507974624634, avg_entr 0.10887011885643005
ep43_l0_test_time 0.24425292015075684
Test Epoch43 layer1 Acc 0.8402, AUC 0.8868975043296814, avg_entr 0.020886622369289398
ep43_l1_test_time 0.4433917999267578
Test Epoch43 layer2 Acc 0.8406, AUC 0.882664144039154, avg_entr 0.013673773035407066
ep43_l2_test_time 0.6407914161682129
Test Epoch43 layer3 Acc 0.8398, AUC 0.8906870484352112, avg_entr 0.011690770275890827
ep43_l3_test_time 0.8304150104522705
Test Epoch43 layer4 Acc 0.8396, AUC 0.9013073444366455, avg_entr 0.011240122839808464
ep43_l4_test_time 1.0250425338745117
gc 0
Train Epoch44 Acc 0.987725 (39509/40000), AUC 0.9979654550552368
ep44_train_time 30.70207381248474
Test Epoch44 layer0 Acc 0.8494, AUC 0.9225523471832275, avg_entr 0.10878022760152817
ep44_l0_test_time 0.2447071075439453
Test Epoch44 layer1 Acc 0.8402, AUC 0.8869014978408813, avg_entr 0.020831432193517685
ep44_l1_test_time 0.4426403045654297
Test Epoch44 layer2 Acc 0.8404, AUC 0.8826400637626648, avg_entr 0.013591094873845577
ep44_l2_test_time 0.6414141654968262
Test Epoch44 layer3 Acc 0.8396, AUC 0.8906974792480469, avg_entr 0.011609125882387161
ep44_l3_test_time 0.8306074142456055
Test Epoch44 layer4 Acc 0.8396, AUC 0.9012641310691833, avg_entr 0.011161265894770622
ep44_l4_test_time 1.0229301452636719
gc 0
Train Epoch45 Acc 0.987725 (39509/40000), AUC 0.9980159997940063
ep45_train_time 30.708533763885498
Test Epoch45 layer0 Acc 0.8496, AUC 0.9225552082061768, avg_entr 0.10868631303310394
ep45_l0_test_time 0.24457669258117676
Test Epoch45 layer1 Acc 0.8402, AUC 0.8869072198867798, avg_entr 0.020839551463723183
ep45_l1_test_time 0.4424576759338379
Test Epoch45 layer2 Acc 0.8404, AUC 0.8826460838317871, avg_entr 0.013645573519170284
ep45_l2_test_time 0.6397316455841064
Test Epoch45 layer3 Acc 0.8398, AUC 0.890672504901886, avg_entr 0.011665225960314274
ep45_l3_test_time 0.831629753112793
Test Epoch45 layer4 Acc 0.8396, AUC 0.9011905193328857, avg_entr 0.011223210953176022
ep45_l4_test_time 1.0235862731933594
gc 0
Train Epoch46 Acc 0.98775 (39510/40000), AUC 0.9980107545852661
ep46_train_time 30.693342685699463
Test Epoch46 layer0 Acc 0.8496, AUC 0.9225568771362305, avg_entr 0.10858790576457977
ep46_l0_test_time 0.24456238746643066
Test Epoch46 layer1 Acc 0.8404, AUC 0.8869304656982422, avg_entr 0.0208435095846653
ep46_l1_test_time 0.44304728507995605
Test Epoch46 layer2 Acc 0.8402, AUC 0.8826673030853271, avg_entr 0.01370162796229124
ep46_l2_test_time 0.6391959190368652
Test Epoch46 layer3 Acc 0.8396, AUC 0.8906770348548889, avg_entr 0.011717356741428375
ep46_l3_test_time 0.8295724391937256
Test Epoch46 layer4 Acc 0.8396, AUC 0.901158332824707, avg_entr 0.01127786934375763
ep46_l4_test_time 1.0234975814819336
gc 0
Train Epoch47 Acc 0.987475 (39499/40000), AUC 0.9981372356414795
ep47_train_time 30.709885120391846
Test Epoch47 layer0 Acc 0.8496, AUC 0.9225571155548096, avg_entr 0.10853534936904907
ep47_l0_test_time 0.24380230903625488
Test Epoch47 layer1 Acc 0.8402, AUC 0.8869257569313049, avg_entr 0.020799631252884865
ep47_l1_test_time 0.4411940574645996
Test Epoch47 layer2 Acc 0.8404, AUC 0.8826326727867126, avg_entr 0.01363912783563137
ep47_l2_test_time 0.639967679977417
Test Epoch47 layer3 Acc 0.84, AUC 0.8906559348106384, avg_entr 0.011652374640107155
ep47_l3_test_time 0.8286035060882568
Test Epoch47 layer4 Acc 0.8396, AUC 0.9012060761451721, avg_entr 0.011207993142306805
ep47_l4_test_time 1.0232930183410645
gc 0
Train Epoch48 Acc 0.98775 (39510/40000), AUC 0.9981557130813599
ep48_train_time 30.68781852722168
Test Epoch48 layer0 Acc 0.8494, AUC 0.9225573539733887, avg_entr 0.10847960412502289
ep48_l0_test_time 0.2447986602783203
Test Epoch48 layer1 Acc 0.8404, AUC 0.8869209289550781, avg_entr 0.020777078345417976
ep48_l1_test_time 0.4421651363372803
Test Epoch48 layer2 Acc 0.8404, AUC 0.8826565742492676, avg_entr 0.013617590069770813
ep48_l2_test_time 0.6392745971679688
Test Epoch48 layer3 Acc 0.84, AUC 0.8906694650650024, avg_entr 0.011633810587227345
ep48_l3_test_time 0.8316018581390381
Test Epoch48 layer4 Acc 0.8396, AUC 0.9011716842651367, avg_entr 0.011190453544259071
ep48_l4_test_time 1.0222148895263672
gc 0
Train Epoch49 Acc 0.987325 (39493/40000), AUC 0.9979987144470215
ep49_train_time 30.711155891418457
Test Epoch49 layer0 Acc 0.8494, AUC 0.9225579500198364, avg_entr 0.10842142254114151
ep49_l0_test_time 0.24452900886535645
Test Epoch49 layer1 Acc 0.8402, AUC 0.8869383335113525, avg_entr 0.02076300047338009
ep49_l1_test_time 0.44169187545776367
Test Epoch49 layer2 Acc 0.8404, AUC 0.8826987147331238, avg_entr 0.01362180057913065
ep49_l2_test_time 0.6388545036315918
Test Epoch49 layer3 Acc 0.84, AUC 0.8906898498535156, avg_entr 0.011636273935437202
ep49_l3_test_time 0.8304245471954346
Test Epoch49 layer4 Acc 0.8396, AUC 0.9011567831039429, avg_entr 0.011195349507033825
ep49_l4_test_time 1.0233135223388672
Best AUC 0.9488769769668579
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train+valid_time 1696.921502828598
Start Testing
Load ckpt at ckpt/imdb_transformeral_l5_pad200//imdb_transformeral_l5.pt
Test layer0 Acc 0.8786, AUC 0.944724440574646, avg_entr 0.20604822039604187
l0_test_time 0.2487497329711914
Test layer1 Acc 0.8716, AUC 0.9456492066383362, avg_entr 0.16194641590118408
l1_test_time 0.44864988327026367
Test layer2 Acc 0.8732, AUC 0.945979118347168, avg_entr 0.10844509303569794
l2_test_time 0.6440873146057129
Test layer3 Acc 0.8724, AUC 0.9452778100967407, avg_entr 0.08249103277921677
l3_test_time 0.8326094150543213
Test layer4 Acc 0.8726, AUC 0.9453685879707336, avg_entr 0.07130573689937592
l4_test_time 1.0285546779632568
