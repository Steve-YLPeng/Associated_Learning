total count words 222751
vocab size 30000
train size 40000, valid size 5000, test size 5000
found 27937 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=2, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=2, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 256
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 256
layers.0.ae.h.0.bias 2
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13671778
init_time 21.369799375534058
Start Training
gc 0
Train Epoch0 Acc 0.49925 (19970/40000), AUC 0.4937751591205597
ep0_train_time 16.227216958999634
Test Epoch0 layer0 Acc 0.809, AUC 0.8929344415664673, avg_entr 0.40833693742752075
ep0_l0_test_time 0.13822293281555176
Save ckpt to ckpt/imdb_transformeral_l5_pad100//imdb_transformeral_l5.pt  ,ep 0
Test Epoch0 layer1 Acc 0.8006, AUC 0.8831234574317932, avg_entr 0.41002804040908813
ep0_l1_test_time 0.2331104278564453
Test Epoch0 layer2 Acc 0.7964, AUC 0.881414532661438, avg_entr 0.573991596698761
ep0_l2_test_time 0.3251535892486572
Test Epoch0 layer3 Acc 0.7766, AUC 0.8760402202606201, avg_entr 0.6581200957298279
ep0_l3_test_time 0.42017340660095215
Test Epoch0 layer4 Acc 0.5182, AUC 0.7851564288139343, avg_entr 0.6876354217529297
ep0_l4_test_time 0.5113623142242432
gc 0
Train Epoch1 Acc 0.81345 (32538/40000), AUC 0.8907821178436279
ep1_train_time 15.890890121459961
Test Epoch1 layer0 Acc 0.8378, AUC 0.9187999367713928, avg_entr 0.2651899755001068
ep1_l0_test_time 0.13712477684020996
Save ckpt to ckpt/imdb_transformeral_l5_pad100//imdb_transformeral_l5.pt  ,ep 1
Test Epoch1 layer1 Acc 0.842, AUC 0.9206169843673706, avg_entr 0.22368909418582916
ep1_l1_test_time 0.23406362533569336
Save ckpt to ckpt/imdb_transformeral_l5_pad100//imdb_transformeral_l5.pt  ,ep 1
Test Epoch1 layer2 Acc 0.811, AUC 0.9209606647491455, avg_entr 0.1924113780260086
ep1_l2_test_time 0.3284945487976074
Save ckpt to ckpt/imdb_transformeral_l5_pad100//imdb_transformeral_l5.pt  ,ep 1
Test Epoch1 layer3 Acc 0.7856, AUC 0.9202651977539062, avg_entr 0.16460920870304108
ep1_l3_test_time 0.42249631881713867
Test Epoch1 layer4 Acc 0.77, AUC 0.9199556708335876, avg_entr 0.15383341908454895
ep1_l4_test_time 0.5142958164215088
gc 0
Train Epoch2 Acc 0.894725 (35789/40000), AUC 0.9582715034484863
ep2_train_time 15.907565593719482
Test Epoch2 layer0 Acc 0.8436, AUC 0.9201596975326538, avg_entr 0.21567484736442566
ep2_l0_test_time 0.1378920078277588
Test Epoch2 layer1 Acc 0.8374, AUC 0.9151381254196167, avg_entr 0.17276978492736816
ep2_l1_test_time 0.23169589042663574
Test Epoch2 layer2 Acc 0.8394, AUC 0.9151197075843811, avg_entr 0.1242322251200676
ep2_l2_test_time 0.32679104804992676
Test Epoch2 layer3 Acc 0.8406, AUC 0.9148677587509155, avg_entr 0.10137630254030228
ep2_l3_test_time 0.4193589687347412
Test Epoch2 layer4 Acc 0.8398, AUC 0.9146525859832764, avg_entr 0.0949096530675888
ep2_l4_test_time 0.5131275653839111
gc 0
Train Epoch3 Acc 0.92695 (37078/40000), AUC 0.976405143737793
ep3_train_time 15.96165943145752
Test Epoch3 layer0 Acc 0.842, AUC 0.9164949655532837, avg_entr 0.19408120214939117
ep3_l0_test_time 0.13784480094909668
Test Epoch3 layer1 Acc 0.8236, AUC 0.9045080542564392, avg_entr 0.15040448307991028
ep3_l1_test_time 0.23074650764465332
Test Epoch3 layer2 Acc 0.8242, AUC 0.9040786027908325, avg_entr 0.08660891652107239
ep3_l2_test_time 0.3274569511413574
Test Epoch3 layer3 Acc 0.8246, AUC 0.9041221141815186, avg_entr 0.0744842067360878
ep3_l3_test_time 0.4197380542755127
Test Epoch3 layer4 Acc 0.8244, AUC 0.9039384126663208, avg_entr 0.0701916292309761
ep3_l4_test_time 0.5134859085083008
gc 0
Train Epoch4 Acc 0.939225 (37569/40000), AUC 0.9825038909912109
ep4_train_time 15.885656118392944
Test Epoch4 layer0 Acc 0.83, AUC 0.9111461639404297, avg_entr 0.17740020155906677
ep4_l0_test_time 0.13767194747924805
Test Epoch4 layer1 Acc 0.8156, AUC 0.8961610794067383, avg_entr 0.11832479387521744
ep4_l1_test_time 0.23138809204101562
Test Epoch4 layer2 Acc 0.8158, AUC 0.8966772556304932, avg_entr 0.060388050973415375
ep4_l2_test_time 0.32689690589904785
Test Epoch4 layer3 Acc 0.8162, AUC 0.8963067531585693, avg_entr 0.05622901767492294
ep4_l3_test_time 0.42083120346069336
Test Epoch4 layer4 Acc 0.8174, AUC 0.8961367607116699, avg_entr 0.05448511987924576
ep4_l4_test_time 0.5152163505554199
gc 0
Train Epoch5 Acc 0.9501 (38004/40000), AUC 0.9874818921089172
ep5_train_time 15.919867277145386
Test Epoch5 layer0 Acc 0.828, AUC 0.9059886932373047, avg_entr 0.16474144160747528
ep5_l0_test_time 0.13720965385437012
Test Epoch5 layer1 Acc 0.8086, AUC 0.8950966000556946, avg_entr 0.07803096622228622
ep5_l1_test_time 0.23105740547180176
Test Epoch5 layer2 Acc 0.8114, AUC 0.8967915773391724, avg_entr 0.05049385502934456
ep5_l2_test_time 0.32675862312316895
Test Epoch5 layer3 Acc 0.8116, AUC 0.8965945243835449, avg_entr 0.04943200945854187
ep5_l3_test_time 0.41973161697387695
Test Epoch5 layer4 Acc 0.8126, AUC 0.8965383768081665, avg_entr 0.048699717968702316
ep5_l4_test_time 0.5133388042449951
gc 0
Train Epoch6 Acc 0.9572 (38288/40000), AUC 0.9905109405517578
ep6_train_time 15.913555383682251
Test Epoch6 layer0 Acc 0.8252, AUC 0.9006630182266235, avg_entr 0.15384529531002045
ep6_l0_test_time 0.13744807243347168
Test Epoch6 layer1 Acc 0.812, AUC 0.8861352205276489, avg_entr 0.06790190935134888
ep6_l1_test_time 0.2318558692932129
Test Epoch6 layer2 Acc 0.8132, AUC 0.8922228217124939, avg_entr 0.04737337678670883
ep6_l2_test_time 0.3276479244232178
Test Epoch6 layer3 Acc 0.812, AUC 0.8921353816986084, avg_entr 0.045823607593774796
ep6_l3_test_time 0.4200918674468994
Test Epoch6 layer4 Acc 0.8134, AUC 0.8921606540679932, avg_entr 0.04466071352362633
ep6_l4_test_time 0.513159990310669
gc 0
Train Epoch7 Acc 0.9658 (38632/40000), AUC 0.9931217432022095
ep7_train_time 15.890580415725708
Test Epoch7 layer0 Acc 0.8236, AUC 0.8969445824623108, avg_entr 0.1492096483707428
ep7_l0_test_time 0.13765931129455566
Test Epoch7 layer1 Acc 0.8072, AUC 0.8750235438346863, avg_entr 0.058628443628549576
ep7_l1_test_time 0.23147058486938477
Test Epoch7 layer2 Acc 0.8088, AUC 0.8863622546195984, avg_entr 0.03970411792397499
ep7_l2_test_time 0.32662367820739746
Test Epoch7 layer3 Acc 0.8086, AUC 0.887502133846283, avg_entr 0.03748803213238716
ep7_l3_test_time 0.41994547843933105
Test Epoch7 layer4 Acc 0.8092, AUC 0.887669563293457, avg_entr 0.036317113786935806
ep7_l4_test_time 0.5164227485656738
gc 0
Train Epoch8 Acc 0.968325 (38733/40000), AUC 0.9941393136978149
ep8_train_time 15.896758317947388
Test Epoch8 layer0 Acc 0.8212, AUC 0.8939727544784546, avg_entr 0.14619438350200653
ep8_l0_test_time 0.13765430450439453
Test Epoch8 layer1 Acc 0.8054, AUC 0.8697961568832397, avg_entr 0.05570328235626221
ep8_l1_test_time 0.23065471649169922
Test Epoch8 layer2 Acc 0.8068, AUC 0.884098470211029, avg_entr 0.03884952515363693
ep8_l2_test_time 0.32625889778137207
Test Epoch8 layer3 Acc 0.8068, AUC 0.8850927352905273, avg_entr 0.037044886499643326
ep8_l3_test_time 0.4193582534790039
Test Epoch8 layer4 Acc 0.8062, AUC 0.8855636715888977, avg_entr 0.03560607135295868
ep8_l4_test_time 0.512779712677002
gc 0
Train Epoch9 Acc 0.97055 (38822/40000), AUC 0.9940305352210999
ep9_train_time 15.890724420547485
Test Epoch9 layer0 Acc 0.816, AUC 0.8905457258224487, avg_entr 0.14265590906143188
ep9_l0_test_time 0.13670992851257324
Test Epoch9 layer1 Acc 0.8034, AUC 0.8631377220153809, avg_entr 0.05067062750458717
ep9_l1_test_time 0.2305762767791748
Test Epoch9 layer2 Acc 0.804, AUC 0.8808765411376953, avg_entr 0.03514418378472328
ep9_l2_test_time 0.32631492614746094
Test Epoch9 layer3 Acc 0.8036, AUC 0.882302463054657, avg_entr 0.03294304013252258
ep9_l3_test_time 0.42002248764038086
Test Epoch9 layer4 Acc 0.8032, AUC 0.8831473588943481, avg_entr 0.03140426054596901
ep9_l4_test_time 0.5129129886627197
gc 0
Train Epoch10 Acc 0.9731 (38924/40000), AUC 0.9950096011161804
ep10_train_time 15.89808702468872
Test Epoch10 layer0 Acc 0.8152, AUC 0.8878883719444275, avg_entr 0.13918176293373108
ep10_l0_test_time 0.13637566566467285
Test Epoch10 layer1 Acc 0.799, AUC 0.859450101852417, avg_entr 0.04835067316889763
ep10_l1_test_time 0.23064517974853516
Test Epoch10 layer2 Acc 0.8002, AUC 0.8774012923240662, avg_entr 0.03402148559689522
ep10_l2_test_time 0.3267519474029541
Test Epoch10 layer3 Acc 0.7986, AUC 0.8795228004455566, avg_entr 0.031954120844602585
ep10_l3_test_time 0.4215879440307617
Test Epoch10 layer4 Acc 0.7982, AUC 0.8804600238800049, avg_entr 0.03066244162619114
ep10_l4_test_time 0.5168774127960205
gc 0
Train Epoch11 Acc 0.975775 (39031/40000), AUC 0.995797872543335
ep11_train_time 15.891421556472778
Test Epoch11 layer0 Acc 0.8122, AUC 0.8860282897949219, avg_entr 0.13628342747688293
ep11_l0_test_time 0.1375119686126709
Test Epoch11 layer1 Acc 0.8004, AUC 0.8575087785720825, avg_entr 0.04365368187427521
ep11_l1_test_time 0.2311849594116211
Test Epoch11 layer2 Acc 0.8, AUC 0.8758193254470825, avg_entr 0.029690342023968697
ep11_l2_test_time 0.32625865936279297
Test Epoch11 layer3 Acc 0.8002, AUC 0.8780348300933838, avg_entr 0.02767375111579895
ep11_l3_test_time 0.4182262420654297
Test Epoch11 layer4 Acc 0.8002, AUC 0.8790526390075684, avg_entr 0.02638932131230831
ep11_l4_test_time 0.5127773284912109
gc 0
Train Epoch12 Acc 0.9771 (39084/40000), AUC 0.9958253502845764
ep12_train_time 15.909827709197998
Test Epoch12 layer0 Acc 0.8128, AUC 0.8843787312507629, avg_entr 0.13485170900821686
ep12_l0_test_time 0.13694429397583008
Test Epoch12 layer1 Acc 0.7978, AUC 0.8533601760864258, avg_entr 0.03987232968211174
ep12_l1_test_time 0.2322826385498047
Test Epoch12 layer2 Acc 0.799, AUC 0.8731296062469482, avg_entr 0.026954486966133118
ep12_l2_test_time 0.326491117477417
Test Epoch12 layer3 Acc 0.7996, AUC 0.8760759234428406, avg_entr 0.02481483481824398
ep12_l3_test_time 0.4210999011993408
Test Epoch12 layer4 Acc 0.8002, AUC 0.8775345683097839, avg_entr 0.02348226122558117
ep12_l4_test_time 0.5131165981292725
gc 0
Train Epoch13 Acc 0.97695 (39078/40000), AUC 0.9960451126098633
ep13_train_time 15.902870178222656
Test Epoch13 layer0 Acc 0.8124, AUC 0.8834081888198853, avg_entr 0.13228769600391388
ep13_l0_test_time 0.13756561279296875
Test Epoch13 layer1 Acc 0.7966, AUC 0.849736213684082, avg_entr 0.040293727070093155
ep13_l1_test_time 0.23046422004699707
Test Epoch13 layer2 Acc 0.7968, AUC 0.8701076507568359, avg_entr 0.02735259011387825
ep13_l2_test_time 0.3257133960723877
Test Epoch13 layer3 Acc 0.7972, AUC 0.8738654255867004, avg_entr 0.025458339601755142
ep13_l3_test_time 0.41933584213256836
Test Epoch13 layer4 Acc 0.7966, AUC 0.8754198551177979, avg_entr 0.023892154917120934
ep13_l4_test_time 0.5132937431335449
gc 0
Train Epoch14 Acc 0.978725 (39149/40000), AUC 0.9964636564254761
ep14_train_time 15.898741245269775
Test Epoch14 layer0 Acc 0.8098, AUC 0.8818829655647278, avg_entr 0.13036251068115234
ep14_l0_test_time 0.1371135711669922
Test Epoch14 layer1 Acc 0.7972, AUC 0.8485028743743896, avg_entr 0.03952372446656227
ep14_l1_test_time 0.23252654075622559
Test Epoch14 layer2 Acc 0.7964, AUC 0.8684821724891663, avg_entr 0.026771491393446922
ep14_l2_test_time 0.32637810707092285
Test Epoch14 layer3 Acc 0.7966, AUC 0.8730326294898987, avg_entr 0.024557817727327347
ep14_l3_test_time 0.4201173782348633
Test Epoch14 layer4 Acc 0.7968, AUC 0.8747225999832153, avg_entr 0.022974401712417603
ep14_l4_test_time 0.513155460357666
gc 0
Train Epoch15 Acc 0.9796 (39184/40000), AUC 0.9965559244155884
ep15_train_time 15.90390944480896
Test Epoch15 layer0 Acc 0.8108, AUC 0.8812597990036011, avg_entr 0.12988081574440002
ep15_l0_test_time 0.1413896083831787
Test Epoch15 layer1 Acc 0.7958, AUC 0.8477733135223389, avg_entr 0.03974241763353348
ep15_l1_test_time 0.23070621490478516
Test Epoch15 layer2 Acc 0.7956, AUC 0.8675596117973328, avg_entr 0.027101708576083183
ep15_l2_test_time 0.3259739875793457
Test Epoch15 layer3 Acc 0.795, AUC 0.8725415468215942, avg_entr 0.02490965649485588
ep15_l3_test_time 0.42008280754089355
Test Epoch15 layer4 Acc 0.7954, AUC 0.8741678595542908, avg_entr 0.023548563942313194
ep15_l4_test_time 0.5132648944854736
gc 0
Train Epoch16 Acc 0.980125 (39205/40000), AUC 0.9968220591545105
ep16_train_time 15.91500735282898
Test Epoch16 layer0 Acc 0.8082, AUC 0.8807819485664368, avg_entr 0.12803450226783752
ep16_l0_test_time 0.13680219650268555
Test Epoch16 layer1 Acc 0.7964, AUC 0.8467797040939331, avg_entr 0.03728308528661728
ep16_l1_test_time 0.2310168743133545
Test Epoch16 layer2 Acc 0.7954, AUC 0.8665302991867065, avg_entr 0.025043195113539696
ep16_l2_test_time 0.3262319564819336
Test Epoch16 layer3 Acc 0.7956, AUC 0.8725138306617737, avg_entr 0.022818569093942642
ep16_l3_test_time 0.4195981025695801
Test Epoch16 layer4 Acc 0.797, AUC 0.8743255734443665, avg_entr 0.021209003403782845
ep16_l4_test_time 0.5166640281677246
gc 0
Train Epoch17 Acc 0.9802 (39208/40000), AUC 0.9968582391738892
ep17_train_time 15.948293209075928
Test Epoch17 layer0 Acc 0.8074, AUC 0.8798795938491821, avg_entr 0.12716792523860931
ep17_l0_test_time 0.1376817226409912
Test Epoch17 layer1 Acc 0.7956, AUC 0.8454583287239075, avg_entr 0.036787521094083786
ep17_l1_test_time 0.23307156562805176
Test Epoch17 layer2 Acc 0.796, AUC 0.8656895160675049, avg_entr 0.024892056360840797
ep17_l2_test_time 0.32650065422058105
Test Epoch17 layer3 Acc 0.7958, AUC 0.8712688088417053, avg_entr 0.022851191461086273
ep17_l3_test_time 0.4188690185546875
Test Epoch17 layer4 Acc 0.7964, AUC 0.8730821013450623, avg_entr 0.021378885954618454
ep17_l4_test_time 0.5132017135620117
gc 0
Train Epoch18 Acc 0.980425 (39217/40000), AUC 0.9969973564147949
ep18_train_time 15.911401510238647
Test Epoch18 layer0 Acc 0.8076, AUC 0.8791855573654175, avg_entr 0.1258479207754135
ep18_l0_test_time 0.1456589698791504
Test Epoch18 layer1 Acc 0.7956, AUC 0.8453777432441711, avg_entr 0.036851830780506134
ep18_l1_test_time 0.23274445533752441
Test Epoch18 layer2 Acc 0.7956, AUC 0.8651743531227112, avg_entr 0.025218628346920013
ep18_l2_test_time 0.32657337188720703
Test Epoch18 layer3 Acc 0.7956, AUC 0.8710432052612305, avg_entr 0.02327474020421505
ep18_l3_test_time 0.42142534255981445
Test Epoch18 layer4 Acc 0.7952, AUC 0.8728519082069397, avg_entr 0.02182110585272312
ep18_l4_test_time 0.5127396583557129
gc 0
Train Epoch19 Acc 0.980975 (39239/40000), AUC 0.9972556233406067
ep19_train_time 15.929132461547852
Test Epoch19 layer0 Acc 0.8052, AUC 0.8788524270057678, avg_entr 0.12564711272716522
ep19_l0_test_time 0.13692569732666016
Test Epoch19 layer1 Acc 0.7954, AUC 0.8445485830307007, avg_entr 0.03659604489803314
ep19_l1_test_time 0.23137354850769043
Test Epoch19 layer2 Acc 0.7954, AUC 0.864109992980957, avg_entr 0.02464686520397663
ep19_l2_test_time 0.326387882232666
Test Epoch19 layer3 Acc 0.796, AUC 0.8705545663833618, avg_entr 0.022495372220873833
ep19_l3_test_time 0.41879773139953613
Test Epoch19 layer4 Acc 0.7958, AUC 0.8724937438964844, avg_entr 0.020877746865153313
ep19_l4_test_time 0.5140793323516846
gc 0
Train Epoch20 Acc 0.981225 (39249/40000), AUC 0.9971331357955933
ep20_train_time 15.938255071640015
Test Epoch20 layer0 Acc 0.806, AUC 0.8786352276802063, avg_entr 0.12474451959133148
ep20_l0_test_time 0.13629722595214844
Test Epoch20 layer1 Acc 0.7946, AUC 0.8438738584518433, avg_entr 0.03680359572172165
ep20_l1_test_time 0.23220539093017578
Test Epoch20 layer2 Acc 0.7944, AUC 0.8628053069114685, avg_entr 0.025136275216937065
ep20_l2_test_time 0.3262200355529785
Test Epoch20 layer3 Acc 0.7944, AUC 0.8700412511825562, avg_entr 0.02333243191242218
ep20_l3_test_time 0.4196619987487793
Test Epoch20 layer4 Acc 0.7946, AUC 0.8719148635864258, avg_entr 0.022003326565027237
ep20_l4_test_time 0.5130002498626709
gc 0
Train Epoch21 Acc 0.98145 (39258/40000), AUC 0.9972726106643677
ep21_train_time 15.98646855354309
Test Epoch21 layer0 Acc 0.8056, AUC 0.8781368732452393, avg_entr 0.12401940673589706
ep21_l0_test_time 0.1364600658416748
Test Epoch21 layer1 Acc 0.7918, AUC 0.843372106552124, avg_entr 0.036599840968847275
ep21_l1_test_time 0.23114442825317383
Test Epoch21 layer2 Acc 0.7904, AUC 0.8623355627059937, avg_entr 0.025333702564239502
ep21_l2_test_time 0.32722949981689453
Test Epoch21 layer3 Acc 0.7912, AUC 0.8699023723602295, avg_entr 0.023481035605072975
ep21_l3_test_time 0.422440767288208
Test Epoch21 layer4 Acc 0.7898, AUC 0.8717138171195984, avg_entr 0.021857498213648796
ep21_l4_test_time 0.5138142108917236
gc 0
Train Epoch22 Acc 0.9816 (39264/40000), AUC 0.9971432089805603
ep22_train_time 15.931342363357544
Test Epoch22 layer0 Acc 0.8044, AUC 0.8779246807098389, avg_entr 0.12281353771686554
ep22_l0_test_time 0.13653111457824707
Test Epoch22 layer1 Acc 0.7942, AUC 0.8421820998191833, avg_entr 0.03469966724514961
ep22_l1_test_time 0.23079824447631836
Test Epoch22 layer2 Acc 0.7948, AUC 0.8609596490859985, avg_entr 0.023447269573807716
ep22_l2_test_time 0.32648134231567383
Test Epoch22 layer3 Acc 0.7954, AUC 0.8690308928489685, avg_entr 0.021387837827205658
ep22_l3_test_time 0.41979384422302246
Test Epoch22 layer4 Acc 0.7952, AUC 0.8712177276611328, avg_entr 0.019767584279179573
ep22_l4_test_time 0.5142700672149658
gc 0
Train Epoch23 Acc 0.981925 (39277/40000), AUC 0.9972758293151855
ep23_train_time 15.901221990585327
Test Epoch23 layer0 Acc 0.8044, AUC 0.8777188658714294, avg_entr 0.12285169959068298
ep23_l0_test_time 0.1374495029449463
Test Epoch23 layer1 Acc 0.7938, AUC 0.8421401977539062, avg_entr 0.03543872758746147
ep23_l1_test_time 0.2328052520751953
Test Epoch23 layer2 Acc 0.7932, AUC 0.860353410243988, avg_entr 0.024187196046113968
ep23_l2_test_time 0.3264625072479248
Test Epoch23 layer3 Acc 0.7932, AUC 0.8689594864845276, avg_entr 0.022212963551282883
ep23_l3_test_time 0.41944408416748047
Test Epoch23 layer4 Acc 0.7922, AUC 0.8709816932678223, avg_entr 0.020666804164648056
ep23_l4_test_time 0.5131485462188721
gc 0
Train Epoch24 Acc 0.981825 (39273/40000), AUC 0.9973692893981934
ep24_train_time 15.939385175704956
Test Epoch24 layer0 Acc 0.8044, AUC 0.8776079416275024, avg_entr 0.12238765507936478
ep24_l0_test_time 0.1365525722503662
Test Epoch24 layer1 Acc 0.7932, AUC 0.8418033123016357, avg_entr 0.035245515406131744
ep24_l1_test_time 0.23049354553222656
Test Epoch24 layer2 Acc 0.7934, AUC 0.8600172400474548, avg_entr 0.024120798334479332
ep24_l2_test_time 0.3263273239135742
Test Epoch24 layer3 Acc 0.7928, AUC 0.8688194751739502, avg_entr 0.022232189774513245
ep24_l3_test_time 0.42133212089538574
Test Epoch24 layer4 Acc 0.7928, AUC 0.8708999156951904, avg_entr 0.0207666028290987
ep24_l4_test_time 0.5130703449249268
gc 0
Train Epoch25 Acc 0.9821 (39284/40000), AUC 0.9974088668823242
ep25_train_time 15.90585994720459
Test Epoch25 layer0 Acc 0.8044, AUC 0.8774154186248779, avg_entr 0.12182586640119553
ep25_l0_test_time 0.1371612548828125
Test Epoch25 layer1 Acc 0.793, AUC 0.8413933515548706, avg_entr 0.03508972004055977
ep25_l1_test_time 0.23069310188293457
Test Epoch25 layer2 Acc 0.793, AUC 0.8594616651535034, avg_entr 0.02389618009328842
ep25_l2_test_time 0.32662010192871094
Test Epoch25 layer3 Acc 0.7932, AUC 0.8686560988426208, avg_entr 0.022051174193620682
ep25_l3_test_time 0.41989898681640625
Test Epoch25 layer4 Acc 0.7922, AUC 0.8707074522972107, avg_entr 0.020525405183434486
ep25_l4_test_time 0.5141191482543945
gc 0
Train Epoch26 Acc 0.982125 (39285/40000), AUC 0.9974639415740967
ep26_train_time 15.903110980987549
Test Epoch26 layer0 Acc 0.8032, AUC 0.8773176670074463, avg_entr 0.12142422050237656
ep26_l0_test_time 0.13670635223388672
Test Epoch26 layer1 Acc 0.7936, AUC 0.8412123918533325, avg_entr 0.034495458006858826
ep26_l1_test_time 0.23297858238220215
Test Epoch26 layer2 Acc 0.7926, AUC 0.8592565059661865, avg_entr 0.023482555523514748
ep26_l2_test_time 0.3263566493988037
Test Epoch26 layer3 Acc 0.7928, AUC 0.8683868646621704, avg_entr 0.0216611847281456
ep26_l3_test_time 0.4199821949005127
Test Epoch26 layer4 Acc 0.7926, AUC 0.8705416321754456, avg_entr 0.02017274871468544
ep26_l4_test_time 0.5133335590362549
gc 0
Train Epoch27 Acc 0.98225 (39290/40000), AUC 0.9973905086517334
ep27_train_time 15.922516345977783
Test Epoch27 layer0 Acc 0.8028, AUC 0.8772249221801758, avg_entr 0.12093618512153625
ep27_l0_test_time 0.13668608665466309
Test Epoch27 layer1 Acc 0.7934, AUC 0.8409639596939087, avg_entr 0.034438371658325195
ep27_l1_test_time 0.2307140827178955
Test Epoch27 layer2 Acc 0.7928, AUC 0.8589159250259399, avg_entr 0.023506151512265205
ep27_l2_test_time 0.326138973236084
Test Epoch27 layer3 Acc 0.7922, AUC 0.8683521747589111, avg_entr 0.021721554920077324
ep27_l3_test_time 0.4211900234222412
Test Epoch27 layer4 Acc 0.7932, AUC 0.8704798221588135, avg_entr 0.020229164510965347
ep27_l4_test_time 0.515181303024292
gc 0
Train Epoch28 Acc 0.982225 (39289/40000), AUC 0.9972676038742065
ep28_train_time 15.903237104415894
Test Epoch28 layer0 Acc 0.8036, AUC 0.8771626353263855, avg_entr 0.12064222246408463
ep28_l0_test_time 0.13627052307128906
Test Epoch28 layer1 Acc 0.793, AUC 0.8407424688339233, avg_entr 0.034429144114255905
ep28_l1_test_time 0.22998523712158203
Test Epoch28 layer2 Acc 0.7932, AUC 0.8586333990097046, avg_entr 0.02342991530895233
ep28_l2_test_time 0.32620954513549805
Test Epoch28 layer3 Acc 0.7926, AUC 0.8682365417480469, avg_entr 0.021611301228404045
ep28_l3_test_time 0.418790340423584
Test Epoch28 layer4 Acc 0.7924, AUC 0.8704026937484741, avg_entr 0.020084897056221962
ep28_l4_test_time 0.5134103298187256
gc 0
Train Epoch29 Acc 0.982525 (39301/40000), AUC 0.9973348379135132
ep29_train_time 15.91943883895874
Test Epoch29 layer0 Acc 0.8034, AUC 0.8770933151245117, avg_entr 0.12032019346952438
ep29_l0_test_time 0.13812685012817383
Test Epoch29 layer1 Acc 0.791, AUC 0.840593695640564, avg_entr 0.03446391597390175
ep29_l1_test_time 0.23314380645751953
Test Epoch29 layer2 Acc 0.7906, AUC 0.858494758605957, avg_entr 0.023366838693618774
ep29_l2_test_time 0.3265538215637207
Test Epoch29 layer3 Acc 0.7906, AUC 0.8682887554168701, avg_entr 0.021515434607863426
ep29_l3_test_time 0.4202120304107666
Test Epoch29 layer4 Acc 0.7902, AUC 0.8703714609146118, avg_entr 0.019886784255504608
ep29_l4_test_time 0.5134372711181641
gc 0
Train Epoch30 Acc 0.98265 (39306/40000), AUC 0.997525155544281
ep30_train_time 15.932687044143677
Test Epoch30 layer0 Acc 0.8036, AUC 0.8770509958267212, avg_entr 0.11995280534029007
ep30_l0_test_time 0.13674402236938477
Test Epoch30 layer1 Acc 0.791, AUC 0.8405792713165283, avg_entr 0.03423986956477165
ep30_l1_test_time 0.23125839233398438
Test Epoch30 layer2 Acc 0.7908, AUC 0.8583291172981262, avg_entr 0.023204311728477478
ep30_l2_test_time 0.326343297958374
Test Epoch30 layer3 Acc 0.7916, AUC 0.8681530952453613, avg_entr 0.021364280954003334
ep30_l3_test_time 0.42131996154785156
Test Epoch30 layer4 Acc 0.7902, AUC 0.8702666759490967, avg_entr 0.019755158573389053
ep30_l4_test_time 0.513519287109375
gc 0
Train Epoch31 Acc 0.982475 (39299/40000), AUC 0.9974896907806396
ep31_train_time 15.91028380393982
Test Epoch31 layer0 Acc 0.8036, AUC 0.877026379108429, avg_entr 0.11963172256946564
ep31_l0_test_time 0.13723540306091309
Test Epoch31 layer1 Acc 0.7916, AUC 0.8404734134674072, avg_entr 0.03407104313373566
ep31_l1_test_time 0.23114824295043945
Test Epoch31 layer2 Acc 0.7908, AUC 0.858208417892456, avg_entr 0.023080971091985703
ep31_l2_test_time 0.32662534713745117
Test Epoch31 layer3 Acc 0.7916, AUC 0.8680888414382935, avg_entr 0.021262476220726967
ep31_l3_test_time 0.4190669059753418
Test Epoch31 layer4 Acc 0.7902, AUC 0.8702080845832825, avg_entr 0.019661402329802513
ep31_l4_test_time 0.5148942470550537
gc 0
Train Epoch32 Acc 0.9825 (39300/40000), AUC 0.997562050819397
ep32_train_time 15.918519020080566
Test Epoch32 layer0 Acc 0.804, AUC 0.8770080804824829, avg_entr 0.11923529952764511
ep32_l0_test_time 0.13770699501037598
Test Epoch32 layer1 Acc 0.7928, AUC 0.8403990268707275, avg_entr 0.03368121758103371
ep32_l1_test_time 0.23246264457702637
Test Epoch32 layer2 Acc 0.7924, AUC 0.8579878807067871, avg_entr 0.02286468632519245
ep32_l2_test_time 0.32655882835388184
Test Epoch32 layer3 Acc 0.792, AUC 0.8679994344711304, avg_entr 0.021085811778903008
ep32_l3_test_time 0.4194929599761963
Test Epoch32 layer4 Acc 0.793, AUC 0.8701597452163696, avg_entr 0.01958499848842621
ep32_l4_test_time 0.5133452415466309
gc 0
Train Epoch33 Acc 0.9827 (39308/40000), AUC 0.9973599910736084
ep33_train_time 15.90665578842163
Test Epoch33 layer0 Acc 0.8036, AUC 0.8769941329956055, avg_entr 0.11910444498062134
ep33_l0_test_time 0.13698863983154297
Test Epoch33 layer1 Acc 0.793, AUC 0.840359628200531, avg_entr 0.03349819779396057
ep33_l1_test_time 0.2306206226348877
Test Epoch33 layer2 Acc 0.7924, AUC 0.8579630255699158, avg_entr 0.02271953783929348
ep33_l2_test_time 0.32604026794433594
Test Epoch33 layer3 Acc 0.792, AUC 0.8678915500640869, avg_entr 0.02094615064561367
ep33_l3_test_time 0.4212193489074707
Test Epoch33 layer4 Acc 0.7926, AUC 0.8701111674308777, avg_entr 0.019460244104266167
ep33_l4_test_time 0.5130200386047363
gc 0
Train Epoch34 Acc 0.982675 (39307/40000), AUC 0.997454047203064
ep34_train_time 15.898320436477661
Test Epoch34 layer0 Acc 0.8036, AUC 0.8769696950912476, avg_entr 0.11867591738700867
ep34_l0_test_time 0.13653326034545898
Test Epoch34 layer1 Acc 0.793, AUC 0.8402708768844604, avg_entr 0.03325558826327324
ep34_l1_test_time 0.23101377487182617
Test Epoch34 layer2 Acc 0.7922, AUC 0.8577439188957214, avg_entr 0.022567955777049065
ep34_l2_test_time 0.32679176330566406
Test Epoch34 layer3 Acc 0.7922, AUC 0.8678808808326721, avg_entr 0.02080363780260086
ep34_l3_test_time 0.4189796447753906
Test Epoch34 layer4 Acc 0.792, AUC 0.8701004981994629, avg_entr 0.019347861409187317
ep34_l4_test_time 0.5131118297576904
gc 0
Train Epoch35 Acc 0.982725 (39309/40000), AUC 0.9974991083145142
ep35_train_time 15.900359869003296
Test Epoch35 layer0 Acc 0.8038, AUC 0.8769699931144714, avg_entr 0.11854566633701324
ep35_l0_test_time 0.1367812156677246
Test Epoch35 layer1 Acc 0.7934, AUC 0.8402695655822754, avg_entr 0.033218979835510254
ep35_l1_test_time 0.232452392578125
Test Epoch35 layer2 Acc 0.7922, AUC 0.8577801585197449, avg_entr 0.022545794025063515
ep35_l2_test_time 0.32667112350463867
Test Epoch35 layer3 Acc 0.792, AUC 0.8679051399230957, avg_entr 0.02078067697584629
ep35_l3_test_time 0.42870020866394043
Test Epoch35 layer4 Acc 0.7926, AUC 0.8700908422470093, avg_entr 0.01930931769311428
ep35_l4_test_time 0.5151171684265137
gc 0
Train Epoch36 Acc 0.9827 (39308/40000), AUC 0.9974263906478882
ep36_train_time 15.899524688720703
Test Epoch36 layer0 Acc 0.8036, AUC 0.8769662380218506, avg_entr 0.11836447566747665
ep36_l0_test_time 0.13675212860107422
Test Epoch36 layer1 Acc 0.7932, AUC 0.8402584791183472, avg_entr 0.03309975191950798
ep36_l1_test_time 0.23103094100952148
Test Epoch36 layer2 Acc 0.7922, AUC 0.8577860593795776, avg_entr 0.02245277538895607
ep36_l2_test_time 0.3261880874633789
Test Epoch36 layer3 Acc 0.7922, AUC 0.8678754568099976, avg_entr 0.020689133554697037
ep36_l3_test_time 0.4200477600097656
Test Epoch36 layer4 Acc 0.7924, AUC 0.8700718879699707, avg_entr 0.019227618351578712
ep36_l4_test_time 0.5132198333740234
gc 0
Train Epoch37 Acc 0.98265 (39306/40000), AUC 0.9974840879440308
ep37_train_time 15.896917819976807
Test Epoch37 layer0 Acc 0.8028, AUC 0.876961350440979, avg_entr 0.11821285635232925
ep37_l0_test_time 0.1367943286895752
Test Epoch37 layer1 Acc 0.7926, AUC 0.840186595916748, avg_entr 0.03317777067422867
ep37_l1_test_time 0.2306063175201416
Test Epoch37 layer2 Acc 0.7932, AUC 0.8577747941017151, avg_entr 0.02246556058526039
ep37_l2_test_time 0.3269507884979248
Test Epoch37 layer3 Acc 0.7926, AUC 0.8679155111312866, avg_entr 0.02070031873881817
ep37_l3_test_time 0.4198474884033203
Test Epoch37 layer4 Acc 0.7922, AUC 0.8700366616249084, avg_entr 0.019185831770300865
ep37_l4_test_time 0.5132842063903809
gc 0
Train Epoch38 Acc 0.9827 (39308/40000), AUC 0.9975205063819885
ep38_train_time 15.918455362319946
Test Epoch38 layer0 Acc 0.8028, AUC 0.8769699335098267, avg_entr 0.11798493564128876
ep38_l0_test_time 0.13688349723815918
Test Epoch38 layer1 Acc 0.7926, AUC 0.8401553630828857, avg_entr 0.03305837884545326
ep38_l1_test_time 0.23209786415100098
Test Epoch38 layer2 Acc 0.7928, AUC 0.8576927185058594, avg_entr 0.022406745702028275
ep38_l2_test_time 0.32730531692504883
Test Epoch38 layer3 Acc 0.7922, AUC 0.867851972579956, avg_entr 0.020653747022151947
ep38_l3_test_time 0.41924428939819336
Test Epoch38 layer4 Acc 0.7928, AUC 0.8700350522994995, avg_entr 0.01915798708796501
ep38_l4_test_time 0.5128438472747803
gc 0
Train Epoch39 Acc 0.98295 (39318/40000), AUC 0.9975534081459045
ep39_train_time 15.939003467559814
Test Epoch39 layer0 Acc 0.803, AUC 0.8769737482070923, avg_entr 0.11788852512836456
ep39_l0_test_time 0.13722681999206543
Test Epoch39 layer1 Acc 0.7926, AUC 0.8401713371276855, avg_entr 0.03310579061508179
ep39_l1_test_time 0.231095552444458
Test Epoch39 layer2 Acc 0.793, AUC 0.857742965221405, avg_entr 0.022394662722945213
ep39_l2_test_time 0.32627248764038086
Test Epoch39 layer3 Acc 0.7926, AUC 0.8678746223449707, avg_entr 0.020630106329917908
ep39_l3_test_time 0.41994547843933105
Test Epoch39 layer4 Acc 0.792, AUC 0.8700317144393921, avg_entr 0.01909256912767887
ep39_l4_test_time 0.5136559009552002
gc 0
Train Epoch40 Acc 0.98275 (39310/40000), AUC 0.9974504709243774
ep40_train_time 16.005903720855713
Test Epoch40 layer0 Acc 0.8028, AUC 0.8769645094871521, avg_entr 0.11771997064352036
ep40_l0_test_time 0.13750410079956055
Test Epoch40 layer1 Acc 0.7924, AUC 0.8401499390602112, avg_entr 0.032945215702056885
ep40_l1_test_time 0.23122310638427734
Test Epoch40 layer2 Acc 0.7928, AUC 0.8576703071594238, avg_entr 0.022313809022307396
ep40_l2_test_time 0.32627320289611816
Test Epoch40 layer3 Acc 0.7924, AUC 0.8678330183029175, avg_entr 0.02055790089070797
ep40_l3_test_time 0.419205904006958
Test Epoch40 layer4 Acc 0.7924, AUC 0.8700138926506042, avg_entr 0.019060317426919937
ep40_l4_test_time 0.5131306648254395
gc 0
Train Epoch41 Acc 0.982575 (39303/40000), AUC 0.9974757432937622
ep41_train_time 15.898385524749756
Test Epoch41 layer0 Acc 0.8028, AUC 0.8769630193710327, avg_entr 0.11758029460906982
ep41_l0_test_time 0.13721346855163574
Test Epoch41 layer1 Acc 0.793, AUC 0.8401450514793396, avg_entr 0.032832905650138855
ep41_l1_test_time 0.2328493595123291
Test Epoch41 layer2 Acc 0.7922, AUC 0.85763019323349, avg_entr 0.02224804274737835
ep41_l2_test_time 0.3269968032836914
Test Epoch41 layer3 Acc 0.7918, AUC 0.8678109049797058, avg_entr 0.02049616165459156
ep41_l3_test_time 0.41891980171203613
Test Epoch41 layer4 Acc 0.7928, AUC 0.8699891567230225, avg_entr 0.019017182290554047
ep41_l4_test_time 0.5127990245819092
gc 0
Train Epoch42 Acc 0.982875 (39315/40000), AUC 0.9974206686019897
ep42_train_time 15.909765720367432
Test Epoch42 layer0 Acc 0.8028, AUC 0.8769674301147461, avg_entr 0.11742179840803146
ep42_l0_test_time 0.13668465614318848
Test Epoch42 layer1 Acc 0.793, AUC 0.8401572704315186, avg_entr 0.0327780656516552
ep42_l1_test_time 0.2311697006225586
Test Epoch42 layer2 Acc 0.7924, AUC 0.8576124906539917, avg_entr 0.02220204845070839
ep42_l2_test_time 0.32666897773742676
Test Epoch42 layer3 Acc 0.7918, AUC 0.8678011298179626, avg_entr 0.02045685052871704
ep42_l3_test_time 0.4202156066894531
Test Epoch42 layer4 Acc 0.7928, AUC 0.8699923753738403, avg_entr 0.018972856923937798
ep42_l4_test_time 0.5133321285247803
gc 0
Train Epoch43 Acc 0.98265 (39306/40000), AUC 0.9974178075790405
ep43_train_time 15.905099391937256
Test Epoch43 layer0 Acc 0.8026, AUC 0.8769567012786865, avg_entr 0.11733759939670563
ep43_l0_test_time 0.13772964477539062
Test Epoch43 layer1 Acc 0.793, AUC 0.8401557207107544, avg_entr 0.032726481556892395
ep43_l1_test_time 0.2314434051513672
Test Epoch43 layer2 Acc 0.7924, AUC 0.8576359152793884, avg_entr 0.022167285904288292
ep43_l2_test_time 0.32698583602905273
Test Epoch43 layer3 Acc 0.7918, AUC 0.8677886128425598, avg_entr 0.02042209915816784
ep43_l3_test_time 0.4192321300506592
Test Epoch43 layer4 Acc 0.7928, AUC 0.8699947595596313, avg_entr 0.018946634605526924
ep43_l4_test_time 0.5133373737335205
gc 0
Train Epoch44 Acc 0.98305 (39322/40000), AUC 0.9975764751434326
ep44_train_time 15.918555974960327
Test Epoch44 layer0 Acc 0.803, AUC 0.8769582509994507, avg_entr 0.11723044514656067
ep44_l0_test_time 0.13736391067504883
Test Epoch44 layer1 Acc 0.793, AUC 0.8401461839675903, avg_entr 0.032659318298101425
ep44_l1_test_time 0.23223471641540527
Test Epoch44 layer2 Acc 0.7924, AUC 0.8576351404190063, avg_entr 0.022127926349639893
ep44_l2_test_time 0.328338623046875
Test Epoch44 layer3 Acc 0.7918, AUC 0.8677979707717896, avg_entr 0.02038617618381977
ep44_l3_test_time 0.41997599601745605
Test Epoch44 layer4 Acc 0.793, AUC 0.8700000047683716, avg_entr 0.018915269523859024
ep44_l4_test_time 0.513324499130249
gc 0
Train Epoch45 Acc 0.98285 (39314/40000), AUC 0.9976506233215332
ep45_train_time 15.907642364501953
Test Epoch45 layer0 Acc 0.8026, AUC 0.876960277557373, avg_entr 0.11713901162147522
ep45_l0_test_time 0.13696503639221191
Test Epoch45 layer1 Acc 0.793, AUC 0.8401648998260498, avg_entr 0.032614365220069885
ep45_l1_test_time 0.2310314178466797
Test Epoch45 layer2 Acc 0.7924, AUC 0.8576477766036987, avg_entr 0.022091634571552277
ep45_l2_test_time 0.3270399570465088
Test Epoch45 layer3 Acc 0.7918, AUC 0.8677808046340942, avg_entr 0.0203480813652277
ep45_l3_test_time 0.42113828659057617
Test Epoch45 layer4 Acc 0.7928, AUC 0.8700004816055298, avg_entr 0.018878471106290817
ep45_l4_test_time 0.5142683982849121
gc 0
Train Epoch46 Acc 0.983 (39320/40000), AUC 0.9975575804710388
ep46_train_time 15.95271110534668
Test Epoch46 layer0 Acc 0.8026, AUC 0.8769614696502686, avg_entr 0.117049939930439
ep46_l0_test_time 0.13913536071777344
Test Epoch46 layer1 Acc 0.7928, AUC 0.8401695489883423, avg_entr 0.03260980546474457
ep46_l1_test_time 0.23342108726501465
Test Epoch46 layer2 Acc 0.7926, AUC 0.857621967792511, avg_entr 0.02207791805267334
ep46_l2_test_time 0.32894086837768555
Test Epoch46 layer3 Acc 0.792, AUC 0.8678046464920044, avg_entr 0.020332928746938705
ep46_l3_test_time 0.42153167724609375
Test Epoch46 layer4 Acc 0.7928, AUC 0.8699965476989746, avg_entr 0.018849877640604973
ep46_l4_test_time 0.5137836933135986
gc 0
Train Epoch47 Acc 0.982725 (39309/40000), AUC 0.9975612163543701
ep47_train_time 15.916118383407593
Test Epoch47 layer0 Acc 0.8026, AUC 0.8769630789756775, avg_entr 0.11699382215738297
ep47_l0_test_time 0.1376023292541504
Test Epoch47 layer1 Acc 0.793, AUC 0.8401618003845215, avg_entr 0.03256746381521225
ep47_l1_test_time 0.23205184936523438
Test Epoch47 layer2 Acc 0.7924, AUC 0.8576395511627197, avg_entr 0.022053537890315056
ep47_l2_test_time 0.326977014541626
Test Epoch47 layer3 Acc 0.792, AUC 0.8677105903625488, avg_entr 0.020311065018177032
ep47_l3_test_time 0.4196343421936035
Test Epoch47 layer4 Acc 0.7926, AUC 0.8700002431869507, avg_entr 0.01883448101580143
ep47_l4_test_time 0.5127034187316895
gc 0
Train Epoch48 Acc 0.98285 (39314/40000), AUC 0.997427761554718
ep48_train_time 15.945604085922241
Test Epoch48 layer0 Acc 0.8026, AUC 0.8769636154174805, avg_entr 0.11693651974201202
ep48_l0_test_time 0.1388564109802246
Test Epoch48 layer1 Acc 0.793, AUC 0.8401638269424438, avg_entr 0.032533757388591766
ep48_l1_test_time 0.23290085792541504
Test Epoch48 layer2 Acc 0.7924, AUC 0.8576993942260742, avg_entr 0.022030269727110863
ep48_l2_test_time 0.3266770839691162
Test Epoch48 layer3 Acc 0.7918, AUC 0.8677846193313599, avg_entr 0.0202889833599329
ep48_l3_test_time 0.421262264251709
Test Epoch48 layer4 Acc 0.7928, AUC 0.8699449896812439, avg_entr 0.01881597936153412
ep48_l4_test_time 0.5138487815856934
gc 0
Train Epoch49 Acc 0.9829 (39316/40000), AUC 0.9976197481155396
ep49_train_time 15.909443140029907
Test Epoch49 layer0 Acc 0.8026, AUC 0.876967191696167, avg_entr 0.11687996983528137
ep49_l0_test_time 0.13666391372680664
Test Epoch49 layer1 Acc 0.793, AUC 0.8401838541030884, avg_entr 0.03252612054347992
ep49_l1_test_time 0.23112058639526367
Test Epoch49 layer2 Acc 0.7924, AUC 0.8577041625976562, avg_entr 0.02202051691710949
ep49_l2_test_time 0.3264040946960449
Test Epoch49 layer3 Acc 0.792, AUC 0.8677871227264404, avg_entr 0.02027854509651661
ep49_l3_test_time 0.4199059009552002
Test Epoch49 layer4 Acc 0.7928, AUC 0.8699493408203125, avg_entr 0.01879856176674366
ep49_l4_test_time 0.5137732028961182
Best AUC 0.9209606647491455
train_loss (2, 5, 50)
valid_acc (5, 50)
valid_AUC (5, 50)
train_acc (50,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train+valid_time 880.307993888855
Start Testing
Load ckpt at ckpt/imdb_transformeral_l5_pad100//imdb_transformeral_l5.pt
Test layer0 Acc 0.8352, AUC 0.9206439256668091, avg_entr 0.26571738719940186
l0_test_time 0.13474273681640625
Test layer1 Acc 0.8358, AUC 0.9236592650413513, avg_entr 0.22211435437202454
l1_test_time 0.23014307022094727
Test layer2 Acc 0.8072, AUC 0.9230766296386719, avg_entr 0.19158297777175903
l2_test_time 0.32614994049072266
Test layer3 Acc 0.7834, AUC 0.9223576784133911, avg_entr 0.16359733045101166
l3_test_time 0.4189941883087158
Test layer4 Acc 0.7678, AUC 0.9218912124633789, avg_entr 0.1522694081068039
l4_test_time 0.5119633674621582
