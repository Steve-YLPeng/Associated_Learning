total count words 222751
vocab size 30000
found 27937 words in glove
model: TransformerModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=2, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=2, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): TransLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): TransformerEncoder(
          (multi_headed_attention): MultiHeadAttention(
            (linears): ModuleList(
              (0): Linear(in_features=300, out_features=300, bias=True)
              (1): Linear(in_features=300, out_features=300, bias=True)
              (2): Linear(in_features=300, out_features=300, bias=True)
              (3): Linear(in_features=300, out_features=300, bias=True)
            )
            (sdpa): ScaledDotProductAttention()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (feed_forward): FeedForward(
            (w_1): Linear(in_features=300, out_features=300, bias=True)
            (w_2): Linear(in_features=300, out_features=300, bias=True)
            (relu): ReLU()
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (encoder_layer): EncoderLayer(
            (self_attn): MultiHeadAttention(
              (linears): ModuleList(
                (0): Linear(in_features=300, out_features=300, bias=True)
                (1): Linear(in_features=300, out_features=300, bias=True)
                (2): Linear(in_features=300, out_features=300, bias=True)
                (3): Linear(in_features=300, out_features=300, bias=True)
              )
              (sdpa): ScaledDotProductAttention()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (feed_forward): FeedForward(
              (w_1): Linear(in_features=300, out_features=300, bias=True)
              (w_2): Linear(in_features=300, out_features=300, bias=True)
              (relu): ReLU()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (encoder): Encoder(
            (layers): ModuleList(
              (0): EncoderLayer(
                (self_attn): MultiHeadAttention(
                  (linears): ModuleList(
                    (0): Linear(in_features=300, out_features=300, bias=True)
                    (1): Linear(in_features=300, out_features=300, bias=True)
                    (2): Linear(in_features=300, out_features=300, bias=True)
                    (3): Linear(in_features=300, out_features=300, bias=True)
                  )
                  (sdpa): ScaledDotProductAttention()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (feed_forward): FeedForward(
                  (w_1): Linear(in_features=300, out_features=300, bias=True)
                  (w_2): Linear(in_features=300, out_features=300, bias=True)
                  (relu): ReLU()
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (sublayer): ModuleList(
                  (0): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                  (1): SublayerConnection(
                    (norm): LayerNorm()
                    (dropout): Dropout(p=0.1, inplace=False)
                  )
                )
              )
            )
            (norm): LayerNorm()
          )
        )
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 256
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 256
layers.0.ae.h.0.bias 2
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.multi_headed_attention.linears.0.weight 90000
layers.1.enc.f.multi_headed_attention.linears.0.bias 300
layers.1.enc.f.multi_headed_attention.linears.1.weight 90000
layers.1.enc.f.multi_headed_attention.linears.1.bias 300
layers.1.enc.f.multi_headed_attention.linears.2.weight 90000
layers.1.enc.f.multi_headed_attention.linears.2.bias 300
layers.1.enc.f.multi_headed_attention.linears.3.weight 90000
layers.1.enc.f.multi_headed_attention.linears.3.bias 300
layers.1.enc.f.feed_forward.w_1.weight 90000
layers.1.enc.f.feed_forward.w_1.bias 300
layers.1.enc.f.feed_forward.w_2.weight 90000
layers.1.enc.f.feed_forward.w_2.bias 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.1.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.1.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.1.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.1.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.1.enc.f.encoder.norm.a 300
layers.1.enc.f.encoder.norm.b 300
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.multi_headed_attention.linears.0.weight 90000
layers.2.enc.f.multi_headed_attention.linears.0.bias 300
layers.2.enc.f.multi_headed_attention.linears.1.weight 90000
layers.2.enc.f.multi_headed_attention.linears.1.bias 300
layers.2.enc.f.multi_headed_attention.linears.2.weight 90000
layers.2.enc.f.multi_headed_attention.linears.2.bias 300
layers.2.enc.f.multi_headed_attention.linears.3.weight 90000
layers.2.enc.f.multi_headed_attention.linears.3.bias 300
layers.2.enc.f.feed_forward.w_1.weight 90000
layers.2.enc.f.feed_forward.w_1.bias 300
layers.2.enc.f.feed_forward.w_2.weight 90000
layers.2.enc.f.feed_forward.w_2.bias 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.2.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.2.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.2.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.2.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.2.enc.f.encoder.norm.a 300
layers.2.enc.f.encoder.norm.b 300
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.multi_headed_attention.linears.0.weight 90000
layers.3.enc.f.multi_headed_attention.linears.0.bias 300
layers.3.enc.f.multi_headed_attention.linears.1.weight 90000
layers.3.enc.f.multi_headed_attention.linears.1.bias 300
layers.3.enc.f.multi_headed_attention.linears.2.weight 90000
layers.3.enc.f.multi_headed_attention.linears.2.bias 300
layers.3.enc.f.multi_headed_attention.linears.3.weight 90000
layers.3.enc.f.multi_headed_attention.linears.3.bias 300
layers.3.enc.f.feed_forward.w_1.weight 90000
layers.3.enc.f.feed_forward.w_1.bias 300
layers.3.enc.f.feed_forward.w_2.weight 90000
layers.3.enc.f.feed_forward.w_2.bias 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.3.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.3.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.3.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.3.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.3.enc.f.encoder.norm.a 300
layers.3.enc.f.encoder.norm.b 300
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.multi_headed_attention.linears.0.weight 90000
layers.4.enc.f.multi_headed_attention.linears.0.bias 300
layers.4.enc.f.multi_headed_attention.linears.1.weight 90000
layers.4.enc.f.multi_headed_attention.linears.1.bias 300
layers.4.enc.f.multi_headed_attention.linears.2.weight 90000
layers.4.enc.f.multi_headed_attention.linears.2.bias 300
layers.4.enc.f.multi_headed_attention.linears.3.weight 90000
layers.4.enc.f.multi_headed_attention.linears.3.bias 300
layers.4.enc.f.feed_forward.w_1.weight 90000
layers.4.enc.f.feed_forward.w_1.bias 300
layers.4.enc.f.feed_forward.w_2.weight 90000
layers.4.enc.f.feed_forward.w_2.bias 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.0.norm.b 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.a 300
layers.4.enc.f.encoder_layer.sublayer.1.norm.b 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.0.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.1.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.2.bias 300
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.weight 90000
layers.4.enc.f.encoder.layers.0.self_attn.linears.3.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_1.bias 300
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.weight 90000
layers.4.enc.f.encoder.layers.0.feed_forward.w_2.bias 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.0.norm.b 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.a 300
layers.4.enc.f.encoder.layers.0.sublayer.1.norm.b 300
layers.4.enc.f.encoder.norm.a 300
layers.4.enc.f.encoder.norm.b 300
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 13671778
Start Training
train_mask {0}
gc 0
Train Epoch0 Acc 0.4998 (19992/40000), AUC 0.47253286838531494
ep0_train_time 46.48080110549927
Test Epoch0 threshold 0.1 Acc 0.8205, AUC 0.8966728448867798, avg_entr 0.8119151592254639
ep0_t0.1_test_time 1.1121418476104736
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 0
Test Epoch0 threshold 0.2 Acc 0.8205, AUC 0.8966728448867798, avg_entr 0.8119151592254639
ep0_t0.2_test_time 1.111548662185669
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 0
Test Epoch0 threshold 0.3 Acc 0.8205, AUC 0.8966728448867798, avg_entr 0.8119151592254639
ep0_t0.3_test_time 1.142737627029419
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 0
Test Epoch0 threshold 0.4 Acc 0.8205, AUC 0.8966728448867798, avg_entr 0.8119151592254639
ep0_t0.4_test_time 1.1081407070159912
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 0
Test Epoch0 threshold 0.5 Acc 0.8205, AUC 0.8966728448867798, avg_entr 0.8119151592254639
ep0_t0.5_test_time 1.1081187725067139
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 0
Test Epoch0 threshold 0.6 Acc 0.8205, AUC 0.8966728448867798, avg_entr 0.8119151592254639
ep0_t0.6_test_time 1.1141645908355713
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 0
Test Epoch0 threshold 0.7 Acc 0.8205, AUC 0.8966728448867798, avg_entr 0.8119151592254639
ep0_t0.7_test_time 1.1232967376708984
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 0
Test Epoch0 threshold 0.8 Acc 0.8205, AUC 0.8966728448867798, avg_entr 0.8119151592254639
ep0_t0.8_test_time 1.1308672428131104
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 0
Test Epoch0 threshold 0.9 Acc 0.8205, AUC 0.8966728448867798, avg_entr 0.8119151592254639
ep0_t0.9_test_time 1.1044342517852783
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.499675 (19987/40000), AUC 0.36105358600616455
ep1_train_time 46.17007899284363
Test Epoch1 threshold 0.1 Acc 0.8515, AUC 0.9206315875053406, avg_entr 0.6478199362754822
ep1_t0.1_test_time 1.1337659358978271
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 1
Test Epoch1 threshold 0.2 Acc 0.8515, AUC 0.9206315875053406, avg_entr 0.6478199362754822
ep1_t0.2_test_time 1.1168994903564453
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 1
Test Epoch1 threshold 0.3 Acc 0.8515, AUC 0.9206315875053406, avg_entr 0.6478199362754822
ep1_t0.3_test_time 1.106266975402832
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 1
Test Epoch1 threshold 0.4 Acc 0.8515, AUC 0.9206315875053406, avg_entr 0.6478199362754822
ep1_t0.4_test_time 1.108457088470459
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 1
Test Epoch1 threshold 0.5 Acc 0.8515, AUC 0.9206315875053406, avg_entr 0.6478199362754822
ep1_t0.5_test_time 1.1208696365356445
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 1
Test Epoch1 threshold 0.6 Acc 0.8515, AUC 0.9206315875053406, avg_entr 0.6478199362754822
ep1_t0.6_test_time 1.1043765544891357
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 1
Test Epoch1 threshold 0.7 Acc 0.8515, AUC 0.9206315875053406, avg_entr 0.6478199362754822
ep1_t0.7_test_time 1.104642629623413
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 1
Test Epoch1 threshold 0.8 Acc 0.8515, AUC 0.9206315875053406, avg_entr 0.6478199362754822
ep1_t0.8_test_time 1.119832992553711
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 1
Test Epoch1 threshold 0.9 Acc 0.8515, AUC 0.9206315875053406, avg_entr 0.6478199362754822
ep1_t0.9_test_time 1.1087782382965088
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.499675 (19987/40000), AUC 0.3468411862850189
ep2_train_time 46.168574810028076
Test Epoch2 threshold 0.1 Acc 0.8513, AUC 0.9245731830596924, avg_entr 0.6075757145881653
ep2_t0.1_test_time 1.1106786727905273
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 2
Test Epoch2 threshold 0.2 Acc 0.8513, AUC 0.9245731830596924, avg_entr 0.6075757145881653
ep2_t0.2_test_time 1.1141059398651123
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 2
Test Epoch2 threshold 0.3 Acc 0.8513, AUC 0.9245731830596924, avg_entr 0.6075757145881653
ep2_t0.3_test_time 1.125779628753662
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 2
Test Epoch2 threshold 0.4 Acc 0.8513, AUC 0.9245731830596924, avg_entr 0.6075757145881653
ep2_t0.4_test_time 1.1080071926116943
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 2
Test Epoch2 threshold 0.5 Acc 0.8513, AUC 0.9245731830596924, avg_entr 0.6075757145881653
ep2_t0.5_test_time 1.1163787841796875
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 2
Test Epoch2 threshold 0.6 Acc 0.8513, AUC 0.9245731830596924, avg_entr 0.6075757145881653
ep2_t0.6_test_time 1.1201677322387695
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 2
Test Epoch2 threshold 0.7 Acc 0.8513, AUC 0.9245731830596924, avg_entr 0.6075757145881653
ep2_t0.7_test_time 1.102323055267334
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 2
Test Epoch2 threshold 0.8 Acc 0.8513, AUC 0.9245731830596924, avg_entr 0.6075757145881653
ep2_t0.8_test_time 1.1180789470672607
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 2
Test Epoch2 threshold 0.9 Acc 0.8513, AUC 0.9245731830596924, avg_entr 0.6075757145881653
ep2_t0.9_test_time 1.1177356243133545
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.499675 (19987/40000), AUC 0.3453233242034912
ep3_train_time 46.16797375679016
Test Epoch3 threshold 0.1 Acc 0.8604, AUC 0.925346851348877, avg_entr 0.6018680930137634
ep3_t0.1_test_time 1.1079299449920654
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 3
Test Epoch3 threshold 0.2 Acc 0.8604, AUC 0.925346851348877, avg_entr 0.6018680930137634
ep3_t0.2_test_time 1.13582444190979
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 3
Test Epoch3 threshold 0.3 Acc 0.8604, AUC 0.925346851348877, avg_entr 0.6018680930137634
ep3_t0.3_test_time 1.1126925945281982
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 3
Test Epoch3 threshold 0.4 Acc 0.8604, AUC 0.925346851348877, avg_entr 0.6018680930137634
ep3_t0.4_test_time 1.104144811630249
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 3
Test Epoch3 threshold 0.5 Acc 0.8604, AUC 0.925346851348877, avg_entr 0.6018680930137634
ep3_t0.5_test_time 1.1031062602996826
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 3
Test Epoch3 threshold 0.6 Acc 0.8604, AUC 0.925346851348877, avg_entr 0.6018680930137634
ep3_t0.6_test_time 1.1021900177001953
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 3
Test Epoch3 threshold 0.7 Acc 0.8604, AUC 0.925346851348877, avg_entr 0.6018680930137634
ep3_t0.7_test_time 1.1224145889282227
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 3
Test Epoch3 threshold 0.8 Acc 0.8604, AUC 0.925346851348877, avg_entr 0.6018680930137634
ep3_t0.8_test_time 1.1242907047271729
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 3
Test Epoch3 threshold 0.9 Acc 0.8604, AUC 0.925346851348877, avg_entr 0.6018680930137634
ep3_t0.9_test_time 1.1183788776397705
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 3
gc 0
Train Epoch4 Acc 0.499675 (19987/40000), AUC 0.3449661135673523
ep4_train_time 46.18895506858826
Test Epoch4 threshold 0.1 Acc 0.8599, AUC 0.9255695343017578, avg_entr 0.5988025665283203
ep4_t0.1_test_time 1.1481127738952637
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 4
Test Epoch4 threshold 0.2 Acc 0.8599, AUC 0.9255695343017578, avg_entr 0.5988025665283203
ep4_t0.2_test_time 1.1440351009368896
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 4
Test Epoch4 threshold 0.3 Acc 0.8599, AUC 0.9255695343017578, avg_entr 0.5988025665283203
ep4_t0.3_test_time 1.1443886756896973
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 4
Test Epoch4 threshold 0.4 Acc 0.8599, AUC 0.9255695343017578, avg_entr 0.5988025665283203
ep4_t0.4_test_time 1.1213531494140625
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 4
Test Epoch4 threshold 0.5 Acc 0.8599, AUC 0.9255695343017578, avg_entr 0.5988025665283203
ep4_t0.5_test_time 1.1122329235076904
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 4
Test Epoch4 threshold 0.6 Acc 0.8599, AUC 0.9255695343017578, avg_entr 0.5988025665283203
ep4_t0.6_test_time 1.1069738864898682
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 4
Test Epoch4 threshold 0.7 Acc 0.8599, AUC 0.9255695343017578, avg_entr 0.5988025665283203
ep4_t0.7_test_time 1.1056244373321533
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 4
Test Epoch4 threshold 0.8 Acc 0.8599, AUC 0.9255695343017578, avg_entr 0.5988025665283203
ep4_t0.8_test_time 1.1027812957763672
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 4
Test Epoch4 threshold 0.9 Acc 0.8599, AUC 0.9255695343017578, avg_entr 0.5988025665283203
ep4_t0.9_test_time 1.1001653671264648
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 4
gc 0
Train Epoch5 Acc 0.499675 (19987/40000), AUC 0.34489235281944275
ep5_train_time 46.26884961128235
Test Epoch5 threshold 0.1 Acc 0.8603, AUC 0.9256100058555603, avg_entr 0.5983057022094727
ep5_t0.1_test_time 1.1070880889892578
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 5
Test Epoch5 threshold 0.2 Acc 0.8603, AUC 0.9256100058555603, avg_entr 0.5983057022094727
ep5_t0.2_test_time 1.1118230819702148
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 5
Test Epoch5 threshold 0.3 Acc 0.8603, AUC 0.9256100058555603, avg_entr 0.5983057022094727
ep5_t0.3_test_time 1.1109809875488281
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 5
Test Epoch5 threshold 0.4 Acc 0.8603, AUC 0.9256100058555603, avg_entr 0.5983057022094727
ep5_t0.4_test_time 1.110666275024414
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 5
Test Epoch5 threshold 0.5 Acc 0.8603, AUC 0.9256100058555603, avg_entr 0.5983057022094727
ep5_t0.5_test_time 1.1060795783996582
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 5
Test Epoch5 threshold 0.6 Acc 0.8603, AUC 0.9256100058555603, avg_entr 0.5983057022094727
ep5_t0.6_test_time 1.116426944732666
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 5
Test Epoch5 threshold 0.7 Acc 0.8603, AUC 0.9256100058555603, avg_entr 0.5983057022094727
ep5_t0.7_test_time 1.1249067783355713
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 5
Test Epoch5 threshold 0.8 Acc 0.8603, AUC 0.9256100058555603, avg_entr 0.5983057022094727
ep5_t0.8_test_time 1.1001300811767578
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 5
Test Epoch5 threshold 0.9 Acc 0.8603, AUC 0.9256100058555603, avg_entr 0.5983057022094727
ep5_t0.9_test_time 1.1078615188598633
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 5
gc 0
Train Epoch6 Acc 0.499675 (19987/40000), AUC 0.34486329555511475
ep6_train_time 46.22129511833191
Test Epoch6 threshold 0.1 Acc 0.8602, AUC 0.9256216287612915, avg_entr 0.5981466770172119
ep6_t0.1_test_time 1.1446454524993896
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 6
Test Epoch6 threshold 0.2 Acc 0.8602, AUC 0.9256216287612915, avg_entr 0.5981466770172119
ep6_t0.2_test_time 1.1123242378234863
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 6
Test Epoch6 threshold 0.3 Acc 0.8602, AUC 0.9256216287612915, avg_entr 0.5981466770172119
ep6_t0.3_test_time 1.1218993663787842
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 6
Test Epoch6 threshold 0.4 Acc 0.8602, AUC 0.9256216287612915, avg_entr 0.5981466770172119
ep6_t0.4_test_time 1.2224841117858887
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 6
Test Epoch6 threshold 0.5 Acc 0.8602, AUC 0.9256216287612915, avg_entr 0.5981466770172119
ep6_t0.5_test_time 1.1044838428497314
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 6
Test Epoch6 threshold 0.6 Acc 0.8602, AUC 0.9256216287612915, avg_entr 0.5981466770172119
ep6_t0.6_test_time 1.1141088008880615
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 6
Test Epoch6 threshold 0.7 Acc 0.8602, AUC 0.9256216287612915, avg_entr 0.5981466770172119
ep6_t0.7_test_time 1.1471383571624756
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 6
Test Epoch6 threshold 0.8 Acc 0.8602, AUC 0.9256216287612915, avg_entr 0.5981466770172119
ep6_t0.8_test_time 1.1000735759735107
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 6
Test Epoch6 threshold 0.9 Acc 0.8602, AUC 0.9256216287612915, avg_entr 0.5981466770172119
ep6_t0.9_test_time 1.096409797668457
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 6
gc 0
Train Epoch7 Acc 0.499675 (19987/40000), AUC 0.3448548913002014
ep7_train_time 46.20256519317627
Test Epoch7 threshold 0.1 Acc 0.8601, AUC 0.9256241321563721, avg_entr 0.5981019735336304
ep7_t0.1_test_time 1.1027145385742188
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 7
Test Epoch7 threshold 0.2 Acc 0.8601, AUC 0.9256241321563721, avg_entr 0.5981019735336304
ep7_t0.2_test_time 1.1374351978302002
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 7
Test Epoch7 threshold 0.3 Acc 0.8601, AUC 0.9256241321563721, avg_entr 0.5981019735336304
ep7_t0.3_test_time 1.110198736190796
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 7
Test Epoch7 threshold 0.4 Acc 0.8601, AUC 0.9256241321563721, avg_entr 0.5981019735336304
ep7_t0.4_test_time 1.122969388961792
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 7
Test Epoch7 threshold 0.5 Acc 0.8601, AUC 0.9256241321563721, avg_entr 0.5981019735336304
ep7_t0.5_test_time 1.131727933883667
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 7
Test Epoch7 threshold 0.6 Acc 0.8601, AUC 0.9256241321563721, avg_entr 0.5981019735336304
ep7_t0.6_test_time 1.1269831657409668
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 7
Test Epoch7 threshold 0.7 Acc 0.8601, AUC 0.9256241321563721, avg_entr 0.5981019735336304
ep7_t0.7_test_time 1.1100490093231201
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 7
Test Epoch7 threshold 0.8 Acc 0.8601, AUC 0.9256241321563721, avg_entr 0.5981019735336304
ep7_t0.8_test_time 1.0964982509613037
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 7
Test Epoch7 threshold 0.9 Acc 0.8601, AUC 0.9256241321563721, avg_entr 0.5981019735336304
ep7_t0.9_test_time 1.1097235679626465
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 7
gc 0
Train Epoch8 Acc 0.499675 (19987/40000), AUC 0.3448528051376343
ep8_train_time 46.219592571258545
Test Epoch8 threshold 0.1 Acc 0.8601, AUC 0.9256246089935303, avg_entr 0.5980934500694275
ep8_t0.1_test_time 1.1066796779632568
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 8
Test Epoch8 threshold 0.2 Acc 0.8601, AUC 0.9256246089935303, avg_entr 0.5980934500694275
ep8_t0.2_test_time 1.118131160736084
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 8
Test Epoch8 threshold 0.3 Acc 0.8601, AUC 0.9256246089935303, avg_entr 0.5980934500694275
ep8_t0.3_test_time 1.1499717235565186
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 8
Test Epoch8 threshold 0.4 Acc 0.8601, AUC 0.9256246089935303, avg_entr 0.5980934500694275
ep8_t0.4_test_time 1.1138255596160889
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 8
Test Epoch8 threshold 0.5 Acc 0.8601, AUC 0.9256246089935303, avg_entr 0.5980934500694275
ep8_t0.5_test_time 1.1132805347442627
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 8
Test Epoch8 threshold 0.6 Acc 0.8601, AUC 0.9256246089935303, avg_entr 0.5980934500694275
ep8_t0.6_test_time 1.1456847190856934
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 8
Test Epoch8 threshold 0.7 Acc 0.8601, AUC 0.9256246089935303, avg_entr 0.5980934500694275
ep8_t0.7_test_time 1.119070291519165
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 8
Test Epoch8 threshold 0.8 Acc 0.8601, AUC 0.9256246089935303, avg_entr 0.5980934500694275
ep8_t0.8_test_time 1.1016154289245605
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 8
Test Epoch8 threshold 0.9 Acc 0.8601, AUC 0.9256246089935303, avg_entr 0.5980934500694275
ep8_t0.9_test_time 1.100809097290039
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 8
gc 0
Train Epoch9 Acc 0.499675 (19987/40000), AUC 0.344851553440094
ep9_train_time 46.234604597091675
Test Epoch9 threshold 0.1 Acc 0.8601, AUC 0.9256248474121094, avg_entr 0.5980848670005798
ep9_t0.1_test_time 1.1149466037750244
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 9
Test Epoch9 threshold 0.2 Acc 0.8601, AUC 0.9256248474121094, avg_entr 0.5980848670005798
ep9_t0.2_test_time 1.1044001579284668
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 9
Test Epoch9 threshold 0.3 Acc 0.8601, AUC 0.9256248474121094, avg_entr 0.5980848670005798
ep9_t0.3_test_time 1.1442267894744873
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 9
Test Epoch9 threshold 0.4 Acc 0.8601, AUC 0.9256248474121094, avg_entr 0.5980848670005798
ep9_t0.4_test_time 1.1088695526123047
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 9
Test Epoch9 threshold 0.5 Acc 0.8601, AUC 0.9256248474121094, avg_entr 0.5980848670005798
ep9_t0.5_test_time 1.1142668724060059
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 9
Test Epoch9 threshold 0.6 Acc 0.8601, AUC 0.9256248474121094, avg_entr 0.5980848670005798
ep9_t0.6_test_time 1.1503138542175293
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 9
Test Epoch9 threshold 0.7 Acc 0.8601, AUC 0.9256248474121094, avg_entr 0.5980848670005798
ep9_t0.7_test_time 1.100853443145752
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 9
Test Epoch9 threshold 0.8 Acc 0.8601, AUC 0.9256248474121094, avg_entr 0.5980848670005798
ep9_t0.8_test_time 1.1129279136657715
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 9
Test Epoch9 threshold 0.9 Acc 0.8601, AUC 0.9256248474121094, avg_entr 0.5980848670005798
ep9_t0.9_test_time 1.3304369449615479
Save ckpt to ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt  ,ep 9
Best AUC 0.9256248474121094
train_loss (2, 5, 10)
valid_acc (10, 9)
valid_AUC (10, 9)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Start Testing
Load ckpt at ckpt/imdb_transformeral_l5_pad500_m1//imdb_transformeral_l5_prefix.pt
[[4371  642]
 [ 757 4230]]
Figure(640x480)
tensor([0.2869, 0.1566, 0.6383,  ..., 0.1662, 0.3948, 0.0972])
[[ 173 4840]
 [ 317 4670]]
Figure(640x480)
tensor([0.6301, 0.5857, 0.6270,  ..., 0.5720, 0.5592, 0.5858])
[[5013    0]
 [4987    0]]
Figure(640x480)
tensor([0.4832, 0.4307, 0.4500,  ..., 0.3890, 0.4472, 0.4312])
[[4984   29]
 [4956   31]]
Figure(640x480)
tensor([0.5250, 0.5357, 0.5574,  ..., 0.5708, 0.5507, 0.5597])
[[5013    0]
 [4987    0]]
Figure(640x480)
tensor([0.4390, 0.3820, 0.2683,  ..., 0.3811, 0.4806, 0.4133])
