total count words 102019
vocab size 30000
found 26754 words in glove
Load ckpt from ckpt/ag_news_lstmal_l5adf_pad175_t0.4_m1//ag_news_lstmal_l5_prefix.pt
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
init_time 19.984986066818237
Start Training
train_mask {0, 1}
gc 9
Train Epoch0 Acc 0.30669166666666664 (36803/120000), AUC 0.5016266703605652
ep0_train_time 55.977829933166504
Test Epoch0 threshold 0.4 Acc 0.9121052631578948, AUC 0.9784348011016846, avg_entr 0.02582535333931446
ep0_t0.4_test_time 0.20520830154418945
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.4_m2//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.254025 (30483/120000), AUC 0.44406670331954956
ep1_train_time 55.93107509613037
Test Epoch1 threshold 0.4 Acc 0.9107894736842105, AUC 0.9780946969985962, avg_entr 0.02483619749546051
ep1_t0.4_test_time 0.2082366943359375
gc 0
Train Epoch2 Acc 0.251475 (30177/120000), AUC 0.4328877627849579
ep2_train_time 55.94047927856445
Test Epoch2 threshold 0.4 Acc 0.911578947368421, AUC 0.9786145687103271, avg_entr 0.02594231441617012
ep2_t0.4_test_time 0.18174433708190918
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.4_m2//ag_news_lstmal_l5_prefix.pt  ,ep 2
gc 0
Train Epoch3 Acc 0.25128333333333336 (30154/120000), AUC 0.41789406538009644
ep3_train_time 55.96784496307373
Test Epoch3 threshold 0.4 Acc 0.9113157894736842, AUC 0.9784075021743774, avg_entr 0.02442309446632862
ep3_t0.4_test_time 0.19603323936462402
gc 0
Train Epoch4 Acc 0.25178333333333336 (30214/120000), AUC 0.41919994354248047
ep4_train_time 55.97816753387451
Test Epoch4 threshold 0.4 Acc 0.9113157894736842, AUC 0.9782557487487793, avg_entr 0.024815518409013748
ep4_t0.4_test_time 0.19170713424682617
gc 0
Train Epoch5 Acc 0.25228333333333336 (30274/120000), AUC 0.4201771318912506
ep5_train_time 55.96781849861145
Test Epoch5 threshold 0.4 Acc 0.9089473684210526, AUC 0.9780381321907043, avg_entr 0.024689072743058205
ep5_t0.4_test_time 0.18596696853637695
gc 0
Train Epoch6 Acc 0.25235833333333335 (30283/120000), AUC 0.42989182472229004
ep6_train_time 56.052873373031616
Test Epoch6 threshold 0.4 Acc 0.9107894736842105, AUC 0.977891206741333, avg_entr 0.02489965409040451
ep6_t0.4_test_time 0.18612933158874512
gc 0
Train Epoch7 Acc 0.25298333333333334 (30358/120000), AUC 0.4342009127140045
ep7_train_time 56.008413314819336
Test Epoch7 threshold 0.4 Acc 0.9107894736842105, AUC 0.9775567054748535, avg_entr 0.024207191541790962
ep7_t0.4_test_time 0.1869831085205078
gc 0
Train Epoch8 Acc 0.25378333333333336 (30454/120000), AUC 0.44165945053100586
ep8_train_time 56.03850245475769
Test Epoch8 threshold 0.4 Acc 0.9102631578947369, AUC 0.9776990413665771, avg_entr 0.02539636380970478
ep8_t0.4_test_time 0.1794755458831787
gc 0
Train Epoch9 Acc 0.25476666666666664 (30572/120000), AUC 0.450408011674881
ep9_train_time 56.048932790756226
Test Epoch9 threshold 0.4 Acc 0.9107894736842105, AUC 0.9776328802108765, avg_entr 0.02520669810473919
ep9_t0.4_test_time 0.18430638313293457
Best AUC 0.9786145687103271
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train/valid_time 562.6887228488922
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad175_t0.4_m2//ag_news_lstmal_l5_prefix.pt
Test threshold 0.4 Acc 0.925, AUC 0.9848158359527588, avg_entr 0.02481798268854618
t0.4_test_time 0.19228529930114746
