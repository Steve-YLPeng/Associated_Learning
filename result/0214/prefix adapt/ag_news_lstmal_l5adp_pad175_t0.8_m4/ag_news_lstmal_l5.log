total count words 102019
vocab size 30000
found 26754 words in glove
Load ckpt from ckpt/ag_news_lstmal_l5adp_pad175_t0.8_m3//ag_news_lstmal_l5_prefix.pt
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
init_time 20.66331672668457
Start Training
train_mask {0, 1, 2, 3}
gc 9
Train Epoch0 Acc 0.155175 (18621/120000), AUC 0.34658679366111755
ep0_train_time 77.37692832946777
Test Epoch0 threshold 0.8 Acc 0.911578947368421, AUC 0.9786356687545776, avg_entr 0.025913316756486893
ep0_t0.8_test_time 0.16063642501831055
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.8_m4//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.225425 (27051/120000), AUC 0.39616841077804565
ep1_train_time 77.48647880554199
Test Epoch1 threshold 0.8 Acc 0.9123684210526316, AUC 0.9786806702613831, avg_entr 0.02592281624674797
ep1_t0.8_test_time 0.15781664848327637
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.8_m4//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.22774166666666668 (27329/120000), AUC 0.4096393585205078
ep2_train_time 77.3450608253479
Test Epoch2 threshold 0.8 Acc 0.9097368421052632, AUC 0.9783003330230713, avg_entr 0.025806833058595657
ep2_t0.8_test_time 0.1615004539489746
gc 0
Train Epoch3 Acc 0.23110833333333333 (27733/120000), AUC 0.43211376667022705
ep3_train_time 77.30313348770142
Test Epoch3 threshold 0.8 Acc 0.9094736842105263, AUC 0.9782443642616272, avg_entr 0.02585146389901638
ep3_t0.8_test_time 0.15901422500610352
gc 0
Train Epoch4 Acc 0.23129166666666667 (27755/120000), AUC 0.45526576042175293
ep4_train_time 77.38081431388855
Test Epoch4 threshold 0.8 Acc 0.9068421052631579, AUC 0.9781157374382019, avg_entr 0.025679267942905426
ep4_t0.8_test_time 0.15797638893127441
gc 0
Train Epoch5 Acc 0.23050833333333334 (27661/120000), AUC 0.4797680377960205
ep5_train_time 77.371826171875
Test Epoch5 threshold 0.8 Acc 0.908157894736842, AUC 0.97795170545578, avg_entr 0.025875432416796684
ep5_t0.8_test_time 0.15833044052124023
gc 0
Train Epoch6 Acc 0.23009166666666667 (27611/120000), AUC 0.48755258321762085
ep6_train_time 77.35191249847412
Test Epoch6 threshold 0.8 Acc 0.9105263157894737, AUC 0.9779560565948486, avg_entr 0.025546204298734665
ep6_t0.8_test_time 0.15770435333251953
gc 0
Train Epoch7 Acc 0.23806666666666668 (28568/120000), AUC 0.49724191427230835
ep7_train_time 77.4879207611084
Test Epoch7 threshold 0.8 Acc 0.9097368421052632, AUC 0.9778260588645935, avg_entr 0.0263714250177145
ep7_t0.8_test_time 0.1614212989807129
gc 0
Train Epoch8 Acc 0.236625 (28395/120000), AUC 0.4997575879096985
ep8_train_time 77.33720397949219
Test Epoch8 threshold 0.8 Acc 0.9092105263157895, AUC 0.9776902794837952, avg_entr 0.02568250149488449
ep8_t0.8_test_time 0.15819001197814941
gc 0
Train Epoch9 Acc 0.23666666666666666 (28400/120000), AUC 0.5058185458183289
ep9_train_time 77.50065588951111
Test Epoch9 threshold 0.8 Acc 0.9078947368421053, AUC 0.977615237236023, avg_entr 0.02613351121544838
ep9_t0.8_test_time 0.15790605545043945
Best AUC 0.9786806702613831
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train/valid_time 776.3979530334473
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adp_pad175_t0.8_m4//ag_news_lstmal_l5_prefix.pt
Test threshold 0.8 Acc 0.9223684210526316, AUC 0.9848731756210327, avg_entr 0.02478764019906521
t0.8_test_time 0.15730881690979004
