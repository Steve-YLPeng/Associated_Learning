total count words 102019
vocab size 30000
found 26754 words in glove
Load ckpt from ckpt/ag_news_lstmal_l5adp_pad175_t0.8_m2//ag_news_lstmal_l5_prefix.pt
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
init_time 22.976385593414307
Start Training
train_mask {0, 1, 2}
gc 9
Train Epoch0 Acc 0.24828333333333333 (29794/120000), AUC 0.36618882417678833
ep0_train_time 69.24472761154175
Test Epoch0 threshold 0.8 Acc 0.9094736842105263, AUC 0.9787759184837341, avg_entr 0.0264553464949131
ep0_t0.8_test_time 0.20924854278564453
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.8_m3//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.24895 (29874/120000), AUC 0.3766559064388275
ep1_train_time 70.91089200973511
Test Epoch1 threshold 0.8 Acc 0.9128947368421053, AUC 0.9787861704826355, avg_entr 0.025708718225359917
ep1_t0.8_test_time 0.20679473876953125
Save ckpt to ckpt/ag_news_lstmal_l5adp_pad175_t0.8_m3//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.24941666666666668 (29930/120000), AUC 0.4044078290462494
ep2_train_time 68.79830384254456
Test Epoch2 threshold 0.8 Acc 0.9113157894736842, AUC 0.9785709381103516, avg_entr 0.026153789833188057
ep2_t0.8_test_time 0.15694975852966309
gc 0
Train Epoch3 Acc 0.24966666666666668 (29960/120000), AUC 0.4182778000831604
ep3_train_time 66.63515973091125
Test Epoch3 threshold 0.8 Acc 0.9131578947368421, AUC 0.9785487651824951, avg_entr 0.025281324982643127
ep3_t0.8_test_time 0.15848112106323242
gc 0
Train Epoch4 Acc 0.24988333333333335 (29986/120000), AUC 0.43173617124557495
ep4_train_time 66.76984691619873
Test Epoch4 threshold 0.8 Acc 0.911578947368421, AUC 0.9783656001091003, avg_entr 0.02615356631577015
ep4_t0.8_test_time 0.16168975830078125
gc 0
Train Epoch5 Acc 0.25016666666666665 (30020/120000), AUC 0.44116517901420593
ep5_train_time 66.69317817687988
Test Epoch5 threshold 0.8 Acc 0.9118421052631579, AUC 0.9782532453536987, avg_entr 0.02585022710263729
ep5_t0.8_test_time 0.1597142219543457
gc 0
Train Epoch6 Acc 0.2502916666666667 (30035/120000), AUC 0.4438875913619995
ep6_train_time 66.67941904067993
Test Epoch6 threshold 0.8 Acc 0.9105263157894737, AUC 0.9780968427658081, avg_entr 0.026042556390166283
ep6_t0.8_test_time 0.15755867958068848
gc 0
Train Epoch7 Acc 0.250325 (30039/120000), AUC 0.44768837094306946
ep7_train_time 66.71530532836914
Test Epoch7 threshold 0.8 Acc 0.9105263157894737, AUC 0.9780793190002441, avg_entr 0.026769155636429787
ep7_t0.8_test_time 0.15752840042114258
gc 0
Train Epoch8 Acc 0.25038333333333335 (30046/120000), AUC 0.4469679296016693
ep8_train_time 66.7815272808075
Test Epoch8 threshold 0.8 Acc 0.9086842105263158, AUC 0.9778913259506226, avg_entr 0.026982802897691727
ep8_t0.8_test_time 0.15734338760375977
gc 0
Train Epoch9 Acc 0.2506333333333333 (30076/120000), AUC 0.4481395184993744
ep9_train_time 66.75899004936218
Test Epoch9 threshold 0.8 Acc 0.908157894736842, AUC 0.9778628349304199, avg_entr 0.026356862857937813
ep9_t0.8_test_time 0.1599564552307129
Best AUC 0.9787861704826355
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train/valid_time 678.6128280162811
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adp_pad175_t0.8_m3//ag_news_lstmal_l5_prefix.pt
Test threshold 0.8 Acc 0.925, AUC 0.9849266409873962, avg_entr 0.02391362190246582
t0.8_test_time 0.15720391273498535
