total count words 102019
vocab size 30000
found 26754 words in glove
Load ckpt from ckpt/ag_news_lstmal_l5adf_pad175_t0.6_m3//ag_news_lstmal_l5_prefix.pt
model: LSTMModelML(
  (layers): ModuleList(
    (0): EMBLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): Embedding(30000, 300)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=4, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=4, bias=True)
          (1): Sigmoid()
        )
        (cri): CrossEntropyLoss()
      )
    )
    (1): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(300, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (2): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (3): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
    (4): LSTMLayer(
      (enc): ENC(
        (b): Sequential(
          (0): Linear(in_features=300, out_features=128, bias=True)
          (1): Tanh()
        )
        (f): LSTM(600, 300, batch_first=True, bidirectional=True)
        (cri): MSELoss()
      )
      (ae): AE(
        (g): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): Tanh()
        )
        (h): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
        )
        (cri): MSELoss()
      )
    )
  )
)
layers.0.enc.b.0.weight 38400
layers.0.enc.b.0.bias 128
layers.0.enc.f.weight 9000000
layers.0.ae.g.0.weight 512
layers.0.ae.g.0.bias 128
layers.0.ae.h.0.weight 512
layers.0.ae.h.0.bias 4
layers.1.enc.b.0.weight 38400
layers.1.enc.b.0.bias 128
layers.1.enc.f.weight_ih_l0 360000
layers.1.enc.f.weight_hh_l0 360000
layers.1.enc.f.bias_ih_l0 1200
layers.1.enc.f.bias_hh_l0 1200
layers.1.enc.f.weight_ih_l0_reverse 360000
layers.1.enc.f.weight_hh_l0_reverse 360000
layers.1.enc.f.bias_ih_l0_reverse 1200
layers.1.enc.f.bias_hh_l0_reverse 1200
layers.1.ae.g.0.weight 16384
layers.1.ae.g.0.bias 128
layers.1.ae.h.0.weight 16384
layers.1.ae.h.0.bias 128
layers.2.enc.b.0.weight 38400
layers.2.enc.b.0.bias 128
layers.2.enc.f.weight_ih_l0 720000
layers.2.enc.f.weight_hh_l0 360000
layers.2.enc.f.bias_ih_l0 1200
layers.2.enc.f.bias_hh_l0 1200
layers.2.enc.f.weight_ih_l0_reverse 720000
layers.2.enc.f.weight_hh_l0_reverse 360000
layers.2.enc.f.bias_ih_l0_reverse 1200
layers.2.enc.f.bias_hh_l0_reverse 1200
layers.2.ae.g.0.weight 16384
layers.2.ae.g.0.bias 128
layers.2.ae.h.0.weight 16384
layers.2.ae.h.0.bias 128
layers.3.enc.b.0.weight 38400
layers.3.enc.b.0.bias 128
layers.3.enc.f.weight_ih_l0 720000
layers.3.enc.f.weight_hh_l0 360000
layers.3.enc.f.bias_ih_l0 1200
layers.3.enc.f.bias_hh_l0 1200
layers.3.enc.f.weight_ih_l0_reverse 720000
layers.3.enc.f.weight_hh_l0_reverse 360000
layers.3.enc.f.bias_ih_l0_reverse 1200
layers.3.enc.f.bias_hh_l0_reverse 1200
layers.3.ae.g.0.weight 16384
layers.3.ae.g.0.bias 128
layers.3.ae.h.0.weight 16384
layers.3.ae.h.0.bias 128
layers.4.enc.b.0.weight 38400
layers.4.enc.b.0.bias 128
layers.4.enc.f.weight_ih_l0 720000
layers.4.enc.f.weight_hh_l0 360000
layers.4.enc.f.bias_ih_l0 1200
layers.4.enc.f.bias_hh_l0 1200
layers.4.enc.f.weight_ih_l0_reverse 720000
layers.4.enc.f.weight_hh_l0_reverse 360000
layers.4.enc.f.bias_ih_l0_reverse 1200
layers.4.enc.f.bias_hh_l0_reverse 1200
layers.4.ae.g.0.weight 16384
layers.4.ae.g.0.bias 128
layers.4.ae.h.0.weight 16384
layers.4.ae.h.0.bias 128
Total Trainable Params: 17265092
init_time 20.167470932006836
Start Training
train_mask {0, 1, 2, 3}
gc 9
Train Epoch0 Acc 0.1868 (22416/120000), AUC 0.5765175223350525
ep0_train_time 77.33566617965698
Test Epoch0 threshold 0.6 Acc 0.9126315789473685, AUC 0.9787302017211914, avg_entr 0.025555303320288658
ep0_t0.6_test_time 0.16283392906188965
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.6_m4//ag_news_lstmal_l5_prefix.pt  ,ep 0
gc 0
Train Epoch1 Acc 0.04873333333333333 (5848/120000), AUC 0.5966033935546875
ep1_train_time 77.45386171340942
Test Epoch1 threshold 0.6 Acc 0.911578947368421, AUC 0.9787617921829224, avg_entr 0.025552423670887947
ep1_t0.6_test_time 0.1588602066040039
Save ckpt to ckpt/ag_news_lstmal_l5adf_pad175_t0.6_m4//ag_news_lstmal_l5_prefix.pt  ,ep 1
gc 0
Train Epoch2 Acc 0.030241666666666667 (3629/120000), AUC 0.6243186593055725
ep2_train_time 77.48046922683716
Test Epoch2 threshold 0.6 Acc 0.9123684210526316, AUC 0.9785664081573486, avg_entr 0.02636304311454296
ep2_t0.6_test_time 0.15718793869018555
gc 0
Train Epoch3 Acc 0.074225 (8907/120000), AUC 0.625587522983551
ep3_train_time 77.36040329933167
Test Epoch3 threshold 0.6 Acc 0.9107894736842105, AUC 0.9784804582595825, avg_entr 0.02702243998646736
ep3_t0.6_test_time 0.15787291526794434
gc 0
Train Epoch4 Acc 0.18889166666666668 (22667/120000), AUC 0.6310216784477234
ep4_train_time 77.40546011924744
Test Epoch4 threshold 0.6 Acc 0.9105263157894737, AUC 0.978061318397522, avg_entr 0.025720393285155296
ep4_t0.6_test_time 0.1570889949798584
gc 0
Train Epoch5 Acc 0.21998333333333334 (26398/120000), AUC 0.6332752704620361
ep5_train_time 77.33798885345459
Test Epoch5 threshold 0.6 Acc 0.9105263157894737, AUC 0.9780723452568054, avg_entr 0.02577129565179348
ep5_t0.6_test_time 0.15765857696533203
gc 0
Train Epoch6 Acc 0.22941666666666666 (27530/120000), AUC 0.6212288737297058
ep6_train_time 77.40490674972534
Test Epoch6 threshold 0.6 Acc 0.91, AUC 0.9780111312866211, avg_entr 0.026375921443104744
ep6_t0.6_test_time 0.15851783752441406
gc 0
Train Epoch7 Acc 0.24608333333333332 (29530/120000), AUC 0.6162243485450745
ep7_train_time 77.49018716812134
Test Epoch7 threshold 0.6 Acc 0.9107894736842105, AUC 0.9779908657073975, avg_entr 0.026355521753430367
ep7_t0.6_test_time 0.15787386894226074
gc 0
Train Epoch8 Acc 0.25330833333333336 (30397/120000), AUC 0.6102122068405151
ep8_train_time 77.62414741516113
Test Epoch8 threshold 0.6 Acc 0.9097368421052632, AUC 0.9779112935066223, avg_entr 0.02642393484711647
ep8_t0.6_test_time 0.1601107120513916
gc 0
Train Epoch9 Acc 0.26255833333333334 (31507/120000), AUC 0.6116012930870056
ep9_train_time 77.8454236984253
Test Epoch9 threshold 0.6 Acc 0.9110526315789473, AUC 0.9778413772583008, avg_entr 0.026353349909186363
ep9_t0.6_test_time 0.16077232360839844
Best AUC 0.9787617921829224
train_loss (2, 5, 10)
valid_acc (10, 1)
valid_AUC (10, 1)
train_acc (10,)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
Figure(640x480)
total_train/valid_time 777.1904971599579
Start Testing
Load ckpt at ckpt/ag_news_lstmal_l5adf_pad175_t0.6_m4//ag_news_lstmal_l5_prefix.pt
Test threshold 0.6 Acc 0.9247368421052632, AUC 0.9848755598068237, avg_entr 0.024064261466264725
t0.6_test_time 0.16071724891662598
