{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bbac891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "  0%|                                                   | 0/258 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 0.6403655409812927: 100%|█| 258/258 [00:01<00:00, 190.26it/s]\n",
      "Train Epoch0 out_loss 0.4100678861141205, R2 0.589984655380249\n",
      "Test Epoch0 layer0 out_loss 0.3176153004169464, R2 0.682165265083313\n",
      "Test Epoch0 layer1 out_loss 0.2983078360557556, R2 0.7014861106872559\n",
      "Test Epoch0 layer2 out_loss 0.2951917052268982, R2 0.7046043872833252\n",
      "Test Epoch0 layer3 out_loss 0.29966121912002563, R2 0.7001317739486694\n",
      "Test Epoch0 layer4 out_loss 0.29881009459495544, R2 0.7009835243225098\n",
      "Best r2 0.7046043872833252 at L2\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Start Testing\n"
     ]
    }
   ],
   "source": [
    "# LinearAL \n",
    "\n",
    "data = \"ca_housing\"\n",
    "#data = \"paint\"\n",
    "model =  \"linearal\"\n",
    "#for layer in range(1,11):\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{data}/\n",
    "    !python3 dis_train_al.py --dataset {data} --model {model} --epoch 100 --num-layer {layer} --lr 0.001 --task regression # > {log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f7a8d985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/12500 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.74409125 (595273/800000): 100%|█| 12500/12500 [01:46<00:00, 116.\n",
      "Train 1 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:51<00:00, 111.\n",
      "Train 2 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:58<00:00, 105.\n",
      "Train 3 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:56<00:00, 106.\n",
      "Train 4 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:44<00:00, 119.\n",
      "Train 5 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:41<00:00, 122.\n",
      "Train 6 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:45<00:00, 118.\n",
      "Train 7 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:57<00:00, 106.\n",
      "Train 8 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:45<00:00, 118.\n",
      "Train 9 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:51<00:00, 111.\n"
     ]
    }
   ],
   "source": [
    "# LinearAL \n",
    "data = \"criteo\"\n",
    "\n",
    "model =  \"linearal\"\n",
    "#for layer in range(1,11):\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{data}/\n",
    "    !python3 dis_train_al.py --dataset {data} --model {model} --epoch 10 --num-layer {layer} --task classification --lr 0.0001 --l1-dim 300 --label-emb 128 > {log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abecc5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ae70865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:408: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.8999645632419572 (355549/395070): 100%|█| 3087/3087 [00:17<00:00\n",
      "Train 1 | Acc 0.9900346773989419 (391133/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 2 | Acc 0.9956716531247627 (393360/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 3 | Acc 0.9961323309793201 (393542/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 4 | Acc 0.9966967879110031 (393765/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 5 | Acc 0.997053686688435 (393906/395070): 100%|█| 3087/3087 [00:16<00:00,\n",
      "Train 6 | Acc 0.9972612448426861 (393988/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 7 | Acc 0.9974612094059281 (394067/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 8 | Acc 0.9976307996051332 (394134/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 9 | Acc 0.997739641076265 (394177/395070): 100%|█| 3087/3087 [00:16<00:00,\n",
      "Train 10 | Acc 0.997820639380363 (394209/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 11 | Acc 0.9979269496544916 (394251/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 12 | Acc 0.9979623864125345 (394265/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 13 | Acc 0.9980079479585896 (394283/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 14 | Acc 0.9980661654896601 (394306/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 15 | Acc 0.9980661654896601 (394306/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 16 | Acc 0.9980737590806692 (394309/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 17 | Acc 0.998106664641709 (394322/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 18 | Acc 0.9981522261877642 (394340/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 19 | Acc 0.9981750069607918 (394349/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 20 | Acc 0.9981522261877642 (394340/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 21 | Acc 0.9981623509757764 (394344/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 22 | Acc 0.9982205685068469 (394367/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 23 | Acc 0.9982205685068469 (394367/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 24 | Acc 0.998228162097856 (394370/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 25 | Acc 0.998228162097856 (394370/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 26 | Acc 0.9982534740678867 (394380/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 27 | Acc 0.9982306932948591 (394371/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 28 | Acc 0.9982560052648898 (394381/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 29 | Acc 0.9982509428708837 (394379/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 30 | Acc 0.9982585364618928 (394382/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 31 | Acc 0.9982889108259296 (394394/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 32 | Acc 0.9982863796289265 (394393/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 33 | Acc 0.9983015668109448 (394399/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 34 | Acc 0.9983015668109448 (394399/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 35 | Acc 0.9982990356139418 (394398/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 36 | Acc 0.9983268787809755 (394409/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 37 | Acc 0.9983243475839725 (394408/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 38 | Acc 0.9983243475839725 (394408/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 39 | Acc 0.9983268787809755 (394409/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 40 | Acc 0.9983370035689878 (394413/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 41 | Acc 0.9983420659629939 (394415/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 42 | Acc 0.9983395347659908 (394414/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 43 | Acc 0.998344597159997 (394416/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 44 | Acc 0.9983370035689878 (394413/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 45 | Acc 0.9983623155390184 (394423/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 46 | Acc 0.998347128357 (394417/395070): 100%|█| 3087/3087 [00:16<00:00, 1\n",
      "Train 47 | Acc 0.9983623155390184 (394423/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 48 | Acc 0.9983699091300275 (394426/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 49 | Acc 0.9983572531450122 (394421/395070): 100%|█| 3087/3087 [00:16<00:0\n"
     ]
    }
   ],
   "source": [
    "# LinearAL \n",
    "data = \"kdd99\"\n",
    "\n",
    "model =  \"linearal\"\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{data}/\n",
    "    !python3 dis_train_al.py --dataset {data} --model {model} --epoch 50 --num-layer {layer} --batch-size 128 --lr 0.0001 --l1-dim 128 --label-emb 128 --task classification > {log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7675b11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:408: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.855023160452578 (337794/395070): 100%|█| 3087/3087 [00:25<00:00,\n",
      "Train 1 | Acc 0.9883210570278684 (390456/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 2 | Acc 0.9946338623535069 (392950/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 3 | Acc 0.9955248436985851 (393302/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 4 | Acc 0.9958083377629281 (393414/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 5 | Acc 0.9960184271141823 (393497/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 6 | Acc 0.9961728301313691 (393558/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 7 | Acc 0.9964057002556509 (393650/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 8 | Acc 0.9966866631229908 (393761/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 9 | Acc 0.9969701571873338 (393873/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 10 | Acc 0.997134684992533 (393938/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 11 | Acc 0.9972511200546739 (393984/395070): 100%|█| 3087/3087 [00:25<00:0\n",
      "Train 12 | Acc 0.9974156478598729 (394049/395070): 100%|█| 3087/3087 [00:25<00:0\n",
      "Train 13 | Acc 0.9975371453160199 (394097/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 14 | Acc 0.9976409243931456 (394138/395070): 100%|█| 3087/3087 [00:23<00:0\n",
      "Train 15 | Acc 0.9977067355152252 (394164/395070): 100%|█| 3087/3087 [00:23<00:0\n",
      "Train 16 | Acc 0.9978257017743691 (394211/395070): 100%|█| 3087/3087 [00:25<00:0\n",
      "Train 17 | Acc 0.9978839193054395 (394234/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 18 | Acc 0.9979117624724733 (394245/395070): 100%|█| 3087/3087 [00:25<00:0\n",
      "Train 19 | Acc 0.997980104791556 (394272/395070): 100%|█| 3087/3087 [00:23<00:00\n",
      "Train 20 | Acc 0.9980028855645835 (394281/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 21 | Acc 0.9980535095046448 (394301/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 22 | Acc 0.998063634292657 (394305/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 23 | Acc 0.9981167894297213 (394326/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 24 | Acc 0.9981117270357152 (394324/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 25 | Acc 0.9981167894297213 (394326/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 26 | Acc 0.9982053813248285 (394361/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 27 | Acc 0.9982079125218316 (394362/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 28 | Acc 0.9982230997038499 (394368/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 29 | Acc 0.998263598855899 (394384/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 30 | Acc 0.998263598855899 (394384/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 31 | Acc 0.9982863796289265 (394393/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 32 | Acc 0.9982737236439112 (394388/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 33 | Acc 0.9982838484319234 (394392/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 34 | Acc 0.9982939732199357 (394396/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 35 | Acc 0.9982838484319234 (394392/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 36 | Acc 0.9982939732199357 (394396/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 37 | Acc 0.9983015668109448 (394399/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 38 | Acc 0.9982914420229326 (394395/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 39 | Acc 0.9982863796289265 (394393/395070): 100%|█| 3087/3087 [00:23<00:0\n",
      "Train 40 | Acc 0.9983192851899664 (394406/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 41 | Acc 0.9983015668109448 (394399/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 42 | Acc 0.9983066292049511 (394401/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 43 | Acc 0.9983192851899664 (394406/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 44 | Acc 0.9983319411749817 (394411/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 45 | Acc 0.9983294099779786 (394410/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 46 | Acc 0.9983395347659908 (394414/395070): 100%|█| 3087/3087 [00:25<00:0\n",
      "Train 47 | Acc 0.9982863796289265 (394393/395070): 100%|█| 3087/3087 [00:25<00:0\n",
      "Train 48 | Acc 0.9983319411749817 (394411/395070): 100%|█| 3087/3087 [00:26<00:0\n",
      "Train 49 | Acc 0.9983496595540031 (394418/395070): 100%|█| 3087/3087 [00:25<00:0\n"
     ]
    }
   ],
   "source": [
    "# LinearAL side \n",
    "data = \"kdd99\"\n",
    "\n",
    "model =  \"linearalside\"\n",
    "#for layer in range(1,11):\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{data}/\n",
    "    !python3 dis_train_al.py --dataset {data} --model {model} --epoch 50 --num-layer {layer} --batch-size 128 --lr 0.0001 --l1-dim 128 --label-emb 128 --task classification > {log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56678f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformer.encoder import TransformerEncoder\n",
    "from torch.nn import ModuleList\n",
    "from typing import List\n",
    "class AE(nn.Module):\n",
    "\n",
    "    def __init__(self, inp_dim, out_dim, cri='ce', act=None):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        if act == None:\n",
    "            self.g = nn.Sequential(\n",
    "                    nn.Linear(inp_dim, out_dim),\n",
    "                    nn.Tanh()            \n",
    "                )\n",
    "            if cri == 'ce':\n",
    "                self.h = nn.Sequential(\n",
    "                    nn.Linear(out_dim, inp_dim),\n",
    "                    nn.Tanh()            \n",
    "                )\n",
    "                self.cri = nn.CrossEntropyLoss()\n",
    "                \n",
    "            elif cri == 'mse':\n",
    "                self.h = nn.Sequential(\n",
    "                    nn.Linear(out_dim, inp_dim),\n",
    "                )\n",
    "                self.cri = nn.MSELoss()\n",
    "            \n",
    "        else:\n",
    "            if act[0] != None:\n",
    "                self.g = nn.Sequential(\n",
    "                    nn.Linear(inp_dim, out_dim),       \n",
    "                    act[0]    \n",
    "                )\n",
    "            else:\n",
    "                self.g = nn.Sequential(\n",
    "                    nn.Linear(inp_dim, out_dim),         \n",
    "                )\n",
    "            if act[1] != None:\n",
    "                self.h = nn.Sequential(\n",
    "                    nn.Linear(out_dim, inp_dim),\n",
    "                    act[1] \n",
    "                )\n",
    "            else:\n",
    "                self.h = nn.Sequential(\n",
    "                    nn.Linear(out_dim, inp_dim), \n",
    "                )\n",
    "            if cri == 'mse' :\n",
    "                self.cri = nn.MSELoss()\n",
    "            else :\n",
    "                self.cri = nn.CrossEntropyLoss()\n",
    "            \n",
    "        self.mode = cri\n",
    "    \n",
    "    def forward(self, x):\n",
    "        enc_x = self.g(x)\n",
    "        rec_x = self.h(enc_x)\n",
    "        if self.mode == 'ce':\n",
    "            #print(\"ae\",rec_x)\n",
    "            #print(\"lab\",x)\n",
    "            return enc_x, self.cri(rec_x, x.argmax(1))\n",
    "        elif self.mode == 'mse':\n",
    "            return enc_x, self.cri(rec_x, x)\n",
    "\n",
    "class ENC(nn.Module):\n",
    "\n",
    "    def __init__(self, inp_dim, out_dim, lab_dim=128, f='emb', n_heads=4, word_vec=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.b = nn.Sequential(\n",
    "            nn.Linear(out_dim, lab_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.mode = f\n",
    "        if f == 'emb':\n",
    "            self.f = nn.Embedding(inp_dim, out_dim)\n",
    "            if word_vec is not None:\n",
    "                self.f = nn.Embedding.from_pretrained(word_vec, freeze=False)\n",
    "        elif f == 'lstm':\n",
    "            self.f = nn.LSTM(inp_dim, out_dim, bidirectional=True, batch_first=True)\n",
    "        elif f == 'trans':\n",
    "            self.f = TransformerEncoder(d_model=inp_dim, d_ff=out_dim, n_heads=n_heads)\n",
    "            self.b = nn.Sequential(\n",
    "                nn.Linear(inp_dim, lab_dim),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        elif f == 'linear':\n",
    "            self.f = nn.Sequential(\n",
    "                nn.Linear(inp_dim, out_dim),\n",
    "                #nn.BatchNorm1d(out_dim),\n",
    "                nn.ELU(),\n",
    "                #nn.Tanh(),\n",
    "                #nn.Sigmoid(),\n",
    "                \n",
    "            )\n",
    "            self.b = nn.Sequential(\n",
    "                nn.Linear(out_dim, lab_dim),\n",
    "                #nn.BatchNorm1d(out_dim),\n",
    "                #nn.ELU(),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "\n",
    "        self.cri = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, x, tgt, mask=None, h=None):\n",
    "\n",
    "        if self.mode == 'emb' :\n",
    "            enc_x = self.f(x.long())\n",
    "        elif self.mode == 'linear' :\n",
    "            enc_x = self.f(x)\n",
    "        elif self.mode == 'lstm':\n",
    "            enc_x, (h, c) = self.f(x, h)\n",
    "        elif self.mode == 'trans':\n",
    "            enc_x = self.f(x, mask=mask)\n",
    "        \n",
    "        red_x = self.reduction(enc_x, mask, h)\n",
    "        red_x = self.b(red_x)\n",
    "        loss = self.cri(red_x, tgt)\n",
    "        \n",
    "        return enc_x, loss, h, mask\n",
    "\n",
    "    def reduction(self, x, mask=None, h=None):\n",
    "\n",
    "        # to match bridge function\n",
    "        if self.mode == 'emb':\n",
    "            return x.mean(1)\n",
    "\n",
    "        elif self.mode == 'lstm':\n",
    "            _h = h[0] + h[1]\n",
    "            return _h\n",
    "\n",
    "        elif self.mode == 'trans':\n",
    "\n",
    "            denom = torch.sum(mask, -1, keepdim=True)\n",
    "            feat = torch.sum(x * mask.unsqueeze(-1), dim=1) / denom\n",
    "            return feat\n",
    "        \n",
    "        elif self.mode == 'linear':\n",
    "            return x\n",
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, inp_dim, lab_dim, hid_dim, lr, out_dim=None, ae_cri='mse', ae_act=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc = ENC(inp_dim, hid_dim, lab_dim=lab_dim, f='linear')\n",
    "        if out_dim == None:\n",
    "            self.ae = AE(lab_dim, lab_dim, cri=ae_cri, act=ae_act)\n",
    "        else:\n",
    "            self.ae = AE(out_dim, lab_dim, cri=ae_cri, act=ae_act)\n",
    "    \n",
    "        self.ae_opt = torch.optim.Adam(self.ae.parameters(), lr=lr)\n",
    "        self.enc_opt = torch.optim.Adam(self.enc.parameters(), lr=lr)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "\n",
    "        self.ae_opt.zero_grad()\n",
    "        enc_y , ae_loss = self.ae(y)\n",
    "        ae_loss.backward()\n",
    "        #nn.utils.clip_grad_norm_(self.ae.parameters(), 5)\n",
    "        self.ae_opt.step()\n",
    "    \n",
    "        self.enc_opt.zero_grad()\n",
    "        tgt = enc_y.clone().detach()\n",
    "        enc_x, enc_loss, _, _ = self.enc(x, tgt)\n",
    "        enc_loss.backward()\n",
    "        #nn.utils.clip_grad_norm_(self.enc.parameters(), 5)\n",
    "        self.enc_opt.step()\n",
    "        #(h, c) = hidden\n",
    "        #h = h.reshape(2, x.size(0), -1)\n",
    "        #hidden = (h.detach(), c.detach())\n",
    "\n",
    "        return enc_x.detach(), enc_y.detach(), ae_loss, enc_loss \n",
    "class alModel(nn.Module):\n",
    "    def __init__(self, num_layer, l1_dim, class_num, lab_dim, emb_dim=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layer = num_layer\n",
    "        self.history = {\"train_acc\":[],\"valid_acc\":[],\"train_loss\":[],\n",
    "                        \"train_AUC\":[],\"valid_AUC\":[],\n",
    "                        \"train_r2\":[],\"valid_r2\":[],\n",
    "                        \"train_out\":[],\"valid_out\":[],\n",
    "                        } \n",
    "        self.emb_dim = emb_dim\n",
    "        self.l1_dim = l1_dim\n",
    "        self.lab_dim = lab_dim\n",
    "        self.losses = [0.0] * (num_layer*2)\n",
    "        self.class_num = class_num\n",
    "class LinearALRegress(alModel): \n",
    "    \n",
    "    def __init__(self, num_layer, feature_dim, class_num, l1_dim, lr, lab_dim=128):\n",
    "        super().__init__(num_layer, l1_dim, class_num, lab_dim)\n",
    "              \n",
    "        layers = ModuleList([])\n",
    "        for idx in range(self.num_layer):\n",
    "            if idx == 0:\n",
    "                act = [nn.Tanh(),None]\n",
    "                #act = [None,None]\n",
    "                layer = LinearLayer(inp_dim=feature_dim, out_dim=class_num, \n",
    "                                    hid_dim=l1_dim, lab_dim=lab_dim, lr=lr, ae_act=act)\n",
    "            else:\n",
    "                layer = LinearLayer(l1_dim, lab_dim, l1_dim, lr=lr)\n",
    "            layers.append(layer)\n",
    "        \n",
    "        self.layers = layers     \n",
    "model = LinearALRegress(3,20,11,128,0.001,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3689e30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.layers[1].train()\n",
    "print(model.training)\n",
    "print(model.layers[0].training)\n",
    "print(model.layers[0].enc.training)\n",
    "print(model.layers[0].ae.training)\n",
    "print(model.layers[1].training)\n",
    "print(model.layers[1].enc.training)\n",
    "print(model.layers[1].ae.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e40cd61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearALRegress(\n",
       "  (layers): ModuleList(\n",
       "    (0): LinearLayer(\n",
       "      (enc): ENC(\n",
       "        (b): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (f): Sequential(\n",
       "          (0): Linear(in_features=20, out_features=128, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (cri): MSELoss()\n",
       "      )\n",
       "      (ae): AE(\n",
       "        (g): Sequential(\n",
       "          (0): Linear(in_features=11, out_features=128, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (h): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=11, bias=True)\n",
       "        )\n",
       "        (cri): MSELoss()\n",
       "      )\n",
       "    )\n",
       "    (1): LinearLayer(\n",
       "      (enc): ENC(\n",
       "        (b): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (f): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (cri): MSELoss()\n",
       "      )\n",
       "      (ae): AE(\n",
       "        (g): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (h): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (cri): MSELoss()\n",
       "      )\n",
       "    )\n",
       "    (2): LinearLayer(\n",
       "      (enc): ENC(\n",
       "        (b): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (f): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (cri): MSELoss()\n",
       "      )\n",
       "      (ae): AE(\n",
       "        (g): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (h): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (cri): MSELoss()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "model.modules\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5444bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/train_l4//’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/train_l4//kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:408: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.8866529982028502 (350290/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 1 | Acc 0.9892525375249955 (390824/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 2 | Acc 0.9953020983623155 (393214/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 3 | Acc 0.9962538284354672 (393590/395070): 100%|█| 3087/3087 [00:17<00:00\n",
      "Train 4 | Acc 0.9972840256157137 (393997/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 5 | Acc 0.9976383931961424 (394137/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 6 | Acc 0.9978257017743691 (394211/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 7 | Acc 0.9979725112005468 (394269/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 8 | Acc 0.9980914774596907 (394316/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 9 | Acc 0.998144632596755 (394337/395070): 100%|█| 3087/3087 [00:18<00:00,\n",
      "Train 10 | Acc 0.998228162097856 (394370/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 11 | Acc 0.998228162097856 (394370/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 12 | Acc 0.9982737236439112 (394388/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 13 | Acc 0.9982838484319234 (394392/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 14 | Acc 0.9983395347659908 (394414/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 15 | Acc 0.9983496595540031 (394418/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 16 | Acc 0.9983749715240338 (394428/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 17 | Acc 0.9983901587060521 (394434/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 18 | Acc 0.9983800339180399 (394430/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 19 | Acc 0.9984104082820766 (394442/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 20 | Acc 0.9984255954640949 (394448/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 21 | Acc 0.9984458450401195 (394456/395070): 100%|█| 3087/3087 [00:17<00:0\n",
      "Train 22 | Acc 0.9984559698281317 (394460/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 23 | Acc 0.9984762194041562 (394468/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 24 | Acc 0.9984812817981623 (394470/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 25 | Acc 0.9984812817981623 (394470/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 26 | Acc 0.9984711570101501 (394466/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 27 | Acc 0.9984838129951654 (394471/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 28 | Acc 0.9984838129951654 (394471/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 29 | Acc 0.9984838129951654 (394471/395070): 100%|█| 3087/3087 [00:18<00:0\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# layer mask training \n",
    "######################\n",
    "\n",
    "data = \"kdd99\"\n",
    "save = \"train_l4/\"\n",
    "load = \"train_l3/\"\n",
    "model =  \"linearal\"\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{save}/\n",
    "    !mkdir ckpt/{save}/{data}/\n",
    "    !python3 dis_train_side.py --dataset {data} --model {model} --epoch 30 \\\n",
    "    --num-layer {layer} --batch-size 128 --lr 0.0001 --l1-dim 128 --label-emb 128 \\\n",
    "    --task classification > {log}\n",
    "    #--save-dir ./ckpt/{save} \\\n",
    "    #--load-dir ./ckpt/{load} \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ccf3594c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/side_mask4//’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/side_mask4//kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:408: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.8885893639101932 (351055/395070): 100%|█| 3087/3087 [00:17<00:00\n",
      "Train 1 | Acc 0.9881767787986939 (390399/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 2 | Acc 0.995362847090389 (393238/395070): 100%|█| 3087/3087 [00:16<00:00,\n",
      "Train 3 | Acc 0.9960918318272711 (393526/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 4 | Acc 0.9967524742450705 (393787/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 5 | Acc 0.9970460930974258 (393903/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 6 | Acc 0.9972283392816463 (393975/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 7 | Acc 0.9973295871617688 (394015/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 8 | Acc 0.9974156478598729 (394049/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 9 | Acc 0.9975523324980383 (394103/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 10 | Acc 0.9976282684081302 (394133/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 11 | Acc 0.997658642772167 (394145/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 12 | Acc 0.9977624218492925 (394186/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 13 | Acc 0.9977953274103324 (394199/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 14 | Acc 0.9978029210013415 (394202/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 15 | Acc 0.997820639380363 (394209/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 16 | Acc 0.997823170577366 (394210/395070): 100%|█| 3087/3087 [00:16<00:00\n",
      "Train 17 | Acc 0.9978459513503936 (394219/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 18 | Acc 0.9978586073354089 (394224/395070): 100%|█| 3087/3087 [00:17<00:0\n",
      "Train 19 | Acc 0.9978662009264181 (394227/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 20 | Acc 0.9978813881084365 (394233/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 21 | Acc 0.9978839193054395 (394234/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 22 | Acc 0.9979016376844609 (394241/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 23 | Acc 0.9979117624724733 (394245/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 24 | Acc 0.9979117624724733 (394245/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 25 | Acc 0.9979218872604855 (394249/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 26 | Acc 0.9979168248664794 (394247/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 27 | Acc 0.9979244184574886 (394250/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 28 | Acc 0.9979294808514947 (394252/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 29 | Acc 0.9979269496544916 (394251/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 30 | Acc 0.9979370744425039 (394255/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 31 | Acc 0.9979396056395069 (394256/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 32 | Acc 0.9979269496544916 (394251/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 33 | Acc 0.9979396056395069 (394256/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 34 | Acc 0.9979370744425039 (394255/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 35 | Acc 0.9979294808514947 (394252/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 36 | Acc 0.9979345432455008 (394254/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 37 | Acc 0.9979396056395069 (394256/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 38 | Acc 0.9979320120484977 (394253/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 39 | Acc 0.9979345432455008 (394254/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 40 | Acc 0.9979370744425039 (394255/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 41 | Acc 0.9979345432455008 (394254/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 42 | Acc 0.9979370744425039 (394255/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 43 | Acc 0.9979396056395069 (394256/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 44 | Acc 0.9979370744425039 (394255/395070): 100%|█| 3087/3087 [00:17<00:0\n",
      "Train 45 | Acc 0.9979370744425039 (394255/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 46 | Acc 0.9979370744425039 (394255/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 47 | Acc 0.9979396056395069 (394256/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 48 | Acc 0.9979370744425039 (394255/395070): 100%|█| 3087/3087 [00:16<00:0\n",
      "Train 49 | Acc 0.9979370744425039 (394255/395070): 100%|█| 3087/3087 [00:16<00:0\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# layer mask training \n",
    "######################\n",
    "\n",
    "data = \"kdd99\"\n",
    "model =  \"linearal\"\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{save}/\n",
    "    !mkdir ckpt/{save}/{data}/\n",
    "    !python3 dis_train_side.py --dataset {data} --model {model} --epoch 50 \\\n",
    "    --num-layer {layer} --batch-size 128 --lr 0.0001 --l1-dim 128 --label-emb 128 \\\n",
    "    --lr-schedule ReduceLROnPlateau \\\n",
    "    --task classification > {log}\n",
    "    #--save-dir ./ckpt/{save} \\\n",
    "    #--load-dir ./ckpt/{load} \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "da5b5373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/side_mask4//’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/side_mask4//kdd99/’: File exists\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# layer mask training \n",
    "######################\n",
    "\n",
    "data = \"kdd99\"\n",
    "model =  \"linearalside\"\n",
    "save = \"side_mask4/\"\n",
    "load = \"side_mask3/\"\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{save}/\n",
    "    !mkdir ckpt/{save}/{data}/\n",
    "    !python3 dis_train_side.py --dataset {data} --model {model} --epoch 50 \\\n",
    "    --num-layer {layer} --batch-size 128 --lr 0.0001 --l1-dim 128 --label-emb 128 \\\n",
    "    --lr-schedule ReduceLROnPlateau \\\n",
    "    --task classification > {log}\n",
    "    #--save-dir ./ckpt/{save} \\\n",
    "    #--load-dir ./ckpt/{load} \\\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de8eee6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
