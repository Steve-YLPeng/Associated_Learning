{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06dd4036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       42\n",
       "1       37\n",
       "2       35\n",
       "3       37\n",
       "4       57\n",
       "      ... \n",
       "630     97\n",
       "631     92\n",
       "632    100\n",
       "633    100\n",
       "634    104\n",
       "Name: sensor_point5_i_value, Length: 635, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv(\"2022-train-v2.csv\")\n",
    "data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f28f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad319671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(635, 125)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_target = data.columns[:6]\n",
    "col_feature1 = data.columns[6:33].to_list() # 27 cols\n",
    "col_feature2 = data.columns[33:43].to_list() # 10 cols\n",
    "col_feature3 = data.columns[43:103].to_list() # 60 cols\n",
    "col_feature4 = data.columns[103:].to_list() # 28 cols\n",
    "y = data[col_target]\n",
    "x = data[col_feature1 + col_feature2 + col_feature3 + col_feature4]\n",
    "x = x.fillna(0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2f394a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 92, 100,  78,  78,  84,  68])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train, clean_test, train_label, test_label = train_test_split(x, y, test_size=0.2)\n",
    "train_label.to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e22348e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor_point5_i_value     0\n",
      "sensor_point6_i_value     0\n",
      "sensor_point7_i_value     0\n",
      "sensor_point8_i_value     0\n",
      "sensor_point9_i_value     0\n",
      "sensor_point10_i_value    0\n",
      "dtype: int64\n",
      "sensor_point5_i_value     0\n",
      "sensor_point6_i_value     0\n",
      "sensor_point7_i_value     0\n",
      "sensor_point8_i_value     0\n",
      "sensor_point9_i_value     0\n",
      "sensor_point10_i_value    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((y == 0).sum())\n",
    "print((y.isna()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57f55723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      22\n",
      "238     1\n",
      "286     3\n",
      "621     1\n",
      "dtype: int64 \n",
      "\n",
      "0    10\n",
      "dtype: int64 \n",
      "\n",
      "0      20\n",
      "16      2\n",
      "18      3\n",
      "21      5\n",
      "131     5\n",
      "162    10\n",
      "164     3\n",
      "167     1\n",
      "171     1\n",
      "573    10\n",
      "dtype: int64 \n",
      "\n",
      "0      15\n",
      "27      5\n",
      "65      5\n",
      "111     1\n",
      "117     1\n",
      "579     1\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for col in [col_feature1,col_feature2,col_feature3,col_feature4]:\n",
    "    print((x[col]==0).sum(axis=0).value_counts().sort_index(),\"\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d93b4abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    321\n",
      "2     28\n",
      "3     14\n",
      "4     62\n",
      "5    210\n",
      "dtype: int64 \n",
      "\n",
      "0    635\n",
      "dtype: int64 \n",
      "\n",
      "0      62\n",
      "10    345\n",
      "11      4\n",
      "12      3\n",
      "15     33\n",
      "20     69\n",
      "25      3\n",
      "30    109\n",
      "38      2\n",
      "40      5\n",
      "dtype: int64 \n",
      "\n",
      "0     52\n",
      "1    380\n",
      "2     86\n",
      "3     25\n",
      "6      4\n",
      "7     88\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [col_feature1,col_feature2,col_feature3,col_feature4]:\n",
    "    print((x[col]==0).sum(axis=1).value_counts().sort_index(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbac891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 80.40139770507812: 100%|███████| 8/8 [00:00<00:00, 21.18it/s]\n",
      "Train 1 | out_loss 79.84711456298828: 100%|██████| 8/8 [00:00<00:00, 659.37it/s]\n",
      "Train 2 | out_loss 79.49046325683594: 100%|██████| 8/8 [00:00<00:00, 717.77it/s]\n",
      "Train 3 | out_loss 78.6607437133789: 100%|███████| 8/8 [00:00<00:00, 710.72it/s]\n",
      "Train 4 | out_loss 77.94669342041016: 100%|██████| 8/8 [00:00<00:00, 710.75it/s]\n",
      "Train 5 | out_loss 77.35505676269531: 100%|██████| 8/8 [00:00<00:00, 727.22it/s]\n",
      "Train 6 | out_loss 76.81263732910156: 100%|██████| 8/8 [00:00<00:00, 712.95it/s]\n",
      "Train 7 | out_loss 76.26959228515625: 100%|██████| 8/8 [00:00<00:00, 712.38it/s]\n",
      "Train 8 | out_loss 75.72826385498047: 100%|██████| 8/8 [00:00<00:00, 715.20it/s]\n",
      "Train 9 | out_loss 75.1964111328125: 100%|███████| 8/8 [00:00<00:00, 662.59it/s]\n",
      "Train 10 | out_loss 74.66710662841797: 100%|█████| 8/8 [00:00<00:00, 691.40it/s]\n",
      "Train 11 | out_loss 74.14476013183594: 100%|█████| 8/8 [00:00<00:00, 691.53it/s]\n",
      "Train 12 | out_loss 73.62429809570312: 100%|█████| 8/8 [00:00<00:00, 697.81it/s]\n",
      "Train 13 | out_loss 73.10322570800781: 100%|█████| 8/8 [00:00<00:00, 705.79it/s]\n",
      "Train 14 | out_loss 72.58346557617188: 100%|█████| 8/8 [00:00<00:00, 707.78it/s]\n",
      "Train 15 | out_loss 72.06513214111328: 100%|█████| 8/8 [00:00<00:00, 708.33it/s]\n",
      "Train 16 | out_loss 71.54786682128906: 100%|█████| 8/8 [00:00<00:00, 710.06it/s]\n",
      "Train 17 | out_loss 71.03372192382812: 100%|█████| 8/8 [00:00<00:00, 685.51it/s]\n",
      "Train 18 | out_loss 70.51837158203125: 100%|█████| 8/8 [00:00<00:00, 706.84it/s]\n",
      "Train 19 | out_loss 69.99903106689453: 100%|█████| 8/8 [00:00<00:00, 700.98it/s]\n",
      "Train 20 | out_loss 69.48550415039062: 100%|█████| 8/8 [00:00<00:00, 711.46it/s]\n",
      "Train 21 | out_loss 68.96733856201172: 100%|█████| 8/8 [00:00<00:00, 706.72it/s]\n",
      "Train 22 | out_loss 68.4544677734375: 100%|██████| 8/8 [00:00<00:00, 711.55it/s]\n",
      "Train 23 | out_loss 67.94120788574219: 100%|█████| 8/8 [00:00<00:00, 712.08it/s]\n",
      "Train 24 | out_loss 67.42581939697266: 100%|█████| 8/8 [00:00<00:00, 711.59it/s]\n",
      "Train 25 | out_loss 66.91223907470703: 100%|█████| 8/8 [00:00<00:00, 708.24it/s]\n",
      "Train 26 | out_loss 66.39937591552734: 100%|█████| 8/8 [00:00<00:00, 712.29it/s]\n",
      "Train 27 | out_loss 65.88594818115234: 100%|█████| 8/8 [00:00<00:00, 713.17it/s]\n",
      "Train 28 | out_loss 65.3709487915039: 100%|██████| 8/8 [00:00<00:00, 715.64it/s]\n",
      "Train 29 | out_loss 64.85908508300781: 100%|█████| 8/8 [00:00<00:00, 709.11it/s]\n",
      "Train 30 | out_loss 64.34587860107422: 100%|█████| 8/8 [00:00<00:00, 713.71it/s]\n",
      "Train 31 | out_loss 63.83564376831055: 100%|█████| 8/8 [00:00<00:00, 711.80it/s]\n",
      "Train 32 | out_loss 63.323211669921875: 100%|████| 8/8 [00:00<00:00, 661.84it/s]\n",
      "Train 33 | out_loss 62.81081771850586: 100%|█████| 8/8 [00:00<00:00, 641.69it/s]\n",
      "Train 34 | out_loss 62.30315017700195: 100%|█████| 8/8 [00:00<00:00, 706.54it/s]\n",
      "Train 35 | out_loss 61.791290283203125: 100%|████| 8/8 [00:00<00:00, 708.63it/s]\n",
      "Train 36 | out_loss 61.28171920776367: 100%|█████| 8/8 [00:00<00:00, 716.65it/s]\n",
      "Train 37 | out_loss 60.77023696899414: 100%|█████| 8/8 [00:00<00:00, 711.68it/s]\n",
      "Train 38 | out_loss 60.260162353515625: 100%|████| 8/8 [00:00<00:00, 693.30it/s]\n",
      "Train 39 | out_loss 59.74994659423828: 100%|█████| 8/8 [00:00<00:00, 659.25it/s]\n",
      "Train 40 | out_loss 59.24045181274414: 100%|█████| 8/8 [00:00<00:00, 668.55it/s]\n",
      "Train 41 | out_loss 58.73141098022461: 100%|█████| 8/8 [00:00<00:00, 706.26it/s]\n",
      "Train 42 | out_loss 58.222103118896484: 100%|████| 8/8 [00:00<00:00, 728.68it/s]\n",
      "Train 43 | out_loss 57.712947845458984: 100%|████| 8/8 [00:00<00:00, 735.65it/s]\n",
      "Train 44 | out_loss 57.20429992675781: 100%|█████| 8/8 [00:00<00:00, 720.41it/s]\n",
      "Train 45 | out_loss 56.69801330566406: 100%|█████| 8/8 [00:00<00:00, 719.03it/s]\n",
      "Train 46 | out_loss 56.18757247924805: 100%|█████| 8/8 [00:00<00:00, 721.14it/s]\n",
      "Train 47 | out_loss 55.68324279785156: 100%|█████| 8/8 [00:00<00:00, 721.24it/s]\n",
      "Train 48 | out_loss 55.174068450927734: 100%|████| 8/8 [00:00<00:00, 719.81it/s]\n",
      "Train 49 | out_loss 54.66960906982422: 100%|█████| 8/8 [00:00<00:00, 719.08it/s]\n",
      "Train 50 | out_loss 54.162349700927734: 100%|████| 8/8 [00:00<00:00, 718.83it/s]\n",
      "Train 51 | out_loss 53.657283782958984: 100%|████| 8/8 [00:00<00:00, 719.87it/s]\n",
      "Train 52 | out_loss 53.147525787353516: 100%|████| 8/8 [00:00<00:00, 721.85it/s]\n",
      "Train 53 | out_loss 52.64369583129883: 100%|█████| 8/8 [00:00<00:00, 723.11it/s]\n",
      "Train 54 | out_loss 52.137027740478516: 100%|████| 8/8 [00:00<00:00, 722.97it/s]\n",
      "Train 55 | out_loss 51.63453674316406: 100%|█████| 8/8 [00:00<00:00, 718.73it/s]\n",
      "Train 56 | out_loss 51.126041412353516: 100%|████| 8/8 [00:00<00:00, 720.62it/s]\n",
      "Train 57 | out_loss 50.626487731933594: 100%|████| 8/8 [00:00<00:00, 719.10it/s]\n",
      "Train 58 | out_loss 50.12152862548828: 100%|█████| 8/8 [00:00<00:00, 722.86it/s]\n",
      "Train 59 | out_loss 49.619422912597656: 100%|████| 8/8 [00:00<00:00, 717.86it/s]\n",
      "Train 60 | out_loss 49.1168327331543: 100%|██████| 8/8 [00:00<00:00, 664.01it/s]\n",
      "Train 61 | out_loss 48.61277389526367: 100%|█████| 8/8 [00:00<00:00, 653.92it/s]\n",
      "Train 62 | out_loss 48.11146545410156: 100%|█████| 8/8 [00:00<00:00, 709.80it/s]\n",
      "Train 63 | out_loss 47.610191345214844: 100%|████| 8/8 [00:00<00:00, 688.88it/s]\n",
      "Train 64 | out_loss 47.11043930053711: 100%|█████| 8/8 [00:00<00:00, 689.17it/s]\n",
      "Train 65 | out_loss 46.61205291748047: 100%|█████| 8/8 [00:00<00:00, 712.14it/s]\n",
      "Train 66 | out_loss 46.11252975463867: 100%|█████| 8/8 [00:00<00:00, 716.29it/s]\n",
      "Train 67 | out_loss 45.620662689208984: 100%|████| 8/8 [00:00<00:00, 710.61it/s]\n",
      "Train 68 | out_loss 45.130958557128906: 100%|████| 8/8 [00:00<00:00, 718.71it/s]\n",
      "Train 69 | out_loss 44.645912170410156: 100%|████| 8/8 [00:00<00:00, 722.25it/s]\n",
      "Train 70 | out_loss 44.19009780883789: 100%|█████| 8/8 [00:00<00:00, 715.52it/s]\n",
      "Train 71 | out_loss 43.765464782714844: 100%|████| 8/8 [00:00<00:00, 720.02it/s]\n",
      "Train 72 | out_loss 43.35102462768555: 100%|█████| 8/8 [00:00<00:00, 723.08it/s]\n",
      "Train 73 | out_loss 42.933292388916016: 100%|████| 8/8 [00:00<00:00, 726.18it/s]\n",
      "Train 74 | out_loss 42.544921875: 100%|██████████| 8/8 [00:00<00:00, 720.86it/s]\n",
      "Train 75 | out_loss 42.19286346435547: 100%|█████| 8/8 [00:00<00:00, 722.55it/s]\n",
      "Train 76 | out_loss 41.91612243652344: 100%|█████| 8/8 [00:00<00:00, 727.91it/s]\n",
      "Train 77 | out_loss 41.69344711303711: 100%|█████| 8/8 [00:00<00:00, 727.36it/s]\n",
      "Train 78 | out_loss 41.48460006713867: 100%|█████| 8/8 [00:00<00:00, 714.81it/s]\n",
      "Train 79 | out_loss 41.31120681762695: 100%|█████| 8/8 [00:00<00:00, 710.57it/s]\n",
      "Train 80 | out_loss 41.140106201171875: 100%|████| 8/8 [00:00<00:00, 718.73it/s]\n",
      "Train 81 | out_loss 40.96116638183594: 100%|█████| 8/8 [00:00<00:00, 732.13it/s]\n",
      "Train 82 | out_loss 40.80050277709961: 100%|█████| 8/8 [00:00<00:00, 715.39it/s]\n",
      "Train 83 | out_loss 40.64588928222656: 100%|█████| 8/8 [00:00<00:00, 713.06it/s]\n",
      "Train 84 | out_loss 40.47060012817383: 100%|█████| 8/8 [00:00<00:00, 731.43it/s]\n",
      "Train 85 | out_loss 40.29774856567383: 100%|█████| 8/8 [00:00<00:00, 732.10it/s]\n",
      "Train 86 | out_loss 40.14988708496094: 100%|█████| 8/8 [00:00<00:00, 712.26it/s]\n",
      "Train 87 | out_loss 40.01398849487305: 100%|█████| 8/8 [00:00<00:00, 675.21it/s]\n",
      "Train 88 | out_loss 39.89204025268555: 100%|█████| 8/8 [00:00<00:00, 717.31it/s]\n",
      "Train 89 | out_loss 39.762107849121094: 100%|████| 8/8 [00:00<00:00, 735.26it/s]\n",
      "Train 90 | out_loss 39.64716339111328: 100%|█████| 8/8 [00:00<00:00, 723.34it/s]\n",
      "Train 91 | out_loss 39.54755401611328: 100%|█████| 8/8 [00:00<00:00, 723.39it/s]\n",
      "Train 92 | out_loss 39.42306900024414: 100%|█████| 8/8 [00:00<00:00, 728.23it/s]\n",
      "Train 93 | out_loss 39.31111526489258: 100%|█████| 8/8 [00:00<00:00, 728.57it/s]\n",
      "Train 94 | out_loss 39.22718811035156: 100%|█████| 8/8 [00:00<00:00, 720.42it/s]\n",
      "Train 95 | out_loss 39.1439208984375: 100%|██████| 8/8 [00:00<00:00, 729.02it/s]\n",
      "Train 96 | out_loss 39.05636215209961: 100%|█████| 8/8 [00:00<00:00, 739.25it/s]\n",
      "Train 97 | out_loss 38.949398040771484: 100%|████| 8/8 [00:00<00:00, 728.97it/s]\n",
      "Train 98 | out_loss 38.876609802246094: 100%|████| 8/8 [00:00<00:00, 730.13it/s]\n",
      "Train 99 | out_loss 38.80714797973633: 100%|█████| 8/8 [00:00<00:00, 721.00it/s]\n",
      "Train 100 | out_loss 38.76641082763672: 100%|████| 8/8 [00:00<00:00, 723.45it/s]\n",
      "Train 101 | out_loss 38.72355651855469: 100%|████| 8/8 [00:00<00:00, 718.26it/s]\n",
      "Train 102 | out_loss 38.67548370361328: 100%|████| 8/8 [00:00<00:00, 717.82it/s]\n",
      "Train 103 | out_loss 38.62220764160156: 100%|████| 8/8 [00:00<00:00, 730.68it/s]\n",
      "Train 104 | out_loss 38.548831939697266: 100%|███| 8/8 [00:00<00:00, 739.79it/s]\n",
      "Train 105 | out_loss 38.48085021972656: 100%|████| 8/8 [00:00<00:00, 727.81it/s]\n",
      "Train 106 | out_loss 38.42313766479492: 100%|████| 8/8 [00:00<00:00, 709.38it/s]\n",
      "Train 107 | out_loss 38.35354232788086: 100%|████| 8/8 [00:00<00:00, 724.11it/s]\n",
      "Train 108 | out_loss 38.26423645019531: 100%|████| 8/8 [00:00<00:00, 720.41it/s]\n",
      "Train 109 | out_loss 38.19343566894531: 100%|████| 8/8 [00:00<00:00, 727.80it/s]\n",
      "Train 110 | out_loss 38.129859924316406: 100%|███| 8/8 [00:00<00:00, 724.20it/s]\n",
      "Train 111 | out_loss 38.08415222167969: 100%|████| 8/8 [00:00<00:00, 727.86it/s]\n",
      "Train 112 | out_loss 38.03693389892578: 100%|████| 8/8 [00:00<00:00, 739.44it/s]\n",
      "Train 113 | out_loss 37.991695404052734: 100%|███| 8/8 [00:00<00:00, 719.22it/s]\n",
      "Train 114 | out_loss 37.948856353759766: 100%|███| 8/8 [00:00<00:00, 711.76it/s]\n",
      "Train 115 | out_loss 37.907535552978516: 100%|███| 8/8 [00:00<00:00, 709.44it/s]\n",
      "Train 116 | out_loss 37.833988189697266: 100%|███| 8/8 [00:00<00:00, 719.77it/s]\n",
      "Train 117 | out_loss 37.765777587890625: 100%|███| 8/8 [00:00<00:00, 718.80it/s]\n",
      "Train 118 | out_loss 37.70829391479492: 100%|████| 8/8 [00:00<00:00, 718.90it/s]\n",
      "Train 119 | out_loss 37.66883850097656: 100%|████| 8/8 [00:00<00:00, 724.51it/s]\n",
      "Train 120 | out_loss 37.61955642700195: 100%|████| 8/8 [00:00<00:00, 724.11it/s]\n",
      "Train 121 | out_loss 37.57240295410156: 100%|████| 8/8 [00:00<00:00, 719.17it/s]\n",
      "Train 122 | out_loss 37.524959564208984: 100%|███| 8/8 [00:00<00:00, 722.61it/s]\n",
      "Train 123 | out_loss 37.47648620605469: 100%|████| 8/8 [00:00<00:00, 723.95it/s]\n",
      "Train 124 | out_loss 37.435333251953125: 100%|███| 8/8 [00:00<00:00, 721.12it/s]\n",
      "Train 125 | out_loss 37.396549224853516: 100%|███| 8/8 [00:00<00:00, 723.45it/s]\n",
      "Train 126 | out_loss 37.35641098022461: 100%|████| 8/8 [00:00<00:00, 721.46it/s]\n",
      "Train 127 | out_loss 37.313480377197266: 100%|███| 8/8 [00:00<00:00, 721.99it/s]\n",
      "Train 128 | out_loss 37.266876220703125: 100%|███| 8/8 [00:00<00:00, 717.51it/s]\n",
      "Train 129 | out_loss 37.2332763671875: 100%|█████| 8/8 [00:00<00:00, 718.88it/s]\n",
      "Train 130 | out_loss 37.19130325317383: 100%|████| 8/8 [00:00<00:00, 723.64it/s]\n",
      "Train 131 | out_loss 37.15351104736328: 100%|████| 8/8 [00:00<00:00, 722.88it/s]\n",
      "Train 132 | out_loss 37.103092193603516: 100%|███| 8/8 [00:00<00:00, 669.08it/s]\n",
      "Train 133 | out_loss 37.049991607666016: 100%|███| 8/8 [00:00<00:00, 661.58it/s]\n",
      "Train 134 | out_loss 36.999107360839844: 100%|███| 8/8 [00:00<00:00, 721.82it/s]\n",
      "Train 135 | out_loss 36.944393157958984: 100%|███| 8/8 [00:00<00:00, 727.04it/s]\n",
      "Train 136 | out_loss 36.895626068115234: 100%|███| 8/8 [00:00<00:00, 721.68it/s]\n",
      "Train 137 | out_loss 36.85477066040039: 100%|████| 8/8 [00:00<00:00, 720.56it/s]\n",
      "Train 138 | out_loss 36.82136154174805: 100%|████| 8/8 [00:00<00:00, 727.50it/s]\n",
      "Train 139 | out_loss 36.79035949707031: 100%|████| 8/8 [00:00<00:00, 726.59it/s]\n",
      "Train 140 | out_loss 36.768089294433594: 100%|███| 8/8 [00:00<00:00, 716.85it/s]\n",
      "Train 141 | out_loss 36.743831634521484: 100%|███| 8/8 [00:00<00:00, 720.25it/s]\n",
      "Train 142 | out_loss 36.70951843261719: 100%|████| 8/8 [00:00<00:00, 724.17it/s]\n",
      "Train 143 | out_loss 36.6623420715332: 100%|█████| 8/8 [00:00<00:00, 721.90it/s]\n",
      "Train 144 | out_loss 36.61558532714844: 100%|████| 8/8 [00:00<00:00, 667.87it/s]\n",
      "Train 145 | out_loss 36.5590705871582: 100%|█████| 8/8 [00:00<00:00, 717.80it/s]\n",
      "Train 146 | out_loss 36.5112419128418: 100%|█████| 8/8 [00:00<00:00, 690.35it/s]\n",
      "Train 147 | out_loss 36.46809387207031: 100%|████| 8/8 [00:00<00:00, 694.00it/s]\n",
      "Train 148 | out_loss 36.44118881225586: 100%|████| 8/8 [00:00<00:00, 720.19it/s]\n",
      "Train 149 | out_loss 36.417259216308594: 100%|███| 8/8 [00:00<00:00, 727.03it/s]\n",
      "Train 150 | out_loss 36.3936882019043: 100%|█████| 8/8 [00:00<00:00, 723.76it/s]\n",
      "Train 151 | out_loss 36.3675422668457: 100%|█████| 8/8 [00:00<00:00, 720.41it/s]\n",
      "Train 152 | out_loss 36.33732223510742: 100%|████| 8/8 [00:00<00:00, 717.53it/s]\n",
      "Train 153 | out_loss 36.3033332824707: 100%|█████| 8/8 [00:00<00:00, 723.55it/s]\n",
      "Train 154 | out_loss 36.277706146240234: 100%|███| 8/8 [00:00<00:00, 726.16it/s]\n",
      "Train 155 | out_loss 36.24702072143555: 100%|████| 8/8 [00:00<00:00, 718.31it/s]\n",
      "Train 156 | out_loss 36.20729064941406: 100%|████| 8/8 [00:00<00:00, 719.22it/s]\n",
      "Train 157 | out_loss 36.17599868774414: 100%|████| 8/8 [00:00<00:00, 724.22it/s]\n",
      "Train 158 | out_loss 36.15069580078125: 100%|████| 8/8 [00:00<00:00, 732.23it/s]\n",
      "Train 159 | out_loss 36.11880111694336: 100%|████| 8/8 [00:00<00:00, 730.08it/s]\n",
      "Train 160 | out_loss 36.0817756652832: 100%|█████| 8/8 [00:00<00:00, 728.13it/s]\n",
      "Train 161 | out_loss 36.05366516113281: 100%|████| 8/8 [00:00<00:00, 719.08it/s]\n",
      "Train 162 | out_loss 36.0219612121582: 100%|█████| 8/8 [00:00<00:00, 719.48it/s]\n",
      "Train 163 | out_loss 35.990196228027344: 100%|███| 8/8 [00:00<00:00, 709.25it/s]\n",
      "Train 164 | out_loss 35.96241760253906: 100%|████| 8/8 [00:00<00:00, 707.11it/s]\n",
      "Train 165 | out_loss 35.94158935546875: 100%|████| 8/8 [00:00<00:00, 715.95it/s]\n",
      "Train 166 | out_loss 35.918636322021484: 100%|███| 8/8 [00:00<00:00, 728.04it/s]\n",
      "Train 167 | out_loss 35.89468765258789: 100%|████| 8/8 [00:00<00:00, 725.67it/s]\n",
      "Train 168 | out_loss 35.870872497558594: 100%|███| 8/8 [00:00<00:00, 725.55it/s]\n",
      "Train 169 | out_loss 35.834224700927734: 100%|███| 8/8 [00:00<00:00, 737.04it/s]\n",
      "Train 170 | out_loss 35.79450225830078: 100%|████| 8/8 [00:00<00:00, 732.33it/s]\n",
      "Train 171 | out_loss 35.760799407958984: 100%|███| 8/8 [00:00<00:00, 720.62it/s]\n",
      "Train 172 | out_loss 35.707340240478516: 100%|███| 8/8 [00:00<00:00, 670.08it/s]\n",
      "Train 173 | out_loss 35.6538200378418: 100%|█████| 8/8 [00:00<00:00, 666.57it/s]\n",
      "Train 174 | out_loss 35.60639572143555: 100%|████| 8/8 [00:00<00:00, 659.21it/s]\n",
      "Train 175 | out_loss 35.57284927368164: 100%|████| 8/8 [00:00<00:00, 717.50it/s]\n",
      "Train 176 | out_loss 35.54208755493164: 100%|████| 8/8 [00:00<00:00, 722.80it/s]\n",
      "Train 177 | out_loss 35.511722564697266: 100%|███| 8/8 [00:00<00:00, 667.55it/s]\n",
      "Train 178 | out_loss 35.494773864746094: 100%|███| 8/8 [00:00<00:00, 541.82it/s]\n",
      "Train 179 | out_loss 35.47815704345703: 100%|████| 8/8 [00:00<00:00, 680.30it/s]\n",
      "Train 180 | out_loss 35.462833404541016: 100%|███| 8/8 [00:00<00:00, 710.01it/s]\n",
      "Train 181 | out_loss 35.434967041015625: 100%|███| 8/8 [00:00<00:00, 660.27it/s]\n",
      "Train 182 | out_loss 35.402530670166016: 100%|███| 8/8 [00:00<00:00, 716.94it/s]\n",
      "Train 183 | out_loss 35.374698638916016: 100%|███| 8/8 [00:00<00:00, 719.76it/s]\n",
      "Train 184 | out_loss 35.338287353515625: 100%|███| 8/8 [00:00<00:00, 709.58it/s]\n",
      "Train 185 | out_loss 35.31159973144531: 100%|████| 8/8 [00:00<00:00, 652.94it/s]\n",
      "Train 186 | out_loss 35.284637451171875: 100%|███| 8/8 [00:00<00:00, 653.15it/s]\n",
      "Train 187 | out_loss 35.244075775146484: 100%|███| 8/8 [00:00<00:00, 720.08it/s]\n",
      "Train 188 | out_loss 35.214839935302734: 100%|███| 8/8 [00:00<00:00, 728.05it/s]\n",
      "Train 189 | out_loss 35.19123458862305: 100%|████| 8/8 [00:00<00:00, 671.76it/s]\n",
      "Train 190 | out_loss 35.16337966918945: 100%|████| 8/8 [00:00<00:00, 720.76it/s]\n",
      "Train 191 | out_loss 35.13177490234375: 100%|████| 8/8 [00:00<00:00, 724.59it/s]\n",
      "Train 192 | out_loss 35.09928894042969: 100%|████| 8/8 [00:00<00:00, 716.27it/s]\n",
      "Train 193 | out_loss 35.06623077392578: 100%|████| 8/8 [00:00<00:00, 606.03it/s]\n",
      "Train 194 | out_loss 35.037899017333984: 100%|███| 8/8 [00:00<00:00, 678.95it/s]\n",
      "Train 195 | out_loss 35.02206039428711: 100%|████| 8/8 [00:00<00:00, 717.79it/s]\n",
      "Train 196 | out_loss 35.004981994628906: 100%|███| 8/8 [00:00<00:00, 713.44it/s]\n",
      "Train 197 | out_loss 34.98942947387695: 100%|████| 8/8 [00:00<00:00, 715.11it/s]\n",
      "Train 198 | out_loss 34.962127685546875: 100%|███| 8/8 [00:00<00:00, 710.19it/s]\n",
      "Train 199 | out_loss 34.92845916748047: 100%|████| 8/8 [00:00<00:00, 723.90it/s]\n",
      "Train 200 | out_loss 34.890567779541016: 100%|███| 8/8 [00:00<00:00, 692.29it/s]\n",
      "Train 201 | out_loss 34.863258361816406: 100%|███| 8/8 [00:00<00:00, 715.78it/s]\n",
      "Train 202 | out_loss 34.8423957824707: 100%|█████| 8/8 [00:00<00:00, 715.20it/s]\n",
      "Train 203 | out_loss 34.82299041748047: 100%|████| 8/8 [00:00<00:00, 719.59it/s]\n",
      "Train 204 | out_loss 34.81224822998047: 100%|████| 8/8 [00:00<00:00, 706.16it/s]\n",
      "Train 205 | out_loss 34.798519134521484: 100%|███| 8/8 [00:00<00:00, 705.47it/s]\n",
      "Train 206 | out_loss 34.78130340576172: 100%|████| 8/8 [00:00<00:00, 720.98it/s]\n",
      "Train 207 | out_loss 34.759765625: 100%|█████████| 8/8 [00:00<00:00, 726.11it/s]\n",
      "Train 208 | out_loss 34.73299026489258: 100%|████| 8/8 [00:00<00:00, 680.26it/s]\n",
      "Train 209 | out_loss 34.70905685424805: 100%|████| 8/8 [00:00<00:00, 706.29it/s]\n",
      "Train 210 | out_loss 34.68329620361328: 100%|████| 8/8 [00:00<00:00, 708.66it/s]\n",
      "Train 211 | out_loss 34.65839767456055: 100%|████| 8/8 [00:00<00:00, 708.87it/s]\n",
      "Train 212 | out_loss 34.62379455566406: 100%|████| 8/8 [00:00<00:00, 712.29it/s]\n",
      "Train 213 | out_loss 34.601078033447266: 100%|███| 8/8 [00:00<00:00, 709.23it/s]\n",
      "Train 214 | out_loss 34.581031799316406: 100%|███| 8/8 [00:00<00:00, 702.89it/s]\n",
      "Train 215 | out_loss 34.548519134521484: 100%|███| 8/8 [00:00<00:00, 705.03it/s]\n",
      "Train 216 | out_loss 34.5097541809082: 100%|█████| 8/8 [00:00<00:00, 704.94it/s]\n",
      "Train 217 | out_loss 34.478485107421875: 100%|███| 8/8 [00:00<00:00, 545.96it/s]\n",
      "Train 218 | out_loss 34.4580078125: 100%|████████| 8/8 [00:00<00:00, 682.67it/s]\n",
      "Train 219 | out_loss 34.43804931640625: 100%|████| 8/8 [00:00<00:00, 677.98it/s]\n",
      "Train 220 | out_loss 34.41640090942383: 100%|████| 8/8 [00:00<00:00, 716.93it/s]\n",
      "Train 221 | out_loss 34.402076721191406: 100%|███| 8/8 [00:00<00:00, 719.81it/s]\n",
      "Train 222 | out_loss 34.38914489746094: 100%|████| 8/8 [00:00<00:00, 710.52it/s]\n",
      "Train 223 | out_loss 34.38198471069336: 100%|████| 8/8 [00:00<00:00, 707.63it/s]\n",
      "Train 224 | out_loss 34.36820983886719: 100%|████| 8/8 [00:00<00:00, 712.09it/s]\n",
      "Train 225 | out_loss 34.361785888671875: 100%|███| 8/8 [00:00<00:00, 712.54it/s]\n",
      "Train 226 | out_loss 34.35042190551758: 100%|████| 8/8 [00:00<00:00, 713.26it/s]\n",
      "Train 227 | out_loss 34.33314895629883: 100%|████| 8/8 [00:00<00:00, 704.72it/s]\n",
      "Train 228 | out_loss 34.3098030090332: 100%|█████| 8/8 [00:00<00:00, 718.66it/s]\n",
      "Train 229 | out_loss 34.29832458496094: 100%|████| 8/8 [00:00<00:00, 716.98it/s]\n",
      "Train 230 | out_loss 34.283546447753906: 100%|███| 8/8 [00:00<00:00, 683.63it/s]\n",
      "Train 231 | out_loss 34.276222229003906: 100%|███| 8/8 [00:00<00:00, 696.67it/s]\n",
      "Train 232 | out_loss 34.25601577758789: 100%|████| 8/8 [00:00<00:00, 632.48it/s]\n",
      "Train 233 | out_loss 34.22505569458008: 100%|████| 8/8 [00:00<00:00, 723.80it/s]\n",
      "Train 234 | out_loss 34.19729995727539: 100%|████| 8/8 [00:00<00:00, 715.29it/s]\n",
      "Train 235 | out_loss 34.16811752319336: 100%|████| 8/8 [00:00<00:00, 722.64it/s]\n",
      "Train 236 | out_loss 34.13930130004883: 100%|████| 8/8 [00:00<00:00, 720.53it/s]\n",
      "Train 237 | out_loss 34.11392593383789: 100%|████| 8/8 [00:00<00:00, 724.53it/s]\n",
      "Train 238 | out_loss 34.095985412597656: 100%|███| 8/8 [00:00<00:00, 708.90it/s]\n",
      "Train 239 | out_loss 34.073448181152344: 100%|███| 8/8 [00:00<00:00, 724.17it/s]\n",
      "Train 240 | out_loss 34.04548645019531: 100%|████| 8/8 [00:00<00:00, 731.42it/s]\n",
      "Train 241 | out_loss 34.0202751159668: 100%|█████| 8/8 [00:00<00:00, 724.20it/s]\n",
      "Train 242 | out_loss 34.0022087097168: 100%|█████| 8/8 [00:00<00:00, 722.36it/s]\n",
      "Train 243 | out_loss 33.983436584472656: 100%|███| 8/8 [00:00<00:00, 722.83it/s]\n",
      "Train 244 | out_loss 33.9682731628418: 100%|█████| 8/8 [00:00<00:00, 726.02it/s]\n",
      "Train 245 | out_loss 33.951393127441406: 100%|███| 8/8 [00:00<00:00, 723.44it/s]\n",
      "Train 246 | out_loss 33.9273796081543: 100%|█████| 8/8 [00:00<00:00, 714.05it/s]\n",
      "Train 247 | out_loss 33.90237045288086: 100%|████| 8/8 [00:00<00:00, 725.00it/s]\n",
      "Train 248 | out_loss 33.87447738647461: 100%|████| 8/8 [00:00<00:00, 720.75it/s]\n",
      "Train 249 | out_loss 33.84550857543945: 100%|████| 8/8 [00:00<00:00, 721.77it/s]\n",
      "Train 250 | out_loss 33.81898880004883: 100%|████| 8/8 [00:00<00:00, 703.57it/s]\n",
      "Train 251 | out_loss 33.79610061645508: 100%|████| 8/8 [00:00<00:00, 717.40it/s]\n",
      "Train 252 | out_loss 33.77473449707031: 100%|████| 8/8 [00:00<00:00, 721.72it/s]\n",
      "Train 253 | out_loss 33.74869155883789: 100%|████| 8/8 [00:00<00:00, 655.19it/s]\n",
      "Train 254 | out_loss 33.71813201904297: 100%|████| 8/8 [00:00<00:00, 712.76it/s]\n",
      "Train 255 | out_loss 33.694358825683594: 100%|███| 8/8 [00:00<00:00, 717.80it/s]\n",
      "Train 256 | out_loss 33.67283630371094: 100%|████| 8/8 [00:00<00:00, 728.76it/s]\n",
      "Train 257 | out_loss 33.64649200439453: 100%|████| 8/8 [00:00<00:00, 718.88it/s]\n",
      "Train 258 | out_loss 33.615760803222656: 100%|███| 8/8 [00:00<00:00, 710.64it/s]\n",
      "Train 259 | out_loss 33.58513259887695: 100%|████| 8/8 [00:00<00:00, 720.90it/s]\n",
      "Train 260 | out_loss 33.54948043823242: 100%|████| 8/8 [00:00<00:00, 721.03it/s]\n",
      "Train 261 | out_loss 33.51133346557617: 100%|████| 8/8 [00:00<00:00, 718.36it/s]\n",
      "Train 262 | out_loss 33.48674392700195: 100%|████| 8/8 [00:00<00:00, 722.74it/s]\n",
      "Train 263 | out_loss 33.464332580566406: 100%|███| 8/8 [00:00<00:00, 725.11it/s]\n",
      "Train 264 | out_loss 33.4518928527832: 100%|█████| 8/8 [00:00<00:00, 723.08it/s]\n",
      "Train 265 | out_loss 33.43661880493164: 100%|████| 8/8 [00:00<00:00, 719.94it/s]\n",
      "Train 266 | out_loss 33.40605545043945: 100%|████| 8/8 [00:00<00:00, 713.04it/s]\n",
      "Train 267 | out_loss 33.376914978027344: 100%|███| 8/8 [00:00<00:00, 719.47it/s]\n",
      "Train 268 | out_loss 33.35634994506836: 100%|████| 8/8 [00:00<00:00, 721.49it/s]\n",
      "Train 269 | out_loss 33.34157180786133: 100%|████| 8/8 [00:00<00:00, 703.34it/s]\n",
      "Train 270 | out_loss 33.32994079589844: 100%|████| 8/8 [00:00<00:00, 664.98it/s]\n",
      "Train 271 | out_loss 33.31835174560547: 100%|████| 8/8 [00:00<00:00, 655.89it/s]\n",
      "Train 272 | out_loss 33.30709457397461: 100%|████| 8/8 [00:00<00:00, 645.91it/s]\n",
      "Train 273 | out_loss 33.2899284362793: 100%|█████| 8/8 [00:00<00:00, 629.66it/s]\n",
      "Train 274 | out_loss 33.2684440612793: 100%|█████| 8/8 [00:00<00:00, 686.92it/s]\n",
      "Train 275 | out_loss 33.252952575683594: 100%|███| 8/8 [00:00<00:00, 706.53it/s]\n",
      "Train 276 | out_loss 33.242530822753906: 100%|███| 8/8 [00:00<00:00, 719.79it/s]\n",
      "Train 277 | out_loss 33.229759216308594: 100%|███| 8/8 [00:00<00:00, 723.97it/s]\n",
      "Train 278 | out_loss 33.208702087402344: 100%|███| 8/8 [00:00<00:00, 718.79it/s]\n",
      "Train 279 | out_loss 33.186256408691406: 100%|███| 8/8 [00:00<00:00, 722.92it/s]\n",
      "Train 280 | out_loss 33.17976379394531: 100%|████| 8/8 [00:00<00:00, 701.52it/s]\n",
      "Train 281 | out_loss 33.1656608581543: 100%|█████| 8/8 [00:00<00:00, 715.35it/s]\n",
      "Train 282 | out_loss 33.14783477783203: 100%|████| 8/8 [00:00<00:00, 720.01it/s]\n",
      "Train 283 | out_loss 33.12776565551758: 100%|████| 8/8 [00:00<00:00, 720.14it/s]\n",
      "Train 284 | out_loss 33.111244201660156: 100%|███| 8/8 [00:00<00:00, 716.13it/s]\n",
      "Train 285 | out_loss 33.09056091308594: 100%|████| 8/8 [00:00<00:00, 710.99it/s]\n",
      "Train 286 | out_loss 33.066619873046875: 100%|███| 8/8 [00:00<00:00, 717.79it/s]\n",
      "Train 287 | out_loss 33.04219436645508: 100%|████| 8/8 [00:00<00:00, 714.58it/s]\n",
      "Train 288 | out_loss 33.02313232421875: 100%|████| 8/8 [00:00<00:00, 701.98it/s]\n",
      "Train 289 | out_loss 32.97471618652344: 100%|████| 8/8 [00:00<00:00, 664.62it/s]\n",
      "Train 290 | out_loss 32.93208694458008: 100%|████| 8/8 [00:00<00:00, 719.17it/s]\n",
      "Train 291 | out_loss 32.90540313720703: 100%|████| 8/8 [00:00<00:00, 638.09it/s]\n",
      "Train 292 | out_loss 32.882789611816406: 100%|███| 8/8 [00:00<00:00, 696.64it/s]\n",
      "Train 293 | out_loss 32.857784271240234: 100%|███| 8/8 [00:00<00:00, 720.33it/s]\n",
      "Train 294 | out_loss 32.82297897338867: 100%|████| 8/8 [00:00<00:00, 722.42it/s]\n",
      "Train 295 | out_loss 32.789493560791016: 100%|███| 8/8 [00:00<00:00, 716.52it/s]\n",
      "Train 296 | out_loss 32.76374816894531: 100%|████| 8/8 [00:00<00:00, 722.98it/s]\n",
      "Train 297 | out_loss 32.73423385620117: 100%|████| 8/8 [00:00<00:00, 722.30it/s]\n",
      "Train 298 | out_loss 32.71098327636719: 100%|████| 8/8 [00:00<00:00, 720.36it/s]\n",
      "Train 299 | out_loss 32.69768142700195: 100%|████| 8/8 [00:00<00:00, 719.62it/s]\n",
      "Train 300 | out_loss 32.68367385864258: 100%|████| 8/8 [00:00<00:00, 720.35it/s]\n",
      "Train 301 | out_loss 32.666099548339844: 100%|███| 8/8 [00:00<00:00, 720.86it/s]\n",
      "Train 302 | out_loss 32.631370544433594: 100%|███| 8/8 [00:00<00:00, 656.69it/s]\n",
      "Train 303 | out_loss 32.60153579711914: 100%|████| 8/8 [00:00<00:00, 719.94it/s]\n",
      "Train 304 | out_loss 32.57835006713867: 100%|████| 8/8 [00:00<00:00, 716.90it/s]\n",
      "Train 305 | out_loss 32.552978515625: 100%|██████| 8/8 [00:00<00:00, 722.80it/s]\n",
      "Train 306 | out_loss 32.533084869384766: 100%|███| 8/8 [00:00<00:00, 652.64it/s]\n",
      "Train 307 | out_loss 32.50716018676758: 100%|████| 8/8 [00:00<00:00, 660.82it/s]\n",
      "Train 308 | out_loss 32.48500442504883: 100%|████| 8/8 [00:00<00:00, 698.77it/s]\n",
      "Train 309 | out_loss 32.453948974609375: 100%|███| 8/8 [00:00<00:00, 603.05it/s]\n",
      "Train 310 | out_loss 32.430816650390625: 100%|███| 8/8 [00:00<00:00, 690.58it/s]\n",
      "Train 311 | out_loss 32.41752624511719: 100%|████| 8/8 [00:00<00:00, 641.56it/s]\n",
      "Train 312 | out_loss 32.411537170410156: 100%|███| 8/8 [00:00<00:00, 715.64it/s]\n",
      "Train 313 | out_loss 32.39814376831055: 100%|████| 8/8 [00:00<00:00, 721.23it/s]\n",
      "Train 314 | out_loss 32.38469696044922: 100%|████| 8/8 [00:00<00:00, 725.19it/s]\n",
      "Train 315 | out_loss 32.35518264770508: 100%|████| 8/8 [00:00<00:00, 711.46it/s]\n",
      "Train 316 | out_loss 32.31725311279297: 100%|████| 8/8 [00:00<00:00, 700.54it/s]\n",
      "Train 317 | out_loss 32.29628372192383: 100%|████| 8/8 [00:00<00:00, 692.50it/s]\n",
      "Train 318 | out_loss 32.28018569946289: 100%|████| 8/8 [00:00<00:00, 703.49it/s]\n",
      "Train 319 | out_loss 32.2700080871582: 100%|█████| 8/8 [00:00<00:00, 692.89it/s]\n",
      "Train 320 | out_loss 32.26248550415039: 100%|████| 8/8 [00:00<00:00, 706.83it/s]\n",
      "Train 321 | out_loss 32.2562141418457: 100%|█████| 8/8 [00:00<00:00, 683.47it/s]\n",
      "Train 322 | out_loss 32.24553680419922: 100%|████| 8/8 [00:00<00:00, 712.98it/s]\n",
      "Train 323 | out_loss 32.22401809692383: 100%|████| 8/8 [00:00<00:00, 716.81it/s]\n",
      "Train 324 | out_loss 32.1900634765625: 100%|█████| 8/8 [00:00<00:00, 716.99it/s]\n",
      "Train 325 | out_loss 32.163761138916016: 100%|███| 8/8 [00:00<00:00, 722.19it/s]\n",
      "Train 326 | out_loss 32.14461898803711: 100%|████| 8/8 [00:00<00:00, 719.02it/s]\n",
      "Train 327 | out_loss 32.12510681152344: 100%|████| 8/8 [00:00<00:00, 737.15it/s]\n",
      "Train 328 | out_loss 32.10721206665039: 100%|████| 8/8 [00:00<00:00, 729.25it/s]\n",
      "Train 329 | out_loss 32.0851936340332: 100%|█████| 8/8 [00:00<00:00, 726.90it/s]\n",
      "Train 330 | out_loss 32.071044921875: 100%|██████| 8/8 [00:00<00:00, 727.06it/s]\n",
      "Train 331 | out_loss 32.044742584228516: 100%|███| 8/8 [00:00<00:00, 739.56it/s]\n",
      "Train 332 | out_loss 32.00815200805664: 100%|████| 8/8 [00:00<00:00, 733.01it/s]\n",
      "Train 333 | out_loss 31.98571014404297: 100%|████| 8/8 [00:00<00:00, 725.55it/s]\n",
      "Train 334 | out_loss 31.96535301208496: 100%|████| 8/8 [00:00<00:00, 730.79it/s]\n",
      "Train 335 | out_loss 31.94082260131836: 100%|████| 8/8 [00:00<00:00, 732.87it/s]\n",
      "Train 336 | out_loss 31.924285888671875: 100%|███| 8/8 [00:00<00:00, 726.48it/s]\n",
      "Train 337 | out_loss 31.91533660888672: 100%|████| 8/8 [00:00<00:00, 730.56it/s]\n",
      "Train 338 | out_loss 31.897216796875: 100%|██████| 8/8 [00:00<00:00, 736.63it/s]\n",
      "Train 339 | out_loss 31.874597549438477: 100%|███| 8/8 [00:00<00:00, 738.55it/s]\n",
      "Train 340 | out_loss 31.856260299682617: 100%|███| 8/8 [00:00<00:00, 712.64it/s]\n",
      "Train 341 | out_loss 31.83321189880371: 100%|████| 8/8 [00:00<00:00, 711.43it/s]\n",
      "Train 342 | out_loss 31.812822341918945: 100%|███| 8/8 [00:00<00:00, 681.63it/s]\n",
      "Train 343 | out_loss 31.793161392211914: 100%|███| 8/8 [00:00<00:00, 722.66it/s]\n",
      "Train 344 | out_loss 31.77664566040039: 100%|████| 8/8 [00:00<00:00, 715.31it/s]\n",
      "Train 345 | out_loss 31.761005401611328: 100%|███| 8/8 [00:00<00:00, 612.79it/s]\n",
      "Train 346 | out_loss 31.74837303161621: 100%|████| 8/8 [00:00<00:00, 691.00it/s]\n",
      "Train 347 | out_loss 31.740392684936523: 100%|███| 8/8 [00:00<00:00, 690.05it/s]\n",
      "Train 348 | out_loss 31.73381233215332: 100%|████| 8/8 [00:00<00:00, 711.71it/s]\n",
      "Train 349 | out_loss 31.716890335083008: 100%|███| 8/8 [00:00<00:00, 708.78it/s]\n",
      "Train 350 | out_loss 31.695310592651367: 100%|███| 8/8 [00:00<00:00, 705.15it/s]\n",
      "Train 351 | out_loss 31.674888610839844: 100%|███| 8/8 [00:00<00:00, 714.24it/s]\n",
      "Train 352 | out_loss 31.663108825683594: 100%|███| 8/8 [00:00<00:00, 710.61it/s]\n",
      "Train 353 | out_loss 31.65043830871582: 100%|████| 8/8 [00:00<00:00, 711.79it/s]\n",
      "Train 354 | out_loss 31.63650131225586: 100%|████| 8/8 [00:00<00:00, 717.19it/s]\n",
      "Train 355 | out_loss 31.59714698791504: 100%|████| 8/8 [00:00<00:00, 704.58it/s]\n",
      "Train 356 | out_loss 31.539947509765625: 100%|███| 8/8 [00:00<00:00, 712.68it/s]\n",
      "Train 357 | out_loss 31.495765686035156: 100%|███| 8/8 [00:00<00:00, 716.73it/s]\n",
      "Train 358 | out_loss 31.445159912109375: 100%|███| 8/8 [00:00<00:00, 681.77it/s]\n",
      "Train 359 | out_loss 31.39253044128418: 100%|████| 8/8 [00:00<00:00, 702.73it/s]\n",
      "Train 360 | out_loss 31.370256423950195: 100%|███| 8/8 [00:00<00:00, 713.57it/s]\n",
      "Train 361 | out_loss 31.354337692260742: 100%|███| 8/8 [00:00<00:00, 633.05it/s]\n",
      "Train 362 | out_loss 31.337907791137695: 100%|███| 8/8 [00:00<00:00, 667.30it/s]\n",
      "Train 363 | out_loss 31.322561264038086: 100%|███| 8/8 [00:00<00:00, 709.04it/s]\n",
      "Train 364 | out_loss 31.301719665527344: 100%|███| 8/8 [00:00<00:00, 667.31it/s]\n",
      "Train 365 | out_loss 31.279672622680664: 100%|███| 8/8 [00:00<00:00, 658.07it/s]\n",
      "Train 366 | out_loss 31.260766983032227: 100%|███| 8/8 [00:00<00:00, 701.14it/s]\n",
      "Train 367 | out_loss 31.253049850463867: 100%|███| 8/8 [00:00<00:00, 708.11it/s]\n",
      "Train 368 | out_loss 31.246910095214844: 100%|███| 8/8 [00:00<00:00, 683.46it/s]\n",
      "Train 369 | out_loss 31.238300323486328: 100%|███| 8/8 [00:00<00:00, 699.09it/s]\n",
      "Train 370 | out_loss 31.228918075561523: 100%|███| 8/8 [00:00<00:00, 710.09it/s]\n",
      "Train 371 | out_loss 31.217220306396484: 100%|███| 8/8 [00:00<00:00, 709.52it/s]\n",
      "Train 372 | out_loss 31.192420959472656: 100%|███| 8/8 [00:00<00:00, 710.81it/s]\n",
      "Train 373 | out_loss 31.17291831970215: 100%|████| 8/8 [00:00<00:00, 716.50it/s]\n",
      "Train 374 | out_loss 31.14876365661621: 100%|████| 8/8 [00:00<00:00, 709.67it/s]\n",
      "Train 375 | out_loss 31.1231689453125: 100%|█████| 8/8 [00:00<00:00, 713.92it/s]\n",
      "Train 376 | out_loss 31.105403900146484: 100%|███| 8/8 [00:00<00:00, 723.42it/s]\n",
      "Train 377 | out_loss 31.08983612060547: 100%|████| 8/8 [00:00<00:00, 725.23it/s]\n",
      "Train 378 | out_loss 31.07743263244629: 100%|████| 8/8 [00:00<00:00, 715.03it/s]\n",
      "Train 379 | out_loss 31.06309700012207: 100%|████| 8/8 [00:00<00:00, 712.11it/s]\n",
      "Train 380 | out_loss 31.042194366455078: 100%|███| 8/8 [00:00<00:00, 728.15it/s]\n",
      "Train 381 | out_loss 31.015426635742188: 100%|███| 8/8 [00:00<00:00, 703.55it/s]\n",
      "Train 382 | out_loss 31.002605438232422: 100%|███| 8/8 [00:00<00:00, 702.55it/s]\n",
      "Train 383 | out_loss 30.99882698059082: 100%|████| 8/8 [00:00<00:00, 715.57it/s]\n",
      "Train 384 | out_loss 30.99089241027832: 100%|████| 8/8 [00:00<00:00, 701.71it/s]\n",
      "Train 385 | out_loss 30.98207664489746: 100%|████| 8/8 [00:00<00:00, 707.12it/s]\n",
      "Train 386 | out_loss 30.971818923950195: 100%|███| 8/8 [00:00<00:00, 703.48it/s]\n",
      "Train 387 | out_loss 30.94532585144043: 100%|████| 8/8 [00:00<00:00, 709.71it/s]\n",
      "Train 388 | out_loss 30.907012939453125: 100%|███| 8/8 [00:00<00:00, 713.88it/s]\n",
      "Train 389 | out_loss 30.87911033630371: 100%|████| 8/8 [00:00<00:00, 708.36it/s]\n",
      "Train 390 | out_loss 30.855955123901367: 100%|███| 8/8 [00:00<00:00, 709.85it/s]\n",
      "Train 391 | out_loss 30.79197120666504: 100%|████| 8/8 [00:00<00:00, 709.64it/s]\n",
      "Train 392 | out_loss 30.70404815673828: 100%|████| 8/8 [00:00<00:00, 712.61it/s]\n",
      "Train 393 | out_loss 30.655702590942383: 100%|███| 8/8 [00:00<00:00, 709.49it/s]\n",
      "Train 394 | out_loss 30.63033676147461: 100%|████| 8/8 [00:00<00:00, 693.89it/s]\n",
      "Train 395 | out_loss 30.611520767211914: 100%|███| 8/8 [00:00<00:00, 698.89it/s]\n",
      "Train 396 | out_loss 30.59954833984375: 100%|████| 8/8 [00:00<00:00, 693.12it/s]\n",
      "Train 397 | out_loss 30.58810806274414: 100%|████| 8/8 [00:00<00:00, 704.23it/s]\n",
      "Train 398 | out_loss 30.576696395874023: 100%|███| 8/8 [00:00<00:00, 710.04it/s]\n",
      "Train 399 | out_loss 30.568679809570312: 100%|███| 8/8 [00:00<00:00, 718.00it/s]\n",
      "Train 400 | out_loss 30.557912826538086: 100%|███| 8/8 [00:00<00:00, 705.31it/s]\n",
      "Train 401 | out_loss 30.554208755493164: 100%|███| 8/8 [00:00<00:00, 708.23it/s]\n",
      "Train 402 | out_loss 30.534791946411133: 100%|███| 8/8 [00:00<00:00, 674.39it/s]\n",
      "Train 403 | out_loss 30.494932174682617: 100%|███| 8/8 [00:00<00:00, 718.40it/s]\n",
      "Train 404 | out_loss 30.456022262573242: 100%|███| 8/8 [00:00<00:00, 634.30it/s]\n",
      "Train 405 | out_loss 30.414613723754883: 100%|███| 8/8 [00:00<00:00, 698.47it/s]\n",
      "Train 406 | out_loss 30.33891487121582: 100%|████| 8/8 [00:00<00:00, 657.84it/s]\n",
      "Train 407 | out_loss 30.286277770996094: 100%|███| 8/8 [00:00<00:00, 697.16it/s]\n",
      "Train 408 | out_loss 30.23241424560547: 100%|████| 8/8 [00:00<00:00, 684.09it/s]\n",
      "Train 409 | out_loss 30.204296112060547: 100%|███| 8/8 [00:00<00:00, 701.78it/s]\n",
      "Train 410 | out_loss 30.174888610839844: 100%|███| 8/8 [00:00<00:00, 715.61it/s]\n",
      "Train 411 | out_loss 30.155532836914062: 100%|███| 8/8 [00:00<00:00, 711.12it/s]\n",
      "Train 412 | out_loss 30.14603042602539: 100%|████| 8/8 [00:00<00:00, 707.00it/s]\n",
      "Train 413 | out_loss 30.142282485961914: 100%|███| 8/8 [00:00<00:00, 711.80it/s]\n",
      "Train 414 | out_loss 30.131120681762695: 100%|███| 8/8 [00:00<00:00, 715.10it/s]\n",
      "Train 415 | out_loss 30.099830627441406: 100%|███| 8/8 [00:00<00:00, 712.32it/s]\n",
      "Train 416 | out_loss 30.023801803588867: 100%|███| 8/8 [00:00<00:00, 721.83it/s]\n",
      "Train 417 | out_loss 29.895116806030273: 100%|███| 8/8 [00:00<00:00, 720.95it/s]\n",
      "Train 418 | out_loss 29.823762893676758: 100%|███| 8/8 [00:00<00:00, 726.38it/s]\n",
      "Train 419 | out_loss 29.790245056152344: 100%|███| 8/8 [00:00<00:00, 715.28it/s]\n",
      "Train 420 | out_loss 29.769140243530273: 100%|███| 8/8 [00:00<00:00, 719.17it/s]\n",
      "Train 421 | out_loss 29.705053329467773: 100%|███| 8/8 [00:00<00:00, 719.03it/s]\n",
      "Train 422 | out_loss 29.58735466003418: 100%|████| 8/8 [00:00<00:00, 723.48it/s]\n",
      "Train 423 | out_loss 29.50058937072754: 100%|████| 8/8 [00:00<00:00, 712.02it/s]\n",
      "Train 424 | out_loss 29.46179962158203: 100%|████| 8/8 [00:00<00:00, 717.01it/s]\n",
      "Train 425 | out_loss 29.445772171020508: 100%|███| 8/8 [00:00<00:00, 698.34it/s]\n",
      "Train 426 | out_loss 29.43535041809082: 100%|████| 8/8 [00:00<00:00, 703.48it/s]\n",
      "Train 427 | out_loss 29.41910743713379: 100%|████| 8/8 [00:00<00:00, 706.07it/s]\n",
      "Train 428 | out_loss 29.348663330078125: 100%|███| 8/8 [00:00<00:00, 707.60it/s]\n",
      "Train 429 | out_loss 29.295503616333008: 100%|███| 8/8 [00:00<00:00, 709.70it/s]\n",
      "Train 430 | out_loss 29.275304794311523: 100%|███| 8/8 [00:00<00:00, 713.89it/s]\n",
      "Train 431 | out_loss 29.264385223388672: 100%|███| 8/8 [00:00<00:00, 716.06it/s]\n",
      "Train 432 | out_loss 29.255090713500977: 100%|███| 8/8 [00:00<00:00, 709.08it/s]\n",
      "Train 433 | out_loss 29.240406036376953: 100%|███| 8/8 [00:00<00:00, 710.60it/s]\n",
      "Train 434 | out_loss 29.238788604736328: 100%|███| 8/8 [00:00<00:00, 710.93it/s]\n",
      "Train 435 | out_loss 29.22323989868164: 100%|████| 8/8 [00:00<00:00, 720.42it/s]\n",
      "Train 436 | out_loss 29.205459594726562: 100%|███| 8/8 [00:00<00:00, 713.24it/s]\n",
      "Train 437 | out_loss 29.196971893310547: 100%|███| 8/8 [00:00<00:00, 707.54it/s]\n",
      "Train 438 | out_loss 29.162582397460938: 100%|███| 8/8 [00:00<00:00, 717.86it/s]\n",
      "Train 439 | out_loss 29.100868225097656: 100%|███| 8/8 [00:00<00:00, 717.19it/s]\n",
      "Train 440 | out_loss 29.044565200805664: 100%|███| 8/8 [00:00<00:00, 693.63it/s]\n",
      "Train 441 | out_loss 29.003400802612305: 100%|███| 8/8 [00:00<00:00, 712.11it/s]\n",
      "Train 442 | out_loss 28.976961135864258: 100%|███| 8/8 [00:00<00:00, 678.91it/s]\n",
      "Train 443 | out_loss 28.96430778503418: 100%|████| 8/8 [00:00<00:00, 711.11it/s]\n",
      "Train 444 | out_loss 28.957401275634766: 100%|███| 8/8 [00:00<00:00, 700.48it/s]\n",
      "Train 445 | out_loss 28.950998306274414: 100%|███| 8/8 [00:00<00:00, 715.55it/s]\n",
      "Train 446 | out_loss 28.947635650634766: 100%|███| 8/8 [00:00<00:00, 713.92it/s]\n",
      "Train 447 | out_loss 28.942670822143555: 100%|███| 8/8 [00:00<00:00, 695.83it/s]\n",
      "Train 448 | out_loss 28.94141387939453: 100%|████| 8/8 [00:00<00:00, 704.87it/s]\n",
      "Train 449 | out_loss 28.936704635620117: 100%|███| 8/8 [00:00<00:00, 707.26it/s]\n",
      "Train 450 | out_loss 28.915790557861328: 100%|███| 8/8 [00:00<00:00, 636.72it/s]\n",
      "Train 451 | out_loss 28.860538482666016: 100%|███| 8/8 [00:00<00:00, 688.89it/s]\n",
      "Train 452 | out_loss 28.82569122314453: 100%|████| 8/8 [00:00<00:00, 698.80it/s]\n",
      "Train 453 | out_loss 28.79731559753418: 100%|████| 8/8 [00:00<00:00, 686.55it/s]\n",
      "Train 454 | out_loss 28.75789451599121: 100%|████| 8/8 [00:00<00:00, 703.36it/s]\n",
      "Train 455 | out_loss 28.73542594909668: 100%|████| 8/8 [00:00<00:00, 717.77it/s]\n",
      "Train 456 | out_loss 28.729040145874023: 100%|███| 8/8 [00:00<00:00, 724.45it/s]\n",
      "Train 457 | out_loss 28.722604751586914: 100%|███| 8/8 [00:00<00:00, 716.12it/s]\n",
      "Train 458 | out_loss 28.714797973632812: 100%|███| 8/8 [00:00<00:00, 720.89it/s]\n",
      "Train 459 | out_loss 28.70652198791504: 100%|████| 8/8 [00:00<00:00, 697.92it/s]\n",
      "Train 460 | out_loss 28.700037002563477: 100%|███| 8/8 [00:00<00:00, 716.76it/s]\n",
      "Train 461 | out_loss 28.7027587890625: 100%|█████| 8/8 [00:00<00:00, 659.43it/s]\n",
      "Train 462 | out_loss 28.69468879699707: 100%|████| 8/8 [00:00<00:00, 674.20it/s]\n",
      "Train 463 | out_loss 28.68401527404785: 100%|████| 8/8 [00:00<00:00, 699.56it/s]\n",
      "Train 464 | out_loss 28.679162979125977: 100%|███| 8/8 [00:00<00:00, 717.24it/s]\n",
      "Train 465 | out_loss 28.668365478515625: 100%|███| 8/8 [00:00<00:00, 709.52it/s]\n",
      "Train 466 | out_loss 28.659517288208008: 100%|███| 8/8 [00:00<00:00, 689.94it/s]\n",
      "Train 467 | out_loss 28.657970428466797: 100%|███| 8/8 [00:00<00:00, 671.18it/s]\n",
      "Train 468 | out_loss 28.650615692138672: 100%|███| 8/8 [00:00<00:00, 519.78it/s]\n",
      "Train 469 | out_loss 28.640329360961914: 100%|███| 8/8 [00:00<00:00, 621.77it/s]\n",
      "Train 470 | out_loss 28.63372039794922: 100%|████| 8/8 [00:00<00:00, 693.70it/s]\n",
      "Train 471 | out_loss 28.626773834228516: 100%|███| 8/8 [00:00<00:00, 687.62it/s]\n",
      "Train 472 | out_loss 28.62548065185547: 100%|████| 8/8 [00:00<00:00, 688.11it/s]\n",
      "Train 473 | out_loss 28.616724014282227: 100%|███| 8/8 [00:00<00:00, 706.19it/s]\n",
      "Train 474 | out_loss 28.60150909423828: 100%|████| 8/8 [00:00<00:00, 709.17it/s]\n",
      "Train 475 | out_loss 28.585527420043945: 100%|███| 8/8 [00:00<00:00, 714.08it/s]\n",
      "Train 476 | out_loss 28.56814193725586: 100%|████| 8/8 [00:00<00:00, 718.17it/s]\n",
      "Train 477 | out_loss 28.55754280090332: 100%|████| 8/8 [00:00<00:00, 723.62it/s]\n",
      "Train 478 | out_loss 28.551591873168945: 100%|███| 8/8 [00:00<00:00, 719.43it/s]\n",
      "Train 479 | out_loss 28.541950225830078: 100%|███| 8/8 [00:00<00:00, 720.84it/s]\n",
      "Train 480 | out_loss 28.520240783691406: 100%|███| 8/8 [00:00<00:00, 718.26it/s]\n",
      "Train 481 | out_loss 28.4971866607666: 100%|█████| 8/8 [00:00<00:00, 721.45it/s]\n",
      "Train 482 | out_loss 28.483535766601562: 100%|███| 8/8 [00:00<00:00, 717.04it/s]\n",
      "Train 483 | out_loss 28.478551864624023: 100%|███| 8/8 [00:00<00:00, 715.60it/s]\n",
      "Train 484 | out_loss 28.472829818725586: 100%|███| 8/8 [00:00<00:00, 703.12it/s]\n",
      "Train 485 | out_loss 28.468416213989258: 100%|███| 8/8 [00:00<00:00, 710.19it/s]\n",
      "Train 486 | out_loss 28.47168731689453: 100%|████| 8/8 [00:00<00:00, 720.64it/s]\n",
      "Train 487 | out_loss 28.484281539916992: 100%|███| 8/8 [00:00<00:00, 717.25it/s]\n",
      "Train 488 | out_loss 28.498085021972656: 100%|███| 8/8 [00:00<00:00, 720.66it/s]\n",
      "Train 489 | out_loss 28.499021530151367: 100%|███| 8/8 [00:00<00:00, 717.10it/s]\n",
      "Train 490 | out_loss 28.48531723022461: 100%|████| 8/8 [00:00<00:00, 727.66it/s]\n",
      "Train 491 | out_loss 28.471080780029297: 100%|███| 8/8 [00:00<00:00, 718.82it/s]\n",
      "Train 492 | out_loss 28.47072410583496: 100%|████| 8/8 [00:00<00:00, 719.64it/s]\n",
      "Train 493 | out_loss 28.47444725036621: 100%|████| 8/8 [00:00<00:00, 702.02it/s]\n",
      "Train 494 | out_loss 28.465330123901367: 100%|███| 8/8 [00:00<00:00, 716.06it/s]\n",
      "Train 495 | out_loss 28.40130043029785: 100%|████| 8/8 [00:00<00:00, 718.56it/s]\n",
      "Train 496 | out_loss 28.364477157592773: 100%|███| 8/8 [00:00<00:00, 733.53it/s]\n",
      "Train 497 | out_loss 28.306283950805664: 100%|███| 8/8 [00:00<00:00, 715.68it/s]\n",
      "Train 498 | out_loss 28.259845733642578: 100%|███| 8/8 [00:00<00:00, 733.75it/s]\n",
      "Train 499 | out_loss 28.233497619628906: 100%|███| 8/8 [00:00<00:00, 720.93it/s]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 80.1535873413086: 100%|████████| 8/8 [00:00<00:00, 20.71it/s]\n",
      "Train 1 | out_loss 78.85289764404297: 100%|██████| 8/8 [00:00<00:00, 425.45it/s]\n",
      "Train 2 | out_loss 77.63162994384766: 100%|██████| 8/8 [00:00<00:00, 415.79it/s]\n",
      "Train 3 | out_loss 76.94126892089844: 100%|██████| 8/8 [00:00<00:00, 453.95it/s]\n",
      "Train 4 | out_loss 75.74069213867188: 100%|██████| 8/8 [00:00<00:00, 418.96it/s]\n",
      "Train 5 | out_loss 74.44145202636719: 100%|██████| 8/8 [00:00<00:00, 446.26it/s]\n",
      "Train 6 | out_loss 73.45486450195312: 100%|██████| 8/8 [00:00<00:00, 446.65it/s]\n",
      "Train 7 | out_loss 72.40888977050781: 100%|██████| 8/8 [00:00<00:00, 430.86it/s]\n",
      "Train 8 | out_loss 71.02346801757812: 100%|██████| 8/8 [00:00<00:00, 456.96it/s]\n",
      "Train 9 | out_loss 70.07302856445312: 100%|██████| 8/8 [00:00<00:00, 450.81it/s]\n",
      "Train 10 | out_loss 69.06492614746094: 100%|█████| 8/8 [00:00<00:00, 431.23it/s]\n",
      "Train 11 | out_loss 67.95220184326172: 100%|█████| 8/8 [00:00<00:00, 428.23it/s]\n",
      "Train 12 | out_loss 66.9384536743164: 100%|██████| 8/8 [00:00<00:00, 452.53it/s]\n",
      "Train 13 | out_loss 66.08414459228516: 100%|█████| 8/8 [00:00<00:00, 456.70it/s]\n",
      "Train 14 | out_loss 65.2295913696289: 100%|██████| 8/8 [00:00<00:00, 454.73it/s]\n",
      "Train 15 | out_loss 64.23750305175781: 100%|█████| 8/8 [00:00<00:00, 453.98it/s]\n",
      "Train 16 | out_loss 63.40196228027344: 100%|█████| 8/8 [00:00<00:00, 447.95it/s]\n",
      "Train 17 | out_loss 62.513362884521484: 100%|████| 8/8 [00:00<00:00, 449.89it/s]\n",
      "Train 18 | out_loss 61.542842864990234: 100%|████| 8/8 [00:00<00:00, 438.04it/s]\n",
      "Train 19 | out_loss 60.5703125: 100%|████████████| 8/8 [00:00<00:00, 445.08it/s]\n",
      "Train 20 | out_loss 59.60026550292969: 100%|█████| 8/8 [00:00<00:00, 455.04it/s]\n",
      "Train 21 | out_loss 58.63091278076172: 100%|█████| 8/8 [00:00<00:00, 449.51it/s]\n",
      "Train 22 | out_loss 57.67293930053711: 100%|█████| 8/8 [00:00<00:00, 446.58it/s]\n",
      "Train 23 | out_loss 56.70492935180664: 100%|█████| 8/8 [00:00<00:00, 424.51it/s]\n",
      "Train 24 | out_loss 55.74235916137695: 100%|█████| 8/8 [00:00<00:00, 418.92it/s]\n",
      "Train 25 | out_loss 54.78582763671875: 100%|█████| 8/8 [00:00<00:00, 443.55it/s]\n",
      "Train 26 | out_loss 53.83260726928711: 100%|█████| 8/8 [00:00<00:00, 454.88it/s]\n",
      "Train 27 | out_loss 52.87295150756836: 100%|█████| 8/8 [00:00<00:00, 455.46it/s]\n",
      "Train 28 | out_loss 51.91836166381836: 100%|█████| 8/8 [00:00<00:00, 422.88it/s]\n",
      "Train 29 | out_loss 50.96221160888672: 100%|█████| 8/8 [00:00<00:00, 336.26it/s]\n",
      "Train 30 | out_loss 50.0119514465332: 100%|██████| 8/8 [00:00<00:00, 414.34it/s]\n",
      "Train 31 | out_loss 49.06736755371094: 100%|█████| 8/8 [00:00<00:00, 451.33it/s]\n",
      "Train 32 | out_loss 48.11438751220703: 100%|█████| 8/8 [00:00<00:00, 454.82it/s]\n",
      "Train 33 | out_loss 47.174903869628906: 100%|████| 8/8 [00:00<00:00, 456.60it/s]\n",
      "Train 34 | out_loss 46.221710205078125: 100%|████| 8/8 [00:00<00:00, 452.10it/s]\n",
      "Train 35 | out_loss 45.27821731567383: 100%|█████| 8/8 [00:00<00:00, 455.20it/s]\n",
      "Train 36 | out_loss 44.34364700317383: 100%|█████| 8/8 [00:00<00:00, 454.56it/s]\n",
      "Train 37 | out_loss 43.41542434692383: 100%|█████| 8/8 [00:00<00:00, 453.57it/s]\n",
      "Train 38 | out_loss 42.469669342041016: 100%|████| 8/8 [00:00<00:00, 454.38it/s]\n",
      "Train 39 | out_loss 41.53992462158203: 100%|█████| 8/8 [00:00<00:00, 455.99it/s]\n",
      "Train 40 | out_loss 40.61060333251953: 100%|█████| 8/8 [00:00<00:00, 454.69it/s]\n",
      "Train 41 | out_loss 39.6826171875: 100%|█████████| 8/8 [00:00<00:00, 454.90it/s]\n",
      "Train 42 | out_loss 38.75199508666992: 100%|█████| 8/8 [00:00<00:00, 455.80it/s]\n",
      "Train 43 | out_loss 37.82914352416992: 100%|█████| 8/8 [00:00<00:00, 453.71it/s]\n",
      "Train 44 | out_loss 36.918601989746094: 100%|████| 8/8 [00:00<00:00, 455.18it/s]\n",
      "Train 45 | out_loss 35.995216369628906: 100%|████| 8/8 [00:00<00:00, 454.62it/s]\n",
      "Train 46 | out_loss 35.082374572753906: 100%|████| 8/8 [00:00<00:00, 454.51it/s]\n",
      "Train 47 | out_loss 34.18341827392578: 100%|█████| 8/8 [00:00<00:00, 454.51it/s]\n",
      "Train 48 | out_loss 33.27722930908203: 100%|█████| 8/8 [00:00<00:00, 455.00it/s]\n",
      "Train 49 | out_loss 32.3782958984375: 100%|██████| 8/8 [00:00<00:00, 453.57it/s]\n",
      "Train 50 | out_loss 31.482036590576172: 100%|████| 8/8 [00:00<00:00, 453.55it/s]\n",
      "Train 51 | out_loss 30.5980167388916: 100%|██████| 8/8 [00:00<00:00, 450.46it/s]\n",
      "Train 52 | out_loss 29.715803146362305: 100%|████| 8/8 [00:00<00:00, 450.19it/s]\n",
      "Train 53 | out_loss 28.84500503540039: 100%|█████| 8/8 [00:00<00:00, 456.95it/s]\n",
      "Train 54 | out_loss 27.981260299682617: 100%|████| 8/8 [00:00<00:00, 452.19it/s]\n",
      "Train 55 | out_loss 27.121723175048828: 100%|████| 8/8 [00:00<00:00, 322.79it/s]\n",
      "Train 56 | out_loss 26.262697219848633: 100%|████| 8/8 [00:00<00:00, 360.04it/s]\n",
      "Train 57 | out_loss 25.430986404418945: 100%|████| 8/8 [00:00<00:00, 452.05it/s]\n",
      "Train 58 | out_loss 24.599430084228516: 100%|████| 8/8 [00:00<00:00, 453.60it/s]\n",
      "Train 59 | out_loss 23.7698917388916: 100%|██████| 8/8 [00:00<00:00, 420.84it/s]\n",
      "Train 60 | out_loss 22.964839935302734: 100%|████| 8/8 [00:00<00:00, 433.25it/s]\n",
      "Train 61 | out_loss 22.183380126953125: 100%|████| 8/8 [00:00<00:00, 431.25it/s]\n",
      "Train 62 | out_loss 21.41937828063965: 100%|█████| 8/8 [00:00<00:00, 450.43it/s]\n",
      "Train 63 | out_loss 20.64536476135254: 100%|█████| 8/8 [00:00<00:00, 453.30it/s]\n",
      "Train 64 | out_loss 19.92547035217285: 100%|█████| 8/8 [00:00<00:00, 450.93it/s]\n",
      "Train 65 | out_loss 19.267309188842773: 100%|████| 8/8 [00:00<00:00, 448.91it/s]\n",
      "Train 66 | out_loss 18.54527473449707: 100%|█████| 8/8 [00:00<00:00, 457.21it/s]\n",
      "Train 67 | out_loss 17.962186813354492: 100%|████| 8/8 [00:00<00:00, 444.26it/s]\n",
      "Train 68 | out_loss 17.34348487854004: 100%|█████| 8/8 [00:00<00:00, 451.90it/s]\n",
      "Train 69 | out_loss 16.810340881347656: 100%|████| 8/8 [00:00<00:00, 439.40it/s]\n",
      "Train 70 | out_loss 16.335155487060547: 100%|████| 8/8 [00:00<00:00, 453.88it/s]\n",
      "Train 71 | out_loss 15.93288516998291: 100%|█████| 8/8 [00:00<00:00, 449.00it/s]\n",
      "Train 72 | out_loss 15.527359008789062: 100%|████| 8/8 [00:00<00:00, 444.32it/s]\n",
      "Train 73 | out_loss 15.160456657409668: 100%|████| 8/8 [00:00<00:00, 450.73it/s]\n",
      "Train 74 | out_loss 14.913413047790527: 100%|████| 8/8 [00:00<00:00, 454.69it/s]\n",
      "Train 75 | out_loss 14.557647705078125: 100%|████| 8/8 [00:00<00:00, 456.49it/s]\n",
      "Train 76 | out_loss 14.506523132324219: 100%|████| 8/8 [00:00<00:00, 459.95it/s]\n",
      "Train 77 | out_loss 14.187586784362793: 100%|████| 8/8 [00:00<00:00, 452.25it/s]\n",
      "Train 78 | out_loss 14.020578384399414: 100%|████| 8/8 [00:00<00:00, 455.56it/s]\n",
      "Train 79 | out_loss 13.800710678100586: 100%|████| 8/8 [00:00<00:00, 454.17it/s]\n",
      "Train 80 | out_loss 13.630136489868164: 100%|████| 8/8 [00:00<00:00, 453.89it/s]\n",
      "Train 81 | out_loss 13.485675811767578: 100%|████| 8/8 [00:00<00:00, 428.79it/s]\n",
      "Train 82 | out_loss 13.373050689697266: 100%|████| 8/8 [00:00<00:00, 450.60it/s]\n",
      "Train 83 | out_loss 13.29751968383789: 100%|█████| 8/8 [00:00<00:00, 451.05it/s]\n",
      "Train 84 | out_loss 13.208074569702148: 100%|████| 8/8 [00:00<00:00, 438.51it/s]\n",
      "Train 85 | out_loss 13.166135787963867: 100%|████| 8/8 [00:00<00:00, 460.06it/s]\n",
      "Train 86 | out_loss 13.132943153381348: 100%|████| 8/8 [00:00<00:00, 450.13it/s]\n",
      "Train 87 | out_loss 13.112497329711914: 100%|████| 8/8 [00:00<00:00, 451.04it/s]\n",
      "Train 88 | out_loss 13.097146034240723: 100%|████| 8/8 [00:00<00:00, 430.04it/s]\n",
      "Train 89 | out_loss 13.089726448059082: 100%|████| 8/8 [00:00<00:00, 452.63it/s]\n",
      "Train 90 | out_loss 13.08996295928955: 100%|█████| 8/8 [00:00<00:00, 458.65it/s]\n",
      "Train 91 | out_loss 13.09351634979248: 100%|█████| 8/8 [00:00<00:00, 454.92it/s]\n",
      "Train 92 | out_loss 13.094486236572266: 100%|████| 8/8 [00:00<00:00, 455.50it/s]\n",
      "Train 93 | out_loss 13.10686206817627: 100%|█████| 8/8 [00:00<00:00, 454.17it/s]\n",
      "Train 94 | out_loss 13.1207275390625: 100%|██████| 8/8 [00:00<00:00, 453.63it/s]\n",
      "Train 95 | out_loss 13.129597663879395: 100%|████| 8/8 [00:00<00:00, 458.03it/s]\n",
      "Train 96 | out_loss 13.155524253845215: 100%|████| 8/8 [00:00<00:00, 445.50it/s]\n",
      "Train 97 | out_loss 13.175305366516113: 100%|████| 8/8 [00:00<00:00, 443.33it/s]\n",
      "Train 98 | out_loss 13.189457893371582: 100%|████| 8/8 [00:00<00:00, 458.14it/s]\n",
      "Train 99 | out_loss 13.212178230285645: 100%|████| 8/8 [00:00<00:00, 457.76it/s]\n",
      "Train 100 | out_loss 13.246774673461914: 100%|███| 8/8 [00:00<00:00, 457.56it/s]\n",
      "Train 101 | out_loss 13.253131866455078: 100%|███| 8/8 [00:00<00:00, 458.51it/s]\n",
      "Train 102 | out_loss 13.293717384338379: 100%|███| 8/8 [00:00<00:00, 459.67it/s]\n",
      "Train 103 | out_loss 13.334282875061035: 100%|███| 8/8 [00:00<00:00, 457.91it/s]\n",
      "Train 104 | out_loss 13.349323272705078: 100%|███| 8/8 [00:00<00:00, 457.57it/s]\n",
      "Train 105 | out_loss 13.377882957458496: 100%|███| 8/8 [00:00<00:00, 458.20it/s]\n",
      "Train 106 | out_loss 13.420791625976562: 100%|███| 8/8 [00:00<00:00, 457.48it/s]\n",
      "Train 107 | out_loss 13.424120903015137: 100%|███| 8/8 [00:00<00:00, 440.49it/s]\n",
      "Train 108 | out_loss 13.493926048278809: 100%|███| 8/8 [00:00<00:00, 443.78it/s]\n",
      "Train 109 | out_loss 13.513444900512695: 100%|███| 8/8 [00:00<00:00, 429.74it/s]\n",
      "Train 110 | out_loss 13.51524543762207: 100%|████| 8/8 [00:00<00:00, 461.56it/s]\n",
      "Train 111 | out_loss 13.571962356567383: 100%|███| 8/8 [00:00<00:00, 433.09it/s]\n",
      "Train 112 | out_loss 13.561198234558105: 100%|███| 8/8 [00:00<00:00, 461.53it/s]\n",
      "Train 113 | out_loss 13.609148979187012: 100%|███| 8/8 [00:00<00:00, 456.52it/s]\n",
      "Train 114 | out_loss 13.623114585876465: 100%|███| 8/8 [00:00<00:00, 462.14it/s]\n",
      "Train 115 | out_loss 13.660391807556152: 100%|███| 8/8 [00:00<00:00, 464.92it/s]\n",
      "Train 116 | out_loss 13.67606258392334: 100%|████| 8/8 [00:00<00:00, 461.69it/s]\n",
      "Train 117 | out_loss 13.745577812194824: 100%|███| 8/8 [00:00<00:00, 420.21it/s]\n",
      "Train 118 | out_loss 13.7710599899292: 100%|█████| 8/8 [00:00<00:00, 418.82it/s]\n",
      "Train 119 | out_loss 13.8202543258667: 100%|█████| 8/8 [00:00<00:00, 445.24it/s]\n",
      "Train 120 | out_loss 13.846323013305664: 100%|███| 8/8 [00:00<00:00, 432.64it/s]\n",
      "Train 121 | out_loss 13.89403247833252: 100%|████| 8/8 [00:00<00:00, 457.01it/s]\n",
      "Train 122 | out_loss 13.993873596191406: 100%|███| 8/8 [00:00<00:00, 459.39it/s]\n",
      "Train 123 | out_loss 13.979303359985352: 100%|███| 8/8 [00:00<00:00, 457.68it/s]\n",
      "Train 124 | out_loss 14.02690601348877: 100%|████| 8/8 [00:00<00:00, 456.71it/s]\n",
      "Train 125 | out_loss 14.011720657348633: 100%|███| 8/8 [00:00<00:00, 441.68it/s]\n",
      "Train 126 | out_loss 14.096369743347168: 100%|███| 8/8 [00:00<00:00, 436.96it/s]\n",
      "Train 127 | out_loss 14.165597915649414: 100%|███| 8/8 [00:00<00:00, 451.32it/s]\n",
      "Train 128 | out_loss 14.119889259338379: 100%|███| 8/8 [00:00<00:00, 447.26it/s]\n",
      "Train 129 | out_loss 14.18429946899414: 100%|████| 8/8 [00:00<00:00, 450.50it/s]\n",
      "Train 130 | out_loss 14.280119895935059: 100%|███| 8/8 [00:00<00:00, 452.21it/s]\n",
      "Train 131 | out_loss 14.233455657958984: 100%|███| 8/8 [00:00<00:00, 440.72it/s]\n",
      "Train 132 | out_loss 14.302013397216797: 100%|███| 8/8 [00:00<00:00, 444.55it/s]\n",
      "Train 133 | out_loss 14.386181831359863: 100%|███| 8/8 [00:00<00:00, 434.11it/s]\n",
      "Train 134 | out_loss 14.399529457092285: 100%|███| 8/8 [00:00<00:00, 456.72it/s]\n",
      "Train 135 | out_loss 14.436427116394043: 100%|███| 8/8 [00:00<00:00, 445.43it/s]\n",
      "Train 136 | out_loss 14.533669471740723: 100%|███| 8/8 [00:00<00:00, 443.94it/s]\n",
      "Train 137 | out_loss 14.580862998962402: 100%|███| 8/8 [00:00<00:00, 459.41it/s]\n",
      "Train 138 | out_loss 14.611279487609863: 100%|███| 8/8 [00:00<00:00, 442.47it/s]\n",
      "Train 139 | out_loss 14.633124351501465: 100%|███| 8/8 [00:00<00:00, 436.14it/s]\n",
      "Train 140 | out_loss 14.757099151611328: 100%|███| 8/8 [00:00<00:00, 423.06it/s]\n",
      "Train 141 | out_loss 14.7505464553833: 100%|█████| 8/8 [00:00<00:00, 436.41it/s]\n",
      "Train 142 | out_loss 14.802390098571777: 100%|███| 8/8 [00:00<00:00, 453.90it/s]\n",
      "Train 143 | out_loss 14.795465469360352: 100%|███| 8/8 [00:00<00:00, 458.63it/s]\n",
      "Train 144 | out_loss 14.862686157226562: 100%|███| 8/8 [00:00<00:00, 461.27it/s]\n",
      "Train 145 | out_loss 14.944770812988281: 100%|███| 8/8 [00:00<00:00, 449.08it/s]\n",
      "Train 146 | out_loss 14.980375289916992: 100%|███| 8/8 [00:00<00:00, 448.52it/s]\n",
      "Train 147 | out_loss 15.029754638671875: 100%|███| 8/8 [00:00<00:00, 437.16it/s]\n",
      "Train 148 | out_loss 15.090850830078125: 100%|███| 8/8 [00:00<00:00, 455.64it/s]\n",
      "Train 149 | out_loss 15.132333755493164: 100%|███| 8/8 [00:00<00:00, 456.00it/s]\n",
      "Train 150 | out_loss 15.128998756408691: 100%|███| 8/8 [00:00<00:00, 432.96it/s]\n",
      "Train 151 | out_loss 15.18517780303955: 100%|████| 8/8 [00:00<00:00, 440.94it/s]\n",
      "Train 152 | out_loss 15.266963005065918: 100%|███| 8/8 [00:00<00:00, 444.45it/s]\n",
      "Train 153 | out_loss 15.236130714416504: 100%|███| 8/8 [00:00<00:00, 444.49it/s]\n",
      "Train 154 | out_loss 15.314852714538574: 100%|███| 8/8 [00:00<00:00, 451.24it/s]\n",
      "Train 155 | out_loss 15.283285140991211: 100%|███| 8/8 [00:00<00:00, 440.60it/s]\n",
      "Train 156 | out_loss 15.39655590057373: 100%|████| 8/8 [00:00<00:00, 445.40it/s]\n",
      "Train 157 | out_loss 15.388421058654785: 100%|███| 8/8 [00:00<00:00, 445.25it/s]\n",
      "Train 158 | out_loss 15.473672866821289: 100%|███| 8/8 [00:00<00:00, 446.13it/s]\n",
      "Train 159 | out_loss 15.462342262268066: 100%|███| 8/8 [00:00<00:00, 455.80it/s]\n",
      "Train 160 | out_loss 15.476693153381348: 100%|███| 8/8 [00:00<00:00, 443.48it/s]\n",
      "Train 161 | out_loss 15.536231994628906: 100%|███| 8/8 [00:00<00:00, 447.23it/s]\n",
      "Train 162 | out_loss 15.560722351074219: 100%|███| 8/8 [00:00<00:00, 434.49it/s]\n",
      "Train 163 | out_loss 15.619349479675293: 100%|███| 8/8 [00:00<00:00, 451.06it/s]\n",
      "Train 164 | out_loss 15.640280723571777: 100%|███| 8/8 [00:00<00:00, 436.34it/s]\n",
      "Train 165 | out_loss 15.7465238571167: 100%|█████| 8/8 [00:00<00:00, 447.99it/s]\n",
      "Train 166 | out_loss 15.751934051513672: 100%|███| 8/8 [00:00<00:00, 455.88it/s]\n",
      "Train 167 | out_loss 15.764041900634766: 100%|███| 8/8 [00:00<00:00, 421.83it/s]\n",
      "Train 168 | out_loss 15.885562896728516: 100%|███| 8/8 [00:00<00:00, 447.14it/s]\n",
      "Train 169 | out_loss 15.955608367919922: 100%|███| 8/8 [00:00<00:00, 437.61it/s]\n",
      "Train 170 | out_loss 15.923929214477539: 100%|███| 8/8 [00:00<00:00, 452.66it/s]\n",
      "Train 171 | out_loss 15.939043045043945: 100%|███| 8/8 [00:00<00:00, 454.46it/s]\n",
      "Train 172 | out_loss 16.072439193725586: 100%|███| 8/8 [00:00<00:00, 441.68it/s]\n",
      "Train 173 | out_loss 16.103694915771484: 100%|███| 8/8 [00:00<00:00, 433.81it/s]\n",
      "Train 174 | out_loss 16.056623458862305: 100%|███| 8/8 [00:00<00:00, 438.05it/s]\n",
      "Train 175 | out_loss 16.132625579833984: 100%|███| 8/8 [00:00<00:00, 359.84it/s]\n",
      "Train 176 | out_loss 16.288238525390625: 100%|███| 8/8 [00:00<00:00, 373.85it/s]\n",
      "Train 177 | out_loss 16.261472702026367: 100%|███| 8/8 [00:00<00:00, 369.31it/s]\n",
      "Train 178 | out_loss 16.339271545410156: 100%|███| 8/8 [00:00<00:00, 366.18it/s]\n",
      "Train 179 | out_loss 16.40494155883789: 100%|████| 8/8 [00:00<00:00, 445.08it/s]\n",
      "Train 180 | out_loss 16.441404342651367: 100%|███| 8/8 [00:00<00:00, 447.38it/s]\n",
      "Train 181 | out_loss 16.522560119628906: 100%|███| 8/8 [00:00<00:00, 445.39it/s]\n",
      "Train 182 | out_loss 16.562923431396484: 100%|███| 8/8 [00:00<00:00, 459.74it/s]\n",
      "Train 183 | out_loss 16.522953033447266: 100%|███| 8/8 [00:00<00:00, 432.14it/s]\n",
      "Train 184 | out_loss 16.58172035217285: 100%|████| 8/8 [00:00<00:00, 433.84it/s]\n",
      "Train 185 | out_loss 16.75962257385254: 100%|████| 8/8 [00:00<00:00, 456.73it/s]\n",
      "Train 186 | out_loss 16.808027267456055: 100%|███| 8/8 [00:00<00:00, 418.70it/s]\n",
      "Train 187 | out_loss 16.757568359375: 100%|██████| 8/8 [00:00<00:00, 453.12it/s]\n",
      "Train 188 | out_loss 16.82048797607422: 100%|████| 8/8 [00:00<00:00, 417.31it/s]\n",
      "Train 189 | out_loss 17.021942138671875: 100%|███| 8/8 [00:00<00:00, 459.54it/s]\n",
      "Train 190 | out_loss 16.980581283569336: 100%|███| 8/8 [00:00<00:00, 457.31it/s]\n",
      "Train 191 | out_loss 17.093950271606445: 100%|███| 8/8 [00:00<00:00, 457.88it/s]\n",
      "Train 192 | out_loss 17.273115158081055: 100%|███| 8/8 [00:00<00:00, 428.45it/s]\n",
      "Train 193 | out_loss 17.264699935913086: 100%|███| 8/8 [00:00<00:00, 417.60it/s]\n",
      "Train 194 | out_loss 17.381492614746094: 100%|███| 8/8 [00:00<00:00, 450.95it/s]\n",
      "Train 195 | out_loss 17.465967178344727: 100%|███| 8/8 [00:00<00:00, 447.68it/s]\n",
      "Train 196 | out_loss 17.518980026245117: 100%|███| 8/8 [00:00<00:00, 457.34it/s]\n",
      "Train 197 | out_loss 17.53024673461914: 100%|████| 8/8 [00:00<00:00, 458.05it/s]\n",
      "Train 198 | out_loss 17.526498794555664: 100%|███| 8/8 [00:00<00:00, 447.82it/s]\n",
      "Train 199 | out_loss 17.66688346862793: 100%|████| 8/8 [00:00<00:00, 431.27it/s]\n",
      "Train 200 | out_loss 17.718385696411133: 100%|███| 8/8 [00:00<00:00, 435.05it/s]\n",
      "Train 201 | out_loss 17.743024826049805: 100%|███| 8/8 [00:00<00:00, 442.51it/s]\n",
      "Train 202 | out_loss 17.860702514648438: 100%|███| 8/8 [00:00<00:00, 457.25it/s]\n",
      "Train 203 | out_loss 17.968923568725586: 100%|███| 8/8 [00:00<00:00, 442.93it/s]\n",
      "Train 204 | out_loss 17.935617446899414: 100%|███| 8/8 [00:00<00:00, 427.54it/s]\n",
      "Train 205 | out_loss 17.98599624633789: 100%|████| 8/8 [00:00<00:00, 449.88it/s]\n",
      "Train 206 | out_loss 18.122154235839844: 100%|███| 8/8 [00:00<00:00, 455.35it/s]\n",
      "Train 207 | out_loss 18.11869239807129: 100%|████| 8/8 [00:00<00:00, 451.29it/s]\n",
      "Train 208 | out_loss 18.08097267150879: 100%|████| 8/8 [00:00<00:00, 448.76it/s]\n",
      "Train 209 | out_loss 18.22228240966797: 100%|████| 8/8 [00:00<00:00, 455.53it/s]\n",
      "Train 210 | out_loss 18.32294273376465: 100%|████| 8/8 [00:00<00:00, 455.62it/s]\n",
      "Train 211 | out_loss 18.38032341003418: 100%|████| 8/8 [00:00<00:00, 452.00it/s]\n",
      "Train 212 | out_loss 18.394729614257812: 100%|███| 8/8 [00:00<00:00, 453.79it/s]\n",
      "Train 213 | out_loss 18.423627853393555: 100%|███| 8/8 [00:00<00:00, 451.14it/s]\n",
      "Train 214 | out_loss 18.468517303466797: 100%|███| 8/8 [00:00<00:00, 449.08it/s]\n",
      "Train 215 | out_loss 18.54745101928711: 100%|████| 8/8 [00:00<00:00, 451.89it/s]\n",
      "Train 216 | out_loss 18.642807006835938: 100%|███| 8/8 [00:00<00:00, 449.87it/s]\n",
      "Train 217 | out_loss 18.712249755859375: 100%|███| 8/8 [00:00<00:00, 447.65it/s]\n",
      "Train 218 | out_loss 18.73595428466797: 100%|████| 8/8 [00:00<00:00, 446.77it/s]\n",
      "Train 219 | out_loss 18.80740737915039: 100%|████| 8/8 [00:00<00:00, 441.33it/s]\n",
      "Train 220 | out_loss 18.891597747802734: 100%|███| 8/8 [00:00<00:00, 420.96it/s]\n",
      "Train 221 | out_loss 18.98171043395996: 100%|████| 8/8 [00:00<00:00, 444.75it/s]\n",
      "Train 222 | out_loss 18.942588806152344: 100%|███| 8/8 [00:00<00:00, 450.29it/s]\n",
      "Train 223 | out_loss 18.994661331176758: 100%|███| 8/8 [00:00<00:00, 450.60it/s]\n",
      "Train 224 | out_loss 19.072139739990234: 100%|███| 8/8 [00:00<00:00, 456.37it/s]\n",
      "Train 225 | out_loss 19.17067527770996: 100%|████| 8/8 [00:00<00:00, 456.06it/s]\n",
      "Train 226 | out_loss 19.136072158813477: 100%|███| 8/8 [00:00<00:00, 435.05it/s]\n",
      "Train 227 | out_loss 19.188308715820312: 100%|███| 8/8 [00:00<00:00, 444.40it/s]\n",
      "Train 228 | out_loss 19.29367446899414: 100%|████| 8/8 [00:00<00:00, 442.72it/s]\n",
      "Train 229 | out_loss 19.37215232849121: 100%|████| 8/8 [00:00<00:00, 457.69it/s]\n",
      "Train 230 | out_loss 19.336048126220703: 100%|███| 8/8 [00:00<00:00, 454.40it/s]\n",
      "Train 231 | out_loss 19.368070602416992: 100%|███| 8/8 [00:00<00:00, 453.41it/s]\n",
      "Train 232 | out_loss 19.499086380004883: 100%|███| 8/8 [00:00<00:00, 461.10it/s]\n",
      "Train 233 | out_loss 19.57820701599121: 100%|████| 8/8 [00:00<00:00, 458.07it/s]\n",
      "Train 234 | out_loss 19.63846206665039: 100%|████| 8/8 [00:00<00:00, 448.47it/s]\n",
      "Train 235 | out_loss 19.708152770996094: 100%|███| 8/8 [00:00<00:00, 452.81it/s]\n",
      "Train 236 | out_loss 19.783405303955078: 100%|███| 8/8 [00:00<00:00, 448.76it/s]\n",
      "Train 237 | out_loss 19.795745849609375: 100%|███| 8/8 [00:00<00:00, 453.71it/s]\n",
      "Train 238 | out_loss 19.98013687133789: 100%|████| 8/8 [00:00<00:00, 412.11it/s]\n",
      "Train 239 | out_loss 20.071914672851562: 100%|███| 8/8 [00:00<00:00, 451.41it/s]\n",
      "Train 240 | out_loss 20.056228637695312: 100%|███| 8/8 [00:00<00:00, 440.62it/s]\n",
      "Train 241 | out_loss 20.133684158325195: 100%|███| 8/8 [00:00<00:00, 458.93it/s]\n",
      "Train 242 | out_loss 20.19568634033203: 100%|████| 8/8 [00:00<00:00, 457.44it/s]\n",
      "Train 243 | out_loss 20.3195858001709: 100%|█████| 8/8 [00:00<00:00, 458.49it/s]\n",
      "Train 244 | out_loss 20.33641815185547: 100%|████| 8/8 [00:00<00:00, 459.69it/s]\n",
      "Train 245 | out_loss 20.434904098510742: 100%|███| 8/8 [00:00<00:00, 444.81it/s]\n",
      "Train 246 | out_loss 20.569129943847656: 100%|███| 8/8 [00:00<00:00, 455.76it/s]\n",
      "Train 247 | out_loss 20.605121612548828: 100%|███| 8/8 [00:00<00:00, 454.70it/s]\n",
      "Train 248 | out_loss 20.79513168334961: 100%|████| 8/8 [00:00<00:00, 456.93it/s]\n",
      "Train 249 | out_loss 20.853687286376953: 100%|███| 8/8 [00:00<00:00, 457.01it/s]\n",
      "Train 250 | out_loss 20.918027877807617: 100%|███| 8/8 [00:00<00:00, 426.33it/s]\n",
      "Train 251 | out_loss 20.994495391845703: 100%|███| 8/8 [00:00<00:00, 446.62it/s]\n",
      "Train 252 | out_loss 21.106531143188477: 100%|███| 8/8 [00:00<00:00, 450.58it/s]\n",
      "Train 253 | out_loss 21.183835983276367: 100%|███| 8/8 [00:00<00:00, 455.69it/s]\n",
      "Train 254 | out_loss 21.287498474121094: 100%|███| 8/8 [00:00<00:00, 434.08it/s]\n",
      "Train 255 | out_loss 21.315492630004883: 100%|███| 8/8 [00:00<00:00, 456.70it/s]\n",
      "Train 256 | out_loss 21.314010620117188: 100%|███| 8/8 [00:00<00:00, 457.07it/s]\n",
      "Train 257 | out_loss 21.411970138549805: 100%|███| 8/8 [00:00<00:00, 442.75it/s]\n",
      "Train 258 | out_loss 21.50048065185547: 100%|████| 8/8 [00:00<00:00, 449.97it/s]\n",
      "Train 259 | out_loss 21.57211685180664: 100%|████| 8/8 [00:00<00:00, 432.46it/s]\n",
      "Train 260 | out_loss 21.602705001831055: 100%|███| 8/8 [00:00<00:00, 450.14it/s]\n",
      "Train 261 | out_loss 21.63619041442871: 100%|████| 8/8 [00:00<00:00, 456.18it/s]\n",
      "Train 262 | out_loss 21.745975494384766: 100%|███| 8/8 [00:00<00:00, 422.33it/s]\n",
      "Train 263 | out_loss 21.813859939575195: 100%|███| 8/8 [00:00<00:00, 450.07it/s]\n",
      "Train 264 | out_loss 21.803638458251953: 100%|███| 8/8 [00:00<00:00, 418.04it/s]\n",
      "Train 265 | out_loss 21.92171287536621: 100%|████| 8/8 [00:00<00:00, 446.72it/s]\n",
      "Train 266 | out_loss 21.99439811706543: 100%|████| 8/8 [00:00<00:00, 437.53it/s]\n",
      "Train 267 | out_loss 22.0335750579834: 100%|█████| 8/8 [00:00<00:00, 440.31it/s]\n",
      "Train 268 | out_loss 22.1742000579834: 100%|█████| 8/8 [00:00<00:00, 443.22it/s]\n",
      "Train 269 | out_loss 22.122962951660156: 100%|███| 8/8 [00:00<00:00, 444.14it/s]\n",
      "Train 270 | out_loss 22.19760513305664: 100%|████| 8/8 [00:00<00:00, 443.37it/s]\n",
      "Train 271 | out_loss 22.254487991333008: 100%|███| 8/8 [00:00<00:00, 451.82it/s]\n",
      "Train 272 | out_loss 22.364788055419922: 100%|███| 8/8 [00:00<00:00, 442.43it/s]\n",
      "Train 273 | out_loss 22.416645050048828: 100%|███| 8/8 [00:00<00:00, 432.47it/s]\n",
      "Train 274 | out_loss 22.525768280029297: 100%|███| 8/8 [00:00<00:00, 455.53it/s]\n",
      "Train 275 | out_loss 22.59037208557129: 100%|████| 8/8 [00:00<00:00, 456.66it/s]\n",
      "Train 276 | out_loss 22.679838180541992: 100%|███| 8/8 [00:00<00:00, 439.02it/s]\n",
      "Train 277 | out_loss 22.784345626831055: 100%|███| 8/8 [00:00<00:00, 433.08it/s]\n",
      "Train 278 | out_loss 22.85622215270996: 100%|████| 8/8 [00:00<00:00, 452.33it/s]\n",
      "Train 279 | out_loss 22.965112686157227: 100%|███| 8/8 [00:00<00:00, 452.08it/s]\n",
      "Train 280 | out_loss 23.002836227416992: 100%|███| 8/8 [00:00<00:00, 444.87it/s]\n",
      "Train 281 | out_loss 23.117122650146484: 100%|███| 8/8 [00:00<00:00, 453.32it/s]\n",
      "Train 282 | out_loss 23.12689971923828: 100%|████| 8/8 [00:00<00:00, 452.50it/s]\n",
      "Train 283 | out_loss 23.217788696289062: 100%|███| 8/8 [00:00<00:00, 440.56it/s]\n",
      "Train 284 | out_loss 23.3435001373291: 100%|█████| 8/8 [00:00<00:00, 436.44it/s]\n",
      "Train 285 | out_loss 23.429683685302734: 100%|███| 8/8 [00:00<00:00, 455.22it/s]\n",
      "Train 286 | out_loss 23.581565856933594: 100%|███| 8/8 [00:00<00:00, 457.09it/s]\n",
      "Train 287 | out_loss 23.667282104492188: 100%|███| 8/8 [00:00<00:00, 451.09it/s]\n",
      "Train 288 | out_loss 23.720712661743164: 100%|███| 8/8 [00:00<00:00, 458.81it/s]\n",
      "Train 289 | out_loss 23.801074981689453: 100%|███| 8/8 [00:00<00:00, 424.98it/s]\n",
      "Train 290 | out_loss 23.908647537231445: 100%|███| 8/8 [00:00<00:00, 458.10it/s]\n",
      "Train 291 | out_loss 23.961992263793945: 100%|███| 8/8 [00:00<00:00, 453.33it/s]\n",
      "Train 292 | out_loss 24.099040985107422: 100%|███| 8/8 [00:00<00:00, 457.76it/s]\n",
      "Train 293 | out_loss 24.19797706604004: 100%|████| 8/8 [00:00<00:00, 448.18it/s]\n",
      "Train 294 | out_loss 24.2813663482666: 100%|█████| 8/8 [00:00<00:00, 455.88it/s]\n",
      "Train 295 | out_loss 24.366411209106445: 100%|███| 8/8 [00:00<00:00, 455.18it/s]\n",
      "Train 296 | out_loss 24.444761276245117: 100%|███| 8/8 [00:00<00:00, 453.10it/s]\n",
      "Train 297 | out_loss 24.529319763183594: 100%|███| 8/8 [00:00<00:00, 435.21it/s]\n",
      "Train 298 | out_loss 24.612232208251953: 100%|███| 8/8 [00:00<00:00, 450.85it/s]\n",
      "Train 299 | out_loss 24.6632137298584: 100%|█████| 8/8 [00:00<00:00, 426.09it/s]\n",
      "Train 300 | out_loss 24.711400985717773: 100%|███| 8/8 [00:00<00:00, 452.66it/s]\n",
      "Train 301 | out_loss 24.792797088623047: 100%|███| 8/8 [00:00<00:00, 456.28it/s]\n",
      "Train 302 | out_loss 24.86272430419922: 100%|████| 8/8 [00:00<00:00, 456.68it/s]\n",
      "Train 303 | out_loss 24.929922103881836: 100%|███| 8/8 [00:00<00:00, 459.49it/s]\n",
      "Train 304 | out_loss 24.991226196289062: 100%|███| 8/8 [00:00<00:00, 452.37it/s]\n",
      "Train 305 | out_loss 25.052961349487305: 100%|███| 8/8 [00:00<00:00, 454.83it/s]\n",
      "Train 306 | out_loss 25.11806869506836: 100%|████| 8/8 [00:00<00:00, 434.22it/s]\n",
      "Train 307 | out_loss 25.153095245361328: 100%|███| 8/8 [00:00<00:00, 406.13it/s]\n",
      "Train 308 | out_loss 25.227006912231445: 100%|███| 8/8 [00:00<00:00, 456.08it/s]\n",
      "Train 309 | out_loss 25.241313934326172: 100%|███| 8/8 [00:00<00:00, 368.16it/s]\n",
      "Train 310 | out_loss 25.30360984802246: 100%|████| 8/8 [00:00<00:00, 431.72it/s]\n",
      "Train 311 | out_loss 25.42984390258789: 100%|████| 8/8 [00:00<00:00, 455.82it/s]\n",
      "Train 312 | out_loss 25.470230102539062: 100%|███| 8/8 [00:00<00:00, 455.06it/s]\n",
      "Train 313 | out_loss 25.514516830444336: 100%|███| 8/8 [00:00<00:00, 460.29it/s]\n",
      "Train 314 | out_loss 25.655061721801758: 100%|███| 8/8 [00:00<00:00, 457.34it/s]\n",
      "Train 315 | out_loss 25.723617553710938: 100%|███| 8/8 [00:00<00:00, 427.16it/s]\n",
      "Train 316 | out_loss 25.81608772277832: 100%|████| 8/8 [00:00<00:00, 401.48it/s]\n",
      "Train 317 | out_loss 25.974000930786133: 100%|███| 8/8 [00:00<00:00, 444.39it/s]\n",
      "Train 318 | out_loss 26.03974723815918: 100%|████| 8/8 [00:00<00:00, 442.66it/s]\n",
      "Train 319 | out_loss 26.14957046508789: 100%|████| 8/8 [00:00<00:00, 459.52it/s]\n",
      "Train 320 | out_loss 26.281139373779297: 100%|███| 8/8 [00:00<00:00, 455.59it/s]\n",
      "Train 321 | out_loss 26.342716217041016: 100%|███| 8/8 [00:00<00:00, 445.72it/s]\n",
      "Train 322 | out_loss 26.467987060546875: 100%|███| 8/8 [00:00<00:00, 436.33it/s]\n",
      "Train 323 | out_loss 26.578105926513672: 100%|███| 8/8 [00:00<00:00, 453.74it/s]\n",
      "Train 324 | out_loss 26.68185806274414: 100%|████| 8/8 [00:00<00:00, 393.17it/s]\n",
      "Train 325 | out_loss 26.769067764282227: 100%|███| 8/8 [00:00<00:00, 412.35it/s]\n",
      "Train 326 | out_loss 26.813669204711914: 100%|███| 8/8 [00:00<00:00, 456.67it/s]\n",
      "Train 327 | out_loss 26.85434341430664: 100%|████| 8/8 [00:00<00:00, 461.51it/s]\n",
      "Train 328 | out_loss 26.950725555419922: 100%|███| 8/8 [00:00<00:00, 455.88it/s]\n",
      "Train 329 | out_loss 27.034780502319336: 100%|███| 8/8 [00:00<00:00, 432.34it/s]\n",
      "Train 330 | out_loss 27.16876220703125: 100%|████| 8/8 [00:00<00:00, 459.43it/s]\n",
      "Train 331 | out_loss 27.244407653808594: 100%|███| 8/8 [00:00<00:00, 459.79it/s]\n",
      "Train 332 | out_loss 27.288658142089844: 100%|███| 8/8 [00:00<00:00, 466.16it/s]\n",
      "Train 333 | out_loss 27.335596084594727: 100%|███| 8/8 [00:00<00:00, 456.65it/s]\n",
      "Train 334 | out_loss 27.386526107788086: 100%|███| 8/8 [00:00<00:00, 442.18it/s]\n",
      "Train 335 | out_loss 27.465864181518555: 100%|███| 8/8 [00:00<00:00, 459.76it/s]\n",
      "Train 336 | out_loss 27.545461654663086: 100%|███| 8/8 [00:00<00:00, 452.47it/s]\n",
      "Train 337 | out_loss 27.588207244873047: 100%|███| 8/8 [00:00<00:00, 452.42it/s]\n",
      "Train 338 | out_loss 27.627487182617188: 100%|███| 8/8 [00:00<00:00, 447.49it/s]\n",
      "Train 339 | out_loss 27.627471923828125: 100%|███| 8/8 [00:00<00:00, 454.72it/s]\n",
      "Train 340 | out_loss 27.762609481811523: 100%|███| 8/8 [00:00<00:00, 453.85it/s]\n",
      "Train 341 | out_loss 27.826255798339844: 100%|███| 8/8 [00:00<00:00, 458.57it/s]\n",
      "Train 342 | out_loss 28.020992279052734: 100%|███| 8/8 [00:00<00:00, 459.44it/s]\n",
      "Train 343 | out_loss 28.176132202148438: 100%|███| 8/8 [00:00<00:00, 446.24it/s]\n",
      "Train 344 | out_loss 28.22393035888672: 100%|████| 8/8 [00:00<00:00, 457.39it/s]\n",
      "Train 345 | out_loss 28.370513916015625: 100%|███| 8/8 [00:00<00:00, 459.78it/s]\n",
      "Train 346 | out_loss 28.46709632873535: 100%|████| 8/8 [00:00<00:00, 456.52it/s]\n",
      "Train 347 | out_loss 28.537002563476562: 100%|███| 8/8 [00:00<00:00, 464.63it/s]\n",
      "Train 348 | out_loss 28.60816192626953: 100%|████| 8/8 [00:00<00:00, 453.04it/s]\n",
      "Train 349 | out_loss 28.637149810791016: 100%|███| 8/8 [00:00<00:00, 448.83it/s]\n",
      "Train 350 | out_loss 28.705718994140625: 100%|███| 8/8 [00:00<00:00, 424.20it/s]\n",
      "Train 351 | out_loss 28.727012634277344: 100%|███| 8/8 [00:00<00:00, 453.23it/s]\n",
      "Train 352 | out_loss 28.874893188476562: 100%|███| 8/8 [00:00<00:00, 450.87it/s]\n",
      "Train 353 | out_loss 28.956945419311523: 100%|███| 8/8 [00:00<00:00, 451.39it/s]\n",
      "Train 354 | out_loss 29.01107406616211: 100%|████| 8/8 [00:00<00:00, 396.29it/s]\n",
      "Train 355 | out_loss 29.07856559753418: 100%|████| 8/8 [00:00<00:00, 403.16it/s]\n",
      "Train 356 | out_loss 29.153623580932617: 100%|███| 8/8 [00:00<00:00, 432.86it/s]\n",
      "Train 357 | out_loss 29.234447479248047: 100%|███| 8/8 [00:00<00:00, 372.46it/s]\n",
      "Train 358 | out_loss 29.33057975769043: 100%|████| 8/8 [00:00<00:00, 361.95it/s]\n",
      "Train 359 | out_loss 29.45987319946289: 100%|████| 8/8 [00:00<00:00, 441.92it/s]\n",
      "Train 360 | out_loss 29.548192977905273: 100%|███| 8/8 [00:00<00:00, 450.87it/s]\n",
      "Train 361 | out_loss 29.658004760742188: 100%|███| 8/8 [00:00<00:00, 459.62it/s]\n",
      "Train 362 | out_loss 29.69426155090332: 100%|████| 8/8 [00:00<00:00, 451.61it/s]\n",
      "Train 363 | out_loss 29.781150817871094: 100%|███| 8/8 [00:00<00:00, 456.96it/s]\n",
      "Train 364 | out_loss 29.937971115112305: 100%|███| 8/8 [00:00<00:00, 452.50it/s]\n",
      "Train 365 | out_loss 30.011890411376953: 100%|███| 8/8 [00:00<00:00, 450.29it/s]\n",
      "Train 366 | out_loss 29.97329330444336: 100%|████| 8/8 [00:00<00:00, 417.98it/s]\n",
      "Train 367 | out_loss 29.97638511657715: 100%|████| 8/8 [00:00<00:00, 420.80it/s]\n",
      "Train 368 | out_loss 30.0841007232666: 100%|█████| 8/8 [00:00<00:00, 445.08it/s]\n",
      "Train 369 | out_loss 30.246902465820312: 100%|███| 8/8 [00:00<00:00, 444.44it/s]\n",
      "Train 370 | out_loss 30.370254516601562: 100%|███| 8/8 [00:00<00:00, 451.98it/s]\n",
      "Train 371 | out_loss 30.314451217651367: 100%|███| 8/8 [00:00<00:00, 432.87it/s]\n",
      "Train 372 | out_loss 30.305620193481445: 100%|███| 8/8 [00:00<00:00, 449.88it/s]\n",
      "Train 373 | out_loss 30.341506958007812: 100%|███| 8/8 [00:00<00:00, 444.74it/s]\n",
      "Train 374 | out_loss 30.647451400756836: 100%|███| 8/8 [00:00<00:00, 445.01it/s]\n",
      "Train 375 | out_loss 30.739500045776367: 100%|███| 8/8 [00:00<00:00, 459.13it/s]\n",
      "Train 376 | out_loss 30.800493240356445: 100%|███| 8/8 [00:00<00:00, 455.67it/s]\n",
      "Train 377 | out_loss 30.8704833984375: 100%|█████| 8/8 [00:00<00:00, 447.57it/s]\n",
      "Train 378 | out_loss 31.071210861206055: 100%|███| 8/8 [00:00<00:00, 456.58it/s]\n",
      "Train 379 | out_loss 31.160425186157227: 100%|███| 8/8 [00:00<00:00, 432.91it/s]\n",
      "Train 380 | out_loss 31.32535743713379: 100%|████| 8/8 [00:00<00:00, 449.98it/s]\n",
      "Train 381 | out_loss 31.413551330566406: 100%|███| 8/8 [00:00<00:00, 454.07it/s]\n",
      "Train 382 | out_loss 31.501033782958984: 100%|███| 8/8 [00:00<00:00, 454.85it/s]\n",
      "Train 383 | out_loss 31.525440216064453: 100%|███| 8/8 [00:00<00:00, 428.94it/s]\n",
      "Train 384 | out_loss 31.499935150146484: 100%|███| 8/8 [00:00<00:00, 454.33it/s]\n",
      "Train 385 | out_loss 31.560054779052734: 100%|███| 8/8 [00:00<00:00, 448.03it/s]\n",
      "Train 386 | out_loss 31.75419807434082: 100%|████| 8/8 [00:00<00:00, 450.21it/s]\n",
      "Train 387 | out_loss 31.844385147094727: 100%|███| 8/8 [00:00<00:00, 451.98it/s]\n",
      "Train 388 | out_loss 31.85620880126953: 100%|████| 8/8 [00:00<00:00, 443.14it/s]\n",
      "Train 389 | out_loss 31.787172317504883: 100%|███| 8/8 [00:00<00:00, 454.82it/s]\n",
      "Train 390 | out_loss 31.769989013671875: 100%|███| 8/8 [00:00<00:00, 456.62it/s]\n",
      "Train 391 | out_loss 31.841339111328125: 100%|███| 8/8 [00:00<00:00, 453.51it/s]\n",
      "Train 392 | out_loss 31.88098907470703: 100%|████| 8/8 [00:00<00:00, 450.85it/s]\n",
      "Train 393 | out_loss 31.88981056213379: 100%|████| 8/8 [00:00<00:00, 458.25it/s]\n",
      "Train 394 | out_loss 32.03245544433594: 100%|████| 8/8 [00:00<00:00, 456.73it/s]\n",
      "Train 395 | out_loss 32.12932205200195: 100%|████| 8/8 [00:00<00:00, 456.59it/s]\n",
      "Train 396 | out_loss 32.1878776550293: 100%|█████| 8/8 [00:00<00:00, 454.87it/s]\n",
      "Train 397 | out_loss 32.158836364746094: 100%|███| 8/8 [00:00<00:00, 446.48it/s]\n",
      "Train 398 | out_loss 32.15534591674805: 100%|████| 8/8 [00:00<00:00, 453.02it/s]\n",
      "Train 399 | out_loss 32.17366027832031: 100%|████| 8/8 [00:00<00:00, 452.12it/s]\n",
      "Train 400 | out_loss 32.2188835144043: 100%|█████| 8/8 [00:00<00:00, 435.20it/s]\n",
      "Train 401 | out_loss 32.24906539916992: 100%|████| 8/8 [00:00<00:00, 424.02it/s]\n",
      "Train 402 | out_loss 32.24888229370117: 100%|████| 8/8 [00:00<00:00, 430.95it/s]\n",
      "Train 403 | out_loss 32.23781967163086: 100%|████| 8/8 [00:00<00:00, 455.54it/s]\n",
      "Train 404 | out_loss 32.23218536376953: 100%|████| 8/8 [00:00<00:00, 432.09it/s]\n",
      "Train 405 | out_loss 32.27090072631836: 100%|████| 8/8 [00:00<00:00, 449.94it/s]\n",
      "Train 406 | out_loss 32.3999137878418: 100%|█████| 8/8 [00:00<00:00, 441.55it/s]\n",
      "Train 407 | out_loss 32.594810485839844: 100%|███| 8/8 [00:00<00:00, 441.84it/s]\n",
      "Train 408 | out_loss 32.5499153137207: 100%|█████| 8/8 [00:00<00:00, 452.66it/s]\n",
      "Train 409 | out_loss 32.49196243286133: 100%|████| 8/8 [00:00<00:00, 454.11it/s]\n",
      "Train 410 | out_loss 32.561241149902344: 100%|███| 8/8 [00:00<00:00, 451.55it/s]\n",
      "Train 411 | out_loss 32.851070404052734: 100%|███| 8/8 [00:00<00:00, 449.97it/s]\n",
      "Train 412 | out_loss 33.07558059692383: 100%|████| 8/8 [00:00<00:00, 453.92it/s]\n",
      "Train 413 | out_loss 33.05162811279297: 100%|████| 8/8 [00:00<00:00, 434.15it/s]\n",
      "Train 414 | out_loss 33.1658935546875: 100%|█████| 8/8 [00:00<00:00, 428.54it/s]\n",
      "Train 415 | out_loss 33.35191345214844: 100%|████| 8/8 [00:00<00:00, 439.98it/s]\n",
      "Train 416 | out_loss 33.47314453125: 100%|███████| 8/8 [00:00<00:00, 449.71it/s]\n",
      "Train 417 | out_loss 33.46368408203125: 100%|████| 8/8 [00:00<00:00, 444.07it/s]\n",
      "Train 418 | out_loss 33.37971115112305: 100%|████| 8/8 [00:00<00:00, 445.26it/s]\n",
      "Train 419 | out_loss 33.340293884277344: 100%|███| 8/8 [00:00<00:00, 455.93it/s]\n",
      "Train 420 | out_loss 33.36695861816406: 100%|████| 8/8 [00:00<00:00, 452.56it/s]\n",
      "Train 421 | out_loss 33.41355514526367: 100%|████| 8/8 [00:00<00:00, 453.89it/s]\n",
      "Train 422 | out_loss 33.43874740600586: 100%|████| 8/8 [00:00<00:00, 453.37it/s]\n",
      "Train 423 | out_loss 33.47136306762695: 100%|████| 8/8 [00:00<00:00, 451.13it/s]\n",
      "Train 424 | out_loss 33.49858093261719: 100%|████| 8/8 [00:00<00:00, 453.64it/s]\n",
      "Train 425 | out_loss 33.5093879699707: 100%|█████| 8/8 [00:00<00:00, 454.11it/s]\n",
      "Train 426 | out_loss 33.4851188659668: 100%|█████| 8/8 [00:00<00:00, 435.92it/s]\n",
      "Train 427 | out_loss 33.472572326660156: 100%|███| 8/8 [00:00<00:00, 451.36it/s]\n",
      "Train 428 | out_loss 33.498382568359375: 100%|███| 8/8 [00:00<00:00, 454.88it/s]\n",
      "Train 429 | out_loss 33.52375030517578: 100%|████| 8/8 [00:00<00:00, 445.76it/s]\n",
      "Train 430 | out_loss 33.5386962890625: 100%|█████| 8/8 [00:00<00:00, 455.89it/s]\n",
      "Train 431 | out_loss 33.545169830322266: 100%|███| 8/8 [00:00<00:00, 450.29it/s]\n",
      "Train 432 | out_loss 33.55447769165039: 100%|████| 8/8 [00:00<00:00, 451.38it/s]\n",
      "Train 433 | out_loss 33.57209014892578: 100%|████| 8/8 [00:00<00:00, 453.70it/s]\n",
      "Train 434 | out_loss 33.56927490234375: 100%|████| 8/8 [00:00<00:00, 456.68it/s]\n",
      "Train 435 | out_loss 33.57569885253906: 100%|████| 8/8 [00:00<00:00, 458.11it/s]\n",
      "Train 436 | out_loss 33.583457946777344: 100%|███| 8/8 [00:00<00:00, 453.45it/s]\n",
      "Train 437 | out_loss 33.58606719970703: 100%|████| 8/8 [00:00<00:00, 455.67it/s]\n",
      "Train 438 | out_loss 33.58027648925781: 100%|████| 8/8 [00:00<00:00, 448.90it/s]\n",
      "Train 439 | out_loss 33.56291961669922: 100%|████| 8/8 [00:00<00:00, 434.47it/s]\n",
      "Train 440 | out_loss 33.55933380126953: 100%|████| 8/8 [00:00<00:00, 451.54it/s]\n",
      "Train 441 | out_loss 33.55528259277344: 100%|████| 8/8 [00:00<00:00, 443.13it/s]\n",
      "Train 442 | out_loss 33.58171081542969: 100%|████| 8/8 [00:00<00:00, 453.29it/s]\n",
      "Train 443 | out_loss 33.53517150878906: 100%|████| 8/8 [00:00<00:00, 453.58it/s]\n",
      "Train 444 | out_loss 33.540653228759766: 100%|███| 8/8 [00:00<00:00, 454.24it/s]\n",
      "Train 445 | out_loss 33.63717269897461: 100%|████| 8/8 [00:00<00:00, 455.69it/s]\n",
      "Train 446 | out_loss 33.644935607910156: 100%|███| 8/8 [00:00<00:00, 455.09it/s]\n",
      "Train 447 | out_loss 33.69786834716797: 100%|████| 8/8 [00:00<00:00, 455.23it/s]\n",
      "Train 448 | out_loss 33.74712371826172: 100%|████| 8/8 [00:00<00:00, 391.38it/s]\n",
      "Train 449 | out_loss 33.75257110595703: 100%|████| 8/8 [00:00<00:00, 346.77it/s]\n",
      "Train 450 | out_loss 33.76972198486328: 100%|████| 8/8 [00:00<00:00, 437.72it/s]\n",
      "Train 451 | out_loss 33.866600036621094: 100%|███| 8/8 [00:00<00:00, 453.46it/s]\n",
      "Train 452 | out_loss 33.97869873046875: 100%|████| 8/8 [00:00<00:00, 452.56it/s]\n",
      "Train 453 | out_loss 33.98059844970703: 100%|████| 8/8 [00:00<00:00, 450.03it/s]\n",
      "Train 454 | out_loss 33.93388366699219: 100%|████| 8/8 [00:00<00:00, 455.79it/s]\n",
      "Train 455 | out_loss 33.921382904052734: 100%|███| 8/8 [00:00<00:00, 455.83it/s]\n",
      "Train 456 | out_loss 33.968570709228516: 100%|███| 8/8 [00:00<00:00, 436.54it/s]\n",
      "Train 457 | out_loss 33.99428939819336: 100%|████| 8/8 [00:00<00:00, 418.05it/s]\n",
      "Train 458 | out_loss 34.07008743286133: 100%|████| 8/8 [00:00<00:00, 356.03it/s]\n",
      "Train 459 | out_loss 34.10597229003906: 100%|████| 8/8 [00:00<00:00, 368.18it/s]\n",
      "Train 460 | out_loss 34.09328842163086: 100%|████| 8/8 [00:00<00:00, 425.40it/s]\n",
      "Train 461 | out_loss 34.12925720214844: 100%|████| 8/8 [00:00<00:00, 401.71it/s]\n",
      "Train 462 | out_loss 34.12429428100586: 100%|████| 8/8 [00:00<00:00, 448.98it/s]\n",
      "Train 463 | out_loss 34.178810119628906: 100%|███| 8/8 [00:00<00:00, 453.68it/s]\n",
      "Train 464 | out_loss 34.182064056396484: 100%|███| 8/8 [00:00<00:00, 453.98it/s]\n",
      "Train 465 | out_loss 34.13203811645508: 100%|████| 8/8 [00:00<00:00, 454.49it/s]\n",
      "Train 466 | out_loss 34.11635208129883: 100%|████| 8/8 [00:00<00:00, 438.71it/s]\n",
      "Train 467 | out_loss 34.14527893066406: 100%|████| 8/8 [00:00<00:00, 450.37it/s]\n",
      "Train 468 | out_loss 34.16914749145508: 100%|████| 8/8 [00:00<00:00, 438.70it/s]\n",
      "Train 469 | out_loss 34.14542007446289: 100%|████| 8/8 [00:00<00:00, 425.02it/s]\n",
      "Train 470 | out_loss 34.14836120605469: 100%|████| 8/8 [00:00<00:00, 435.51it/s]\n",
      "Train 471 | out_loss 34.25150680541992: 100%|████| 8/8 [00:00<00:00, 427.01it/s]\n",
      "Train 472 | out_loss 34.22052764892578: 100%|████| 8/8 [00:00<00:00, 450.79it/s]\n",
      "Train 473 | out_loss 34.16842269897461: 100%|████| 8/8 [00:00<00:00, 453.24it/s]\n",
      "Train 474 | out_loss 34.1544303894043: 100%|█████| 8/8 [00:00<00:00, 450.03it/s]\n",
      "Train 475 | out_loss 34.177940368652344: 100%|███| 8/8 [00:00<00:00, 454.49it/s]\n",
      "Train 476 | out_loss 34.2202262878418: 100%|█████| 8/8 [00:00<00:00, 439.94it/s]\n",
      "Train 477 | out_loss 34.2193489074707: 100%|█████| 8/8 [00:00<00:00, 452.11it/s]\n",
      "Train 478 | out_loss 34.205223083496094: 100%|███| 8/8 [00:00<00:00, 452.50it/s]\n",
      "Train 479 | out_loss 34.20799255371094: 100%|████| 8/8 [00:00<00:00, 436.00it/s]\n",
      "Train 480 | out_loss 34.14397430419922: 100%|████| 8/8 [00:00<00:00, 453.93it/s]\n",
      "Train 481 | out_loss 34.12965393066406: 100%|████| 8/8 [00:00<00:00, 439.19it/s]\n",
      "Train 482 | out_loss 34.2795524597168: 100%|█████| 8/8 [00:00<00:00, 446.73it/s]\n",
      "Train 483 | out_loss 34.22391128540039: 100%|████| 8/8 [00:00<00:00, 448.66it/s]\n",
      "Train 484 | out_loss 34.18690872192383: 100%|████| 8/8 [00:00<00:00, 454.29it/s]\n",
      "Train 485 | out_loss 34.166343688964844: 100%|███| 8/8 [00:00<00:00, 453.40it/s]\n",
      "Train 486 | out_loss 34.202430725097656: 100%|███| 8/8 [00:00<00:00, 457.00it/s]\n",
      "Train 487 | out_loss 34.25246810913086: 100%|████| 8/8 [00:00<00:00, 443.08it/s]\n",
      "Train 488 | out_loss 34.35733413696289: 100%|████| 8/8 [00:00<00:00, 323.57it/s]\n",
      "Train 489 | out_loss 34.33055877685547: 100%|████| 8/8 [00:00<00:00, 356.10it/s]\n",
      "Train 490 | out_loss 34.26935958862305: 100%|████| 8/8 [00:00<00:00, 335.22it/s]\n",
      "Train 491 | out_loss 34.263389587402344: 100%|███| 8/8 [00:00<00:00, 352.84it/s]\n",
      "Train 492 | out_loss 34.35927200317383: 100%|████| 8/8 [00:00<00:00, 455.18it/s]\n",
      "Train 493 | out_loss 34.389183044433594: 100%|███| 8/8 [00:00<00:00, 445.49it/s]\n",
      "Train 494 | out_loss 34.32460403442383: 100%|████| 8/8 [00:00<00:00, 452.19it/s]\n",
      "Train 495 | out_loss 34.36722946166992: 100%|████| 8/8 [00:00<00:00, 453.68it/s]\n",
      "Train 496 | out_loss 34.41395950317383: 100%|████| 8/8 [00:00<00:00, 455.12it/s]\n",
      "Train 497 | out_loss 34.4280891418457: 100%|█████| 8/8 [00:00<00:00, 453.51it/s]\n",
      "Train 498 | out_loss 34.40138244628906: 100%|████| 8/8 [00:00<00:00, 443.40it/s]\n",
      "Train 499 | out_loss 34.403141021728516: 100%|███| 8/8 [00:00<00:00, 451.83it/s]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 80.27472686767578: 100%|███████| 8/8 [00:00<00:00, 19.96it/s]\n",
      "Train 1 | out_loss 79.11065673828125: 100%|██████| 8/8 [00:00<00:00, 329.37it/s]\n",
      "Train 2 | out_loss 77.78433990478516: 100%|██████| 8/8 [00:00<00:00, 329.76it/s]\n",
      "Train 3 | out_loss 76.64713287353516: 100%|██████| 8/8 [00:00<00:00, 329.08it/s]\n",
      "Train 4 | out_loss 75.29220581054688: 100%|██████| 8/8 [00:00<00:00, 266.76it/s]\n",
      "Train 5 | out_loss 73.94082641601562: 100%|██████| 8/8 [00:00<00:00, 289.19it/s]\n",
      "Train 6 | out_loss 72.84768676757812: 100%|██████| 8/8 [00:00<00:00, 330.23it/s]\n",
      "Train 7 | out_loss 71.47258758544922: 100%|██████| 8/8 [00:00<00:00, 309.25it/s]\n",
      "Train 8 | out_loss 70.20819091796875: 100%|██████| 8/8 [00:00<00:00, 307.53it/s]\n",
      "Train 9 | out_loss 68.86492156982422: 100%|██████| 8/8 [00:00<00:00, 330.76it/s]\n",
      "Train 10 | out_loss 67.71471405029297: 100%|█████| 8/8 [00:00<00:00, 324.56it/s]\n",
      "Train 11 | out_loss 66.68711853027344: 100%|█████| 8/8 [00:00<00:00, 314.48it/s]\n",
      "Train 12 | out_loss 65.59674072265625: 100%|█████| 8/8 [00:00<00:00, 324.89it/s]\n",
      "Train 13 | out_loss 64.40650177001953: 100%|█████| 8/8 [00:00<00:00, 329.28it/s]\n",
      "Train 14 | out_loss 63.222537994384766: 100%|████| 8/8 [00:00<00:00, 332.87it/s]\n",
      "Train 15 | out_loss 62.037559509277344: 100%|████| 8/8 [00:00<00:00, 321.86it/s]\n",
      "Train 16 | out_loss 60.846893310546875: 100%|████| 8/8 [00:00<00:00, 312.46it/s]\n",
      "Train 17 | out_loss 59.67097854614258: 100%|█████| 8/8 [00:00<00:00, 326.18it/s]\n",
      "Train 18 | out_loss 58.496543884277344: 100%|████| 8/8 [00:00<00:00, 326.40it/s]\n",
      "Train 19 | out_loss 57.3140754699707: 100%|██████| 8/8 [00:00<00:00, 320.02it/s]\n",
      "Train 20 | out_loss 56.1348991394043: 100%|██████| 8/8 [00:00<00:00, 235.58it/s]\n",
      "Train 21 | out_loss 54.96417999267578: 100%|█████| 8/8 [00:00<00:00, 326.71it/s]\n",
      "Train 22 | out_loss 53.79694366455078: 100%|█████| 8/8 [00:00<00:00, 326.47it/s]\n",
      "Train 23 | out_loss 52.62289810180664: 100%|█████| 8/8 [00:00<00:00, 311.48it/s]\n",
      "Train 24 | out_loss 51.44630813598633: 100%|█████| 8/8 [00:00<00:00, 316.92it/s]\n",
      "Train 25 | out_loss 50.29668426513672: 100%|█████| 8/8 [00:00<00:00, 324.34it/s]\n",
      "Train 26 | out_loss 49.12661361694336: 100%|█████| 8/8 [00:00<00:00, 331.31it/s]\n",
      "Train 27 | out_loss 47.96928024291992: 100%|█████| 8/8 [00:00<00:00, 328.32it/s]\n",
      "Train 28 | out_loss 46.80756759643555: 100%|█████| 8/8 [00:00<00:00, 329.12it/s]\n",
      "Train 29 | out_loss 45.65534973144531: 100%|█████| 8/8 [00:00<00:00, 321.31it/s]\n",
      "Train 30 | out_loss 44.50699996948242: 100%|█████| 8/8 [00:00<00:00, 328.05it/s]\n",
      "Train 31 | out_loss 43.35847473144531: 100%|█████| 8/8 [00:00<00:00, 328.68it/s]\n",
      "Train 32 | out_loss 42.20420837402344: 100%|█████| 8/8 [00:00<00:00, 315.33it/s]\n",
      "Train 33 | out_loss 41.06553649902344: 100%|█████| 8/8 [00:00<00:00, 313.60it/s]\n",
      "Train 34 | out_loss 39.931148529052734: 100%|████| 8/8 [00:00<00:00, 322.32it/s]\n",
      "Train 35 | out_loss 38.79225540161133: 100%|█████| 8/8 [00:00<00:00, 314.48it/s]\n",
      "Train 36 | out_loss 37.65559387207031: 100%|█████| 8/8 [00:00<00:00, 329.48it/s]\n",
      "Train 37 | out_loss 36.53397750854492: 100%|█████| 8/8 [00:00<00:00, 331.21it/s]\n",
      "Train 38 | out_loss 35.419437408447266: 100%|████| 8/8 [00:00<00:00, 323.66it/s]\n",
      "Train 39 | out_loss 34.307151794433594: 100%|████| 8/8 [00:00<00:00, 326.14it/s]\n",
      "Train 40 | out_loss 33.18382263183594: 100%|█████| 8/8 [00:00<00:00, 327.03it/s]\n",
      "Train 41 | out_loss 32.0839729309082: 100%|██████| 8/8 [00:00<00:00, 326.85it/s]\n",
      "Train 42 | out_loss 30.997299194335938: 100%|████| 8/8 [00:00<00:00, 324.19it/s]\n",
      "Train 43 | out_loss 29.901473999023438: 100%|████| 8/8 [00:00<00:00, 328.20it/s]\n",
      "Train 44 | out_loss 28.829689025878906: 100%|████| 8/8 [00:00<00:00, 326.24it/s]\n",
      "Train 45 | out_loss 27.762622833251953: 100%|████| 8/8 [00:00<00:00, 320.98it/s]\n",
      "Train 46 | out_loss 26.71042823791504: 100%|█████| 8/8 [00:00<00:00, 283.53it/s]\n",
      "Train 47 | out_loss 25.66204261779785: 100%|█████| 8/8 [00:00<00:00, 311.12it/s]\n",
      "Train 48 | out_loss 24.627399444580078: 100%|████| 8/8 [00:00<00:00, 311.03it/s]\n",
      "Train 49 | out_loss 23.59815216064453: 100%|█████| 8/8 [00:00<00:00, 329.22it/s]\n",
      "Train 50 | out_loss 22.613737106323242: 100%|████| 8/8 [00:00<00:00, 325.67it/s]\n",
      "Train 51 | out_loss 21.646440505981445: 100%|████| 8/8 [00:00<00:00, 325.68it/s]\n",
      "Train 52 | out_loss 20.703887939453125: 100%|████| 8/8 [00:00<00:00, 326.60it/s]\n",
      "Train 53 | out_loss 19.795238494873047: 100%|████| 8/8 [00:00<00:00, 327.28it/s]\n",
      "Train 54 | out_loss 18.876277923583984: 100%|████| 8/8 [00:00<00:00, 324.87it/s]\n",
      "Train 55 | out_loss 18.01429557800293: 100%|█████| 8/8 [00:00<00:00, 324.76it/s]\n",
      "Train 56 | out_loss 17.188352584838867: 100%|████| 8/8 [00:00<00:00, 324.99it/s]\n",
      "Train 57 | out_loss 16.460416793823242: 100%|████| 8/8 [00:00<00:00, 325.05it/s]\n",
      "Train 58 | out_loss 15.705016136169434: 100%|████| 8/8 [00:00<00:00, 329.06it/s]\n",
      "Train 59 | out_loss 15.065848350524902: 100%|████| 8/8 [00:00<00:00, 330.66it/s]\n",
      "Train 60 | out_loss 14.473668098449707: 100%|████| 8/8 [00:00<00:00, 312.47it/s]\n",
      "Train 61 | out_loss 13.989272117614746: 100%|████| 8/8 [00:00<00:00, 326.77it/s]\n",
      "Train 62 | out_loss 13.565465927124023: 100%|████| 8/8 [00:00<00:00, 322.40it/s]\n",
      "Train 63 | out_loss 13.244124412536621: 100%|████| 8/8 [00:00<00:00, 313.76it/s]\n",
      "Train 64 | out_loss 13.011539459228516: 100%|████| 8/8 [00:00<00:00, 327.15it/s]\n",
      "Train 65 | out_loss 12.89876651763916: 100%|█████| 8/8 [00:00<00:00, 332.13it/s]\n",
      "Train 66 | out_loss 12.905106544494629: 100%|████| 8/8 [00:00<00:00, 330.00it/s]\n",
      "Train 67 | out_loss 12.964421272277832: 100%|████| 8/8 [00:00<00:00, 317.47it/s]\n",
      "Train 68 | out_loss 13.15726375579834: 100%|█████| 8/8 [00:00<00:00, 321.74it/s]\n",
      "Train 69 | out_loss 13.41746997833252: 100%|█████| 8/8 [00:00<00:00, 331.71it/s]\n",
      "Train 70 | out_loss 13.651540756225586: 100%|████| 8/8 [00:00<00:00, 321.46it/s]\n",
      "Train 71 | out_loss 14.148014068603516: 100%|████| 8/8 [00:00<00:00, 331.07it/s]\n",
      "Train 72 | out_loss 14.396918296813965: 100%|████| 8/8 [00:00<00:00, 337.59it/s]\n",
      "Train 73 | out_loss 14.748248100280762: 100%|████| 8/8 [00:00<00:00, 333.55it/s]\n",
      "Train 74 | out_loss 15.245504379272461: 100%|████| 8/8 [00:00<00:00, 321.65it/s]\n",
      "Train 75 | out_loss 15.445294380187988: 100%|████| 8/8 [00:00<00:00, 330.54it/s]\n",
      "Train 76 | out_loss 15.728243827819824: 100%|████| 8/8 [00:00<00:00, 330.25it/s]\n",
      "Train 77 | out_loss 16.314350128173828: 100%|████| 8/8 [00:00<00:00, 335.09it/s]\n",
      "Train 78 | out_loss 16.415014266967773: 100%|████| 8/8 [00:00<00:00, 332.23it/s]\n",
      "Train 79 | out_loss 16.680057525634766: 100%|████| 8/8 [00:00<00:00, 333.06it/s]\n",
      "Train 80 | out_loss 17.411487579345703: 100%|████| 8/8 [00:00<00:00, 331.82it/s]\n",
      "Train 81 | out_loss 17.3207950592041: 100%|██████| 8/8 [00:00<00:00, 327.72it/s]\n",
      "Train 82 | out_loss 17.772205352783203: 100%|████| 8/8 [00:00<00:00, 330.36it/s]\n",
      "Train 83 | out_loss 18.442527770996094: 100%|████| 8/8 [00:00<00:00, 330.40it/s]\n",
      "Train 84 | out_loss 18.41776466369629: 100%|█████| 8/8 [00:00<00:00, 328.05it/s]\n",
      "Train 85 | out_loss 19.31871795654297: 100%|█████| 8/8 [00:00<00:00, 326.10it/s]\n",
      "Train 86 | out_loss 19.9475040435791: 100%|██████| 8/8 [00:00<00:00, 334.72it/s]\n",
      "Train 87 | out_loss 20.39670181274414: 100%|█████| 8/8 [00:00<00:00, 335.71it/s]\n",
      "Train 88 | out_loss 21.314260482788086: 100%|████| 8/8 [00:00<00:00, 328.54it/s]\n",
      "Train 89 | out_loss 21.636232376098633: 100%|████| 8/8 [00:00<00:00, 335.22it/s]\n",
      "Train 90 | out_loss 22.467193603515625: 100%|████| 8/8 [00:00<00:00, 330.44it/s]\n",
      "Train 91 | out_loss 22.745361328125: 100%|███████| 8/8 [00:00<00:00, 334.36it/s]\n",
      "Train 92 | out_loss 23.162982940673828: 100%|████| 8/8 [00:00<00:00, 336.01it/s]\n",
      "Train 93 | out_loss 23.502723693847656: 100%|████| 8/8 [00:00<00:00, 329.64it/s]\n",
      "Train 94 | out_loss 23.808931350708008: 100%|████| 8/8 [00:00<00:00, 327.29it/s]\n",
      "Train 95 | out_loss 23.995067596435547: 100%|████| 8/8 [00:00<00:00, 311.51it/s]\n",
      "Train 96 | out_loss 24.095064163208008: 100%|████| 8/8 [00:00<00:00, 331.64it/s]\n",
      "Train 97 | out_loss 24.365537643432617: 100%|████| 8/8 [00:00<00:00, 329.02it/s]\n",
      "Train 98 | out_loss 24.46700668334961: 100%|█████| 8/8 [00:00<00:00, 330.74it/s]\n",
      "Train 99 | out_loss 24.760793685913086: 100%|████| 8/8 [00:00<00:00, 335.09it/s]\n",
      "Train 100 | out_loss 24.925622940063477: 100%|███| 8/8 [00:00<00:00, 338.87it/s]\n",
      "Train 101 | out_loss 25.072816848754883: 100%|███| 8/8 [00:00<00:00, 332.33it/s]\n",
      "Train 102 | out_loss 25.548656463623047: 100%|███| 8/8 [00:00<00:00, 321.37it/s]\n",
      "Train 103 | out_loss 25.506772994995117: 100%|███| 8/8 [00:00<00:00, 332.27it/s]\n",
      "Train 104 | out_loss 25.941556930541992: 100%|███| 8/8 [00:00<00:00, 328.02it/s]\n",
      "Train 105 | out_loss 26.331483840942383: 100%|███| 8/8 [00:00<00:00, 340.11it/s]\n",
      "Train 106 | out_loss 26.38627052307129: 100%|████| 8/8 [00:00<00:00, 324.69it/s]\n",
      "Train 107 | out_loss 26.559326171875: 100%|██████| 8/8 [00:00<00:00, 325.52it/s]\n",
      "Train 108 | out_loss 26.89383316040039: 100%|████| 8/8 [00:00<00:00, 333.90it/s]\n",
      "Train 109 | out_loss 26.890737533569336: 100%|███| 8/8 [00:00<00:00, 336.35it/s]\n",
      "Train 110 | out_loss 27.14985466003418: 100%|████| 8/8 [00:00<00:00, 334.04it/s]\n",
      "Train 111 | out_loss 27.356834411621094: 100%|███| 8/8 [00:00<00:00, 333.60it/s]\n",
      "Train 112 | out_loss 27.43199348449707: 100%|████| 8/8 [00:00<00:00, 314.09it/s]\n",
      "Train 113 | out_loss 27.497814178466797: 100%|███| 8/8 [00:00<00:00, 316.29it/s]\n",
      "Train 114 | out_loss 27.74172592163086: 100%|████| 8/8 [00:00<00:00, 325.22it/s]\n",
      "Train 115 | out_loss 27.77895164489746: 100%|████| 8/8 [00:00<00:00, 314.67it/s]\n",
      "Train 116 | out_loss 27.844070434570312: 100%|███| 8/8 [00:00<00:00, 330.10it/s]\n",
      "Train 117 | out_loss 28.059358596801758: 100%|███| 8/8 [00:00<00:00, 326.19it/s]\n",
      "Train 118 | out_loss 28.06159019470215: 100%|████| 8/8 [00:00<00:00, 336.48it/s]\n",
      "Train 119 | out_loss 28.196630477905273: 100%|███| 8/8 [00:00<00:00, 333.14it/s]\n",
      "Train 120 | out_loss 28.433961868286133: 100%|███| 8/8 [00:00<00:00, 323.69it/s]\n",
      "Train 121 | out_loss 28.52316665649414: 100%|████| 8/8 [00:00<00:00, 335.87it/s]\n",
      "Train 122 | out_loss 28.72234535217285: 100%|████| 8/8 [00:00<00:00, 338.89it/s]\n",
      "Train 123 | out_loss 28.89205551147461: 100%|████| 8/8 [00:00<00:00, 327.67it/s]\n",
      "Train 124 | out_loss 29.318784713745117: 100%|███| 8/8 [00:00<00:00, 331.42it/s]\n",
      "Train 125 | out_loss 29.24253273010254: 100%|████| 8/8 [00:00<00:00, 332.55it/s]\n",
      "Train 126 | out_loss 29.867952346801758: 100%|███| 8/8 [00:00<00:00, 334.55it/s]\n",
      "Train 127 | out_loss 29.992876052856445: 100%|███| 8/8 [00:00<00:00, 224.91it/s]\n",
      "Train 128 | out_loss 30.289413452148438: 100%|███| 8/8 [00:00<00:00, 278.37it/s]\n",
      "Train 129 | out_loss 30.65547752380371: 100%|████| 8/8 [00:00<00:00, 330.86it/s]\n",
      "Train 130 | out_loss 30.74629020690918: 100%|████| 8/8 [00:00<00:00, 332.82it/s]\n",
      "Train 131 | out_loss 30.982418060302734: 100%|███| 8/8 [00:00<00:00, 305.41it/s]\n",
      "Train 132 | out_loss 31.303081512451172: 100%|███| 8/8 [00:00<00:00, 315.86it/s]\n",
      "Train 133 | out_loss 31.256122589111328: 100%|███| 8/8 [00:00<00:00, 332.41it/s]\n",
      "Train 134 | out_loss 31.538326263427734: 100%|███| 8/8 [00:00<00:00, 338.46it/s]\n",
      "Train 135 | out_loss 31.739290237426758: 100%|███| 8/8 [00:00<00:00, 326.75it/s]\n",
      "Train 136 | out_loss 31.705366134643555: 100%|███| 8/8 [00:00<00:00, 318.99it/s]\n",
      "Train 137 | out_loss 31.835390090942383: 100%|███| 8/8 [00:00<00:00, 321.84it/s]\n",
      "Train 138 | out_loss 31.85471534729004: 100%|████| 8/8 [00:00<00:00, 333.55it/s]\n",
      "Train 139 | out_loss 31.964834213256836: 100%|███| 8/8 [00:00<00:00, 337.81it/s]\n",
      "Train 140 | out_loss 32.117671966552734: 100%|███| 8/8 [00:00<00:00, 338.17it/s]\n",
      "Train 141 | out_loss 32.082618713378906: 100%|███| 8/8 [00:00<00:00, 330.68it/s]\n",
      "Train 142 | out_loss 32.29003143310547: 100%|████| 8/8 [00:00<00:00, 336.96it/s]\n",
      "Train 143 | out_loss 32.23488235473633: 100%|████| 8/8 [00:00<00:00, 329.32it/s]\n",
      "Train 144 | out_loss 32.1611442565918: 100%|█████| 8/8 [00:00<00:00, 326.81it/s]\n",
      "Train 145 | out_loss 32.503082275390625: 100%|███| 8/8 [00:00<00:00, 329.51it/s]\n",
      "Train 146 | out_loss 32.618289947509766: 100%|███| 8/8 [00:00<00:00, 328.96it/s]\n",
      "Train 147 | out_loss 32.46925354003906: 100%|████| 8/8 [00:00<00:00, 317.02it/s]\n",
      "Train 148 | out_loss 32.37128829956055: 100%|████| 8/8 [00:00<00:00, 329.45it/s]\n",
      "Train 149 | out_loss 30.963226318359375: 100%|███| 8/8 [00:00<00:00, 334.23it/s]\n",
      "Train 150 | out_loss 31.862377166748047: 100%|███| 8/8 [00:00<00:00, 332.50it/s]\n",
      "Train 151 | out_loss 30.25450897216797: 100%|████| 8/8 [00:00<00:00, 331.56it/s]\n",
      "Train 152 | out_loss 25.206218719482422: 100%|███| 8/8 [00:00<00:00, 339.93it/s]\n",
      "Train 153 | out_loss 25.349401473999023: 100%|███| 8/8 [00:00<00:00, 332.07it/s]\n",
      "Train 154 | out_loss 23.350488662719727: 100%|███| 8/8 [00:00<00:00, 332.71it/s]\n",
      "Train 155 | out_loss 24.301240921020508: 100%|███| 8/8 [00:00<00:00, 330.77it/s]\n",
      "Train 156 | out_loss 24.347782135009766: 100%|███| 8/8 [00:00<00:00, 319.98it/s]\n",
      "Train 157 | out_loss 23.495431900024414: 100%|███| 8/8 [00:00<00:00, 321.88it/s]\n",
      "Train 158 | out_loss 22.621417999267578: 100%|███| 8/8 [00:00<00:00, 324.07it/s]\n",
      "Train 159 | out_loss 22.269895553588867: 100%|███| 8/8 [00:00<00:00, 331.97it/s]\n",
      "Train 160 | out_loss 22.758947372436523: 100%|███| 8/8 [00:00<00:00, 315.33it/s]\n",
      "Train 161 | out_loss 22.85081672668457: 100%|████| 8/8 [00:00<00:00, 331.34it/s]\n",
      "Train 162 | out_loss 22.82725715637207: 100%|████| 8/8 [00:00<00:00, 312.14it/s]\n",
      "Train 163 | out_loss 22.90142822265625: 100%|████| 8/8 [00:00<00:00, 319.35it/s]\n",
      "Train 164 | out_loss 22.96251678466797: 100%|████| 8/8 [00:00<00:00, 324.17it/s]\n",
      "Train 165 | out_loss 22.943052291870117: 100%|███| 8/8 [00:00<00:00, 323.25it/s]\n",
      "Train 166 | out_loss 22.733020782470703: 100%|███| 8/8 [00:00<00:00, 336.66it/s]\n",
      "Train 167 | out_loss 21.507488250732422: 100%|███| 8/8 [00:00<00:00, 332.59it/s]\n",
      "Train 168 | out_loss 21.577299118041992: 100%|███| 8/8 [00:00<00:00, 335.33it/s]\n",
      "Train 169 | out_loss 21.602252960205078: 100%|███| 8/8 [00:00<00:00, 335.83it/s]\n",
      "Train 170 | out_loss 22.19583511352539: 100%|████| 8/8 [00:00<00:00, 337.55it/s]\n",
      "Train 171 | out_loss 22.06171989440918: 100%|████| 8/8 [00:00<00:00, 331.02it/s]\n",
      "Train 172 | out_loss 22.188705444335938: 100%|███| 8/8 [00:00<00:00, 334.21it/s]\n",
      "Train 173 | out_loss 22.27235221862793: 100%|████| 8/8 [00:00<00:00, 329.14it/s]\n",
      "Train 174 | out_loss 22.39207649230957: 100%|████| 8/8 [00:00<00:00, 310.89it/s]\n",
      "Train 175 | out_loss 22.411725997924805: 100%|███| 8/8 [00:00<00:00, 337.89it/s]\n",
      "Train 176 | out_loss 22.5948543548584: 100%|█████| 8/8 [00:00<00:00, 336.44it/s]\n",
      "Train 177 | out_loss 22.54233741760254: 100%|████| 8/8 [00:00<00:00, 323.85it/s]\n",
      "Train 178 | out_loss 22.675859451293945: 100%|███| 8/8 [00:00<00:00, 275.98it/s]\n",
      "Train 179 | out_loss 22.73305892944336: 100%|████| 8/8 [00:00<00:00, 320.70it/s]\n",
      "Train 180 | out_loss 22.76451301574707: 100%|████| 8/8 [00:00<00:00, 332.20it/s]\n",
      "Train 181 | out_loss 22.86760139465332: 100%|████| 8/8 [00:00<00:00, 334.51it/s]\n",
      "Train 182 | out_loss 22.91794776916504: 100%|████| 8/8 [00:00<00:00, 340.01it/s]\n",
      "Train 183 | out_loss 23.013530731201172: 100%|███| 8/8 [00:00<00:00, 324.42it/s]\n",
      "Train 184 | out_loss 23.08666229248047: 100%|████| 8/8 [00:00<00:00, 334.92it/s]\n",
      "Train 185 | out_loss 23.225339889526367: 100%|███| 8/8 [00:00<00:00, 332.66it/s]\n",
      "Train 186 | out_loss 23.189647674560547: 100%|███| 8/8 [00:00<00:00, 337.06it/s]\n",
      "Train 187 | out_loss 23.32166290283203: 100%|████| 8/8 [00:00<00:00, 325.47it/s]\n",
      "Train 188 | out_loss 23.430654525756836: 100%|███| 8/8 [00:00<00:00, 332.20it/s]\n",
      "Train 189 | out_loss 23.45091438293457: 100%|████| 8/8 [00:00<00:00, 336.51it/s]\n",
      "Train 190 | out_loss 23.46955680847168: 100%|████| 8/8 [00:00<00:00, 333.28it/s]\n",
      "Train 191 | out_loss 23.550025939941406: 100%|███| 8/8 [00:00<00:00, 333.72it/s]\n",
      "Train 192 | out_loss 23.534732818603516: 100%|███| 8/8 [00:00<00:00, 336.03it/s]\n",
      "Train 193 | out_loss 23.643646240234375: 100%|███| 8/8 [00:00<00:00, 323.15it/s]\n",
      "Train 194 | out_loss 23.644906997680664: 100%|███| 8/8 [00:00<00:00, 304.36it/s]\n",
      "Train 195 | out_loss 23.704172134399414: 100%|███| 8/8 [00:00<00:00, 318.50it/s]\n",
      "Train 196 | out_loss 23.797264099121094: 100%|███| 8/8 [00:00<00:00, 314.28it/s]\n",
      "Train 197 | out_loss 23.807815551757812: 100%|███| 8/8 [00:00<00:00, 321.05it/s]\n",
      "Train 198 | out_loss 23.888668060302734: 100%|███| 8/8 [00:00<00:00, 330.73it/s]\n",
      "Train 199 | out_loss 24.005279541015625: 100%|███| 8/8 [00:00<00:00, 319.47it/s]\n",
      "Train 200 | out_loss 24.01505470275879: 100%|████| 8/8 [00:00<00:00, 332.07it/s]\n",
      "Train 201 | out_loss 24.20201873779297: 100%|████| 8/8 [00:00<00:00, 325.54it/s]\n",
      "Train 202 | out_loss 24.246931076049805: 100%|███| 8/8 [00:00<00:00, 309.25it/s]\n",
      "Train 203 | out_loss 24.321147918701172: 100%|███| 8/8 [00:00<00:00, 325.71it/s]\n",
      "Train 204 | out_loss 24.379913330078125: 100%|███| 8/8 [00:00<00:00, 328.70it/s]\n",
      "Train 205 | out_loss 24.48232650756836: 100%|████| 8/8 [00:00<00:00, 327.11it/s]\n",
      "Train 206 | out_loss 24.466184616088867: 100%|███| 8/8 [00:00<00:00, 334.21it/s]\n",
      "Train 207 | out_loss 24.5882511138916: 100%|█████| 8/8 [00:00<00:00, 334.56it/s]\n",
      "Train 208 | out_loss 24.579856872558594: 100%|███| 8/8 [00:00<00:00, 333.69it/s]\n",
      "Train 209 | out_loss 24.65083885192871: 100%|████| 8/8 [00:00<00:00, 336.83it/s]\n",
      "Train 210 | out_loss 24.644004821777344: 100%|███| 8/8 [00:00<00:00, 337.50it/s]\n",
      "Train 211 | out_loss 24.68158531188965: 100%|████| 8/8 [00:00<00:00, 327.61it/s]\n",
      "Train 212 | out_loss 24.788124084472656: 100%|███| 8/8 [00:00<00:00, 327.70it/s]\n",
      "Train 213 | out_loss 24.788991928100586: 100%|███| 8/8 [00:00<00:00, 316.24it/s]\n",
      "Train 214 | out_loss 24.01665496826172: 100%|████| 8/8 [00:00<00:00, 315.70it/s]\n",
      "Train 215 | out_loss 21.212207794189453: 100%|███| 8/8 [00:00<00:00, 335.76it/s]\n",
      "Train 216 | out_loss 21.288223266601562: 100%|███| 8/8 [00:00<00:00, 279.98it/s]\n",
      "Train 217 | out_loss 21.357250213623047: 100%|███| 8/8 [00:00<00:00, 329.81it/s]\n",
      "Train 218 | out_loss 21.40424919128418: 100%|████| 8/8 [00:00<00:00, 330.03it/s]\n",
      "Train 219 | out_loss 21.427858352661133: 100%|███| 8/8 [00:00<00:00, 335.95it/s]\n",
      "Train 220 | out_loss 21.473508834838867: 100%|███| 8/8 [00:00<00:00, 314.45it/s]\n",
      "Train 221 | out_loss 21.532373428344727: 100%|███| 8/8 [00:00<00:00, 268.31it/s]\n",
      "Train 222 | out_loss 21.59971046447754: 100%|████| 8/8 [00:00<00:00, 332.88it/s]\n",
      "Train 223 | out_loss 21.645753860473633: 100%|███| 8/8 [00:00<00:00, 335.80it/s]\n",
      "Train 224 | out_loss 21.60016441345215: 100%|████| 8/8 [00:00<00:00, 313.51it/s]\n",
      "Train 225 | out_loss 21.646860122680664: 100%|███| 8/8 [00:00<00:00, 321.78it/s]\n",
      "Train 226 | out_loss 21.64496421813965: 100%|████| 8/8 [00:00<00:00, 333.46it/s]\n",
      "Train 227 | out_loss 21.727495193481445: 100%|███| 8/8 [00:00<00:00, 337.78it/s]\n",
      "Train 228 | out_loss 21.79208755493164: 100%|████| 8/8 [00:00<00:00, 333.69it/s]\n",
      "Train 229 | out_loss 21.87837791442871: 100%|████| 8/8 [00:00<00:00, 324.51it/s]\n",
      "Train 230 | out_loss 21.960594177246094: 100%|███| 8/8 [00:00<00:00, 335.45it/s]\n",
      "Train 231 | out_loss 22.00910758972168: 100%|████| 8/8 [00:00<00:00, 341.00it/s]\n",
      "Train 232 | out_loss 22.008771896362305: 100%|███| 8/8 [00:00<00:00, 334.46it/s]\n",
      "Train 233 | out_loss 22.119075775146484: 100%|███| 8/8 [00:00<00:00, 333.98it/s]\n",
      "Train 234 | out_loss 22.174501419067383: 100%|███| 8/8 [00:00<00:00, 336.38it/s]\n",
      "Train 235 | out_loss 22.236713409423828: 100%|███| 8/8 [00:00<00:00, 332.76it/s]\n",
      "Train 236 | out_loss 22.282085418701172: 100%|███| 8/8 [00:00<00:00, 334.49it/s]\n",
      "Train 237 | out_loss 22.384078979492188: 100%|███| 8/8 [00:00<00:00, 336.83it/s]\n",
      "Train 238 | out_loss 22.38579559326172: 100%|████| 8/8 [00:00<00:00, 332.89it/s]\n",
      "Train 239 | out_loss 22.413724899291992: 100%|███| 8/8 [00:00<00:00, 333.10it/s]\n",
      "Train 240 | out_loss 22.40614128112793: 100%|████| 8/8 [00:00<00:00, 339.84it/s]\n",
      "Train 241 | out_loss 22.418062210083008: 100%|███| 8/8 [00:00<00:00, 339.42it/s]\n",
      "Train 242 | out_loss 22.429107666015625: 100%|███| 8/8 [00:00<00:00, 325.02it/s]\n",
      "Train 243 | out_loss 22.390657424926758: 100%|███| 8/8 [00:00<00:00, 330.17it/s]\n",
      "Train 244 | out_loss 22.392000198364258: 100%|███| 8/8 [00:00<00:00, 327.41it/s]\n",
      "Train 245 | out_loss 22.425079345703125: 100%|███| 8/8 [00:00<00:00, 313.72it/s]\n",
      "Train 246 | out_loss 23.197126388549805: 100%|███| 8/8 [00:00<00:00, 337.46it/s]\n",
      "Train 247 | out_loss 25.4718074798584: 100%|█████| 8/8 [00:00<00:00, 283.52it/s]\n",
      "Train 248 | out_loss 25.50689697265625: 100%|████| 8/8 [00:00<00:00, 323.32it/s]\n",
      "Train 249 | out_loss 25.537364959716797: 100%|███| 8/8 [00:00<00:00, 311.70it/s]\n",
      "Train 250 | out_loss 25.619821548461914: 100%|███| 8/8 [00:00<00:00, 317.14it/s]\n",
      "Train 251 | out_loss 25.65540313720703: 100%|████| 8/8 [00:00<00:00, 337.31it/s]\n",
      "Train 252 | out_loss 25.672161102294922: 100%|███| 8/8 [00:00<00:00, 334.34it/s]\n",
      "Train 253 | out_loss 25.65998649597168: 100%|████| 8/8 [00:00<00:00, 336.07it/s]\n",
      "Train 254 | out_loss 25.65006446838379: 100%|████| 8/8 [00:00<00:00, 318.75it/s]\n",
      "Train 255 | out_loss 25.611669540405273: 100%|███| 8/8 [00:00<00:00, 329.96it/s]\n",
      "Train 256 | out_loss 25.504188537597656: 100%|███| 8/8 [00:00<00:00, 319.07it/s]\n",
      "Train 257 | out_loss 25.476802825927734: 100%|███| 8/8 [00:00<00:00, 310.89it/s]\n",
      "Train 258 | out_loss 25.50987434387207: 100%|████| 8/8 [00:00<00:00, 321.72it/s]\n",
      "Train 259 | out_loss 25.530038833618164: 100%|███| 8/8 [00:00<00:00, 332.40it/s]\n",
      "Train 260 | out_loss 25.565427780151367: 100%|███| 8/8 [00:00<00:00, 339.30it/s]\n",
      "Train 261 | out_loss 25.556133270263672: 100%|███| 8/8 [00:00<00:00, 338.77it/s]\n",
      "Train 262 | out_loss 25.569353103637695: 100%|███| 8/8 [00:00<00:00, 330.95it/s]\n",
      "Train 263 | out_loss 25.622940063476562: 100%|███| 8/8 [00:00<00:00, 335.26it/s]\n",
      "Train 264 | out_loss 25.647682189941406: 100%|███| 8/8 [00:00<00:00, 335.16it/s]\n",
      "Train 265 | out_loss 25.705293655395508: 100%|███| 8/8 [00:00<00:00, 338.08it/s]\n",
      "Train 266 | out_loss 25.7547550201416: 100%|█████| 8/8 [00:00<00:00, 320.41it/s]\n",
      "Train 267 | out_loss 25.769250869750977: 100%|███| 8/8 [00:00<00:00, 336.05it/s]\n",
      "Train 268 | out_loss 25.798620223999023: 100%|███| 8/8 [00:00<00:00, 331.94it/s]\n",
      "Train 269 | out_loss 25.91730499267578: 100%|████| 8/8 [00:00<00:00, 333.81it/s]\n",
      "Train 270 | out_loss 25.910146713256836: 100%|███| 8/8 [00:00<00:00, 334.81it/s]\n",
      "Train 271 | out_loss 25.88785743713379: 100%|████| 8/8 [00:00<00:00, 335.63it/s]\n",
      "Train 272 | out_loss 25.833688735961914: 100%|███| 8/8 [00:00<00:00, 335.20it/s]\n",
      "Train 273 | out_loss 25.708723068237305: 100%|███| 8/8 [00:00<00:00, 332.13it/s]\n",
      "Train 274 | out_loss 25.62962532043457: 100%|████| 8/8 [00:00<00:00, 326.70it/s]\n",
      "Train 275 | out_loss 25.601215362548828: 100%|███| 8/8 [00:00<00:00, 325.28it/s]\n",
      "Train 276 | out_loss 25.513708114624023: 100%|███| 8/8 [00:00<00:00, 331.86it/s]\n",
      "Train 277 | out_loss 25.61025047302246: 100%|████| 8/8 [00:00<00:00, 329.32it/s]\n",
      "Train 278 | out_loss 25.75325584411621: 100%|████| 8/8 [00:00<00:00, 339.07it/s]\n",
      "Train 279 | out_loss 25.826698303222656: 100%|███| 8/8 [00:00<00:00, 337.83it/s]\n",
      "Train 280 | out_loss 25.965879440307617: 100%|███| 8/8 [00:00<00:00, 323.24it/s]\n",
      "Train 281 | out_loss 26.036611557006836: 100%|███| 8/8 [00:00<00:00, 335.27it/s]\n",
      "Train 282 | out_loss 26.11472511291504: 100%|████| 8/8 [00:00<00:00, 338.54it/s]\n",
      "Train 283 | out_loss 26.138093948364258: 100%|███| 8/8 [00:00<00:00, 336.69it/s]\n",
      "Train 284 | out_loss 26.206789016723633: 100%|███| 8/8 [00:00<00:00, 313.05it/s]\n",
      "Train 285 | out_loss 26.202028274536133: 100%|███| 8/8 [00:00<00:00, 334.59it/s]\n",
      "Train 286 | out_loss 26.25330924987793: 100%|████| 8/8 [00:00<00:00, 316.01it/s]\n",
      "Train 287 | out_loss 26.29573631286621: 100%|████| 8/8 [00:00<00:00, 334.24it/s]\n",
      "Train 288 | out_loss 26.316722869873047: 100%|███| 8/8 [00:00<00:00, 335.79it/s]\n",
      "Train 289 | out_loss 26.260265350341797: 100%|███| 8/8 [00:00<00:00, 330.51it/s]\n",
      "Train 290 | out_loss 26.2186279296875: 100%|█████| 8/8 [00:00<00:00, 333.04it/s]\n",
      "Train 291 | out_loss 26.092388153076172: 100%|███| 8/8 [00:00<00:00, 317.87it/s]\n",
      "Train 292 | out_loss 26.097049713134766: 100%|███| 8/8 [00:00<00:00, 305.14it/s]\n",
      "Train 293 | out_loss 26.095516204833984: 100%|███| 8/8 [00:00<00:00, 329.14it/s]\n",
      "Train 294 | out_loss 26.061504364013672: 100%|███| 8/8 [00:00<00:00, 330.05it/s]\n",
      "Train 295 | out_loss 26.0285701751709: 100%|█████| 8/8 [00:00<00:00, 331.51it/s]\n",
      "Train 296 | out_loss 26.122020721435547: 100%|███| 8/8 [00:00<00:00, 336.58it/s]\n",
      "Train 297 | out_loss 26.187328338623047: 100%|███| 8/8 [00:00<00:00, 337.10it/s]\n",
      "Train 298 | out_loss 26.273569107055664: 100%|███| 8/8 [00:00<00:00, 333.12it/s]\n",
      "Train 299 | out_loss 26.313173294067383: 100%|███| 8/8 [00:00<00:00, 337.25it/s]\n",
      "Train 300 | out_loss 26.181785583496094: 100%|███| 8/8 [00:00<00:00, 322.25it/s]\n",
      "Train 301 | out_loss 26.153715133666992: 100%|███| 8/8 [00:00<00:00, 308.10it/s]\n",
      "Train 302 | out_loss 26.150880813598633: 100%|███| 8/8 [00:00<00:00, 331.31it/s]\n",
      "Train 303 | out_loss 26.204038619995117: 100%|███| 8/8 [00:00<00:00, 338.70it/s]\n",
      "Train 304 | out_loss 26.20174789428711: 100%|████| 8/8 [00:00<00:00, 328.98it/s]\n",
      "Train 305 | out_loss 26.220478057861328: 100%|███| 8/8 [00:00<00:00, 337.85it/s]\n",
      "Train 306 | out_loss 26.238183975219727: 100%|███| 8/8 [00:00<00:00, 329.15it/s]\n",
      "Train 307 | out_loss 26.238008499145508: 100%|███| 8/8 [00:00<00:00, 332.92it/s]\n",
      "Train 308 | out_loss 26.2568359375: 100%|████████| 8/8 [00:00<00:00, 313.91it/s]\n",
      "Train 309 | out_loss 26.289674758911133: 100%|███| 8/8 [00:00<00:00, 254.49it/s]\n",
      "Train 310 | out_loss 26.274776458740234: 100%|███| 8/8 [00:00<00:00, 327.32it/s]\n",
      "Train 311 | out_loss 26.262008666992188: 100%|███| 8/8 [00:00<00:00, 330.05it/s]\n",
      "Train 312 | out_loss 26.19192886352539: 100%|████| 8/8 [00:00<00:00, 331.58it/s]\n",
      "Train 313 | out_loss 26.14732551574707: 100%|████| 8/8 [00:00<00:00, 332.55it/s]\n",
      "Train 314 | out_loss 26.313678741455078: 100%|███| 8/8 [00:00<00:00, 327.67it/s]\n",
      "Train 315 | out_loss 26.33707046508789: 100%|████| 8/8 [00:00<00:00, 320.23it/s]\n",
      "Train 316 | out_loss 26.417097091674805: 100%|███| 8/8 [00:00<00:00, 314.50it/s]\n",
      "Train 317 | out_loss 26.437986373901367: 100%|███| 8/8 [00:00<00:00, 322.69it/s]\n",
      "Train 318 | out_loss 26.53358268737793: 100%|████| 8/8 [00:00<00:00, 331.43it/s]\n",
      "Train 319 | out_loss 26.635225296020508: 100%|███| 8/8 [00:00<00:00, 321.18it/s]\n",
      "Train 320 | out_loss 26.779205322265625: 100%|███| 8/8 [00:00<00:00, 318.36it/s]\n",
      "Train 321 | out_loss 26.888547897338867: 100%|███| 8/8 [00:00<00:00, 328.63it/s]\n",
      "Train 322 | out_loss 26.971696853637695: 100%|███| 8/8 [00:00<00:00, 332.71it/s]\n",
      "Train 323 | out_loss 27.097200393676758: 100%|███| 8/8 [00:00<00:00, 338.50it/s]\n",
      "Train 324 | out_loss 27.041576385498047: 100%|███| 8/8 [00:00<00:00, 332.33it/s]\n",
      "Train 325 | out_loss 27.11784553527832: 100%|████| 8/8 [00:00<00:00, 332.56it/s]\n",
      "Train 326 | out_loss 27.260053634643555: 100%|███| 8/8 [00:00<00:00, 326.91it/s]\n",
      "Train 327 | out_loss 27.42355728149414: 100%|████| 8/8 [00:00<00:00, 329.43it/s]\n",
      "Train 328 | out_loss 27.42526626586914: 100%|████| 8/8 [00:00<00:00, 332.81it/s]\n",
      "Train 329 | out_loss 27.5042781829834: 100%|█████| 8/8 [00:00<00:00, 333.87it/s]\n",
      "Train 330 | out_loss 27.5664119720459: 100%|█████| 8/8 [00:00<00:00, 325.78it/s]\n",
      "Train 331 | out_loss 27.59097671508789: 100%|████| 8/8 [00:00<00:00, 335.19it/s]\n",
      "Train 332 | out_loss 27.567977905273438: 100%|███| 8/8 [00:00<00:00, 334.98it/s]\n",
      "Train 333 | out_loss 27.554805755615234: 100%|███| 8/8 [00:00<00:00, 331.01it/s]\n",
      "Train 334 | out_loss 27.601369857788086: 100%|███| 8/8 [00:00<00:00, 338.52it/s]\n",
      "Train 335 | out_loss 27.747526168823242: 100%|███| 8/8 [00:00<00:00, 334.54it/s]\n",
      "Train 336 | out_loss 27.759511947631836: 100%|███| 8/8 [00:00<00:00, 331.11it/s]\n",
      "Train 337 | out_loss 27.822463989257812: 100%|███| 8/8 [00:00<00:00, 335.87it/s]\n",
      "Train 338 | out_loss 27.88979148864746: 100%|████| 8/8 [00:00<00:00, 335.61it/s]\n",
      "Train 339 | out_loss 28.0590763092041: 100%|█████| 8/8 [00:00<00:00, 331.49it/s]\n",
      "Train 340 | out_loss 27.94903564453125: 100%|████| 8/8 [00:00<00:00, 321.07it/s]\n",
      "Train 341 | out_loss 28.067014694213867: 100%|███| 8/8 [00:00<00:00, 333.09it/s]\n",
      "Train 342 | out_loss 28.390134811401367: 100%|███| 8/8 [00:00<00:00, 335.91it/s]\n",
      "Train 343 | out_loss 28.44974708557129: 100%|████| 8/8 [00:00<00:00, 334.29it/s]\n",
      "Train 344 | out_loss 28.56540870666504: 100%|████| 8/8 [00:00<00:00, 314.37it/s]\n",
      "Train 345 | out_loss 28.721948623657227: 100%|███| 8/8 [00:00<00:00, 312.37it/s]\n",
      "Train 346 | out_loss 28.798818588256836: 100%|███| 8/8 [00:00<00:00, 318.69it/s]\n",
      "Train 347 | out_loss 28.831239700317383: 100%|███| 8/8 [00:00<00:00, 317.11it/s]\n",
      "Train 348 | out_loss 28.94268035888672: 100%|████| 8/8 [00:00<00:00, 327.80it/s]\n",
      "Train 349 | out_loss 28.94064712524414: 100%|████| 8/8 [00:00<00:00, 333.60it/s]\n",
      "Train 350 | out_loss 28.99761390686035: 100%|████| 8/8 [00:00<00:00, 337.33it/s]\n",
      "Train 351 | out_loss 29.046295166015625: 100%|███| 8/8 [00:00<00:00, 332.17it/s]\n",
      "Train 352 | out_loss 29.10342025756836: 100%|████| 8/8 [00:00<00:00, 331.08it/s]\n",
      "Train 353 | out_loss 29.259872436523438: 100%|███| 8/8 [00:00<00:00, 331.63it/s]\n",
      "Train 354 | out_loss 29.42679786682129: 100%|████| 8/8 [00:00<00:00, 332.11it/s]\n",
      "Train 355 | out_loss 29.54960060119629: 100%|████| 8/8 [00:00<00:00, 331.71it/s]\n",
      "Train 356 | out_loss 29.579086303710938: 100%|███| 8/8 [00:00<00:00, 330.13it/s]\n",
      "Train 357 | out_loss 29.63905143737793: 100%|████| 8/8 [00:00<00:00, 332.43it/s]\n",
      "Train 358 | out_loss 29.723739624023438: 100%|███| 8/8 [00:00<00:00, 332.65it/s]\n",
      "Train 359 | out_loss 29.783491134643555: 100%|███| 8/8 [00:00<00:00, 319.16it/s]\n",
      "Train 360 | out_loss 29.9101619720459: 100%|█████| 8/8 [00:00<00:00, 333.76it/s]\n",
      "Train 361 | out_loss 30.00379180908203: 100%|████| 8/8 [00:00<00:00, 316.58it/s]\n",
      "Train 362 | out_loss 30.04940414428711: 100%|████| 8/8 [00:00<00:00, 334.77it/s]\n",
      "Train 363 | out_loss 30.163854598999023: 100%|███| 8/8 [00:00<00:00, 333.92it/s]\n",
      "Train 364 | out_loss 30.20044708251953: 100%|████| 8/8 [00:00<00:00, 329.76it/s]\n",
      "Train 365 | out_loss 30.260841369628906: 100%|███| 8/8 [00:00<00:00, 320.19it/s]\n",
      "Train 366 | out_loss 30.345163345336914: 100%|███| 8/8 [00:00<00:00, 329.66it/s]\n",
      "Train 367 | out_loss 30.42632293701172: 100%|████| 8/8 [00:00<00:00, 326.12it/s]\n",
      "Train 368 | out_loss 30.482187271118164: 100%|███| 8/8 [00:00<00:00, 337.69it/s]\n",
      "Train 369 | out_loss 30.428668975830078: 100%|███| 8/8 [00:00<00:00, 331.72it/s]\n",
      "Train 370 | out_loss 30.514150619506836: 100%|███| 8/8 [00:00<00:00, 328.59it/s]\n",
      "Train 371 | out_loss 30.594261169433594: 100%|███| 8/8 [00:00<00:00, 324.96it/s]\n",
      "Train 372 | out_loss 30.62937355041504: 100%|████| 8/8 [00:00<00:00, 329.79it/s]\n",
      "Train 373 | out_loss 30.80156898498535: 100%|████| 8/8 [00:00<00:00, 333.15it/s]\n",
      "Train 374 | out_loss 30.78740119934082: 100%|████| 8/8 [00:00<00:00, 335.11it/s]\n",
      "Train 375 | out_loss 30.758987426757812: 100%|███| 8/8 [00:00<00:00, 318.53it/s]\n",
      "Train 376 | out_loss 30.86536407470703: 100%|████| 8/8 [00:00<00:00, 332.51it/s]\n",
      "Train 377 | out_loss 31.01906967163086: 100%|████| 8/8 [00:00<00:00, 323.91it/s]\n",
      "Train 378 | out_loss 31.147022247314453: 100%|███| 8/8 [00:00<00:00, 314.65it/s]\n",
      "Train 379 | out_loss 31.213951110839844: 100%|███| 8/8 [00:00<00:00, 338.55it/s]\n",
      "Train 380 | out_loss 31.38859748840332: 100%|████| 8/8 [00:00<00:00, 315.87it/s]\n",
      "Train 381 | out_loss 31.572898864746094: 100%|███| 8/8 [00:00<00:00, 331.19it/s]\n",
      "Train 382 | out_loss 31.67612075805664: 100%|████| 8/8 [00:00<00:00, 323.05it/s]\n",
      "Train 383 | out_loss 31.743770599365234: 100%|███| 8/8 [00:00<00:00, 310.78it/s]\n",
      "Train 384 | out_loss 31.92926025390625: 100%|████| 8/8 [00:00<00:00, 281.74it/s]\n",
      "Train 385 | out_loss 32.086265563964844: 100%|███| 8/8 [00:00<00:00, 313.86it/s]\n",
      "Train 386 | out_loss 32.057228088378906: 100%|███| 8/8 [00:00<00:00, 334.48it/s]\n",
      "Train 387 | out_loss 32.04545974731445: 100%|████| 8/8 [00:00<00:00, 337.62it/s]\n",
      "Train 388 | out_loss 32.07380294799805: 100%|████| 8/8 [00:00<00:00, 330.66it/s]\n",
      "Train 389 | out_loss 32.087432861328125: 100%|███| 8/8 [00:00<00:00, 300.97it/s]\n",
      "Train 390 | out_loss 32.08281707763672: 100%|████| 8/8 [00:00<00:00, 333.38it/s]\n",
      "Train 391 | out_loss 32.05706787109375: 100%|████| 8/8 [00:00<00:00, 328.75it/s]\n",
      "Train 392 | out_loss 32.11324691772461: 100%|████| 8/8 [00:00<00:00, 313.59it/s]\n",
      "Train 393 | out_loss 32.159332275390625: 100%|███| 8/8 [00:00<00:00, 336.12it/s]\n",
      "Train 394 | out_loss 32.219444274902344: 100%|███| 8/8 [00:00<00:00, 339.05it/s]\n",
      "Train 395 | out_loss 32.337196350097656: 100%|███| 8/8 [00:00<00:00, 337.58it/s]\n",
      "Train 396 | out_loss 32.46489715576172: 100%|████| 8/8 [00:00<00:00, 327.82it/s]\n",
      "Train 397 | out_loss 32.470237731933594: 100%|███| 8/8 [00:00<00:00, 328.06it/s]\n",
      "Train 398 | out_loss 32.59910583496094: 100%|████| 8/8 [00:00<00:00, 332.13it/s]\n",
      "Train 399 | out_loss 32.67687225341797: 100%|████| 8/8 [00:00<00:00, 328.77it/s]\n",
      "Train 400 | out_loss 32.75530242919922: 100%|████| 8/8 [00:00<00:00, 337.21it/s]\n",
      "Train 401 | out_loss 32.83062744140625: 100%|████| 8/8 [00:00<00:00, 331.60it/s]\n",
      "Train 402 | out_loss 32.953086853027344: 100%|███| 8/8 [00:00<00:00, 332.86it/s]\n",
      "Train 403 | out_loss 32.950660705566406: 100%|███| 8/8 [00:00<00:00, 328.54it/s]\n",
      "Train 404 | out_loss 32.956398010253906: 100%|███| 8/8 [00:00<00:00, 334.92it/s]\n",
      "Train 405 | out_loss 32.947757720947266: 100%|███| 8/8 [00:00<00:00, 328.02it/s]\n",
      "Train 406 | out_loss 32.96376037597656: 100%|████| 8/8 [00:00<00:00, 313.07it/s]\n",
      "Train 407 | out_loss 32.96016311645508: 100%|████| 8/8 [00:00<00:00, 336.24it/s]\n",
      "Train 408 | out_loss 33.00136184692383: 100%|████| 8/8 [00:00<00:00, 330.04it/s]\n",
      "Train 409 | out_loss 33.15423583984375: 100%|████| 8/8 [00:00<00:00, 323.36it/s]\n",
      "Train 410 | out_loss 33.29307556152344: 100%|████| 8/8 [00:00<00:00, 326.60it/s]\n",
      "Train 411 | out_loss 33.41438293457031: 100%|████| 8/8 [00:00<00:00, 327.32it/s]\n",
      "Train 412 | out_loss 33.46992492675781: 100%|████| 8/8 [00:00<00:00, 329.04it/s]\n",
      "Train 413 | out_loss 33.61915588378906: 100%|████| 8/8 [00:00<00:00, 327.54it/s]\n",
      "Train 414 | out_loss 33.67530822753906: 100%|████| 8/8 [00:00<00:00, 328.69it/s]\n",
      "Train 415 | out_loss 33.69160079956055: 100%|████| 8/8 [00:00<00:00, 333.99it/s]\n",
      "Train 416 | out_loss 33.67079544067383: 100%|████| 8/8 [00:00<00:00, 324.32it/s]\n",
      "Train 417 | out_loss 33.79449462890625: 100%|████| 8/8 [00:00<00:00, 323.24it/s]\n",
      "Train 418 | out_loss 33.877349853515625: 100%|███| 8/8 [00:00<00:00, 331.41it/s]\n",
      "Train 419 | out_loss 33.9502067565918: 100%|█████| 8/8 [00:00<00:00, 338.80it/s]\n",
      "Train 420 | out_loss 33.905670166015625: 100%|███| 8/8 [00:00<00:00, 332.24it/s]\n",
      "Train 421 | out_loss 33.93132019042969: 100%|████| 8/8 [00:00<00:00, 337.54it/s]\n",
      "Train 422 | out_loss 33.9757194519043: 100%|█████| 8/8 [00:00<00:00, 337.63it/s]\n",
      "Train 423 | out_loss 34.099491119384766: 100%|███| 8/8 [00:00<00:00, 332.39it/s]\n",
      "Train 424 | out_loss 34.160179138183594: 100%|███| 8/8 [00:00<00:00, 317.66it/s]\n",
      "Train 425 | out_loss 34.15583419799805: 100%|████| 8/8 [00:00<00:00, 333.97it/s]\n",
      "Train 426 | out_loss 34.18885040283203: 100%|████| 8/8 [00:00<00:00, 338.20it/s]\n",
      "Train 427 | out_loss 34.23611831665039: 100%|████| 8/8 [00:00<00:00, 332.26it/s]\n",
      "Train 428 | out_loss 34.160770416259766: 100%|███| 8/8 [00:00<00:00, 329.48it/s]\n",
      "Train 429 | out_loss 34.16836166381836: 100%|████| 8/8 [00:00<00:00, 332.73it/s]\n",
      "Train 430 | out_loss 34.17226028442383: 100%|████| 8/8 [00:00<00:00, 331.80it/s]\n",
      "Train 431 | out_loss 34.17965316772461: 100%|████| 8/8 [00:00<00:00, 330.04it/s]\n",
      "Train 432 | out_loss 34.207847595214844: 100%|███| 8/8 [00:00<00:00, 337.63it/s]\n",
      "Train 433 | out_loss 34.32122039794922: 100%|████| 8/8 [00:00<00:00, 332.54it/s]\n",
      "Train 434 | out_loss 34.335853576660156: 100%|███| 8/8 [00:00<00:00, 325.58it/s]\n",
      "Train 435 | out_loss 34.3241081237793: 100%|█████| 8/8 [00:00<00:00, 337.25it/s]\n",
      "Train 436 | out_loss 34.30131530761719: 100%|████| 8/8 [00:00<00:00, 336.73it/s]\n",
      "Train 437 | out_loss 34.287635803222656: 100%|███| 8/8 [00:00<00:00, 335.70it/s]\n",
      "Train 438 | out_loss 34.26368713378906: 100%|████| 8/8 [00:00<00:00, 335.32it/s]\n",
      "Train 439 | out_loss 34.33383560180664: 100%|████| 8/8 [00:00<00:00, 326.31it/s]\n",
      "Train 440 | out_loss 34.413814544677734: 100%|███| 8/8 [00:00<00:00, 334.27it/s]\n",
      "Train 441 | out_loss 34.438106536865234: 100%|███| 8/8 [00:00<00:00, 330.85it/s]\n",
      "Train 442 | out_loss 34.474700927734375: 100%|███| 8/8 [00:00<00:00, 336.62it/s]\n",
      "Train 443 | out_loss 34.45158004760742: 100%|████| 8/8 [00:00<00:00, 338.10it/s]\n",
      "Train 444 | out_loss 34.45539474487305: 100%|████| 8/8 [00:00<00:00, 337.37it/s]\n",
      "Train 445 | out_loss 34.32695007324219: 100%|████| 8/8 [00:00<00:00, 334.01it/s]\n",
      "Train 446 | out_loss 34.30860900878906: 100%|████| 8/8 [00:00<00:00, 334.71it/s]\n",
      "Train 447 | out_loss 34.30335998535156: 100%|████| 8/8 [00:00<00:00, 323.63it/s]\n",
      "Train 448 | out_loss 34.243289947509766: 100%|███| 8/8 [00:00<00:00, 332.11it/s]\n",
      "Train 449 | out_loss 34.1928596496582: 100%|█████| 8/8 [00:00<00:00, 334.59it/s]\n",
      "Train 450 | out_loss 34.21216583251953: 100%|████| 8/8 [00:00<00:00, 339.68it/s]\n",
      "Train 451 | out_loss 34.21720504760742: 100%|████| 8/8 [00:00<00:00, 331.47it/s]\n",
      "Train 452 | out_loss 34.122737884521484: 100%|███| 8/8 [00:00<00:00, 327.93it/s]\n",
      "Train 453 | out_loss 34.130306243896484: 100%|███| 8/8 [00:00<00:00, 301.64it/s]\n",
      "Train 454 | out_loss 34.17555236816406: 100%|████| 8/8 [00:00<00:00, 270.48it/s]\n",
      "Train 455 | out_loss 34.21017074584961: 100%|████| 8/8 [00:00<00:00, 270.23it/s]\n",
      "Train 456 | out_loss 34.19375991821289: 100%|████| 8/8 [00:00<00:00, 276.49it/s]\n",
      "Train 457 | out_loss 34.15653991699219: 100%|████| 8/8 [00:00<00:00, 304.21it/s]\n",
      "Train 458 | out_loss 34.177886962890625: 100%|███| 8/8 [00:00<00:00, 277.44it/s]\n",
      "Train 459 | out_loss 34.201290130615234: 100%|███| 8/8 [00:00<00:00, 287.09it/s]\n",
      "Train 460 | out_loss 34.17860412597656: 100%|████| 8/8 [00:00<00:00, 328.30it/s]\n",
      "Train 461 | out_loss 33.90046310424805: 100%|████| 8/8 [00:00<00:00, 327.31it/s]\n",
      "Train 462 | out_loss 33.64405822753906: 100%|████| 8/8 [00:00<00:00, 258.06it/s]\n",
      "Train 463 | out_loss 33.49449920654297: 100%|████| 8/8 [00:00<00:00, 312.38it/s]\n",
      "Train 464 | out_loss 33.42216491699219: 100%|████| 8/8 [00:00<00:00, 333.32it/s]\n",
      "Train 465 | out_loss 33.336917877197266: 100%|███| 8/8 [00:00<00:00, 338.71it/s]\n",
      "Train 466 | out_loss 33.25663757324219: 100%|████| 8/8 [00:00<00:00, 339.16it/s]\n",
      "Train 467 | out_loss 33.23485565185547: 100%|████| 8/8 [00:00<00:00, 325.57it/s]\n",
      "Train 468 | out_loss 33.22798538208008: 100%|████| 8/8 [00:00<00:00, 335.04it/s]\n",
      "Train 469 | out_loss 33.230377197265625: 100%|███| 8/8 [00:00<00:00, 327.59it/s]\n",
      "Train 470 | out_loss 33.20504379272461: 100%|████| 8/8 [00:00<00:00, 334.12it/s]\n",
      "Train 471 | out_loss 33.24888610839844: 100%|████| 8/8 [00:00<00:00, 329.85it/s]\n",
      "Train 472 | out_loss 33.06425857543945: 100%|████| 8/8 [00:00<00:00, 331.58it/s]\n",
      "Train 473 | out_loss 33.0789680480957: 100%|█████| 8/8 [00:00<00:00, 332.36it/s]\n",
      "Train 474 | out_loss 33.07581329345703: 100%|████| 8/8 [00:00<00:00, 331.77it/s]\n",
      "Train 475 | out_loss 33.02352523803711: 100%|████| 8/8 [00:00<00:00, 318.87it/s]\n",
      "Train 476 | out_loss 33.052425384521484: 100%|███| 8/8 [00:00<00:00, 334.44it/s]\n",
      "Train 477 | out_loss 33.1427116394043: 100%|█████| 8/8 [00:00<00:00, 332.03it/s]\n",
      "Train 478 | out_loss 32.96808624267578: 100%|████| 8/8 [00:00<00:00, 334.32it/s]\n",
      "Train 479 | out_loss 32.259239196777344: 100%|███| 8/8 [00:00<00:00, 336.80it/s]\n",
      "Train 480 | out_loss 31.63360023498535: 100%|████| 8/8 [00:00<00:00, 332.29it/s]\n",
      "Train 481 | out_loss 31.256563186645508: 100%|███| 8/8 [00:00<00:00, 340.62it/s]\n",
      "Train 482 | out_loss 31.056196212768555: 100%|███| 8/8 [00:00<00:00, 336.19it/s]\n",
      "Train 483 | out_loss 30.98576545715332: 100%|████| 8/8 [00:00<00:00, 333.50it/s]\n",
      "Train 484 | out_loss 30.93266487121582: 100%|████| 8/8 [00:00<00:00, 336.88it/s]\n",
      "Train 485 | out_loss 30.896377563476562: 100%|███| 8/8 [00:00<00:00, 332.84it/s]\n",
      "Train 486 | out_loss 30.869625091552734: 100%|███| 8/8 [00:00<00:00, 335.72it/s]\n",
      "Train 487 | out_loss 30.841873168945312: 100%|███| 8/8 [00:00<00:00, 302.23it/s]\n",
      "Train 488 | out_loss 30.82185935974121: 100%|████| 8/8 [00:00<00:00, 328.47it/s]\n",
      "Train 489 | out_loss 30.80577278137207: 100%|████| 8/8 [00:00<00:00, 333.32it/s]\n",
      "Train 490 | out_loss 30.769439697265625: 100%|███| 8/8 [00:00<00:00, 328.88it/s]\n",
      "Train 491 | out_loss 30.74469757080078: 100%|████| 8/8 [00:00<00:00, 330.31it/s]\n",
      "Train 492 | out_loss 30.71439552307129: 100%|████| 8/8 [00:00<00:00, 332.69it/s]\n",
      "Train 493 | out_loss 30.642749786376953: 100%|███| 8/8 [00:00<00:00, 326.82it/s]\n",
      "Train 494 | out_loss 30.662635803222656: 100%|███| 8/8 [00:00<00:00, 335.16it/s]\n",
      "Train 495 | out_loss 30.774822235107422: 100%|███| 8/8 [00:00<00:00, 331.09it/s]\n",
      "Train 496 | out_loss 30.628276824951172: 100%|███| 8/8 [00:00<00:00, 331.76it/s]\n",
      "Train 497 | out_loss 30.78516960144043: 100%|████| 8/8 [00:00<00:00, 335.31it/s]\n",
      "Train 498 | out_loss 30.925207138061523: 100%|███| 8/8 [00:00<00:00, 332.78it/s]\n",
      "Train 499 | out_loss 30.8308048248291: 100%|█████| 8/8 [00:00<00:00, 328.66it/s]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 80.52318572998047: 100%|███████| 8/8 [00:00<00:00, 19.88it/s]\n",
      "Train 1 | out_loss 79.36109924316406: 100%|██████| 8/8 [00:00<00:00, 266.10it/s]\n",
      "Train 2 | out_loss 76.28742980957031: 100%|██████| 8/8 [00:00<00:00, 261.19it/s]\n",
      "Train 3 | out_loss 75.54007720947266: 100%|██████| 8/8 [00:00<00:00, 246.24it/s]\n",
      "Train 4 | out_loss 73.5544662475586: 100%|███████| 8/8 [00:00<00:00, 259.74it/s]\n",
      "Train 5 | out_loss 71.74237060546875: 100%|██████| 8/8 [00:00<00:00, 249.41it/s]\n",
      "Train 6 | out_loss 70.06394958496094: 100%|██████| 8/8 [00:00<00:00, 262.91it/s]\n",
      "Train 7 | out_loss 69.3017578125: 100%|██████████| 8/8 [00:00<00:00, 260.24it/s]\n",
      "Train 8 | out_loss 67.93173217773438: 100%|██████| 8/8 [00:00<00:00, 253.47it/s]\n",
      "Train 9 | out_loss 66.28883361816406: 100%|██████| 8/8 [00:00<00:00, 258.58it/s]\n",
      "Train 10 | out_loss 65.81695556640625: 100%|█████| 8/8 [00:00<00:00, 257.10it/s]\n",
      "Train 11 | out_loss 65.68569946289062: 100%|█████| 8/8 [00:00<00:00, 201.54it/s]\n",
      "Train 12 | out_loss 64.92159271240234: 100%|█████| 8/8 [00:00<00:00, 245.87it/s]\n",
      "Train 13 | out_loss 63.84404373168945: 100%|█████| 8/8 [00:00<00:00, 220.84it/s]\n",
      "Train 14 | out_loss 63.35221862792969: 100%|█████| 8/8 [00:00<00:00, 262.42it/s]\n",
      "Train 15 | out_loss 63.82457733154297: 100%|█████| 8/8 [00:00<00:00, 257.59it/s]\n",
      "Train 16 | out_loss 62.80868148803711: 100%|█████| 8/8 [00:00<00:00, 255.59it/s]\n",
      "Train 17 | out_loss 61.82463836669922: 100%|█████| 8/8 [00:00<00:00, 262.23it/s]\n",
      "Train 18 | out_loss 61.191017150878906: 100%|████| 8/8 [00:00<00:00, 259.04it/s]\n",
      "Train 19 | out_loss 60.03285217285156: 100%|█████| 8/8 [00:00<00:00, 245.35it/s]\n",
      "Train 20 | out_loss 59.03520202636719: 100%|█████| 8/8 [00:00<00:00, 258.03it/s]\n",
      "Train 21 | out_loss 58.20400619506836: 100%|█████| 8/8 [00:00<00:00, 242.73it/s]\n",
      "Train 22 | out_loss 57.170692443847656: 100%|████| 8/8 [00:00<00:00, 257.51it/s]\n",
      "Train 23 | out_loss 56.186763763427734: 100%|████| 8/8 [00:00<00:00, 254.40it/s]\n",
      "Train 24 | out_loss 55.39665603637695: 100%|█████| 8/8 [00:00<00:00, 179.71it/s]\n",
      "Train 25 | out_loss 54.20584487915039: 100%|█████| 8/8 [00:00<00:00, 256.46it/s]\n",
      "Train 26 | out_loss 53.302059173583984: 100%|████| 8/8 [00:00<00:00, 261.34it/s]\n",
      "Train 27 | out_loss 52.32179260253906: 100%|█████| 8/8 [00:00<00:00, 253.70it/s]\n",
      "Train 28 | out_loss 51.344268798828125: 100%|████| 8/8 [00:00<00:00, 253.89it/s]\n",
      "Train 29 | out_loss 50.37797164916992: 100%|█████| 8/8 [00:00<00:00, 251.23it/s]\n",
      "Train 30 | out_loss 49.41810607910156: 100%|█████| 8/8 [00:00<00:00, 257.45it/s]\n",
      "Train 31 | out_loss 48.4703254699707: 100%|██████| 8/8 [00:00<00:00, 248.64it/s]\n",
      "Train 32 | out_loss 47.300682067871094: 100%|████| 8/8 [00:00<00:00, 259.10it/s]\n",
      "Train 33 | out_loss 46.38154983520508: 100%|█████| 8/8 [00:00<00:00, 260.78it/s]\n",
      "Train 34 | out_loss 45.38008499145508: 100%|█████| 8/8 [00:00<00:00, 255.16it/s]\n",
      "Train 35 | out_loss 44.40920639038086: 100%|█████| 8/8 [00:00<00:00, 262.37it/s]\n",
      "Train 36 | out_loss 43.35658645629883: 100%|█████| 8/8 [00:00<00:00, 259.66it/s]\n",
      "Train 37 | out_loss 42.47488021850586: 100%|█████| 8/8 [00:00<00:00, 257.02it/s]\n",
      "Train 38 | out_loss 41.38189697265625: 100%|█████| 8/8 [00:00<00:00, 256.08it/s]\n",
      "Train 39 | out_loss 40.372032165527344: 100%|████| 8/8 [00:00<00:00, 262.19it/s]\n",
      "Train 40 | out_loss 39.41604995727539: 100%|█████| 8/8 [00:00<00:00, 255.09it/s]\n",
      "Train 41 | out_loss 38.513118743896484: 100%|████| 8/8 [00:00<00:00, 257.17it/s]\n",
      "Train 42 | out_loss 37.50019073486328: 100%|█████| 8/8 [00:00<00:00, 260.07it/s]\n",
      "Train 43 | out_loss 36.53092956542969: 100%|█████| 8/8 [00:00<00:00, 259.84it/s]\n",
      "Train 44 | out_loss 35.564666748046875: 100%|████| 8/8 [00:00<00:00, 260.19it/s]\n",
      "Train 45 | out_loss 34.633819580078125: 100%|████| 8/8 [00:00<00:00, 257.54it/s]\n",
      "Train 46 | out_loss 33.61420440673828: 100%|█████| 8/8 [00:00<00:00, 258.30it/s]\n",
      "Train 47 | out_loss 32.70442581176758: 100%|█████| 8/8 [00:00<00:00, 250.80it/s]\n",
      "Train 48 | out_loss 31.817630767822266: 100%|████| 8/8 [00:00<00:00, 245.66it/s]\n",
      "Train 49 | out_loss 30.80524253845215: 100%|█████| 8/8 [00:00<00:00, 249.58it/s]\n",
      "Train 50 | out_loss 29.906850814819336: 100%|████| 8/8 [00:00<00:00, 257.62it/s]\n",
      "Train 51 | out_loss 28.97283363342285: 100%|█████| 8/8 [00:00<00:00, 250.68it/s]\n",
      "Train 52 | out_loss 28.045799255371094: 100%|████| 8/8 [00:00<00:00, 258.70it/s]\n",
      "Train 53 | out_loss 27.16787338256836: 100%|█████| 8/8 [00:00<00:00, 256.96it/s]\n",
      "Train 54 | out_loss 26.233394622802734: 100%|████| 8/8 [00:00<00:00, 259.67it/s]\n",
      "Train 55 | out_loss 25.365915298461914: 100%|████| 8/8 [00:00<00:00, 259.43it/s]\n",
      "Train 56 | out_loss 24.489194869995117: 100%|████| 8/8 [00:00<00:00, 258.95it/s]\n",
      "Train 57 | out_loss 23.60106086730957: 100%|█████| 8/8 [00:00<00:00, 261.27it/s]\n",
      "Train 58 | out_loss 22.782489776611328: 100%|████| 8/8 [00:00<00:00, 259.35it/s]\n",
      "Train 59 | out_loss 21.931663513183594: 100%|████| 8/8 [00:00<00:00, 258.18it/s]\n",
      "Train 60 | out_loss 21.142152786254883: 100%|████| 8/8 [00:00<00:00, 259.58it/s]\n",
      "Train 61 | out_loss 20.34065055847168: 100%|█████| 8/8 [00:00<00:00, 252.54it/s]\n",
      "Train 62 | out_loss 19.572656631469727: 100%|████| 8/8 [00:00<00:00, 258.71it/s]\n",
      "Train 63 | out_loss 18.78618049621582: 100%|█████| 8/8 [00:00<00:00, 261.69it/s]\n",
      "Train 64 | out_loss 18.133331298828125: 100%|████| 8/8 [00:00<00:00, 260.15it/s]\n",
      "Train 65 | out_loss 17.454099655151367: 100%|████| 8/8 [00:00<00:00, 228.54it/s]\n",
      "Train 66 | out_loss 16.785043716430664: 100%|████| 8/8 [00:00<00:00, 258.53it/s]\n",
      "Train 67 | out_loss 16.245872497558594: 100%|████| 8/8 [00:00<00:00, 255.41it/s]\n",
      "Train 68 | out_loss 15.748502731323242: 100%|████| 8/8 [00:00<00:00, 192.50it/s]\n",
      "Train 69 | out_loss 15.304441452026367: 100%|████| 8/8 [00:00<00:00, 238.23it/s]\n",
      "Train 70 | out_loss 14.799893379211426: 100%|████| 8/8 [00:00<00:00, 261.68it/s]\n",
      "Train 71 | out_loss 14.49203872680664: 100%|█████| 8/8 [00:00<00:00, 265.15it/s]\n",
      "Train 72 | out_loss 14.462773323059082: 100%|████| 8/8 [00:00<00:00, 254.56it/s]\n",
      "Train 73 | out_loss 13.866592407226562: 100%|████| 8/8 [00:00<00:00, 260.01it/s]\n",
      "Train 74 | out_loss 13.96901798248291: 100%|█████| 8/8 [00:00<00:00, 259.91it/s]\n",
      "Train 75 | out_loss 13.610627174377441: 100%|████| 8/8 [00:00<00:00, 258.75it/s]\n",
      "Train 76 | out_loss 13.586313247680664: 100%|████| 8/8 [00:00<00:00, 260.26it/s]\n",
      "Train 77 | out_loss 13.510738372802734: 100%|████| 8/8 [00:00<00:00, 252.38it/s]\n",
      "Train 78 | out_loss 13.714762687683105: 100%|████| 8/8 [00:00<00:00, 252.23it/s]\n",
      "Train 79 | out_loss 13.32199478149414: 100%|█████| 8/8 [00:00<00:00, 253.83it/s]\n",
      "Train 80 | out_loss 13.159207344055176: 100%|████| 8/8 [00:00<00:00, 215.91it/s]\n",
      "Train 81 | out_loss 13.767786979675293: 100%|████| 8/8 [00:00<00:00, 250.26it/s]\n",
      "Train 82 | out_loss 13.324416160583496: 100%|████| 8/8 [00:00<00:00, 244.64it/s]\n",
      "Train 83 | out_loss 13.659602165222168: 100%|████| 8/8 [00:00<00:00, 231.90it/s]\n",
      "Train 84 | out_loss 13.184348106384277: 100%|████| 8/8 [00:00<00:00, 247.84it/s]\n",
      "Train 85 | out_loss 13.170197486877441: 100%|████| 8/8 [00:00<00:00, 250.99it/s]\n",
      "Train 86 | out_loss 13.136601448059082: 100%|████| 8/8 [00:00<00:00, 259.99it/s]\n",
      "Train 87 | out_loss 13.14540958404541: 100%|█████| 8/8 [00:00<00:00, 261.99it/s]\n",
      "Train 88 | out_loss 13.06463623046875: 100%|█████| 8/8 [00:00<00:00, 259.49it/s]\n",
      "Train 89 | out_loss 13.086345672607422: 100%|████| 8/8 [00:00<00:00, 252.48it/s]\n",
      "Train 90 | out_loss 13.187528610229492: 100%|████| 8/8 [00:00<00:00, 265.50it/s]\n",
      "Train 91 | out_loss 13.202387809753418: 100%|████| 8/8 [00:00<00:00, 260.65it/s]\n",
      "Train 92 | out_loss 13.55587387084961: 100%|█████| 8/8 [00:00<00:00, 248.46it/s]\n",
      "Train 93 | out_loss 13.863405227661133: 100%|████| 8/8 [00:00<00:00, 257.48it/s]\n",
      "Train 94 | out_loss 13.129021644592285: 100%|████| 8/8 [00:00<00:00, 263.40it/s]\n",
      "Train 95 | out_loss 13.221097946166992: 100%|████| 8/8 [00:00<00:00, 259.20it/s]\n",
      "Train 96 | out_loss 13.270987510681152: 100%|████| 8/8 [00:00<00:00, 262.12it/s]\n",
      "Train 97 | out_loss 13.088600158691406: 100%|████| 8/8 [00:00<00:00, 267.01it/s]\n",
      "Train 98 | out_loss 13.07401180267334: 100%|█████| 8/8 [00:00<00:00, 262.82it/s]\n",
      "Train 99 | out_loss 13.411847114562988: 100%|████| 8/8 [00:00<00:00, 263.66it/s]\n",
      "Train 100 | out_loss 13.041250228881836: 100%|███| 8/8 [00:00<00:00, 252.40it/s]\n",
      "Train 101 | out_loss 13.038078308105469: 100%|███| 8/8 [00:00<00:00, 244.11it/s]\n",
      "Train 102 | out_loss 13.139172554016113: 100%|███| 8/8 [00:00<00:00, 259.83it/s]\n",
      "Train 103 | out_loss 13.293961524963379: 100%|███| 8/8 [00:00<00:00, 265.16it/s]\n",
      "Train 104 | out_loss 13.053378105163574: 100%|███| 8/8 [00:00<00:00, 261.16it/s]\n",
      "Train 105 | out_loss 13.262041091918945: 100%|███| 8/8 [00:00<00:00, 259.08it/s]\n",
      "Train 106 | out_loss 13.068489074707031: 100%|███| 8/8 [00:00<00:00, 255.41it/s]\n",
      "Train 107 | out_loss 13.067327499389648: 100%|███| 8/8 [00:00<00:00, 257.20it/s]\n",
      "Train 108 | out_loss 13.183082580566406: 100%|███| 8/8 [00:00<00:00, 259.63it/s]\n",
      "Train 109 | out_loss 13.051667213439941: 100%|███| 8/8 [00:00<00:00, 256.19it/s]\n",
      "Train 110 | out_loss 13.054383277893066: 100%|███| 8/8 [00:00<00:00, 263.11it/s]\n",
      "Train 111 | out_loss 13.162165641784668: 100%|███| 8/8 [00:00<00:00, 262.80it/s]\n",
      "Train 112 | out_loss 13.027017593383789: 100%|███| 8/8 [00:00<00:00, 262.57it/s]\n",
      "Train 113 | out_loss 13.062727928161621: 100%|███| 8/8 [00:00<00:00, 251.68it/s]\n",
      "Train 114 | out_loss 13.092158317565918: 100%|███| 8/8 [00:00<00:00, 258.01it/s]\n",
      "Train 115 | out_loss 13.063013076782227: 100%|███| 8/8 [00:00<00:00, 256.34it/s]\n",
      "Train 116 | out_loss 13.453560829162598: 100%|███| 8/8 [00:00<00:00, 264.50it/s]\n",
      "Train 117 | out_loss 13.25728988647461: 100%|████| 8/8 [00:00<00:00, 254.49it/s]\n",
      "Train 118 | out_loss 13.564696311950684: 100%|███| 8/8 [00:00<00:00, 244.92it/s]\n",
      "Train 119 | out_loss 13.297053337097168: 100%|███| 8/8 [00:00<00:00, 253.96it/s]\n",
      "Train 120 | out_loss 13.149069786071777: 100%|███| 8/8 [00:00<00:00, 240.40it/s]\n",
      "Train 121 | out_loss 13.14046859741211: 100%|████| 8/8 [00:00<00:00, 252.29it/s]\n",
      "Train 122 | out_loss 13.16137981414795: 100%|████| 8/8 [00:00<00:00, 258.22it/s]\n",
      "Train 123 | out_loss 13.155994415283203: 100%|███| 8/8 [00:00<00:00, 260.79it/s]\n",
      "Train 124 | out_loss 13.079497337341309: 100%|███| 8/8 [00:00<00:00, 252.36it/s]\n",
      "Train 125 | out_loss 13.074655532836914: 100%|███| 8/8 [00:00<00:00, 252.75it/s]\n",
      "Train 126 | out_loss 13.170378684997559: 100%|███| 8/8 [00:00<00:00, 257.83it/s]\n",
      "Train 127 | out_loss 13.318096160888672: 100%|███| 8/8 [00:00<00:00, 252.76it/s]\n",
      "Train 128 | out_loss 13.282465934753418: 100%|███| 8/8 [00:00<00:00, 247.62it/s]\n",
      "Train 129 | out_loss 13.306510925292969: 100%|███| 8/8 [00:00<00:00, 264.36it/s]\n",
      "Train 130 | out_loss 13.235875129699707: 100%|███| 8/8 [00:00<00:00, 255.49it/s]\n",
      "Train 131 | out_loss 13.260873794555664: 100%|███| 8/8 [00:00<00:00, 259.90it/s]\n",
      "Train 132 | out_loss 13.243091583251953: 100%|███| 8/8 [00:00<00:00, 265.90it/s]\n",
      "Train 133 | out_loss 13.225310325622559: 100%|███| 8/8 [00:00<00:00, 256.08it/s]\n",
      "Train 134 | out_loss 13.340746879577637: 100%|███| 8/8 [00:00<00:00, 267.00it/s]\n",
      "Train 135 | out_loss 13.136442184448242: 100%|███| 8/8 [00:00<00:00, 257.00it/s]\n",
      "Train 136 | out_loss 13.035183906555176: 100%|███| 8/8 [00:00<00:00, 260.04it/s]\n",
      "Train 137 | out_loss 13.097907066345215: 100%|███| 8/8 [00:00<00:00, 256.13it/s]\n",
      "Train 138 | out_loss 13.125940322875977: 100%|███| 8/8 [00:00<00:00, 257.02it/s]\n",
      "Train 139 | out_loss 13.08188533782959: 100%|████| 8/8 [00:00<00:00, 251.39it/s]\n",
      "Train 140 | out_loss 13.128873825073242: 100%|███| 8/8 [00:00<00:00, 261.55it/s]\n",
      "Train 141 | out_loss 13.307133674621582: 100%|███| 8/8 [00:00<00:00, 262.76it/s]\n",
      "Train 142 | out_loss 13.406850814819336: 100%|███| 8/8 [00:00<00:00, 261.29it/s]\n",
      "Train 143 | out_loss 13.15371036529541: 100%|████| 8/8 [00:00<00:00, 260.01it/s]\n",
      "Train 144 | out_loss 13.133339881896973: 100%|███| 8/8 [00:00<00:00, 259.94it/s]\n",
      "Train 145 | out_loss 13.092615127563477: 100%|███| 8/8 [00:00<00:00, 258.15it/s]\n",
      "Train 146 | out_loss 13.239876747131348: 100%|███| 8/8 [00:00<00:00, 257.72it/s]\n",
      "Train 147 | out_loss 13.17288589477539: 100%|████| 8/8 [00:00<00:00, 261.72it/s]\n",
      "Train 148 | out_loss 13.188701629638672: 100%|███| 8/8 [00:00<00:00, 263.38it/s]\n",
      "Train 149 | out_loss 13.092917442321777: 100%|███| 8/8 [00:00<00:00, 263.49it/s]\n",
      "Train 150 | out_loss 13.10533618927002: 100%|████| 8/8 [00:00<00:00, 259.31it/s]\n",
      "Train 151 | out_loss 13.064631462097168: 100%|███| 8/8 [00:00<00:00, 261.22it/s]\n",
      "Train 152 | out_loss 13.040627479553223: 100%|███| 8/8 [00:00<00:00, 263.81it/s]\n",
      "Train 153 | out_loss 13.047741889953613: 100%|███| 8/8 [00:00<00:00, 251.65it/s]\n",
      "Train 154 | out_loss 13.050594329833984: 100%|███| 8/8 [00:00<00:00, 258.88it/s]\n",
      "Train 155 | out_loss 13.094230651855469: 100%|███| 8/8 [00:00<00:00, 254.02it/s]\n",
      "Train 156 | out_loss 13.090302467346191: 100%|███| 8/8 [00:00<00:00, 258.60it/s]\n",
      "Train 157 | out_loss 12.989537239074707: 100%|███| 8/8 [00:00<00:00, 248.15it/s]\n",
      "Train 158 | out_loss 13.032307624816895: 100%|███| 8/8 [00:00<00:00, 259.65it/s]\n",
      "Train 159 | out_loss 13.078274726867676: 100%|███| 8/8 [00:00<00:00, 256.40it/s]\n",
      "Train 160 | out_loss 13.015074729919434: 100%|███| 8/8 [00:00<00:00, 248.34it/s]\n",
      "Train 161 | out_loss 12.919389724731445: 100%|███| 8/8 [00:00<00:00, 258.17it/s]\n",
      "Train 162 | out_loss 12.880287170410156: 100%|███| 8/8 [00:00<00:00, 232.41it/s]\n",
      "Train 163 | out_loss 12.910329818725586: 100%|███| 8/8 [00:00<00:00, 250.64it/s]\n",
      "Train 164 | out_loss 12.97984790802002: 100%|████| 8/8 [00:00<00:00, 189.75it/s]\n",
      "Train 165 | out_loss 12.997061729431152: 100%|███| 8/8 [00:00<00:00, 232.10it/s]\n",
      "Train 166 | out_loss 12.996806144714355: 100%|███| 8/8 [00:00<00:00, 256.99it/s]\n",
      "Train 167 | out_loss 12.985771179199219: 100%|███| 8/8 [00:00<00:00, 256.45it/s]\n",
      "Train 168 | out_loss 12.912700653076172: 100%|███| 8/8 [00:00<00:00, 260.95it/s]\n",
      "Train 169 | out_loss 13.115833282470703: 100%|███| 8/8 [00:00<00:00, 260.13it/s]\n",
      "Train 170 | out_loss 13.129436492919922: 100%|███| 8/8 [00:00<00:00, 251.37it/s]\n",
      "Train 171 | out_loss 13.218859672546387: 100%|███| 8/8 [00:00<00:00, 259.80it/s]\n",
      "Train 172 | out_loss 13.284132957458496: 100%|███| 8/8 [00:00<00:00, 262.63it/s]\n",
      "Train 173 | out_loss 13.207908630371094: 100%|███| 8/8 [00:00<00:00, 251.30it/s]\n",
      "Train 174 | out_loss 13.170647621154785: 100%|███| 8/8 [00:00<00:00, 248.26it/s]\n",
      "Train 175 | out_loss 13.054522514343262: 100%|███| 8/8 [00:00<00:00, 252.03it/s]\n",
      "Train 176 | out_loss 13.099237442016602: 100%|███| 8/8 [00:00<00:00, 257.68it/s]\n",
      "Train 177 | out_loss 13.233238220214844: 100%|███| 8/8 [00:00<00:00, 240.59it/s]\n",
      "Train 178 | out_loss 13.118157386779785: 100%|███| 8/8 [00:00<00:00, 262.47it/s]\n",
      "Train 179 | out_loss 13.29488468170166: 100%|████| 8/8 [00:00<00:00, 223.13it/s]\n",
      "Train 180 | out_loss 13.144540786743164: 100%|███| 8/8 [00:00<00:00, 259.02it/s]\n",
      "Train 181 | out_loss 13.0874662399292: 100%|█████| 8/8 [00:00<00:00, 262.21it/s]\n",
      "Train 182 | out_loss 13.111699104309082: 100%|███| 8/8 [00:00<00:00, 253.76it/s]\n",
      "Train 183 | out_loss 13.08697509765625: 100%|████| 8/8 [00:00<00:00, 258.21it/s]\n",
      "Train 184 | out_loss 13.101329803466797: 100%|███| 8/8 [00:00<00:00, 258.26it/s]\n",
      "Train 185 | out_loss 13.130922317504883: 100%|███| 8/8 [00:00<00:00, 259.64it/s]\n",
      "Train 186 | out_loss 13.31340503692627: 100%|████| 8/8 [00:00<00:00, 264.19it/s]\n",
      "Train 187 | out_loss 13.098240852355957: 100%|███| 8/8 [00:00<00:00, 256.46it/s]\n",
      "Train 188 | out_loss 13.250688552856445: 100%|███| 8/8 [00:00<00:00, 260.71it/s]\n",
      "Train 189 | out_loss 13.14233112335205: 100%|████| 8/8 [00:00<00:00, 261.66it/s]\n",
      "Train 190 | out_loss 13.323515892028809: 100%|███| 8/8 [00:00<00:00, 255.03it/s]\n",
      "Train 191 | out_loss 13.096920013427734: 100%|███| 8/8 [00:00<00:00, 267.87it/s]\n",
      "Train 192 | out_loss 13.053383827209473: 100%|███| 8/8 [00:00<00:00, 260.79it/s]\n",
      "Train 193 | out_loss 13.040745735168457: 100%|███| 8/8 [00:00<00:00, 263.41it/s]\n",
      "Train 194 | out_loss 12.996456146240234: 100%|███| 8/8 [00:00<00:00, 262.77it/s]\n",
      "Train 195 | out_loss 13.040938377380371: 100%|███| 8/8 [00:00<00:00, 264.09it/s]\n",
      "Train 196 | out_loss 13.12183666229248: 100%|████| 8/8 [00:00<00:00, 260.84it/s]\n",
      "Train 197 | out_loss 13.114348411560059: 100%|███| 8/8 [00:00<00:00, 262.10it/s]\n",
      "Train 198 | out_loss 13.106889724731445: 100%|███| 8/8 [00:00<00:00, 259.23it/s]\n",
      "Train 199 | out_loss 13.209840774536133: 100%|███| 8/8 [00:00<00:00, 256.44it/s]\n",
      "Train 200 | out_loss 13.3280611038208: 100%|█████| 8/8 [00:00<00:00, 258.25it/s]\n",
      "Train 201 | out_loss 13.502209663391113: 100%|███| 8/8 [00:00<00:00, 252.80it/s]\n",
      "Train 202 | out_loss 13.313364028930664: 100%|███| 8/8 [00:00<00:00, 260.07it/s]\n",
      "Train 203 | out_loss 13.385774612426758: 100%|███| 8/8 [00:00<00:00, 262.21it/s]\n",
      "Train 204 | out_loss 13.352545738220215: 100%|███| 8/8 [00:00<00:00, 265.75it/s]\n",
      "Train 205 | out_loss 13.318618774414062: 100%|███| 8/8 [00:00<00:00, 260.15it/s]\n",
      "Train 206 | out_loss 13.255959510803223: 100%|███| 8/8 [00:00<00:00, 257.50it/s]\n",
      "Train 207 | out_loss 13.185416221618652: 100%|███| 8/8 [00:00<00:00, 251.47it/s]\n",
      "Train 208 | out_loss 13.076983451843262: 100%|███| 8/8 [00:00<00:00, 261.59it/s]\n",
      "Train 209 | out_loss 13.016265869140625: 100%|███| 8/8 [00:00<00:00, 265.28it/s]\n",
      "Train 210 | out_loss 12.958788871765137: 100%|███| 8/8 [00:00<00:00, 249.15it/s]\n",
      "Train 211 | out_loss 12.912760734558105: 100%|███| 8/8 [00:00<00:00, 260.28it/s]\n",
      "Train 212 | out_loss 12.906609535217285: 100%|███| 8/8 [00:00<00:00, 261.46it/s]\n",
      "Train 213 | out_loss 12.92905044555664: 100%|████| 8/8 [00:00<00:00, 258.79it/s]\n",
      "Train 214 | out_loss 12.984272003173828: 100%|███| 8/8 [00:00<00:00, 264.52it/s]\n",
      "Train 215 | out_loss 13.232419967651367: 100%|███| 8/8 [00:00<00:00, 268.14it/s]\n",
      "Train 216 | out_loss 13.38486099243164: 100%|████| 8/8 [00:00<00:00, 259.49it/s]\n",
      "Train 217 | out_loss 13.630273818969727: 100%|███| 8/8 [00:00<00:00, 261.84it/s]\n",
      "Train 218 | out_loss 13.583005905151367: 100%|███| 8/8 [00:00<00:00, 264.70it/s]\n",
      "Train 219 | out_loss 13.468862533569336: 100%|███| 8/8 [00:00<00:00, 258.29it/s]\n",
      "Train 220 | out_loss 13.320531845092773: 100%|███| 8/8 [00:00<00:00, 261.60it/s]\n",
      "Train 221 | out_loss 13.274449348449707: 100%|███| 8/8 [00:00<00:00, 262.26it/s]\n",
      "Train 222 | out_loss 13.14926815032959: 100%|████| 8/8 [00:00<00:00, 263.81it/s]\n",
      "Train 223 | out_loss 13.083412170410156: 100%|███| 8/8 [00:00<00:00, 265.94it/s]\n",
      "Train 224 | out_loss 13.03927230834961: 100%|████| 8/8 [00:00<00:00, 242.55it/s]\n",
      "Train 225 | out_loss 13.064756393432617: 100%|███| 8/8 [00:00<00:00, 243.48it/s]\n",
      "Train 226 | out_loss 13.00114631652832: 100%|████| 8/8 [00:00<00:00, 261.83it/s]\n",
      "Train 227 | out_loss 13.151084899902344: 100%|███| 8/8 [00:00<00:00, 260.65it/s]\n",
      "Train 228 | out_loss 13.094564437866211: 100%|███| 8/8 [00:00<00:00, 265.12it/s]\n",
      "Train 229 | out_loss 13.17446231842041: 100%|████| 8/8 [00:00<00:00, 264.21it/s]\n",
      "Train 230 | out_loss 13.149085998535156: 100%|███| 8/8 [00:00<00:00, 262.17it/s]\n",
      "Train 231 | out_loss 13.126118659973145: 100%|███| 8/8 [00:00<00:00, 257.27it/s]\n",
      "Train 232 | out_loss 13.142929077148438: 100%|███| 8/8 [00:00<00:00, 259.88it/s]\n",
      "Train 233 | out_loss 13.144898414611816: 100%|███| 8/8 [00:00<00:00, 260.91it/s]\n",
      "Train 234 | out_loss 13.119322776794434: 100%|███| 8/8 [00:00<00:00, 240.70it/s]\n",
      "Train 235 | out_loss 13.14578914642334: 100%|████| 8/8 [00:00<00:00, 250.77it/s]\n",
      "Train 236 | out_loss 13.132657051086426: 100%|███| 8/8 [00:00<00:00, 242.03it/s]\n",
      "Train 237 | out_loss 13.18851375579834: 100%|████| 8/8 [00:00<00:00, 246.72it/s]\n",
      "Train 238 | out_loss 13.062374114990234: 100%|███| 8/8 [00:00<00:00, 239.60it/s]\n",
      "Train 239 | out_loss 13.091253280639648: 100%|███| 8/8 [00:00<00:00, 245.83it/s]\n",
      "Train 240 | out_loss 12.979388236999512: 100%|███| 8/8 [00:00<00:00, 260.52it/s]\n",
      "Train 241 | out_loss 13.12147331237793: 100%|████| 8/8 [00:00<00:00, 263.67it/s]\n",
      "Train 242 | out_loss 12.900081634521484: 100%|███| 8/8 [00:00<00:00, 249.69it/s]\n",
      "Train 243 | out_loss 12.874166488647461: 100%|███| 8/8 [00:00<00:00, 253.84it/s]\n",
      "Train 244 | out_loss 13.107033729553223: 100%|███| 8/8 [00:00<00:00, 257.84it/s]\n",
      "Train 245 | out_loss 13.204216957092285: 100%|███| 8/8 [00:00<00:00, 255.17it/s]\n",
      "Train 246 | out_loss 13.587903022766113: 100%|███| 8/8 [00:00<00:00, 255.13it/s]\n",
      "Train 247 | out_loss 13.886826515197754: 100%|███| 8/8 [00:00<00:00, 253.56it/s]\n",
      "Train 248 | out_loss 13.671876907348633: 100%|███| 8/8 [00:00<00:00, 257.28it/s]\n",
      "Train 249 | out_loss 13.5003662109375: 100%|█████| 8/8 [00:00<00:00, 258.05it/s]\n",
      "Train 250 | out_loss 13.257355690002441: 100%|███| 8/8 [00:00<00:00, 261.41it/s]\n",
      "Train 251 | out_loss 13.215790748596191: 100%|███| 8/8 [00:00<00:00, 263.32it/s]\n",
      "Train 252 | out_loss 13.078447341918945: 100%|███| 8/8 [00:00<00:00, 265.18it/s]\n",
      "Train 253 | out_loss 12.944475173950195: 100%|███| 8/8 [00:00<00:00, 262.18it/s]\n",
      "Train 254 | out_loss 12.91072940826416: 100%|████| 8/8 [00:00<00:00, 257.64it/s]\n",
      "Train 255 | out_loss 12.851088523864746: 100%|███| 8/8 [00:00<00:00, 264.77it/s]\n",
      "Train 256 | out_loss 12.894586563110352: 100%|███| 8/8 [00:00<00:00, 261.16it/s]\n",
      "Train 257 | out_loss 12.8713960647583: 100%|█████| 8/8 [00:00<00:00, 259.43it/s]\n",
      "Train 258 | out_loss 12.882155418395996: 100%|███| 8/8 [00:00<00:00, 264.43it/s]\n",
      "Train 259 | out_loss 12.964140892028809: 100%|███| 8/8 [00:00<00:00, 266.15it/s]\n",
      "Train 260 | out_loss 13.166622161865234: 100%|███| 8/8 [00:00<00:00, 260.52it/s]\n",
      "Train 261 | out_loss 13.176074028015137: 100%|███| 8/8 [00:00<00:00, 264.33it/s]\n",
      "Train 262 | out_loss 13.105751991271973: 100%|███| 8/8 [00:00<00:00, 266.13it/s]\n",
      "Train 263 | out_loss 13.066682815551758: 100%|███| 8/8 [00:00<00:00, 266.09it/s]\n",
      "Train 264 | out_loss 13.144245147705078: 100%|███| 8/8 [00:00<00:00, 250.59it/s]\n",
      "Train 265 | out_loss 13.1026029586792: 100%|█████| 8/8 [00:00<00:00, 255.98it/s]\n",
      "Train 266 | out_loss 13.055784225463867: 100%|███| 8/8 [00:00<00:00, 256.15it/s]\n",
      "Train 267 | out_loss 12.96275806427002: 100%|████| 8/8 [00:00<00:00, 243.33it/s]\n",
      "Train 268 | out_loss 12.755426406860352: 100%|███| 8/8 [00:00<00:00, 252.90it/s]\n",
      "Train 269 | out_loss 12.995048522949219: 100%|███| 8/8 [00:00<00:00, 247.62it/s]\n",
      "Train 270 | out_loss 13.067570686340332: 100%|███| 8/8 [00:00<00:00, 261.92it/s]\n",
      "Train 271 | out_loss 13.317533493041992: 100%|███| 8/8 [00:00<00:00, 255.08it/s]\n",
      "Train 272 | out_loss 13.512563705444336: 100%|███| 8/8 [00:00<00:00, 265.80it/s]\n",
      "Train 273 | out_loss 13.162028312683105: 100%|███| 8/8 [00:00<00:00, 259.37it/s]\n",
      "Train 274 | out_loss 12.982728958129883: 100%|███| 8/8 [00:00<00:00, 248.87it/s]\n",
      "Train 275 | out_loss 12.837555885314941: 100%|███| 8/8 [00:00<00:00, 249.08it/s]\n",
      "Train 276 | out_loss 12.882536888122559: 100%|███| 8/8 [00:00<00:00, 252.37it/s]\n",
      "Train 277 | out_loss 12.874678611755371: 100%|███| 8/8 [00:00<00:00, 244.69it/s]\n",
      "Train 278 | out_loss 13.00362491607666: 100%|████| 8/8 [00:00<00:00, 255.15it/s]\n",
      "Train 279 | out_loss 12.854667663574219: 100%|███| 8/8 [00:00<00:00, 231.59it/s]\n",
      "Train 280 | out_loss 12.675352096557617: 100%|███| 8/8 [00:00<00:00, 256.35it/s]\n",
      "Train 281 | out_loss 13.10993766784668: 100%|████| 8/8 [00:00<00:00, 255.59it/s]\n",
      "Train 282 | out_loss 13.0352783203125: 100%|█████| 8/8 [00:00<00:00, 252.68it/s]\n",
      "Train 283 | out_loss 13.136338233947754: 100%|███| 8/8 [00:00<00:00, 249.74it/s]\n",
      "Train 284 | out_loss 13.002077102661133: 100%|███| 8/8 [00:00<00:00, 263.31it/s]\n",
      "Train 285 | out_loss 13.007208824157715: 100%|███| 8/8 [00:00<00:00, 265.69it/s]\n",
      "Train 286 | out_loss 13.059202194213867: 100%|███| 8/8 [00:00<00:00, 255.37it/s]\n",
      "Train 287 | out_loss 12.888754844665527: 100%|███| 8/8 [00:00<00:00, 261.23it/s]\n",
      "Train 288 | out_loss 12.990005493164062: 100%|███| 8/8 [00:00<00:00, 260.36it/s]\n",
      "Train 289 | out_loss 12.987165451049805: 100%|███| 8/8 [00:00<00:00, 261.25it/s]\n",
      "Train 290 | out_loss 13.038124084472656: 100%|███| 8/8 [00:00<00:00, 261.59it/s]\n",
      "Train 291 | out_loss 13.000244140625: 100%|██████| 8/8 [00:00<00:00, 265.74it/s]\n",
      "Train 292 | out_loss 13.124076843261719: 100%|███| 8/8 [00:00<00:00, 256.60it/s]\n",
      "Train 293 | out_loss 13.048099517822266: 100%|███| 8/8 [00:00<00:00, 263.78it/s]\n",
      "Train 294 | out_loss 25.206253051757812: 100%|███| 8/8 [00:00<00:00, 259.80it/s]\n",
      "Train 295 | out_loss 29.754135131835938: 100%|███| 8/8 [00:00<00:00, 256.42it/s]\n",
      "Train 296 | out_loss 21.476898193359375: 100%|███| 8/8 [00:00<00:00, 264.45it/s]\n",
      "Train 297 | out_loss 28.519378662109375: 100%|███| 8/8 [00:00<00:00, 260.23it/s]\n",
      "Train 298 | out_loss 14.006641387939453: 100%|███| 8/8 [00:00<00:00, 263.68it/s]\n",
      "Train 299 | out_loss 13.10871410369873: 100%|████| 8/8 [00:00<00:00, 258.51it/s]\n",
      "Train 300 | out_loss 13.142065048217773: 100%|███| 8/8 [00:00<00:00, 261.73it/s]\n",
      "Train 301 | out_loss 13.088501930236816: 100%|███| 8/8 [00:00<00:00, 262.15it/s]\n",
      "Train 302 | out_loss 13.049291610717773: 100%|███| 8/8 [00:00<00:00, 262.95it/s]\n",
      "Train 303 | out_loss 13.124403953552246: 100%|███| 8/8 [00:00<00:00, 265.37it/s]\n",
      "Train 304 | out_loss 13.065646171569824: 100%|███| 8/8 [00:00<00:00, 253.88it/s]\n",
      "Train 305 | out_loss 13.105724334716797: 100%|███| 8/8 [00:00<00:00, 260.98it/s]\n",
      "Train 306 | out_loss 13.168283462524414: 100%|███| 8/8 [00:00<00:00, 253.43it/s]\n",
      "Train 307 | out_loss 13.035099029541016: 100%|███| 8/8 [00:00<00:00, 254.27it/s]\n",
      "Train 308 | out_loss 13.199690818786621: 100%|███| 8/8 [00:00<00:00, 263.05it/s]\n",
      "Train 309 | out_loss 13.135489463806152: 100%|███| 8/8 [00:00<00:00, 262.12it/s]\n",
      "Train 310 | out_loss 21.105920791625977: 100%|███| 8/8 [00:00<00:00, 258.99it/s]\n",
      "Train 311 | out_loss 13.067060470581055: 100%|███| 8/8 [00:00<00:00, 262.44it/s]\n",
      "Train 312 | out_loss 13.167386054992676: 100%|███| 8/8 [00:00<00:00, 264.68it/s]\n",
      "Train 313 | out_loss 13.102747917175293: 100%|███| 8/8 [00:00<00:00, 264.83it/s]\n",
      "Train 314 | out_loss 13.047587394714355: 100%|███| 8/8 [00:00<00:00, 261.51it/s]\n",
      "Train 315 | out_loss 13.051734924316406: 100%|███| 8/8 [00:00<00:00, 250.55it/s]\n",
      "Train 316 | out_loss 13.121879577636719: 100%|███| 8/8 [00:00<00:00, 221.75it/s]\n",
      "Train 317 | out_loss 13.093695640563965: 100%|███| 8/8 [00:00<00:00, 251.27it/s]\n",
      "Train 318 | out_loss 13.0336275100708: 100%|█████| 8/8 [00:00<00:00, 242.24it/s]\n",
      "Train 319 | out_loss 13.096892356872559: 100%|███| 8/8 [00:00<00:00, 264.44it/s]\n",
      "Train 320 | out_loss 13.148245811462402: 100%|███| 8/8 [00:00<00:00, 254.13it/s]\n",
      "Train 321 | out_loss 13.099248886108398: 100%|███| 8/8 [00:00<00:00, 264.73it/s]\n",
      "Train 322 | out_loss 13.023357391357422: 100%|███| 8/8 [00:00<00:00, 248.42it/s]\n",
      "Train 323 | out_loss 13.099005699157715: 100%|███| 8/8 [00:00<00:00, 256.69it/s]\n",
      "Train 324 | out_loss 13.081103324890137: 100%|███| 8/8 [00:00<00:00, 233.16it/s]\n",
      "Train 325 | out_loss 13.120294570922852: 100%|███| 8/8 [00:00<00:00, 264.27it/s]\n",
      "Train 326 | out_loss 13.06037712097168: 100%|████| 8/8 [00:00<00:00, 260.52it/s]\n",
      "Train 327 | out_loss 13.121378898620605: 100%|███| 8/8 [00:00<00:00, 258.51it/s]\n",
      "Train 328 | out_loss 13.208919525146484: 100%|███| 8/8 [00:00<00:00, 260.33it/s]\n",
      "Train 329 | out_loss 13.060173034667969: 100%|███| 8/8 [00:00<00:00, 245.77it/s]\n",
      "Train 330 | out_loss 13.058846473693848: 100%|███| 8/8 [00:00<00:00, 262.50it/s]\n",
      "Train 331 | out_loss 13.024589538574219: 100%|███| 8/8 [00:00<00:00, 263.88it/s]\n",
      "Train 332 | out_loss 13.057852745056152: 100%|███| 8/8 [00:00<00:00, 255.20it/s]\n",
      "Train 333 | out_loss 13.26120662689209: 100%|████| 8/8 [00:00<00:00, 256.32it/s]\n",
      "Train 334 | out_loss 13.034234046936035: 100%|███| 8/8 [00:00<00:00, 253.81it/s]\n",
      "Train 335 | out_loss 13.066941261291504: 100%|███| 8/8 [00:00<00:00, 263.76it/s]\n",
      "Train 336 | out_loss 13.05057144165039: 100%|████| 8/8 [00:00<00:00, 261.44it/s]\n",
      "Train 337 | out_loss 13.074909210205078: 100%|███| 8/8 [00:00<00:00, 260.44it/s]\n",
      "Train 338 | out_loss 13.080960273742676: 100%|███| 8/8 [00:00<00:00, 261.95it/s]\n",
      "Train 339 | out_loss 13.129883766174316: 100%|███| 8/8 [00:00<00:00, 254.99it/s]\n",
      "Train 340 | out_loss 13.062883377075195: 100%|███| 8/8 [00:00<00:00, 258.79it/s]\n",
      "Train 341 | out_loss 13.061917304992676: 100%|███| 8/8 [00:00<00:00, 234.26it/s]\n",
      "Train 342 | out_loss 13.211645126342773: 100%|███| 8/8 [00:00<00:00, 231.60it/s]\n",
      "Train 343 | out_loss 13.147798538208008: 100%|███| 8/8 [00:00<00:00, 260.23it/s]\n",
      "Train 344 | out_loss 13.086211204528809: 100%|███| 8/8 [00:00<00:00, 251.56it/s]\n",
      "Train 345 | out_loss 13.103012084960938: 100%|███| 8/8 [00:00<00:00, 213.73it/s]\n",
      "Train 346 | out_loss 13.120102882385254: 100%|███| 8/8 [00:00<00:00, 261.17it/s]\n",
      "Train 347 | out_loss 13.106975555419922: 100%|███| 8/8 [00:00<00:00, 226.15it/s]\n",
      "Train 348 | out_loss 13.127959251403809: 100%|███| 8/8 [00:00<00:00, 251.32it/s]\n",
      "Train 349 | out_loss 13.085375785827637: 100%|███| 8/8 [00:00<00:00, 245.03it/s]\n",
      "Train 350 | out_loss 13.176088333129883: 100%|███| 8/8 [00:00<00:00, 252.16it/s]\n",
      "Train 351 | out_loss 13.104063987731934: 100%|███| 8/8 [00:00<00:00, 263.26it/s]\n",
      "Train 352 | out_loss 13.09360122680664: 100%|████| 8/8 [00:00<00:00, 266.19it/s]\n",
      "Train 353 | out_loss 13.062978744506836: 100%|███| 8/8 [00:00<00:00, 247.91it/s]\n",
      "Train 354 | out_loss 13.086709976196289: 100%|███| 8/8 [00:00<00:00, 257.23it/s]\n",
      "Train 355 | out_loss 13.07401180267334: 100%|████| 8/8 [00:00<00:00, 265.13it/s]\n",
      "Train 356 | out_loss 13.172048568725586: 100%|███| 8/8 [00:00<00:00, 262.65it/s]\n",
      "Train 357 | out_loss 13.089417457580566: 100%|███| 8/8 [00:00<00:00, 256.55it/s]\n",
      "Train 358 | out_loss 13.330835342407227: 100%|███| 8/8 [00:00<00:00, 265.50it/s]\n",
      "Train 359 | out_loss 13.219738006591797: 100%|███| 8/8 [00:00<00:00, 260.85it/s]\n",
      "Train 360 | out_loss 13.096856117248535: 100%|███| 8/8 [00:00<00:00, 264.04it/s]\n",
      "Train 361 | out_loss 13.111970901489258: 100%|███| 8/8 [00:00<00:00, 248.95it/s]\n",
      "Train 362 | out_loss 13.118440628051758: 100%|███| 8/8 [00:00<00:00, 257.00it/s]\n",
      "Train 363 | out_loss 13.128190040588379: 100%|███| 8/8 [00:00<00:00, 263.94it/s]\n",
      "Train 364 | out_loss 13.143204689025879: 100%|███| 8/8 [00:00<00:00, 262.05it/s]\n",
      "Train 365 | out_loss 13.345470428466797: 100%|███| 8/8 [00:00<00:00, 257.49it/s]\n",
      "Train 366 | out_loss 13.17288589477539: 100%|████| 8/8 [00:00<00:00, 256.68it/s]\n",
      "Train 367 | out_loss 13.47288990020752: 100%|████| 8/8 [00:00<00:00, 257.20it/s]\n",
      "Train 368 | out_loss 13.10367488861084: 100%|████| 8/8 [00:00<00:00, 256.17it/s]\n",
      "Train 369 | out_loss 13.077857971191406: 100%|███| 8/8 [00:00<00:00, 261.14it/s]\n",
      "Train 370 | out_loss 13.251148223876953: 100%|███| 8/8 [00:00<00:00, 258.50it/s]\n",
      "Train 371 | out_loss 13.205841064453125: 100%|███| 8/8 [00:00<00:00, 261.26it/s]\n",
      "Train 372 | out_loss 13.22286319732666: 100%|████| 8/8 [00:00<00:00, 265.12it/s]\n",
      "Train 373 | out_loss 13.587251663208008: 100%|███| 8/8 [00:00<00:00, 263.58it/s]\n",
      "Train 374 | out_loss 13.371448516845703: 100%|███| 8/8 [00:00<00:00, 256.12it/s]\n",
      "Train 375 | out_loss 13.062641143798828: 100%|███| 8/8 [00:00<00:00, 260.44it/s]\n",
      "Train 376 | out_loss 13.103543281555176: 100%|███| 8/8 [00:00<00:00, 251.52it/s]\n",
      "Train 377 | out_loss 13.00725269317627: 100%|████| 8/8 [00:00<00:00, 259.35it/s]\n",
      "Train 378 | out_loss 13.037878036499023: 100%|███| 8/8 [00:00<00:00, 258.01it/s]\n",
      "Train 379 | out_loss 13.124284744262695: 100%|███| 8/8 [00:00<00:00, 252.50it/s]\n",
      "Train 380 | out_loss 13.098441123962402: 100%|███| 8/8 [00:00<00:00, 260.09it/s]\n",
      "Train 381 | out_loss 13.09109115600586: 100%|████| 8/8 [00:00<00:00, 249.33it/s]\n",
      "Train 382 | out_loss 13.114666938781738: 100%|███| 8/8 [00:00<00:00, 257.23it/s]\n",
      "Train 383 | out_loss 13.033620834350586: 100%|███| 8/8 [00:00<00:00, 259.29it/s]\n",
      "Train 384 | out_loss 13.158130645751953: 100%|███| 8/8 [00:00<00:00, 258.03it/s]\n",
      "Train 385 | out_loss 13.104514122009277: 100%|███| 8/8 [00:00<00:00, 257.24it/s]\n",
      "Train 386 | out_loss 13.09266185760498: 100%|████| 8/8 [00:00<00:00, 257.18it/s]\n",
      "Train 387 | out_loss 13.134056091308594: 100%|███| 8/8 [00:00<00:00, 261.56it/s]\n",
      "Train 388 | out_loss 13.22625732421875: 100%|████| 8/8 [00:00<00:00, 263.61it/s]\n",
      "Train 389 | out_loss 13.304369926452637: 100%|███| 8/8 [00:00<00:00, 252.78it/s]\n",
      "Train 390 | out_loss 13.1273832321167: 100%|█████| 8/8 [00:00<00:00, 258.56it/s]\n",
      "Train 391 | out_loss 13.050532341003418: 100%|███| 8/8 [00:00<00:00, 257.35it/s]\n",
      "Train 392 | out_loss 13.059131622314453: 100%|███| 8/8 [00:00<00:00, 262.44it/s]\n",
      "Train 393 | out_loss 13.126302719116211: 100%|███| 8/8 [00:00<00:00, 256.63it/s]\n",
      "Train 394 | out_loss 13.083211898803711: 100%|███| 8/8 [00:00<00:00, 261.02it/s]\n",
      "Train 395 | out_loss 13.181268692016602: 100%|███| 8/8 [00:00<00:00, 213.44it/s]\n",
      "Train 396 | out_loss 13.083983421325684: 100%|███| 8/8 [00:00<00:00, 255.55it/s]\n",
      "Train 397 | out_loss 13.231201171875: 100%|██████| 8/8 [00:00<00:00, 246.18it/s]\n",
      "Train 398 | out_loss 13.206644058227539: 100%|███| 8/8 [00:00<00:00, 239.72it/s]\n",
      "Train 399 | out_loss 13.06722354888916: 100%|████| 8/8 [00:00<00:00, 259.96it/s]\n",
      "Train 400 | out_loss 13.078592300415039: 100%|███| 8/8 [00:00<00:00, 239.99it/s]\n",
      "Train 401 | out_loss 13.039875984191895: 100%|███| 8/8 [00:00<00:00, 261.75it/s]\n",
      "Train 402 | out_loss 13.204930305480957: 100%|███| 8/8 [00:00<00:00, 261.00it/s]\n",
      "Train 403 | out_loss 13.070545196533203: 100%|███| 8/8 [00:00<00:00, 260.18it/s]\n",
      "Train 404 | out_loss 13.079736709594727: 100%|███| 8/8 [00:00<00:00, 249.97it/s]\n",
      "Train 405 | out_loss 13.106258392333984: 100%|███| 8/8 [00:00<00:00, 259.30it/s]\n",
      "Train 406 | out_loss 13.098896980285645: 100%|███| 8/8 [00:00<00:00, 194.70it/s]\n",
      "Train 407 | out_loss 13.072582244873047: 100%|███| 8/8 [00:00<00:00, 252.95it/s]\n",
      "Train 408 | out_loss 13.05382251739502: 100%|████| 8/8 [00:00<00:00, 254.88it/s]\n",
      "Train 409 | out_loss 13.235024452209473: 100%|███| 8/8 [00:00<00:00, 259.82it/s]\n",
      "Train 410 | out_loss 12.99621868133545: 100%|████| 8/8 [00:00<00:00, 255.18it/s]\n",
      "Train 411 | out_loss 13.225889205932617: 100%|███| 8/8 [00:00<00:00, 258.84it/s]\n",
      "Train 412 | out_loss 13.10836124420166: 100%|████| 8/8 [00:00<00:00, 243.33it/s]\n",
      "Train 413 | out_loss 13.092942237854004: 100%|███| 8/8 [00:00<00:00, 266.13it/s]\n",
      "Train 414 | out_loss 13.191285133361816: 100%|███| 8/8 [00:00<00:00, 231.55it/s]\n",
      "Train 415 | out_loss 13.057265281677246: 100%|███| 8/8 [00:00<00:00, 239.10it/s]\n",
      "Train 416 | out_loss 13.147024154663086: 100%|███| 8/8 [00:00<00:00, 244.49it/s]\n",
      "Train 417 | out_loss 13.196181297302246: 100%|███| 8/8 [00:00<00:00, 258.83it/s]\n",
      "Train 418 | out_loss 13.083693504333496: 100%|███| 8/8 [00:00<00:00, 260.01it/s]\n",
      "Train 419 | out_loss 13.10091781616211: 100%|████| 8/8 [00:00<00:00, 260.09it/s]\n",
      "Train 420 | out_loss 13.085336685180664: 100%|███| 8/8 [00:00<00:00, 253.19it/s]\n",
      "Train 421 | out_loss 13.092817306518555: 100%|███| 8/8 [00:00<00:00, 256.96it/s]\n",
      "Train 422 | out_loss 13.196671485900879: 100%|███| 8/8 [00:00<00:00, 258.57it/s]\n",
      "Train 423 | out_loss 13.201205253601074: 100%|███| 8/8 [00:00<00:00, 258.16it/s]\n",
      "Train 424 | out_loss 13.085000038146973: 100%|███| 8/8 [00:00<00:00, 257.72it/s]\n",
      "Train 425 | out_loss 13.151439666748047: 100%|███| 8/8 [00:00<00:00, 261.10it/s]\n",
      "Train 426 | out_loss 13.072601318359375: 100%|███| 8/8 [00:00<00:00, 261.52it/s]\n",
      "Train 427 | out_loss 13.052125930786133: 100%|███| 8/8 [00:00<00:00, 257.75it/s]\n",
      "Train 428 | out_loss 13.036641120910645: 100%|███| 8/8 [00:00<00:00, 263.49it/s]\n",
      "Train 429 | out_loss 13.115426063537598: 100%|███| 8/8 [00:00<00:00, 254.03it/s]\n",
      "Train 430 | out_loss 13.04636001586914: 100%|████| 8/8 [00:00<00:00, 250.88it/s]\n",
      "Train 431 | out_loss 13.044964790344238: 100%|███| 8/8 [00:00<00:00, 218.07it/s]\n",
      "Train 432 | out_loss 13.076286315917969: 100%|███| 8/8 [00:00<00:00, 247.17it/s]\n",
      "Train 433 | out_loss 13.298782348632812: 100%|███| 8/8 [00:00<00:00, 252.30it/s]\n",
      "Train 434 | out_loss 13.310545921325684: 100%|███| 8/8 [00:00<00:00, 256.91it/s]\n",
      "Train 435 | out_loss 13.385998725891113: 100%|███| 8/8 [00:00<00:00, 258.05it/s]\n",
      "Train 436 | out_loss 13.342050552368164: 100%|███| 8/8 [00:00<00:00, 247.14it/s]\n",
      "Train 437 | out_loss 13.459403038024902: 100%|███| 8/8 [00:00<00:00, 260.01it/s]\n",
      "Train 438 | out_loss 13.122810363769531: 100%|███| 8/8 [00:00<00:00, 250.95it/s]\n",
      "Train 439 | out_loss 13.123515129089355: 100%|███| 8/8 [00:00<00:00, 253.48it/s]\n",
      "Train 440 | out_loss 13.201103210449219: 100%|███| 8/8 [00:00<00:00, 247.79it/s]\n",
      "Train 441 | out_loss 13.251769065856934: 100%|███| 8/8 [00:00<00:00, 228.30it/s]\n",
      "Train 442 | out_loss 13.120070457458496: 100%|███| 8/8 [00:00<00:00, 258.42it/s]\n",
      "Train 443 | out_loss 13.222306251525879: 100%|███| 8/8 [00:00<00:00, 267.64it/s]\n",
      "Train 444 | out_loss 13.026212692260742: 100%|███| 8/8 [00:00<00:00, 253.77it/s]\n",
      "Train 445 | out_loss 13.140116691589355: 100%|███| 8/8 [00:00<00:00, 256.82it/s]\n",
      "Train 446 | out_loss 13.064208984375: 100%|██████| 8/8 [00:00<00:00, 260.75it/s]\n",
      "Train 447 | out_loss 13.15756893157959: 100%|████| 8/8 [00:00<00:00, 258.19it/s]\n",
      "Train 448 | out_loss 13.05971622467041: 100%|████| 8/8 [00:00<00:00, 255.17it/s]\n",
      "Train 449 | out_loss 12.987357139587402: 100%|███| 8/8 [00:00<00:00, 252.48it/s]\n",
      "Train 450 | out_loss 13.307753562927246: 100%|███| 8/8 [00:00<00:00, 246.78it/s]\n",
      "Train 451 | out_loss 13.050544738769531: 100%|███| 8/8 [00:00<00:00, 250.31it/s]\n",
      "Train 452 | out_loss 13.137262344360352: 100%|███| 8/8 [00:00<00:00, 249.85it/s]\n",
      "Train 453 | out_loss 13.080812454223633: 100%|███| 8/8 [00:00<00:00, 252.03it/s]\n",
      "Train 454 | out_loss 13.180063247680664: 100%|███| 8/8 [00:00<00:00, 244.04it/s]\n",
      "Train 455 | out_loss 13.19820499420166: 100%|████| 8/8 [00:00<00:00, 253.48it/s]\n",
      "Train 456 | out_loss 13.104788780212402: 100%|███| 8/8 [00:00<00:00, 258.55it/s]\n",
      "Train 457 | out_loss 13.131497383117676: 100%|███| 8/8 [00:00<00:00, 259.33it/s]\n",
      "Train 458 | out_loss 13.212859153747559: 100%|███| 8/8 [00:00<00:00, 262.15it/s]\n",
      "Train 459 | out_loss 13.065686225891113: 100%|███| 8/8 [00:00<00:00, 262.41it/s]\n",
      "Train 460 | out_loss 13.026347160339355: 100%|███| 8/8 [00:00<00:00, 256.07it/s]\n",
      "Train 461 | out_loss 13.059297561645508: 100%|███| 8/8 [00:00<00:00, 258.83it/s]\n",
      "Train 462 | out_loss 13.048563003540039: 100%|███| 8/8 [00:00<00:00, 264.19it/s]\n",
      "Train 463 | out_loss 13.280123710632324: 100%|███| 8/8 [00:00<00:00, 259.31it/s]\n",
      "Train 464 | out_loss 13.359345436096191: 100%|███| 8/8 [00:00<00:00, 262.89it/s]\n",
      "Train 465 | out_loss 13.152274131774902: 100%|███| 8/8 [00:00<00:00, 255.28it/s]\n",
      "Train 466 | out_loss 13.114181518554688: 100%|███| 8/8 [00:00<00:00, 262.49it/s]\n",
      "Train 467 | out_loss 13.159160614013672: 100%|███| 8/8 [00:00<00:00, 260.86it/s]\n",
      "Train 468 | out_loss 13.185285568237305: 100%|███| 8/8 [00:00<00:00, 261.24it/s]\n",
      "Train 469 | out_loss 13.046584129333496: 100%|███| 8/8 [00:00<00:00, 259.53it/s]\n",
      "Train 470 | out_loss 13.091059684753418: 100%|███| 8/8 [00:00<00:00, 262.21it/s]\n",
      "Train 471 | out_loss 13.15363597869873: 100%|████| 8/8 [00:00<00:00, 254.20it/s]\n",
      "Train 472 | out_loss 13.168974876403809: 100%|███| 8/8 [00:00<00:00, 261.41it/s]\n",
      "Train 473 | out_loss 13.124482154846191: 100%|███| 8/8 [00:00<00:00, 253.51it/s]\n",
      "Train 474 | out_loss 13.035347938537598: 100%|███| 8/8 [00:00<00:00, 262.21it/s]\n",
      "Train 475 | out_loss 13.102962493896484: 100%|███| 8/8 [00:00<00:00, 236.52it/s]\n",
      "Train 476 | out_loss 13.182254791259766: 100%|███| 8/8 [00:00<00:00, 258.82it/s]\n",
      "Train 477 | out_loss 13.271626472473145: 100%|███| 8/8 [00:00<00:00, 261.67it/s]\n",
      "Train 478 | out_loss 13.63160228729248: 100%|████| 8/8 [00:00<00:00, 260.99it/s]\n",
      "Train 479 | out_loss 13.12340259552002: 100%|████| 8/8 [00:00<00:00, 259.63it/s]\n",
      "Train 480 | out_loss 13.08512020111084: 100%|████| 8/8 [00:00<00:00, 260.74it/s]\n",
      "Train 481 | out_loss 13.109380722045898: 100%|███| 8/8 [00:00<00:00, 257.30it/s]\n",
      "Train 482 | out_loss 13.043442726135254: 100%|███| 8/8 [00:00<00:00, 255.31it/s]\n",
      "Train 483 | out_loss 13.072585105895996: 100%|███| 8/8 [00:00<00:00, 264.70it/s]\n",
      "Train 484 | out_loss 13.09724235534668: 100%|████| 8/8 [00:00<00:00, 264.10it/s]\n",
      "Train 485 | out_loss 13.451383590698242: 100%|███| 8/8 [00:00<00:00, 253.23it/s]\n",
      "Train 486 | out_loss 13.20188045501709: 100%|████| 8/8 [00:00<00:00, 255.51it/s]\n",
      "Train 487 | out_loss 13.066699028015137: 100%|███| 8/8 [00:00<00:00, 260.92it/s]\n",
      "Train 488 | out_loss 13.013586044311523: 100%|███| 8/8 [00:00<00:00, 239.44it/s]\n",
      "Train 489 | out_loss 13.025712966918945: 100%|███| 8/8 [00:00<00:00, 259.06it/s]\n",
      "Train 490 | out_loss 13.067888259887695: 100%|███| 8/8 [00:00<00:00, 234.49it/s]\n",
      "Train 491 | out_loss 13.16826057434082: 100%|████| 8/8 [00:00<00:00, 249.10it/s]\n",
      "Train 492 | out_loss 13.072430610656738: 100%|███| 8/8 [00:00<00:00, 241.46it/s]\n",
      "Train 493 | out_loss 13.171967506408691: 100%|███| 8/8 [00:00<00:00, 254.41it/s]\n",
      "Train 494 | out_loss 13.077601432800293: 100%|███| 8/8 [00:00<00:00, 258.84it/s]\n",
      "Train 495 | out_loss 13.241525650024414: 100%|███| 8/8 [00:00<00:00, 257.48it/s]\n",
      "Train 496 | out_loss 13.063210487365723: 100%|███| 8/8 [00:00<00:00, 253.42it/s]\n",
      "Train 497 | out_loss 13.093401908874512: 100%|███| 8/8 [00:00<00:00, 260.73it/s]\n",
      "Train 498 | out_loss 13.057929992675781: 100%|███| 8/8 [00:00<00:00, 262.45it/s]\n",
      "Train 499 | out_loss 13.402018547058105: 100%|███| 8/8 [00:00<00:00, 253.79it/s]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 80.21270751953125: 100%|███████| 8/8 [00:00<00:00, 19.85it/s]\n",
      "Train 1 | out_loss 78.94646453857422: 100%|██████| 8/8 [00:00<00:00, 207.77it/s]\n",
      "Train 2 | out_loss 74.73246002197266: 100%|██████| 8/8 [00:00<00:00, 163.88it/s]\n",
      "Train 3 | out_loss 75.18265533447266: 100%|██████| 8/8 [00:00<00:00, 209.77it/s]\n",
      "Train 4 | out_loss 73.61567687988281: 100%|██████| 8/8 [00:00<00:00, 200.17it/s]\n",
      "Train 5 | out_loss 72.09169006347656: 100%|██████| 8/8 [00:00<00:00, 211.76it/s]\n",
      "Train 6 | out_loss 72.45094299316406: 100%|██████| 8/8 [00:00<00:00, 209.29it/s]\n",
      "Train 7 | out_loss 71.3495864868164: 100%|███████| 8/8 [00:00<00:00, 209.78it/s]\n",
      "Train 8 | out_loss 70.79148864746094: 100%|██████| 8/8 [00:00<00:00, 218.13it/s]\n",
      "Train 9 | out_loss 70.1053237915039: 100%|███████| 8/8 [00:00<00:00, 211.09it/s]\n",
      "Train 10 | out_loss 69.4205322265625: 100%|██████| 8/8 [00:00<00:00, 209.38it/s]\n",
      "Train 11 | out_loss 67.6922836303711: 100%|██████| 8/8 [00:00<00:00, 217.13it/s]\n",
      "Train 12 | out_loss 67.45039367675781: 100%|█████| 8/8 [00:00<00:00, 211.42it/s]\n",
      "Train 13 | out_loss 65.13851165771484: 100%|█████| 8/8 [00:00<00:00, 217.97it/s]\n",
      "Train 14 | out_loss 65.60860443115234: 100%|█████| 8/8 [00:00<00:00, 220.53it/s]\n",
      "Train 15 | out_loss 63.789058685302734: 100%|████| 8/8 [00:00<00:00, 214.72it/s]\n",
      "Train 16 | out_loss 62.9105224609375: 100%|██████| 8/8 [00:00<00:00, 216.19it/s]\n",
      "Train 17 | out_loss 61.695552825927734: 100%|████| 8/8 [00:00<00:00, 208.38it/s]\n",
      "Train 18 | out_loss 61.339805603027344: 100%|████| 8/8 [00:00<00:00, 215.58it/s]\n",
      "Train 19 | out_loss 59.6309928894043: 100%|██████| 8/8 [00:00<00:00, 213.37it/s]\n",
      "Train 20 | out_loss 59.12765121459961: 100%|█████| 8/8 [00:00<00:00, 215.70it/s]\n",
      "Train 21 | out_loss 57.85618591308594: 100%|█████| 8/8 [00:00<00:00, 216.95it/s]\n",
      "Train 22 | out_loss 56.772918701171875: 100%|████| 8/8 [00:00<00:00, 213.88it/s]\n",
      "Train 23 | out_loss 55.995155334472656: 100%|████| 8/8 [00:00<00:00, 216.86it/s]\n",
      "Train 24 | out_loss 54.781192779541016: 100%|████| 8/8 [00:00<00:00, 213.26it/s]\n",
      "Train 25 | out_loss 54.07798385620117: 100%|█████| 8/8 [00:00<00:00, 211.18it/s]\n",
      "Train 26 | out_loss 52.72182846069336: 100%|█████| 8/8 [00:00<00:00, 209.55it/s]\n",
      "Train 27 | out_loss 51.95087814331055: 100%|█████| 8/8 [00:00<00:00, 214.26it/s]\n",
      "Train 28 | out_loss 51.24738693237305: 100%|█████| 8/8 [00:00<00:00, 207.46it/s]\n",
      "Train 29 | out_loss 49.731449127197266: 100%|████| 8/8 [00:00<00:00, 205.51it/s]\n",
      "Train 30 | out_loss 49.355384826660156: 100%|████| 8/8 [00:00<00:00, 216.43it/s]\n",
      "Train 31 | out_loss 48.14287567138672: 100%|█████| 8/8 [00:00<00:00, 214.07it/s]\n",
      "Train 32 | out_loss 47.82961654663086: 100%|█████| 8/8 [00:00<00:00, 218.10it/s]\n",
      "Train 33 | out_loss 45.26166915893555: 100%|█████| 8/8 [00:00<00:00, 216.40it/s]\n",
      "Train 34 | out_loss 46.361572265625: 100%|███████| 8/8 [00:00<00:00, 211.34it/s]\n",
      "Train 35 | out_loss 43.879966735839844: 100%|████| 8/8 [00:00<00:00, 213.72it/s]\n",
      "Train 36 | out_loss 42.74576950073242: 100%|█████| 8/8 [00:00<00:00, 217.29it/s]\n",
      "Train 37 | out_loss 41.965904235839844: 100%|████| 8/8 [00:00<00:00, 215.41it/s]\n",
      "Train 38 | out_loss 40.99857711791992: 100%|█████| 8/8 [00:00<00:00, 213.10it/s]\n",
      "Train 39 | out_loss 39.81678771972656: 100%|█████| 8/8 [00:00<00:00, 216.39it/s]\n",
      "Train 40 | out_loss 39.039981842041016: 100%|████| 8/8 [00:00<00:00, 212.43it/s]\n",
      "Train 41 | out_loss 38.132164001464844: 100%|████| 8/8 [00:00<00:00, 212.18it/s]\n",
      "Train 42 | out_loss 37.08445358276367: 100%|█████| 8/8 [00:00<00:00, 220.25it/s]\n",
      "Train 43 | out_loss 36.094940185546875: 100%|████| 8/8 [00:00<00:00, 210.43it/s]\n",
      "Train 44 | out_loss 35.00520324707031: 100%|█████| 8/8 [00:00<00:00, 212.70it/s]\n",
      "Train 45 | out_loss 34.12849807739258: 100%|█████| 8/8 [00:00<00:00, 213.76it/s]\n",
      "Train 46 | out_loss 33.19234085083008: 100%|█████| 8/8 [00:00<00:00, 209.50it/s]\n",
      "Train 47 | out_loss 32.242713928222656: 100%|████| 8/8 [00:00<00:00, 217.46it/s]\n",
      "Train 48 | out_loss 31.296579360961914: 100%|████| 8/8 [00:00<00:00, 212.29it/s]\n",
      "Train 49 | out_loss 30.326326370239258: 100%|████| 8/8 [00:00<00:00, 212.26it/s]\n",
      "Train 50 | out_loss 29.426504135131836: 100%|████| 8/8 [00:00<00:00, 211.50it/s]\n",
      "Train 51 | out_loss 28.493600845336914: 100%|████| 8/8 [00:00<00:00, 212.86it/s]\n",
      "Train 52 | out_loss 27.580690383911133: 100%|████| 8/8 [00:00<00:00, 212.58it/s]\n",
      "Train 53 | out_loss 26.653621673583984: 100%|████| 8/8 [00:00<00:00, 208.59it/s]\n",
      "Train 54 | out_loss 25.724403381347656: 100%|████| 8/8 [00:00<00:00, 173.20it/s]\n",
      "Train 55 | out_loss 24.94978141784668: 100%|█████| 8/8 [00:00<00:00, 178.95it/s]\n",
      "Train 56 | out_loss 23.92670249938965: 100%|█████| 8/8 [00:00<00:00, 188.15it/s]\n",
      "Train 57 | out_loss 23.100725173950195: 100%|████| 8/8 [00:00<00:00, 204.96it/s]\n",
      "Train 58 | out_loss 22.304222106933594: 100%|████| 8/8 [00:00<00:00, 217.63it/s]\n",
      "Train 59 | out_loss 21.430206298828125: 100%|████| 8/8 [00:00<00:00, 192.60it/s]\n",
      "Train 60 | out_loss 20.617042541503906: 100%|████| 8/8 [00:00<00:00, 211.85it/s]\n",
      "Train 61 | out_loss 19.80815315246582: 100%|█████| 8/8 [00:00<00:00, 214.33it/s]\n",
      "Train 62 | out_loss 19.09668731689453: 100%|█████| 8/8 [00:00<00:00, 217.03it/s]\n",
      "Train 63 | out_loss 18.344436645507812: 100%|████| 8/8 [00:00<00:00, 214.80it/s]\n",
      "Train 64 | out_loss 17.617103576660156: 100%|████| 8/8 [00:00<00:00, 212.40it/s]\n",
      "Train 65 | out_loss 16.96807861328125: 100%|█████| 8/8 [00:00<00:00, 216.36it/s]\n",
      "Train 66 | out_loss 16.33628273010254: 100%|█████| 8/8 [00:00<00:00, 203.25it/s]\n",
      "Train 67 | out_loss 15.758184432983398: 100%|████| 8/8 [00:00<00:00, 213.87it/s]\n",
      "Train 68 | out_loss 15.201861381530762: 100%|████| 8/8 [00:00<00:00, 210.30it/s]\n",
      "Train 69 | out_loss 14.825133323669434: 100%|████| 8/8 [00:00<00:00, 211.78it/s]\n",
      "Train 70 | out_loss 14.418159484863281: 100%|████| 8/8 [00:00<00:00, 213.50it/s]\n",
      "Train 71 | out_loss 14.052120208740234: 100%|████| 8/8 [00:00<00:00, 212.30it/s]\n",
      "Train 72 | out_loss 13.907705307006836: 100%|████| 8/8 [00:00<00:00, 219.14it/s]\n",
      "Train 73 | out_loss 13.613062858581543: 100%|████| 8/8 [00:00<00:00, 210.54it/s]\n",
      "Train 74 | out_loss 13.404024124145508: 100%|████| 8/8 [00:00<00:00, 212.69it/s]\n",
      "Train 75 | out_loss 13.54224681854248: 100%|█████| 8/8 [00:00<00:00, 207.81it/s]\n",
      "Train 76 | out_loss 13.221992492675781: 100%|████| 8/8 [00:00<00:00, 215.31it/s]\n",
      "Train 77 | out_loss 13.05562973022461: 100%|█████| 8/8 [00:00<00:00, 218.63it/s]\n",
      "Train 78 | out_loss 13.082733154296875: 100%|████| 8/8 [00:00<00:00, 209.13it/s]\n",
      "Train 79 | out_loss 13.388381004333496: 100%|████| 8/8 [00:00<00:00, 214.44it/s]\n",
      "Train 80 | out_loss 13.711647033691406: 100%|████| 8/8 [00:00<00:00, 215.00it/s]\n",
      "Train 81 | out_loss 13.171133041381836: 100%|████| 8/8 [00:00<00:00, 219.78it/s]\n",
      "Train 82 | out_loss 14.472758293151855: 100%|████| 8/8 [00:00<00:00, 215.89it/s]\n",
      "Train 83 | out_loss 14.017914772033691: 100%|████| 8/8 [00:00<00:00, 207.01it/s]\n",
      "Train 84 | out_loss 14.208498001098633: 100%|████| 8/8 [00:00<00:00, 205.46it/s]\n",
      "Train 85 | out_loss 14.7520751953125: 100%|██████| 8/8 [00:00<00:00, 206.26it/s]\n",
      "Train 86 | out_loss 13.453410148620605: 100%|████| 8/8 [00:00<00:00, 208.75it/s]\n",
      "Train 87 | out_loss 15.328227996826172: 100%|████| 8/8 [00:00<00:00, 214.08it/s]\n",
      "Train 88 | out_loss 14.147096633911133: 100%|████| 8/8 [00:00<00:00, 211.11it/s]\n",
      "Train 89 | out_loss 14.510834693908691: 100%|████| 8/8 [00:00<00:00, 213.10it/s]\n",
      "Train 90 | out_loss 14.561779975891113: 100%|████| 8/8 [00:00<00:00, 215.36it/s]\n",
      "Train 91 | out_loss 15.27976131439209: 100%|█████| 8/8 [00:00<00:00, 212.86it/s]\n",
      "Train 92 | out_loss 15.447318077087402: 100%|████| 8/8 [00:00<00:00, 218.13it/s]\n",
      "Train 93 | out_loss 15.93264389038086: 100%|█████| 8/8 [00:00<00:00, 210.07it/s]\n",
      "Train 94 | out_loss 15.199541091918945: 100%|████| 8/8 [00:00<00:00, 216.72it/s]\n",
      "Train 95 | out_loss 13.911081314086914: 100%|████| 8/8 [00:00<00:00, 216.42it/s]\n",
      "Train 96 | out_loss 14.685239791870117: 100%|████| 8/8 [00:00<00:00, 217.39it/s]\n",
      "Train 97 | out_loss 15.241230010986328: 100%|████| 8/8 [00:00<00:00, 205.20it/s]\n",
      "Train 98 | out_loss 16.91104507446289: 100%|█████| 8/8 [00:00<00:00, 206.68it/s]\n",
      "Train 99 | out_loss 14.212301254272461: 100%|████| 8/8 [00:00<00:00, 204.54it/s]\n",
      "Train 100 | out_loss 15.92400074005127: 100%|████| 8/8 [00:00<00:00, 216.58it/s]\n",
      "Train 101 | out_loss 16.692241668701172: 100%|███| 8/8 [00:00<00:00, 213.88it/s]\n",
      "Train 102 | out_loss 17.878643035888672: 100%|███| 8/8 [00:00<00:00, 186.43it/s]\n",
      "Train 103 | out_loss 17.364601135253906: 100%|███| 8/8 [00:00<00:00, 198.72it/s]\n",
      "Train 104 | out_loss 16.143918991088867: 100%|███| 8/8 [00:00<00:00, 212.97it/s]\n",
      "Train 105 | out_loss 14.57653522491455: 100%|████| 8/8 [00:00<00:00, 205.79it/s]\n",
      "Train 106 | out_loss 13.058685302734375: 100%|███| 8/8 [00:00<00:00, 213.63it/s]\n",
      "Train 107 | out_loss 13.387970924377441: 100%|███| 8/8 [00:00<00:00, 220.77it/s]\n",
      "Train 108 | out_loss 13.195514678955078: 100%|███| 8/8 [00:00<00:00, 207.28it/s]\n",
      "Train 109 | out_loss 13.205885887145996: 100%|███| 8/8 [00:00<00:00, 206.03it/s]\n",
      "Train 110 | out_loss 12.93069839477539: 100%|████| 8/8 [00:00<00:00, 210.77it/s]\n",
      "Train 111 | out_loss 13.385687828063965: 100%|███| 8/8 [00:00<00:00, 218.32it/s]\n",
      "Train 112 | out_loss 13.224674224853516: 100%|███| 8/8 [00:00<00:00, 213.85it/s]\n",
      "Train 113 | out_loss 14.132694244384766: 100%|███| 8/8 [00:00<00:00, 209.17it/s]\n",
      "Train 114 | out_loss 15.34572982788086: 100%|████| 8/8 [00:00<00:00, 214.62it/s]\n",
      "Train 115 | out_loss 14.1958646774292: 100%|█████| 8/8 [00:00<00:00, 212.06it/s]\n",
      "Train 116 | out_loss 13.35312271118164: 100%|████| 8/8 [00:00<00:00, 212.42it/s]\n",
      "Train 117 | out_loss 14.322086334228516: 100%|███| 8/8 [00:00<00:00, 210.01it/s]\n",
      "Train 118 | out_loss 13.383248329162598: 100%|███| 8/8 [00:00<00:00, 183.16it/s]\n",
      "Train 119 | out_loss 13.48141098022461: 100%|████| 8/8 [00:00<00:00, 217.58it/s]\n",
      "Train 120 | out_loss 13.57695484161377: 100%|████| 8/8 [00:00<00:00, 191.92it/s]\n",
      "Train 121 | out_loss 13.138360977172852: 100%|███| 8/8 [00:00<00:00, 216.69it/s]\n",
      "Train 122 | out_loss 13.688766479492188: 100%|███| 8/8 [00:00<00:00, 179.77it/s]\n",
      "Train 123 | out_loss 13.55656623840332: 100%|████| 8/8 [00:00<00:00, 203.71it/s]\n",
      "Train 124 | out_loss 13.399726867675781: 100%|███| 8/8 [00:00<00:00, 213.46it/s]\n",
      "Train 125 | out_loss 13.294742584228516: 100%|███| 8/8 [00:00<00:00, 214.96it/s]\n",
      "Train 126 | out_loss 13.682604789733887: 100%|███| 8/8 [00:00<00:00, 207.78it/s]\n",
      "Train 127 | out_loss 13.448837280273438: 100%|███| 8/8 [00:00<00:00, 213.76it/s]\n",
      "Train 128 | out_loss 13.09774112701416: 100%|████| 8/8 [00:00<00:00, 208.42it/s]\n",
      "Train 129 | out_loss 13.409198760986328: 100%|███| 8/8 [00:00<00:00, 209.88it/s]\n",
      "Train 130 | out_loss 13.455544471740723: 100%|███| 8/8 [00:00<00:00, 208.38it/s]\n",
      "Train 131 | out_loss 13.77079963684082: 100%|████| 8/8 [00:00<00:00, 207.48it/s]\n",
      "Train 132 | out_loss 13.521241188049316: 100%|███| 8/8 [00:00<00:00, 215.96it/s]\n",
      "Train 133 | out_loss 14.374844551086426: 100%|███| 8/8 [00:00<00:00, 211.61it/s]\n",
      "Train 134 | out_loss 14.04688549041748: 100%|████| 8/8 [00:00<00:00, 216.83it/s]\n",
      "Train 135 | out_loss 14.291901588439941: 100%|███| 8/8 [00:00<00:00, 217.06it/s]\n",
      "Train 136 | out_loss 13.234551429748535: 100%|███| 8/8 [00:00<00:00, 219.28it/s]\n",
      "Train 137 | out_loss 13.34365177154541: 100%|████| 8/8 [00:00<00:00, 217.15it/s]\n",
      "Train 138 | out_loss 13.202147483825684: 100%|███| 8/8 [00:00<00:00, 209.24it/s]\n",
      "Train 139 | out_loss 13.733177185058594: 100%|███| 8/8 [00:00<00:00, 213.97it/s]\n",
      "Train 140 | out_loss 13.46606159210205: 100%|████| 8/8 [00:00<00:00, 194.17it/s]\n",
      "Train 141 | out_loss 12.985011100769043: 100%|███| 8/8 [00:00<00:00, 191.56it/s]\n",
      "Train 142 | out_loss 13.009815216064453: 100%|███| 8/8 [00:00<00:00, 203.99it/s]\n",
      "Train 143 | out_loss 13.521153450012207: 100%|███| 8/8 [00:00<00:00, 212.56it/s]\n",
      "Train 144 | out_loss 13.356268882751465: 100%|███| 8/8 [00:00<00:00, 180.58it/s]\n",
      "Train 145 | out_loss 13.015127182006836: 100%|███| 8/8 [00:00<00:00, 209.89it/s]\n",
      "Train 146 | out_loss 12.969353675842285: 100%|███| 8/8 [00:00<00:00, 217.91it/s]\n",
      "Train 147 | out_loss 13.235655784606934: 100%|███| 8/8 [00:00<00:00, 219.68it/s]\n",
      "Train 148 | out_loss 14.073777198791504: 100%|███| 8/8 [00:00<00:00, 219.51it/s]\n",
      "Train 149 | out_loss 14.261223793029785: 100%|███| 8/8 [00:00<00:00, 219.22it/s]\n",
      "Train 150 | out_loss 13.130340576171875: 100%|███| 8/8 [00:00<00:00, 217.30it/s]\n",
      "Train 151 | out_loss 12.916926383972168: 100%|███| 8/8 [00:00<00:00, 216.16it/s]\n",
      "Train 152 | out_loss 13.646409034729004: 100%|███| 8/8 [00:00<00:00, 215.68it/s]\n",
      "Train 153 | out_loss 13.4749174118042: 100%|█████| 8/8 [00:00<00:00, 206.68it/s]\n",
      "Train 154 | out_loss 13.170437812805176: 100%|███| 8/8 [00:00<00:00, 172.31it/s]\n",
      "Train 155 | out_loss 13.754098892211914: 100%|███| 8/8 [00:00<00:00, 185.91it/s]\n",
      "Train 156 | out_loss 14.0623197555542: 100%|█████| 8/8 [00:00<00:00, 210.58it/s]\n",
      "Train 157 | out_loss 14.998220443725586: 100%|███| 8/8 [00:00<00:00, 211.92it/s]\n",
      "Train 158 | out_loss 13.661397933959961: 100%|███| 8/8 [00:00<00:00, 206.28it/s]\n",
      "Train 159 | out_loss 14.35004711151123: 100%|████| 8/8 [00:00<00:00, 207.81it/s]\n",
      "Train 160 | out_loss 15.330458641052246: 100%|███| 8/8 [00:00<00:00, 218.76it/s]\n",
      "Train 161 | out_loss 16.72722625732422: 100%|████| 8/8 [00:00<00:00, 212.50it/s]\n",
      "Train 162 | out_loss 15.67143440246582: 100%|████| 8/8 [00:00<00:00, 210.28it/s]\n",
      "Train 163 | out_loss 15.191670417785645: 100%|███| 8/8 [00:00<00:00, 214.94it/s]\n",
      "Train 164 | out_loss 15.810260772705078: 100%|███| 8/8 [00:00<00:00, 221.71it/s]\n",
      "Train 165 | out_loss 16.663984298706055: 100%|███| 8/8 [00:00<00:00, 214.14it/s]\n",
      "Train 166 | out_loss 15.741012573242188: 100%|███| 8/8 [00:00<00:00, 212.54it/s]\n",
      "Train 167 | out_loss 14.258997917175293: 100%|███| 8/8 [00:00<00:00, 213.05it/s]\n",
      "Train 168 | out_loss 14.108023643493652: 100%|███| 8/8 [00:00<00:00, 217.24it/s]\n",
      "Train 169 | out_loss 15.819957733154297: 100%|███| 8/8 [00:00<00:00, 208.73it/s]\n",
      "Train 170 | out_loss 16.919145584106445: 100%|███| 8/8 [00:00<00:00, 213.85it/s]\n",
      "Train 171 | out_loss 17.70396614074707: 100%|████| 8/8 [00:00<00:00, 211.12it/s]\n",
      "Train 172 | out_loss 16.37529754638672: 100%|████| 8/8 [00:00<00:00, 219.01it/s]\n",
      "Train 173 | out_loss 15.198067665100098: 100%|███| 8/8 [00:00<00:00, 214.16it/s]\n",
      "Train 174 | out_loss 14.142318725585938: 100%|███| 8/8 [00:00<00:00, 209.30it/s]\n",
      "Train 175 | out_loss 13.281201362609863: 100%|███| 8/8 [00:00<00:00, 217.05it/s]\n",
      "Train 176 | out_loss 13.301350593566895: 100%|███| 8/8 [00:00<00:00, 219.21it/s]\n",
      "Train 177 | out_loss 13.508405685424805: 100%|███| 8/8 [00:00<00:00, 206.84it/s]\n",
      "Train 178 | out_loss 13.177412986755371: 100%|███| 8/8 [00:00<00:00, 207.49it/s]\n",
      "Train 179 | out_loss 13.742074012756348: 100%|███| 8/8 [00:00<00:00, 192.46it/s]\n",
      "Train 180 | out_loss 13.066842079162598: 100%|███| 8/8 [00:00<00:00, 173.00it/s]\n",
      "Train 181 | out_loss 12.98066520690918: 100%|████| 8/8 [00:00<00:00, 209.55it/s]\n",
      "Train 182 | out_loss 13.339777946472168: 100%|███| 8/8 [00:00<00:00, 214.43it/s]\n",
      "Train 183 | out_loss 13.29819393157959: 100%|████| 8/8 [00:00<00:00, 215.86it/s]\n",
      "Train 184 | out_loss 13.596569061279297: 100%|███| 8/8 [00:00<00:00, 219.16it/s]\n",
      "Train 185 | out_loss 13.645394325256348: 100%|███| 8/8 [00:00<00:00, 210.06it/s]\n",
      "Train 186 | out_loss 13.699044227600098: 100%|███| 8/8 [00:00<00:00, 216.92it/s]\n",
      "Train 187 | out_loss 13.102607727050781: 100%|███| 8/8 [00:00<00:00, 217.04it/s]\n",
      "Train 188 | out_loss 13.034343719482422: 100%|███| 8/8 [00:00<00:00, 217.04it/s]\n",
      "Train 189 | out_loss 12.971550941467285: 100%|███| 8/8 [00:00<00:00, 218.51it/s]\n",
      "Train 190 | out_loss 12.935590744018555: 100%|███| 8/8 [00:00<00:00, 216.99it/s]\n",
      "Train 191 | out_loss 12.931585311889648: 100%|███| 8/8 [00:00<00:00, 212.71it/s]\n",
      "Train 192 | out_loss 12.914454460144043: 100%|███| 8/8 [00:00<00:00, 214.64it/s]\n",
      "Train 193 | out_loss 13.25995922088623: 100%|████| 8/8 [00:00<00:00, 214.54it/s]\n",
      "Train 194 | out_loss 13.044693946838379: 100%|███| 8/8 [00:00<00:00, 211.24it/s]\n",
      "Train 195 | out_loss 13.312028884887695: 100%|███| 8/8 [00:00<00:00, 214.43it/s]\n",
      "Train 196 | out_loss 13.378632545471191: 100%|███| 8/8 [00:00<00:00, 216.04it/s]\n",
      "Train 197 | out_loss 13.385022163391113: 100%|███| 8/8 [00:00<00:00, 213.62it/s]\n",
      "Train 198 | out_loss 13.036096572875977: 100%|███| 8/8 [00:00<00:00, 210.02it/s]\n",
      "Train 199 | out_loss 12.887648582458496: 100%|███| 8/8 [00:00<00:00, 206.20it/s]\n",
      "Train 200 | out_loss 12.92999267578125: 100%|████| 8/8 [00:00<00:00, 211.81it/s]\n",
      "Train 201 | out_loss 12.982941627502441: 100%|███| 8/8 [00:00<00:00, 205.29it/s]\n",
      "Train 202 | out_loss 13.026814460754395: 100%|███| 8/8 [00:00<00:00, 213.63it/s]\n",
      "Train 203 | out_loss 13.085648536682129: 100%|███| 8/8 [00:00<00:00, 202.51it/s]\n",
      "Train 204 | out_loss 12.962339401245117: 100%|███| 8/8 [00:00<00:00, 211.48it/s]\n",
      "Train 205 | out_loss 12.88301944732666: 100%|████| 8/8 [00:00<00:00, 209.59it/s]\n",
      "Train 206 | out_loss 13.14584732055664: 100%|████| 8/8 [00:00<00:00, 203.21it/s]\n",
      "Train 207 | out_loss 13.296518325805664: 100%|███| 8/8 [00:00<00:00, 214.09it/s]\n",
      "Train 208 | out_loss 12.903305053710938: 100%|███| 8/8 [00:00<00:00, 213.71it/s]\n",
      "Train 209 | out_loss 12.961816787719727: 100%|███| 8/8 [00:00<00:00, 212.82it/s]\n",
      "Train 210 | out_loss 13.026961326599121: 100%|███| 8/8 [00:00<00:00, 213.32it/s]\n",
      "Train 211 | out_loss 13.01642894744873: 100%|████| 8/8 [00:00<00:00, 216.81it/s]\n",
      "Train 212 | out_loss 12.977287292480469: 100%|███| 8/8 [00:00<00:00, 216.00it/s]\n",
      "Train 213 | out_loss 12.927199363708496: 100%|███| 8/8 [00:00<00:00, 215.52it/s]\n",
      "Train 214 | out_loss 12.8251314163208: 100%|█████| 8/8 [00:00<00:00, 214.60it/s]\n",
      "Train 215 | out_loss 12.907182693481445: 100%|███| 8/8 [00:00<00:00, 207.62it/s]\n",
      "Train 216 | out_loss 12.823657035827637: 100%|███| 8/8 [00:00<00:00, 216.80it/s]\n",
      "Train 217 | out_loss 12.831448554992676: 100%|███| 8/8 [00:00<00:00, 199.07it/s]\n",
      "Train 218 | out_loss 12.886310577392578: 100%|███| 8/8 [00:00<00:00, 204.86it/s]\n",
      "Train 219 | out_loss 13.021574974060059: 100%|███| 8/8 [00:00<00:00, 217.74it/s]\n",
      "Train 220 | out_loss 12.905344009399414: 100%|███| 8/8 [00:00<00:00, 218.27it/s]\n",
      "Train 221 | out_loss 12.8988676071167: 100%|█████| 8/8 [00:00<00:00, 210.07it/s]\n",
      "Train 222 | out_loss 13.223739624023438: 100%|███| 8/8 [00:00<00:00, 218.68it/s]\n",
      "Train 223 | out_loss 13.24463176727295: 100%|████| 8/8 [00:00<00:00, 211.37it/s]\n",
      "Train 224 | out_loss 13.392589569091797: 100%|███| 8/8 [00:00<00:00, 213.14it/s]\n",
      "Train 225 | out_loss 12.93607234954834: 100%|████| 8/8 [00:00<00:00, 214.02it/s]\n",
      "Train 226 | out_loss 12.826630592346191: 100%|███| 8/8 [00:00<00:00, 207.11it/s]\n",
      "Train 227 | out_loss 12.779930114746094: 100%|███| 8/8 [00:00<00:00, 207.53it/s]\n",
      "Train 228 | out_loss 12.87135124206543: 100%|████| 8/8 [00:00<00:00, 215.36it/s]\n",
      "Train 229 | out_loss 13.021831512451172: 100%|███| 8/8 [00:00<00:00, 207.00it/s]\n",
      "Train 230 | out_loss 13.35128402709961: 100%|████| 8/8 [00:00<00:00, 207.64it/s]\n",
      "Train 231 | out_loss 12.960898399353027: 100%|███| 8/8 [00:00<00:00, 214.71it/s]\n",
      "Train 232 | out_loss 12.937969207763672: 100%|███| 8/8 [00:00<00:00, 210.89it/s]\n",
      "Train 233 | out_loss 12.979623794555664: 100%|███| 8/8 [00:00<00:00, 205.39it/s]\n",
      "Train 234 | out_loss 12.91812801361084: 100%|████| 8/8 [00:00<00:00, 202.57it/s]\n",
      "Train 235 | out_loss 12.896458625793457: 100%|███| 8/8 [00:00<00:00, 204.33it/s]\n",
      "Train 236 | out_loss 12.958416938781738: 100%|███| 8/8 [00:00<00:00, 215.21it/s]\n",
      "Train 237 | out_loss 13.0775728225708: 100%|█████| 8/8 [00:00<00:00, 211.65it/s]\n",
      "Train 238 | out_loss 13.178611755371094: 100%|███| 8/8 [00:00<00:00, 213.57it/s]\n",
      "Train 239 | out_loss 13.280831336975098: 100%|███| 8/8 [00:00<00:00, 208.00it/s]\n",
      "Train 240 | out_loss 12.94482707977295: 100%|████| 8/8 [00:00<00:00, 168.29it/s]\n",
      "Train 241 | out_loss 12.845325469970703: 100%|███| 8/8 [00:00<00:00, 201.41it/s]\n",
      "Train 242 | out_loss 12.675640106201172: 100%|███| 8/8 [00:00<00:00, 210.26it/s]\n",
      "Train 243 | out_loss 12.844846725463867: 100%|███| 8/8 [00:00<00:00, 212.94it/s]\n",
      "Train 244 | out_loss 12.700782775878906: 100%|███| 8/8 [00:00<00:00, 215.58it/s]\n",
      "Train 245 | out_loss 12.640181541442871: 100%|███| 8/8 [00:00<00:00, 206.97it/s]\n",
      "Train 246 | out_loss 12.614133834838867: 100%|███| 8/8 [00:00<00:00, 213.36it/s]\n",
      "Train 247 | out_loss 12.740474700927734: 100%|███| 8/8 [00:00<00:00, 211.01it/s]\n",
      "Train 248 | out_loss 12.816269874572754: 100%|███| 8/8 [00:00<00:00, 203.64it/s]\n",
      "Train 249 | out_loss 12.86557388305664: 100%|████| 8/8 [00:00<00:00, 212.95it/s]\n",
      "Train 250 | out_loss 12.637359619140625: 100%|███| 8/8 [00:00<00:00, 213.31it/s]\n",
      "Train 251 | out_loss 12.537373542785645: 100%|███| 8/8 [00:00<00:00, 213.97it/s]\n",
      "Train 252 | out_loss 12.567666053771973: 100%|███| 8/8 [00:00<00:00, 208.93it/s]\n",
      "Train 253 | out_loss 12.537935256958008: 100%|███| 8/8 [00:00<00:00, 192.25it/s]\n",
      "Train 254 | out_loss 12.56351089477539: 100%|████| 8/8 [00:00<00:00, 191.72it/s]\n",
      "Train 255 | out_loss 12.735273361206055: 100%|███| 8/8 [00:00<00:00, 204.13it/s]\n",
      "Train 256 | out_loss 12.619816780090332: 100%|███| 8/8 [00:00<00:00, 212.05it/s]\n",
      "Train 257 | out_loss 12.60760498046875: 100%|████| 8/8 [00:00<00:00, 195.32it/s]\n",
      "Train 258 | out_loss 12.666258811950684: 100%|███| 8/8 [00:00<00:00, 210.71it/s]\n",
      "Train 259 | out_loss 12.527595520019531: 100%|███| 8/8 [00:00<00:00, 210.46it/s]\n",
      "Train 260 | out_loss 12.564712524414062: 100%|███| 8/8 [00:00<00:00, 212.77it/s]\n",
      "Train 261 | out_loss 12.432656288146973: 100%|███| 8/8 [00:00<00:00, 217.47it/s]\n",
      "Train 262 | out_loss 12.391654968261719: 100%|███| 8/8 [00:00<00:00, 209.44it/s]\n",
      "Train 263 | out_loss 12.555091857910156: 100%|███| 8/8 [00:00<00:00, 210.70it/s]\n",
      "Train 264 | out_loss 12.410990715026855: 100%|███| 8/8 [00:00<00:00, 216.00it/s]\n",
      "Train 265 | out_loss 12.310324668884277: 100%|███| 8/8 [00:00<00:00, 207.69it/s]\n",
      "Train 266 | out_loss 12.374920845031738: 100%|███| 8/8 [00:00<00:00, 208.60it/s]\n",
      "Train 267 | out_loss 12.38908576965332: 100%|████| 8/8 [00:00<00:00, 213.76it/s]\n",
      "Train 268 | out_loss 12.395172119140625: 100%|███| 8/8 [00:00<00:00, 214.84it/s]\n",
      "Train 269 | out_loss 12.33040714263916: 100%|████| 8/8 [00:00<00:00, 216.18it/s]\n",
      "Train 270 | out_loss 12.45336627960205: 100%|████| 8/8 [00:00<00:00, 218.45it/s]\n",
      "Train 271 | out_loss 12.47958755493164: 100%|████| 8/8 [00:00<00:00, 213.37it/s]\n",
      "Train 272 | out_loss 12.387990951538086: 100%|███| 8/8 [00:00<00:00, 208.31it/s]\n",
      "Train 273 | out_loss 12.603020668029785: 100%|███| 8/8 [00:00<00:00, 215.49it/s]\n",
      "Train 274 | out_loss 12.330077171325684: 100%|███| 8/8 [00:00<00:00, 196.66it/s]\n",
      "Train 275 | out_loss 12.458149909973145: 100%|███| 8/8 [00:00<00:00, 207.56it/s]\n",
      "Train 276 | out_loss 12.42831802368164: 100%|████| 8/8 [00:00<00:00, 203.56it/s]\n",
      "Train 277 | out_loss 12.564208030700684: 100%|███| 8/8 [00:00<00:00, 211.43it/s]\n",
      "Train 278 | out_loss 12.459896087646484: 100%|███| 8/8 [00:00<00:00, 184.71it/s]\n",
      "Train 279 | out_loss 12.333219528198242: 100%|███| 8/8 [00:00<00:00, 197.45it/s]\n",
      "Train 280 | out_loss 12.473889350891113: 100%|███| 8/8 [00:00<00:00, 207.35it/s]\n",
      "Train 281 | out_loss 12.179081916809082: 100%|███| 8/8 [00:00<00:00, 215.03it/s]\n",
      "Train 282 | out_loss 12.300607681274414: 100%|███| 8/8 [00:00<00:00, 209.45it/s]\n",
      "Train 283 | out_loss 12.35058307647705: 100%|████| 8/8 [00:00<00:00, 214.23it/s]\n",
      "Train 284 | out_loss 12.216156959533691: 100%|███| 8/8 [00:00<00:00, 215.17it/s]\n",
      "Train 285 | out_loss 12.118025779724121: 100%|███| 8/8 [00:00<00:00, 213.99it/s]\n",
      "Train 286 | out_loss 12.158258438110352: 100%|███| 8/8 [00:00<00:00, 211.51it/s]\n",
      "Train 287 | out_loss 12.311068534851074: 100%|███| 8/8 [00:00<00:00, 215.93it/s]\n",
      "Train 288 | out_loss 12.299700736999512: 100%|███| 8/8 [00:00<00:00, 214.08it/s]\n",
      "Train 289 | out_loss 12.26865005493164: 100%|████| 8/8 [00:00<00:00, 219.39it/s]\n",
      "Train 290 | out_loss 12.703063011169434: 100%|███| 8/8 [00:00<00:00, 214.24it/s]\n",
      "Train 291 | out_loss 12.5691556930542: 100%|█████| 8/8 [00:00<00:00, 213.29it/s]\n",
      "Train 292 | out_loss 12.189412117004395: 100%|███| 8/8 [00:00<00:00, 208.86it/s]\n",
      "Train 293 | out_loss 12.29512882232666: 100%|████| 8/8 [00:00<00:00, 206.49it/s]\n",
      "Train 294 | out_loss 12.653696060180664: 100%|███| 8/8 [00:00<00:00, 213.07it/s]\n",
      "Train 295 | out_loss 12.537758827209473: 100%|███| 8/8 [00:00<00:00, 195.47it/s]\n",
      "Train 296 | out_loss 12.241798400878906: 100%|███| 8/8 [00:00<00:00, 207.23it/s]\n",
      "Train 297 | out_loss 12.244427680969238: 100%|███| 8/8 [00:00<00:00, 212.70it/s]\n",
      "Train 298 | out_loss 12.01878833770752: 100%|████| 8/8 [00:00<00:00, 167.32it/s]\n",
      "Train 299 | out_loss 12.367340087890625: 100%|███| 8/8 [00:00<00:00, 188.09it/s]\n",
      "Train 300 | out_loss 12.609094619750977: 100%|███| 8/8 [00:00<00:00, 192.91it/s]\n",
      "Train 301 | out_loss 12.237489700317383: 100%|███| 8/8 [00:00<00:00, 195.90it/s]\n",
      "Train 302 | out_loss 12.09203815460205: 100%|████| 8/8 [00:00<00:00, 202.68it/s]\n",
      "Train 303 | out_loss 12.17373275756836: 100%|████| 8/8 [00:00<00:00, 217.46it/s]\n",
      "Train 304 | out_loss 12.496452331542969: 100%|███| 8/8 [00:00<00:00, 211.07it/s]\n",
      "Train 305 | out_loss 12.027081489562988: 100%|███| 8/8 [00:00<00:00, 209.01it/s]\n",
      "Train 306 | out_loss 12.044035911560059: 100%|███| 8/8 [00:00<00:00, 210.18it/s]\n",
      "Train 307 | out_loss 12.003422737121582: 100%|███| 8/8 [00:00<00:00, 209.57it/s]\n",
      "Train 308 | out_loss 11.941115379333496: 100%|███| 8/8 [00:00<00:00, 213.80it/s]\n",
      "Train 309 | out_loss 11.66899299621582: 100%|████| 8/8 [00:00<00:00, 208.49it/s]\n",
      "Train 310 | out_loss 11.858357429504395: 100%|███| 8/8 [00:00<00:00, 210.28it/s]\n",
      "Train 311 | out_loss 11.921255111694336: 100%|███| 8/8 [00:00<00:00, 214.20it/s]\n",
      "Train 312 | out_loss 11.875840187072754: 100%|███| 8/8 [00:00<00:00, 216.15it/s]\n",
      "Train 313 | out_loss 11.973881721496582: 100%|███| 8/8 [00:00<00:00, 211.81it/s]\n",
      "Train 314 | out_loss 11.96528148651123: 100%|████| 8/8 [00:00<00:00, 216.42it/s]\n",
      "Train 315 | out_loss 11.97813892364502: 100%|████| 8/8 [00:00<00:00, 212.87it/s]\n",
      "Train 316 | out_loss 12.035909652709961: 100%|███| 8/8 [00:00<00:00, 209.53it/s]\n",
      "Train 317 | out_loss 12.241975784301758: 100%|███| 8/8 [00:00<00:00, 206.37it/s]\n",
      "Train 318 | out_loss 12.454597473144531: 100%|███| 8/8 [00:00<00:00, 189.95it/s]\n",
      "Train 319 | out_loss 12.039323806762695: 100%|███| 8/8 [00:00<00:00, 204.73it/s]\n",
      "Train 320 | out_loss 12.000044822692871: 100%|███| 8/8 [00:00<00:00, 208.04it/s]\n",
      "Train 321 | out_loss 11.895679473876953: 100%|███| 8/8 [00:00<00:00, 207.83it/s]\n",
      "Train 322 | out_loss 11.869873046875: 100%|██████| 8/8 [00:00<00:00, 212.83it/s]\n",
      "Train 323 | out_loss 11.907715797424316: 100%|███| 8/8 [00:00<00:00, 218.58it/s]\n",
      "Train 324 | out_loss 11.974614143371582: 100%|███| 8/8 [00:00<00:00, 213.46it/s]\n",
      "Train 325 | out_loss 11.928712844848633: 100%|███| 8/8 [00:00<00:00, 216.58it/s]\n",
      "Train 326 | out_loss 11.9193696975708: 100%|█████| 8/8 [00:00<00:00, 214.32it/s]\n",
      "Train 327 | out_loss 12.256439208984375: 100%|███| 8/8 [00:00<00:00, 210.69it/s]\n",
      "Train 328 | out_loss 12.259305000305176: 100%|███| 8/8 [00:00<00:00, 218.22it/s]\n",
      "Train 329 | out_loss 11.920208930969238: 100%|███| 8/8 [00:00<00:00, 200.80it/s]\n",
      "Train 330 | out_loss 12.184537887573242: 100%|███| 8/8 [00:00<00:00, 207.67it/s]\n",
      "Train 331 | out_loss 12.110926628112793: 100%|███| 8/8 [00:00<00:00, 213.50it/s]\n",
      "Train 332 | out_loss 12.250149726867676: 100%|███| 8/8 [00:00<00:00, 209.12it/s]\n",
      "Train 333 | out_loss 11.861327171325684: 100%|███| 8/8 [00:00<00:00, 208.72it/s]\n",
      "Train 334 | out_loss 12.211810111999512: 100%|███| 8/8 [00:00<00:00, 216.28it/s]\n",
      "Train 335 | out_loss 12.0326566696167: 100%|█████| 8/8 [00:00<00:00, 213.82it/s]\n",
      "Train 336 | out_loss 12.1509370803833: 100%|█████| 8/8 [00:00<00:00, 212.52it/s]\n",
      "Train 337 | out_loss 12.14769172668457: 100%|████| 8/8 [00:00<00:00, 217.37it/s]\n",
      "Train 338 | out_loss 11.950031280517578: 100%|███| 8/8 [00:00<00:00, 215.39it/s]\n",
      "Train 339 | out_loss 11.985455513000488: 100%|███| 8/8 [00:00<00:00, 209.59it/s]\n",
      "Train 340 | out_loss 11.764147758483887: 100%|███| 8/8 [00:00<00:00, 216.62it/s]\n",
      "Train 341 | out_loss 11.707343101501465: 100%|███| 8/8 [00:00<00:00, 209.21it/s]\n",
      "Train 342 | out_loss 11.503826141357422: 100%|███| 8/8 [00:00<00:00, 196.73it/s]\n",
      "Train 343 | out_loss 11.543654441833496: 100%|███| 8/8 [00:00<00:00, 197.21it/s]\n",
      "Train 344 | out_loss 11.611268997192383: 100%|███| 8/8 [00:00<00:00, 214.52it/s]\n",
      "Train 345 | out_loss 12.173016548156738: 100%|███| 8/8 [00:00<00:00, 212.39it/s]\n",
      "Train 346 | out_loss 11.71819019317627: 100%|████| 8/8 [00:00<00:00, 202.29it/s]\n",
      "Train 347 | out_loss 11.603153228759766: 100%|███| 8/8 [00:00<00:00, 216.63it/s]\n",
      "Train 348 | out_loss 11.712981224060059: 100%|███| 8/8 [00:00<00:00, 202.55it/s]\n",
      "Train 349 | out_loss 12.060966491699219: 100%|███| 8/8 [00:00<00:00, 216.41it/s]\n",
      "Train 350 | out_loss 11.804850578308105: 100%|███| 8/8 [00:00<00:00, 208.39it/s]\n",
      "Train 351 | out_loss 11.797552108764648: 100%|███| 8/8 [00:00<00:00, 216.77it/s]\n",
      "Train 352 | out_loss 11.828351020812988: 100%|███| 8/8 [00:00<00:00, 217.89it/s]\n",
      "Train 353 | out_loss 12.050789833068848: 100%|███| 8/8 [00:00<00:00, 214.37it/s]\n",
      "Train 354 | out_loss 11.879770278930664: 100%|███| 8/8 [00:00<00:00, 210.09it/s]\n",
      "Train 355 | out_loss 11.601174354553223: 100%|███| 8/8 [00:00<00:00, 190.78it/s]\n",
      "Train 356 | out_loss 12.170014381408691: 100%|███| 8/8 [00:00<00:00, 216.73it/s]\n",
      "Train 357 | out_loss 11.948974609375: 100%|██████| 8/8 [00:00<00:00, 215.81it/s]\n",
      "Train 358 | out_loss 11.77408504486084: 100%|████| 8/8 [00:00<00:00, 213.80it/s]\n",
      "Train 359 | out_loss 11.741121292114258: 100%|███| 8/8 [00:00<00:00, 214.45it/s]\n",
      "Train 360 | out_loss 12.13847827911377: 100%|████| 8/8 [00:00<00:00, 216.75it/s]\n",
      "Train 361 | out_loss 12.853948593139648: 100%|███| 8/8 [00:00<00:00, 211.21it/s]\n",
      "Train 362 | out_loss 11.797418594360352: 100%|███| 8/8 [00:00<00:00, 209.51it/s]\n",
      "Train 363 | out_loss 12.340664863586426: 100%|███| 8/8 [00:00<00:00, 209.61it/s]\n",
      "Train 364 | out_loss 11.982755661010742: 100%|███| 8/8 [00:00<00:00, 220.23it/s]\n",
      "Train 365 | out_loss 11.755853652954102: 100%|███| 8/8 [00:00<00:00, 219.98it/s]\n",
      "Train 366 | out_loss 11.829695701599121: 100%|███| 8/8 [00:00<00:00, 203.11it/s]\n",
      "Train 367 | out_loss 13.234789848327637: 100%|███| 8/8 [00:00<00:00, 217.96it/s]\n",
      "Train 368 | out_loss 12.314818382263184: 100%|███| 8/8 [00:00<00:00, 203.75it/s]\n",
      "Train 369 | out_loss 12.168282508850098: 100%|███| 8/8 [00:00<00:00, 211.45it/s]\n",
      "Train 370 | out_loss 11.880949974060059: 100%|███| 8/8 [00:00<00:00, 217.69it/s]\n",
      "Train 371 | out_loss 11.44840145111084: 100%|████| 8/8 [00:00<00:00, 213.52it/s]\n",
      "Train 372 | out_loss 11.646174430847168: 100%|███| 8/8 [00:00<00:00, 215.67it/s]\n",
      "Train 373 | out_loss 11.8024263381958: 100%|█████| 8/8 [00:00<00:00, 210.91it/s]\n",
      "Train 374 | out_loss 12.056417465209961: 100%|███| 8/8 [00:00<00:00, 206.33it/s]\n",
      "Train 375 | out_loss 11.926624298095703: 100%|███| 8/8 [00:00<00:00, 212.47it/s]\n",
      "Train 376 | out_loss 11.992962837219238: 100%|███| 8/8 [00:00<00:00, 211.00it/s]\n",
      "Train 377 | out_loss 12.271622657775879: 100%|███| 8/8 [00:00<00:00, 219.00it/s]\n",
      "Train 378 | out_loss 11.817158699035645: 100%|███| 8/8 [00:00<00:00, 217.94it/s]\n",
      "Train 379 | out_loss 11.793059349060059: 100%|███| 8/8 [00:00<00:00, 215.02it/s]\n",
      "Train 380 | out_loss 11.50912857055664: 100%|████| 8/8 [00:00<00:00, 203.54it/s]\n",
      "Train 381 | out_loss 11.628661155700684: 100%|███| 8/8 [00:00<00:00, 211.82it/s]\n",
      "Train 382 | out_loss 12.098861694335938: 100%|███| 8/8 [00:00<00:00, 209.90it/s]\n",
      "Train 383 | out_loss 12.206966400146484: 100%|███| 8/8 [00:00<00:00, 208.24it/s]\n",
      "Train 384 | out_loss 11.62696647644043: 100%|████| 8/8 [00:00<00:00, 210.65it/s]\n",
      "Train 385 | out_loss 12.532393455505371: 100%|███| 8/8 [00:00<00:00, 215.02it/s]\n",
      "Train 386 | out_loss 12.383357048034668: 100%|███| 8/8 [00:00<00:00, 212.92it/s]\n",
      "Train 387 | out_loss 11.900559425354004: 100%|███| 8/8 [00:00<00:00, 216.26it/s]\n",
      "Train 388 | out_loss 11.688965797424316: 100%|███| 8/8 [00:00<00:00, 212.88it/s]\n",
      "Train 389 | out_loss 11.936395645141602: 100%|███| 8/8 [00:00<00:00, 213.97it/s]\n",
      "Train 390 | out_loss 11.729799270629883: 100%|███| 8/8 [00:00<00:00, 214.01it/s]\n",
      "Train 391 | out_loss 11.91759204864502: 100%|████| 8/8 [00:00<00:00, 213.06it/s]\n",
      "Train 392 | out_loss 12.129977226257324: 100%|███| 8/8 [00:00<00:00, 219.81it/s]\n",
      "Train 393 | out_loss 11.819878578186035: 100%|███| 8/8 [00:00<00:00, 216.59it/s]\n",
      "Train 394 | out_loss 11.577977180480957: 100%|███| 8/8 [00:00<00:00, 215.40it/s]\n",
      "Train 395 | out_loss 11.481973648071289: 100%|███| 8/8 [00:00<00:00, 211.07it/s]\n",
      "Train 396 | out_loss 11.656296730041504: 100%|███| 8/8 [00:00<00:00, 208.73it/s]\n",
      "Train 397 | out_loss 11.354805946350098: 100%|███| 8/8 [00:00<00:00, 215.81it/s]\n",
      "Train 398 | out_loss 11.485298156738281: 100%|███| 8/8 [00:00<00:00, 204.78it/s]\n",
      "Train 399 | out_loss 11.54664134979248: 100%|████| 8/8 [00:00<00:00, 191.42it/s]\n",
      "Train 400 | out_loss 12.072370529174805: 100%|███| 8/8 [00:00<00:00, 208.36it/s]\n",
      "Train 401 | out_loss 11.598037719726562: 100%|███| 8/8 [00:00<00:00, 210.35it/s]\n",
      "Train 402 | out_loss 11.33684253692627: 100%|████| 8/8 [00:00<00:00, 209.35it/s]\n",
      "Train 403 | out_loss 11.559072494506836: 100%|███| 8/8 [00:00<00:00, 212.08it/s]\n",
      "Train 404 | out_loss 11.650579452514648: 100%|███| 8/8 [00:00<00:00, 214.55it/s]\n",
      "Train 405 | out_loss 11.391094207763672: 100%|███| 8/8 [00:00<00:00, 195.91it/s]\n",
      "Train 406 | out_loss 11.844704627990723: 100%|███| 8/8 [00:00<00:00, 206.90it/s]\n",
      "Train 407 | out_loss 11.322303771972656: 100%|███| 8/8 [00:00<00:00, 210.77it/s]\n",
      "Train 408 | out_loss 11.44114875793457: 100%|████| 8/8 [00:00<00:00, 209.98it/s]\n",
      "Train 409 | out_loss 11.505548477172852: 100%|███| 8/8 [00:00<00:00, 215.20it/s]\n",
      "Train 410 | out_loss 11.60872745513916: 100%|████| 8/8 [00:00<00:00, 144.41it/s]\n",
      "Train 411 | out_loss 11.399218559265137: 100%|███| 8/8 [00:00<00:00, 169.41it/s]\n",
      "Train 412 | out_loss 11.240736961364746: 100%|███| 8/8 [00:00<00:00, 211.95it/s]\n",
      "Train 413 | out_loss 11.243176460266113: 100%|███| 8/8 [00:00<00:00, 203.51it/s]\n",
      "Train 414 | out_loss 11.91477108001709: 100%|████| 8/8 [00:00<00:00, 216.96it/s]\n",
      "Train 415 | out_loss 12.194740295410156: 100%|███| 8/8 [00:00<00:00, 168.14it/s]\n",
      "Train 416 | out_loss 11.440319061279297: 100%|███| 8/8 [00:00<00:00, 218.53it/s]\n",
      "Train 417 | out_loss 11.828038215637207: 100%|███| 8/8 [00:00<00:00, 218.80it/s]\n",
      "Train 418 | out_loss 11.745864868164062: 100%|███| 8/8 [00:00<00:00, 221.98it/s]\n",
      "Train 419 | out_loss 11.92182731628418: 100%|████| 8/8 [00:00<00:00, 217.60it/s]\n",
      "Train 420 | out_loss 11.527565002441406: 100%|███| 8/8 [00:00<00:00, 214.49it/s]\n",
      "Train 421 | out_loss 11.437403678894043: 100%|███| 8/8 [00:00<00:00, 208.14it/s]\n",
      "Train 422 | out_loss 11.604373931884766: 100%|███| 8/8 [00:00<00:00, 209.10it/s]\n",
      "Train 423 | out_loss 11.40527629852295: 100%|████| 8/8 [00:00<00:00, 213.79it/s]\n",
      "Train 424 | out_loss 11.507530212402344: 100%|███| 8/8 [00:00<00:00, 212.89it/s]\n",
      "Train 425 | out_loss 11.332402229309082: 100%|███| 8/8 [00:00<00:00, 213.44it/s]\n",
      "Train 426 | out_loss 11.407814025878906: 100%|███| 8/8 [00:00<00:00, 178.03it/s]\n",
      "Train 427 | out_loss 12.183130264282227: 100%|███| 8/8 [00:00<00:00, 210.24it/s]\n",
      "Train 428 | out_loss 11.513035774230957: 100%|███| 8/8 [00:00<00:00, 218.72it/s]\n",
      "Train 429 | out_loss 11.725830078125: 100%|██████| 8/8 [00:00<00:00, 189.60it/s]\n",
      "Train 430 | out_loss 11.897652626037598: 100%|███| 8/8 [00:00<00:00, 179.40it/s]\n",
      "Train 431 | out_loss 11.786619186401367: 100%|███| 8/8 [00:00<00:00, 205.13it/s]\n",
      "Train 432 | out_loss 11.383111000061035: 100%|███| 8/8 [00:00<00:00, 210.25it/s]\n",
      "Train 433 | out_loss 11.452425003051758: 100%|███| 8/8 [00:00<00:00, 215.18it/s]\n",
      "Train 434 | out_loss 11.217531204223633: 100%|███| 8/8 [00:00<00:00, 210.19it/s]\n",
      "Train 435 | out_loss 11.287919044494629: 100%|███| 8/8 [00:00<00:00, 205.99it/s]\n",
      "Train 436 | out_loss 11.288270950317383: 100%|███| 8/8 [00:00<00:00, 211.96it/s]\n",
      "Train 437 | out_loss 11.23476791381836: 100%|████| 8/8 [00:00<00:00, 208.53it/s]\n",
      "Train 438 | out_loss 12.754029273986816: 100%|███| 8/8 [00:00<00:00, 214.03it/s]\n",
      "Train 439 | out_loss 11.450729370117188: 100%|███| 8/8 [00:00<00:00, 207.10it/s]\n",
      "Train 440 | out_loss 11.587614059448242: 100%|███| 8/8 [00:00<00:00, 208.35it/s]\n",
      "Train 441 | out_loss 11.774380683898926: 100%|███| 8/8 [00:00<00:00, 214.18it/s]\n",
      "Train 442 | out_loss 11.502306938171387: 100%|███| 8/8 [00:00<00:00, 216.39it/s]\n",
      "Train 443 | out_loss 11.591998100280762: 100%|███| 8/8 [00:00<00:00, 218.11it/s]\n",
      "Train 444 | out_loss 11.921887397766113: 100%|███| 8/8 [00:00<00:00, 210.67it/s]\n",
      "Train 445 | out_loss 12.022494316101074: 100%|███| 8/8 [00:00<00:00, 216.40it/s]\n",
      "Train 446 | out_loss 11.735492706298828: 100%|███| 8/8 [00:00<00:00, 216.27it/s]\n",
      "Train 447 | out_loss 11.737008094787598: 100%|███| 8/8 [00:00<00:00, 217.12it/s]\n",
      "Train 448 | out_loss 11.436368942260742: 100%|███| 8/8 [00:00<00:00, 214.64it/s]\n",
      "Train 449 | out_loss 11.461585998535156: 100%|███| 8/8 [00:00<00:00, 221.50it/s]\n",
      "Train 450 | out_loss 11.493431091308594: 100%|███| 8/8 [00:00<00:00, 219.87it/s]\n",
      "Train 451 | out_loss 11.360392570495605: 100%|███| 8/8 [00:00<00:00, 213.71it/s]\n",
      "Train 452 | out_loss 11.610980033874512: 100%|███| 8/8 [00:00<00:00, 209.87it/s]\n",
      "Train 453 | out_loss 12.038324356079102: 100%|███| 8/8 [00:00<00:00, 209.76it/s]\n",
      "Train 454 | out_loss 11.58122444152832: 100%|████| 8/8 [00:00<00:00, 211.40it/s]\n",
      "Train 455 | out_loss 11.506290435791016: 100%|███| 8/8 [00:00<00:00, 203.99it/s]\n",
      "Train 456 | out_loss 11.30833911895752: 100%|████| 8/8 [00:00<00:00, 218.78it/s]\n",
      "Train 457 | out_loss 11.317694664001465: 100%|███| 8/8 [00:00<00:00, 205.75it/s]\n",
      "Train 458 | out_loss 11.167779922485352: 100%|███| 8/8 [00:00<00:00, 213.37it/s]\n",
      "Train 459 | out_loss 11.934757232666016: 100%|███| 8/8 [00:00<00:00, 212.87it/s]\n",
      "Train 460 | out_loss 11.80225944519043: 100%|████| 8/8 [00:00<00:00, 209.94it/s]\n",
      "Train 461 | out_loss 11.67025089263916: 100%|████| 8/8 [00:00<00:00, 210.12it/s]\n",
      "Train 462 | out_loss 11.332489013671875: 100%|███| 8/8 [00:00<00:00, 218.58it/s]\n",
      "Train 463 | out_loss 11.438886642456055: 100%|███| 8/8 [00:00<00:00, 206.02it/s]\n",
      "Train 464 | out_loss 11.699898719787598: 100%|███| 8/8 [00:00<00:00, 190.68it/s]\n",
      "Train 465 | out_loss 11.695980072021484: 100%|███| 8/8 [00:00<00:00, 213.08it/s]\n",
      "Train 466 | out_loss 11.901780128479004: 100%|███| 8/8 [00:00<00:00, 215.45it/s]\n",
      "Train 467 | out_loss 11.741617202758789: 100%|███| 8/8 [00:00<00:00, 219.17it/s]\n",
      "Train 468 | out_loss 11.625900268554688: 100%|███| 8/8 [00:00<00:00, 212.69it/s]\n",
      "Train 469 | out_loss 11.539490699768066: 100%|███| 8/8 [00:00<00:00, 218.98it/s]\n",
      "Train 470 | out_loss 11.638725280761719: 100%|███| 8/8 [00:00<00:00, 216.83it/s]\n",
      "Train 471 | out_loss 11.575636863708496: 100%|███| 8/8 [00:00<00:00, 211.06it/s]\n",
      "Train 472 | out_loss 11.792819023132324: 100%|███| 8/8 [00:00<00:00, 215.89it/s]\n",
      "Train 473 | out_loss 11.565452575683594: 100%|███| 8/8 [00:00<00:00, 208.27it/s]\n",
      "Train 474 | out_loss 11.464349746704102: 100%|███| 8/8 [00:00<00:00, 216.50it/s]\n",
      "Train 475 | out_loss 11.948225021362305: 100%|███| 8/8 [00:00<00:00, 220.10it/s]\n",
      "Train 476 | out_loss 11.36945915222168: 100%|████| 8/8 [00:00<00:00, 212.80it/s]\n",
      "Train 477 | out_loss 12.17956829071045: 100%|████| 8/8 [00:00<00:00, 184.79it/s]\n",
      "Train 478 | out_loss 11.386346817016602: 100%|███| 8/8 [00:00<00:00, 209.49it/s]\n",
      "Train 479 | out_loss 11.574190139770508: 100%|███| 8/8 [00:00<00:00, 208.19it/s]\n",
      "Train 480 | out_loss 11.214916229248047: 100%|███| 8/8 [00:00<00:00, 215.82it/s]\n",
      "Train 481 | out_loss 11.434517860412598: 100%|███| 8/8 [00:00<00:00, 206.40it/s]\n",
      "Train 482 | out_loss 11.269828796386719: 100%|███| 8/8 [00:00<00:00, 220.84it/s]\n",
      "Train 483 | out_loss 11.215470314025879: 100%|███| 8/8 [00:00<00:00, 201.90it/s]\n",
      "Train 484 | out_loss 11.417401313781738: 100%|███| 8/8 [00:00<00:00, 216.90it/s]\n",
      "Train 485 | out_loss 11.140205383300781: 100%|███| 8/8 [00:00<00:00, 216.39it/s]\n",
      "Train 486 | out_loss 11.252605438232422: 100%|███| 8/8 [00:00<00:00, 207.03it/s]\n",
      "Train 487 | out_loss 11.18022346496582: 100%|████| 8/8 [00:00<00:00, 214.04it/s]\n",
      "Train 488 | out_loss 11.38442611694336: 100%|████| 8/8 [00:00<00:00, 213.56it/s]\n",
      "Train 489 | out_loss 11.208283424377441: 100%|███| 8/8 [00:00<00:00, 212.00it/s]\n",
      "Train 490 | out_loss 11.574759483337402: 100%|███| 8/8 [00:00<00:00, 211.40it/s]\n",
      "Train 491 | out_loss 11.257874488830566: 100%|███| 8/8 [00:00<00:00, 214.29it/s]\n",
      "Train 492 | out_loss 11.585777282714844: 100%|███| 8/8 [00:00<00:00, 208.06it/s]\n",
      "Train 493 | out_loss 11.471543312072754: 100%|███| 8/8 [00:00<00:00, 211.85it/s]\n",
      "Train 494 | out_loss 11.123780250549316: 100%|███| 8/8 [00:00<00:00, 214.04it/s]\n",
      "Train 495 | out_loss 11.108867645263672: 100%|███| 8/8 [00:00<00:00, 207.14it/s]\n",
      "Train 496 | out_loss 11.464181900024414: 100%|███| 8/8 [00:00<00:00, 217.02it/s]\n",
      "Train 497 | out_loss 11.69309139251709: 100%|████| 8/8 [00:00<00:00, 218.48it/s]\n",
      "Train 498 | out_loss 11.384156227111816: 100%|███| 8/8 [00:00<00:00, 215.42it/s]\n",
      "Train 499 | out_loss 11.287219047546387: 100%|███| 8/8 [00:00<00:00, 217.65it/s]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 80.2464828491211: 100%|████████| 8/8 [00:00<00:00, 19.20it/s]\n",
      "Train 1 | out_loss 79.38587188720703: 100%|██████| 8/8 [00:00<00:00, 187.94it/s]\n",
      "Train 2 | out_loss 75.31450653076172: 100%|██████| 8/8 [00:00<00:00, 178.29it/s]\n",
      "Train 3 | out_loss 75.60395050048828: 100%|██████| 8/8 [00:00<00:00, 180.07it/s]\n",
      "Train 4 | out_loss 76.63945770263672: 100%|██████| 8/8 [00:00<00:00, 167.44it/s]\n",
      "Train 5 | out_loss 75.26271057128906: 100%|██████| 8/8 [00:00<00:00, 177.41it/s]\n",
      "Train 6 | out_loss 73.62935638427734: 100%|██████| 8/8 [00:00<00:00, 185.97it/s]\n",
      "Train 7 | out_loss 72.37208557128906: 100%|██████| 8/8 [00:00<00:00, 179.48it/s]\n",
      "Train 8 | out_loss 71.75382995605469: 100%|██████| 8/8 [00:00<00:00, 166.38it/s]\n",
      "Train 9 | out_loss 70.48146057128906: 100%|██████| 8/8 [00:00<00:00, 180.38it/s]\n",
      "Train 10 | out_loss 69.52937316894531: 100%|█████| 8/8 [00:00<00:00, 174.48it/s]\n",
      "Train 11 | out_loss 68.43218994140625: 100%|█████| 8/8 [00:00<00:00, 170.03it/s]\n",
      "Train 12 | out_loss 67.30976867675781: 100%|█████| 8/8 [00:00<00:00, 175.35it/s]\n",
      "Train 13 | out_loss 65.78563690185547: 100%|█████| 8/8 [00:00<00:00, 116.73it/s]\n",
      "Train 14 | out_loss 65.67749786376953: 100%|█████| 8/8 [00:00<00:00, 171.28it/s]\n",
      "Train 15 | out_loss 63.89323806762695: 100%|█████| 8/8 [00:00<00:00, 179.58it/s]\n",
      "Train 16 | out_loss 63.57406234741211: 100%|█████| 8/8 [00:00<00:00, 173.62it/s]\n",
      "Train 17 | out_loss 61.895389556884766: 100%|████| 8/8 [00:00<00:00, 182.74it/s]\n",
      "Train 18 | out_loss 60.70916748046875: 100%|█████| 8/8 [00:00<00:00, 169.61it/s]\n",
      "Train 19 | out_loss 60.215576171875: 100%|███████| 8/8 [00:00<00:00, 173.98it/s]\n",
      "Train 20 | out_loss 58.92839813232422: 100%|█████| 8/8 [00:00<00:00, 164.24it/s]\n",
      "Train 21 | out_loss 57.742942810058594: 100%|████| 8/8 [00:00<00:00, 168.82it/s]\n",
      "Train 22 | out_loss 57.081092834472656: 100%|████| 8/8 [00:00<00:00, 162.08it/s]\n",
      "Train 23 | out_loss 55.98899459838867: 100%|█████| 8/8 [00:00<00:00, 162.64it/s]\n",
      "Train 24 | out_loss 54.957279205322266: 100%|████| 8/8 [00:00<00:00, 177.18it/s]\n",
      "Train 25 | out_loss 53.98723220825195: 100%|█████| 8/8 [00:00<00:00, 184.94it/s]\n",
      "Train 26 | out_loss 52.333621978759766: 100%|████| 8/8 [00:00<00:00, 180.07it/s]\n",
      "Train 27 | out_loss 52.42943572998047: 100%|█████| 8/8 [00:00<00:00, 180.94it/s]\n",
      "Train 28 | out_loss 50.52536392211914: 100%|█████| 8/8 [00:00<00:00, 177.80it/s]\n",
      "Train 29 | out_loss 50.11741256713867: 100%|█████| 8/8 [00:00<00:00, 182.43it/s]\n",
      "Train 30 | out_loss 48.777137756347656: 100%|████| 8/8 [00:00<00:00, 175.64it/s]\n",
      "Train 31 | out_loss 47.966819763183594: 100%|████| 8/8 [00:00<00:00, 177.91it/s]\n",
      "Train 32 | out_loss 46.965904235839844: 100%|████| 8/8 [00:00<00:00, 182.61it/s]\n",
      "Train 33 | out_loss 45.81454849243164: 100%|█████| 8/8 [00:00<00:00, 180.69it/s]\n",
      "Train 34 | out_loss 44.78782272338867: 100%|█████| 8/8 [00:00<00:00, 171.49it/s]\n",
      "Train 35 | out_loss 43.82045364379883: 100%|█████| 8/8 [00:00<00:00, 176.94it/s]\n",
      "Train 36 | out_loss 42.984256744384766: 100%|████| 8/8 [00:00<00:00, 158.40it/s]\n",
      "Train 37 | out_loss 42.01276779174805: 100%|█████| 8/8 [00:00<00:00, 176.69it/s]\n",
      "Train 38 | out_loss 41.07067108154297: 100%|█████| 8/8 [00:00<00:00, 178.23it/s]\n",
      "Train 39 | out_loss 39.793312072753906: 100%|████| 8/8 [00:00<00:00, 183.06it/s]\n",
      "Train 40 | out_loss 39.07815933227539: 100%|█████| 8/8 [00:00<00:00, 180.76it/s]\n",
      "Train 41 | out_loss 37.7661018371582: 100%|██████| 8/8 [00:00<00:00, 180.96it/s]\n",
      "Train 42 | out_loss 37.16720199584961: 100%|█████| 8/8 [00:00<00:00, 180.54it/s]\n",
      "Train 43 | out_loss 36.064090728759766: 100%|████| 8/8 [00:00<00:00, 163.28it/s]\n",
      "Train 44 | out_loss 34.98310089111328: 100%|█████| 8/8 [00:00<00:00, 176.30it/s]\n",
      "Train 45 | out_loss 33.98294448852539: 100%|█████| 8/8 [00:00<00:00, 177.54it/s]\n",
      "Train 46 | out_loss 33.139225006103516: 100%|████| 8/8 [00:00<00:00, 184.53it/s]\n",
      "Train 47 | out_loss 32.13553237915039: 100%|█████| 8/8 [00:00<00:00, 179.06it/s]\n",
      "Train 48 | out_loss 31.27339744567871: 100%|█████| 8/8 [00:00<00:00, 175.58it/s]\n",
      "Train 49 | out_loss 30.434345245361328: 100%|████| 8/8 [00:00<00:00, 180.92it/s]\n",
      "Train 50 | out_loss 29.395198822021484: 100%|████| 8/8 [00:00<00:00, 182.13it/s]\n",
      "Train 51 | out_loss 28.208118438720703: 100%|████| 8/8 [00:00<00:00, 181.41it/s]\n",
      "Train 52 | out_loss 27.85915756225586: 100%|█████| 8/8 [00:00<00:00, 167.02it/s]\n",
      "Train 53 | out_loss 26.371244430541992: 100%|████| 8/8 [00:00<00:00, 183.46it/s]\n",
      "Train 54 | out_loss 25.62156105041504: 100%|█████| 8/8 [00:00<00:00, 182.99it/s]\n",
      "Train 55 | out_loss 24.962039947509766: 100%|████| 8/8 [00:00<00:00, 182.94it/s]\n",
      "Train 56 | out_loss 23.94794464111328: 100%|█████| 8/8 [00:00<00:00, 181.09it/s]\n",
      "Train 57 | out_loss 23.07111358642578: 100%|█████| 8/8 [00:00<00:00, 177.56it/s]\n",
      "Train 58 | out_loss 22.385547637939453: 100%|████| 8/8 [00:00<00:00, 176.07it/s]\n",
      "Train 59 | out_loss 21.343589782714844: 100%|████| 8/8 [00:00<00:00, 175.05it/s]\n",
      "Train 60 | out_loss 20.603717803955078: 100%|████| 8/8 [00:00<00:00, 172.39it/s]\n",
      "Train 61 | out_loss 19.957014083862305: 100%|████| 8/8 [00:00<00:00, 183.19it/s]\n",
      "Train 62 | out_loss 19.18206787109375: 100%|█████| 8/8 [00:00<00:00, 179.79it/s]\n",
      "Train 63 | out_loss 18.376893997192383: 100%|████| 8/8 [00:00<00:00, 163.07it/s]\n",
      "Train 64 | out_loss 17.6973819732666: 100%|██████| 8/8 [00:00<00:00, 124.04it/s]\n",
      "Train 65 | out_loss 17.171323776245117: 100%|████| 8/8 [00:00<00:00, 156.25it/s]\n",
      "Train 66 | out_loss 16.51975440979004: 100%|█████| 8/8 [00:00<00:00, 178.44it/s]\n",
      "Train 67 | out_loss 15.848990440368652: 100%|████| 8/8 [00:00<00:00, 174.02it/s]\n",
      "Train 68 | out_loss 15.611038208007812: 100%|████| 8/8 [00:00<00:00, 176.54it/s]\n",
      "Train 69 | out_loss 14.898829460144043: 100%|████| 8/8 [00:00<00:00, 178.77it/s]\n",
      "Train 70 | out_loss 14.535845756530762: 100%|████| 8/8 [00:00<00:00, 182.96it/s]\n",
      "Train 71 | out_loss 14.792350769042969: 100%|████| 8/8 [00:00<00:00, 179.24it/s]\n",
      "Train 72 | out_loss 14.392792701721191: 100%|████| 8/8 [00:00<00:00, 165.43it/s]\n",
      "Train 73 | out_loss 13.762120246887207: 100%|████| 8/8 [00:00<00:00, 176.87it/s]\n",
      "Train 74 | out_loss 14.174020767211914: 100%|████| 8/8 [00:00<00:00, 177.48it/s]\n",
      "Train 75 | out_loss 14.300078392028809: 100%|████| 8/8 [00:00<00:00, 185.51it/s]\n",
      "Train 76 | out_loss 14.665566444396973: 100%|████| 8/8 [00:00<00:00, 181.47it/s]\n",
      "Train 77 | out_loss 13.61940860748291: 100%|█████| 8/8 [00:00<00:00, 181.75it/s]\n",
      "Train 78 | out_loss 13.977686882019043: 100%|████| 8/8 [00:00<00:00, 179.63it/s]\n",
      "Train 79 | out_loss 20.17752456665039: 100%|█████| 8/8 [00:00<00:00, 173.58it/s]\n",
      "Train 80 | out_loss 17.686281204223633: 100%|████| 8/8 [00:00<00:00, 182.04it/s]\n",
      "Train 81 | out_loss 17.184167861938477: 100%|████| 8/8 [00:00<00:00, 183.20it/s]\n",
      "Train 82 | out_loss 19.60057830810547: 100%|█████| 8/8 [00:00<00:00, 172.19it/s]\n",
      "Train 83 | out_loss 21.694175720214844: 100%|████| 8/8 [00:00<00:00, 182.20it/s]\n",
      "Train 84 | out_loss 16.273847579956055: 100%|████| 8/8 [00:00<00:00, 184.31it/s]\n",
      "Train 85 | out_loss 16.64925765991211: 100%|█████| 8/8 [00:00<00:00, 177.09it/s]\n",
      "Train 86 | out_loss 15.25809383392334: 100%|█████| 8/8 [00:00<00:00, 167.31it/s]\n",
      "Train 87 | out_loss 18.164669036865234: 100%|████| 8/8 [00:00<00:00, 169.64it/s]\n",
      "Train 88 | out_loss 22.732267379760742: 100%|████| 8/8 [00:00<00:00, 181.34it/s]\n",
      "Train 89 | out_loss 27.10346031188965: 100%|█████| 8/8 [00:00<00:00, 158.03it/s]\n",
      "Train 90 | out_loss 16.98379898071289: 100%|█████| 8/8 [00:00<00:00, 151.14it/s]\n",
      "Train 91 | out_loss 23.101337432861328: 100%|████| 8/8 [00:00<00:00, 177.44it/s]\n",
      "Train 92 | out_loss 16.868850708007812: 100%|████| 8/8 [00:00<00:00, 174.98it/s]\n",
      "Train 93 | out_loss 17.744583129882812: 100%|████| 8/8 [00:00<00:00, 181.49it/s]\n",
      "Train 94 | out_loss 15.587209701538086: 100%|████| 8/8 [00:00<00:00, 184.70it/s]\n",
      "Train 95 | out_loss 18.30425453186035: 100%|█████| 8/8 [00:00<00:00, 184.78it/s]\n",
      "Train 96 | out_loss 19.355634689331055: 100%|████| 8/8 [00:00<00:00, 178.49it/s]\n",
      "Train 97 | out_loss 19.562583923339844: 100%|████| 8/8 [00:00<00:00, 174.79it/s]\n",
      "Train 98 | out_loss 16.07074737548828: 100%|█████| 8/8 [00:00<00:00, 150.46it/s]\n",
      "Train 99 | out_loss 25.38473129272461: 100%|█████| 8/8 [00:00<00:00, 145.69it/s]\n",
      "Train 100 | out_loss 30.98235511779785: 100%|████| 8/8 [00:00<00:00, 178.06it/s]\n",
      "Train 101 | out_loss 25.217714309692383: 100%|███| 8/8 [00:00<00:00, 158.27it/s]\n",
      "Train 102 | out_loss 16.849336624145508: 100%|███| 8/8 [00:00<00:00, 172.30it/s]\n",
      "Train 103 | out_loss 15.360400199890137: 100%|███| 8/8 [00:00<00:00, 175.46it/s]\n",
      "Train 104 | out_loss 14.664844512939453: 100%|███| 8/8 [00:00<00:00, 164.91it/s]\n",
      "Train 105 | out_loss 13.712841033935547: 100%|███| 8/8 [00:00<00:00, 178.64it/s]\n",
      "Train 106 | out_loss 14.111343383789062: 100%|███| 8/8 [00:00<00:00, 182.74it/s]\n",
      "Train 107 | out_loss 23.84731101989746: 100%|████| 8/8 [00:00<00:00, 176.06it/s]\n",
      "Train 108 | out_loss 20.936548233032227: 100%|███| 8/8 [00:00<00:00, 171.68it/s]\n",
      "Train 109 | out_loss 19.226856231689453: 100%|███| 8/8 [00:00<00:00, 164.73it/s]\n",
      "Train 110 | out_loss 22.084732055664062: 100%|███| 8/8 [00:00<00:00, 172.09it/s]\n",
      "Train 111 | out_loss 18.479734420776367: 100%|███| 8/8 [00:00<00:00, 175.92it/s]\n",
      "Train 112 | out_loss 22.801429748535156: 100%|███| 8/8 [00:00<00:00, 186.34it/s]\n",
      "Train 113 | out_loss 13.64246654510498: 100%|████| 8/8 [00:00<00:00, 177.98it/s]\n",
      "Train 114 | out_loss 20.081283569335938: 100%|███| 8/8 [00:00<00:00, 183.47it/s]\n",
      "Train 115 | out_loss 17.514795303344727: 100%|███| 8/8 [00:00<00:00, 177.05it/s]\n",
      "Train 116 | out_loss 20.75498390197754: 100%|████| 8/8 [00:00<00:00, 180.70it/s]\n",
      "Train 117 | out_loss 16.366268157958984: 100%|███| 8/8 [00:00<00:00, 182.25it/s]\n",
      "Train 118 | out_loss 16.141817092895508: 100%|███| 8/8 [00:00<00:00, 177.74it/s]\n",
      "Train 119 | out_loss 16.00066375732422: 100%|████| 8/8 [00:00<00:00, 177.90it/s]\n",
      "Train 120 | out_loss 14.627968788146973: 100%|███| 8/8 [00:00<00:00, 176.30it/s]\n",
      "Train 121 | out_loss 14.962560653686523: 100%|███| 8/8 [00:00<00:00, 161.45it/s]\n",
      "Train 122 | out_loss 14.617508888244629: 100%|███| 8/8 [00:00<00:00, 181.09it/s]\n",
      "Train 123 | out_loss 14.051841735839844: 100%|███| 8/8 [00:00<00:00, 178.22it/s]\n",
      "Train 124 | out_loss 13.467720985412598: 100%|███| 8/8 [00:00<00:00, 182.71it/s]\n",
      "Train 125 | out_loss 13.499406814575195: 100%|███| 8/8 [00:00<00:00, 183.05it/s]\n",
      "Train 126 | out_loss 13.647536277770996: 100%|███| 8/8 [00:00<00:00, 180.34it/s]\n",
      "Train 127 | out_loss 13.43889331817627: 100%|████| 8/8 [00:00<00:00, 176.35it/s]\n",
      "Train 128 | out_loss 13.606287002563477: 100%|███| 8/8 [00:00<00:00, 181.99it/s]\n",
      "Train 129 | out_loss 14.360629081726074: 100%|███| 8/8 [00:00<00:00, 180.29it/s]\n",
      "Train 130 | out_loss 15.706076622009277: 100%|███| 8/8 [00:00<00:00, 176.95it/s]\n",
      "Train 131 | out_loss 14.639594078063965: 100%|███| 8/8 [00:00<00:00, 183.68it/s]\n",
      "Train 132 | out_loss 15.269892692565918: 100%|███| 8/8 [00:00<00:00, 178.72it/s]\n",
      "Train 133 | out_loss 13.89648723602295: 100%|████| 8/8 [00:00<00:00, 179.01it/s]\n",
      "Train 134 | out_loss 14.113340377807617: 100%|███| 8/8 [00:00<00:00, 179.19it/s]\n",
      "Train 135 | out_loss 14.021498680114746: 100%|███| 8/8 [00:00<00:00, 181.27it/s]\n",
      "Train 136 | out_loss 14.756301879882812: 100%|███| 8/8 [00:00<00:00, 176.97it/s]\n",
      "Train 137 | out_loss 15.622504234313965: 100%|███| 8/8 [00:00<00:00, 177.74it/s]\n",
      "Train 138 | out_loss 15.384713172912598: 100%|███| 8/8 [00:00<00:00, 174.25it/s]\n",
      "Train 139 | out_loss 14.108416557312012: 100%|███| 8/8 [00:00<00:00, 174.15it/s]\n",
      "Train 140 | out_loss 14.339388847351074: 100%|███| 8/8 [00:00<00:00, 179.93it/s]\n",
      "Train 141 | out_loss 15.08577823638916: 100%|████| 8/8 [00:00<00:00, 178.04it/s]\n",
      "Train 142 | out_loss 13.662995338439941: 100%|███| 8/8 [00:00<00:00, 177.61it/s]\n",
      "Train 143 | out_loss 14.28567123413086: 100%|████| 8/8 [00:00<00:00, 181.10it/s]\n",
      "Train 144 | out_loss 15.457989692687988: 100%|███| 8/8 [00:00<00:00, 182.51it/s]\n",
      "Train 145 | out_loss 14.535930633544922: 100%|███| 8/8 [00:00<00:00, 175.63it/s]\n",
      "Train 146 | out_loss 13.384586334228516: 100%|███| 8/8 [00:00<00:00, 180.21it/s]\n",
      "Train 147 | out_loss 15.538656234741211: 100%|███| 8/8 [00:00<00:00, 183.93it/s]\n",
      "Train 148 | out_loss 14.428507804870605: 100%|███| 8/8 [00:00<00:00, 176.04it/s]\n",
      "Train 149 | out_loss 15.036956787109375: 100%|███| 8/8 [00:00<00:00, 183.20it/s]\n",
      "Train 150 | out_loss 13.970751762390137: 100%|███| 8/8 [00:00<00:00, 185.00it/s]\n",
      "Train 151 | out_loss 13.593262672424316: 100%|███| 8/8 [00:00<00:00, 182.92it/s]\n",
      "Train 152 | out_loss 13.981202125549316: 100%|███| 8/8 [00:00<00:00, 183.73it/s]\n",
      "Train 153 | out_loss 14.52310562133789: 100%|████| 8/8 [00:00<00:00, 183.34it/s]\n",
      "Train 154 | out_loss 14.228130340576172: 100%|███| 8/8 [00:00<00:00, 184.08it/s]\n",
      "Train 155 | out_loss 13.5150146484375: 100%|█████| 8/8 [00:00<00:00, 179.42it/s]\n",
      "Train 156 | out_loss 13.492420196533203: 100%|███| 8/8 [00:00<00:00, 183.38it/s]\n",
      "Train 157 | out_loss 13.549250602722168: 100%|███| 8/8 [00:00<00:00, 178.95it/s]\n",
      "Train 158 | out_loss 13.95071029663086: 100%|████| 8/8 [00:00<00:00, 182.17it/s]\n",
      "Train 159 | out_loss 14.390832901000977: 100%|███| 8/8 [00:00<00:00, 182.07it/s]\n",
      "Train 160 | out_loss 15.362367630004883: 100%|███| 8/8 [00:00<00:00, 181.56it/s]\n",
      "Train 161 | out_loss 14.878151893615723: 100%|███| 8/8 [00:00<00:00, 179.56it/s]\n",
      "Train 162 | out_loss 14.191665649414062: 100%|███| 8/8 [00:00<00:00, 180.93it/s]\n",
      "Train 163 | out_loss 15.202691078186035: 100%|███| 8/8 [00:00<00:00, 177.05it/s]\n",
      "Train 164 | out_loss 13.875139236450195: 100%|███| 8/8 [00:00<00:00, 178.98it/s]\n",
      "Train 165 | out_loss 13.7658109664917: 100%|█████| 8/8 [00:00<00:00, 181.52it/s]\n",
      "Train 166 | out_loss 14.16372299194336: 100%|████| 8/8 [00:00<00:00, 183.68it/s]\n",
      "Train 167 | out_loss 13.641140937805176: 100%|███| 8/8 [00:00<00:00, 180.61it/s]\n",
      "Train 168 | out_loss 13.306257247924805: 100%|███| 8/8 [00:00<00:00, 181.63it/s]\n",
      "Train 169 | out_loss 13.912775993347168: 100%|███| 8/8 [00:00<00:00, 179.40it/s]\n",
      "Train 170 | out_loss 13.520040512084961: 100%|███| 8/8 [00:00<00:00, 179.83it/s]\n",
      "Train 171 | out_loss 13.30815315246582: 100%|████| 8/8 [00:00<00:00, 185.32it/s]\n",
      "Train 172 | out_loss 13.417494773864746: 100%|███| 8/8 [00:00<00:00, 183.19it/s]\n",
      "Train 173 | out_loss 13.41122817993164: 100%|████| 8/8 [00:00<00:00, 184.11it/s]\n",
      "Train 174 | out_loss 13.386621475219727: 100%|███| 8/8 [00:00<00:00, 182.04it/s]\n",
      "Train 175 | out_loss 13.580406188964844: 100%|███| 8/8 [00:00<00:00, 183.88it/s]\n",
      "Train 176 | out_loss 13.901517868041992: 100%|███| 8/8 [00:00<00:00, 178.34it/s]\n",
      "Train 177 | out_loss 13.885702133178711: 100%|███| 8/8 [00:00<00:00, 173.02it/s]\n",
      "Train 178 | out_loss 13.32175350189209: 100%|████| 8/8 [00:00<00:00, 180.45it/s]\n",
      "Train 179 | out_loss 13.367623329162598: 100%|███| 8/8 [00:00<00:00, 181.90it/s]\n",
      "Train 180 | out_loss 13.352683067321777: 100%|███| 8/8 [00:00<00:00, 184.60it/s]\n",
      "Train 181 | out_loss 13.61506175994873: 100%|████| 8/8 [00:00<00:00, 182.85it/s]\n",
      "Train 182 | out_loss 14.27943229675293: 100%|████| 8/8 [00:00<00:00, 183.39it/s]\n",
      "Train 183 | out_loss 13.819684028625488: 100%|███| 8/8 [00:00<00:00, 176.58it/s]\n",
      "Train 184 | out_loss 14.037388801574707: 100%|███| 8/8 [00:00<00:00, 182.94it/s]\n",
      "Train 185 | out_loss 14.214439392089844: 100%|███| 8/8 [00:00<00:00, 176.92it/s]\n",
      "Train 186 | out_loss 13.874221801757812: 100%|███| 8/8 [00:00<00:00, 172.26it/s]\n",
      "Train 187 | out_loss 13.676347732543945: 100%|███| 8/8 [00:00<00:00, 157.55it/s]\n",
      "Train 188 | out_loss 13.506234169006348: 100%|███| 8/8 [00:00<00:00, 153.89it/s]\n",
      "Train 189 | out_loss 13.428083419799805: 100%|███| 8/8 [00:00<00:00, 185.87it/s]\n",
      "Train 190 | out_loss 13.352871894836426: 100%|███| 8/8 [00:00<00:00, 179.19it/s]\n",
      "Train 191 | out_loss 13.624978065490723: 100%|███| 8/8 [00:00<00:00, 181.35it/s]\n",
      "Train 192 | out_loss 13.328898429870605: 100%|███| 8/8 [00:00<00:00, 177.74it/s]\n",
      "Train 193 | out_loss 13.863585472106934: 100%|███| 8/8 [00:00<00:00, 179.72it/s]\n",
      "Train 194 | out_loss 13.662964820861816: 100%|███| 8/8 [00:00<00:00, 178.09it/s]\n",
      "Train 195 | out_loss 13.448006629943848: 100%|███| 8/8 [00:00<00:00, 181.42it/s]\n",
      "Train 196 | out_loss 13.546966552734375: 100%|███| 8/8 [00:00<00:00, 177.02it/s]\n",
      "Train 197 | out_loss 13.543401718139648: 100%|███| 8/8 [00:00<00:00, 183.58it/s]\n",
      "Train 198 | out_loss 13.345739364624023: 100%|███| 8/8 [00:00<00:00, 180.67it/s]\n",
      "Train 199 | out_loss 13.667397499084473: 100%|███| 8/8 [00:00<00:00, 175.63it/s]\n",
      "Train 200 | out_loss 13.438650131225586: 100%|███| 8/8 [00:00<00:00, 178.16it/s]\n",
      "Train 201 | out_loss 13.363523483276367: 100%|███| 8/8 [00:00<00:00, 178.43it/s]\n",
      "Train 202 | out_loss 13.351024627685547: 100%|███| 8/8 [00:00<00:00, 181.72it/s]\n",
      "Train 203 | out_loss 13.355504035949707: 100%|███| 8/8 [00:00<00:00, 177.05it/s]\n",
      "Train 204 | out_loss 13.296801567077637: 100%|███| 8/8 [00:00<00:00, 180.57it/s]\n",
      "Train 205 | out_loss 13.865532875061035: 100%|███| 8/8 [00:00<00:00, 177.26it/s]\n",
      "Train 206 | out_loss 14.294963836669922: 100%|███| 8/8 [00:00<00:00, 176.10it/s]\n",
      "Train 207 | out_loss 14.067877769470215: 100%|███| 8/8 [00:00<00:00, 180.45it/s]\n",
      "Train 208 | out_loss 14.118253707885742: 100%|███| 8/8 [00:00<00:00, 178.69it/s]\n",
      "Train 209 | out_loss 14.041773796081543: 100%|███| 8/8 [00:00<00:00, 179.39it/s]\n",
      "Train 210 | out_loss 13.523877143859863: 100%|███| 8/8 [00:00<00:00, 175.21it/s]\n",
      "Train 211 | out_loss 13.374094009399414: 100%|███| 8/8 [00:00<00:00, 179.45it/s]\n",
      "Train 212 | out_loss 13.690953254699707: 100%|███| 8/8 [00:00<00:00, 159.78it/s]\n",
      "Train 213 | out_loss 13.652810096740723: 100%|███| 8/8 [00:00<00:00, 158.61it/s]\n",
      "Train 214 | out_loss 13.45091438293457: 100%|████| 8/8 [00:00<00:00, 175.83it/s]\n",
      "Train 215 | out_loss 13.828128814697266: 100%|███| 8/8 [00:00<00:00, 171.22it/s]\n",
      "Train 216 | out_loss 13.657999992370605: 100%|███| 8/8 [00:00<00:00, 157.66it/s]\n",
      "Train 217 | out_loss 13.552425384521484: 100%|███| 8/8 [00:00<00:00, 141.56it/s]\n",
      "Train 218 | out_loss 13.469450950622559: 100%|███| 8/8 [00:00<00:00, 174.43it/s]\n",
      "Train 219 | out_loss 13.542980194091797: 100%|███| 8/8 [00:00<00:00, 147.59it/s]\n",
      "Train 220 | out_loss 14.841684341430664: 100%|███| 8/8 [00:00<00:00, 181.94it/s]\n",
      "Train 221 | out_loss 15.221769332885742: 100%|███| 8/8 [00:00<00:00, 172.75it/s]\n",
      "Train 222 | out_loss 13.417816162109375: 100%|███| 8/8 [00:00<00:00, 181.60it/s]\n",
      "Train 223 | out_loss 13.737472534179688: 100%|███| 8/8 [00:00<00:00, 183.16it/s]\n",
      "Train 224 | out_loss 13.42214298248291: 100%|████| 8/8 [00:00<00:00, 178.35it/s]\n",
      "Train 225 | out_loss 13.609219551086426: 100%|███| 8/8 [00:00<00:00, 158.61it/s]\n",
      "Train 226 | out_loss 13.60981559753418: 100%|████| 8/8 [00:00<00:00, 159.81it/s]\n",
      "Train 227 | out_loss 15.015411376953125: 100%|███| 8/8 [00:00<00:00, 177.19it/s]\n",
      "Train 228 | out_loss 14.740289688110352: 100%|███| 8/8 [00:00<00:00, 177.92it/s]\n",
      "Train 229 | out_loss 14.108574867248535: 100%|███| 8/8 [00:00<00:00, 176.88it/s]\n",
      "Train 230 | out_loss 13.636372566223145: 100%|███| 8/8 [00:00<00:00, 177.95it/s]\n",
      "Train 231 | out_loss 13.578300476074219: 100%|███| 8/8 [00:00<00:00, 180.81it/s]\n",
      "Train 232 | out_loss 13.469902992248535: 100%|███| 8/8 [00:00<00:00, 179.98it/s]\n",
      "Train 233 | out_loss 13.382109642028809: 100%|███| 8/8 [00:00<00:00, 177.17it/s]\n",
      "Train 234 | out_loss 13.392390251159668: 100%|███| 8/8 [00:00<00:00, 184.89it/s]\n",
      "Train 235 | out_loss 13.519059181213379: 100%|███| 8/8 [00:00<00:00, 182.85it/s]\n",
      "Train 236 | out_loss 13.341788291931152: 100%|███| 8/8 [00:00<00:00, 186.08it/s]\n",
      "Train 237 | out_loss 13.486507415771484: 100%|███| 8/8 [00:00<00:00, 185.64it/s]\n",
      "Train 238 | out_loss 13.485072135925293: 100%|███| 8/8 [00:00<00:00, 177.50it/s]\n",
      "Train 239 | out_loss 13.328235626220703: 100%|███| 8/8 [00:00<00:00, 178.24it/s]\n",
      "Train 240 | out_loss 13.352350234985352: 100%|███| 8/8 [00:00<00:00, 177.65it/s]\n",
      "Train 241 | out_loss 13.564586639404297: 100%|███| 8/8 [00:00<00:00, 176.29it/s]\n",
      "Train 242 | out_loss 13.36944580078125: 100%|████| 8/8 [00:00<00:00, 174.61it/s]\n",
      "Train 243 | out_loss 13.369982719421387: 100%|███| 8/8 [00:00<00:00, 172.61it/s]\n",
      "Train 244 | out_loss 13.285113334655762: 100%|███| 8/8 [00:00<00:00, 176.21it/s]\n",
      "Train 245 | out_loss 13.414579391479492: 100%|███| 8/8 [00:00<00:00, 179.81it/s]\n",
      "Train 246 | out_loss 13.232378005981445: 100%|███| 8/8 [00:00<00:00, 181.97it/s]\n",
      "Train 247 | out_loss 14.006678581237793: 100%|███| 8/8 [00:00<00:00, 184.39it/s]\n",
      "Train 248 | out_loss 13.7574462890625: 100%|█████| 8/8 [00:00<00:00, 180.46it/s]\n",
      "Train 249 | out_loss 13.338963508605957: 100%|███| 8/8 [00:00<00:00, 181.63it/s]\n",
      "Train 250 | out_loss 13.356893539428711: 100%|███| 8/8 [00:00<00:00, 182.20it/s]\n",
      "Train 251 | out_loss 13.517465591430664: 100%|███| 8/8 [00:00<00:00, 180.83it/s]\n",
      "Train 252 | out_loss 13.432379722595215: 100%|███| 8/8 [00:00<00:00, 177.27it/s]\n",
      "Train 253 | out_loss 13.312790870666504: 100%|███| 8/8 [00:00<00:00, 181.65it/s]\n",
      "Train 254 | out_loss 13.717547416687012: 100%|███| 8/8 [00:00<00:00, 180.16it/s]\n",
      "Train 255 | out_loss 13.575772285461426: 100%|███| 8/8 [00:00<00:00, 179.55it/s]\n",
      "Train 256 | out_loss 13.357728004455566: 100%|███| 8/8 [00:00<00:00, 179.62it/s]\n",
      "Train 257 | out_loss 13.47872543334961: 100%|████| 8/8 [00:00<00:00, 178.84it/s]\n",
      "Train 258 | out_loss 13.297118186950684: 100%|███| 8/8 [00:00<00:00, 178.18it/s]\n",
      "Train 259 | out_loss 13.78951644897461: 100%|████| 8/8 [00:00<00:00, 176.43it/s]\n",
      "Train 260 | out_loss 13.74182415008545: 100%|████| 8/8 [00:00<00:00, 159.89it/s]\n",
      "Train 261 | out_loss 13.412129402160645: 100%|███| 8/8 [00:00<00:00, 181.44it/s]\n",
      "Train 262 | out_loss 13.277971267700195: 100%|███| 8/8 [00:00<00:00, 160.83it/s]\n",
      "Train 263 | out_loss 13.285846710205078: 100%|███| 8/8 [00:00<00:00, 171.18it/s]\n",
      "Train 264 | out_loss 13.345832824707031: 100%|███| 8/8 [00:00<00:00, 132.87it/s]\n",
      "Train 265 | out_loss 13.437492370605469: 100%|███| 8/8 [00:00<00:00, 176.27it/s]\n",
      "Train 266 | out_loss 13.314126968383789: 100%|███| 8/8 [00:00<00:00, 180.05it/s]\n",
      "Train 267 | out_loss 13.375307083129883: 100%|███| 8/8 [00:00<00:00, 176.85it/s]\n",
      "Train 268 | out_loss 13.418428421020508: 100%|███| 8/8 [00:00<00:00, 183.76it/s]\n",
      "Train 269 | out_loss 13.398329734802246: 100%|███| 8/8 [00:00<00:00, 158.41it/s]\n",
      "Train 270 | out_loss 13.362299919128418: 100%|███| 8/8 [00:00<00:00, 153.76it/s]\n",
      "Train 271 | out_loss 13.287740707397461: 100%|███| 8/8 [00:00<00:00, 175.91it/s]\n",
      "Train 272 | out_loss 13.442155838012695: 100%|███| 8/8 [00:00<00:00, 180.04it/s]\n",
      "Train 273 | out_loss 13.440032958984375: 100%|███| 8/8 [00:00<00:00, 176.06it/s]\n",
      "Train 274 | out_loss 13.442740440368652: 100%|███| 8/8 [00:00<00:00, 183.24it/s]\n",
      "Train 275 | out_loss 13.7918119430542: 100%|█████| 8/8 [00:00<00:00, 184.34it/s]\n",
      "Train 276 | out_loss 13.396282196044922: 100%|███| 8/8 [00:00<00:00, 177.03it/s]\n",
      "Train 277 | out_loss 13.356986045837402: 100%|███| 8/8 [00:00<00:00, 182.30it/s]\n",
      "Train 278 | out_loss 13.334759712219238: 100%|███| 8/8 [00:00<00:00, 179.39it/s]\n",
      "Train 279 | out_loss 13.363485336303711: 100%|███| 8/8 [00:00<00:00, 175.89it/s]\n",
      "Train 280 | out_loss 13.985538482666016: 100%|███| 8/8 [00:00<00:00, 177.67it/s]\n",
      "Train 281 | out_loss 13.650928497314453: 100%|███| 8/8 [00:00<00:00, 164.93it/s]\n",
      "Train 282 | out_loss 13.435816764831543: 100%|███| 8/8 [00:00<00:00, 180.75it/s]\n",
      "Train 283 | out_loss 13.331012725830078: 100%|███| 8/8 [00:00<00:00, 178.24it/s]\n",
      "Train 284 | out_loss 13.48871898651123: 100%|████| 8/8 [00:00<00:00, 177.59it/s]\n",
      "Train 285 | out_loss 13.42527961730957: 100%|████| 8/8 [00:00<00:00, 185.87it/s]\n",
      "Train 286 | out_loss 13.538430213928223: 100%|███| 8/8 [00:00<00:00, 183.67it/s]\n",
      "Train 287 | out_loss 13.483351707458496: 100%|███| 8/8 [00:00<00:00, 179.33it/s]\n",
      "Train 288 | out_loss 13.525381088256836: 100%|███| 8/8 [00:00<00:00, 181.69it/s]\n",
      "Train 289 | out_loss 13.605055809020996: 100%|███| 8/8 [00:00<00:00, 167.65it/s]\n",
      "Train 290 | out_loss 13.558188438415527: 100%|███| 8/8 [00:00<00:00, 178.95it/s]\n",
      "Train 291 | out_loss 13.749704360961914: 100%|███| 8/8 [00:00<00:00, 170.57it/s]\n",
      "Train 292 | out_loss 13.28661060333252: 100%|████| 8/8 [00:00<00:00, 161.31it/s]\n",
      "Train 293 | out_loss 13.869173049926758: 100%|███| 8/8 [00:00<00:00, 180.28it/s]\n",
      "Train 294 | out_loss 13.401466369628906: 100%|███| 8/8 [00:00<00:00, 176.79it/s]\n",
      "Train 295 | out_loss 13.54953670501709: 100%|████| 8/8 [00:00<00:00, 183.71it/s]\n",
      "Train 296 | out_loss 13.411720275878906: 100%|███| 8/8 [00:00<00:00, 145.11it/s]\n",
      "Train 297 | out_loss 13.318699836730957: 100%|███| 8/8 [00:00<00:00, 134.69it/s]\n",
      "Train 298 | out_loss 13.399923324584961: 100%|███| 8/8 [00:00<00:00, 159.04it/s]\n",
      "Train 299 | out_loss 13.451326370239258: 100%|███| 8/8 [00:00<00:00, 174.31it/s]\n",
      "Train 300 | out_loss 13.362969398498535: 100%|███| 8/8 [00:00<00:00, 182.15it/s]\n",
      "Train 301 | out_loss 13.388816833496094: 100%|███| 8/8 [00:00<00:00, 155.16it/s]\n",
      "Train 302 | out_loss 13.388001441955566: 100%|███| 8/8 [00:00<00:00, 173.40it/s]\n",
      "Train 303 | out_loss 13.753409385681152: 100%|███| 8/8 [00:00<00:00, 179.84it/s]\n",
      "Train 304 | out_loss 13.465705871582031: 100%|███| 8/8 [00:00<00:00, 172.50it/s]\n",
      "Train 305 | out_loss 13.44387435913086: 100%|████| 8/8 [00:00<00:00, 178.53it/s]\n",
      "Train 306 | out_loss 13.3923921585083: 100%|█████| 8/8 [00:00<00:00, 175.23it/s]\n",
      "Train 307 | out_loss 13.311808586120605: 100%|███| 8/8 [00:00<00:00, 170.19it/s]\n",
      "Train 308 | out_loss 13.258453369140625: 100%|███| 8/8 [00:00<00:00, 135.34it/s]\n",
      "Train 309 | out_loss 13.292101860046387: 100%|███| 8/8 [00:00<00:00, 175.88it/s]\n",
      "Train 310 | out_loss 13.266684532165527: 100%|███| 8/8 [00:00<00:00, 131.49it/s]\n",
      "Train 311 | out_loss 13.287087440490723: 100%|███| 8/8 [00:00<00:00, 180.03it/s]\n",
      "Train 312 | out_loss 13.294733047485352: 100%|███| 8/8 [00:00<00:00, 172.73it/s]\n",
      "Train 313 | out_loss 13.382342338562012: 100%|███| 8/8 [00:00<00:00, 177.15it/s]\n",
      "Train 314 | out_loss 13.308269500732422: 100%|███| 8/8 [00:00<00:00, 183.15it/s]\n",
      "Train 315 | out_loss 13.303986549377441: 100%|███| 8/8 [00:00<00:00, 176.85it/s]\n",
      "Train 316 | out_loss 13.348345756530762: 100%|███| 8/8 [00:00<00:00, 182.34it/s]\n",
      "Train 317 | out_loss 13.390641212463379: 100%|███| 8/8 [00:00<00:00, 168.92it/s]\n",
      "Train 318 | out_loss 13.520527839660645: 100%|███| 8/8 [00:00<00:00, 175.45it/s]\n",
      "Train 319 | out_loss 13.617754936218262: 100%|███| 8/8 [00:00<00:00, 176.25it/s]\n",
      "Train 320 | out_loss 13.734116554260254: 100%|███| 8/8 [00:00<00:00, 164.13it/s]\n",
      "Train 321 | out_loss 13.733739852905273: 100%|███| 8/8 [00:00<00:00, 160.42it/s]\n",
      "Train 322 | out_loss 13.533790588378906: 100%|███| 8/8 [00:00<00:00, 147.74it/s]\n",
      "Train 323 | out_loss 13.386366844177246: 100%|███| 8/8 [00:00<00:00, 182.46it/s]\n",
      "Train 324 | out_loss 13.303183555603027: 100%|███| 8/8 [00:00<00:00, 181.54it/s]\n",
      "Train 325 | out_loss 13.478006362915039: 100%|███| 8/8 [00:00<00:00, 178.55it/s]\n",
      "Train 326 | out_loss 13.485374450683594: 100%|███| 8/8 [00:00<00:00, 182.09it/s]\n",
      "Train 327 | out_loss 13.369098663330078: 100%|███| 8/8 [00:00<00:00, 172.98it/s]\n",
      "Train 328 | out_loss 13.372912406921387: 100%|███| 8/8 [00:00<00:00, 182.04it/s]\n",
      "Train 329 | out_loss 13.52206802368164: 100%|████| 8/8 [00:00<00:00, 181.73it/s]\n",
      "Train 330 | out_loss 13.378207206726074: 100%|███| 8/8 [00:00<00:00, 177.97it/s]\n",
      "Train 331 | out_loss 13.243605613708496: 100%|███| 8/8 [00:00<00:00, 173.81it/s]\n",
      "Train 332 | out_loss 13.448395729064941: 100%|███| 8/8 [00:00<00:00, 183.17it/s]\n",
      "Train 333 | out_loss 13.482401847839355: 100%|███| 8/8 [00:00<00:00, 172.55it/s]\n",
      "Train 334 | out_loss 13.405139923095703: 100%|███| 8/8 [00:00<00:00, 159.85it/s]\n",
      "Train 335 | out_loss 13.24090576171875: 100%|████| 8/8 [00:00<00:00, 178.46it/s]\n",
      "Train 336 | out_loss 13.466489791870117: 100%|███| 8/8 [00:00<00:00, 176.25it/s]\n",
      "Train 337 | out_loss 13.31860065460205: 100%|████| 8/8 [00:00<00:00, 181.99it/s]\n",
      "Train 338 | out_loss 13.383715629577637: 100%|███| 8/8 [00:00<00:00, 158.55it/s]\n",
      "Train 339 | out_loss 13.327520370483398: 100%|███| 8/8 [00:00<00:00, 181.77it/s]\n",
      "Train 340 | out_loss 13.213746070861816: 100%|███| 8/8 [00:00<00:00, 178.80it/s]\n",
      "Train 341 | out_loss 13.300042152404785: 100%|███| 8/8 [00:00<00:00, 176.19it/s]\n",
      "Train 342 | out_loss 13.325858116149902: 100%|███| 8/8 [00:00<00:00, 180.04it/s]\n",
      "Train 343 | out_loss 13.346748352050781: 100%|███| 8/8 [00:00<00:00, 170.44it/s]\n",
      "Train 344 | out_loss 13.431292533874512: 100%|███| 8/8 [00:00<00:00, 177.31it/s]\n",
      "Train 345 | out_loss 13.290834426879883: 100%|███| 8/8 [00:00<00:00, 174.01it/s]\n",
      "Train 346 | out_loss 13.156563758850098: 100%|███| 8/8 [00:00<00:00, 177.14it/s]\n",
      "Train 347 | out_loss 13.289412498474121: 100%|███| 8/8 [00:00<00:00, 178.41it/s]\n",
      "Train 348 | out_loss 13.368087768554688: 100%|███| 8/8 [00:00<00:00, 177.97it/s]\n",
      "Train 349 | out_loss 13.344311714172363: 100%|███| 8/8 [00:00<00:00, 173.92it/s]\n",
      "Train 350 | out_loss 13.532602310180664: 100%|███| 8/8 [00:00<00:00, 172.65it/s]\n",
      "Train 351 | out_loss 13.389286041259766: 100%|███| 8/8 [00:00<00:00, 181.72it/s]\n",
      "Train 352 | out_loss 13.392911911010742: 100%|███| 8/8 [00:00<00:00, 177.70it/s]\n",
      "Train 353 | out_loss 13.315861701965332: 100%|███| 8/8 [00:00<00:00, 181.41it/s]\n",
      "Train 354 | out_loss 13.367741584777832: 100%|███| 8/8 [00:00<00:00, 165.37it/s]\n",
      "Train 355 | out_loss 13.619451522827148: 100%|███| 8/8 [00:00<00:00, 174.87it/s]\n",
      "Train 356 | out_loss 13.46300220489502: 100%|████| 8/8 [00:00<00:00, 174.78it/s]\n",
      "Train 357 | out_loss 13.380584716796875: 100%|███| 8/8 [00:00<00:00, 181.29it/s]\n",
      "Train 358 | out_loss 13.410216331481934: 100%|███| 8/8 [00:00<00:00, 181.50it/s]\n",
      "Train 359 | out_loss 13.347631454467773: 100%|███| 8/8 [00:00<00:00, 184.96it/s]\n",
      "Train 360 | out_loss 13.364160537719727: 100%|███| 8/8 [00:00<00:00, 186.19it/s]\n",
      "Train 361 | out_loss 13.354870796203613: 100%|███| 8/8 [00:00<00:00, 181.10it/s]\n",
      "Train 362 | out_loss 13.420836448669434: 100%|███| 8/8 [00:00<00:00, 178.15it/s]\n",
      "Train 363 | out_loss 13.320358276367188: 100%|███| 8/8 [00:00<00:00, 171.37it/s]\n",
      "Train 364 | out_loss 13.400651931762695: 100%|███| 8/8 [00:00<00:00, 170.58it/s]\n",
      "Train 365 | out_loss 13.303173065185547: 100%|███| 8/8 [00:00<00:00, 182.18it/s]\n",
      "Train 366 | out_loss 13.344225883483887: 100%|███| 8/8 [00:00<00:00, 180.23it/s]\n",
      "Train 367 | out_loss 13.377528190612793: 100%|███| 8/8 [00:00<00:00, 182.55it/s]\n",
      "Train 368 | out_loss 13.335057258605957: 100%|███| 8/8 [00:00<00:00, 176.70it/s]\n",
      "Train 369 | out_loss 13.273273468017578: 100%|███| 8/8 [00:00<00:00, 176.58it/s]\n",
      "Train 370 | out_loss 13.3247709274292: 100%|█████| 8/8 [00:00<00:00, 184.12it/s]\n",
      "Train 371 | out_loss 13.351271629333496: 100%|███| 8/8 [00:00<00:00, 178.98it/s]\n",
      "Train 372 | out_loss 13.250503540039062: 100%|███| 8/8 [00:00<00:00, 174.65it/s]\n",
      "Train 373 | out_loss 13.311820030212402: 100%|███| 8/8 [00:00<00:00, 179.39it/s]\n",
      "Train 374 | out_loss 13.330824851989746: 100%|███| 8/8 [00:00<00:00, 179.41it/s]\n",
      "Train 375 | out_loss 13.439101219177246: 100%|███| 8/8 [00:00<00:00, 130.57it/s]\n",
      "Train 376 | out_loss 13.297319412231445: 100%|███| 8/8 [00:00<00:00, 181.77it/s]\n",
      "Train 377 | out_loss 13.466924667358398: 100%|███| 8/8 [00:00<00:00, 180.44it/s]\n",
      "Train 378 | out_loss 13.380533218383789: 100%|███| 8/8 [00:00<00:00, 182.63it/s]\n",
      "Train 379 | out_loss 13.483230590820312: 100%|███| 8/8 [00:00<00:00, 180.73it/s]\n",
      "Train 380 | out_loss 13.360921859741211: 100%|███| 8/8 [00:00<00:00, 171.33it/s]\n",
      "Train 381 | out_loss 13.286376953125: 100%|██████| 8/8 [00:00<00:00, 180.70it/s]\n",
      "Train 382 | out_loss 13.247398376464844: 100%|███| 8/8 [00:00<00:00, 174.30it/s]\n",
      "Train 383 | out_loss 13.235475540161133: 100%|███| 8/8 [00:00<00:00, 174.84it/s]\n",
      "Train 384 | out_loss 13.241774559020996: 100%|███| 8/8 [00:00<00:00, 180.71it/s]\n",
      "Train 385 | out_loss 13.140295028686523: 100%|███| 8/8 [00:00<00:00, 178.67it/s]\n",
      "Train 386 | out_loss 13.381563186645508: 100%|███| 8/8 [00:00<00:00, 164.01it/s]\n",
      "Train 387 | out_loss 13.265316009521484: 100%|███| 8/8 [00:00<00:00, 178.26it/s]\n",
      "Train 388 | out_loss 13.178926467895508: 100%|███| 8/8 [00:00<00:00, 172.84it/s]\n",
      "Train 389 | out_loss 13.291458129882812: 100%|███| 8/8 [00:00<00:00, 176.42it/s]\n",
      "Train 390 | out_loss 13.215047836303711: 100%|███| 8/8 [00:00<00:00, 175.53it/s]\n",
      "Train 391 | out_loss 13.74152660369873: 100%|████| 8/8 [00:00<00:00, 179.29it/s]\n",
      "Train 392 | out_loss 13.572397232055664: 100%|███| 8/8 [00:00<00:00, 181.40it/s]\n",
      "Train 393 | out_loss 13.19067668914795: 100%|████| 8/8 [00:00<00:00, 179.07it/s]\n",
      "Train 394 | out_loss 13.119185447692871: 100%|███| 8/8 [00:00<00:00, 147.45it/s]\n",
      "Train 395 | out_loss 13.41211223602295: 100%|████| 8/8 [00:00<00:00, 179.89it/s]\n",
      "Train 396 | out_loss 13.391088485717773: 100%|███| 8/8 [00:00<00:00, 181.84it/s]\n",
      "Train 397 | out_loss 13.286455154418945: 100%|███| 8/8 [00:00<00:00, 183.13it/s]\n",
      "Train 398 | out_loss 13.232842445373535: 100%|███| 8/8 [00:00<00:00, 184.64it/s]\n",
      "Train 399 | out_loss 13.366629600524902: 100%|███| 8/8 [00:00<00:00, 178.39it/s]\n",
      "Train 400 | out_loss 13.447240829467773: 100%|███| 8/8 [00:00<00:00, 174.44it/s]\n",
      "Train 401 | out_loss 13.31208324432373: 100%|████| 8/8 [00:00<00:00, 177.84it/s]\n",
      "Train 402 | out_loss 13.307084083557129: 100%|███| 8/8 [00:00<00:00, 175.85it/s]\n",
      "Train 403 | out_loss 13.219514846801758: 100%|███| 8/8 [00:00<00:00, 180.05it/s]\n",
      "Train 404 | out_loss 13.178678512573242: 100%|███| 8/8 [00:00<00:00, 180.78it/s]\n",
      "Train 405 | out_loss 13.253435134887695: 100%|███| 8/8 [00:00<00:00, 179.47it/s]\n",
      "Train 406 | out_loss 13.358986854553223: 100%|███| 8/8 [00:00<00:00, 174.01it/s]\n",
      "Train 407 | out_loss 13.298240661621094: 100%|███| 8/8 [00:00<00:00, 182.46it/s]\n",
      "Train 408 | out_loss 13.151455879211426: 100%|███| 8/8 [00:00<00:00, 182.46it/s]\n",
      "Train 409 | out_loss 13.115471839904785: 100%|███| 8/8 [00:00<00:00, 175.89it/s]\n",
      "Train 410 | out_loss 13.205013275146484: 100%|███| 8/8 [00:00<00:00, 177.39it/s]\n",
      "Train 411 | out_loss 13.589584350585938: 100%|███| 8/8 [00:00<00:00, 142.00it/s]\n",
      "Train 412 | out_loss 13.098550796508789: 100%|███| 8/8 [00:00<00:00, 168.51it/s]\n",
      "Train 413 | out_loss 13.260956764221191: 100%|███| 8/8 [00:00<00:00, 183.92it/s]\n",
      "Train 414 | out_loss 13.27221393585205: 100%|████| 8/8 [00:00<00:00, 184.75it/s]\n",
      "Train 415 | out_loss 13.103594779968262: 100%|███| 8/8 [00:00<00:00, 186.18it/s]\n",
      "Train 416 | out_loss 13.004972457885742: 100%|███| 8/8 [00:00<00:00, 177.31it/s]\n",
      "Train 417 | out_loss 12.981661796569824: 100%|███| 8/8 [00:00<00:00, 110.55it/s]\n",
      "Train 418 | out_loss 12.937454223632812: 100%|███| 8/8 [00:00<00:00, 172.65it/s]\n",
      "Train 419 | out_loss 12.894380569458008: 100%|███| 8/8 [00:00<00:00, 175.62it/s]\n",
      "Train 420 | out_loss 12.891790390014648: 100%|███| 8/8 [00:00<00:00, 173.15it/s]\n",
      "Train 421 | out_loss 12.787363052368164: 100%|███| 8/8 [00:00<00:00, 177.03it/s]\n",
      "Train 422 | out_loss 14.10135269165039: 100%|████| 8/8 [00:00<00:00, 181.36it/s]\n",
      "Train 423 | out_loss 13.088762283325195: 100%|███| 8/8 [00:00<00:00, 176.32it/s]\n",
      "Train 424 | out_loss 13.43169116973877: 100%|████| 8/8 [00:00<00:00, 178.31it/s]\n",
      "Train 425 | out_loss 13.742462158203125: 100%|███| 8/8 [00:00<00:00, 178.63it/s]\n",
      "Train 426 | out_loss 13.8109769821167: 100%|█████| 8/8 [00:00<00:00, 177.52it/s]\n",
      "Train 427 | out_loss 13.535786628723145: 100%|███| 8/8 [00:00<00:00, 178.23it/s]\n",
      "Train 428 | out_loss 13.43790054321289: 100%|████| 8/8 [00:00<00:00, 183.60it/s]\n",
      "Train 429 | out_loss 13.344454765319824: 100%|███| 8/8 [00:00<00:00, 184.16it/s]\n",
      "Train 430 | out_loss 13.301108360290527: 100%|███| 8/8 [00:00<00:00, 181.69it/s]\n",
      "Train 431 | out_loss 13.674222946166992: 100%|███| 8/8 [00:00<00:00, 173.59it/s]\n",
      "Train 432 | out_loss 13.30285358428955: 100%|████| 8/8 [00:00<00:00, 176.23it/s]\n",
      "Train 433 | out_loss 13.277210235595703: 100%|███| 8/8 [00:00<00:00, 175.66it/s]\n",
      "Train 434 | out_loss 13.447798728942871: 100%|███| 8/8 [00:00<00:00, 183.70it/s]\n",
      "Train 435 | out_loss 13.562333106994629: 100%|███| 8/8 [00:00<00:00, 180.29it/s]\n",
      "Train 436 | out_loss 13.737446784973145: 100%|███| 8/8 [00:00<00:00, 181.64it/s]\n",
      "Train 437 | out_loss 13.832785606384277: 100%|███| 8/8 [00:00<00:00, 155.00it/s]\n",
      "Train 438 | out_loss 13.588363647460938: 100%|███| 8/8 [00:00<00:00, 171.08it/s]\n",
      "Train 439 | out_loss 13.698186874389648: 100%|███| 8/8 [00:00<00:00, 178.47it/s]\n",
      "Train 440 | out_loss 13.346600532531738: 100%|███| 8/8 [00:00<00:00, 179.89it/s]\n",
      "Train 441 | out_loss 13.310279846191406: 100%|███| 8/8 [00:00<00:00, 181.23it/s]\n",
      "Train 442 | out_loss 13.293418884277344: 100%|███| 8/8 [00:00<00:00, 181.46it/s]\n",
      "Train 443 | out_loss 13.280850410461426: 100%|███| 8/8 [00:00<00:00, 176.03it/s]\n",
      "Train 444 | out_loss 13.269203186035156: 100%|███| 8/8 [00:00<00:00, 183.70it/s]\n",
      "Train 445 | out_loss 13.33611011505127: 100%|████| 8/8 [00:00<00:00, 138.74it/s]\n",
      "Train 446 | out_loss 13.26678466796875: 100%|████| 8/8 [00:00<00:00, 134.07it/s]\n",
      "Train 447 | out_loss 13.369433403015137: 100%|███| 8/8 [00:00<00:00, 162.88it/s]\n",
      "Train 448 | out_loss 13.287253379821777: 100%|███| 8/8 [00:00<00:00, 172.01it/s]\n",
      "Train 449 | out_loss 13.261898040771484: 100%|███| 8/8 [00:00<00:00, 179.68it/s]\n",
      "Train 450 | out_loss 13.277449607849121: 100%|███| 8/8 [00:00<00:00, 179.79it/s]\n",
      "Train 451 | out_loss 13.395432472229004: 100%|███| 8/8 [00:00<00:00, 185.28it/s]\n",
      "Train 452 | out_loss 13.312480926513672: 100%|███| 8/8 [00:00<00:00, 172.87it/s]\n",
      "Train 453 | out_loss 13.258049964904785: 100%|███| 8/8 [00:00<00:00, 185.81it/s]\n",
      "Train 454 | out_loss 13.259292602539062: 100%|███| 8/8 [00:00<00:00, 178.14it/s]\n",
      "Train 455 | out_loss 13.237282752990723: 100%|███| 8/8 [00:00<00:00, 165.34it/s]\n",
      "Train 456 | out_loss 13.345065116882324: 100%|███| 8/8 [00:00<00:00, 175.24it/s]\n",
      "Train 457 | out_loss 13.449568748474121: 100%|███| 8/8 [00:00<00:00, 177.76it/s]\n",
      "Train 458 | out_loss 13.303979873657227: 100%|███| 8/8 [00:00<00:00, 178.59it/s]\n",
      "Train 459 | out_loss 13.590910911560059: 100%|███| 8/8 [00:00<00:00, 179.73it/s]\n",
      "Train 460 | out_loss 13.588089942932129: 100%|███| 8/8 [00:00<00:00, 180.33it/s]\n",
      "Train 461 | out_loss 13.51557445526123: 100%|████| 8/8 [00:00<00:00, 180.44it/s]\n",
      "Train 462 | out_loss 13.448751449584961: 100%|███| 8/8 [00:00<00:00, 172.16it/s]\n",
      "Train 463 | out_loss 13.44369125366211: 100%|████| 8/8 [00:00<00:00, 182.49it/s]\n",
      "Train 464 | out_loss 13.368398666381836: 100%|███| 8/8 [00:00<00:00, 147.41it/s]\n",
      "Train 465 | out_loss 13.381234169006348: 100%|███| 8/8 [00:00<00:00, 180.24it/s]\n",
      "Train 466 | out_loss 13.401013374328613: 100%|███| 8/8 [00:00<00:00, 177.14it/s]\n",
      "Train 467 | out_loss 13.511004447937012: 100%|███| 8/8 [00:00<00:00, 170.92it/s]\n",
      "Train 468 | out_loss 13.420491218566895: 100%|███| 8/8 [00:00<00:00, 168.20it/s]\n",
      "Train 469 | out_loss 13.395435333251953: 100%|███| 8/8 [00:00<00:00, 169.55it/s]\n",
      "Train 470 | out_loss 13.33151626586914: 100%|████| 8/8 [00:00<00:00, 172.49it/s]\n",
      "Train 471 | out_loss 13.404060363769531: 100%|███| 8/8 [00:00<00:00, 166.82it/s]\n",
      "Train 472 | out_loss 13.311373710632324: 100%|███| 8/8 [00:00<00:00, 155.50it/s]\n",
      "Train 473 | out_loss 13.330745697021484: 100%|███| 8/8 [00:00<00:00, 177.67it/s]\n",
      "Train 474 | out_loss 13.324540138244629: 100%|███| 8/8 [00:00<00:00, 173.59it/s]\n",
      "Train 475 | out_loss 13.322991371154785: 100%|███| 8/8 [00:00<00:00, 177.48it/s]\n",
      "Train 476 | out_loss 13.37792682647705: 100%|████| 8/8 [00:00<00:00, 178.05it/s]\n",
      "Train 477 | out_loss 13.287252426147461: 100%|███| 8/8 [00:00<00:00, 184.66it/s]\n",
      "Train 478 | out_loss 13.369691848754883: 100%|███| 8/8 [00:00<00:00, 185.01it/s]\n",
      "Train 479 | out_loss 13.411396026611328: 100%|███| 8/8 [00:00<00:00, 176.60it/s]\n",
      "Train 480 | out_loss 13.294964790344238: 100%|███| 8/8 [00:00<00:00, 172.50it/s]\n",
      "Train 481 | out_loss 13.350680351257324: 100%|███| 8/8 [00:00<00:00, 177.00it/s]\n",
      "Train 482 | out_loss 13.291418075561523: 100%|███| 8/8 [00:00<00:00, 175.60it/s]\n",
      "Train 483 | out_loss 13.314770698547363: 100%|███| 8/8 [00:00<00:00, 177.40it/s]\n",
      "Train 484 | out_loss 13.378324508666992: 100%|███| 8/8 [00:00<00:00, 161.05it/s]\n",
      "Train 485 | out_loss 13.299408912658691: 100%|███| 8/8 [00:00<00:00, 177.68it/s]\n",
      "Train 486 | out_loss 13.377976417541504: 100%|███| 8/8 [00:00<00:00, 150.95it/s]\n",
      "Train 487 | out_loss 13.348424911499023: 100%|███| 8/8 [00:00<00:00, 160.04it/s]\n",
      "Train 488 | out_loss 13.303494453430176: 100%|███| 8/8 [00:00<00:00, 162.36it/s]\n",
      "Train 489 | out_loss 13.320825576782227: 100%|███| 8/8 [00:00<00:00, 179.34it/s]\n",
      "Train 490 | out_loss 13.34148120880127: 100%|████| 8/8 [00:00<00:00, 176.62it/s]\n",
      "Train 491 | out_loss 13.262201309204102: 100%|███| 8/8 [00:00<00:00, 175.87it/s]\n",
      "Train 492 | out_loss 13.371313095092773: 100%|███| 8/8 [00:00<00:00, 175.65it/s]\n",
      "Train 493 | out_loss 13.350210189819336: 100%|███| 8/8 [00:00<00:00, 181.20it/s]\n",
      "Train 494 | out_loss 13.35559368133545: 100%|████| 8/8 [00:00<00:00, 185.95it/s]\n",
      "Train 495 | out_loss 13.26435375213623: 100%|████| 8/8 [00:00<00:00, 182.79it/s]\n",
      "Train 496 | out_loss 13.210895538330078: 100%|███| 8/8 [00:00<00:00, 179.77it/s]\n",
      "Train 497 | out_loss 13.412806510925293: 100%|███| 8/8 [00:00<00:00, 184.29it/s]\n",
      "Train 498 | out_loss 13.448921203613281: 100%|███| 8/8 [00:00<00:00, 173.65it/s]\n",
      "Train 499 | out_loss 13.42934513092041: 100%|████| 8/8 [00:00<00:00, 179.43it/s]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 80.37303161621094: 100%|███████| 8/8 [00:00<00:00, 19.18it/s]\n",
      "Train 1 | out_loss 79.98702239990234: 100%|██████| 8/8 [00:00<00:00, 158.57it/s]\n",
      "Train 2 | out_loss 77.26176452636719: 100%|██████| 8/8 [00:00<00:00, 153.72it/s]\n",
      "Train 3 | out_loss 75.99961853027344: 100%|██████| 8/8 [00:00<00:00, 154.83it/s]\n",
      "Train 4 | out_loss 76.8012924194336: 100%|███████| 8/8 [00:00<00:00, 154.74it/s]\n",
      "Train 5 | out_loss 76.151611328125: 100%|████████| 8/8 [00:00<00:00, 157.47it/s]\n",
      "Train 6 | out_loss 73.76752471923828: 100%|██████| 8/8 [00:00<00:00, 148.82it/s]\n",
      "Train 7 | out_loss 73.14448547363281: 100%|██████| 8/8 [00:00<00:00, 152.04it/s]\n",
      "Train 8 | out_loss 69.92134094238281: 100%|██████| 8/8 [00:00<00:00, 154.85it/s]\n",
      "Train 9 | out_loss 72.81761932373047: 100%|██████| 8/8 [00:00<00:00, 147.06it/s]\n",
      "Train 10 | out_loss 65.45917510986328: 100%|█████| 8/8 [00:00<00:00, 159.44it/s]\n",
      "Train 11 | out_loss 69.63118743896484: 100%|█████| 8/8 [00:00<00:00, 157.56it/s]\n",
      "Train 12 | out_loss 67.8066635131836: 100%|██████| 8/8 [00:00<00:00, 154.34it/s]\n",
      "Train 13 | out_loss 66.97901916503906: 100%|█████| 8/8 [00:00<00:00, 152.96it/s]\n",
      "Train 14 | out_loss 66.60755920410156: 100%|█████| 8/8 [00:00<00:00, 156.74it/s]\n",
      "Train 15 | out_loss 62.61205291748047: 100%|█████| 8/8 [00:00<00:00, 154.79it/s]\n",
      "Train 16 | out_loss 64.59711456298828: 100%|█████| 8/8 [00:00<00:00, 158.53it/s]\n",
      "Train 17 | out_loss 61.895381927490234: 100%|████| 8/8 [00:00<00:00, 116.95it/s]\n",
      "Train 18 | out_loss 61.72974395751953: 100%|█████| 8/8 [00:00<00:00, 153.58it/s]\n",
      "Train 19 | out_loss 60.170501708984375: 100%|████| 8/8 [00:00<00:00, 153.03it/s]\n",
      "Train 20 | out_loss 59.53107452392578: 100%|█████| 8/8 [00:00<00:00, 147.44it/s]\n",
      "Train 21 | out_loss 59.08842086791992: 100%|█████| 8/8 [00:00<00:00, 156.10it/s]\n",
      "Train 22 | out_loss 55.03208541870117: 100%|█████| 8/8 [00:00<00:00, 157.56it/s]\n",
      "Train 23 | out_loss 57.466400146484375: 100%|████| 8/8 [00:00<00:00, 156.68it/s]\n",
      "Train 24 | out_loss 54.62371826171875: 100%|█████| 8/8 [00:00<00:00, 159.71it/s]\n",
      "Train 25 | out_loss 53.72623825073242: 100%|█████| 8/8 [00:00<00:00, 141.10it/s]\n",
      "Train 26 | out_loss 53.43919372558594: 100%|█████| 8/8 [00:00<00:00, 152.53it/s]\n",
      "Train 27 | out_loss 51.98340606689453: 100%|█████| 8/8 [00:00<00:00, 155.01it/s]\n",
      "Train 28 | out_loss 51.0102424621582: 100%|██████| 8/8 [00:00<00:00, 155.30it/s]\n",
      "Train 29 | out_loss 50.09413146972656: 100%|█████| 8/8 [00:00<00:00, 155.59it/s]\n",
      "Train 30 | out_loss 48.97354507446289: 100%|█████| 8/8 [00:00<00:00, 154.36it/s]\n",
      "Train 31 | out_loss 47.967620849609375: 100%|████| 8/8 [00:00<00:00, 151.48it/s]\n",
      "Train 32 | out_loss 47.158363342285156: 100%|████| 8/8 [00:00<00:00, 156.38it/s]\n",
      "Train 33 | out_loss 45.91791534423828: 100%|█████| 8/8 [00:00<00:00, 155.44it/s]\n",
      "Train 34 | out_loss 45.01601791381836: 100%|█████| 8/8 [00:00<00:00, 151.59it/s]\n",
      "Train 35 | out_loss 44.0824089050293: 100%|██████| 8/8 [00:00<00:00, 158.25it/s]\n",
      "Train 36 | out_loss 42.960941314697266: 100%|████| 8/8 [00:00<00:00, 148.94it/s]\n",
      "Train 37 | out_loss 42.061134338378906: 100%|████| 8/8 [00:00<00:00, 160.74it/s]\n",
      "Train 38 | out_loss 41.07851791381836: 100%|█████| 8/8 [00:00<00:00, 159.84it/s]\n",
      "Train 39 | out_loss 40.11821365356445: 100%|█████| 8/8 [00:00<00:00, 157.21it/s]\n",
      "Train 40 | out_loss 39.06121826171875: 100%|█████| 8/8 [00:00<00:00, 154.43it/s]\n",
      "Train 41 | out_loss 38.1722412109375: 100%|██████| 8/8 [00:00<00:00, 158.45it/s]\n",
      "Train 42 | out_loss 37.11274719238281: 100%|█████| 8/8 [00:00<00:00, 154.14it/s]\n",
      "Train 43 | out_loss 36.13344192504883: 100%|█████| 8/8 [00:00<00:00, 152.24it/s]\n",
      "Train 44 | out_loss 35.29728698730469: 100%|█████| 8/8 [00:00<00:00, 122.84it/s]\n",
      "Train 45 | out_loss 34.295204162597656: 100%|████| 8/8 [00:00<00:00, 152.18it/s]\n",
      "Train 46 | out_loss 33.22084045410156: 100%|█████| 8/8 [00:00<00:00, 156.31it/s]\n",
      "Train 47 | out_loss 32.355613708496094: 100%|████| 8/8 [00:00<00:00, 153.94it/s]\n",
      "Train 48 | out_loss 31.38960075378418: 100%|█████| 8/8 [00:00<00:00, 161.31it/s]\n",
      "Train 49 | out_loss 30.487781524658203: 100%|████| 8/8 [00:00<00:00, 158.73it/s]\n",
      "Train 50 | out_loss 29.544322967529297: 100%|████| 8/8 [00:00<00:00, 155.43it/s]\n",
      "Train 51 | out_loss 28.609832763671875: 100%|████| 8/8 [00:00<00:00, 153.93it/s]\n",
      "Train 52 | out_loss 27.760635375976562: 100%|████| 8/8 [00:00<00:00, 148.74it/s]\n",
      "Train 53 | out_loss 27.014326095581055: 100%|████| 8/8 [00:00<00:00, 151.42it/s]\n",
      "Train 54 | out_loss 26.22455596923828: 100%|█████| 8/8 [00:00<00:00, 153.32it/s]\n",
      "Train 55 | out_loss 24.84946060180664: 100%|█████| 8/8 [00:00<00:00, 152.17it/s]\n",
      "Train 56 | out_loss 23.731657028198242: 100%|████| 8/8 [00:00<00:00, 156.18it/s]\n",
      "Train 57 | out_loss 22.964801788330078: 100%|████| 8/8 [00:00<00:00, 156.36it/s]\n",
      "Train 58 | out_loss 23.135305404663086: 100%|████| 8/8 [00:00<00:00, 154.06it/s]\n",
      "Train 59 | out_loss 21.400819778442383: 100%|████| 8/8 [00:00<00:00, 149.32it/s]\n",
      "Train 60 | out_loss 21.309967041015625: 100%|████| 8/8 [00:00<00:00, 152.83it/s]\n",
      "Train 61 | out_loss 20.76428985595703: 100%|█████| 8/8 [00:00<00:00, 157.82it/s]\n",
      "Train 62 | out_loss 20.03074836730957: 100%|█████| 8/8 [00:00<00:00, 161.95it/s]\n",
      "Train 63 | out_loss 18.124385833740234: 100%|████| 8/8 [00:00<00:00, 155.11it/s]\n",
      "Train 64 | out_loss 18.410886764526367: 100%|████| 8/8 [00:00<00:00, 157.42it/s]\n",
      "Train 65 | out_loss 17.344465255737305: 100%|████| 8/8 [00:00<00:00, 157.73it/s]\n",
      "Train 66 | out_loss 17.545236587524414: 100%|████| 8/8 [00:00<00:00, 162.27it/s]\n",
      "Train 67 | out_loss 15.6173734664917: 100%|██████| 8/8 [00:00<00:00, 153.78it/s]\n",
      "Train 68 | out_loss 16.52667808532715: 100%|█████| 8/8 [00:00<00:00, 153.10it/s]\n",
      "Train 69 | out_loss 15.22463321685791: 100%|█████| 8/8 [00:00<00:00, 154.03it/s]\n",
      "Train 70 | out_loss 16.877405166625977: 100%|████| 8/8 [00:00<00:00, 158.16it/s]\n",
      "Train 71 | out_loss 14.106635093688965: 100%|████| 8/8 [00:00<00:00, 156.80it/s]\n",
      "Train 72 | out_loss 20.720842361450195: 100%|████| 8/8 [00:00<00:00, 158.51it/s]\n",
      "Train 73 | out_loss 15.038125991821289: 100%|████| 8/8 [00:00<00:00, 151.12it/s]\n",
      "Train 74 | out_loss 19.674863815307617: 100%|████| 8/8 [00:00<00:00, 131.84it/s]\n",
      "Train 75 | out_loss 13.526824951171875: 100%|████| 8/8 [00:00<00:00, 154.23it/s]\n",
      "Train 76 | out_loss 15.265612602233887: 100%|████| 8/8 [00:00<00:00, 157.80it/s]\n",
      "Train 77 | out_loss 18.07749366760254: 100%|█████| 8/8 [00:00<00:00, 156.35it/s]\n",
      "Train 78 | out_loss 13.442962646484375: 100%|████| 8/8 [00:00<00:00, 158.80it/s]\n",
      "Train 79 | out_loss 15.507803916931152: 100%|████| 8/8 [00:00<00:00, 157.36it/s]\n",
      "Train 80 | out_loss 14.867193222045898: 100%|████| 8/8 [00:00<00:00, 152.67it/s]\n",
      "Train 81 | out_loss 14.135783195495605: 100%|████| 8/8 [00:00<00:00, 155.89it/s]\n",
      "Train 82 | out_loss 13.960524559020996: 100%|████| 8/8 [00:00<00:00, 155.38it/s]\n",
      "Train 83 | out_loss 14.51169204711914: 100%|█████| 8/8 [00:00<00:00, 161.42it/s]\n",
      "Train 84 | out_loss 17.2656307220459: 100%|██████| 8/8 [00:00<00:00, 147.93it/s]\n",
      "Train 85 | out_loss 16.611936569213867: 100%|████| 8/8 [00:00<00:00, 152.67it/s]\n",
      "Train 86 | out_loss 17.72688865661621: 100%|█████| 8/8 [00:00<00:00, 157.30it/s]\n",
      "Train 87 | out_loss 22.299728393554688: 100%|████| 8/8 [00:00<00:00, 159.14it/s]\n",
      "Train 88 | out_loss 20.14836311340332: 100%|█████| 8/8 [00:00<00:00, 157.66it/s]\n",
      "Train 89 | out_loss 20.470224380493164: 100%|████| 8/8 [00:00<00:00, 158.12it/s]\n",
      "Train 90 | out_loss 13.589287757873535: 100%|████| 8/8 [00:00<00:00, 161.36it/s]\n",
      "Train 91 | out_loss 14.178067207336426: 100%|████| 8/8 [00:00<00:00, 153.71it/s]\n",
      "Train 92 | out_loss 14.413654327392578: 100%|████| 8/8 [00:00<00:00, 155.55it/s]\n",
      "Train 93 | out_loss 16.760496139526367: 100%|████| 8/8 [00:00<00:00, 159.78it/s]\n",
      "Train 94 | out_loss 14.859864234924316: 100%|████| 8/8 [00:00<00:00, 158.22it/s]\n",
      "Train 95 | out_loss 16.24027442932129: 100%|█████| 8/8 [00:00<00:00, 155.50it/s]\n",
      "Train 96 | out_loss 13.516668319702148: 100%|████| 8/8 [00:00<00:00, 156.71it/s]\n",
      "Train 97 | out_loss 14.492504119873047: 100%|████| 8/8 [00:00<00:00, 153.01it/s]\n",
      "Train 98 | out_loss 20.003904342651367: 100%|████| 8/8 [00:00<00:00, 155.76it/s]\n",
      "Train 99 | out_loss 13.617162704467773: 100%|████| 8/8 [00:00<00:00, 153.81it/s]\n",
      "Train 100 | out_loss 13.604154586791992: 100%|███| 8/8 [00:00<00:00, 155.31it/s]\n",
      "Train 101 | out_loss 18.939363479614258: 100%|███| 8/8 [00:00<00:00, 150.29it/s]\n",
      "Train 102 | out_loss 15.6353120803833: 100%|█████| 8/8 [00:00<00:00, 109.14it/s]\n",
      "Train 103 | out_loss 15.208784103393555: 100%|███| 8/8 [00:00<00:00, 117.51it/s]\n",
      "Train 104 | out_loss 13.445852279663086: 100%|███| 8/8 [00:00<00:00, 146.53it/s]\n",
      "Train 105 | out_loss 13.24161434173584: 100%|████| 8/8 [00:00<00:00, 157.11it/s]\n",
      "Train 106 | out_loss 13.718886375427246: 100%|███| 8/8 [00:00<00:00, 138.50it/s]\n",
      "Train 107 | out_loss 13.88382625579834: 100%|████| 8/8 [00:00<00:00, 154.70it/s]\n",
      "Train 108 | out_loss 14.655232429504395: 100%|███| 8/8 [00:00<00:00, 150.16it/s]\n",
      "Train 109 | out_loss 14.31169319152832: 100%|████| 8/8 [00:00<00:00, 152.11it/s]\n",
      "Train 110 | out_loss 14.133001327514648: 100%|███| 8/8 [00:00<00:00, 156.27it/s]\n",
      "Train 111 | out_loss 12.669512748718262: 100%|███| 8/8 [00:00<00:00, 151.32it/s]\n",
      "Train 112 | out_loss 12.762857437133789: 100%|███| 8/8 [00:00<00:00, 152.66it/s]\n",
      "Train 113 | out_loss 12.173919677734375: 100%|███| 8/8 [00:00<00:00, 154.64it/s]\n",
      "Train 114 | out_loss 12.93532943725586: 100%|████| 8/8 [00:00<00:00, 159.79it/s]\n",
      "Train 115 | out_loss 12.240424156188965: 100%|███| 8/8 [00:00<00:00, 161.77it/s]\n",
      "Train 116 | out_loss 12.127761840820312: 100%|███| 8/8 [00:00<00:00, 158.92it/s]\n",
      "Train 117 | out_loss 13.051082611083984: 100%|███| 8/8 [00:00<00:00, 148.75it/s]\n",
      "Train 118 | out_loss 13.348624229431152: 100%|███| 8/8 [00:00<00:00, 157.08it/s]\n",
      "Train 119 | out_loss 12.16468620300293: 100%|████| 8/8 [00:00<00:00, 155.62it/s]\n",
      "Train 120 | out_loss 12.319253921508789: 100%|███| 8/8 [00:00<00:00, 155.92it/s]\n",
      "Train 121 | out_loss 12.571331024169922: 100%|███| 8/8 [00:00<00:00, 161.84it/s]\n",
      "Train 122 | out_loss 15.064480781555176: 100%|███| 8/8 [00:00<00:00, 158.08it/s]\n",
      "Train 123 | out_loss 13.80407428741455: 100%|████| 8/8 [00:00<00:00, 159.06it/s]\n",
      "Train 124 | out_loss 13.989228248596191: 100%|███| 8/8 [00:00<00:00, 157.48it/s]\n",
      "Train 125 | out_loss 15.710855484008789: 100%|███| 8/8 [00:00<00:00, 134.17it/s]\n",
      "Train 126 | out_loss 15.068782806396484: 100%|███| 8/8 [00:00<00:00, 152.50it/s]\n",
      "Train 127 | out_loss 14.81389331817627: 100%|████| 8/8 [00:00<00:00, 153.65it/s]\n",
      "Train 128 | out_loss 14.154582977294922: 100%|███| 8/8 [00:00<00:00, 159.74it/s]\n",
      "Train 129 | out_loss 13.514769554138184: 100%|███| 8/8 [00:00<00:00, 153.81it/s]\n",
      "Train 130 | out_loss 13.576055526733398: 100%|███| 8/8 [00:00<00:00, 145.04it/s]\n",
      "Train 131 | out_loss 13.396989822387695: 100%|███| 8/8 [00:00<00:00, 156.57it/s]\n",
      "Train 132 | out_loss 13.520502090454102: 100%|███| 8/8 [00:00<00:00, 157.35it/s]\n",
      "Train 133 | out_loss 13.251953125: 100%|█████████| 8/8 [00:00<00:00, 132.53it/s]\n",
      "Train 134 | out_loss 13.528486251831055: 100%|███| 8/8 [00:00<00:00, 154.16it/s]\n",
      "Train 135 | out_loss 13.049481391906738: 100%|███| 8/8 [00:00<00:00, 154.74it/s]\n",
      "Train 136 | out_loss 12.632355690002441: 100%|███| 8/8 [00:00<00:00, 130.74it/s]\n",
      "Train 137 | out_loss 12.6744966506958: 100%|█████| 8/8 [00:00<00:00, 157.52it/s]\n",
      "Train 138 | out_loss 12.708747863769531: 100%|███| 8/8 [00:00<00:00, 146.83it/s]\n",
      "Train 139 | out_loss 13.026823997497559: 100%|███| 8/8 [00:00<00:00, 142.24it/s]\n",
      "Train 140 | out_loss 13.328132629394531: 100%|███| 8/8 [00:00<00:00, 155.75it/s]\n",
      "Train 141 | out_loss 12.522428512573242: 100%|███| 8/8 [00:00<00:00, 152.53it/s]\n",
      "Train 142 | out_loss 12.366026878356934: 100%|███| 8/8 [00:00<00:00, 153.46it/s]\n",
      "Train 143 | out_loss 12.979596138000488: 100%|███| 8/8 [00:00<00:00, 157.62it/s]\n",
      "Train 144 | out_loss 13.380163192749023: 100%|███| 8/8 [00:00<00:00, 150.46it/s]\n",
      "Train 145 | out_loss 13.477721214294434: 100%|███| 8/8 [00:00<00:00, 151.76it/s]\n",
      "Train 146 | out_loss 13.47157096862793: 100%|████| 8/8 [00:00<00:00, 155.09it/s]\n",
      "Train 147 | out_loss 13.16331672668457: 100%|████| 8/8 [00:00<00:00, 150.99it/s]\n",
      "Train 148 | out_loss 13.10202693939209: 100%|████| 8/8 [00:00<00:00, 153.51it/s]\n",
      "Train 149 | out_loss 12.473027229309082: 100%|███| 8/8 [00:00<00:00, 157.84it/s]\n",
      "Train 150 | out_loss 12.214258193969727: 100%|███| 8/8 [00:00<00:00, 137.77it/s]\n",
      "Train 151 | out_loss 12.396133422851562: 100%|███| 8/8 [00:00<00:00, 146.43it/s]\n",
      "Train 152 | out_loss 12.518167495727539: 100%|███| 8/8 [00:00<00:00, 159.04it/s]\n",
      "Train 153 | out_loss 12.95064640045166: 100%|████| 8/8 [00:00<00:00, 151.28it/s]\n",
      "Train 154 | out_loss 12.64966106414795: 100%|████| 8/8 [00:00<00:00, 158.08it/s]\n",
      "Train 155 | out_loss 12.69963550567627: 100%|████| 8/8 [00:00<00:00, 158.84it/s]\n",
      "Train 156 | out_loss 13.343274116516113: 100%|███| 8/8 [00:00<00:00, 153.68it/s]\n",
      "Train 157 | out_loss 12.989420890808105: 100%|███| 8/8 [00:00<00:00, 118.70it/s]\n",
      "Train 158 | out_loss 12.799528121948242: 100%|███| 8/8 [00:00<00:00, 153.42it/s]\n",
      "Train 159 | out_loss 13.615691184997559: 100%|███| 8/8 [00:00<00:00, 130.25it/s]\n",
      "Train 160 | out_loss 13.432145118713379: 100%|███| 8/8 [00:00<00:00, 159.62it/s]\n",
      "Train 161 | out_loss 13.095004081726074: 100%|███| 8/8 [00:00<00:00, 147.06it/s]\n",
      "Train 162 | out_loss 12.525964736938477: 100%|███| 8/8 [00:00<00:00, 145.65it/s]\n",
      "Train 163 | out_loss 12.72657585144043: 100%|████| 8/8 [00:00<00:00, 130.00it/s]\n",
      "Train 164 | out_loss 12.834163665771484: 100%|███| 8/8 [00:00<00:00, 143.10it/s]\n",
      "Train 165 | out_loss 12.539471626281738: 100%|███| 8/8 [00:00<00:00, 146.29it/s]\n",
      "Train 166 | out_loss 12.421159744262695: 100%|███| 8/8 [00:00<00:00, 159.52it/s]\n",
      "Train 167 | out_loss 12.174212455749512: 100%|███| 8/8 [00:00<00:00, 160.55it/s]\n",
      "Train 168 | out_loss 12.124813079833984: 100%|███| 8/8 [00:00<00:00, 153.71it/s]\n",
      "Train 169 | out_loss 12.460797309875488: 100%|███| 8/8 [00:00<00:00, 149.89it/s]\n",
      "Train 170 | out_loss 12.448164939880371: 100%|███| 8/8 [00:00<00:00, 134.23it/s]\n",
      "Train 171 | out_loss 12.518475532531738: 100%|███| 8/8 [00:00<00:00, 156.53it/s]\n",
      "Train 172 | out_loss 12.639801979064941: 100%|███| 8/8 [00:00<00:00, 156.88it/s]\n",
      "Train 173 | out_loss 12.610617637634277: 100%|███| 8/8 [00:00<00:00, 147.55it/s]\n",
      "Train 174 | out_loss 12.369003295898438: 100%|███| 8/8 [00:00<00:00, 135.97it/s]\n",
      "Train 175 | out_loss 12.423346519470215: 100%|███| 8/8 [00:00<00:00, 154.45it/s]\n",
      "Train 176 | out_loss 12.585890769958496: 100%|███| 8/8 [00:00<00:00, 155.33it/s]\n",
      "Train 177 | out_loss 12.196669578552246: 100%|███| 8/8 [00:00<00:00, 153.92it/s]\n",
      "Train 178 | out_loss 12.756092071533203: 100%|███| 8/8 [00:00<00:00, 145.58it/s]\n",
      "Train 179 | out_loss 12.165349960327148: 100%|███| 8/8 [00:00<00:00, 148.79it/s]\n",
      "Train 180 | out_loss 12.593061447143555: 100%|███| 8/8 [00:00<00:00, 135.64it/s]\n",
      "Train 181 | out_loss 12.95777416229248: 100%|████| 8/8 [00:00<00:00, 159.88it/s]\n",
      "Train 182 | out_loss 12.403519630432129: 100%|███| 8/8 [00:00<00:00, 155.24it/s]\n",
      "Train 183 | out_loss 12.403789520263672: 100%|███| 8/8 [00:00<00:00, 136.80it/s]\n",
      "Train 184 | out_loss 12.615148544311523: 100%|███| 8/8 [00:00<00:00, 135.22it/s]\n",
      "Train 185 | out_loss 12.493850708007812: 100%|███| 8/8 [00:00<00:00, 152.14it/s]\n",
      "Train 186 | out_loss 12.048559188842773: 100%|███| 8/8 [00:00<00:00, 156.50it/s]\n",
      "Train 187 | out_loss 12.385637283325195: 100%|███| 8/8 [00:00<00:00, 157.36it/s]\n",
      "Train 188 | out_loss 12.1223726272583: 100%|█████| 8/8 [00:00<00:00, 152.14it/s]\n",
      "Train 189 | out_loss 12.288951873779297: 100%|███| 8/8 [00:00<00:00, 154.38it/s]\n",
      "Train 190 | out_loss 12.496996879577637: 100%|███| 8/8 [00:00<00:00, 157.30it/s]\n",
      "Train 191 | out_loss 12.7793607711792: 100%|█████| 8/8 [00:00<00:00, 155.34it/s]\n",
      "Train 192 | out_loss 12.720467567443848: 100%|███| 8/8 [00:00<00:00, 151.84it/s]\n",
      "Train 193 | out_loss 12.2051362991333: 100%|█████| 8/8 [00:00<00:00, 155.90it/s]\n",
      "Train 194 | out_loss 12.482437133789062: 100%|███| 8/8 [00:00<00:00, 156.40it/s]\n",
      "Train 195 | out_loss 13.072139739990234: 100%|███| 8/8 [00:00<00:00, 149.15it/s]\n",
      "Train 196 | out_loss 12.700321197509766: 100%|███| 8/8 [00:00<00:00, 157.01it/s]\n",
      "Train 197 | out_loss 11.87395191192627: 100%|████| 8/8 [00:00<00:00, 154.52it/s]\n",
      "Train 198 | out_loss 12.007975578308105: 100%|███| 8/8 [00:00<00:00, 151.90it/s]\n",
      "Train 199 | out_loss 11.976362228393555: 100%|███| 8/8 [00:00<00:00, 155.67it/s]\n",
      "Train 200 | out_loss 11.982495307922363: 100%|███| 8/8 [00:00<00:00, 153.76it/s]\n",
      "Train 201 | out_loss 12.106535911560059: 100%|███| 8/8 [00:00<00:00, 150.59it/s]\n",
      "Train 202 | out_loss 12.212783813476562: 100%|███| 8/8 [00:00<00:00, 146.36it/s]\n",
      "Train 203 | out_loss 12.122828483581543: 100%|███| 8/8 [00:00<00:00, 159.05it/s]\n",
      "Train 204 | out_loss 12.192660331726074: 100%|███| 8/8 [00:00<00:00, 158.68it/s]\n",
      "Train 205 | out_loss 12.382729530334473: 100%|███| 8/8 [00:00<00:00, 156.92it/s]\n",
      "Train 206 | out_loss 12.907612800598145: 100%|███| 8/8 [00:00<00:00, 154.90it/s]\n",
      "Train 207 | out_loss 12.070584297180176: 100%|███| 8/8 [00:00<00:00, 157.24it/s]\n",
      "Train 208 | out_loss 12.983123779296875: 100%|███| 8/8 [00:00<00:00, 155.73it/s]\n",
      "Train 209 | out_loss 12.891289710998535: 100%|███| 8/8 [00:00<00:00, 154.23it/s]\n",
      "Train 210 | out_loss 13.10290241241455: 100%|████| 8/8 [00:00<00:00, 160.18it/s]\n",
      "Train 211 | out_loss 12.21176528930664: 100%|████| 8/8 [00:00<00:00, 133.30it/s]\n",
      "Train 212 | out_loss 13.342048645019531: 100%|███| 8/8 [00:00<00:00, 155.11it/s]\n",
      "Train 213 | out_loss 13.213174819946289: 100%|███| 8/8 [00:00<00:00, 143.97it/s]\n",
      "Train 214 | out_loss 12.50480842590332: 100%|████| 8/8 [00:00<00:00, 156.55it/s]\n",
      "Train 215 | out_loss 12.147165298461914: 100%|███| 8/8 [00:00<00:00, 139.15it/s]\n",
      "Train 216 | out_loss 11.963149070739746: 100%|███| 8/8 [00:00<00:00, 158.22it/s]\n",
      "Train 217 | out_loss 12.205739974975586: 100%|███| 8/8 [00:00<00:00, 154.69it/s]\n",
      "Train 218 | out_loss 12.3160400390625: 100%|█████| 8/8 [00:00<00:00, 154.97it/s]\n",
      "Train 219 | out_loss 13.479757308959961: 100%|███| 8/8 [00:00<00:00, 151.16it/s]\n",
      "Train 220 | out_loss 11.985499382019043: 100%|███| 8/8 [00:00<00:00, 157.58it/s]\n",
      "Train 221 | out_loss 12.95297622680664: 100%|████| 8/8 [00:00<00:00, 137.53it/s]\n",
      "Train 222 | out_loss 13.281529426574707: 100%|███| 8/8 [00:00<00:00, 155.80it/s]\n",
      "Train 223 | out_loss 13.762129783630371: 100%|███| 8/8 [00:00<00:00, 154.72it/s]\n",
      "Train 224 | out_loss 13.736119270324707: 100%|███| 8/8 [00:00<00:00, 159.75it/s]\n",
      "Train 225 | out_loss 13.310452461242676: 100%|███| 8/8 [00:00<00:00, 158.99it/s]\n",
      "Train 226 | out_loss 13.297752380371094: 100%|███| 8/8 [00:00<00:00, 155.64it/s]\n",
      "Train 227 | out_loss 13.275317192077637: 100%|███| 8/8 [00:00<00:00, 160.64it/s]\n",
      "Train 228 | out_loss 13.298019409179688: 100%|███| 8/8 [00:00<00:00, 157.27it/s]\n",
      "Train 229 | out_loss 13.309959411621094: 100%|███| 8/8 [00:00<00:00, 158.04it/s]\n",
      "Train 230 | out_loss 13.38720417022705: 100%|████| 8/8 [00:00<00:00, 155.07it/s]\n",
      "Train 231 | out_loss 13.228514671325684: 100%|███| 8/8 [00:00<00:00, 142.24it/s]\n",
      "Train 232 | out_loss 13.290771484375: 100%|██████| 8/8 [00:00<00:00, 151.66it/s]\n",
      "Train 233 | out_loss 13.303689002990723: 100%|███| 8/8 [00:00<00:00, 154.18it/s]\n",
      "Train 234 | out_loss 13.06181526184082: 100%|████| 8/8 [00:00<00:00, 146.96it/s]\n",
      "Train 235 | out_loss 13.11743450164795: 100%|████| 8/8 [00:00<00:00, 151.82it/s]\n",
      "Train 236 | out_loss 13.07519245147705: 100%|████| 8/8 [00:00<00:00, 150.78it/s]\n",
      "Train 237 | out_loss 13.306058883666992: 100%|███| 8/8 [00:00<00:00, 154.23it/s]\n",
      "Train 238 | out_loss 13.232992172241211: 100%|███| 8/8 [00:00<00:00, 137.52it/s]\n",
      "Train 239 | out_loss 13.231649398803711: 100%|███| 8/8 [00:00<00:00, 159.77it/s]\n",
      "Train 240 | out_loss 13.381163597106934: 100%|███| 8/8 [00:00<00:00, 154.27it/s]\n",
      "Train 241 | out_loss 13.07359504699707: 100%|████| 8/8 [00:00<00:00, 155.90it/s]\n",
      "Train 242 | out_loss 12.957798957824707: 100%|███| 8/8 [00:00<00:00, 158.35it/s]\n",
      "Train 243 | out_loss 13.03989315032959: 100%|████| 8/8 [00:00<00:00, 153.11it/s]\n",
      "Train 244 | out_loss 12.97193717956543: 100%|████| 8/8 [00:00<00:00, 153.17it/s]\n",
      "Train 245 | out_loss 12.803851127624512: 100%|███| 8/8 [00:00<00:00, 148.84it/s]\n",
      "Train 246 | out_loss 13.018421173095703: 100%|███| 8/8 [00:00<00:00, 160.66it/s]\n",
      "Train 247 | out_loss 12.950911521911621: 100%|███| 8/8 [00:00<00:00, 140.43it/s]\n",
      "Train 248 | out_loss 12.740361213684082: 100%|███| 8/8 [00:00<00:00, 140.93it/s]\n",
      "Train 249 | out_loss 12.776718139648438: 100%|███| 8/8 [00:00<00:00, 154.75it/s]\n",
      "Train 250 | out_loss 12.781332969665527: 100%|███| 8/8 [00:00<00:00, 135.75it/s]\n",
      "Train 251 | out_loss 12.568634033203125: 100%|███| 8/8 [00:00<00:00, 133.80it/s]\n",
      "Train 252 | out_loss 12.337961196899414: 100%|███| 8/8 [00:00<00:00, 151.09it/s]\n",
      "Train 253 | out_loss 12.310552597045898: 100%|███| 8/8 [00:00<00:00, 158.59it/s]\n",
      "Train 254 | out_loss 12.365468978881836: 100%|███| 8/8 [00:00<00:00, 155.05it/s]\n",
      "Train 255 | out_loss 13.194286346435547: 100%|███| 8/8 [00:00<00:00, 156.96it/s]\n",
      "Train 256 | out_loss 12.340326309204102: 100%|███| 8/8 [00:00<00:00, 155.91it/s]\n",
      "Train 257 | out_loss 12.673497200012207: 100%|███| 8/8 [00:00<00:00, 160.21it/s]\n",
      "Train 258 | out_loss 12.78753662109375: 100%|████| 8/8 [00:00<00:00, 136.67it/s]\n",
      "Train 259 | out_loss 12.459857940673828: 100%|███| 8/8 [00:00<00:00, 153.62it/s]\n",
      "Train 260 | out_loss 12.334698677062988: 100%|███| 8/8 [00:00<00:00, 152.51it/s]\n",
      "Train 261 | out_loss 12.372061729431152: 100%|███| 8/8 [00:00<00:00, 154.91it/s]\n",
      "Train 262 | out_loss 12.279792785644531: 100%|███| 8/8 [00:00<00:00, 157.84it/s]\n",
      "Train 263 | out_loss 12.452459335327148: 100%|███| 8/8 [00:00<00:00, 156.52it/s]\n",
      "Train 264 | out_loss 12.495844841003418: 100%|███| 8/8 [00:00<00:00, 143.87it/s]\n",
      "Train 265 | out_loss 12.465702056884766: 100%|███| 8/8 [00:00<00:00, 150.64it/s]\n",
      "Train 266 | out_loss 12.261528015136719: 100%|███| 8/8 [00:00<00:00, 146.95it/s]\n",
      "Train 267 | out_loss 12.325637817382812: 100%|███| 8/8 [00:00<00:00, 161.46it/s]\n",
      "Train 268 | out_loss 12.15477466583252: 100%|████| 8/8 [00:00<00:00, 135.41it/s]\n",
      "Train 269 | out_loss 11.968666076660156: 100%|███| 8/8 [00:00<00:00, 148.97it/s]\n",
      "Train 270 | out_loss 12.074148178100586: 100%|███| 8/8 [00:00<00:00, 157.85it/s]\n",
      "Train 271 | out_loss 12.335478782653809: 100%|███| 8/8 [00:00<00:00, 157.86it/s]\n",
      "Train 272 | out_loss 12.162247657775879: 100%|███| 8/8 [00:00<00:00, 159.32it/s]\n",
      "Train 273 | out_loss 11.989086151123047: 100%|███| 8/8 [00:00<00:00, 155.64it/s]\n",
      "Train 274 | out_loss 11.811866760253906: 100%|███| 8/8 [00:00<00:00, 151.41it/s]\n",
      "Train 275 | out_loss 12.461528778076172: 100%|███| 8/8 [00:00<00:00, 158.46it/s]\n",
      "Train 276 | out_loss 13.379629135131836: 100%|███| 8/8 [00:00<00:00, 121.91it/s]\n",
      "Train 277 | out_loss 12.941447257995605: 100%|███| 8/8 [00:00<00:00, 154.48it/s]\n",
      "Train 278 | out_loss 12.979007720947266: 100%|███| 8/8 [00:00<00:00, 160.03it/s]\n",
      "Train 279 | out_loss 12.824482917785645: 100%|███| 8/8 [00:00<00:00, 157.87it/s]\n",
      "Train 280 | out_loss 12.864069938659668: 100%|███| 8/8 [00:00<00:00, 150.36it/s]\n",
      "Train 281 | out_loss 12.675628662109375: 100%|███| 8/8 [00:00<00:00, 131.46it/s]\n",
      "Train 282 | out_loss 13.0819091796875: 100%|█████| 8/8 [00:00<00:00, 151.87it/s]\n",
      "Train 283 | out_loss 12.642213821411133: 100%|███| 8/8 [00:00<00:00, 157.67it/s]\n",
      "Train 284 | out_loss 12.693310737609863: 100%|███| 8/8 [00:00<00:00, 156.67it/s]\n",
      "Train 285 | out_loss 13.122801780700684: 100%|███| 8/8 [00:00<00:00, 159.03it/s]\n",
      "Train 286 | out_loss 12.488680839538574: 100%|███| 8/8 [00:00<00:00, 157.42it/s]\n",
      "Train 287 | out_loss 12.34732437133789: 100%|████| 8/8 [00:00<00:00, 153.60it/s]\n",
      "Train 288 | out_loss 12.405686378479004: 100%|███| 8/8 [00:00<00:00, 156.13it/s]\n",
      "Train 289 | out_loss 13.536155700683594: 100%|███| 8/8 [00:00<00:00, 159.53it/s]\n",
      "Train 290 | out_loss 12.466346740722656: 100%|███| 8/8 [00:00<00:00, 159.62it/s]\n",
      "Train 291 | out_loss 12.29802131652832: 100%|████| 8/8 [00:00<00:00, 155.90it/s]\n",
      "Train 292 | out_loss 12.580010414123535: 100%|███| 8/8 [00:00<00:00, 148.17it/s]\n",
      "Train 293 | out_loss 12.932619094848633: 100%|███| 8/8 [00:00<00:00, 156.86it/s]\n",
      "Train 294 | out_loss 12.390565872192383: 100%|███| 8/8 [00:00<00:00, 161.20it/s]\n",
      "Train 295 | out_loss 12.519679069519043: 100%|███| 8/8 [00:00<00:00, 158.48it/s]\n",
      "Train 296 | out_loss 12.893903732299805: 100%|███| 8/8 [00:00<00:00, 154.20it/s]\n",
      "Train 297 | out_loss 12.004524230957031: 100%|███| 8/8 [00:00<00:00, 149.44it/s]\n",
      "Train 298 | out_loss 12.157453536987305: 100%|███| 8/8 [00:00<00:00, 153.06it/s]\n",
      "Train 299 | out_loss 13.56212329864502: 100%|████| 8/8 [00:00<00:00, 152.06it/s]\n",
      "Train 300 | out_loss 14.03383731842041: 100%|████| 8/8 [00:00<00:00, 155.07it/s]\n",
      "Train 301 | out_loss 13.362788200378418: 100%|███| 8/8 [00:00<00:00, 153.56it/s]\n",
      "Train 302 | out_loss 13.961761474609375: 100%|███| 8/8 [00:00<00:00, 146.73it/s]\n",
      "Train 303 | out_loss 15.399157524108887: 100%|███| 8/8 [00:00<00:00, 155.30it/s]\n",
      "Train 304 | out_loss 11.961718559265137: 100%|███| 8/8 [00:00<00:00, 140.16it/s]\n",
      "Train 305 | out_loss 12.209930419921875: 100%|███| 8/8 [00:00<00:00, 154.87it/s]\n",
      "Train 306 | out_loss 12.014527320861816: 100%|███| 8/8 [00:00<00:00, 158.22it/s]\n",
      "Train 307 | out_loss 12.36204719543457: 100%|████| 8/8 [00:00<00:00, 142.81it/s]\n",
      "Train 308 | out_loss 12.490778923034668: 100%|███| 8/8 [00:00<00:00, 134.05it/s]\n",
      "Train 309 | out_loss 12.546355247497559: 100%|███| 8/8 [00:00<00:00, 147.13it/s]\n",
      "Train 310 | out_loss 12.97158145904541: 100%|████| 8/8 [00:00<00:00, 155.23it/s]\n",
      "Train 311 | out_loss 12.268741607666016: 100%|███| 8/8 [00:00<00:00, 161.06it/s]\n",
      "Train 312 | out_loss 12.146421432495117: 100%|███| 8/8 [00:00<00:00, 146.71it/s]\n",
      "Train 313 | out_loss 12.019428253173828: 100%|███| 8/8 [00:00<00:00, 152.57it/s]\n",
      "Train 314 | out_loss 11.645792961120605: 100%|███| 8/8 [00:00<00:00, 160.31it/s]\n",
      "Train 315 | out_loss 11.740052223205566: 100%|███| 8/8 [00:00<00:00, 154.76it/s]\n",
      "Train 316 | out_loss 11.954883575439453: 100%|███| 8/8 [00:00<00:00, 154.13it/s]\n",
      "Train 317 | out_loss 12.035078048706055: 100%|███| 8/8 [00:00<00:00, 159.19it/s]\n",
      "Train 318 | out_loss 11.841306686401367: 100%|███| 8/8 [00:00<00:00, 140.75it/s]\n",
      "Train 319 | out_loss 11.864215850830078: 100%|███| 8/8 [00:00<00:00, 143.63it/s]\n",
      "Train 320 | out_loss 12.022488594055176: 100%|███| 8/8 [00:00<00:00, 152.33it/s]\n",
      "Train 321 | out_loss 12.196215629577637: 100%|███| 8/8 [00:00<00:00, 149.30it/s]\n",
      "Train 322 | out_loss 12.151613235473633: 100%|███| 8/8 [00:00<00:00, 146.29it/s]\n",
      "Train 323 | out_loss 12.037898063659668: 100%|███| 8/8 [00:00<00:00, 151.83it/s]\n",
      "Train 324 | out_loss 11.69688892364502: 100%|████| 8/8 [00:00<00:00, 156.35it/s]\n",
      "Train 325 | out_loss 13.445782661437988: 100%|███| 8/8 [00:00<00:00, 158.65it/s]\n",
      "Train 326 | out_loss 13.334999084472656: 100%|███| 8/8 [00:00<00:00, 147.36it/s]\n",
      "Train 327 | out_loss 13.282085418701172: 100%|███| 8/8 [00:00<00:00, 159.81it/s]\n",
      "Train 328 | out_loss 13.411662101745605: 100%|███| 8/8 [00:00<00:00, 155.28it/s]\n",
      "Train 329 | out_loss 13.393903732299805: 100%|███| 8/8 [00:00<00:00, 157.11it/s]\n",
      "Train 330 | out_loss 13.32028579711914: 100%|████| 8/8 [00:00<00:00, 155.84it/s]\n",
      "Train 331 | out_loss 13.371726989746094: 100%|███| 8/8 [00:00<00:00, 153.56it/s]\n",
      "Train 332 | out_loss 13.36949348449707: 100%|████| 8/8 [00:00<00:00, 158.51it/s]\n",
      "Train 333 | out_loss 13.414986610412598: 100%|███| 8/8 [00:00<00:00, 155.62it/s]\n",
      "Train 334 | out_loss 13.350034713745117: 100%|███| 8/8 [00:00<00:00, 156.72it/s]\n",
      "Train 335 | out_loss 13.337868690490723: 100%|███| 8/8 [00:00<00:00, 163.12it/s]\n",
      "Train 336 | out_loss 13.364410400390625: 100%|███| 8/8 [00:00<00:00, 154.95it/s]\n",
      "Train 337 | out_loss 13.360501289367676: 100%|███| 8/8 [00:00<00:00, 161.19it/s]\n",
      "Train 338 | out_loss 13.349234580993652: 100%|███| 8/8 [00:00<00:00, 157.64it/s]\n",
      "Train 339 | out_loss 13.317699432373047: 100%|███| 8/8 [00:00<00:00, 156.92it/s]\n",
      "Train 340 | out_loss 13.42660140991211: 100%|████| 8/8 [00:00<00:00, 149.96it/s]\n",
      "Train 341 | out_loss 13.29222297668457: 100%|████| 8/8 [00:00<00:00, 152.73it/s]\n",
      "Train 342 | out_loss 13.260644912719727: 100%|███| 8/8 [00:00<00:00, 154.56it/s]\n",
      "Train 343 | out_loss 16.18429946899414: 100%|████| 8/8 [00:00<00:00, 156.68it/s]\n",
      "Train 344 | out_loss 14.439310073852539: 100%|███| 8/8 [00:00<00:00, 137.93it/s]\n",
      "Train 345 | out_loss 18.762907028198242: 100%|███| 8/8 [00:00<00:00, 140.16it/s]\n",
      "Train 346 | out_loss 15.533819198608398: 100%|███| 8/8 [00:00<00:00, 151.97it/s]\n",
      "Train 347 | out_loss 17.726572036743164: 100%|███| 8/8 [00:00<00:00, 152.21it/s]\n",
      "Train 348 | out_loss 14.962448120117188: 100%|███| 8/8 [00:00<00:00, 155.83it/s]\n",
      "Train 349 | out_loss 13.856339454650879: 100%|███| 8/8 [00:00<00:00, 150.31it/s]\n",
      "Train 350 | out_loss 13.34228515625: 100%|███████| 8/8 [00:00<00:00, 156.90it/s]\n",
      "Train 351 | out_loss 13.339210510253906: 100%|███| 8/8 [00:00<00:00, 152.45it/s]\n",
      "Train 352 | out_loss 13.538366317749023: 100%|███| 8/8 [00:00<00:00, 140.29it/s]\n",
      "Train 353 | out_loss 13.724736213684082: 100%|███| 8/8 [00:00<00:00, 157.10it/s]\n",
      "Train 354 | out_loss 14.645210266113281: 100%|███| 8/8 [00:00<00:00, 150.63it/s]\n",
      "Train 355 | out_loss 13.363481521606445: 100%|███| 8/8 [00:00<00:00, 158.18it/s]\n",
      "Train 356 | out_loss 13.387038230895996: 100%|███| 8/8 [00:00<00:00, 155.19it/s]\n",
      "Train 357 | out_loss 13.440448760986328: 100%|███| 8/8 [00:00<00:00, 151.23it/s]\n",
      "Train 358 | out_loss 13.332639694213867: 100%|███| 8/8 [00:00<00:00, 160.47it/s]\n",
      "Train 359 | out_loss 15.589335441589355: 100%|███| 8/8 [00:00<00:00, 158.72it/s]\n",
      "Train 360 | out_loss 13.366742134094238: 100%|███| 8/8 [00:00<00:00, 159.42it/s]\n",
      "Train 361 | out_loss 13.344012260437012: 100%|███| 8/8 [00:00<00:00, 151.93it/s]\n",
      "Train 362 | out_loss 13.516963005065918: 100%|███| 8/8 [00:00<00:00, 151.51it/s]\n",
      "Train 363 | out_loss 13.339044570922852: 100%|███| 8/8 [00:00<00:00, 155.89it/s]\n",
      "Train 364 | out_loss 13.370648384094238: 100%|███| 8/8 [00:00<00:00, 156.85it/s]\n",
      "Train 365 | out_loss 13.336584091186523: 100%|███| 8/8 [00:00<00:00, 155.01it/s]\n",
      "Train 366 | out_loss 13.339765548706055: 100%|███| 8/8 [00:00<00:00, 151.24it/s]\n",
      "Train 367 | out_loss 13.3467378616333: 100%|█████| 8/8 [00:00<00:00, 152.98it/s]\n",
      "Train 368 | out_loss 13.323615074157715: 100%|███| 8/8 [00:00<00:00, 148.91it/s]\n",
      "Train 369 | out_loss 13.309189796447754: 100%|███| 8/8 [00:00<00:00, 151.68it/s]\n",
      "Train 370 | out_loss 13.463852882385254: 100%|███| 8/8 [00:00<00:00, 155.32it/s]\n",
      "Train 371 | out_loss 13.456713676452637: 100%|███| 8/8 [00:00<00:00, 152.02it/s]\n",
      "Train 372 | out_loss 13.516919136047363: 100%|███| 8/8 [00:00<00:00, 151.06it/s]\n",
      "Train 373 | out_loss 13.501823425292969: 100%|███| 8/8 [00:00<00:00, 155.85it/s]\n",
      "Train 374 | out_loss 13.406828880310059: 100%|███| 8/8 [00:00<00:00, 150.14it/s]\n",
      "Train 375 | out_loss 13.48561954498291: 100%|████| 8/8 [00:00<00:00, 151.29it/s]\n",
      "Train 376 | out_loss 13.80782413482666: 100%|████| 8/8 [00:00<00:00, 150.98it/s]\n",
      "Train 377 | out_loss 13.475531578063965: 100%|███| 8/8 [00:00<00:00, 154.17it/s]\n",
      "Train 378 | out_loss 13.636686325073242: 100%|███| 8/8 [00:00<00:00, 146.69it/s]\n",
      "Train 379 | out_loss 13.637484550476074: 100%|███| 8/8 [00:00<00:00, 153.72it/s]\n",
      "Train 380 | out_loss 13.374879837036133: 100%|███| 8/8 [00:00<00:00, 156.67it/s]\n",
      "Train 381 | out_loss 13.402132987976074: 100%|███| 8/8 [00:00<00:00, 156.97it/s]\n",
      "Train 382 | out_loss 13.365403175354004: 100%|███| 8/8 [00:00<00:00, 154.02it/s]\n",
      "Train 383 | out_loss 13.337043762207031: 100%|███| 8/8 [00:00<00:00, 160.37it/s]\n",
      "Train 384 | out_loss 13.398991584777832: 100%|███| 8/8 [00:00<00:00, 155.61it/s]\n",
      "Train 385 | out_loss 13.489142417907715: 100%|███| 8/8 [00:00<00:00, 158.15it/s]\n",
      "Train 386 | out_loss 13.38163948059082: 100%|████| 8/8 [00:00<00:00, 153.76it/s]\n",
      "Train 387 | out_loss 13.506032943725586: 100%|███| 8/8 [00:00<00:00, 152.91it/s]\n",
      "Train 388 | out_loss 13.343935012817383: 100%|███| 8/8 [00:00<00:00, 154.72it/s]\n",
      "Train 389 | out_loss 13.39801025390625: 100%|████| 8/8 [00:00<00:00, 157.88it/s]\n",
      "Train 390 | out_loss 13.402576446533203: 100%|███| 8/8 [00:00<00:00, 146.90it/s]\n",
      "Train 391 | out_loss 13.41296672821045: 100%|████| 8/8 [00:00<00:00, 156.02it/s]\n",
      "Train 392 | out_loss 13.407538414001465: 100%|███| 8/8 [00:00<00:00, 157.54it/s]\n",
      "Train 393 | out_loss 13.337276458740234: 100%|███| 8/8 [00:00<00:00, 136.42it/s]\n",
      "Train 394 | out_loss 13.479412078857422: 100%|███| 8/8 [00:00<00:00, 146.30it/s]\n",
      "Train 395 | out_loss 13.36125659942627: 100%|████| 8/8 [00:00<00:00, 151.47it/s]\n",
      "Train 396 | out_loss 13.35607624053955: 100%|████| 8/8 [00:00<00:00, 136.33it/s]\n",
      "Train 397 | out_loss 13.385290145874023: 100%|███| 8/8 [00:00<00:00, 148.92it/s]\n",
      "Train 398 | out_loss 13.381595611572266: 100%|███| 8/8 [00:00<00:00, 154.93it/s]\n",
      "Train 399 | out_loss 13.366827011108398: 100%|███| 8/8 [00:00<00:00, 158.97it/s]\n",
      "Train 400 | out_loss 13.420842170715332: 100%|███| 8/8 [00:00<00:00, 150.60it/s]\n",
      "Train 401 | out_loss 13.369536399841309: 100%|███| 8/8 [00:00<00:00, 158.81it/s]\n",
      "Train 402 | out_loss 13.362386703491211: 100%|███| 8/8 [00:00<00:00, 154.97it/s]\n",
      "Train 403 | out_loss 13.45800495147705: 100%|████| 8/8 [00:00<00:00, 144.38it/s]\n",
      "Train 404 | out_loss 13.496899604797363: 100%|███| 8/8 [00:00<00:00, 140.22it/s]\n",
      "Train 405 | out_loss 13.386309623718262: 100%|███| 8/8 [00:00<00:00, 154.82it/s]\n",
      "Train 406 | out_loss 13.376724243164062: 100%|███| 8/8 [00:00<00:00, 158.55it/s]\n",
      "Train 407 | out_loss 13.355157852172852: 100%|███| 8/8 [00:00<00:00, 150.19it/s]\n",
      "Train 408 | out_loss 13.333274841308594: 100%|███| 8/8 [00:00<00:00, 135.98it/s]\n",
      "Train 409 | out_loss 13.367440223693848: 100%|███| 8/8 [00:00<00:00, 152.40it/s]\n",
      "Train 410 | out_loss 13.333695411682129: 100%|███| 8/8 [00:00<00:00, 155.89it/s]\n",
      "Train 411 | out_loss 13.33614730834961: 100%|████| 8/8 [00:00<00:00, 154.83it/s]\n",
      "Train 412 | out_loss 13.400347709655762: 100%|███| 8/8 [00:00<00:00, 152.72it/s]\n",
      "Train 413 | out_loss 13.700658798217773: 100%|███| 8/8 [00:00<00:00, 156.18it/s]\n",
      "Train 414 | out_loss 13.385037422180176: 100%|███| 8/8 [00:00<00:00, 148.84it/s]\n",
      "Train 415 | out_loss 13.369647979736328: 100%|███| 8/8 [00:00<00:00, 157.04it/s]\n",
      "Train 416 | out_loss 13.384732246398926: 100%|███| 8/8 [00:00<00:00, 158.44it/s]\n",
      "Train 417 | out_loss 13.391783714294434: 100%|███| 8/8 [00:00<00:00, 139.66it/s]\n",
      "Train 418 | out_loss 13.366727828979492: 100%|███| 8/8 [00:00<00:00, 155.71it/s]\n",
      "Train 419 | out_loss 13.346943855285645: 100%|███| 8/8 [00:00<00:00, 130.10it/s]\n",
      "Train 420 | out_loss 13.372163772583008: 100%|███| 8/8 [00:00<00:00, 147.24it/s]\n",
      "Train 421 | out_loss 13.523589134216309: 100%|███| 8/8 [00:00<00:00, 157.05it/s]\n",
      "Train 422 | out_loss 13.461600303649902: 100%|███| 8/8 [00:00<00:00, 154.40it/s]\n",
      "Train 423 | out_loss 13.376823425292969: 100%|███| 8/8 [00:00<00:00, 157.66it/s]\n",
      "Train 424 | out_loss 13.317687034606934: 100%|███| 8/8 [00:00<00:00, 151.77it/s]\n",
      "Train 425 | out_loss 13.456001281738281: 100%|███| 8/8 [00:00<00:00, 142.77it/s]\n",
      "Train 426 | out_loss 13.50191593170166: 100%|████| 8/8 [00:00<00:00, 149.92it/s]\n",
      "Train 427 | out_loss 13.595292091369629: 100%|███| 8/8 [00:00<00:00, 154.16it/s]\n",
      "Train 428 | out_loss 13.34753131866455: 100%|████| 8/8 [00:00<00:00, 159.02it/s]\n",
      "Train 429 | out_loss 13.367727279663086: 100%|███| 8/8 [00:00<00:00, 152.20it/s]\n",
      "Train 430 | out_loss 13.404507637023926: 100%|███| 8/8 [00:00<00:00, 159.81it/s]\n",
      "Train 431 | out_loss 13.353174209594727: 100%|███| 8/8 [00:00<00:00, 153.43it/s]\n",
      "Train 432 | out_loss 13.39396858215332: 100%|████| 8/8 [00:00<00:00, 155.75it/s]\n",
      "Train 433 | out_loss 13.362750053405762: 100%|███| 8/8 [00:00<00:00, 120.61it/s]\n",
      "Train 434 | out_loss 13.39050006866455: 100%|████| 8/8 [00:00<00:00, 145.97it/s]\n",
      "Train 435 | out_loss 13.411737442016602: 100%|███| 8/8 [00:00<00:00, 154.09it/s]\n",
      "Train 436 | out_loss 13.411764144897461: 100%|███| 8/8 [00:00<00:00, 153.01it/s]\n",
      "Train 437 | out_loss 13.41978931427002: 100%|████| 8/8 [00:00<00:00, 160.88it/s]\n",
      "Train 438 | out_loss 13.388270378112793: 100%|███| 8/8 [00:00<00:00, 153.06it/s]\n",
      "Train 439 | out_loss 13.503440856933594: 100%|███| 8/8 [00:00<00:00, 154.31it/s]\n",
      "Train 440 | out_loss 13.424558639526367: 100%|███| 8/8 [00:00<00:00, 157.80it/s]\n",
      "Train 441 | out_loss 13.35785961151123: 100%|████| 8/8 [00:00<00:00, 155.60it/s]\n",
      "Train 442 | out_loss 13.392535209655762: 100%|███| 8/8 [00:00<00:00, 152.97it/s]\n",
      "Train 443 | out_loss 13.35545825958252: 100%|████| 8/8 [00:00<00:00, 149.71it/s]\n",
      "Train 444 | out_loss 13.407268524169922: 100%|███| 8/8 [00:00<00:00, 155.86it/s]\n",
      "Train 445 | out_loss 13.401199340820312: 100%|███| 8/8 [00:00<00:00, 144.42it/s]\n",
      "Train 446 | out_loss 13.371842384338379: 100%|███| 8/8 [00:00<00:00, 125.68it/s]\n",
      "Train 447 | out_loss 13.368911743164062: 100%|███| 8/8 [00:00<00:00, 135.67it/s]\n",
      "Train 448 | out_loss 13.436102867126465: 100%|███| 8/8 [00:00<00:00, 146.47it/s]\n",
      "Train 449 | out_loss 13.401288032531738: 100%|███| 8/8 [00:00<00:00, 148.96it/s]\n",
      "Train 450 | out_loss 13.355977058410645: 100%|███| 8/8 [00:00<00:00, 158.40it/s]\n",
      "Train 451 | out_loss 13.373754501342773: 100%|███| 8/8 [00:00<00:00, 156.24it/s]\n",
      "Train 452 | out_loss 13.343635559082031: 100%|███| 8/8 [00:00<00:00, 154.46it/s]\n",
      "Train 453 | out_loss 13.477364540100098: 100%|███| 8/8 [00:00<00:00, 124.31it/s]\n",
      "Train 454 | out_loss 13.389044761657715: 100%|███| 8/8 [00:00<00:00, 147.10it/s]\n",
      "Train 455 | out_loss 13.36559772491455: 100%|████| 8/8 [00:00<00:00, 154.15it/s]\n",
      "Train 456 | out_loss 13.348015785217285: 100%|███| 8/8 [00:00<00:00, 154.80it/s]\n",
      "Train 457 | out_loss 13.398791313171387: 100%|███| 8/8 [00:00<00:00, 151.51it/s]\n",
      "Train 458 | out_loss 13.731879234313965: 100%|███| 8/8 [00:00<00:00, 158.09it/s]\n",
      "Train 459 | out_loss 13.466151237487793: 100%|███| 8/8 [00:00<00:00, 156.72it/s]\n",
      "Train 460 | out_loss 13.550149917602539: 100%|███| 8/8 [00:00<00:00, 144.72it/s]\n",
      "Train 461 | out_loss 13.354987144470215: 100%|███| 8/8 [00:00<00:00, 157.20it/s]\n",
      "Train 462 | out_loss 13.438995361328125: 100%|███| 8/8 [00:00<00:00, 154.79it/s]\n",
      "Train 463 | out_loss 13.371501922607422: 100%|███| 8/8 [00:00<00:00, 160.08it/s]\n",
      "Train 464 | out_loss 13.323700904846191: 100%|███| 8/8 [00:00<00:00, 160.50it/s]\n",
      "Train 465 | out_loss 13.382981300354004: 100%|███| 8/8 [00:00<00:00, 153.11it/s]\n",
      "Train 466 | out_loss 13.356742858886719: 100%|███| 8/8 [00:00<00:00, 154.15it/s]\n",
      "Train 467 | out_loss 13.355541229248047: 100%|███| 8/8 [00:00<00:00, 145.86it/s]\n",
      "Train 468 | out_loss 13.29952621459961: 100%|████| 8/8 [00:00<00:00, 151.01it/s]\n",
      "Train 469 | out_loss 13.396981239318848: 100%|███| 8/8 [00:00<00:00, 158.12it/s]\n",
      "Train 470 | out_loss 13.406299591064453: 100%|███| 8/8 [00:00<00:00, 154.51it/s]\n",
      "Train 471 | out_loss 13.362740516662598: 100%|███| 8/8 [00:00<00:00, 148.10it/s]\n",
      "Train 472 | out_loss 13.373775482177734: 100%|███| 8/8 [00:00<00:00, 150.00it/s]\n",
      "Train 473 | out_loss 13.365436553955078: 100%|███| 8/8 [00:00<00:00, 159.35it/s]\n",
      "Train 474 | out_loss 13.374168395996094: 100%|███| 8/8 [00:00<00:00, 153.07it/s]\n",
      "Train 475 | out_loss 13.367189407348633: 100%|███| 8/8 [00:00<00:00, 160.70it/s]\n",
      "Train 476 | out_loss 13.421574592590332: 100%|███| 8/8 [00:00<00:00, 155.89it/s]\n",
      "Train 477 | out_loss 13.367466926574707: 100%|███| 8/8 [00:00<00:00, 155.98it/s]\n",
      "Train 478 | out_loss 13.453261375427246: 100%|███| 8/8 [00:00<00:00, 158.86it/s]\n",
      "Train 479 | out_loss 13.538240432739258: 100%|███| 8/8 [00:00<00:00, 153.32it/s]\n",
      "Train 480 | out_loss 13.360413551330566: 100%|███| 8/8 [00:00<00:00, 153.69it/s]\n",
      "Train 481 | out_loss 13.502765655517578: 100%|███| 8/8 [00:00<00:00, 143.91it/s]\n",
      "Train 482 | out_loss 13.364006996154785: 100%|███| 8/8 [00:00<00:00, 154.29it/s]\n",
      "Train 483 | out_loss 13.55932331085205: 100%|████| 8/8 [00:00<00:00, 157.67it/s]\n",
      "Train 484 | out_loss 13.358977317810059: 100%|███| 8/8 [00:00<00:00, 157.77it/s]\n",
      "Train 485 | out_loss 13.394784927368164: 100%|███| 8/8 [00:00<00:00, 155.01it/s]\n",
      "Train 486 | out_loss 13.359587669372559: 100%|███| 8/8 [00:00<00:00, 156.48it/s]\n",
      "Train 487 | out_loss 13.428997993469238: 100%|███| 8/8 [00:00<00:00, 158.82it/s]\n",
      "Train 488 | out_loss 13.646416664123535: 100%|███| 8/8 [00:00<00:00, 153.42it/s]\n",
      "Train 489 | out_loss 13.54509449005127: 100%|████| 8/8 [00:00<00:00, 150.69it/s]\n",
      "Train 490 | out_loss 13.775877952575684: 100%|███| 8/8 [00:00<00:00, 152.57it/s]\n",
      "Train 491 | out_loss 13.330056190490723: 100%|███| 8/8 [00:00<00:00, 152.60it/s]\n",
      "Train 492 | out_loss 13.398503303527832: 100%|███| 8/8 [00:00<00:00, 154.65it/s]\n",
      "Train 493 | out_loss 13.381332397460938: 100%|███| 8/8 [00:00<00:00, 141.02it/s]\n",
      "Train 494 | out_loss 13.459394454956055: 100%|███| 8/8 [00:00<00:00, 128.11it/s]\n",
      "Train 495 | out_loss 13.445701599121094: 100%|███| 8/8 [00:00<00:00, 149.33it/s]\n",
      "Train 496 | out_loss 13.42834758758545: 100%|████| 8/8 [00:00<00:00, 159.75it/s]\n",
      "Train 497 | out_loss 13.40713119506836: 100%|████| 8/8 [00:00<00:00, 138.29it/s]\n",
      "Train 498 | out_loss 13.347611427307129: 100%|███| 8/8 [00:00<00:00, 150.80it/s]\n",
      "Train 499 | out_loss 13.3294038772583: 100%|█████| 8/8 [00:00<00:00, 147.89it/s]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 80.223876953125: 100%|█████████| 8/8 [00:00<00:00, 18.81it/s]\n",
      "Train 1 | out_loss 79.88777160644531: 100%|██████| 8/8 [00:00<00:00, 141.47it/s]\n",
      "Train 2 | out_loss 76.55028533935547: 100%|██████| 8/8 [00:00<00:00, 138.72it/s]\n",
      "Train 3 | out_loss 75.22187805175781: 100%|██████| 8/8 [00:00<00:00, 136.73it/s]\n",
      "Train 4 | out_loss 77.32617950439453: 100%|██████| 8/8 [00:00<00:00, 124.22it/s]\n",
      "Train 5 | out_loss 72.75139617919922: 100%|██████| 8/8 [00:00<00:00, 137.25it/s]\n",
      "Train 6 | out_loss 73.781005859375: 100%|████████| 8/8 [00:00<00:00, 136.08it/s]\n",
      "Train 7 | out_loss 72.46659851074219: 100%|██████| 8/8 [00:00<00:00, 130.39it/s]\n",
      "Train 8 | out_loss 72.52972412109375: 100%|██████| 8/8 [00:00<00:00, 139.36it/s]\n",
      "Train 9 | out_loss 72.12960815429688: 100%|██████| 8/8 [00:00<00:00, 139.12it/s]\n",
      "Train 10 | out_loss 70.36063385009766: 100%|█████| 8/8 [00:00<00:00, 138.65it/s]\n",
      "Train 11 | out_loss 64.66839599609375: 100%|█████| 8/8 [00:00<00:00, 133.77it/s]\n",
      "Train 12 | out_loss 69.35318756103516: 100%|█████| 8/8 [00:00<00:00, 138.47it/s]\n",
      "Train 13 | out_loss 67.96208190917969: 100%|█████| 8/8 [00:00<00:00, 136.86it/s]\n",
      "Train 14 | out_loss 66.93404388427734: 100%|█████| 8/8 [00:00<00:00, 126.08it/s]\n",
      "Train 15 | out_loss 62.860294342041016: 100%|████| 8/8 [00:00<00:00, 109.90it/s]\n",
      "Train 16 | out_loss 63.055118560791016: 100%|████| 8/8 [00:00<00:00, 125.18it/s]\n",
      "Train 17 | out_loss 60.885623931884766: 100%|████| 8/8 [00:00<00:00, 131.96it/s]\n",
      "Train 18 | out_loss 62.932838439941406: 100%|████| 8/8 [00:00<00:00, 125.96it/s]\n",
      "Train 19 | out_loss 63.668975830078125: 100%|████| 8/8 [00:00<00:00, 136.01it/s]\n",
      "Train 20 | out_loss 54.770790100097656: 100%|████| 8/8 [00:00<00:00, 134.14it/s]\n",
      "Train 21 | out_loss 56.43639373779297: 100%|█████| 8/8 [00:00<00:00, 128.91it/s]\n",
      "Train 22 | out_loss 60.68748474121094: 100%|█████| 8/8 [00:00<00:00, 133.36it/s]\n",
      "Train 23 | out_loss 58.170047760009766: 100%|████| 8/8 [00:00<00:00, 136.28it/s]\n",
      "Train 24 | out_loss 54.30153274536133: 100%|█████| 8/8 [00:00<00:00, 137.10it/s]\n",
      "Train 25 | out_loss 52.34383773803711: 100%|█████| 8/8 [00:00<00:00, 114.80it/s]\n",
      "Train 26 | out_loss 52.81670379638672: 100%|█████| 8/8 [00:00<00:00, 127.18it/s]\n",
      "Train 27 | out_loss 53.43474578857422: 100%|█████| 8/8 [00:00<00:00, 139.70it/s]\n",
      "Train 28 | out_loss 51.30363464355469: 100%|█████| 8/8 [00:00<00:00, 137.64it/s]\n",
      "Train 29 | out_loss 49.948890686035156: 100%|████| 8/8 [00:00<00:00, 115.01it/s]\n",
      "Train 30 | out_loss 49.30635452270508: 100%|█████| 8/8 [00:00<00:00, 140.34it/s]\n",
      "Train 31 | out_loss 48.700870513916016: 100%|████| 8/8 [00:00<00:00, 137.43it/s]\n",
      "Train 32 | out_loss 47.164154052734375: 100%|████| 8/8 [00:00<00:00, 139.49it/s]\n",
      "Train 33 | out_loss 46.43655014038086: 100%|█████| 8/8 [00:00<00:00, 136.69it/s]\n",
      "Train 34 | out_loss 45.131004333496094: 100%|████| 8/8 [00:00<00:00, 136.77it/s]\n",
      "Train 35 | out_loss 44.2413330078125: 100%|██████| 8/8 [00:00<00:00, 133.73it/s]\n",
      "Train 36 | out_loss 43.27273178100586: 100%|█████| 8/8 [00:00<00:00, 134.33it/s]\n",
      "Train 37 | out_loss 42.21903991699219: 100%|█████| 8/8 [00:00<00:00, 137.98it/s]\n",
      "Train 38 | out_loss 41.184207916259766: 100%|████| 8/8 [00:00<00:00, 129.63it/s]\n",
      "Train 39 | out_loss 40.49018478393555: 100%|█████| 8/8 [00:00<00:00, 135.58it/s]\n",
      "Train 40 | out_loss 39.47139358520508: 100%|█████| 8/8 [00:00<00:00, 135.24it/s]\n",
      "Train 41 | out_loss 38.254947662353516: 100%|████| 8/8 [00:00<00:00, 133.35it/s]\n",
      "Train 42 | out_loss 37.23274612426758: 100%|█████| 8/8 [00:00<00:00, 137.43it/s]\n",
      "Train 43 | out_loss 36.42424774169922: 100%|█████| 8/8 [00:00<00:00, 136.52it/s]\n",
      "Train 44 | out_loss 35.6835823059082: 100%|██████| 8/8 [00:00<00:00, 138.09it/s]\n",
      "Train 45 | out_loss 34.6177864074707: 100%|██████| 8/8 [00:00<00:00, 140.70it/s]\n",
      "Train 46 | out_loss 33.453826904296875: 100%|████| 8/8 [00:00<00:00, 137.64it/s]\n",
      "Train 47 | out_loss 32.52485275268555: 100%|█████| 8/8 [00:00<00:00, 110.76it/s]\n",
      "Train 48 | out_loss 31.723464965820312: 100%|████| 8/8 [00:00<00:00, 109.21it/s]\n",
      "Train 49 | out_loss 30.823102951049805: 100%|████| 8/8 [00:00<00:00, 130.64it/s]\n",
      "Train 50 | out_loss 29.88731575012207: 100%|█████| 8/8 [00:00<00:00, 137.68it/s]\n",
      "Train 51 | out_loss 28.88916778564453: 100%|█████| 8/8 [00:00<00:00, 136.98it/s]\n",
      "Train 52 | out_loss 27.866750717163086: 100%|████| 8/8 [00:00<00:00, 137.17it/s]\n",
      "Train 53 | out_loss 27.01106834411621: 100%|█████| 8/8 [00:00<00:00, 139.18it/s]\n",
      "Train 54 | out_loss 26.278656005859375: 100%|████| 8/8 [00:00<00:00, 140.78it/s]\n",
      "Train 55 | out_loss 25.41250991821289: 100%|█████| 8/8 [00:00<00:00, 133.08it/s]\n",
      "Train 56 | out_loss 24.667734146118164: 100%|████| 8/8 [00:00<00:00, 136.44it/s]\n",
      "Train 57 | out_loss 24.12149429321289: 100%|█████| 8/8 [00:00<00:00, 137.89it/s]\n",
      "Train 58 | out_loss 22.164295196533203: 100%|████| 8/8 [00:00<00:00, 137.99it/s]\n",
      "Train 59 | out_loss 21.733007431030273: 100%|████| 8/8 [00:00<00:00, 137.94it/s]\n",
      "Train 60 | out_loss 21.383874893188477: 100%|████| 8/8 [00:00<00:00, 137.16it/s]\n",
      "Train 61 | out_loss 20.695449829101562: 100%|████| 8/8 [00:00<00:00, 136.87it/s]\n",
      "Train 62 | out_loss 19.810367584228516: 100%|████| 8/8 [00:00<00:00, 142.49it/s]\n",
      "Train 63 | out_loss 18.808982849121094: 100%|████| 8/8 [00:00<00:00, 130.20it/s]\n",
      "Train 64 | out_loss 18.31138801574707: 100%|█████| 8/8 [00:00<00:00, 120.40it/s]\n",
      "Train 65 | out_loss 17.97606658935547: 100%|█████| 8/8 [00:00<00:00, 138.47it/s]\n",
      "Train 66 | out_loss 16.637226104736328: 100%|████| 8/8 [00:00<00:00, 130.32it/s]\n",
      "Train 67 | out_loss 17.17662811279297: 100%|█████| 8/8 [00:00<00:00, 138.77it/s]\n",
      "Train 68 | out_loss 16.315227508544922: 100%|████| 8/8 [00:00<00:00, 139.34it/s]\n",
      "Train 69 | out_loss 14.51785945892334: 100%|█████| 8/8 [00:00<00:00, 140.95it/s]\n",
      "Train 70 | out_loss 17.73634147644043: 100%|█████| 8/8 [00:00<00:00, 127.77it/s]\n",
      "Train 71 | out_loss 14.762309074401855: 100%|████| 8/8 [00:00<00:00, 129.34it/s]\n",
      "Train 72 | out_loss 14.2333345413208: 100%|██████| 8/8 [00:00<00:00, 143.69it/s]\n",
      "Train 73 | out_loss 15.9157075881958: 100%|██████| 8/8 [00:00<00:00, 137.90it/s]\n",
      "Train 74 | out_loss 14.394708633422852: 100%|████| 8/8 [00:00<00:00, 138.02it/s]\n",
      "Train 75 | out_loss 13.574304580688477: 100%|████| 8/8 [00:00<00:00, 141.30it/s]\n",
      "Train 76 | out_loss 16.624237060546875: 100%|████| 8/8 [00:00<00:00, 138.33it/s]\n",
      "Train 77 | out_loss 14.893851280212402: 100%|████| 8/8 [00:00<00:00, 138.80it/s]\n",
      "Train 78 | out_loss 15.781431198120117: 100%|████| 8/8 [00:00<00:00, 138.79it/s]\n",
      "Train 79 | out_loss 16.62314224243164: 100%|█████| 8/8 [00:00<00:00, 140.27it/s]\n",
      "Train 80 | out_loss 13.985709190368652: 100%|████| 8/8 [00:00<00:00, 139.37it/s]\n",
      "Train 81 | out_loss 14.00938606262207: 100%|█████| 8/8 [00:00<00:00, 135.86it/s]\n",
      "Train 82 | out_loss 13.689105987548828: 100%|████| 8/8 [00:00<00:00, 142.24it/s]\n",
      "Train 83 | out_loss 14.235657691955566: 100%|████| 8/8 [00:00<00:00, 131.96it/s]\n",
      "Train 84 | out_loss 19.673927307128906: 100%|████| 8/8 [00:00<00:00, 132.43it/s]\n",
      "Train 85 | out_loss 14.117383003234863: 100%|████| 8/8 [00:00<00:00, 136.49it/s]\n",
      "Train 86 | out_loss 13.526249885559082: 100%|████| 8/8 [00:00<00:00, 135.43it/s]\n",
      "Train 87 | out_loss 17.70201301574707: 100%|█████| 8/8 [00:00<00:00, 133.86it/s]\n",
      "Train 88 | out_loss 16.5460205078125: 100%|██████| 8/8 [00:00<00:00, 140.98it/s]\n",
      "Train 89 | out_loss 15.886329650878906: 100%|████| 8/8 [00:00<00:00, 134.74it/s]\n",
      "Train 90 | out_loss 16.021827697753906: 100%|████| 8/8 [00:00<00:00, 140.78it/s]\n",
      "Train 91 | out_loss 15.376855850219727: 100%|████| 8/8 [00:00<00:00, 138.39it/s]\n",
      "Train 92 | out_loss 15.39168643951416: 100%|█████| 8/8 [00:00<00:00, 139.29it/s]\n",
      "Train 93 | out_loss 16.62509536743164: 100%|█████| 8/8 [00:00<00:00, 139.85it/s]\n",
      "Train 94 | out_loss 13.933881759643555: 100%|████| 8/8 [00:00<00:00, 143.89it/s]\n",
      "Train 95 | out_loss 14.950364112854004: 100%|████| 8/8 [00:00<00:00, 137.48it/s]\n",
      "Train 96 | out_loss 15.235770225524902: 100%|████| 8/8 [00:00<00:00, 135.21it/s]\n",
      "Train 97 | out_loss 16.04568099975586: 100%|█████| 8/8 [00:00<00:00, 139.94it/s]\n",
      "Train 98 | out_loss 15.14168643951416: 100%|█████| 8/8 [00:00<00:00, 142.71it/s]\n",
      "Train 99 | out_loss 14.167525291442871: 100%|████| 8/8 [00:00<00:00, 142.65it/s]\n",
      "Train 100 | out_loss 14.891375541687012: 100%|███| 8/8 [00:00<00:00, 143.24it/s]\n",
      "Train 101 | out_loss 13.64305591583252: 100%|████| 8/8 [00:00<00:00, 134.98it/s]\n",
      "Train 102 | out_loss 13.581717491149902: 100%|███| 8/8 [00:00<00:00, 141.06it/s]\n",
      "Train 103 | out_loss 14.437579154968262: 100%|███| 8/8 [00:00<00:00, 136.85it/s]\n",
      "Train 104 | out_loss 14.262063980102539: 100%|███| 8/8 [00:00<00:00, 140.11it/s]\n",
      "Train 105 | out_loss 13.381948471069336: 100%|███| 8/8 [00:00<00:00, 140.48it/s]\n",
      "Train 106 | out_loss 13.573424339294434: 100%|███| 8/8 [00:00<00:00, 141.14it/s]\n",
      "Train 107 | out_loss 13.767051696777344: 100%|███| 8/8 [00:00<00:00, 141.13it/s]\n",
      "Train 108 | out_loss 13.240249633789062: 100%|███| 8/8 [00:00<00:00, 139.91it/s]\n",
      "Train 109 | out_loss 13.557878494262695: 100%|███| 8/8 [00:00<00:00, 142.39it/s]\n",
      "Train 110 | out_loss 13.313374519348145: 100%|███| 8/8 [00:00<00:00, 140.15it/s]\n",
      "Train 111 | out_loss 13.977981567382812: 100%|███| 8/8 [00:00<00:00, 142.67it/s]\n",
      "Train 112 | out_loss 13.362212181091309: 100%|███| 8/8 [00:00<00:00, 141.39it/s]\n",
      "Train 113 | out_loss 13.581700325012207: 100%|███| 8/8 [00:00<00:00, 126.87it/s]\n",
      "Train 114 | out_loss 13.319117546081543: 100%|███| 8/8 [00:00<00:00, 132.45it/s]\n",
      "Train 115 | out_loss 13.334484100341797: 100%|███| 8/8 [00:00<00:00, 137.51it/s]\n",
      "Train 116 | out_loss 13.703699111938477: 100%|███| 8/8 [00:00<00:00, 144.38it/s]\n",
      "Train 117 | out_loss 13.440730094909668: 100%|███| 8/8 [00:00<00:00, 141.68it/s]\n",
      "Train 118 | out_loss 13.554439544677734: 100%|███| 8/8 [00:00<00:00, 137.86it/s]\n",
      "Train 119 | out_loss 13.341651916503906: 100%|███| 8/8 [00:00<00:00, 141.20it/s]\n",
      "Train 120 | out_loss 13.408614158630371: 100%|███| 8/8 [00:00<00:00, 141.09it/s]\n",
      "Train 121 | out_loss 13.515607833862305: 100%|███| 8/8 [00:00<00:00, 140.94it/s]\n",
      "Train 122 | out_loss 13.308894157409668: 100%|███| 8/8 [00:00<00:00, 142.26it/s]\n",
      "Train 123 | out_loss 13.55782413482666: 100%|████| 8/8 [00:00<00:00, 137.98it/s]\n",
      "Train 124 | out_loss 13.539680480957031: 100%|███| 8/8 [00:00<00:00, 139.60it/s]\n",
      "Train 125 | out_loss 13.328981399536133: 100%|███| 8/8 [00:00<00:00, 123.82it/s]\n",
      "Train 126 | out_loss 13.319354057312012: 100%|███| 8/8 [00:00<00:00, 138.04it/s]\n",
      "Train 127 | out_loss 13.317709922790527: 100%|███| 8/8 [00:00<00:00, 130.51it/s]\n",
      "Train 128 | out_loss 13.45075798034668: 100%|████| 8/8 [00:00<00:00, 136.27it/s]\n",
      "Train 129 | out_loss 13.305445671081543: 100%|███| 8/8 [00:00<00:00, 140.49it/s]\n",
      "Train 130 | out_loss 14.51480484008789: 100%|████| 8/8 [00:00<00:00, 141.91it/s]\n",
      "Train 131 | out_loss 15.555513381958008: 100%|███| 8/8 [00:00<00:00, 137.53it/s]\n",
      "Train 132 | out_loss 13.888309478759766: 100%|███| 8/8 [00:00<00:00, 136.69it/s]\n",
      "Train 133 | out_loss 13.553634643554688: 100%|███| 8/8 [00:00<00:00, 121.52it/s]\n",
      "Train 134 | out_loss 13.358772277832031: 100%|███| 8/8 [00:00<00:00, 119.89it/s]\n",
      "Train 135 | out_loss 13.747733116149902: 100%|███| 8/8 [00:00<00:00, 141.49it/s]\n",
      "Train 136 | out_loss 13.660543441772461: 100%|███| 8/8 [00:00<00:00, 135.59it/s]\n",
      "Train 137 | out_loss 13.50416374206543: 100%|████| 8/8 [00:00<00:00, 126.62it/s]\n",
      "Train 138 | out_loss 13.362411499023438: 100%|███| 8/8 [00:00<00:00, 125.44it/s]\n",
      "Train 139 | out_loss 13.478286743164062: 100%|███| 8/8 [00:00<00:00, 137.83it/s]\n",
      "Train 140 | out_loss 13.382498741149902: 100%|███| 8/8 [00:00<00:00, 139.46it/s]\n",
      "Train 141 | out_loss 13.383720397949219: 100%|███| 8/8 [00:00<00:00, 128.80it/s]\n",
      "Train 142 | out_loss 13.534018516540527: 100%|███| 8/8 [00:00<00:00, 125.08it/s]\n",
      "Train 143 | out_loss 13.450292587280273: 100%|███| 8/8 [00:00<00:00, 110.29it/s]\n",
      "Train 144 | out_loss 13.402524948120117: 100%|███| 8/8 [00:00<00:00, 117.15it/s]\n",
      "Train 145 | out_loss 13.619290351867676: 100%|███| 8/8 [00:00<00:00, 135.92it/s]\n",
      "Train 146 | out_loss 13.384710311889648: 100%|███| 8/8 [00:00<00:00, 103.90it/s]\n",
      "Train 147 | out_loss 13.457825660705566: 100%|███| 8/8 [00:00<00:00, 131.76it/s]\n",
      "Train 148 | out_loss 13.535218238830566: 100%|███| 8/8 [00:00<00:00, 140.54it/s]\n",
      "Train 149 | out_loss 13.494865417480469: 100%|███| 8/8 [00:00<00:00, 133.16it/s]\n",
      "Train 150 | out_loss 13.427499771118164: 100%|███| 8/8 [00:00<00:00, 135.97it/s]\n",
      "Train 151 | out_loss 13.571310997009277: 100%|███| 8/8 [00:00<00:00, 138.13it/s]\n",
      "Train 152 | out_loss 13.580958366394043: 100%|███| 8/8 [00:00<00:00, 139.88it/s]\n",
      "Train 153 | out_loss 13.822845458984375: 100%|███| 8/8 [00:00<00:00, 138.98it/s]\n",
      "Train 154 | out_loss 13.49697494506836: 100%|████| 8/8 [00:00<00:00, 142.29it/s]\n",
      "Train 155 | out_loss 13.3717622756958: 100%|█████| 8/8 [00:00<00:00, 139.97it/s]\n",
      "Train 156 | out_loss 13.453938484191895: 100%|███| 8/8 [00:00<00:00, 142.08it/s]\n",
      "Train 157 | out_loss 13.330920219421387: 100%|███| 8/8 [00:00<00:00, 138.74it/s]\n",
      "Train 158 | out_loss 13.261504173278809: 100%|███| 8/8 [00:00<00:00, 138.45it/s]\n",
      "Train 159 | out_loss 13.549585342407227: 100%|███| 8/8 [00:00<00:00, 137.79it/s]\n",
      "Train 160 | out_loss 13.702012062072754: 100%|███| 8/8 [00:00<00:00, 139.57it/s]\n",
      "Train 161 | out_loss 13.281826972961426: 100%|███| 8/8 [00:00<00:00, 143.14it/s]\n",
      "Train 162 | out_loss 13.57661247253418: 100%|████| 8/8 [00:00<00:00, 134.99it/s]\n",
      "Train 163 | out_loss 14.399229049682617: 100%|███| 8/8 [00:00<00:00, 131.25it/s]\n",
      "Train 164 | out_loss 13.554386138916016: 100%|███| 8/8 [00:00<00:00, 127.16it/s]\n",
      "Train 165 | out_loss 13.422465324401855: 100%|███| 8/8 [00:00<00:00, 143.26it/s]\n",
      "Train 166 | out_loss 13.511754035949707: 100%|███| 8/8 [00:00<00:00, 136.91it/s]\n",
      "Train 167 | out_loss 13.311661720275879: 100%|███| 8/8 [00:00<00:00, 144.15it/s]\n",
      "Train 168 | out_loss 13.288966178894043: 100%|███| 8/8 [00:00<00:00, 143.14it/s]\n",
      "Train 169 | out_loss 13.26891040802002: 100%|████| 8/8 [00:00<00:00, 139.66it/s]\n",
      "Train 170 | out_loss 13.314298629760742: 100%|███| 8/8 [00:00<00:00, 139.71it/s]\n",
      "Train 171 | out_loss 13.39838695526123: 100%|████| 8/8 [00:00<00:00, 140.70it/s]\n",
      "Train 172 | out_loss 13.286852836608887: 100%|███| 8/8 [00:00<00:00, 140.25it/s]\n",
      "Train 173 | out_loss 13.278692245483398: 100%|███| 8/8 [00:00<00:00, 138.09it/s]\n",
      "Train 174 | out_loss 13.334710121154785: 100%|███| 8/8 [00:00<00:00, 142.08it/s]\n",
      "Train 175 | out_loss 13.361228942871094: 100%|███| 8/8 [00:00<00:00, 134.34it/s]\n",
      "Train 176 | out_loss 13.744854927062988: 100%|███| 8/8 [00:00<00:00, 132.08it/s]\n",
      "Train 177 | out_loss 13.717306137084961: 100%|███| 8/8 [00:00<00:00, 135.63it/s]\n",
      "Train 178 | out_loss 13.287673950195312: 100%|███| 8/8 [00:00<00:00, 143.00it/s]\n",
      "Train 179 | out_loss 13.555365562438965: 100%|███| 8/8 [00:00<00:00, 133.56it/s]\n",
      "Train 180 | out_loss 13.226866722106934: 100%|███| 8/8 [00:00<00:00, 136.13it/s]\n",
      "Train 181 | out_loss 13.254950523376465: 100%|███| 8/8 [00:00<00:00, 138.83it/s]\n",
      "Train 182 | out_loss 13.312151908874512: 100%|███| 8/8 [00:00<00:00, 132.23it/s]\n",
      "Train 183 | out_loss 13.497893333435059: 100%|███| 8/8 [00:00<00:00, 137.42it/s]\n",
      "Train 184 | out_loss 13.46925163269043: 100%|████| 8/8 [00:00<00:00, 130.78it/s]\n",
      "Train 185 | out_loss 13.3413724899292: 100%|█████| 8/8 [00:00<00:00, 131.40it/s]\n",
      "Train 186 | out_loss 13.28160572052002: 100%|████| 8/8 [00:00<00:00, 136.52it/s]\n",
      "Train 187 | out_loss 13.281599998474121: 100%|███| 8/8 [00:00<00:00, 134.35it/s]\n",
      "Train 188 | out_loss 13.422820091247559: 100%|███| 8/8 [00:00<00:00, 137.30it/s]\n",
      "Train 189 | out_loss 13.46017837524414: 100%|████| 8/8 [00:00<00:00, 139.00it/s]\n",
      "Train 190 | out_loss 13.37763500213623: 100%|████| 8/8 [00:00<00:00, 138.17it/s]\n",
      "Train 191 | out_loss 13.28973388671875: 100%|████| 8/8 [00:00<00:00, 138.79it/s]\n",
      "Train 192 | out_loss 13.287139892578125: 100%|███| 8/8 [00:00<00:00, 132.15it/s]\n",
      "Train 193 | out_loss 13.271489143371582: 100%|███| 8/8 [00:00<00:00, 132.53it/s]\n",
      "Train 194 | out_loss 13.288368225097656: 100%|███| 8/8 [00:00<00:00, 137.21it/s]\n",
      "Train 195 | out_loss 13.474709510803223: 100%|███| 8/8 [00:00<00:00, 134.95it/s]\n",
      "Train 196 | out_loss 13.395196914672852: 100%|███| 8/8 [00:00<00:00, 136.72it/s]\n",
      "Train 197 | out_loss 13.326004981994629: 100%|███| 8/8 [00:00<00:00, 136.39it/s]\n",
      "Train 198 | out_loss 13.275659561157227: 100%|███| 8/8 [00:00<00:00, 124.25it/s]\n",
      "Train 199 | out_loss 13.273398399353027: 100%|███| 8/8 [00:00<00:00, 142.89it/s]\n",
      "Train 200 | out_loss 13.296197891235352: 100%|███| 8/8 [00:00<00:00, 138.73it/s]\n",
      "Train 201 | out_loss 13.2968111038208: 100%|█████| 8/8 [00:00<00:00, 138.30it/s]\n",
      "Train 202 | out_loss 13.293231964111328: 100%|███| 8/8 [00:00<00:00, 133.22it/s]\n",
      "Train 203 | out_loss 13.262651443481445: 100%|███| 8/8 [00:00<00:00, 142.62it/s]\n",
      "Train 204 | out_loss 13.281623840332031: 100%|███| 8/8 [00:00<00:00, 143.75it/s]\n",
      "Train 205 | out_loss 13.201168060302734: 100%|███| 8/8 [00:00<00:00, 139.10it/s]\n",
      "Train 206 | out_loss 13.337878227233887: 100%|███| 8/8 [00:00<00:00, 139.37it/s]\n",
      "Train 207 | out_loss 13.301521301269531: 100%|███| 8/8 [00:00<00:00, 138.02it/s]\n",
      "Train 208 | out_loss 13.3366060256958: 100%|█████| 8/8 [00:00<00:00, 135.48it/s]\n",
      "Train 209 | out_loss 13.2964506149292: 100%|█████| 8/8 [00:00<00:00, 136.91it/s]\n",
      "Train 210 | out_loss 13.287163734436035: 100%|███| 8/8 [00:00<00:00, 137.98it/s]\n",
      "Train 211 | out_loss 13.506397247314453: 100%|███| 8/8 [00:00<00:00, 124.33it/s]\n",
      "Train 212 | out_loss 13.576407432556152: 100%|███| 8/8 [00:00<00:00, 138.14it/s]\n",
      "Train 213 | out_loss 13.234227180480957: 100%|███| 8/8 [00:00<00:00, 141.68it/s]\n",
      "Train 214 | out_loss 13.695852279663086: 100%|███| 8/8 [00:00<00:00, 137.56it/s]\n",
      "Train 215 | out_loss 13.435694694519043: 100%|███| 8/8 [00:00<00:00, 138.40it/s]\n",
      "Train 216 | out_loss 13.38645076751709: 100%|████| 8/8 [00:00<00:00, 135.32it/s]\n",
      "Train 217 | out_loss 13.3576078414917: 100%|█████| 8/8 [00:00<00:00, 128.32it/s]\n",
      "Train 218 | out_loss 13.292031288146973: 100%|███| 8/8 [00:00<00:00, 132.12it/s]\n",
      "Train 219 | out_loss 13.312868118286133: 100%|███| 8/8 [00:00<00:00, 129.83it/s]\n",
      "Train 220 | out_loss 13.304903984069824: 100%|███| 8/8 [00:00<00:00, 139.63it/s]\n",
      "Train 221 | out_loss 13.473155975341797: 100%|███| 8/8 [00:00<00:00, 134.55it/s]\n",
      "Train 222 | out_loss 13.26324462890625: 100%|████| 8/8 [00:00<00:00, 140.27it/s]\n",
      "Train 223 | out_loss 13.342207908630371: 100%|███| 8/8 [00:00<00:00, 134.09it/s]\n",
      "Train 224 | out_loss 13.280587196350098: 100%|███| 8/8 [00:00<00:00, 141.47it/s]\n",
      "Train 225 | out_loss 13.309814453125: 100%|██████| 8/8 [00:00<00:00, 141.57it/s]\n",
      "Train 226 | out_loss 13.287473678588867: 100%|███| 8/8 [00:00<00:00, 135.95it/s]\n",
      "Train 227 | out_loss 13.310619354248047: 100%|███| 8/8 [00:00<00:00, 129.62it/s]\n",
      "Train 228 | out_loss 13.349505424499512: 100%|███| 8/8 [00:00<00:00, 142.97it/s]\n",
      "Train 229 | out_loss 13.58641242980957: 100%|████| 8/8 [00:00<00:00, 138.92it/s]\n",
      "Train 230 | out_loss 13.357131958007812: 100%|███| 8/8 [00:00<00:00, 137.52it/s]\n",
      "Train 231 | out_loss 13.538372039794922: 100%|███| 8/8 [00:00<00:00, 145.71it/s]\n",
      "Train 232 | out_loss 13.088005065917969: 100%|███| 8/8 [00:00<00:00, 140.96it/s]\n",
      "Train 233 | out_loss 13.54044246673584: 100%|████| 8/8 [00:00<00:00, 138.78it/s]\n",
      "Train 234 | out_loss 13.152315139770508: 100%|███| 8/8 [00:00<00:00, 138.47it/s]\n",
      "Train 235 | out_loss 13.170928955078125: 100%|███| 8/8 [00:00<00:00, 135.06it/s]\n",
      "Train 236 | out_loss 13.47690486907959: 100%|████| 8/8 [00:00<00:00, 127.13it/s]\n",
      "Train 237 | out_loss 13.349143028259277: 100%|███| 8/8 [00:00<00:00, 137.66it/s]\n",
      "Train 238 | out_loss 13.105461120605469: 100%|███| 8/8 [00:00<00:00, 139.03it/s]\n",
      "Train 239 | out_loss 13.117571830749512: 100%|███| 8/8 [00:00<00:00, 116.09it/s]\n",
      "Train 240 | out_loss 13.012896537780762: 100%|███| 8/8 [00:00<00:00, 134.18it/s]\n",
      "Train 241 | out_loss 12.998334884643555: 100%|███| 8/8 [00:00<00:00, 136.95it/s]\n",
      "Train 242 | out_loss 12.932759284973145: 100%|███| 8/8 [00:00<00:00, 134.57it/s]\n",
      "Train 243 | out_loss 12.826789855957031: 100%|███| 8/8 [00:00<00:00, 133.11it/s]\n",
      "Train 244 | out_loss 12.935752868652344: 100%|███| 8/8 [00:00<00:00, 140.13it/s]\n",
      "Train 245 | out_loss 12.622032165527344: 100%|███| 8/8 [00:00<00:00, 123.90it/s]\n",
      "Train 246 | out_loss 13.084872245788574: 100%|███| 8/8 [00:00<00:00, 136.23it/s]\n",
      "Train 247 | out_loss 13.095712661743164: 100%|███| 8/8 [00:00<00:00, 134.11it/s]\n",
      "Train 248 | out_loss 12.675268173217773: 100%|███| 8/8 [00:00<00:00, 131.23it/s]\n",
      "Train 249 | out_loss 12.758612632751465: 100%|███| 8/8 [00:00<00:00, 132.03it/s]\n",
      "Train 250 | out_loss 12.77711296081543: 100%|████| 8/8 [00:00<00:00, 112.10it/s]\n",
      "Train 251 | out_loss 12.290430068969727: 100%|███| 8/8 [00:00<00:00, 130.51it/s]\n",
      "Train 252 | out_loss 13.813056945800781: 100%|███| 8/8 [00:00<00:00, 142.20it/s]\n",
      "Train 253 | out_loss 13.232375144958496: 100%|███| 8/8 [00:00<00:00, 131.42it/s]\n",
      "Train 254 | out_loss 13.526589393615723: 100%|███| 8/8 [00:00<00:00, 143.44it/s]\n",
      "Train 255 | out_loss 13.609457015991211: 100%|███| 8/8 [00:00<00:00, 141.06it/s]\n",
      "Train 256 | out_loss 13.204079627990723: 100%|███| 8/8 [00:00<00:00, 134.92it/s]\n",
      "Train 257 | out_loss 13.213830947875977: 100%|███| 8/8 [00:00<00:00, 138.99it/s]\n",
      "Train 258 | out_loss 12.837839126586914: 100%|███| 8/8 [00:00<00:00, 139.71it/s]\n",
      "Train 259 | out_loss 12.295673370361328: 100%|███| 8/8 [00:00<00:00, 127.41it/s]\n",
      "Train 260 | out_loss 12.070791244506836: 100%|███| 8/8 [00:00<00:00, 137.93it/s]\n",
      "Train 261 | out_loss 12.040513038635254: 100%|███| 8/8 [00:00<00:00, 134.55it/s]\n",
      "Train 262 | out_loss 13.41910171508789: 100%|████| 8/8 [00:00<00:00, 135.70it/s]\n",
      "Train 263 | out_loss 13.213335037231445: 100%|███| 8/8 [00:00<00:00, 114.49it/s]\n",
      "Train 264 | out_loss 13.408294677734375: 100%|███| 8/8 [00:00<00:00, 134.63it/s]\n",
      "Train 265 | out_loss 13.088577270507812: 100%|███| 8/8 [00:00<00:00, 141.58it/s]\n",
      "Train 266 | out_loss 13.31777286529541: 100%|████| 8/8 [00:00<00:00, 136.87it/s]\n",
      "Train 267 | out_loss 12.792156219482422: 100%|███| 8/8 [00:00<00:00, 135.19it/s]\n",
      "Train 268 | out_loss 12.789814949035645: 100%|███| 8/8 [00:00<00:00, 135.61it/s]\n",
      "Train 269 | out_loss 13.380558967590332: 100%|███| 8/8 [00:00<00:00, 136.03it/s]\n",
      "Train 270 | out_loss 13.143428802490234: 100%|███| 8/8 [00:00<00:00, 127.24it/s]\n",
      "Train 271 | out_loss 13.629558563232422: 100%|███| 8/8 [00:00<00:00, 134.86it/s]\n",
      "Train 272 | out_loss 13.817822456359863: 100%|███| 8/8 [00:00<00:00, 127.89it/s]\n",
      "Train 273 | out_loss 13.703483581542969: 100%|███| 8/8 [00:00<00:00, 106.24it/s]\n",
      "Train 274 | out_loss 13.438074111938477: 100%|███| 8/8 [00:00<00:00, 134.01it/s]\n",
      "Train 275 | out_loss 13.606023788452148: 100%|███| 8/8 [00:00<00:00, 138.61it/s]\n",
      "Train 276 | out_loss 13.365409851074219: 100%|███| 8/8 [00:00<00:00, 134.00it/s]\n",
      "Train 277 | out_loss 13.336692810058594: 100%|███| 8/8 [00:00<00:00, 118.86it/s]\n",
      "Train 278 | out_loss 13.348966598510742: 100%|███| 8/8 [00:00<00:00, 143.83it/s]\n",
      "Train 279 | out_loss 13.37215518951416: 100%|████| 8/8 [00:00<00:00, 136.53it/s]\n",
      "Train 280 | out_loss 13.336675643920898: 100%|███| 8/8 [00:00<00:00, 134.74it/s]\n",
      "Train 281 | out_loss 13.334893226623535: 100%|███| 8/8 [00:00<00:00, 136.30it/s]\n",
      "Train 282 | out_loss 13.379959106445312: 100%|███| 8/8 [00:00<00:00, 136.45it/s]\n",
      "Train 283 | out_loss 13.316106796264648: 100%|███| 8/8 [00:00<00:00, 135.44it/s]\n",
      "Train 284 | out_loss 13.315824508666992: 100%|███| 8/8 [00:00<00:00, 135.54it/s]\n",
      "Train 285 | out_loss 13.33688735961914: 100%|████| 8/8 [00:00<00:00, 109.93it/s]\n",
      "Train 286 | out_loss 13.347407341003418: 100%|███| 8/8 [00:00<00:00, 134.79it/s]\n",
      "Train 287 | out_loss 13.349533081054688: 100%|███| 8/8 [00:00<00:00, 130.44it/s]\n",
      "Train 288 | out_loss 13.31181812286377: 100%|████| 8/8 [00:00<00:00, 138.05it/s]\n",
      "Train 289 | out_loss 13.363786697387695: 100%|███| 8/8 [00:00<00:00, 138.04it/s]\n",
      "Train 290 | out_loss 13.32305908203125: 100%|████| 8/8 [00:00<00:00, 137.41it/s]\n",
      "Train 291 | out_loss 13.357917785644531: 100%|███| 8/8 [00:00<00:00, 128.42it/s]\n",
      "Train 292 | out_loss 13.373112678527832: 100%|███| 8/8 [00:00<00:00, 127.49it/s]\n",
      "Train 293 | out_loss 13.327301979064941: 100%|███| 8/8 [00:00<00:00, 133.91it/s]\n",
      "Train 294 | out_loss 13.372318267822266: 100%|███| 8/8 [00:00<00:00, 124.29it/s]\n",
      "Train 295 | out_loss 13.323590278625488: 100%|███| 8/8 [00:00<00:00, 122.16it/s]\n",
      "Train 296 | out_loss 13.365402221679688: 100%|███| 8/8 [00:00<00:00, 138.66it/s]\n",
      "Train 297 | out_loss 13.334756851196289: 100%|███| 8/8 [00:00<00:00, 129.13it/s]\n",
      "Train 298 | out_loss 13.319326400756836: 100%|███| 8/8 [00:00<00:00, 131.36it/s]\n",
      "Train 299 | out_loss 13.44046401977539: 100%|████| 8/8 [00:00<00:00, 133.25it/s]\n",
      "Train 300 | out_loss 13.391660690307617: 100%|███| 8/8 [00:00<00:00, 141.06it/s]\n",
      "Train 301 | out_loss 13.387130737304688: 100%|███| 8/8 [00:00<00:00, 141.46it/s]\n",
      "Train 302 | out_loss 13.364689826965332: 100%|███| 8/8 [00:00<00:00, 129.70it/s]\n",
      "Train 303 | out_loss 13.337206840515137: 100%|███| 8/8 [00:00<00:00, 120.68it/s]\n",
      "Train 304 | out_loss 13.338586807250977: 100%|███| 8/8 [00:00<00:00, 134.86it/s]\n",
      "Train 305 | out_loss 13.327859878540039: 100%|███| 8/8 [00:00<00:00, 135.58it/s]\n",
      "Train 306 | out_loss 13.339665412902832: 100%|███| 8/8 [00:00<00:00, 139.94it/s]\n",
      "Train 307 | out_loss 13.331019401550293: 100%|███| 8/8 [00:00<00:00, 140.25it/s]\n",
      "Train 308 | out_loss 13.32815170288086: 100%|████| 8/8 [00:00<00:00, 133.26it/s]\n",
      "Train 309 | out_loss 13.324292182922363: 100%|███| 8/8 [00:00<00:00, 139.55it/s]\n",
      "Train 310 | out_loss 13.326178550720215: 100%|███| 8/8 [00:00<00:00, 135.80it/s]\n",
      "Train 311 | out_loss 13.344117164611816: 100%|███| 8/8 [00:00<00:00, 142.28it/s]\n",
      "Train 312 | out_loss 13.331873893737793: 100%|███| 8/8 [00:00<00:00, 115.56it/s]\n",
      "Train 313 | out_loss 13.334005355834961: 100%|███| 8/8 [00:00<00:00, 142.46it/s]\n",
      "Train 314 | out_loss 13.336348533630371: 100%|███| 8/8 [00:00<00:00, 129.86it/s]\n",
      "Train 315 | out_loss 13.328676223754883: 100%|███| 8/8 [00:00<00:00, 130.73it/s]\n",
      "Train 316 | out_loss 13.334290504455566: 100%|███| 8/8 [00:00<00:00, 132.16it/s]\n",
      "Train 317 | out_loss 13.331809997558594: 100%|███| 8/8 [00:00<00:00, 130.05it/s]\n",
      "Train 318 | out_loss 13.311258316040039: 100%|███| 8/8 [00:00<00:00, 131.52it/s]\n",
      "Train 319 | out_loss 13.359095573425293: 100%|███| 8/8 [00:00<00:00, 135.33it/s]\n",
      "Train 320 | out_loss 13.321170806884766: 100%|███| 8/8 [00:00<00:00, 137.22it/s]\n",
      "Train 321 | out_loss 13.319835662841797: 100%|███| 8/8 [00:00<00:00, 137.85it/s]\n",
      "Train 322 | out_loss 13.328028678894043: 100%|███| 8/8 [00:00<00:00, 136.14it/s]\n",
      "Train 323 | out_loss 13.328190803527832: 100%|███| 8/8 [00:00<00:00, 135.92it/s]\n",
      "Train 324 | out_loss 13.334365844726562: 100%|███| 8/8 [00:00<00:00, 134.66it/s]\n",
      "Train 325 | out_loss 13.341185569763184: 100%|███| 8/8 [00:00<00:00, 137.02it/s]\n",
      "Train 326 | out_loss 13.34595012664795: 100%|████| 8/8 [00:00<00:00, 132.14it/s]\n",
      "Train 327 | out_loss 13.347140312194824: 100%|███| 8/8 [00:00<00:00, 139.96it/s]\n",
      "Train 328 | out_loss 13.348512649536133: 100%|███| 8/8 [00:00<00:00, 138.01it/s]\n",
      "Train 329 | out_loss 13.302996635437012: 100%|███| 8/8 [00:00<00:00, 126.84it/s]\n",
      "Train 330 | out_loss 13.328071594238281: 100%|███| 8/8 [00:00<00:00, 139.66it/s]\n",
      "Train 331 | out_loss 13.31040096282959: 100%|████| 8/8 [00:00<00:00, 138.37it/s]\n",
      "Train 332 | out_loss 13.311392784118652: 100%|███| 8/8 [00:00<00:00, 123.69it/s]\n",
      "Train 333 | out_loss 13.310887336730957: 100%|███| 8/8 [00:00<00:00, 136.74it/s]\n",
      "Train 334 | out_loss 13.318449974060059: 100%|███| 8/8 [00:00<00:00, 129.36it/s]\n",
      "Train 335 | out_loss 13.320887565612793: 100%|███| 8/8 [00:00<00:00, 127.74it/s]\n",
      "Train 336 | out_loss 13.317688941955566: 100%|███| 8/8 [00:00<00:00, 135.52it/s]\n",
      "Train 337 | out_loss 13.32470703125: 100%|███████| 8/8 [00:00<00:00, 119.90it/s]\n",
      "Train 338 | out_loss 13.331094741821289: 100%|███| 8/8 [00:00<00:00, 132.67it/s]\n",
      "Train 339 | out_loss 13.323659896850586: 100%|████| 8/8 [00:00<00:00, 91.42it/s]\n",
      "Train 340 | out_loss 13.327298164367676: 100%|███| 8/8 [00:00<00:00, 136.82it/s]\n",
      "Train 341 | out_loss 13.348797798156738: 100%|███| 8/8 [00:00<00:00, 141.77it/s]\n",
      "Train 342 | out_loss 13.32204532623291: 100%|████| 8/8 [00:00<00:00, 137.33it/s]\n",
      "Train 343 | out_loss 13.329346656799316: 100%|███| 8/8 [00:00<00:00, 132.44it/s]\n",
      "Train 344 | out_loss 13.318580627441406: 100%|███| 8/8 [00:00<00:00, 117.97it/s]\n",
      "Train 345 | out_loss 13.344916343688965: 100%|███| 8/8 [00:00<00:00, 128.46it/s]\n",
      "Train 346 | out_loss 13.321806907653809: 100%|███| 8/8 [00:00<00:00, 134.88it/s]\n",
      "Train 347 | out_loss 13.397198677062988: 100%|███| 8/8 [00:00<00:00, 130.64it/s]\n",
      "Train 348 | out_loss 13.30294418334961: 100%|████| 8/8 [00:00<00:00, 111.34it/s]\n",
      "Train 349 | out_loss 13.363465309143066: 100%|███| 8/8 [00:00<00:00, 131.16it/s]\n",
      "Train 350 | out_loss 13.342143058776855: 100%|███| 8/8 [00:00<00:00, 142.30it/s]\n",
      "Train 351 | out_loss 13.328758239746094: 100%|███| 8/8 [00:00<00:00, 136.26it/s]\n",
      "Train 352 | out_loss 13.352485656738281: 100%|███| 8/8 [00:00<00:00, 131.42it/s]\n",
      "Train 353 | out_loss 13.385632514953613: 100%|███| 8/8 [00:00<00:00, 124.34it/s]\n",
      "Train 354 | out_loss 13.309734344482422: 100%|███| 8/8 [00:00<00:00, 136.79it/s]\n",
      "Train 355 | out_loss 13.362323760986328: 100%|███| 8/8 [00:00<00:00, 142.58it/s]\n",
      "Train 356 | out_loss 13.31920051574707: 100%|████| 8/8 [00:00<00:00, 126.41it/s]\n",
      "Train 357 | out_loss 13.325555801391602: 100%|███| 8/8 [00:00<00:00, 132.94it/s]\n",
      "Train 358 | out_loss 13.321040153503418: 100%|███| 8/8 [00:00<00:00, 138.97it/s]\n",
      "Train 359 | out_loss 13.329041481018066: 100%|███| 8/8 [00:00<00:00, 139.83it/s]\n",
      "Train 360 | out_loss 13.318073272705078: 100%|███| 8/8 [00:00<00:00, 141.88it/s]\n",
      "Train 361 | out_loss 13.317286491394043: 100%|███| 8/8 [00:00<00:00, 140.47it/s]\n",
      "Train 362 | out_loss 13.326276779174805: 100%|███| 8/8 [00:00<00:00, 140.94it/s]\n",
      "Train 363 | out_loss 13.349913597106934: 100%|███| 8/8 [00:00<00:00, 139.86it/s]\n",
      "Train 364 | out_loss 13.31743049621582: 100%|████| 8/8 [00:00<00:00, 139.08it/s]\n",
      "Train 365 | out_loss 13.320466995239258: 100%|███| 8/8 [00:00<00:00, 137.11it/s]\n",
      "Train 366 | out_loss 13.317832946777344: 100%|███| 8/8 [00:00<00:00, 138.15it/s]\n",
      "Train 367 | out_loss 13.318219184875488: 100%|███| 8/8 [00:00<00:00, 139.88it/s]\n",
      "Train 368 | out_loss 13.339831352233887: 100%|███| 8/8 [00:00<00:00, 143.00it/s]\n",
      "Train 369 | out_loss 13.35242748260498: 100%|████| 8/8 [00:00<00:00, 138.91it/s]\n",
      "Train 370 | out_loss 13.324417114257812: 100%|███| 8/8 [00:00<00:00, 139.62it/s]\n",
      "Train 371 | out_loss 13.315934181213379: 100%|███| 8/8 [00:00<00:00, 141.05it/s]\n",
      "Train 372 | out_loss 13.319195747375488: 100%|███| 8/8 [00:00<00:00, 109.32it/s]\n",
      "Train 373 | out_loss 13.321277618408203: 100%|███| 8/8 [00:00<00:00, 125.88it/s]\n",
      "Train 374 | out_loss 13.360968589782715: 100%|███| 8/8 [00:00<00:00, 108.76it/s]\n",
      "Train 375 | out_loss 13.340485572814941: 100%|███| 8/8 [00:00<00:00, 135.76it/s]\n",
      "Train 376 | out_loss 13.303216934204102: 100%|███| 8/8 [00:00<00:00, 140.27it/s]\n",
      "Train 377 | out_loss 13.327797889709473: 100%|███| 8/8 [00:00<00:00, 140.21it/s]\n",
      "Train 378 | out_loss 13.324337005615234: 100%|███| 8/8 [00:00<00:00, 130.23it/s]\n",
      "Train 379 | out_loss 13.309537887573242: 100%|███| 8/8 [00:00<00:00, 138.01it/s]\n",
      "Train 380 | out_loss 13.32197093963623: 100%|████| 8/8 [00:00<00:00, 136.98it/s]\n",
      "Train 381 | out_loss 13.34743881225586: 100%|████| 8/8 [00:00<00:00, 126.00it/s]\n",
      "Train 382 | out_loss 13.354205131530762: 100%|███| 8/8 [00:00<00:00, 139.73it/s]\n",
      "Train 383 | out_loss 13.331714630126953: 100%|███| 8/8 [00:00<00:00, 136.32it/s]\n",
      "Train 384 | out_loss 13.318140029907227: 100%|███| 8/8 [00:00<00:00, 132.50it/s]\n",
      "Train 385 | out_loss 13.366070747375488: 100%|███| 8/8 [00:00<00:00, 140.37it/s]\n",
      "Train 386 | out_loss 13.325030326843262: 100%|███| 8/8 [00:00<00:00, 142.17it/s]\n",
      "Train 387 | out_loss 13.307208061218262: 100%|███| 8/8 [00:00<00:00, 115.86it/s]\n",
      "Train 388 | out_loss 13.338691711425781: 100%|███| 8/8 [00:00<00:00, 113.99it/s]\n",
      "Train 389 | out_loss 13.31863784790039: 100%|████| 8/8 [00:00<00:00, 141.27it/s]\n",
      "Train 390 | out_loss 13.318608283996582: 100%|███| 8/8 [00:00<00:00, 139.51it/s]\n",
      "Train 391 | out_loss 13.361098289489746: 100%|███| 8/8 [00:00<00:00, 139.23it/s]\n",
      "Train 392 | out_loss 13.343395233154297: 100%|███| 8/8 [00:00<00:00, 136.31it/s]\n",
      "Train 393 | out_loss 13.332883834838867: 100%|███| 8/8 [00:00<00:00, 138.81it/s]\n",
      "Train 394 | out_loss 13.316913604736328: 100%|███| 8/8 [00:00<00:00, 137.92it/s]\n",
      "Train 395 | out_loss 13.3297700881958: 100%|█████| 8/8 [00:00<00:00, 141.13it/s]\n",
      "Train 396 | out_loss 13.331961631774902: 100%|███| 8/8 [00:00<00:00, 137.25it/s]\n",
      "Train 397 | out_loss 13.329257011413574: 100%|███| 8/8 [00:00<00:00, 139.55it/s]\n",
      "Train 398 | out_loss 13.30556583404541: 100%|████| 8/8 [00:00<00:00, 139.33it/s]\n",
      "Train 399 | out_loss 13.357919692993164: 100%|███| 8/8 [00:00<00:00, 140.57it/s]\n",
      "Train 400 | out_loss 13.32138729095459: 100%|████| 8/8 [00:00<00:00, 139.29it/s]\n",
      "Train 401 | out_loss 13.282187461853027: 100%|███| 8/8 [00:00<00:00, 126.07it/s]\n",
      "Train 402 | out_loss 13.287304878234863: 100%|███| 8/8 [00:00<00:00, 138.91it/s]\n",
      "Train 403 | out_loss 13.328293800354004: 100%|███| 8/8 [00:00<00:00, 141.72it/s]\n",
      "Train 404 | out_loss 13.315577507019043: 100%|███| 8/8 [00:00<00:00, 138.59it/s]\n",
      "Train 405 | out_loss 13.345163345336914: 100%|███| 8/8 [00:00<00:00, 134.92it/s]\n",
      "Train 406 | out_loss 13.326131820678711: 100%|███| 8/8 [00:00<00:00, 138.93it/s]\n",
      "Train 407 | out_loss 13.313464164733887: 100%|███| 8/8 [00:00<00:00, 142.02it/s]\n",
      "Train 408 | out_loss 13.317246437072754: 100%|███| 8/8 [00:00<00:00, 138.88it/s]\n",
      "Train 409 | out_loss 13.307965278625488: 100%|███| 8/8 [00:00<00:00, 121.97it/s]\n",
      "Train 410 | out_loss 13.336771011352539: 100%|███| 8/8 [00:00<00:00, 129.93it/s]\n",
      "Train 411 | out_loss 13.319717407226562: 100%|███| 8/8 [00:00<00:00, 139.78it/s]\n",
      "Train 412 | out_loss 13.309703826904297: 100%|███| 8/8 [00:00<00:00, 137.10it/s]\n",
      "Train 413 | out_loss 13.37313175201416: 100%|████| 8/8 [00:00<00:00, 141.04it/s]\n",
      "Train 414 | out_loss 13.317994117736816: 100%|███| 8/8 [00:00<00:00, 139.14it/s]\n",
      "Train 415 | out_loss 13.34106731414795: 100%|████| 8/8 [00:00<00:00, 140.37it/s]\n",
      "Train 416 | out_loss 13.352062225341797: 100%|███| 8/8 [00:00<00:00, 131.45it/s]\n",
      "Train 417 | out_loss 13.314026832580566: 100%|███| 8/8 [00:00<00:00, 130.33it/s]\n",
      "Train 418 | out_loss 13.338964462280273: 100%|███| 8/8 [00:00<00:00, 138.45it/s]\n",
      "Train 419 | out_loss 13.324234008789062: 100%|███| 8/8 [00:00<00:00, 134.74it/s]\n",
      "Train 420 | out_loss 13.32200813293457: 100%|████| 8/8 [00:00<00:00, 139.32it/s]\n",
      "Train 421 | out_loss 13.334149360656738: 100%|███| 8/8 [00:00<00:00, 131.23it/s]\n",
      "Train 422 | out_loss 13.30892276763916: 100%|████| 8/8 [00:00<00:00, 139.94it/s]\n",
      "Train 423 | out_loss 13.32960033416748: 100%|████| 8/8 [00:00<00:00, 128.97it/s]\n",
      "Train 424 | out_loss 13.347094535827637: 100%|███| 8/8 [00:00<00:00, 138.08it/s]\n",
      "Train 425 | out_loss 13.358054161071777: 100%|███| 8/8 [00:00<00:00, 141.74it/s]\n",
      "Train 426 | out_loss 13.329545021057129: 100%|███| 8/8 [00:00<00:00, 138.13it/s]\n",
      "Train 427 | out_loss 13.326314926147461: 100%|███| 8/8 [00:00<00:00, 140.42it/s]\n",
      "Train 428 | out_loss 13.322839736938477: 100%|███| 8/8 [00:00<00:00, 133.45it/s]\n",
      "Train 429 | out_loss 13.393669128417969: 100%|███| 8/8 [00:00<00:00, 131.17it/s]\n",
      "Train 430 | out_loss 13.323531150817871: 100%|███| 8/8 [00:00<00:00, 131.92it/s]\n",
      "Train 431 | out_loss 13.408939361572266: 100%|███| 8/8 [00:00<00:00, 122.98it/s]\n",
      "Train 432 | out_loss 13.351078033447266: 100%|███| 8/8 [00:00<00:00, 141.91it/s]\n",
      "Train 433 | out_loss 13.331992149353027: 100%|███| 8/8 [00:00<00:00, 127.92it/s]\n",
      "Train 434 | out_loss 13.33892822265625: 100%|████| 8/8 [00:00<00:00, 137.29it/s]\n",
      "Train 435 | out_loss 13.44082260131836: 100%|████| 8/8 [00:00<00:00, 139.16it/s]\n",
      "Train 436 | out_loss 13.358443260192871: 100%|███| 8/8 [00:00<00:00, 135.30it/s]\n",
      "Train 437 | out_loss 13.316728591918945: 100%|███| 8/8 [00:00<00:00, 140.03it/s]\n",
      "Train 438 | out_loss 13.316803932189941: 100%|███| 8/8 [00:00<00:00, 132.67it/s]\n",
      "Train 439 | out_loss 13.47142505645752: 100%|████| 8/8 [00:00<00:00, 136.23it/s]\n",
      "Train 440 | out_loss 13.329832077026367: 100%|███| 8/8 [00:00<00:00, 139.39it/s]\n",
      "Train 441 | out_loss 13.316139221191406: 100%|███| 8/8 [00:00<00:00, 138.73it/s]\n",
      "Train 442 | out_loss 13.363374710083008: 100%|███| 8/8 [00:00<00:00, 139.28it/s]\n",
      "Train 443 | out_loss 13.30774211883545: 100%|████| 8/8 [00:00<00:00, 139.56it/s]\n",
      "Train 444 | out_loss 13.325387954711914: 100%|███| 8/8 [00:00<00:00, 123.49it/s]\n",
      "Train 445 | out_loss 13.318537712097168: 100%|███| 8/8 [00:00<00:00, 117.13it/s]\n",
      "Train 446 | out_loss 13.30497932434082: 100%|████| 8/8 [00:00<00:00, 132.85it/s]\n",
      "Train 447 | out_loss 13.355223655700684: 100%|███| 8/8 [00:00<00:00, 135.46it/s]\n",
      "Train 448 | out_loss 13.309774398803711: 100%|███| 8/8 [00:00<00:00, 129.76it/s]\n",
      "Train 449 | out_loss 13.356325149536133: 100%|███| 8/8 [00:00<00:00, 136.76it/s]\n",
      "Train 450 | out_loss 13.375758171081543: 100%|███| 8/8 [00:00<00:00, 135.30it/s]\n",
      "Train 451 | out_loss 13.309938430786133: 100%|███| 8/8 [00:00<00:00, 137.91it/s]\n",
      "Train 452 | out_loss 13.406753540039062: 100%|███| 8/8 [00:00<00:00, 139.17it/s]\n",
      "Train 453 | out_loss 13.424734115600586: 100%|███| 8/8 [00:00<00:00, 135.97it/s]\n",
      "Train 454 | out_loss 13.350530624389648: 100%|███| 8/8 [00:00<00:00, 136.33it/s]\n",
      "Train 455 | out_loss 13.363728523254395: 100%|███| 8/8 [00:00<00:00, 132.89it/s]\n",
      "Train 456 | out_loss 13.396888732910156: 100%|███| 8/8 [00:00<00:00, 140.84it/s]\n",
      "Train 457 | out_loss 13.36643123626709: 100%|████| 8/8 [00:00<00:00, 127.37it/s]\n",
      "Train 458 | out_loss 13.328218460083008: 100%|███| 8/8 [00:00<00:00, 138.84it/s]\n",
      "Train 459 | out_loss 13.373411178588867: 100%|███| 8/8 [00:00<00:00, 135.38it/s]\n",
      "Train 460 | out_loss 13.326493263244629: 100%|███| 8/8 [00:00<00:00, 130.78it/s]\n",
      "Train 461 | out_loss 13.34748649597168: 100%|████| 8/8 [00:00<00:00, 137.53it/s]\n",
      "Train 462 | out_loss 13.318034172058105: 100%|███| 8/8 [00:00<00:00, 132.43it/s]\n",
      "Train 463 | out_loss 13.381349563598633: 100%|███| 8/8 [00:00<00:00, 141.19it/s]\n",
      "Train 464 | out_loss 13.384499549865723: 100%|███| 8/8 [00:00<00:00, 136.90it/s]\n",
      "Train 465 | out_loss 13.410504341125488: 100%|███| 8/8 [00:00<00:00, 140.53it/s]\n",
      "Train 466 | out_loss 13.281346321105957: 100%|███| 8/8 [00:00<00:00, 130.37it/s]\n",
      "Train 467 | out_loss 13.339923858642578: 100%|███| 8/8 [00:00<00:00, 119.26it/s]\n",
      "Train 468 | out_loss 13.36240005493164: 100%|████| 8/8 [00:00<00:00, 138.37it/s]\n",
      "Train 469 | out_loss 13.386385917663574: 100%|███| 8/8 [00:00<00:00, 136.99it/s]\n",
      "Train 470 | out_loss 13.446356773376465: 100%|███| 8/8 [00:00<00:00, 136.93it/s]\n",
      "Train 471 | out_loss 13.476462364196777: 100%|███| 8/8 [00:00<00:00, 131.97it/s]\n",
      "Train 472 | out_loss 13.396583557128906: 100%|███| 8/8 [00:00<00:00, 132.01it/s]\n",
      "Train 473 | out_loss 13.398473739624023: 100%|███| 8/8 [00:00<00:00, 129.02it/s]\n",
      "Train 474 | out_loss 13.287303924560547: 100%|███| 8/8 [00:00<00:00, 122.50it/s]\n",
      "Train 475 | out_loss 13.307487487792969: 100%|███| 8/8 [00:00<00:00, 135.59it/s]\n",
      "Train 476 | out_loss 13.37095832824707: 100%|████| 8/8 [00:00<00:00, 122.92it/s]\n",
      "Train 477 | out_loss 13.402979850769043: 100%|███| 8/8 [00:00<00:00, 127.30it/s]\n",
      "Train 478 | out_loss 13.38626766204834: 100%|████| 8/8 [00:00<00:00, 117.46it/s]\n",
      "Train 479 | out_loss 13.3256254196167: 100%|█████| 8/8 [00:00<00:00, 135.13it/s]\n",
      "Train 480 | out_loss 13.3365478515625: 100%|█████| 8/8 [00:00<00:00, 139.50it/s]\n",
      "Train 481 | out_loss 13.363728523254395: 100%|███| 8/8 [00:00<00:00, 142.97it/s]\n",
      "Train 482 | out_loss 13.299237251281738: 100%|███| 8/8 [00:00<00:00, 133.35it/s]\n",
      "Train 483 | out_loss 13.319157600402832: 100%|███| 8/8 [00:00<00:00, 134.83it/s]\n",
      "Train 484 | out_loss 13.39233112335205: 100%|████| 8/8 [00:00<00:00, 133.71it/s]\n",
      "Train 485 | out_loss 13.376456260681152: 100%|███| 8/8 [00:00<00:00, 137.30it/s]\n",
      "Train 486 | out_loss 13.413277626037598: 100%|███| 8/8 [00:00<00:00, 138.94it/s]\n",
      "Train 487 | out_loss 13.320757865905762: 100%|███| 8/8 [00:00<00:00, 136.23it/s]\n",
      "Train 488 | out_loss 13.34653091430664: 100%|████| 8/8 [00:00<00:00, 131.15it/s]\n",
      "Train 489 | out_loss 13.325010299682617: 100%|███| 8/8 [00:00<00:00, 141.80it/s]\n",
      "Train 490 | out_loss 13.369465827941895: 100%|███| 8/8 [00:00<00:00, 129.13it/s]\n",
      "Train 491 | out_loss 13.336055755615234: 100%|███| 8/8 [00:00<00:00, 140.11it/s]\n",
      "Train 492 | out_loss 13.328397750854492: 100%|███| 8/8 [00:00<00:00, 136.70it/s]\n",
      "Train 493 | out_loss 13.375659942626953: 100%|███| 8/8 [00:00<00:00, 135.30it/s]\n",
      "Train 494 | out_loss 13.334897994995117: 100%|███| 8/8 [00:00<00:00, 134.97it/s]\n",
      "Train 495 | out_loss 13.339866638183594: 100%|███| 8/8 [00:00<00:00, 138.85it/s]\n",
      "Train 496 | out_loss 13.32652759552002: 100%|████| 8/8 [00:00<00:00, 137.37it/s]\n",
      "Train 497 | out_loss 13.33228874206543: 100%|████| 8/8 [00:00<00:00, 134.19it/s]\n",
      "Train 498 | out_loss 13.33711051940918: 100%|████| 8/8 [00:00<00:00, 136.74it/s]\n",
      "Train 499 | out_loss 13.365004539489746: 100%|███| 8/8 [00:00<00:00, 137.22it/s]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 80.39862060546875: 100%|███████| 8/8 [00:00<00:00, 18.42it/s]\n",
      "Train 1 | out_loss 79.93669128417969: 100%|██████| 8/8 [00:00<00:00, 124.83it/s]\n",
      "Train 2 | out_loss 74.90277862548828: 100%|██████| 8/8 [00:00<00:00, 112.16it/s]\n",
      "Train 3 | out_loss 75.1519546508789: 100%|███████| 8/8 [00:00<00:00, 113.78it/s]\n",
      "Train 4 | out_loss 76.69586181640625: 100%|██████| 8/8 [00:00<00:00, 111.67it/s]\n",
      "Train 5 | out_loss 73.51482391357422: 100%|██████| 8/8 [00:00<00:00, 120.91it/s]\n",
      "Train 6 | out_loss 72.65339660644531: 100%|██████| 8/8 [00:00<00:00, 123.00it/s]\n",
      "Train 7 | out_loss 70.80294799804688: 100%|██████| 8/8 [00:00<00:00, 124.23it/s]\n",
      "Train 8 | out_loss 71.2508773803711: 100%|███████| 8/8 [00:00<00:00, 124.66it/s]\n",
      "Train 9 | out_loss 71.65451049804688: 100%|██████| 8/8 [00:00<00:00, 121.74it/s]\n",
      "Train 10 | out_loss 67.64810943603516: 100%|█████| 8/8 [00:00<00:00, 108.60it/s]\n",
      "Train 11 | out_loss 66.17237854003906: 100%|█████| 8/8 [00:00<00:00, 119.49it/s]\n",
      "Train 12 | out_loss 61.58012771606445: 100%|█████| 8/8 [00:00<00:00, 116.83it/s]\n",
      "Train 13 | out_loss 66.72930145263672: 100%|█████| 8/8 [00:00<00:00, 108.37it/s]\n",
      "Train 14 | out_loss 68.02214813232422: 100%|█████| 8/8 [00:00<00:00, 121.08it/s]\n",
      "Train 15 | out_loss 60.15420913696289: 100%|█████| 8/8 [00:00<00:00, 115.70it/s]\n",
      "Train 16 | out_loss 59.43606948852539: 100%|█████| 8/8 [00:00<00:00, 122.42it/s]\n",
      "Train 17 | out_loss 61.79803466796875: 100%|█████| 8/8 [00:00<00:00, 124.58it/s]\n",
      "Train 18 | out_loss 62.111663818359375: 100%|████| 8/8 [00:00<00:00, 123.38it/s]\n",
      "Train 19 | out_loss 61.50347137451172: 100%|█████| 8/8 [00:00<00:00, 123.15it/s]\n",
      "Train 20 | out_loss 59.49039077758789: 100%|█████| 8/8 [00:00<00:00, 116.95it/s]\n",
      "Train 21 | out_loss 56.06217956542969: 100%|█████| 8/8 [00:00<00:00, 119.60it/s]\n",
      "Train 22 | out_loss 56.03274154663086: 100%|█████| 8/8 [00:00<00:00, 108.67it/s]\n",
      "Train 23 | out_loss 56.840946197509766: 100%|████| 8/8 [00:00<00:00, 123.08it/s]\n",
      "Train 24 | out_loss 55.266204833984375: 100%|████| 8/8 [00:00<00:00, 117.57it/s]\n",
      "Train 25 | out_loss 53.2752685546875: 100%|██████| 8/8 [00:00<00:00, 126.39it/s]\n",
      "Train 26 | out_loss 51.838077545166016: 100%|████| 8/8 [00:00<00:00, 125.07it/s]\n",
      "Train 27 | out_loss 51.15167999267578: 100%|█████| 8/8 [00:00<00:00, 123.62it/s]\n",
      "Train 28 | out_loss 50.84394454956055: 100%|█████| 8/8 [00:00<00:00, 127.01it/s]\n",
      "Train 29 | out_loss 49.58849334716797: 100%|█████| 8/8 [00:00<00:00, 122.96it/s]\n",
      "Train 30 | out_loss 48.50673294067383: 100%|█████| 8/8 [00:00<00:00, 112.46it/s]\n",
      "Train 31 | out_loss 47.52595901489258: 100%|█████| 8/8 [00:00<00:00, 111.64it/s]\n",
      "Train 32 | out_loss 46.2994270324707: 100%|██████| 8/8 [00:00<00:00, 120.34it/s]\n",
      "Train 33 | out_loss 45.44412612915039: 100%|█████| 8/8 [00:00<00:00, 110.97it/s]\n",
      "Train 34 | out_loss 44.644866943359375: 100%|████| 8/8 [00:00<00:00, 122.96it/s]\n",
      "Train 35 | out_loss 43.500606536865234: 100%|████| 8/8 [00:00<00:00, 128.46it/s]\n",
      "Train 36 | out_loss 42.42539978027344: 100%|█████| 8/8 [00:00<00:00, 112.10it/s]\n",
      "Train 37 | out_loss 41.493961334228516: 100%|████| 8/8 [00:00<00:00, 123.32it/s]\n",
      "Train 38 | out_loss 40.55561828613281: 100%|█████| 8/8 [00:00<00:00, 123.30it/s]\n",
      "Train 39 | out_loss 39.55279541015625: 100%|█████| 8/8 [00:00<00:00, 128.96it/s]\n",
      "Train 40 | out_loss 38.560386657714844: 100%|████| 8/8 [00:00<00:00, 117.21it/s]\n",
      "Train 41 | out_loss 37.572364807128906: 100%|████| 8/8 [00:00<00:00, 116.00it/s]\n",
      "Train 42 | out_loss 36.61450958251953: 100%|█████| 8/8 [00:00<00:00, 121.36it/s]\n",
      "Train 43 | out_loss 35.655235290527344: 100%|████| 8/8 [00:00<00:00, 127.96it/s]\n",
      "Train 44 | out_loss 34.691184997558594: 100%|████| 8/8 [00:00<00:00, 111.92it/s]\n",
      "Train 45 | out_loss 33.71794891357422: 100%|█████| 8/8 [00:00<00:00, 111.89it/s]\n",
      "Train 46 | out_loss 32.774444580078125: 100%|████| 8/8 [00:00<00:00, 124.07it/s]\n",
      "Train 47 | out_loss 31.846086502075195: 100%|████| 8/8 [00:00<00:00, 123.21it/s]\n",
      "Train 48 | out_loss 30.86696434020996: 100%|█████| 8/8 [00:00<00:00, 126.27it/s]\n",
      "Train 49 | out_loss 29.969514846801758: 100%|████| 8/8 [00:00<00:00, 122.30it/s]\n",
      "Train 50 | out_loss 28.993810653686523: 100%|████| 8/8 [00:00<00:00, 126.24it/s]\n",
      "Train 51 | out_loss 28.0876522064209: 100%|██████| 8/8 [00:00<00:00, 122.82it/s]\n",
      "Train 52 | out_loss 27.174467086791992: 100%|████| 8/8 [00:00<00:00, 125.57it/s]\n",
      "Train 53 | out_loss 26.28196907043457: 100%|█████| 8/8 [00:00<00:00, 127.81it/s]\n",
      "Train 54 | out_loss 25.367328643798828: 100%|████| 8/8 [00:00<00:00, 126.28it/s]\n",
      "Train 55 | out_loss 24.527795791625977: 100%|████| 8/8 [00:00<00:00, 123.78it/s]\n",
      "Train 56 | out_loss 23.633007049560547: 100%|████| 8/8 [00:00<00:00, 126.13it/s]\n",
      "Train 57 | out_loss 22.805580139160156: 100%|████| 8/8 [00:00<00:00, 119.48it/s]\n",
      "Train 58 | out_loss 21.915557861328125: 100%|████| 8/8 [00:00<00:00, 119.54it/s]\n",
      "Train 59 | out_loss 21.160924911499023: 100%|████| 8/8 [00:00<00:00, 121.56it/s]\n",
      "Train 60 | out_loss 20.271404266357422: 100%|████| 8/8 [00:00<00:00, 126.46it/s]\n",
      "Train 61 | out_loss 19.589595794677734: 100%|████| 8/8 [00:00<00:00, 113.05it/s]\n",
      "Train 62 | out_loss 18.774856567382812: 100%|████| 8/8 [00:00<00:00, 124.03it/s]\n",
      "Train 63 | out_loss 18.105701446533203: 100%|████| 8/8 [00:00<00:00, 109.54it/s]\n",
      "Train 64 | out_loss 17.32121467590332: 100%|█████| 8/8 [00:00<00:00, 117.89it/s]\n",
      "Train 65 | out_loss 16.829893112182617: 100%|████| 8/8 [00:00<00:00, 122.17it/s]\n",
      "Train 66 | out_loss 16.36748695373535: 100%|█████| 8/8 [00:00<00:00, 111.59it/s]\n",
      "Train 67 | out_loss 15.443906784057617: 100%|████| 8/8 [00:00<00:00, 124.90it/s]\n",
      "Train 68 | out_loss 15.472990036010742: 100%|████| 8/8 [00:00<00:00, 125.59it/s]\n",
      "Train 69 | out_loss 14.45712947845459: 100%|█████| 8/8 [00:00<00:00, 129.19it/s]\n",
      "Train 70 | out_loss 14.685284614562988: 100%|████| 8/8 [00:00<00:00, 115.51it/s]\n",
      "Train 71 | out_loss 14.469914436340332: 100%|████| 8/8 [00:00<00:00, 121.70it/s]\n",
      "Train 72 | out_loss 13.682461738586426: 100%|████| 8/8 [00:00<00:00, 117.70it/s]\n",
      "Train 73 | out_loss 14.322724342346191: 100%|████| 8/8 [00:00<00:00, 126.59it/s]\n",
      "Train 74 | out_loss 13.258087158203125: 100%|████| 8/8 [00:00<00:00, 122.47it/s]\n",
      "Train 75 | out_loss 17.059154510498047: 100%|████| 8/8 [00:00<00:00, 110.10it/s]\n",
      "Train 76 | out_loss 14.235183715820312: 100%|████| 8/8 [00:00<00:00, 104.54it/s]\n",
      "Train 77 | out_loss 13.238987922668457: 100%|████| 8/8 [00:00<00:00, 119.45it/s]\n",
      "Train 78 | out_loss 13.163077354431152: 100%|████| 8/8 [00:00<00:00, 123.98it/s]\n",
      "Train 79 | out_loss 14.427608489990234: 100%|████| 8/8 [00:00<00:00, 115.93it/s]\n",
      "Train 80 | out_loss 13.708754539489746: 100%|████| 8/8 [00:00<00:00, 124.38it/s]\n",
      "Train 81 | out_loss 13.487937927246094: 100%|████| 8/8 [00:00<00:00, 123.37it/s]\n",
      "Train 82 | out_loss 14.375664710998535: 100%|████| 8/8 [00:00<00:00, 124.77it/s]\n",
      "Train 83 | out_loss 13.572331428527832: 100%|████| 8/8 [00:00<00:00, 125.92it/s]\n",
      "Train 84 | out_loss 12.998038291931152: 100%|████| 8/8 [00:00<00:00, 124.60it/s]\n",
      "Train 85 | out_loss 15.248176574707031: 100%|████| 8/8 [00:00<00:00, 126.55it/s]\n",
      "Train 86 | out_loss 14.230647087097168: 100%|████| 8/8 [00:00<00:00, 119.78it/s]\n",
      "Train 87 | out_loss 12.947531700134277: 100%|████| 8/8 [00:00<00:00, 122.77it/s]\n",
      "Train 88 | out_loss 12.982693672180176: 100%|████| 8/8 [00:00<00:00, 125.82it/s]\n",
      "Train 89 | out_loss 13.160938262939453: 100%|████| 8/8 [00:00<00:00, 123.42it/s]\n",
      "Train 90 | out_loss 13.868022918701172: 100%|████| 8/8 [00:00<00:00, 127.66it/s]\n",
      "Train 91 | out_loss 14.009191513061523: 100%|████| 8/8 [00:00<00:00, 126.54it/s]\n",
      "Train 92 | out_loss 13.287764549255371: 100%|████| 8/8 [00:00<00:00, 124.63it/s]\n",
      "Train 93 | out_loss 14.289741516113281: 100%|████| 8/8 [00:00<00:00, 111.61it/s]\n",
      "Train 94 | out_loss 13.87246036529541: 100%|█████| 8/8 [00:00<00:00, 120.86it/s]\n",
      "Train 95 | out_loss 15.574960708618164: 100%|████| 8/8 [00:00<00:00, 119.08it/s]\n",
      "Train 96 | out_loss 13.815699577331543: 100%|████| 8/8 [00:00<00:00, 123.36it/s]\n",
      "Train 97 | out_loss 13.013688087463379: 100%|████| 8/8 [00:00<00:00, 126.53it/s]\n",
      "Train 98 | out_loss 13.318249702453613: 100%|████| 8/8 [00:00<00:00, 123.08it/s]\n",
      "Train 99 | out_loss 14.321784019470215: 100%|████| 8/8 [00:00<00:00, 111.66it/s]\n",
      "Train 100 | out_loss 13.111997604370117: 100%|███| 8/8 [00:00<00:00, 122.78it/s]\n",
      "Train 101 | out_loss 13.794462203979492: 100%|███| 8/8 [00:00<00:00, 123.94it/s]\n",
      "Train 102 | out_loss 13.498170852661133: 100%|███| 8/8 [00:00<00:00, 122.46it/s]\n",
      "Train 103 | out_loss 13.079410552978516: 100%|███| 8/8 [00:00<00:00, 116.65it/s]\n",
      "Train 104 | out_loss 13.272502899169922: 100%|███| 8/8 [00:00<00:00, 126.48it/s]\n",
      "Train 105 | out_loss 13.00356388092041: 100%|████| 8/8 [00:00<00:00, 123.45it/s]\n",
      "Train 106 | out_loss 13.0341796875: 100%|████████| 8/8 [00:00<00:00, 125.25it/s]\n",
      "Train 107 | out_loss 13.358174324035645: 100%|███| 8/8 [00:00<00:00, 124.05it/s]\n",
      "Train 108 | out_loss 13.563643455505371: 100%|███| 8/8 [00:00<00:00, 126.86it/s]\n",
      "Train 109 | out_loss 13.421072959899902: 100%|███| 8/8 [00:00<00:00, 122.96it/s]\n",
      "Train 110 | out_loss 13.796195030212402: 100%|███| 8/8 [00:00<00:00, 120.43it/s]\n",
      "Train 111 | out_loss 13.577550888061523: 100%|███| 8/8 [00:00<00:00, 122.63it/s]\n",
      "Train 112 | out_loss 14.005367279052734: 100%|███| 8/8 [00:00<00:00, 126.38it/s]\n",
      "Train 113 | out_loss 13.245645523071289: 100%|███| 8/8 [00:00<00:00, 118.59it/s]\n",
      "Train 114 | out_loss 13.226421356201172: 100%|███| 8/8 [00:00<00:00, 125.85it/s]\n",
      "Train 115 | out_loss 13.15344524383545: 100%|████| 8/8 [00:00<00:00, 127.08it/s]\n",
      "Train 116 | out_loss 13.246413230895996: 100%|███| 8/8 [00:00<00:00, 127.12it/s]\n",
      "Train 117 | out_loss 12.990959167480469: 100%|███| 8/8 [00:00<00:00, 127.21it/s]\n",
      "Train 118 | out_loss 13.046220779418945: 100%|███| 8/8 [00:00<00:00, 126.50it/s]\n",
      "Train 119 | out_loss 13.0826997756958: 100%|█████| 8/8 [00:00<00:00, 125.53it/s]\n",
      "Train 120 | out_loss 13.010178565979004: 100%|███| 8/8 [00:00<00:00, 125.84it/s]\n",
      "Train 121 | out_loss 13.036538124084473: 100%|███| 8/8 [00:00<00:00, 122.59it/s]\n",
      "Train 122 | out_loss 13.527754783630371: 100%|███| 8/8 [00:00<00:00, 124.82it/s]\n",
      "Train 123 | out_loss 13.313594818115234: 100%|███| 8/8 [00:00<00:00, 118.11it/s]\n",
      "Train 124 | out_loss 13.271156311035156: 100%|███| 8/8 [00:00<00:00, 108.18it/s]\n",
      "Train 125 | out_loss 13.004803657531738: 100%|███| 8/8 [00:00<00:00, 123.68it/s]\n",
      "Train 126 | out_loss 13.439422607421875: 100%|███| 8/8 [00:00<00:00, 121.40it/s]\n",
      "Train 127 | out_loss 13.50094985961914: 100%|████| 8/8 [00:00<00:00, 113.65it/s]\n",
      "Train 128 | out_loss 13.79055118560791: 100%|████| 8/8 [00:00<00:00, 121.56it/s]\n",
      "Train 129 | out_loss 13.472569465637207: 100%|███| 8/8 [00:00<00:00, 125.55it/s]\n",
      "Train 130 | out_loss 13.178451538085938: 100%|███| 8/8 [00:00<00:00, 124.52it/s]\n",
      "Train 131 | out_loss 12.986686706542969: 100%|███| 8/8 [00:00<00:00, 125.42it/s]\n",
      "Train 132 | out_loss 13.005285263061523: 100%|███| 8/8 [00:00<00:00, 124.39it/s]\n",
      "Train 133 | out_loss 13.059700965881348: 100%|███| 8/8 [00:00<00:00, 125.79it/s]\n",
      "Train 134 | out_loss 13.508855819702148: 100%|███| 8/8 [00:00<00:00, 125.66it/s]\n",
      "Train 135 | out_loss 13.071709632873535: 100%|███| 8/8 [00:00<00:00, 126.06it/s]\n",
      "Train 136 | out_loss 13.084613800048828: 100%|███| 8/8 [00:00<00:00, 124.22it/s]\n",
      "Train 137 | out_loss 13.06177806854248: 100%|████| 8/8 [00:00<00:00, 122.94it/s]\n",
      "Train 138 | out_loss 13.096370697021484: 100%|███| 8/8 [00:00<00:00, 118.26it/s]\n",
      "Train 139 | out_loss 13.171838760375977: 100%|███| 8/8 [00:00<00:00, 125.48it/s]\n",
      "Train 140 | out_loss 12.995919227600098: 100%|███| 8/8 [00:00<00:00, 123.10it/s]\n",
      "Train 141 | out_loss 12.993321418762207: 100%|███| 8/8 [00:00<00:00, 121.28it/s]\n",
      "Train 142 | out_loss 12.993566513061523: 100%|███| 8/8 [00:00<00:00, 124.39it/s]\n",
      "Train 143 | out_loss 12.986663818359375: 100%|███| 8/8 [00:00<00:00, 124.48it/s]\n",
      "Train 144 | out_loss 13.036276817321777: 100%|███| 8/8 [00:00<00:00, 101.96it/s]\n",
      "Train 145 | out_loss 13.013124465942383: 100%|███| 8/8 [00:00<00:00, 124.65it/s]\n",
      "Train 146 | out_loss 13.03996753692627: 100%|████| 8/8 [00:00<00:00, 124.26it/s]\n",
      "Train 147 | out_loss 12.976279258728027: 100%|███| 8/8 [00:00<00:00, 123.57it/s]\n",
      "Train 148 | out_loss 13.048619270324707: 100%|███| 8/8 [00:00<00:00, 126.86it/s]\n",
      "Train 149 | out_loss 12.994023323059082: 100%|███| 8/8 [00:00<00:00, 127.04it/s]\n",
      "Train 150 | out_loss 12.974953651428223: 100%|███| 8/8 [00:00<00:00, 127.41it/s]\n",
      "Train 151 | out_loss 12.979058265686035: 100%|███| 8/8 [00:00<00:00, 126.00it/s]\n",
      "Train 152 | out_loss 13.011768341064453: 100%|███| 8/8 [00:00<00:00, 127.15it/s]\n",
      "Train 153 | out_loss 13.038195610046387: 100%|███| 8/8 [00:00<00:00, 127.69it/s]\n",
      "Train 154 | out_loss 13.102048873901367: 100%|███| 8/8 [00:00<00:00, 124.13it/s]\n",
      "Train 155 | out_loss 13.009139060974121: 100%|███| 8/8 [00:00<00:00, 127.24it/s]\n",
      "Train 156 | out_loss 12.979247093200684: 100%|███| 8/8 [00:00<00:00, 124.17it/s]\n",
      "Train 157 | out_loss 12.974441528320312: 100%|███| 8/8 [00:00<00:00, 112.68it/s]\n",
      "Train 158 | out_loss 13.035276412963867: 100%|███| 8/8 [00:00<00:00, 125.11it/s]\n",
      "Train 159 | out_loss 13.00460147857666: 100%|████| 8/8 [00:00<00:00, 128.10it/s]\n",
      "Train 160 | out_loss 13.014069557189941: 100%|███| 8/8 [00:00<00:00, 109.32it/s]\n",
      "Train 161 | out_loss 13.096697807312012: 100%|███| 8/8 [00:00<00:00, 124.46it/s]\n",
      "Train 162 | out_loss 13.13254451751709: 100%|████| 8/8 [00:00<00:00, 117.19it/s]\n",
      "Train 163 | out_loss 13.01839828491211: 100%|████| 8/8 [00:00<00:00, 116.18it/s]\n",
      "Train 164 | out_loss 12.982379913330078: 100%|███| 8/8 [00:00<00:00, 111.93it/s]\n",
      "Train 165 | out_loss 13.012271881103516: 100%|███| 8/8 [00:00<00:00, 121.15it/s]\n",
      "Train 166 | out_loss 13.234235763549805: 100%|███| 8/8 [00:00<00:00, 120.55it/s]\n",
      "Train 167 | out_loss 12.979909896850586: 100%|███| 8/8 [00:00<00:00, 125.83it/s]\n",
      "Train 168 | out_loss 13.005454063415527: 100%|███| 8/8 [00:00<00:00, 124.02it/s]\n",
      "Train 169 | out_loss 13.072928428649902: 100%|███| 8/8 [00:00<00:00, 102.15it/s]\n",
      "Train 170 | out_loss 13.064865112304688: 100%|███| 8/8 [00:00<00:00, 119.70it/s]\n",
      "Train 171 | out_loss 13.024419784545898: 100%|███| 8/8 [00:00<00:00, 123.67it/s]\n",
      "Train 172 | out_loss 13.137142181396484: 100%|███| 8/8 [00:00<00:00, 126.50it/s]\n",
      "Train 173 | out_loss 13.04178524017334: 100%|████| 8/8 [00:00<00:00, 123.37it/s]\n",
      "Train 174 | out_loss 13.004060745239258: 100%|███| 8/8 [00:00<00:00, 122.69it/s]\n",
      "Train 175 | out_loss 13.109271049499512: 100%|███| 8/8 [00:00<00:00, 122.69it/s]\n",
      "Train 176 | out_loss 12.993289947509766: 100%|████| 8/8 [00:00<00:00, 96.63it/s]\n",
      "Train 177 | out_loss 13.099943161010742: 100%|███| 8/8 [00:00<00:00, 115.01it/s]\n",
      "Train 178 | out_loss 13.020756721496582: 100%|███| 8/8 [00:00<00:00, 122.00it/s]\n",
      "Train 179 | out_loss 12.997124671936035: 100%|███| 8/8 [00:00<00:00, 116.84it/s]\n",
      "Train 180 | out_loss 13.023208618164062: 100%|███| 8/8 [00:00<00:00, 123.03it/s]\n",
      "Train 181 | out_loss 13.043179512023926: 100%|███| 8/8 [00:00<00:00, 127.75it/s]\n",
      "Train 182 | out_loss 13.084238052368164: 100%|███| 8/8 [00:00<00:00, 110.62it/s]\n",
      "Train 183 | out_loss 12.970327377319336: 100%|███| 8/8 [00:00<00:00, 118.13it/s]\n",
      "Train 184 | out_loss 13.008719444274902: 100%|███| 8/8 [00:00<00:00, 105.22it/s]\n",
      "Train 185 | out_loss 13.170303344726562: 100%|███| 8/8 [00:00<00:00, 119.59it/s]\n",
      "Train 186 | out_loss 13.00210952758789: 100%|████| 8/8 [00:00<00:00, 107.01it/s]\n",
      "Train 187 | out_loss 13.053030014038086: 100%|███| 8/8 [00:00<00:00, 121.86it/s]\n",
      "Train 188 | out_loss 13.020586967468262: 100%|███| 8/8 [00:00<00:00, 122.55it/s]\n",
      "Train 189 | out_loss 13.00975227355957: 100%|████| 8/8 [00:00<00:00, 114.94it/s]\n",
      "Train 190 | out_loss 12.999024391174316: 100%|███| 8/8 [00:00<00:00, 123.27it/s]\n",
      "Train 191 | out_loss 13.007400512695312: 100%|███| 8/8 [00:00<00:00, 123.28it/s]\n",
      "Train 192 | out_loss 12.997274398803711: 100%|███| 8/8 [00:00<00:00, 107.99it/s]\n",
      "Train 193 | out_loss 13.01330852508545: 100%|████| 8/8 [00:00<00:00, 119.53it/s]\n",
      "Train 194 | out_loss 12.997254371643066: 100%|███| 8/8 [00:00<00:00, 123.04it/s]\n",
      "Train 195 | out_loss 12.967744827270508: 100%|███| 8/8 [00:00<00:00, 116.30it/s]\n",
      "Train 196 | out_loss 13.084304809570312: 100%|███| 8/8 [00:00<00:00, 122.94it/s]\n",
      "Train 197 | out_loss 13.003560066223145: 100%|███| 8/8 [00:00<00:00, 123.02it/s]\n",
      "Train 198 | out_loss 13.052350997924805: 100%|███| 8/8 [00:00<00:00, 127.43it/s]\n",
      "Train 199 | out_loss 13.028589248657227: 100%|███| 8/8 [00:00<00:00, 122.07it/s]\n",
      "Train 200 | out_loss 13.083354949951172: 100%|███| 8/8 [00:00<00:00, 124.56it/s]\n",
      "Train 201 | out_loss 13.288525581359863: 100%|███| 8/8 [00:00<00:00, 125.57it/s]\n",
      "Train 202 | out_loss 13.003173828125: 100%|██████| 8/8 [00:00<00:00, 116.10it/s]\n",
      "Train 203 | out_loss 13.138284683227539: 100%|███| 8/8 [00:00<00:00, 107.88it/s]\n",
      "Train 204 | out_loss 12.97606086730957: 100%|████| 8/8 [00:00<00:00, 110.60it/s]\n",
      "Train 205 | out_loss 13.018559455871582: 100%|███| 8/8 [00:00<00:00, 112.79it/s]\n",
      "Train 206 | out_loss 13.04782772064209: 100%|████| 8/8 [00:00<00:00, 115.76it/s]\n",
      "Train 207 | out_loss 12.987957000732422: 100%|███| 8/8 [00:00<00:00, 128.02it/s]\n",
      "Train 208 | out_loss 13.009946823120117: 100%|███| 8/8 [00:00<00:00, 115.96it/s]\n",
      "Train 209 | out_loss 13.020913124084473: 100%|███| 8/8 [00:00<00:00, 116.86it/s]\n",
      "Train 210 | out_loss 12.964548110961914: 100%|████| 8/8 [00:00<00:00, 99.92it/s]\n",
      "Train 211 | out_loss 12.981856346130371: 100%|███| 8/8 [00:00<00:00, 105.65it/s]\n",
      "Train 212 | out_loss 12.991537094116211: 100%|███| 8/8 [00:00<00:00, 119.82it/s]\n",
      "Train 213 | out_loss 12.972902297973633: 100%|███| 8/8 [00:00<00:00, 111.73it/s]\n",
      "Train 214 | out_loss 13.093703269958496: 100%|███| 8/8 [00:00<00:00, 121.14it/s]\n",
      "Train 215 | out_loss 12.98840618133545: 100%|████| 8/8 [00:00<00:00, 108.40it/s]\n",
      "Train 216 | out_loss 12.999637603759766: 100%|███| 8/8 [00:00<00:00, 126.76it/s]\n",
      "Train 217 | out_loss 12.998539924621582: 100%|███| 8/8 [00:00<00:00, 122.52it/s]\n",
      "Train 218 | out_loss 13.037043571472168: 100%|███| 8/8 [00:00<00:00, 122.54it/s]\n",
      "Train 219 | out_loss 13.03547477722168: 100%|████| 8/8 [00:00<00:00, 123.61it/s]\n",
      "Train 220 | out_loss 12.967242240905762: 100%|███| 8/8 [00:00<00:00, 103.56it/s]\n",
      "Train 221 | out_loss 12.981040954589844: 100%|███| 8/8 [00:00<00:00, 121.99it/s]\n",
      "Train 222 | out_loss 13.064990043640137: 100%|███| 8/8 [00:00<00:00, 122.49it/s]\n",
      "Train 223 | out_loss 12.920974731445312: 100%|███| 8/8 [00:00<00:00, 124.17it/s]\n",
      "Train 224 | out_loss 12.890167236328125: 100%|███| 8/8 [00:00<00:00, 128.78it/s]\n",
      "Train 225 | out_loss 12.867323875427246: 100%|███| 8/8 [00:00<00:00, 121.22it/s]\n",
      "Train 226 | out_loss 12.942362785339355: 100%|███| 8/8 [00:00<00:00, 119.90it/s]\n",
      "Train 227 | out_loss 12.81957721710205: 100%|████| 8/8 [00:00<00:00, 107.60it/s]\n",
      "Train 228 | out_loss 12.790202140808105: 100%|███| 8/8 [00:00<00:00, 126.34it/s]\n",
      "Train 229 | out_loss 12.5982084274292: 100%|█████| 8/8 [00:00<00:00, 126.09it/s]\n",
      "Train 230 | out_loss 12.479689598083496: 100%|███| 8/8 [00:00<00:00, 124.81it/s]\n",
      "Train 231 | out_loss 12.296774864196777: 100%|███| 8/8 [00:00<00:00, 124.73it/s]\n",
      "Train 232 | out_loss 12.289114952087402: 100%|███| 8/8 [00:00<00:00, 124.73it/s]\n",
      "Train 233 | out_loss 11.963823318481445: 100%|███| 8/8 [00:00<00:00, 125.83it/s]\n",
      "Train 234 | out_loss 12.713640213012695: 100%|███| 8/8 [00:00<00:00, 116.38it/s]\n",
      "Train 235 | out_loss 12.18331527709961: 100%|████| 8/8 [00:00<00:00, 119.78it/s]\n",
      "Train 236 | out_loss 12.306816101074219: 100%|███| 8/8 [00:00<00:00, 116.94it/s]\n",
      "Train 237 | out_loss 12.023743629455566: 100%|███| 8/8 [00:00<00:00, 120.29it/s]\n",
      "Train 238 | out_loss 11.639627456665039: 100%|███| 8/8 [00:00<00:00, 124.37it/s]\n",
      "Train 239 | out_loss 11.956053733825684: 100%|███| 8/8 [00:00<00:00, 124.63it/s]\n",
      "Train 240 | out_loss 11.892511367797852: 100%|███| 8/8 [00:00<00:00, 125.25it/s]\n",
      "Train 241 | out_loss 11.658931732177734: 100%|███| 8/8 [00:00<00:00, 125.48it/s]\n",
      "Train 242 | out_loss 11.41616439819336: 100%|████| 8/8 [00:00<00:00, 123.93it/s]\n",
      "Train 243 | out_loss 11.643653869628906: 100%|███| 8/8 [00:00<00:00, 121.02it/s]\n",
      "Train 244 | out_loss 11.534687042236328: 100%|███| 8/8 [00:00<00:00, 117.64it/s]\n",
      "Train 245 | out_loss 12.09000301361084: 100%|████| 8/8 [00:00<00:00, 118.90it/s]\n",
      "Train 246 | out_loss 11.697476387023926: 100%|███| 8/8 [00:00<00:00, 112.83it/s]\n",
      "Train 247 | out_loss 11.39468765258789: 100%|████| 8/8 [00:00<00:00, 128.50it/s]\n",
      "Train 248 | out_loss 11.744837760925293: 100%|███| 8/8 [00:00<00:00, 114.39it/s]\n",
      "Train 249 | out_loss 11.538788795471191: 100%|███| 8/8 [00:00<00:00, 121.36it/s]\n",
      "Train 250 | out_loss 11.05579948425293: 100%|████| 8/8 [00:00<00:00, 126.57it/s]\n",
      "Train 251 | out_loss 11.902519226074219: 100%|███| 8/8 [00:00<00:00, 109.02it/s]\n",
      "Train 252 | out_loss 11.612751960754395: 100%|███| 8/8 [00:00<00:00, 111.33it/s]\n",
      "Train 253 | out_loss 11.582878112792969: 100%|███| 8/8 [00:00<00:00, 128.47it/s]\n",
      "Train 254 | out_loss 11.41981315612793: 100%|████| 8/8 [00:00<00:00, 116.68it/s]\n",
      "Train 255 | out_loss 11.29249095916748: 100%|████| 8/8 [00:00<00:00, 123.57it/s]\n",
      "Train 256 | out_loss 11.579418182373047: 100%|███| 8/8 [00:00<00:00, 121.84it/s]\n",
      "Train 257 | out_loss 12.209630012512207: 100%|███| 8/8 [00:00<00:00, 121.65it/s]\n",
      "Train 258 | out_loss 12.142383575439453: 100%|███| 8/8 [00:00<00:00, 122.44it/s]\n",
      "Train 259 | out_loss 12.06680679321289: 100%|████| 8/8 [00:00<00:00, 110.62it/s]\n",
      "Train 260 | out_loss 12.240204811096191: 100%|███| 8/8 [00:00<00:00, 114.60it/s]\n",
      "Train 261 | out_loss 12.106796264648438: 100%|███| 8/8 [00:00<00:00, 118.08it/s]\n",
      "Train 262 | out_loss 12.291803359985352: 100%|███| 8/8 [00:00<00:00, 120.56it/s]\n",
      "Train 263 | out_loss 11.844456672668457: 100%|███| 8/8 [00:00<00:00, 123.70it/s]\n",
      "Train 264 | out_loss 11.313834190368652: 100%|███| 8/8 [00:00<00:00, 118.61it/s]\n",
      "Train 265 | out_loss 12.236892700195312: 100%|███| 8/8 [00:00<00:00, 124.10it/s]\n",
      "Train 266 | out_loss 12.073076248168945: 100%|███| 8/8 [00:00<00:00, 121.57it/s]\n",
      "Train 267 | out_loss 11.902031898498535: 100%|███| 8/8 [00:00<00:00, 126.47it/s]\n",
      "Train 268 | out_loss 12.001545906066895: 100%|███| 8/8 [00:00<00:00, 120.77it/s]\n",
      "Train 269 | out_loss 11.622864723205566: 100%|███| 8/8 [00:00<00:00, 121.40it/s]\n",
      "Train 270 | out_loss 12.205517768859863: 100%|███| 8/8 [00:00<00:00, 121.25it/s]\n",
      "Train 271 | out_loss 12.349469184875488: 100%|███| 8/8 [00:00<00:00, 122.93it/s]\n",
      "Train 272 | out_loss 12.247346878051758: 100%|███| 8/8 [00:00<00:00, 121.46it/s]\n",
      "Train 273 | out_loss 11.86374568939209: 100%|████| 8/8 [00:00<00:00, 128.11it/s]\n",
      "Train 274 | out_loss 12.081613540649414: 100%|███| 8/8 [00:00<00:00, 126.35it/s]\n",
      "Train 275 | out_loss 12.841581344604492: 100%|███| 8/8 [00:00<00:00, 121.05it/s]\n",
      "Train 276 | out_loss 12.168824195861816: 100%|███| 8/8 [00:00<00:00, 121.19it/s]\n",
      "Train 277 | out_loss 12.3426513671875: 100%|█████| 8/8 [00:00<00:00, 124.55it/s]\n",
      "Train 278 | out_loss 12.004986763000488: 100%|███| 8/8 [00:00<00:00, 127.11it/s]\n",
      "Train 279 | out_loss 12.45821762084961: 100%|████| 8/8 [00:00<00:00, 121.86it/s]\n",
      "Train 280 | out_loss 12.326312065124512: 100%|███| 8/8 [00:00<00:00, 102.92it/s]\n",
      "Train 281 | out_loss 12.5458984375: 100%|████████| 8/8 [00:00<00:00, 105.05it/s]\n",
      "Train 282 | out_loss 12.509760856628418: 100%|███| 8/8 [00:00<00:00, 122.20it/s]\n",
      "Train 283 | out_loss 13.217248916625977: 100%|███| 8/8 [00:00<00:00, 109.82it/s]\n",
      "Train 284 | out_loss 13.31417179107666: 100%|████| 8/8 [00:00<00:00, 123.89it/s]\n",
      "Train 285 | out_loss 13.0180082321167: 100%|█████| 8/8 [00:00<00:00, 122.52it/s]\n",
      "Train 286 | out_loss 13.127755165100098: 100%|███| 8/8 [00:00<00:00, 122.88it/s]\n",
      "Train 287 | out_loss 12.988202095031738: 100%|███| 8/8 [00:00<00:00, 119.85it/s]\n",
      "Train 288 | out_loss 13.044673919677734: 100%|███| 8/8 [00:00<00:00, 125.92it/s]\n",
      "Train 289 | out_loss 12.99440860748291: 100%|████| 8/8 [00:00<00:00, 120.36it/s]\n",
      "Train 290 | out_loss 13.004727363586426: 100%|███| 8/8 [00:00<00:00, 107.76it/s]\n",
      "Train 291 | out_loss 13.016749382019043: 100%|███| 8/8 [00:00<00:00, 107.01it/s]\n",
      "Train 292 | out_loss 13.004271507263184: 100%|███| 8/8 [00:00<00:00, 120.56it/s]\n",
      "Train 293 | out_loss 12.999944686889648: 100%|███| 8/8 [00:00<00:00, 123.44it/s]\n",
      "Train 294 | out_loss 12.981986999511719: 100%|███| 8/8 [00:00<00:00, 124.14it/s]\n",
      "Train 295 | out_loss 13.00855541229248: 100%|████| 8/8 [00:00<00:00, 124.11it/s]\n",
      "Train 296 | out_loss 12.97509765625: 100%|███████| 8/8 [00:00<00:00, 119.24it/s]\n",
      "Train 297 | out_loss 12.984243392944336: 100%|███| 8/8 [00:00<00:00, 125.76it/s]\n",
      "Train 298 | out_loss 13.058135986328125: 100%|███| 8/8 [00:00<00:00, 125.03it/s]\n",
      "Train 299 | out_loss 12.996512413024902: 100%|███| 8/8 [00:00<00:00, 106.03it/s]\n",
      "Train 300 | out_loss 13.013569831848145: 100%|███| 8/8 [00:00<00:00, 123.00it/s]\n",
      "Train 301 | out_loss 13.008913040161133: 100%|███| 8/8 [00:00<00:00, 123.80it/s]\n",
      "Train 302 | out_loss 13.096405982971191: 100%|███| 8/8 [00:00<00:00, 127.01it/s]\n",
      "Train 303 | out_loss 13.009930610656738: 100%|███| 8/8 [00:00<00:00, 117.94it/s]\n",
      "Train 304 | out_loss 13.056628227233887: 100%|███| 8/8 [00:00<00:00, 118.23it/s]\n",
      "Train 305 | out_loss 13.016998291015625: 100%|███| 8/8 [00:00<00:00, 124.25it/s]\n",
      "Train 306 | out_loss 12.997458457946777: 100%|███| 8/8 [00:00<00:00, 122.14it/s]\n",
      "Train 307 | out_loss 13.018203735351562: 100%|███| 8/8 [00:00<00:00, 105.86it/s]\n",
      "Train 308 | out_loss 13.01638126373291: 100%|████| 8/8 [00:00<00:00, 107.21it/s]\n",
      "Train 309 | out_loss 13.125813484191895: 100%|███| 8/8 [00:00<00:00, 111.32it/s]\n",
      "Train 310 | out_loss 13.081536293029785: 100%|███| 8/8 [00:00<00:00, 121.30it/s]\n",
      "Train 311 | out_loss 12.966961860656738: 100%|███| 8/8 [00:00<00:00, 103.74it/s]\n",
      "Train 312 | out_loss 13.013836860656738: 100%|███| 8/8 [00:00<00:00, 103.98it/s]\n",
      "Train 313 | out_loss 12.990497589111328: 100%|███| 8/8 [00:00<00:00, 108.55it/s]\n",
      "Train 314 | out_loss 13.132798194885254: 100%|███| 8/8 [00:00<00:00, 115.60it/s]\n",
      "Train 315 | out_loss 13.022665977478027: 100%|███| 8/8 [00:00<00:00, 120.58it/s]\n",
      "Train 316 | out_loss 13.027511596679688: 100%|███| 8/8 [00:00<00:00, 122.02it/s]\n",
      "Train 317 | out_loss 13.002017974853516: 100%|███| 8/8 [00:00<00:00, 124.15it/s]\n",
      "Train 318 | out_loss 12.96273422241211: 100%|████| 8/8 [00:00<00:00, 122.96it/s]\n",
      "Train 319 | out_loss 12.972037315368652: 100%|███| 8/8 [00:00<00:00, 114.92it/s]\n",
      "Train 320 | out_loss 13.109417915344238: 100%|███| 8/8 [00:00<00:00, 119.21it/s]\n",
      "Train 321 | out_loss 13.058472633361816: 100%|███| 8/8 [00:00<00:00, 120.60it/s]\n",
      "Train 322 | out_loss 13.049190521240234: 100%|███| 8/8 [00:00<00:00, 121.34it/s]\n",
      "Train 323 | out_loss 13.132213592529297: 100%|███| 8/8 [00:00<00:00, 119.64it/s]\n",
      "Train 324 | out_loss 13.027443885803223: 100%|███| 8/8 [00:00<00:00, 124.03it/s]\n",
      "Train 325 | out_loss 13.103232383728027: 100%|███| 8/8 [00:00<00:00, 120.35it/s]\n",
      "Train 326 | out_loss 12.968058586120605: 100%|███| 8/8 [00:00<00:00, 117.29it/s]\n",
      "Train 327 | out_loss 12.994409561157227: 100%|███| 8/8 [00:00<00:00, 124.13it/s]\n",
      "Train 328 | out_loss 13.020337104797363: 100%|███| 8/8 [00:00<00:00, 124.72it/s]\n",
      "Train 329 | out_loss 13.004040718078613: 100%|███| 8/8 [00:00<00:00, 126.23it/s]\n",
      "Train 330 | out_loss 13.021612167358398: 100%|███| 8/8 [00:00<00:00, 123.51it/s]\n",
      "Train 331 | out_loss 13.00613021850586: 100%|████| 8/8 [00:00<00:00, 126.92it/s]\n",
      "Train 332 | out_loss 13.009267807006836: 100%|███| 8/8 [00:00<00:00, 119.07it/s]\n",
      "Train 333 | out_loss 12.951831817626953: 100%|███| 8/8 [00:00<00:00, 106.76it/s]\n",
      "Train 334 | out_loss 13.10344123840332: 100%|████| 8/8 [00:00<00:00, 122.42it/s]\n",
      "Train 335 | out_loss 13.155838966369629: 100%|███| 8/8 [00:00<00:00, 102.38it/s]\n",
      "Train 336 | out_loss 13.190645217895508: 100%|███| 8/8 [00:00<00:00, 116.61it/s]\n",
      "Train 337 | out_loss 13.112842559814453: 100%|███| 8/8 [00:00<00:00, 111.23it/s]\n",
      "Train 338 | out_loss 13.286316871643066: 100%|███| 8/8 [00:00<00:00, 113.61it/s]\n",
      "Train 339 | out_loss 13.070767402648926: 100%|███| 8/8 [00:00<00:00, 122.30it/s]\n",
      "Train 340 | out_loss 13.500663757324219: 100%|███| 8/8 [00:00<00:00, 125.46it/s]\n",
      "Train 341 | out_loss 12.98128604888916: 100%|████| 8/8 [00:00<00:00, 122.79it/s]\n",
      "Train 342 | out_loss 13.107851028442383: 100%|███| 8/8 [00:00<00:00, 123.94it/s]\n",
      "Train 343 | out_loss 12.991106986999512: 100%|███| 8/8 [00:00<00:00, 113.58it/s]\n",
      "Train 344 | out_loss 13.0201416015625: 100%|██████| 8/8 [00:00<00:00, 97.11it/s]\n",
      "Train 345 | out_loss 13.004777908325195: 100%|███| 8/8 [00:00<00:00, 113.55it/s]\n",
      "Train 346 | out_loss 13.021889686584473: 100%|███| 8/8 [00:00<00:00, 122.01it/s]\n",
      "Train 347 | out_loss 13.013993263244629: 100%|███| 8/8 [00:00<00:00, 119.61it/s]\n",
      "Train 348 | out_loss 13.008854866027832: 100%|███| 8/8 [00:00<00:00, 115.91it/s]\n",
      "Train 349 | out_loss 13.000554084777832: 100%|████| 8/8 [00:00<00:00, 94.55it/s]\n",
      "Train 350 | out_loss 12.99071216583252: 100%|████| 8/8 [00:00<00:00, 123.23it/s]\n",
      "Train 351 | out_loss 13.032150268554688: 100%|████| 8/8 [00:00<00:00, 97.21it/s]\n",
      "Train 352 | out_loss 13.03164291381836: 100%|█████| 8/8 [00:00<00:00, 95.00it/s]\n",
      "Train 353 | out_loss 13.09331226348877: 100%|████| 8/8 [00:00<00:00, 116.34it/s]\n",
      "Train 354 | out_loss 12.994434356689453: 100%|███| 8/8 [00:00<00:00, 109.99it/s]\n",
      "Train 355 | out_loss 13.011270523071289: 100%|███| 8/8 [00:00<00:00, 123.90it/s]\n",
      "Train 356 | out_loss 13.0094633102417: 100%|█████| 8/8 [00:00<00:00, 117.19it/s]\n",
      "Train 357 | out_loss 12.98715591430664: 100%|████| 8/8 [00:00<00:00, 106.70it/s]\n",
      "Train 358 | out_loss 13.068564414978027: 100%|███| 8/8 [00:00<00:00, 115.05it/s]\n",
      "Train 359 | out_loss 13.004212379455566: 100%|███| 8/8 [00:00<00:00, 117.03it/s]\n",
      "Train 360 | out_loss 13.0167875289917: 100%|█████| 8/8 [00:00<00:00, 121.31it/s]\n",
      "Train 361 | out_loss 13.038240432739258: 100%|███| 8/8 [00:00<00:00, 125.38it/s]\n",
      "Train 362 | out_loss 12.99658203125: 100%|███████| 8/8 [00:00<00:00, 122.24it/s]\n",
      "Train 363 | out_loss 12.985529899597168: 100%|███| 8/8 [00:00<00:00, 118.59it/s]\n",
      "Train 364 | out_loss 12.980274200439453: 100%|███| 8/8 [00:00<00:00, 102.10it/s]\n",
      "Train 365 | out_loss 12.973189353942871: 100%|███| 8/8 [00:00<00:00, 110.79it/s]\n",
      "Train 366 | out_loss 12.973204612731934: 100%|███| 8/8 [00:00<00:00, 122.00it/s]\n",
      "Train 367 | out_loss 12.970789909362793: 100%|███| 8/8 [00:00<00:00, 118.16it/s]\n",
      "Train 368 | out_loss 12.980291366577148: 100%|███| 8/8 [00:00<00:00, 112.89it/s]\n",
      "Train 369 | out_loss 12.983832359313965: 100%|███| 8/8 [00:00<00:00, 121.53it/s]\n",
      "Train 370 | out_loss 12.982481002807617: 100%|███| 8/8 [00:00<00:00, 113.36it/s]\n",
      "Train 371 | out_loss 12.994485855102539: 100%|███| 8/8 [00:00<00:00, 120.68it/s]\n",
      "Train 372 | out_loss 13.001921653747559: 100%|███| 8/8 [00:00<00:00, 106.76it/s]\n",
      "Train 373 | out_loss 13.013025283813477: 100%|███| 8/8 [00:00<00:00, 116.51it/s]\n",
      "Train 374 | out_loss 13.060669898986816: 100%|███| 8/8 [00:00<00:00, 115.69it/s]\n",
      "Train 375 | out_loss 13.143678665161133: 100%|███| 8/8 [00:00<00:00, 123.93it/s]\n",
      "Train 376 | out_loss 13.062373161315918: 100%|███| 8/8 [00:00<00:00, 121.93it/s]\n",
      "Train 377 | out_loss 13.065735816955566: 100%|███| 8/8 [00:00<00:00, 121.67it/s]\n",
      "Train 378 | out_loss 13.23371410369873: 100%|████| 8/8 [00:00<00:00, 119.52it/s]\n",
      "Train 379 | out_loss 13.040007591247559: 100%|███| 8/8 [00:00<00:00, 104.64it/s]\n",
      "Train 380 | out_loss 12.993285179138184: 100%|███| 8/8 [00:00<00:00, 111.82it/s]\n",
      "Train 381 | out_loss 12.956851959228516: 100%|███| 8/8 [00:00<00:00, 126.27it/s]\n",
      "Train 382 | out_loss 13.118544578552246: 100%|███| 8/8 [00:00<00:00, 124.73it/s]\n",
      "Train 383 | out_loss 13.001513481140137: 100%|███| 8/8 [00:00<00:00, 107.97it/s]\n",
      "Train 384 | out_loss 13.051520347595215: 100%|███| 8/8 [00:00<00:00, 122.62it/s]\n",
      "Train 385 | out_loss 12.994266510009766: 100%|███| 8/8 [00:00<00:00, 124.18it/s]\n",
      "Train 386 | out_loss 13.073339462280273: 100%|███| 8/8 [00:00<00:00, 121.93it/s]\n",
      "Train 387 | out_loss 13.053767204284668: 100%|███| 8/8 [00:00<00:00, 118.68it/s]\n",
      "Train 388 | out_loss 13.184175491333008: 100%|███| 8/8 [00:00<00:00, 108.50it/s]\n",
      "Train 389 | out_loss 13.535346031188965: 100%|███| 8/8 [00:00<00:00, 111.17it/s]\n",
      "Train 390 | out_loss 13.108620643615723: 100%|███| 8/8 [00:00<00:00, 124.80it/s]\n",
      "Train 391 | out_loss 13.26137924194336: 100%|████| 8/8 [00:00<00:00, 103.25it/s]\n",
      "Train 392 | out_loss 13.243209838867188: 100%|███| 8/8 [00:00<00:00, 121.26it/s]\n",
      "Train 393 | out_loss 13.128837585449219: 100%|███| 8/8 [00:00<00:00, 115.07it/s]\n",
      "Train 394 | out_loss 13.264208793640137: 100%|███| 8/8 [00:00<00:00, 126.29it/s]\n",
      "Train 395 | out_loss 13.134967803955078: 100%|███| 8/8 [00:00<00:00, 101.92it/s]\n",
      "Train 396 | out_loss 13.302136421203613: 100%|███| 8/8 [00:00<00:00, 111.49it/s]\n",
      "Train 397 | out_loss 13.104415893554688: 100%|███| 8/8 [00:00<00:00, 105.71it/s]\n",
      "Train 398 | out_loss 13.112918853759766: 100%|███| 8/8 [00:00<00:00, 111.40it/s]\n",
      "Train 399 | out_loss 13.082204818725586: 100%|███| 8/8 [00:00<00:00, 114.04it/s]\n",
      "Train 400 | out_loss 12.986401557922363: 100%|███| 8/8 [00:00<00:00, 119.04it/s]\n",
      "Train 401 | out_loss 12.997758865356445: 100%|███| 8/8 [00:00<00:00, 121.18it/s]\n",
      "Train 402 | out_loss 13.034135818481445: 100%|███| 8/8 [00:00<00:00, 120.86it/s]\n",
      "Train 403 | out_loss 13.032888412475586: 100%|███| 8/8 [00:00<00:00, 117.36it/s]\n",
      "Train 404 | out_loss 12.990626335144043: 100%|███| 8/8 [00:00<00:00, 124.15it/s]\n",
      "Train 405 | out_loss 13.015646934509277: 100%|███| 8/8 [00:00<00:00, 122.79it/s]\n",
      "Train 406 | out_loss 13.020172119140625: 100%|███| 8/8 [00:00<00:00, 112.66it/s]\n",
      "Train 407 | out_loss 12.987119674682617: 100%|███| 8/8 [00:00<00:00, 106.23it/s]\n",
      "Train 408 | out_loss 13.045989036560059: 100%|███| 8/8 [00:00<00:00, 116.45it/s]\n",
      "Train 409 | out_loss 12.967921257019043: 100%|████| 8/8 [00:00<00:00, 99.98it/s]\n",
      "Train 410 | out_loss 13.08615493774414: 100%|████| 8/8 [00:00<00:00, 121.13it/s]\n",
      "Train 411 | out_loss 12.984766006469727: 100%|███| 8/8 [00:00<00:00, 111.61it/s]\n",
      "Train 412 | out_loss 13.159038543701172: 100%|███| 8/8 [00:00<00:00, 117.66it/s]\n",
      "Train 413 | out_loss 12.976173400878906: 100%|███| 8/8 [00:00<00:00, 119.87it/s]\n",
      "Train 414 | out_loss 13.022198677062988: 100%|███| 8/8 [00:00<00:00, 107.86it/s]\n",
      "Train 415 | out_loss 13.153613090515137: 100%|███| 8/8 [00:00<00:00, 107.93it/s]\n",
      "Train 416 | out_loss 13.06322193145752: 100%|████| 8/8 [00:00<00:00, 114.69it/s]\n",
      "Train 417 | out_loss 13.07898235321045: 100%|████| 8/8 [00:00<00:00, 124.78it/s]\n",
      "Train 418 | out_loss 12.962900161743164: 100%|███| 8/8 [00:00<00:00, 119.75it/s]\n",
      "Train 419 | out_loss 12.966290473937988: 100%|███| 8/8 [00:00<00:00, 118.11it/s]\n",
      "Train 420 | out_loss 13.114821434020996: 100%|███| 8/8 [00:00<00:00, 124.89it/s]\n",
      "Train 421 | out_loss 12.979318618774414: 100%|███| 8/8 [00:00<00:00, 123.25it/s]\n",
      "Train 422 | out_loss 13.38747787475586: 100%|████| 8/8 [00:00<00:00, 123.31it/s]\n",
      "Train 423 | out_loss 13.016709327697754: 100%|███| 8/8 [00:00<00:00, 116.53it/s]\n",
      "Train 424 | out_loss 13.516695976257324: 100%|███| 8/8 [00:00<00:00, 104.03it/s]\n",
      "Train 425 | out_loss 13.2572660446167: 100%|█████| 8/8 [00:00<00:00, 116.23it/s]\n",
      "Train 426 | out_loss 13.194485664367676: 100%|███| 8/8 [00:00<00:00, 122.02it/s]\n",
      "Train 427 | out_loss 13.098014831542969: 100%|███| 8/8 [00:00<00:00, 105.89it/s]\n",
      "Train 428 | out_loss 13.025134086608887: 100%|███| 8/8 [00:00<00:00, 107.87it/s]\n",
      "Train 429 | out_loss 13.155722618103027: 100%|███| 8/8 [00:00<00:00, 122.69it/s]\n",
      "Train 430 | out_loss 13.015005111694336: 100%|███| 8/8 [00:00<00:00, 124.28it/s]\n",
      "Train 431 | out_loss 13.30329418182373: 100%|████| 8/8 [00:00<00:00, 123.42it/s]\n",
      "Train 432 | out_loss 13.119154930114746: 100%|███| 8/8 [00:00<00:00, 125.10it/s]\n",
      "Train 433 | out_loss 13.157319068908691: 100%|███| 8/8 [00:00<00:00, 118.07it/s]\n",
      "Train 434 | out_loss 12.972649574279785: 100%|███| 8/8 [00:00<00:00, 122.40it/s]\n",
      "Train 435 | out_loss 13.001201629638672: 100%|███| 8/8 [00:00<00:00, 125.86it/s]\n",
      "Train 436 | out_loss 13.017399787902832: 100%|███| 8/8 [00:00<00:00, 125.93it/s]\n",
      "Train 437 | out_loss 13.004565238952637: 100%|███| 8/8 [00:00<00:00, 114.60it/s]\n",
      "Train 438 | out_loss 12.983552932739258: 100%|███| 8/8 [00:00<00:00, 111.19it/s]\n",
      "Train 439 | out_loss 12.983673095703125: 100%|███| 8/8 [00:00<00:00, 122.95it/s]\n",
      "Train 440 | out_loss 13.014984130859375: 100%|███| 8/8 [00:00<00:00, 113.81it/s]\n",
      "Train 441 | out_loss 13.001693725585938: 100%|███| 8/8 [00:00<00:00, 122.32it/s]\n",
      "Train 442 | out_loss 12.975347518920898: 100%|███| 8/8 [00:00<00:00, 125.05it/s]\n",
      "Train 443 | out_loss 12.970073699951172: 100%|███| 8/8 [00:00<00:00, 118.40it/s]\n",
      "Train 444 | out_loss 12.985696792602539: 100%|███| 8/8 [00:00<00:00, 122.86it/s]\n",
      "Train 445 | out_loss 13.013069152832031: 100%|███| 8/8 [00:00<00:00, 124.06it/s]\n",
      "Train 446 | out_loss 12.988396644592285: 100%|███| 8/8 [00:00<00:00, 123.75it/s]\n",
      "Train 447 | out_loss 13.157642364501953: 100%|███| 8/8 [00:00<00:00, 101.83it/s]\n",
      "Train 448 | out_loss 13.080288887023926: 100%|███| 8/8 [00:00<00:00, 114.42it/s]\n",
      "Train 449 | out_loss 13.028399467468262: 100%|███| 8/8 [00:00<00:00, 120.95it/s]\n",
      "Train 450 | out_loss 13.152613639831543: 100%|███| 8/8 [00:00<00:00, 114.94it/s]\n",
      "Train 451 | out_loss 13.009708404541016: 100%|███| 8/8 [00:00<00:00, 119.78it/s]\n",
      "Train 452 | out_loss 13.171398162841797: 100%|███| 8/8 [00:00<00:00, 112.08it/s]\n",
      "Train 453 | out_loss 13.028346061706543: 100%|███| 8/8 [00:00<00:00, 103.13it/s]\n",
      "Train 454 | out_loss 13.623937606811523: 100%|███| 8/8 [00:00<00:00, 124.33it/s]\n",
      "Train 455 | out_loss 13.242406845092773: 100%|███| 8/8 [00:00<00:00, 116.30it/s]\n",
      "Train 456 | out_loss 13.332040786743164: 100%|███| 8/8 [00:00<00:00, 115.86it/s]\n",
      "Train 457 | out_loss 13.332935333251953: 100%|███| 8/8 [00:00<00:00, 119.64it/s]\n",
      "Train 458 | out_loss 13.087142944335938: 100%|███| 8/8 [00:00<00:00, 116.43it/s]\n",
      "Train 459 | out_loss 13.242071151733398: 100%|███| 8/8 [00:00<00:00, 113.49it/s]\n",
      "Train 460 | out_loss 13.062479019165039: 100%|███| 8/8 [00:00<00:00, 122.03it/s]\n",
      "Train 461 | out_loss 13.090658187866211: 100%|███| 8/8 [00:00<00:00, 121.10it/s]\n",
      "Train 462 | out_loss 13.04464054107666: 100%|████| 8/8 [00:00<00:00, 120.10it/s]\n",
      "Train 463 | out_loss 12.986661911010742: 100%|███| 8/8 [00:00<00:00, 119.40it/s]\n",
      "Train 464 | out_loss 13.00782299041748: 100%|████| 8/8 [00:00<00:00, 118.68it/s]\n",
      "Train 465 | out_loss 12.941346168518066: 100%|███| 8/8 [00:00<00:00, 122.70it/s]\n",
      "Train 466 | out_loss 13.107292175292969: 100%|███| 8/8 [00:00<00:00, 124.08it/s]\n",
      "Train 467 | out_loss 13.091739654541016: 100%|███| 8/8 [00:00<00:00, 122.26it/s]\n",
      "Train 468 | out_loss 13.105123519897461: 100%|███| 8/8 [00:00<00:00, 110.02it/s]\n",
      "Train 469 | out_loss 13.120331764221191: 100%|███| 8/8 [00:00<00:00, 119.85it/s]\n",
      "Train 470 | out_loss 13.017375946044922: 100%|███| 8/8 [00:00<00:00, 119.84it/s]\n",
      "Train 471 | out_loss 13.120403289794922: 100%|███| 8/8 [00:00<00:00, 120.92it/s]\n",
      "Train 472 | out_loss 13.10294246673584: 100%|████| 8/8 [00:00<00:00, 119.24it/s]\n",
      "Train 473 | out_loss 13.138458251953125: 100%|███| 8/8 [00:00<00:00, 119.09it/s]\n",
      "Train 474 | out_loss 13.014151573181152: 100%|███| 8/8 [00:00<00:00, 124.96it/s]\n",
      "Train 475 | out_loss 13.017589569091797: 100%|███| 8/8 [00:00<00:00, 121.28it/s]\n",
      "Train 476 | out_loss 13.071576118469238: 100%|███| 8/8 [00:00<00:00, 108.39it/s]\n",
      "Train 477 | out_loss 13.052526473999023: 100%|███| 8/8 [00:00<00:00, 124.60it/s]\n",
      "Train 478 | out_loss 13.063776969909668: 100%|███| 8/8 [00:00<00:00, 118.11it/s]\n",
      "Train 479 | out_loss 13.006473541259766: 100%|███| 8/8 [00:00<00:00, 109.15it/s]\n",
      "Train 480 | out_loss 13.151074409484863: 100%|███| 8/8 [00:00<00:00, 116.68it/s]\n",
      "Train 481 | out_loss 13.010614395141602: 100%|███| 8/8 [00:00<00:00, 120.16it/s]\n",
      "Train 482 | out_loss 12.961677551269531: 100%|███| 8/8 [00:00<00:00, 121.47it/s]\n",
      "Train 483 | out_loss 13.02637004852295: 100%|████| 8/8 [00:00<00:00, 121.37it/s]\n",
      "Train 484 | out_loss 12.965831756591797: 100%|███| 8/8 [00:00<00:00, 108.28it/s]\n",
      "Train 485 | out_loss 13.00280475616455: 100%|████| 8/8 [00:00<00:00, 121.17it/s]\n",
      "Train 486 | out_loss 12.98701286315918: 100%|████| 8/8 [00:00<00:00, 123.39it/s]\n",
      "Train 487 | out_loss 12.992237091064453: 100%|███| 8/8 [00:00<00:00, 124.37it/s]\n",
      "Train 488 | out_loss 12.988533020019531: 100%|███| 8/8 [00:00<00:00, 115.53it/s]\n",
      "Train 489 | out_loss 12.984733581542969: 100%|███| 8/8 [00:00<00:00, 110.63it/s]\n",
      "Train 490 | out_loss 12.984583854675293: 100%|███| 8/8 [00:00<00:00, 109.13it/s]\n",
      "Train 491 | out_loss 12.991843223571777: 100%|███| 8/8 [00:00<00:00, 115.79it/s]\n",
      "Train 492 | out_loss 12.980298042297363: 100%|███| 8/8 [00:00<00:00, 117.46it/s]\n",
      "Train 493 | out_loss 12.990948677062988: 100%|███| 8/8 [00:00<00:00, 112.96it/s]\n",
      "Train 494 | out_loss 13.011502265930176: 100%|███| 8/8 [00:00<00:00, 117.62it/s]\n",
      "Train 495 | out_loss 13.036373138427734: 100%|███| 8/8 [00:00<00:00, 121.85it/s]\n",
      "Train 496 | out_loss 12.994512557983398: 100%|███| 8/8 [00:00<00:00, 118.79it/s]\n",
      "Train 497 | out_loss 12.996301651000977: 100%|███| 8/8 [00:00<00:00, 122.15it/s]\n",
      "Train 498 | out_loss 12.98374080657959: 100%|████| 8/8 [00:00<00:00, 125.65it/s]\n",
      "Train 499 | out_loss 12.990592002868652: 100%|███| 8/8 [00:00<00:00, 122.72it/s]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 80.603271484375: 100%|█████████| 8/8 [00:00<00:00, 17.78it/s]\n",
      "Train 1 | out_loss 80.34375762939453: 100%|██████| 8/8 [00:00<00:00, 110.21it/s]\n",
      "Train 2 | out_loss 76.6917724609375: 100%|███████| 8/8 [00:00<00:00, 104.91it/s]\n",
      "Train 3 | out_loss 76.36390686035156: 100%|██████| 8/8 [00:00<00:00, 111.63it/s]\n",
      "Train 4 | out_loss 77.8180923461914: 100%|███████| 8/8 [00:00<00:00, 106.91it/s]\n",
      "Train 5 | out_loss 74.70069885253906: 100%|██████| 8/8 [00:00<00:00, 111.04it/s]\n",
      "Train 6 | out_loss 73.4756851196289: 100%|███████| 8/8 [00:00<00:00, 109.77it/s]\n",
      "Train 7 | out_loss 73.97930908203125: 100%|███████| 8/8 [00:00<00:00, 91.96it/s]\n",
      "Train 8 | out_loss 67.91754150390625: 100%|██████| 8/8 [00:00<00:00, 106.74it/s]\n",
      "Train 9 | out_loss 67.56101989746094: 100%|██████| 8/8 [00:00<00:00, 112.60it/s]\n",
      "Train 10 | out_loss 70.41023254394531: 100%|█████| 8/8 [00:00<00:00, 114.02it/s]\n",
      "Train 11 | out_loss 67.34736633300781: 100%|█████| 8/8 [00:00<00:00, 112.24it/s]\n",
      "Train 12 | out_loss 68.09212493896484: 100%|█████| 8/8 [00:00<00:00, 107.40it/s]\n",
      "Train 13 | out_loss 63.483680725097656: 100%|████| 8/8 [00:00<00:00, 111.28it/s]\n",
      "Train 14 | out_loss 65.18001556396484: 100%|█████| 8/8 [00:00<00:00, 106.98it/s]\n",
      "Train 15 | out_loss 65.26420593261719: 100%|█████| 8/8 [00:00<00:00, 109.41it/s]\n",
      "Train 16 | out_loss 59.790950775146484: 100%|████| 8/8 [00:00<00:00, 110.22it/s]\n",
      "Train 17 | out_loss 62.892066955566406: 100%|████| 8/8 [00:00<00:00, 110.78it/s]\n",
      "Train 18 | out_loss 63.738155364990234: 100%|█████| 8/8 [00:00<00:00, 90.43it/s]\n",
      "Train 19 | out_loss 61.217063903808594: 100%|████| 8/8 [00:00<00:00, 100.23it/s]\n",
      "Train 20 | out_loss 59.106178283691406: 100%|████| 8/8 [00:00<00:00, 101.30it/s]\n",
      "Train 21 | out_loss 58.36271667480469: 100%|█████| 8/8 [00:00<00:00, 111.53it/s]\n",
      "Train 22 | out_loss 58.18183135986328: 100%|█████| 8/8 [00:00<00:00, 111.69it/s]\n",
      "Train 23 | out_loss 57.68037033081055: 100%|█████| 8/8 [00:00<00:00, 109.88it/s]\n",
      "Train 24 | out_loss 56.02698516845703: 100%|█████| 8/8 [00:00<00:00, 109.30it/s]\n",
      "Train 25 | out_loss 54.14031982421875: 100%|█████| 8/8 [00:00<00:00, 101.78it/s]\n",
      "Train 26 | out_loss 53.0334358215332: 100%|██████| 8/8 [00:00<00:00, 101.68it/s]\n",
      "Train 27 | out_loss 52.413108825683594: 100%|████| 8/8 [00:00<00:00, 108.54it/s]\n",
      "Train 28 | out_loss 51.700035095214844: 100%|█████| 8/8 [00:00<00:00, 90.26it/s]\n",
      "Train 29 | out_loss 51.530174255371094: 100%|█████| 8/8 [00:00<00:00, 87.27it/s]\n",
      "Train 30 | out_loss 50.266361236572266: 100%|████| 8/8 [00:00<00:00, 105.65it/s]\n",
      "Train 31 | out_loss 48.6060791015625: 100%|██████| 8/8 [00:00<00:00, 105.96it/s]\n",
      "Train 32 | out_loss 47.43019485473633: 100%|█████| 8/8 [00:00<00:00, 112.40it/s]\n",
      "Train 33 | out_loss 46.628089904785156: 100%|████| 8/8 [00:00<00:00, 107.28it/s]\n",
      "Train 34 | out_loss 45.655582427978516: 100%|████| 8/8 [00:00<00:00, 101.02it/s]\n",
      "Train 35 | out_loss 44.88758850097656: 100%|█████| 8/8 [00:00<00:00, 106.43it/s]\n",
      "Train 36 | out_loss 43.64033508300781: 100%|█████| 8/8 [00:00<00:00, 113.81it/s]\n",
      "Train 37 | out_loss 42.64441680908203: 100%|█████| 8/8 [00:00<00:00, 102.81it/s]\n",
      "Train 38 | out_loss 41.952178955078125: 100%|████| 8/8 [00:00<00:00, 109.37it/s]\n",
      "Train 39 | out_loss 40.663997650146484: 100%|████| 8/8 [00:00<00:00, 108.45it/s]\n",
      "Train 40 | out_loss 39.77100372314453: 100%|█████| 8/8 [00:00<00:00, 108.80it/s]\n",
      "Train 41 | out_loss 38.854312896728516: 100%|████| 8/8 [00:00<00:00, 101.26it/s]\n",
      "Train 42 | out_loss 37.82350158691406: 100%|█████| 8/8 [00:00<00:00, 107.20it/s]\n",
      "Train 43 | out_loss 36.9838752746582: 100%|██████| 8/8 [00:00<00:00, 114.56it/s]\n",
      "Train 44 | out_loss 35.958744049072266: 100%|████| 8/8 [00:00<00:00, 113.49it/s]\n",
      "Train 45 | out_loss 34.879032135009766: 100%|████| 8/8 [00:00<00:00, 105.53it/s]\n",
      "Train 46 | out_loss 33.949790954589844: 100%|█████| 8/8 [00:00<00:00, 85.78it/s]\n",
      "Train 47 | out_loss 33.067222595214844: 100%|█████| 8/8 [00:00<00:00, 94.97it/s]\n",
      "Train 48 | out_loss 32.13975524902344: 100%|█████| 8/8 [00:00<00:00, 111.18it/s]\n",
      "Train 49 | out_loss 31.153385162353516: 100%|████| 8/8 [00:00<00:00, 110.41it/s]\n",
      "Train 50 | out_loss 30.201539993286133: 100%|████| 8/8 [00:00<00:00, 106.76it/s]\n",
      "Train 51 | out_loss 29.312816619873047: 100%|████| 8/8 [00:00<00:00, 115.02it/s]\n",
      "Train 52 | out_loss 28.377117156982422: 100%|████| 8/8 [00:00<00:00, 112.06it/s]\n",
      "Train 53 | out_loss 27.477907180786133: 100%|████| 8/8 [00:00<00:00, 116.29it/s]\n",
      "Train 54 | out_loss 26.564838409423828: 100%|████| 8/8 [00:00<00:00, 110.65it/s]\n",
      "Train 55 | out_loss 25.69223976135254: 100%|██████| 8/8 [00:00<00:00, 93.44it/s]\n",
      "Train 56 | out_loss 24.798898696899414: 100%|████| 8/8 [00:00<00:00, 106.98it/s]\n",
      "Train 57 | out_loss 23.941938400268555: 100%|████| 8/8 [00:00<00:00, 111.94it/s]\n",
      "Train 58 | out_loss 23.076515197753906: 100%|█████| 8/8 [00:00<00:00, 88.05it/s]\n",
      "Train 59 | out_loss 22.312047958374023: 100%|████| 8/8 [00:00<00:00, 109.87it/s]\n",
      "Train 60 | out_loss 21.445125579833984: 100%|████| 8/8 [00:00<00:00, 109.28it/s]\n",
      "Train 61 | out_loss 20.60161018371582: 100%|██████| 8/8 [00:00<00:00, 97.45it/s]\n",
      "Train 62 | out_loss 19.8374080657959: 100%|██████| 8/8 [00:00<00:00, 111.17it/s]\n",
      "Train 63 | out_loss 19.261749267578125: 100%|█████| 8/8 [00:00<00:00, 97.60it/s]\n",
      "Train 64 | out_loss 18.394466400146484: 100%|████| 8/8 [00:00<00:00, 114.98it/s]\n",
      "Train 65 | out_loss 17.743778228759766: 100%|█████| 8/8 [00:00<00:00, 96.61it/s]\n",
      "Train 66 | out_loss 17.12773895263672: 100%|█████| 8/8 [00:00<00:00, 101.10it/s]\n",
      "Train 67 | out_loss 16.708873748779297: 100%|████| 8/8 [00:00<00:00, 112.61it/s]\n",
      "Train 68 | out_loss 15.848104476928711: 100%|████| 8/8 [00:00<00:00, 102.89it/s]\n",
      "Train 69 | out_loss 15.62902545928955: 100%|█████| 8/8 [00:00<00:00, 112.67it/s]\n",
      "Train 70 | out_loss 15.300142288208008: 100%|████| 8/8 [00:00<00:00, 104.55it/s]\n",
      "Train 71 | out_loss 14.74856185913086: 100%|██████| 8/8 [00:00<00:00, 99.23it/s]\n",
      "Train 72 | out_loss 14.225221633911133: 100%|████| 8/8 [00:00<00:00, 101.55it/s]\n",
      "Train 73 | out_loss 15.124715805053711: 100%|█████| 8/8 [00:00<00:00, 99.19it/s]\n",
      "Train 74 | out_loss 13.468196868896484: 100%|█████| 8/8 [00:00<00:00, 96.30it/s]\n",
      "Train 75 | out_loss 14.719783782958984: 100%|████| 8/8 [00:00<00:00, 104.69it/s]\n",
      "Train 76 | out_loss 13.771716117858887: 100%|████| 8/8 [00:00<00:00, 106.26it/s]\n",
      "Train 77 | out_loss 14.652883529663086: 100%|████| 8/8 [00:00<00:00, 102.18it/s]\n",
      "Train 78 | out_loss 13.568583488464355: 100%|████| 8/8 [00:00<00:00, 103.00it/s]\n",
      "Train 79 | out_loss 13.895148277282715: 100%|████| 8/8 [00:00<00:00, 101.83it/s]\n",
      "Train 80 | out_loss 15.135702133178711: 100%|█████| 8/8 [00:00<00:00, 91.88it/s]\n",
      "Train 81 | out_loss 13.58645248413086: 100%|█████| 8/8 [00:00<00:00, 107.80it/s]\n",
      "Train 82 | out_loss 13.606649398803711: 100%|████| 8/8 [00:00<00:00, 102.87it/s]\n",
      "Train 83 | out_loss 13.54166030883789: 100%|██████| 8/8 [00:00<00:00, 99.40it/s]\n",
      "Train 84 | out_loss 14.233708381652832: 100%|████| 8/8 [00:00<00:00, 105.91it/s]\n",
      "Train 85 | out_loss 13.505154609680176: 100%|█████| 8/8 [00:00<00:00, 95.07it/s]\n",
      "Train 86 | out_loss 13.362351417541504: 100%|████| 8/8 [00:00<00:00, 113.86it/s]\n",
      "Train 87 | out_loss 15.082207679748535: 100%|████| 8/8 [00:00<00:00, 109.70it/s]\n",
      "Train 88 | out_loss 14.236656188964844: 100%|████| 8/8 [00:00<00:00, 110.04it/s]\n",
      "Train 89 | out_loss 14.547837257385254: 100%|████| 8/8 [00:00<00:00, 114.96it/s]\n",
      "Train 90 | out_loss 13.484919548034668: 100%|████| 8/8 [00:00<00:00, 102.02it/s]\n",
      "Train 91 | out_loss 15.342439651489258: 100%|████| 8/8 [00:00<00:00, 110.71it/s]\n",
      "Train 92 | out_loss 15.80420207977295: 100%|█████| 8/8 [00:00<00:00, 112.55it/s]\n",
      "Train 93 | out_loss 18.395973205566406: 100%|████| 8/8 [00:00<00:00, 106.47it/s]\n",
      "Train 94 | out_loss 23.43519401550293: 100%|█████| 8/8 [00:00<00:00, 112.50it/s]\n",
      "Train 95 | out_loss 16.574005126953125: 100%|████| 8/8 [00:00<00:00, 107.22it/s]\n",
      "Train 96 | out_loss 13.82442855834961: 100%|██████| 8/8 [00:00<00:00, 84.22it/s]\n",
      "Train 97 | out_loss 15.743227005004883: 100%|████| 8/8 [00:00<00:00, 106.42it/s]\n",
      "Train 98 | out_loss 15.519146919250488: 100%|█████| 8/8 [00:00<00:00, 98.49it/s]\n",
      "Train 99 | out_loss 14.54300308227539: 100%|█████| 8/8 [00:00<00:00, 115.71it/s]\n",
      "Train 100 | out_loss 19.245874404907227: 100%|███| 8/8 [00:00<00:00, 109.66it/s]\n",
      "Train 101 | out_loss 14.345680236816406: 100%|███| 8/8 [00:00<00:00, 107.68it/s]\n",
      "Train 102 | out_loss 14.97372817993164: 100%|████| 8/8 [00:00<00:00, 114.71it/s]\n",
      "Train 103 | out_loss 17.70392608642578: 100%|████| 8/8 [00:00<00:00, 101.29it/s]\n",
      "Train 104 | out_loss 15.250358581542969: 100%|████| 8/8 [00:00<00:00, 87.69it/s]\n",
      "Train 105 | out_loss 16.920854568481445: 100%|███| 8/8 [00:00<00:00, 100.46it/s]\n",
      "Train 106 | out_loss 13.908308029174805: 100%|████| 8/8 [00:00<00:00, 98.83it/s]\n",
      "Train 107 | out_loss 13.460762977600098: 100%|████| 8/8 [00:00<00:00, 91.50it/s]\n",
      "Train 108 | out_loss 13.332083702087402: 100%|███| 8/8 [00:00<00:00, 109.80it/s]\n",
      "Train 109 | out_loss 13.309805870056152: 100%|███| 8/8 [00:00<00:00, 108.98it/s]\n",
      "Train 110 | out_loss 13.766080856323242: 100%|███| 8/8 [00:00<00:00, 101.10it/s]\n",
      "Train 111 | out_loss 13.28238582611084: 100%|████| 8/8 [00:00<00:00, 114.29it/s]\n",
      "Train 112 | out_loss 13.317193031311035: 100%|███| 8/8 [00:00<00:00, 107.28it/s]\n",
      "Train 113 | out_loss 13.396023750305176: 100%|███| 8/8 [00:00<00:00, 109.74it/s]\n",
      "Train 114 | out_loss 13.454079627990723: 100%|███| 8/8 [00:00<00:00, 101.47it/s]\n",
      "Train 115 | out_loss 13.321508407592773: 100%|███| 8/8 [00:00<00:00, 106.97it/s]\n",
      "Train 116 | out_loss 13.28515338897705: 100%|████| 8/8 [00:00<00:00, 112.16it/s]\n",
      "Train 117 | out_loss 13.36337947845459: 100%|████| 8/8 [00:00<00:00, 112.21it/s]\n",
      "Train 118 | out_loss 13.735672950744629: 100%|███| 8/8 [00:00<00:00, 110.49it/s]\n",
      "Train 119 | out_loss 13.2715425491333: 100%|█████| 8/8 [00:00<00:00, 112.69it/s]\n",
      "Train 120 | out_loss 13.29892635345459: 100%|████| 8/8 [00:00<00:00, 105.33it/s]\n",
      "Train 121 | out_loss 13.288069725036621: 100%|███| 8/8 [00:00<00:00, 112.37it/s]\n",
      "Train 122 | out_loss 13.496969223022461: 100%|███| 8/8 [00:00<00:00, 112.03it/s]\n",
      "Train 123 | out_loss 13.343239784240723: 100%|███| 8/8 [00:00<00:00, 111.99it/s]\n",
      "Train 124 | out_loss 13.327737808227539: 100%|███| 8/8 [00:00<00:00, 111.70it/s]\n",
      "Train 125 | out_loss 13.33187198638916: 100%|████| 8/8 [00:00<00:00, 100.51it/s]\n",
      "Train 126 | out_loss 13.308835983276367: 100%|████| 8/8 [00:00<00:00, 98.78it/s]\n",
      "Train 127 | out_loss 13.325817108154297: 100%|███| 8/8 [00:00<00:00, 100.15it/s]\n",
      "Train 128 | out_loss 13.400116920471191: 100%|███| 8/8 [00:00<00:00, 109.60it/s]\n",
      "Train 129 | out_loss 13.339446067810059: 100%|███| 8/8 [00:00<00:00, 111.64it/s]\n",
      "Train 130 | out_loss 13.361677169799805: 100%|███| 8/8 [00:00<00:00, 118.13it/s]\n",
      "Train 131 | out_loss 13.302144050598145: 100%|███| 8/8 [00:00<00:00, 107.89it/s]\n",
      "Train 132 | out_loss 13.324600219726562: 100%|███| 8/8 [00:00<00:00, 102.32it/s]\n",
      "Train 133 | out_loss 13.309128761291504: 100%|███| 8/8 [00:00<00:00, 110.91it/s]\n",
      "Train 134 | out_loss 13.281279563903809: 100%|███| 8/8 [00:00<00:00, 109.27it/s]\n",
      "Train 135 | out_loss 13.283759117126465: 100%|████| 8/8 [00:00<00:00, 90.64it/s]\n",
      "Train 136 | out_loss 13.278029441833496: 100%|███| 8/8 [00:00<00:00, 111.46it/s]\n",
      "Train 137 | out_loss 13.3193941116333: 100%|█████| 8/8 [00:00<00:00, 112.60it/s]\n",
      "Train 138 | out_loss 13.297676086425781: 100%|███| 8/8 [00:00<00:00, 113.32it/s]\n",
      "Train 139 | out_loss 13.285849571228027: 100%|███| 8/8 [00:00<00:00, 112.06it/s]\n",
      "Train 140 | out_loss 13.284893989562988: 100%|███| 8/8 [00:00<00:00, 109.92it/s]\n",
      "Train 141 | out_loss 13.278236389160156: 100%|███| 8/8 [00:00<00:00, 110.20it/s]\n",
      "Train 142 | out_loss 13.32819652557373: 100%|█████| 8/8 [00:00<00:00, 92.11it/s]\n",
      "Train 143 | out_loss 13.293334007263184: 100%|███| 8/8 [00:00<00:00, 107.89it/s]\n",
      "Train 144 | out_loss 13.266056060791016: 100%|███| 8/8 [00:00<00:00, 107.36it/s]\n",
      "Train 145 | out_loss 13.37348461151123: 100%|█████| 8/8 [00:00<00:00, 88.65it/s]\n",
      "Train 146 | out_loss 13.270997047424316: 100%|███| 8/8 [00:00<00:00, 111.67it/s]\n",
      "Train 147 | out_loss 13.389081954956055: 100%|███| 8/8 [00:00<00:00, 107.56it/s]\n",
      "Train 148 | out_loss 13.326672554016113: 100%|███| 8/8 [00:00<00:00, 112.57it/s]\n",
      "Train 149 | out_loss 13.283649444580078: 100%|████| 8/8 [00:00<00:00, 76.19it/s]\n",
      "Train 150 | out_loss 13.291695594787598: 100%|████| 8/8 [00:00<00:00, 77.77it/s]\n",
      "Train 151 | out_loss 13.315145492553711: 100%|███| 8/8 [00:00<00:00, 110.65it/s]\n",
      "Train 152 | out_loss 13.441622734069824: 100%|███| 8/8 [00:00<00:00, 109.09it/s]\n",
      "Train 153 | out_loss 13.271788597106934: 100%|███| 8/8 [00:00<00:00, 101.81it/s]\n",
      "Train 154 | out_loss 13.491435050964355: 100%|███| 8/8 [00:00<00:00, 113.11it/s]\n",
      "Train 155 | out_loss 13.39589786529541: 100%|████| 8/8 [00:00<00:00, 103.08it/s]\n",
      "Train 156 | out_loss 13.364665985107422: 100%|███| 8/8 [00:00<00:00, 101.92it/s]\n",
      "Train 157 | out_loss 13.286964416503906: 100%|███| 8/8 [00:00<00:00, 105.53it/s]\n",
      "Train 158 | out_loss 13.289410591125488: 100%|███| 8/8 [00:00<00:00, 109.98it/s]\n",
      "Train 159 | out_loss 13.33807373046875: 100%|████| 8/8 [00:00<00:00, 113.55it/s]\n",
      "Train 160 | out_loss 13.283095359802246: 100%|███| 8/8 [00:00<00:00, 101.58it/s]\n",
      "Train 161 | out_loss 13.28593635559082: 100%|████| 8/8 [00:00<00:00, 114.96it/s]\n",
      "Train 162 | out_loss 13.313539505004883: 100%|███| 8/8 [00:00<00:00, 106.54it/s]\n",
      "Train 163 | out_loss 13.336261749267578: 100%|████| 8/8 [00:00<00:00, 97.99it/s]\n",
      "Train 164 | out_loss 13.289894104003906: 100%|████| 8/8 [00:00<00:00, 99.61it/s]\n",
      "Train 165 | out_loss 13.33587646484375: 100%|████| 8/8 [00:00<00:00, 100.14it/s]\n",
      "Train 166 | out_loss 13.437201499938965: 100%|███| 8/8 [00:00<00:00, 105.31it/s]\n",
      "Train 167 | out_loss 13.335670471191406: 100%|███| 8/8 [00:00<00:00, 102.20it/s]\n",
      "Train 168 | out_loss 13.325627326965332: 100%|███| 8/8 [00:00<00:00, 100.90it/s]\n",
      "Train 169 | out_loss 13.336124420166016: 100%|███| 8/8 [00:00<00:00, 108.85it/s]\n",
      "Train 170 | out_loss 13.312285423278809: 100%|███| 8/8 [00:00<00:00, 115.08it/s]\n",
      "Train 171 | out_loss 13.451093673706055: 100%|███| 8/8 [00:00<00:00, 106.61it/s]\n",
      "Train 172 | out_loss 13.301018714904785: 100%|████| 8/8 [00:00<00:00, 98.11it/s]\n",
      "Train 173 | out_loss 13.454339981079102: 100%|███| 8/8 [00:00<00:00, 109.09it/s]\n",
      "Train 174 | out_loss 13.304101943969727: 100%|███| 8/8 [00:00<00:00, 111.75it/s]\n",
      "Train 175 | out_loss 13.311647415161133: 100%|███| 8/8 [00:00<00:00, 111.15it/s]\n",
      "Train 176 | out_loss 13.376028060913086: 100%|████| 8/8 [00:00<00:00, 98.38it/s]\n",
      "Train 177 | out_loss 13.346574783325195: 100%|███| 8/8 [00:00<00:00, 109.85it/s]\n",
      "Train 178 | out_loss 13.28636646270752: 100%|████| 8/8 [00:00<00:00, 111.75it/s]\n",
      "Train 179 | out_loss 13.303284645080566: 100%|███| 8/8 [00:00<00:00, 107.40it/s]\n",
      "Train 180 | out_loss 13.416393280029297: 100%|███| 8/8 [00:00<00:00, 111.81it/s]\n",
      "Train 181 | out_loss 13.29106616973877: 100%|████| 8/8 [00:00<00:00, 110.59it/s]\n",
      "Train 182 | out_loss 13.32250690460205: 100%|████| 8/8 [00:00<00:00, 111.00it/s]\n",
      "Train 183 | out_loss 13.288047790527344: 100%|███| 8/8 [00:00<00:00, 103.87it/s]\n",
      "Train 184 | out_loss 13.561111450195312: 100%|███| 8/8 [00:00<00:00, 108.17it/s]\n",
      "Train 185 | out_loss 13.376717567443848: 100%|████| 8/8 [00:00<00:00, 88.38it/s]\n",
      "Train 186 | out_loss 13.5319185256958: 100%|██████| 8/8 [00:00<00:00, 98.35it/s]\n",
      "Train 187 | out_loss 13.396733283996582: 100%|███| 8/8 [00:00<00:00, 102.21it/s]\n",
      "Train 188 | out_loss 13.458867073059082: 100%|████| 8/8 [00:00<00:00, 96.86it/s]\n",
      "Train 189 | out_loss 13.27631950378418: 100%|████| 8/8 [00:00<00:00, 109.11it/s]\n",
      "Train 190 | out_loss 13.407098770141602: 100%|███| 8/8 [00:00<00:00, 104.90it/s]\n",
      "Train 191 | out_loss 13.35780143737793: 100%|████| 8/8 [00:00<00:00, 101.66it/s]\n",
      "Train 192 | out_loss 13.329275131225586: 100%|████| 8/8 [00:00<00:00, 94.52it/s]\n",
      "Train 193 | out_loss 13.276134490966797: 100%|████| 8/8 [00:00<00:00, 85.00it/s]\n",
      "Train 194 | out_loss 13.335308074951172: 100%|████| 8/8 [00:00<00:00, 99.38it/s]\n",
      "Train 195 | out_loss 13.285567283630371: 100%|████| 8/8 [00:00<00:00, 97.28it/s]\n",
      "Train 196 | out_loss 13.284661293029785: 100%|████| 8/8 [00:00<00:00, 92.13it/s]\n",
      "Train 197 | out_loss 13.31872272491455: 100%|████| 8/8 [00:00<00:00, 110.37it/s]\n",
      "Train 198 | out_loss 13.29520320892334: 100%|████| 8/8 [00:00<00:00, 102.34it/s]\n",
      "Train 199 | out_loss 13.288247108459473: 100%|███| 8/8 [00:00<00:00, 105.56it/s]\n",
      "Train 200 | out_loss 13.30868911743164: 100%|████| 8/8 [00:00<00:00, 106.93it/s]\n",
      "Train 201 | out_loss 13.2704439163208: 100%|█████| 8/8 [00:00<00:00, 110.22it/s]\n",
      "Train 202 | out_loss 13.280348777770996: 100%|███| 8/8 [00:00<00:00, 112.73it/s]\n",
      "Train 203 | out_loss 13.322665214538574: 100%|███| 8/8 [00:00<00:00, 101.99it/s]\n",
      "Train 204 | out_loss 13.361976623535156: 100%|████| 8/8 [00:00<00:00, 96.49it/s]\n",
      "Train 205 | out_loss 13.308271408081055: 100%|███| 8/8 [00:00<00:00, 111.42it/s]\n",
      "Train 206 | out_loss 13.34121322631836: 100%|████| 8/8 [00:00<00:00, 109.08it/s]\n",
      "Train 207 | out_loss 13.331265449523926: 100%|███| 8/8 [00:00<00:00, 114.35it/s]\n",
      "Train 208 | out_loss 13.29419994354248: 100%|█████| 8/8 [00:00<00:00, 98.34it/s]\n",
      "Train 209 | out_loss 13.292861938476562: 100%|████| 8/8 [00:00<00:00, 95.99it/s]\n",
      "Train 210 | out_loss 13.280202865600586: 100%|███| 8/8 [00:00<00:00, 108.23it/s]\n",
      "Train 211 | out_loss 13.298871040344238: 100%|███| 8/8 [00:00<00:00, 114.43it/s]\n",
      "Train 212 | out_loss 13.43095588684082: 100%|████| 8/8 [00:00<00:00, 110.82it/s]\n",
      "Train 213 | out_loss 13.305973052978516: 100%|███| 8/8 [00:00<00:00, 111.07it/s]\n",
      "Train 214 | out_loss 13.287456512451172: 100%|███| 8/8 [00:00<00:00, 108.68it/s]\n",
      "Train 215 | out_loss 13.28994369506836: 100%|████| 8/8 [00:00<00:00, 106.95it/s]\n",
      "Train 216 | out_loss 13.300629615783691: 100%|████| 8/8 [00:00<00:00, 88.94it/s]\n",
      "Train 217 | out_loss 13.28436279296875: 100%|████| 8/8 [00:00<00:00, 109.12it/s]\n",
      "Train 218 | out_loss 13.283171653747559: 100%|███| 8/8 [00:00<00:00, 111.14it/s]\n",
      "Train 219 | out_loss 13.285626411437988: 100%|███| 8/8 [00:00<00:00, 107.20it/s]\n",
      "Train 220 | out_loss 13.266270637512207: 100%|███| 8/8 [00:00<00:00, 105.99it/s]\n",
      "Train 221 | out_loss 13.324967384338379: 100%|███| 8/8 [00:00<00:00, 104.23it/s]\n",
      "Train 222 | out_loss 13.295141220092773: 100%|███| 8/8 [00:00<00:00, 111.97it/s]\n",
      "Train 223 | out_loss 13.33063793182373: 100%|█████| 8/8 [00:00<00:00, 98.82it/s]\n",
      "Train 224 | out_loss 13.284628868103027: 100%|███| 8/8 [00:00<00:00, 111.03it/s]\n",
      "Train 225 | out_loss 13.33348560333252: 100%|████| 8/8 [00:00<00:00, 108.99it/s]\n",
      "Train 226 | out_loss 13.299906730651855: 100%|███| 8/8 [00:00<00:00, 110.06it/s]\n",
      "Train 227 | out_loss 13.273780822753906: 100%|███| 8/8 [00:00<00:00, 110.94it/s]\n",
      "Train 228 | out_loss 13.307011604309082: 100%|████| 8/8 [00:00<00:00, 87.30it/s]\n",
      "Train 229 | out_loss 13.40518856048584: 100%|█████| 8/8 [00:00<00:00, 90.91it/s]\n",
      "Train 230 | out_loss 13.286408424377441: 100%|████| 8/8 [00:00<00:00, 89.30it/s]\n",
      "Train 231 | out_loss 13.295219421386719: 100%|███| 8/8 [00:00<00:00, 105.20it/s]\n",
      "Train 232 | out_loss 13.285181999206543: 100%|████| 8/8 [00:00<00:00, 92.84it/s]\n",
      "Train 233 | out_loss 13.387943267822266: 100%|███| 8/8 [00:00<00:00, 109.67it/s]\n",
      "Train 234 | out_loss 13.335165977478027: 100%|████| 8/8 [00:00<00:00, 85.80it/s]\n",
      "Train 235 | out_loss 13.372276306152344: 100%|████| 8/8 [00:00<00:00, 98.98it/s]\n",
      "Train 236 | out_loss 13.242745399475098: 100%|███| 8/8 [00:00<00:00, 107.62it/s]\n",
      "Train 237 | out_loss 13.314641952514648: 100%|████| 8/8 [00:00<00:00, 92.76it/s]\n",
      "Train 238 | out_loss 13.311824798583984: 100%|████| 8/8 [00:00<00:00, 87.60it/s]\n",
      "Train 239 | out_loss 13.30577278137207: 100%|█████| 8/8 [00:00<00:00, 88.19it/s]\n",
      "Train 240 | out_loss 13.325335502624512: 100%|███| 8/8 [00:00<00:00, 102.25it/s]\n",
      "Train 241 | out_loss 13.299107551574707: 100%|███| 8/8 [00:00<00:00, 113.95it/s]\n",
      "Train 242 | out_loss 13.30550479888916: 100%|████| 8/8 [00:00<00:00, 104.25it/s]\n",
      "Train 243 | out_loss 13.30545425415039: 100%|█████| 8/8 [00:00<00:00, 97.49it/s]\n",
      "Train 244 | out_loss 13.280923843383789: 100%|███| 8/8 [00:00<00:00, 107.46it/s]\n",
      "Train 245 | out_loss 13.275313377380371: 100%|███| 8/8 [00:00<00:00, 105.89it/s]\n",
      "Train 246 | out_loss 13.29243278503418: 100%|████| 8/8 [00:00<00:00, 101.91it/s]\n",
      "Train 247 | out_loss 13.311423301696777: 100%|███| 8/8 [00:00<00:00, 113.74it/s]\n",
      "Train 248 | out_loss 13.323840141296387: 100%|███| 8/8 [00:00<00:00, 109.34it/s]\n",
      "Train 249 | out_loss 13.286636352539062: 100%|███| 8/8 [00:00<00:00, 103.43it/s]\n",
      "Train 250 | out_loss 13.292333602905273: 100%|███| 8/8 [00:00<00:00, 110.34it/s]\n",
      "Train 251 | out_loss 13.327409744262695: 100%|███| 8/8 [00:00<00:00, 101.47it/s]\n",
      "Train 252 | out_loss 13.274645805358887: 100%|███| 8/8 [00:00<00:00, 110.49it/s]\n",
      "Train 253 | out_loss 13.326014518737793: 100%|███| 8/8 [00:00<00:00, 107.02it/s]\n",
      "Train 254 | out_loss 13.316245079040527: 100%|████| 8/8 [00:00<00:00, 92.06it/s]\n",
      "Train 255 | out_loss 13.391828536987305: 100%|███| 8/8 [00:00<00:00, 108.43it/s]\n",
      "Train 256 | out_loss 13.351614952087402: 100%|███| 8/8 [00:00<00:00, 108.64it/s]\n",
      "Train 257 | out_loss 13.345013618469238: 100%|███| 8/8 [00:00<00:00, 110.52it/s]\n",
      "Train 258 | out_loss 13.375155448913574: 100%|███| 8/8 [00:00<00:00, 108.19it/s]\n",
      "Train 259 | out_loss 13.326461791992188: 100%|███| 8/8 [00:00<00:00, 108.52it/s]\n",
      "Train 260 | out_loss 13.32162857055664: 100%|████| 8/8 [00:00<00:00, 111.91it/s]\n",
      "Train 261 | out_loss 13.415276527404785: 100%|███| 8/8 [00:00<00:00, 102.41it/s]\n",
      "Train 262 | out_loss 13.279580116271973: 100%|████| 8/8 [00:00<00:00, 91.07it/s]\n",
      "Train 263 | out_loss 13.273941040039062: 100%|████| 8/8 [00:00<00:00, 93.57it/s]\n",
      "Train 264 | out_loss 13.268004417419434: 100%|███| 8/8 [00:00<00:00, 106.82it/s]\n",
      "Train 265 | out_loss 13.308481216430664: 100%|███| 8/8 [00:00<00:00, 109.26it/s]\n",
      "Train 266 | out_loss 13.3036470413208: 100%|█████| 8/8 [00:00<00:00, 109.16it/s]\n",
      "Train 267 | out_loss 13.351265907287598: 100%|███| 8/8 [00:00<00:00, 106.71it/s]\n",
      "Train 268 | out_loss 13.277098655700684: 100%|███| 8/8 [00:00<00:00, 109.27it/s]\n",
      "Train 269 | out_loss 13.313366889953613: 100%|████| 8/8 [00:00<00:00, 97.71it/s]\n",
      "Train 270 | out_loss 13.286086082458496: 100%|███| 8/8 [00:00<00:00, 106.00it/s]\n",
      "Train 271 | out_loss 13.294599533081055: 100%|███| 8/8 [00:00<00:00, 101.38it/s]\n",
      "Train 272 | out_loss 13.330108642578125: 100%|███| 8/8 [00:00<00:00, 113.65it/s]\n",
      "Train 273 | out_loss 13.300646781921387: 100%|███| 8/8 [00:00<00:00, 110.10it/s]\n",
      "Train 274 | out_loss 13.278990745544434: 100%|███| 8/8 [00:00<00:00, 109.99it/s]\n",
      "Train 275 | out_loss 13.309207916259766: 100%|███| 8/8 [00:00<00:00, 100.57it/s]\n",
      "Train 276 | out_loss 13.378111839294434: 100%|████| 8/8 [00:00<00:00, 99.92it/s]\n",
      "Train 277 | out_loss 13.277634620666504: 100%|███| 8/8 [00:00<00:00, 106.84it/s]\n",
      "Train 278 | out_loss 13.299281120300293: 100%|███| 8/8 [00:00<00:00, 102.51it/s]\n",
      "Train 279 | out_loss 13.292718887329102: 100%|████| 8/8 [00:00<00:00, 93.08it/s]\n",
      "Train 280 | out_loss 13.298294067382812: 100%|███| 8/8 [00:00<00:00, 108.79it/s]\n",
      "Train 281 | out_loss 13.29378890991211: 100%|████| 8/8 [00:00<00:00, 102.98it/s]\n",
      "Train 282 | out_loss 13.280725479125977: 100%|████| 8/8 [00:00<00:00, 95.78it/s]\n",
      "Train 283 | out_loss 13.363001823425293: 100%|████| 8/8 [00:00<00:00, 99.14it/s]\n",
      "Train 284 | out_loss 13.315900802612305: 100%|████| 8/8 [00:00<00:00, 96.81it/s]\n",
      "Train 285 | out_loss 13.273283004760742: 100%|███| 8/8 [00:00<00:00, 108.12it/s]\n",
      "Train 286 | out_loss 13.318472862243652: 100%|███| 8/8 [00:00<00:00, 109.52it/s]\n",
      "Train 287 | out_loss 13.274714469909668: 100%|███| 8/8 [00:00<00:00, 107.96it/s]\n",
      "Train 288 | out_loss 13.28813648223877: 100%|████| 8/8 [00:00<00:00, 109.87it/s]\n",
      "Train 289 | out_loss 13.291780471801758: 100%|███| 8/8 [00:00<00:00, 115.42it/s]\n",
      "Train 290 | out_loss 13.286154747009277: 100%|███| 8/8 [00:00<00:00, 100.34it/s]\n",
      "Train 291 | out_loss 13.29685115814209: 100%|█████| 8/8 [00:00<00:00, 94.09it/s]\n",
      "Train 292 | out_loss 13.324787139892578: 100%|███| 8/8 [00:00<00:00, 101.64it/s]\n",
      "Train 293 | out_loss 13.31492805480957: 100%|████| 8/8 [00:00<00:00, 103.95it/s]\n",
      "Train 294 | out_loss 13.278475761413574: 100%|███| 8/8 [00:00<00:00, 109.10it/s]\n",
      "Train 295 | out_loss 13.307044982910156: 100%|███| 8/8 [00:00<00:00, 101.52it/s]\n",
      "Train 296 | out_loss 13.315436363220215: 100%|███| 8/8 [00:00<00:00, 108.57it/s]\n",
      "Train 297 | out_loss 13.29094409942627: 100%|████| 8/8 [00:00<00:00, 110.49it/s]\n",
      "Train 298 | out_loss 13.311917304992676: 100%|████| 8/8 [00:00<00:00, 96.51it/s]\n",
      "Train 299 | out_loss 13.349239349365234: 100%|███| 8/8 [00:00<00:00, 104.39it/s]\n",
      "Train 300 | out_loss 13.295063018798828: 100%|████| 8/8 [00:00<00:00, 99.31it/s]\n",
      "Train 301 | out_loss 13.304362297058105: 100%|███| 8/8 [00:00<00:00, 104.92it/s]\n",
      "Train 302 | out_loss 13.304201126098633: 100%|███| 8/8 [00:00<00:00, 110.96it/s]\n",
      "Train 303 | out_loss 13.315027236938477: 100%|███| 8/8 [00:00<00:00, 103.65it/s]\n",
      "Train 304 | out_loss 13.292503356933594: 100%|███| 8/8 [00:00<00:00, 101.60it/s]\n",
      "Train 305 | out_loss 13.272680282592773: 100%|███| 8/8 [00:00<00:00, 101.73it/s]\n",
      "Train 306 | out_loss 13.279136657714844: 100%|███| 8/8 [00:00<00:00, 113.54it/s]\n",
      "Train 307 | out_loss 13.333818435668945: 100%|███| 8/8 [00:00<00:00, 113.17it/s]\n",
      "Train 308 | out_loss 13.357276916503906: 100%|███| 8/8 [00:00<00:00, 106.23it/s]\n",
      "Train 309 | out_loss 13.28272533416748: 100%|████| 8/8 [00:00<00:00, 107.38it/s]\n",
      "Train 310 | out_loss 13.292245864868164: 100%|████| 8/8 [00:00<00:00, 89.70it/s]\n",
      "Train 311 | out_loss 13.288298606872559: 100%|███| 8/8 [00:00<00:00, 108.91it/s]\n",
      "Train 312 | out_loss 13.29433822631836: 100%|████| 8/8 [00:00<00:00, 112.04it/s]\n",
      "Train 313 | out_loss 13.27990436553955: 100%|████| 8/8 [00:00<00:00, 107.02it/s]\n",
      "Train 314 | out_loss 13.267823219299316: 100%|███| 8/8 [00:00<00:00, 104.35it/s]\n",
      "Train 315 | out_loss 13.25083065032959: 100%|████| 8/8 [00:00<00:00, 110.61it/s]\n",
      "Train 316 | out_loss 13.275009155273438: 100%|███| 8/8 [00:00<00:00, 111.46it/s]\n",
      "Train 317 | out_loss 13.255827903747559: 100%|███| 8/8 [00:00<00:00, 110.49it/s]\n",
      "Train 318 | out_loss 13.270820617675781: 100%|███| 8/8 [00:00<00:00, 114.18it/s]\n",
      "Train 319 | out_loss 13.290273666381836: 100%|███| 8/8 [00:00<00:00, 110.24it/s]\n",
      "Train 320 | out_loss 13.411645889282227: 100%|███| 8/8 [00:00<00:00, 111.68it/s]\n",
      "Train 321 | out_loss 13.257162094116211: 100%|███| 8/8 [00:00<00:00, 111.24it/s]\n",
      "Train 322 | out_loss 13.292200088500977: 100%|████| 8/8 [00:00<00:00, 95.29it/s]\n",
      "Train 323 | out_loss 13.307791709899902: 100%|███| 8/8 [00:00<00:00, 106.66it/s]\n",
      "Train 324 | out_loss 13.358000755310059: 100%|███| 8/8 [00:00<00:00, 108.90it/s]\n",
      "Train 325 | out_loss 13.308701515197754: 100%|███| 8/8 [00:00<00:00, 109.27it/s]\n",
      "Train 326 | out_loss 13.289824485778809: 100%|███| 8/8 [00:00<00:00, 103.37it/s]\n",
      "Train 327 | out_loss 13.282539367675781: 100%|███| 8/8 [00:00<00:00, 108.17it/s]\n",
      "Train 328 | out_loss 13.288222312927246: 100%|████| 8/8 [00:00<00:00, 96.78it/s]\n",
      "Train 329 | out_loss 13.290488243103027: 100%|███| 8/8 [00:00<00:00, 107.85it/s]\n",
      "Train 330 | out_loss 13.290732383728027: 100%|███| 8/8 [00:00<00:00, 109.59it/s]\n",
      "Train 331 | out_loss 13.246186256408691: 100%|███| 8/8 [00:00<00:00, 111.63it/s]\n",
      "Train 332 | out_loss 13.250570297241211: 100%|███| 8/8 [00:00<00:00, 107.58it/s]\n",
      "Train 333 | out_loss 13.236393928527832: 100%|███| 8/8 [00:00<00:00, 103.92it/s]\n",
      "Train 334 | out_loss 13.230695724487305: 100%|███| 8/8 [00:00<00:00, 104.95it/s]\n",
      "Train 335 | out_loss 13.251416206359863: 100%|███| 8/8 [00:00<00:00, 113.88it/s]\n",
      "Train 336 | out_loss 13.28410816192627: 100%|████| 8/8 [00:00<00:00, 109.32it/s]\n",
      "Train 337 | out_loss 13.299577713012695: 100%|███| 8/8 [00:00<00:00, 105.75it/s]\n",
      "Train 338 | out_loss 13.248645782470703: 100%|███| 8/8 [00:00<00:00, 109.35it/s]\n",
      "Train 339 | out_loss 13.254417419433594: 100%|███| 8/8 [00:00<00:00, 109.73it/s]\n",
      "Train 340 | out_loss 13.211748123168945: 100%|███| 8/8 [00:00<00:00, 111.14it/s]\n",
      "Train 341 | out_loss 13.202917098999023: 100%|███| 8/8 [00:00<00:00, 104.65it/s]\n",
      "Train 342 | out_loss 13.224503517150879: 100%|███| 8/8 [00:00<00:00, 111.04it/s]\n",
      "Train 343 | out_loss 13.224963188171387: 100%|███| 8/8 [00:00<00:00, 110.12it/s]\n",
      "Train 344 | out_loss 13.281838417053223: 100%|████| 8/8 [00:00<00:00, 98.87it/s]\n",
      "Train 345 | out_loss 13.226201057434082: 100%|███| 8/8 [00:00<00:00, 108.39it/s]\n",
      "Train 346 | out_loss 13.210128784179688: 100%|███| 8/8 [00:00<00:00, 111.93it/s]\n",
      "Train 347 | out_loss 13.200307846069336: 100%|███| 8/8 [00:00<00:00, 105.68it/s]\n",
      "Train 348 | out_loss 13.225221633911133: 100%|███| 8/8 [00:00<00:00, 112.18it/s]\n",
      "Train 349 | out_loss 13.221474647521973: 100%|███| 8/8 [00:00<00:00, 111.25it/s]\n",
      "Train 350 | out_loss 13.255711555480957: 100%|███| 8/8 [00:00<00:00, 111.69it/s]\n",
      "Train 351 | out_loss 13.268889427185059: 100%|███| 8/8 [00:00<00:00, 107.73it/s]\n",
      "Train 352 | out_loss 13.222652435302734: 100%|███| 8/8 [00:00<00:00, 110.08it/s]\n",
      "Train 353 | out_loss 13.259308815002441: 100%|███| 8/8 [00:00<00:00, 104.15it/s]\n",
      "Train 354 | out_loss 13.169357299804688: 100%|███| 8/8 [00:00<00:00, 111.03it/s]\n",
      "Train 355 | out_loss 13.185373306274414: 100%|███| 8/8 [00:00<00:00, 112.35it/s]\n",
      "Train 356 | out_loss 13.158384323120117: 100%|███| 8/8 [00:00<00:00, 109.00it/s]\n",
      "Train 357 | out_loss 13.146797180175781: 100%|████| 8/8 [00:00<00:00, 80.01it/s]\n",
      "Train 358 | out_loss 13.310470581054688: 100%|████| 8/8 [00:00<00:00, 99.92it/s]\n",
      "Train 359 | out_loss 13.281583786010742: 100%|███| 8/8 [00:00<00:00, 111.07it/s]\n",
      "Train 360 | out_loss 13.30537223815918: 100%|████| 8/8 [00:00<00:00, 102.79it/s]\n",
      "Train 361 | out_loss 13.191524505615234: 100%|███| 8/8 [00:00<00:00, 109.94it/s]\n",
      "Train 362 | out_loss 13.305848121643066: 100%|███| 8/8 [00:00<00:00, 106.17it/s]\n",
      "Train 363 | out_loss 13.185872077941895: 100%|███| 8/8 [00:00<00:00, 114.11it/s]\n",
      "Train 364 | out_loss 13.312171936035156: 100%|███| 8/8 [00:00<00:00, 110.21it/s]\n",
      "Train 365 | out_loss 13.186120986938477: 100%|███| 8/8 [00:00<00:00, 110.57it/s]\n",
      "Train 366 | out_loss 13.201760292053223: 100%|███| 8/8 [00:00<00:00, 100.49it/s]\n",
      "Train 367 | out_loss 13.279989242553711: 100%|███| 8/8 [00:00<00:00, 107.53it/s]\n",
      "Train 368 | out_loss 13.170309066772461: 100%|███| 8/8 [00:00<00:00, 108.31it/s]\n",
      "Train 369 | out_loss 13.234989166259766: 100%|███| 8/8 [00:00<00:00, 101.40it/s]\n",
      "Train 370 | out_loss 13.296195030212402: 100%|████| 8/8 [00:00<00:00, 93.59it/s]\n",
      "Train 371 | out_loss 13.279691696166992: 100%|███| 8/8 [00:00<00:00, 103.96it/s]\n",
      "Train 372 | out_loss 13.283197402954102: 100%|███| 8/8 [00:00<00:00, 101.92it/s]\n",
      "Train 373 | out_loss 13.2815580368042: 100%|██████| 8/8 [00:00<00:00, 94.18it/s]\n",
      "Train 374 | out_loss 13.340797424316406: 100%|████| 8/8 [00:00<00:00, 99.99it/s]\n",
      "Train 375 | out_loss 13.309614181518555: 100%|███| 8/8 [00:00<00:00, 108.38it/s]\n",
      "Train 376 | out_loss 13.303229331970215: 100%|███| 8/8 [00:00<00:00, 109.85it/s]\n",
      "Train 377 | out_loss 13.293309211730957: 100%|███| 8/8 [00:00<00:00, 101.07it/s]\n",
      "Train 378 | out_loss 13.285286903381348: 100%|███| 8/8 [00:00<00:00, 103.63it/s]\n",
      "Train 379 | out_loss 13.299997329711914: 100%|███| 8/8 [00:00<00:00, 104.48it/s]\n",
      "Train 380 | out_loss 13.292181015014648: 100%|████| 8/8 [00:00<00:00, 95.05it/s]\n",
      "Train 381 | out_loss 13.297022819519043: 100%|███| 8/8 [00:00<00:00, 109.84it/s]\n",
      "Train 382 | out_loss 13.337368965148926: 100%|███| 8/8 [00:00<00:00, 110.40it/s]\n",
      "Train 383 | out_loss 13.282276153564453: 100%|███| 8/8 [00:00<00:00, 106.75it/s]\n",
      "Train 384 | out_loss 13.31375503540039: 100%|████| 8/8 [00:00<00:00, 106.57it/s]\n",
      "Train 385 | out_loss 13.305045127868652: 100%|███| 8/8 [00:00<00:00, 102.86it/s]\n",
      "Train 386 | out_loss 13.281930923461914: 100%|████| 8/8 [00:00<00:00, 78.76it/s]\n",
      "Train 387 | out_loss 13.309163093566895: 100%|███| 8/8 [00:00<00:00, 105.35it/s]\n",
      "Train 388 | out_loss 13.310215950012207: 100%|███| 8/8 [00:00<00:00, 107.98it/s]\n",
      "Train 389 | out_loss 13.319746971130371: 100%|███| 8/8 [00:00<00:00, 104.54it/s]\n",
      "Train 390 | out_loss 13.343481063842773: 100%|███| 8/8 [00:00<00:00, 102.09it/s]\n",
      "Train 391 | out_loss 13.320674896240234: 100%|████| 8/8 [00:00<00:00, 89.78it/s]\n",
      "Train 392 | out_loss 13.294958114624023: 100%|███| 8/8 [00:00<00:00, 108.81it/s]\n",
      "Train 393 | out_loss 13.2964506149292: 100%|█████| 8/8 [00:00<00:00, 110.90it/s]\n",
      "Train 394 | out_loss 13.301894187927246: 100%|███| 8/8 [00:00<00:00, 108.26it/s]\n",
      "Train 395 | out_loss 13.299649238586426: 100%|███| 8/8 [00:00<00:00, 109.96it/s]\n",
      "Train 396 | out_loss 13.295981407165527: 100%|███| 8/8 [00:00<00:00, 111.28it/s]\n",
      "Train 397 | out_loss 13.300589561462402: 100%|███| 8/8 [00:00<00:00, 106.55it/s]\n",
      "Train 398 | out_loss 13.295391082763672: 100%|███| 8/8 [00:00<00:00, 104.87it/s]\n",
      "Train 399 | out_loss 13.287235260009766: 100%|████| 8/8 [00:00<00:00, 96.11it/s]\n",
      "Train 400 | out_loss 13.299367904663086: 100%|███| 8/8 [00:00<00:00, 107.12it/s]\n",
      "Train 401 | out_loss 13.297471046447754: 100%|███| 8/8 [00:00<00:00, 106.65it/s]\n",
      "Train 402 | out_loss 13.293220520019531: 100%|███| 8/8 [00:00<00:00, 101.61it/s]\n",
      "Train 403 | out_loss 13.296611785888672: 100%|███| 8/8 [00:00<00:00, 106.64it/s]\n",
      "Train 404 | out_loss 13.305502891540527: 100%|███| 8/8 [00:00<00:00, 105.20it/s]\n",
      "Train 405 | out_loss 13.297996520996094: 100%|███| 8/8 [00:00<00:00, 109.83it/s]\n",
      "Train 406 | out_loss 13.298883438110352: 100%|███| 8/8 [00:00<00:00, 108.75it/s]\n",
      "Train 407 | out_loss 13.29549789428711: 100%|█████| 8/8 [00:00<00:00, 91.13it/s]\n",
      "Train 408 | out_loss 13.281219482421875: 100%|███| 8/8 [00:00<00:00, 100.23it/s]\n",
      "Train 409 | out_loss 13.29905891418457: 100%|█████| 8/8 [00:00<00:00, 95.48it/s]\n",
      "Train 410 | out_loss 13.274406433105469: 100%|████| 8/8 [00:00<00:00, 96.93it/s]\n",
      "Train 411 | out_loss 13.287001609802246: 100%|████| 8/8 [00:00<00:00, 98.11it/s]\n",
      "Train 412 | out_loss 13.309473991394043: 100%|████| 8/8 [00:00<00:00, 97.55it/s]\n",
      "Train 413 | out_loss 13.296462059020996: 100%|████| 8/8 [00:00<00:00, 97.20it/s]\n",
      "Train 414 | out_loss 13.293883323669434: 100%|███| 8/8 [00:00<00:00, 101.84it/s]\n",
      "Train 415 | out_loss 13.295781135559082: 100%|████| 8/8 [00:00<00:00, 93.50it/s]\n",
      "Train 416 | out_loss 13.286520004272461: 100%|███| 8/8 [00:00<00:00, 107.84it/s]\n",
      "Train 417 | out_loss 13.285699844360352: 100%|████| 8/8 [00:00<00:00, 86.32it/s]\n",
      "Train 418 | out_loss 13.272632598876953: 100%|████| 8/8 [00:00<00:00, 93.06it/s]\n",
      "Train 419 | out_loss 13.28823184967041: 100%|████| 8/8 [00:00<00:00, 103.54it/s]\n",
      "Train 420 | out_loss 13.328789710998535: 100%|████| 8/8 [00:00<00:00, 88.72it/s]\n",
      "Train 421 | out_loss 13.279273986816406: 100%|███| 8/8 [00:00<00:00, 105.77it/s]\n",
      "Train 422 | out_loss 13.29910945892334: 100%|████| 8/8 [00:00<00:00, 104.09it/s]\n",
      "Train 423 | out_loss 13.294343948364258: 100%|███| 8/8 [00:00<00:00, 109.98it/s]\n",
      "Train 424 | out_loss 13.300683975219727: 100%|████| 8/8 [00:00<00:00, 99.89it/s]\n",
      "Train 425 | out_loss 13.304793357849121: 100%|███| 8/8 [00:00<00:00, 113.98it/s]\n",
      "Train 426 | out_loss 13.294379234313965: 100%|███| 8/8 [00:00<00:00, 108.12it/s]\n",
      "Train 427 | out_loss 13.295209884643555: 100%|███| 8/8 [00:00<00:00, 111.08it/s]\n",
      "Train 428 | out_loss 13.299362182617188: 100%|███| 8/8 [00:00<00:00, 109.37it/s]\n",
      "Train 429 | out_loss 13.300004959106445: 100%|███| 8/8 [00:00<00:00, 110.81it/s]\n",
      "Train 430 | out_loss 13.358333587646484: 100%|████| 8/8 [00:00<00:00, 99.12it/s]\n",
      "Train 431 | out_loss 13.297222137451172: 100%|███| 8/8 [00:00<00:00, 109.28it/s]\n",
      "Train 432 | out_loss 13.294158935546875: 100%|███| 8/8 [00:00<00:00, 110.00it/s]\n",
      "Train 433 | out_loss 13.27212142944336: 100%|█████| 8/8 [00:00<00:00, 93.29it/s]\n",
      "Train 434 | out_loss 13.284537315368652: 100%|███| 8/8 [00:00<00:00, 108.44it/s]\n",
      "Train 435 | out_loss 13.25473690032959: 100%|█████| 8/8 [00:00<00:00, 96.72it/s]\n",
      "Train 436 | out_loss 13.30682373046875: 100%|████| 8/8 [00:00<00:00, 105.85it/s]\n",
      "Train 437 | out_loss 13.303753852844238: 100%|███| 8/8 [00:00<00:00, 105.20it/s]\n",
      "Train 438 | out_loss 13.282684326171875: 100%|███| 8/8 [00:00<00:00, 103.21it/s]\n",
      "Train 439 | out_loss 13.298534393310547: 100%|███| 8/8 [00:00<00:00, 102.18it/s]\n",
      "Train 440 | out_loss 13.28441047668457: 100%|████| 8/8 [00:00<00:00, 111.99it/s]\n",
      "Train 441 | out_loss 13.285511016845703: 100%|███| 8/8 [00:00<00:00, 112.31it/s]\n",
      "Train 442 | out_loss 13.29919147491455: 100%|████| 8/8 [00:00<00:00, 110.61it/s]\n",
      "Train 443 | out_loss 13.303609848022461: 100%|███| 8/8 [00:00<00:00, 111.42it/s]\n",
      "Train 444 | out_loss 13.288581848144531: 100%|███| 8/8 [00:00<00:00, 109.05it/s]\n",
      "Train 445 | out_loss 13.285435676574707: 100%|████| 8/8 [00:00<00:00, 99.32it/s]\n",
      "Train 446 | out_loss 13.28603458404541: 100%|████| 8/8 [00:00<00:00, 109.30it/s]\n",
      "Train 447 | out_loss 13.304080963134766: 100%|███| 8/8 [00:00<00:00, 106.48it/s]\n",
      "Train 448 | out_loss 13.307049751281738: 100%|███| 8/8 [00:00<00:00, 112.75it/s]\n",
      "Train 449 | out_loss 13.305340766906738: 100%|███| 8/8 [00:00<00:00, 108.37it/s]\n",
      "Train 450 | out_loss 13.315563201904297: 100%|████| 8/8 [00:00<00:00, 94.90it/s]\n",
      "Train 451 | out_loss 13.266425132751465: 100%|███| 8/8 [00:00<00:00, 110.46it/s]\n",
      "Train 452 | out_loss 13.268548011779785: 100%|███| 8/8 [00:00<00:00, 101.08it/s]\n",
      "Train 453 | out_loss 13.302519798278809: 100%|████| 8/8 [00:00<00:00, 97.86it/s]\n",
      "Train 454 | out_loss 13.25805950164795: 100%|████| 8/8 [00:00<00:00, 114.15it/s]\n",
      "Train 455 | out_loss 13.289161682128906: 100%|███| 8/8 [00:00<00:00, 106.08it/s]\n",
      "Train 456 | out_loss 13.302207946777344: 100%|████| 8/8 [00:00<00:00, 97.95it/s]\n",
      "Train 457 | out_loss 13.283053398132324: 100%|███| 8/8 [00:00<00:00, 108.16it/s]\n",
      "Train 458 | out_loss 13.2988862991333: 100%|█████| 8/8 [00:00<00:00, 111.46it/s]\n",
      "Train 459 | out_loss 13.26052188873291: 100%|█████| 8/8 [00:00<00:00, 88.04it/s]\n",
      "Train 460 | out_loss 13.297307968139648: 100%|███| 8/8 [00:00<00:00, 104.54it/s]\n",
      "Train 461 | out_loss 13.272174835205078: 100%|████| 8/8 [00:00<00:00, 98.18it/s]\n",
      "Train 462 | out_loss 13.302274703979492: 100%|████| 8/8 [00:00<00:00, 96.09it/s]\n",
      "Train 463 | out_loss 13.313756942749023: 100%|███| 8/8 [00:00<00:00, 104.37it/s]\n",
      "Train 464 | out_loss 13.30901050567627: 100%|█████| 8/8 [00:00<00:00, 88.37it/s]\n",
      "Train 465 | out_loss 13.325971603393555: 100%|███| 8/8 [00:00<00:00, 111.30it/s]\n",
      "Train 466 | out_loss 13.316384315490723: 100%|███| 8/8 [00:00<00:00, 107.95it/s]\n",
      "Train 467 | out_loss 13.364934921264648: 100%|███| 8/8 [00:00<00:00, 106.99it/s]\n",
      "Train 468 | out_loss 13.309431076049805: 100%|███| 8/8 [00:00<00:00, 114.74it/s]\n",
      "Train 469 | out_loss 13.30359172821045: 100%|████| 8/8 [00:00<00:00, 108.94it/s]\n",
      "Train 470 | out_loss 13.295388221740723: 100%|███| 8/8 [00:00<00:00, 112.70it/s]\n",
      "Train 471 | out_loss 13.289596557617188: 100%|███| 8/8 [00:00<00:00, 109.52it/s]\n",
      "Train 472 | out_loss 13.314773559570312: 100%|███| 8/8 [00:00<00:00, 109.58it/s]\n",
      "Train 473 | out_loss 13.300044059753418: 100%|███| 8/8 [00:00<00:00, 109.47it/s]\n",
      "Train 474 | out_loss 13.28419303894043: 100%|█████| 8/8 [00:00<00:00, 94.76it/s]\n",
      "Train 475 | out_loss 13.34426498413086: 100%|█████| 8/8 [00:00<00:00, 97.03it/s]\n",
      "Train 476 | out_loss 13.291482925415039: 100%|███| 8/8 [00:00<00:00, 104.87it/s]\n",
      "Train 477 | out_loss 13.319458961486816: 100%|███| 8/8 [00:00<00:00, 113.43it/s]\n",
      "Train 478 | out_loss 13.29726791381836: 100%|████| 8/8 [00:00<00:00, 111.64it/s]\n",
      "Train 479 | out_loss 13.36396598815918: 100%|████| 8/8 [00:00<00:00, 110.08it/s]\n",
      "Train 480 | out_loss 13.33230972290039: 100%|████| 8/8 [00:00<00:00, 115.79it/s]\n",
      "Train 481 | out_loss 13.362884521484375: 100%|███| 8/8 [00:00<00:00, 107.28it/s]\n",
      "Train 482 | out_loss 13.336784362792969: 100%|████| 8/8 [00:00<00:00, 98.42it/s]\n",
      "Train 483 | out_loss 13.33545207977295: 100%|████| 8/8 [00:00<00:00, 114.89it/s]\n",
      "Train 484 | out_loss 13.311105728149414: 100%|███| 8/8 [00:00<00:00, 112.53it/s]\n",
      "Train 485 | out_loss 13.301026344299316: 100%|███| 8/8 [00:00<00:00, 105.01it/s]\n",
      "Train 486 | out_loss 13.390138626098633: 100%|███| 8/8 [00:00<00:00, 105.71it/s]\n",
      "Train 487 | out_loss 13.336297035217285: 100%|███| 8/8 [00:00<00:00, 107.71it/s]\n",
      "Train 488 | out_loss 13.31125545501709: 100%|████| 8/8 [00:00<00:00, 108.99it/s]\n",
      "Train 489 | out_loss 13.304032325744629: 100%|███| 8/8 [00:00<00:00, 112.68it/s]\n",
      "Train 490 | out_loss 13.276357650756836: 100%|███| 8/8 [00:00<00:00, 109.92it/s]\n",
      "Train 491 | out_loss 13.307311058044434: 100%|███| 8/8 [00:00<00:00, 106.35it/s]\n",
      "Train 492 | out_loss 13.290702819824219: 100%|████| 8/8 [00:00<00:00, 97.20it/s]\n",
      "Train 493 | out_loss 13.305631637573242: 100%|███| 8/8 [00:00<00:00, 101.86it/s]\n",
      "Train 494 | out_loss 13.336350440979004: 100%|████| 8/8 [00:00<00:00, 86.56it/s]\n",
      "Train 495 | out_loss 13.323163986206055: 100%|████| 8/8 [00:00<00:00, 94.44it/s]\n",
      "Train 496 | out_loss 13.32464599609375: 100%|████| 8/8 [00:00<00:00, 107.97it/s]\n",
      "Train 497 | out_loss 13.363736152648926: 100%|███| 8/8 [00:00<00:00, 105.68it/s]\n",
      "Train 498 | out_loss 13.32357406616211: 100%|████| 8/8 [00:00<00:00, 101.91it/s]\n",
      "Train 499 | out_loss 13.297624588012695: 100%|███| 8/8 [00:00<00:00, 101.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# LinearAL \n",
    "\n",
    "data = \"paint\"\n",
    "model =  \"linearal\"\n",
    "for layer in range(1,11):\n",
    "#for layer in [3]:\n",
    "    log = f\"result/{data}_{model}_l{layer}.log\"\n",
    "    !python3 dis_train_al.py --dataset {data} --model {model} --epoch 500 --num-layer {layer} --task regression  > {log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ae70865",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/AL_main_new/new dataset.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.115.59.235/home/AL_main_new/new%20dataset.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.115.59.235/home/AL_main_new/new%20dataset.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B140.115.59.235/home/AL_main_new/new%20dataset.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m args\u001b[39m.\u001b[39mtask \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mregression\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.115.59.235/home/AL_main_new/new%20dataset.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m args\u001b[39m.\u001b[39mfeature_dim \u001b[39m=\u001b[39m \u001b[39m40\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B140.115.59.235/home/AL_main_new/new%20dataset.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m df \u001b[39m=\u001b[39m load_dataset(\u001b[39m'\u001b[39m\u001b[39mLL0_296_ailerons\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "from mit_d3m import load_dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "args.task = \"regression\"\n",
    "args.feature_dim = 40\n",
    "df = load_dataset('LL0_296_ailerons')\n",
    "\n",
    "col_feature = df.X.columns[1:]\n",
    "#col_target= df.y.columns[:]\n",
    "\n",
    "y = df.y\n",
    "x = df.X[col_feature]\n",
    "x = x.fillna(0)\n",
    "feature_train, feature_test, train_target, test_target = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "833b414e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8800,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7675b11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "  0%|                                                   | 0/138 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 0.21462807059288025: 100%|█| 138/138 [00:00<00:00, 253.36it/s\n",
      "[[ 0.7608826  26.74478777]]\n",
      "Train Epoch0 out_loss 0.21462807059288025\n",
      "Test Epoch0 layer0 out_loss 0.1563311666250229\n",
      "Train 1 | out_loss 0.11643515527248383: 100%|█| 138/138 [00:00<00:00, 813.89it/s\n",
      "[[2.26927448e-05 5.69785894e+00]]\n",
      "Train Epoch1 out_loss 0.11643515527248383\n",
      "Test Epoch1 layer0 out_loss 0.05716094374656677\n",
      "Train 2 | out_loss 0.09533262252807617: 100%|█| 138/138 [00:00<00:00, 811.21it/s\n",
      "[[2.18554886e-05 2.97949706e+00]]\n",
      "Train Epoch2 out_loss 0.09533262252807617\n",
      "Test Epoch2 layer0 out_loss 0.11699116975069046\n",
      "Train 3 | out_loss 0.066607266664505: 100%|██| 138/138 [00:00<00:00, 789.94it/s]\n",
      "[[2.16810605e-05 1.49282748e+00]]\n",
      "Train Epoch3 out_loss 0.066607266664505\n",
      "Test Epoch3 layer0 out_loss 0.06255532801151276\n",
      "Train 4 | out_loss 0.04035916551947594: 100%|█| 138/138 [00:00<00:00, 819.36it/s\n",
      "[[2.16286632e-05 9.19612751e-01]]\n",
      "Train Epoch4 out_loss 0.04035916551947594\n",
      "Test Epoch4 layer0 out_loss 0.02381971664726734\n",
      "Train 5 | out_loss 0.03340898081660271: 100%|█| 138/138 [00:00<00:00, 815.21it/s\n",
      "[[2.14047560e-05 6.03253219e-01]]\n",
      "Train Epoch5 out_loss 0.03340898081660271\n",
      "Test Epoch5 layer0 out_loss 0.05841920152306557\n",
      "Train 6 | out_loss 0.06491685658693314: 100%|█| 138/138 [00:00<00:00, 803.24it/s\n",
      "[[2.13036024e-05 2.10214721e+00]]\n",
      "Train Epoch6 out_loss 0.06491685658693314\n",
      "Test Epoch6 layer0 out_loss 0.07979986071586609\n",
      "Train 7 | out_loss 0.057599153369665146: 100%|█| 138/138 [00:00<00:00, 808.79it/\n",
      "[[2.10714512e-05 1.42624738e+00]]\n",
      "Train Epoch7 out_loss 0.057599153369665146\n",
      "Test Epoch7 layer0 out_loss 0.03369564935564995\n",
      "Train 8 | out_loss 0.03069838508963585: 100%|█| 138/138 [00:00<00:00, 818.43it/s\n",
      "[[2.06829254e-05 5.70930403e-01]]\n",
      "Train Epoch8 out_loss 0.03069838508963585\n",
      "Test Epoch8 layer0 out_loss 0.018402457237243652\n",
      "Train 9 | out_loss 0.03383873030543327: 100%|█| 138/138 [00:00<00:00, 821.42it/s\n",
      "[[2.09425323e-05 4.97945699e-01]]\n",
      "Train Epoch9 out_loss 0.03383873030543327\n",
      "Test Epoch9 layer0 out_loss 0.03602129966020584\n",
      "Train 10 | out_loss 0.03580179437994957: 100%|█| 138/138 [00:00<00:00, 822.03it/\n",
      "[[2.04610774e-05 3.90893306e-01]]\n",
      "Train Epoch10 out_loss 0.03580179437994957\n",
      "Test Epoch10 layer0 out_loss 0.03170675039291382\n",
      "Train 11 | out_loss 0.042835112661123276: 100%|█| 138/138 [00:00<00:00, 820.89it\n",
      "[[2.04044782e-05 8.84619696e-01]]\n",
      "Train Epoch11 out_loss 0.042835112661123276\n",
      "Test Epoch11 layer0 out_loss 0.022988855838775635\n",
      "Train 12 | out_loss 0.03696515038609505: 100%|█| 138/138 [00:00<00:00, 806.05it/\n",
      "[[2.05574495e-05 3.15376728e-01]]\n",
      "Train Epoch12 out_loss 0.03696515038609505\n",
      "Test Epoch12 layer0 out_loss 0.06477012485265732\n",
      "Train 13 | out_loss 0.04638189822435379: 100%|█| 138/138 [00:00<00:00, 813.41it/\n",
      "[[1.91745514e-05 4.96372231e-01]]\n",
      "Train Epoch13 out_loss 0.04638189822435379\n",
      "Test Epoch13 layer0 out_loss 0.023154685273766518\n",
      "Train 14 | out_loss 0.03662984445691109: 100%|█| 138/138 [00:00<00:00, 787.58it/\n",
      "[[1.90315483e-05 6.14047745e-01]]\n",
      "Train Epoch14 out_loss 0.03662984445691109\n",
      "Test Epoch14 layer0 out_loss 0.02928004413843155\n",
      "Train 15 | out_loss 0.034117404371500015: 100%|█| 138/138 [00:00<00:00, 767.34it\n",
      "[[1.86377449e-05 4.58166766e-01]]\n",
      "Train Epoch15 out_loss 0.034117404371500015\n",
      "Test Epoch15 layer0 out_loss 0.03752470389008522\n",
      "Train 16 | out_loss 0.03220720961689949: 100%|█| 138/138 [00:00<00:00, 809.65it/\n",
      "[[1.84425265e-05 4.06751400e-01]]\n",
      "Train Epoch16 out_loss 0.03220720961689949\n",
      "Test Epoch16 layer0 out_loss 0.01865285448729992\n",
      "Train 17 | out_loss 0.035569965839385986: 100%|█| 138/138 [00:00<00:00, 794.79it\n",
      "[[1.79736581e-05 2.10121561e-01]]\n",
      "Train Epoch17 out_loss 0.035569965839385986\n",
      "Test Epoch17 layer0 out_loss 0.02665521949529648\n",
      "Train 18 | out_loss 0.0462179034948349: 100%|█| 138/138 [00:00<00:00, 791.72it/s\n",
      "[[1.72321226e-05 5.42803876e-01]]\n",
      "Train Epoch18 out_loss 0.0462179034948349\n",
      "Test Epoch18 layer0 out_loss 0.02044147253036499\n",
      "Train 19 | out_loss 0.036401137709617615: 100%|█| 138/138 [00:00<00:00, 788.37it\n",
      "[[1.74512451e-05 2.70725399e-01]]\n",
      "Train Epoch19 out_loss 0.036401137709617615\n",
      "Test Epoch19 layer0 out_loss 0.025772694498300552\n",
      "Train 20 | out_loss 0.01598249189555645: 100%|█| 138/138 [00:00<00:00, 804.09it/\n",
      "[[1.68037947e-05 1.07171601e-01]]\n",
      "Train Epoch20 out_loss 0.01598249189555645\n",
      "Test Epoch20 layer0 out_loss 0.008063392713665962\n",
      "Train 21 | out_loss 0.03460570052266121: 100%|█| 138/138 [00:00<00:00, 807.49it/\n",
      "[[1.64367359e-05 5.50620220e-01]]\n",
      "Train Epoch21 out_loss 0.03460570052266121\n",
      "Test Epoch21 layer0 out_loss 0.011713434010744095\n",
      "Train 22 | out_loss 0.022513529285788536: 100%|█| 138/138 [00:00<00:00, 816.13it\n",
      "[[1.57420036e-05 2.57767127e-01]]\n",
      "Train Epoch22 out_loss 0.022513529285788536\n",
      "Test Epoch22 layer0 out_loss 0.011457264423370361\n",
      "Train 23 | out_loss 0.017340796068310738: 100%|█| 138/138 [00:00<00:00, 790.55it\n",
      "[[1.54490290e-05 1.11280922e-01]]\n",
      "Train Epoch23 out_loss 0.017340796068310738\n",
      "Test Epoch23 layer0 out_loss 0.01550555694848299\n",
      "Train 24 | out_loss 0.027658876031637192: 100%|█| 138/138 [00:00<00:00, 809.81it\n",
      "[[1.50786803e-05 1.36982613e-01]]\n",
      "Train Epoch24 out_loss 0.027658876031637192\n",
      "Test Epoch24 layer0 out_loss 0.006914978846907616\n",
      "Train 25 | out_loss 0.02601049095392227: 100%|█| 138/138 [00:00<00:00, 794.74it/\n",
      "[[1.31161964e-05 3.57311968e-01]]\n",
      "Train Epoch25 out_loss 0.02601049095392227\n",
      "Test Epoch25 layer0 out_loss 0.03607485443353653\n",
      "Train 26 | out_loss 0.021923264488577843: 100%|█| 138/138 [00:00<00:00, 804.14it\n",
      "[[1.40590619e-05 3.09992646e-01]]\n",
      "Train Epoch26 out_loss 0.021923264488577843\n",
      "Test Epoch26 layer0 out_loss 0.006419003009796143\n",
      "Train 27 | out_loss 0.033442262560129166: 100%|█| 138/138 [00:00<00:00, 820.13it\n",
      "[[1.28669199e-05 3.48898426e-01]]\n",
      "Train Epoch27 out_loss 0.033442262560129166\n",
      "Test Epoch27 layer0 out_loss 0.01105737779289484\n",
      "Train 28 | out_loss 0.008520180359482765: 100%|█| 138/138 [00:00<00:00, 812.99it\n",
      "[[1.20859179e-05 2.05850768e-02]]\n",
      "Train Epoch28 out_loss 0.008520180359482765\n",
      "Test Epoch28 layer0 out_loss 0.009075451642274857\n",
      "Train 29 | out_loss 0.017537685111165047: 100%|█| 138/138 [00:00<00:00, 817.11it\n",
      "[[1.37116334e-05 2.01430975e-01]]\n",
      "Train Epoch29 out_loss 0.017537685111165047\n",
      "Test Epoch29 layer0 out_loss 0.01208307035267353\n",
      "Train 30 | out_loss 0.016453713178634644: 100%|█| 138/138 [00:00<00:00, 823.44it\n",
      "[[1.13483580e-05 8.38303514e-02]]\n",
      "Train Epoch30 out_loss 0.016453713178634644\n",
      "Test Epoch30 layer0 out_loss 0.010636554099619389\n",
      "Train 31 | out_loss 0.02810441516339779: 100%|█| 138/138 [00:00<00:00, 814.88it/\n",
      "[[1.05075808e-05 2.17016572e-01]]\n",
      "Train Epoch31 out_loss 0.02810441516339779\n",
      "Test Epoch31 layer0 out_loss 0.012276731431484222\n",
      "Train 32 | out_loss 0.025069674476981163: 100%|█| 138/138 [00:00<00:00, 814.91it\n",
      "[[9.47907062e-06 2.18709970e-01]]\n",
      "Train Epoch32 out_loss 0.025069674476981163\n",
      "Test Epoch32 layer0 out_loss 0.007052697241306305\n",
      "Train 33 | out_loss 0.009725874289870262: 100%|█| 138/138 [00:00<00:00, 795.56it\n",
      "[[9.57474096e-06 3.58167075e-02]]\n",
      "Train Epoch33 out_loss 0.009725874289870262\n",
      "Test Epoch33 layer0 out_loss 0.0047116572968661785\n",
      "Train 34 | out_loss 0.011783985421061516: 100%|█| 138/138 [00:00<00:00, 832.05it\n",
      "[[9.01260419e-06 6.06438320e-02]]\n",
      "Train Epoch34 out_loss 0.011783985421061516\n",
      "Test Epoch34 layer0 out_loss 0.010468900203704834\n",
      "Train 35 | out_loss 0.011149478144943714: 100%|█| 138/138 [00:00<00:00, 820.39it\n",
      "[[1.08437267e-05 5.76963937e-02]]\n",
      "Train Epoch35 out_loss 0.011149478144943714\n",
      "Test Epoch35 layer0 out_loss 0.011368552222847939\n",
      "Train 36 | out_loss 0.03218904882669449: 100%|█| 138/138 [00:00<00:00, 819.36it/\n",
      "[[8.60307396e-06 4.78194191e-01]]\n",
      "Train Epoch36 out_loss 0.03218904882669449\n",
      "Test Epoch36 layer0 out_loss 0.07989414036273956\n",
      "Train 37 | out_loss 0.023601755499839783: 100%|█| 138/138 [00:00<00:00, 815.81it\n",
      "[[7.28430129e-06 3.17469602e-01]]\n",
      "Train Epoch37 out_loss 0.023601755499839783\n",
      "Test Epoch37 layer0 out_loss 0.012219634838402271\n",
      "Train 38 | out_loss 0.017508920282125473: 100%|█| 138/138 [00:00<00:00, 809.26it\n",
      "[[1.13535769e-05 1.08997481e-01]]\n",
      "Train Epoch38 out_loss 0.017508920282125473\n",
      "Test Epoch38 layer0 out_loss 0.024866925552487373\n",
      "Train 39 | out_loss 0.011000556871294975: 100%|█| 138/138 [00:00<00:00, 810.83it\n",
      "[[7.70755375e-06 4.25611561e-02]]\n",
      "Train Epoch39 out_loss 0.011000556871294975\n",
      "Test Epoch39 layer0 out_loss 0.01087093260139227\n",
      "Train 40 | out_loss 0.015382552519440651: 100%|█| 138/138 [00:00<00:00, 732.56it\n",
      "[[1.34846447e-05 1.27452504e-01]]\n",
      "Train Epoch40 out_loss 0.015382552519440651\n",
      "Test Epoch40 layer0 out_loss 0.016894564032554626\n",
      "Train 41 | out_loss 0.021951811388134956: 100%|█| 138/138 [00:00<00:00, 818.66it\n",
      "[[3.00175306e-05 2.16864966e-01]]\n",
      "Train Epoch41 out_loss 0.021951811388134956\n",
      "Test Epoch41 layer0 out_loss 0.012879902496933937\n",
      "Train 42 | out_loss 0.00948809552937746: 100%|█| 138/138 [00:00<00:00, 790.16it/\n",
      "[[0.00041706 0.04174855]]\n",
      "Train Epoch42 out_loss 0.00948809552937746\n",
      "Test Epoch42 layer0 out_loss 0.0063330125994980335\n",
      "Train 43 | out_loss 0.007127155549824238: 100%|█| 138/138 [00:00<00:00, 808.30it\n",
      "[[0.0002687  0.01584223]]\n",
      "Train Epoch43 out_loss 0.007127155549824238\n",
      "Test Epoch43 layer0 out_loss 0.006097215227782726\n",
      "Train 44 | out_loss 0.013433299958705902: 100%|█| 138/138 [00:00<00:00, 799.76it\n",
      "[[0.00045717 0.19643522]]\n",
      "Train Epoch44 out_loss 0.013433299958705902\n",
      "Test Epoch44 layer0 out_loss 0.014305631630122662\n",
      "Train 45 | out_loss 0.014547135680913925: 100%|█| 138/138 [00:00<00:00, 810.51it\n",
      "[[0.00031086 0.08406834]]\n",
      "Train Epoch45 out_loss 0.014547135680913925\n",
      "Test Epoch45 layer0 out_loss 0.005607844330370426\n",
      "Train 46 | out_loss 0.009020879864692688: 100%|█| 138/138 [00:00<00:00, 806.38it\n",
      "[[0.00041511 0.04252589]]\n",
      "Train Epoch46 out_loss 0.009020879864692688\n",
      "Test Epoch46 layer0 out_loss 0.007945496588945389\n",
      "Train 47 | out_loss 0.012462209910154343: 100%|█| 138/138 [00:00<00:00, 811.33it\n",
      "[[0.0002499  0.05385622]]\n",
      "Train Epoch47 out_loss 0.012462209910154343\n",
      "Test Epoch47 layer0 out_loss 0.015445489436388016\n",
      "Train 48 | out_loss 0.029029659926891327: 100%|█| 138/138 [00:00<00:00, 808.26it\n",
      "[[3.11957751e-04 3.32600308e-01]]\n",
      "Train Epoch48 out_loss 0.029029659926891327\n",
      "Test Epoch48 layer0 out_loss 0.017599087208509445\n",
      "Train 49 | out_loss 0.015929043292999268: 100%|█| 138/138 [00:00<00:00, 792.80it\n",
      "[[0.00036164 0.07489846]]\n",
      "Train Epoch49 out_loss 0.015929043292999268\n",
      "Test Epoch49 layer0 out_loss 0.01371400710195303\n",
      "Train 50 | out_loss 0.011441688053309917: 100%|█| 138/138 [00:00<00:00, 794.56it\n",
      "[[0.00043417 0.03240839]]\n",
      "Train Epoch50 out_loss 0.011441688053309917\n",
      "Test Epoch50 layer0 out_loss 0.01633104681968689\n",
      "Train 51 | out_loss 0.0065882205963134766: 100%|█| 138/138 [00:00<00:00, 795.99i\n",
      "[[0.00040562 0.03394592]]\n",
      "Train Epoch51 out_loss 0.0065882205963134766\n",
      "Test Epoch51 layer0 out_loss 0.005768648348748684\n",
      "Train 52 | out_loss 0.022712403908371925: 100%|█| 138/138 [00:00<00:00, 794.90it\n",
      "[[0.00027468 0.19981849]]\n",
      "Train Epoch52 out_loss 0.022712403908371925\n",
      "Test Epoch52 layer0 out_loss 0.012653352692723274\n",
      "Train 53 | out_loss 0.01549970917403698: 100%|█| 138/138 [00:00<00:00, 812.18it/\n",
      "[[0.00018876 0.12628598]]\n",
      "Train Epoch53 out_loss 0.01549970917403698\n",
      "Test Epoch53 layer0 out_loss 0.0037481733597815037\n",
      "Train 54 | out_loss 0.004546266049146652: 100%|█| 138/138 [00:00<00:00, 781.42it\n",
      "[[0.00046337 0.00786371]]\n",
      "Train Epoch54 out_loss 0.004546266049146652\n",
      "Test Epoch54 layer0 out_loss 0.004748226143419743\n",
      "Train 55 | out_loss 0.006141353864222765: 100%|█| 138/138 [00:00<00:00, 818.36it\n",
      "[[0.00026888 0.01610439]]\n",
      "Train Epoch55 out_loss 0.006141353864222765\n",
      "Test Epoch55 layer0 out_loss 0.008846613578498363\n",
      "Train 56 | out_loss 0.011720435693860054: 100%|█| 138/138 [00:00<00:00, 787.06it\n",
      "[[0.00025033 0.05025224]]\n",
      "Train Epoch56 out_loss 0.011720435693860054\n",
      "Test Epoch56 layer0 out_loss 0.010550716891884804\n",
      "Train 57 | out_loss 0.01843511313199997: 100%|█| 138/138 [00:00<00:00, 800.99it/\n",
      "[[0.00051412 0.11265927]]\n",
      "Train Epoch57 out_loss 0.01843511313199997\n",
      "Test Epoch57 layer0 out_loss 0.010741894133388996\n",
      "Train 58 | out_loss 0.0064319465309381485: 100%|█| 138/138 [00:00<00:00, 813.91i\n",
      "[[0.00039924 0.02361996]]\n",
      "Train Epoch58 out_loss 0.0064319465309381485\n",
      "Test Epoch58 layer0 out_loss 0.014581510797142982\n",
      "Train 59 | out_loss 0.01843818835914135: 100%|█| 138/138 [00:00<00:00, 796.24it/\n",
      "[[0.0004395  0.21473858]]\n",
      "Train Epoch59 out_loss 0.01843818835914135\n",
      "Test Epoch59 layer0 out_loss 0.009647129103541374\n",
      "Train 60 | out_loss 0.008504975587129593: 100%|█| 138/138 [00:00<00:00, 828.45it\n",
      "[[9.53363556e-05 4.96685142e-02]]\n",
      "Train Epoch60 out_loss 0.008504975587129593\n",
      "Test Epoch60 layer0 out_loss 0.008042772300541401\n",
      "Train 61 | out_loss 0.0045076352544128895: 100%|█| 138/138 [00:00<00:00, 797.93i\n",
      "[[0.00033284 0.00541912]]\n",
      "Train Epoch61 out_loss 0.0045076352544128895\n",
      "Test Epoch61 layer0 out_loss 0.0032694810070097446\n",
      "Train 62 | out_loss 0.003750100266188383: 100%|█| 138/138 [00:00<00:00, 804.18it\n",
      "[[0.00042003 0.00389621]]\n",
      "Train Epoch62 out_loss 0.003750100266188383\n",
      "Test Epoch62 layer0 out_loss 0.0040624248795211315\n",
      "Train 63 | out_loss 0.00731638865545392: 100%|█| 138/138 [00:00<00:00, 773.99it/\n",
      "[[0.00021905 0.02042494]]\n",
      "Train Epoch63 out_loss 0.00731638865545392\n",
      "Test Epoch63 layer0 out_loss 0.010559679009020329\n",
      "Train 64 | out_loss 0.024534456431865692: 100%|█| 138/138 [00:00<00:00, 798.69it\n",
      "[[0.00058989 0.21711464]]\n",
      "Train Epoch64 out_loss 0.024534456431865692\n",
      "Test Epoch64 layer0 out_loss 0.012570865452289581\n",
      "Train 65 | out_loss 0.010292988270521164: 100%|█| 138/138 [00:00<00:00, 801.68it\n",
      "[[2.13399191e-05 1.48420753e-02]]\n",
      "Train Epoch65 out_loss 0.010292988270521164\n",
      "Test Epoch65 layer0 out_loss 0.005327911116182804\n",
      "Train 66 | out_loss 0.0038373202551156282: 100%|█| 138/138 [00:00<00:00, 807.54i\n",
      "[[0.00039952 0.00398936]]\n",
      "Train Epoch66 out_loss 0.0038373202551156282\n",
      "Test Epoch66 layer0 out_loss 0.005398089997470379\n",
      "Train 67 | out_loss 0.0052803196012973785: 100%|█| 138/138 [00:00<00:00, 796.40i\n",
      "[[0.00031665 0.00522933]]\n",
      "Train Epoch67 out_loss 0.0052803196012973785\n",
      "Test Epoch67 layer0 out_loss 0.0038993090856820345\n",
      "Train 68 | out_loss 0.009148899465799332: 100%|█| 138/138 [00:00<00:00, 758.58it\n",
      "[[0.000341   0.03311777]]\n",
      "Train Epoch68 out_loss 0.009148899465799332\n",
      "Test Epoch68 layer0 out_loss 0.008181624114513397\n",
      "Train 69 | out_loss 0.006400073412805796: 100%|█| 138/138 [00:00<00:00, 811.53it\n",
      "[[0.00035344 0.01195189]]\n",
      "Train Epoch69 out_loss 0.006400073412805796\n",
      "Test Epoch69 layer0 out_loss 0.007235080469399691\n",
      "Train 70 | out_loss 0.008927897550165653: 100%|█| 138/138 [00:00<00:00, 787.99it\n",
      "[[0.00039091 0.0407189 ]]\n",
      "Train Epoch70 out_loss 0.008927897550165653\n",
      "Test Epoch70 layer0 out_loss 0.0036266809329390526\n",
      "Train 71 | out_loss 0.009733546525239944: 100%|█| 138/138 [00:00<00:00, 796.52it\n",
      "[[0.00023279 0.04004042]]\n",
      "Train Epoch71 out_loss 0.009733546525239944\n",
      "Test Epoch71 layer0 out_loss 0.003955709282308817\n",
      "Train 72 | out_loss 0.005348498001694679: 100%|█| 138/138 [00:00<00:00, 796.20it\n",
      "[[0.00050777 0.01179032]]\n",
      "Train Epoch72 out_loss 0.005348498001694679\n",
      "Test Epoch72 layer0 out_loss 0.004550441633909941\n",
      "Train 73 | out_loss 0.006993826478719711: 100%|█| 138/138 [00:00<00:00, 789.08it\n",
      "[[0.00023956 0.01755804]]\n",
      "Train Epoch73 out_loss 0.006993826478719711\n",
      "Test Epoch73 layer0 out_loss 0.005669999402016401\n",
      "Train 74 | out_loss 0.01579071395099163: 100%|█| 138/138 [00:00<00:00, 813.21it/\n",
      "[[0.00023832 0.11670202]]\n",
      "Train Epoch74 out_loss 0.01579071395099163\n",
      "Test Epoch74 layer0 out_loss 0.0234217569231987\n",
      "Train 75 | out_loss 0.012703129090368748: 100%|█| 138/138 [00:00<00:00, 805.83it\n",
      "[[0.00052882 0.05094595]]\n",
      "Train Epoch75 out_loss 0.012703129090368748\n",
      "Test Epoch75 layer0 out_loss 0.00679522380232811\n",
      "Train 76 | out_loss 0.004370442125946283: 100%|█| 138/138 [00:00<00:00, 815.36it\n",
      "[[0.00020285 0.00439509]]\n",
      "Train Epoch76 out_loss 0.004370442125946283\n",
      "Test Epoch76 layer0 out_loss 0.0028592918533831835\n",
      "Train 77 | out_loss 0.003837088355794549: 100%|█| 138/138 [00:00<00:00, 805.24it\n",
      "[[0.00023157 0.00489715]]\n",
      "Train Epoch77 out_loss 0.003837088355794549\n",
      "Test Epoch77 layer0 out_loss 0.0026376768946647644\n",
      "Train 78 | out_loss 0.007605007849633694: 100%|█| 138/138 [00:00<00:00, 806.24it\n",
      "[[0.00043602 0.01545422]]\n",
      "Train Epoch78 out_loss 0.007605007849633694\n",
      "Test Epoch78 layer0 out_loss 0.029299944639205933\n",
      "Train 79 | out_loss 0.015360601246356964: 100%|█| 138/138 [00:00<00:00, 814.31it\n",
      "[[0.00030546 0.05587601]]\n",
      "Train Epoch79 out_loss 0.015360601246356964\n",
      "Test Epoch79 layer0 out_loss 0.004709395579993725\n",
      "Train 80 | out_loss 0.012337706983089447: 100%|█| 138/138 [00:00<00:00, 813.30it\n",
      "[[0.00030125 0.05586871]]\n",
      "Train Epoch80 out_loss 0.012337706983089447\n",
      "Test Epoch80 layer0 out_loss 0.003103455761447549\n",
      "Train 81 | out_loss 0.008812125772237778: 100%|█| 138/138 [00:00<00:00, 800.79it\n",
      "[[0.00043107 0.04297836]]\n",
      "Train Epoch81 out_loss 0.008812125772237778\n",
      "Test Epoch81 layer0 out_loss 0.026361797004938126\n",
      "Train 82 | out_loss 0.012342069298028946: 100%|█| 138/138 [00:00<00:00, 821.86it\n",
      "[[0.00073077 0.09880321]]\n",
      "Train Epoch82 out_loss 0.012342069298028946\n",
      "Test Epoch82 layer0 out_loss 0.002819845685735345\n",
      "Train 83 | out_loss 0.0029970353934913874: 100%|█| 138/138 [00:00<00:00, 819.09i\n",
      "[[1.30151973e-06 3.38726351e-03]]\n",
      "Train Epoch83 out_loss 0.0029970353934913874\n",
      "Test Epoch83 layer0 out_loss 0.002365023596212268\n",
      "Train 84 | out_loss 0.0031109980773180723: 100%|█| 138/138 [00:00<00:00, 796.86i\n",
      "[[0.00032867 0.0021771 ]]\n",
      "Train Epoch84 out_loss 0.0031109980773180723\n",
      "Test Epoch84 layer0 out_loss 0.0022838676813989878\n",
      "Train 85 | out_loss 0.002908457536250353: 100%|█| 138/138 [00:00<00:00, 811.18it\n",
      "[[0.00026786 0.00246343]]\n",
      "Train Epoch85 out_loss 0.002908457536250353\n",
      "Test Epoch85 layer0 out_loss 0.0021688893903046846\n",
      "Train 86 | out_loss 0.0026801053900271654: 100%|█| 138/138 [00:00<00:00, 810.07i\n",
      "[[0.00024614 0.00212437]]\n",
      "Train Epoch86 out_loss 0.0026801053900271654\n",
      "Test Epoch86 layer0 out_loss 0.002035115147009492\n",
      "Train 87 | out_loss 0.008804667741060257: 100%|█| 138/138 [00:00<00:00, 804.34it\n",
      "[[0.00047831 0.0239345 ]]\n",
      "Train Epoch87 out_loss 0.008804667741060257\n",
      "Test Epoch87 layer0 out_loss 0.023256545886397362\n",
      "Train 88 | out_loss 0.008080879226326942: 100%|█| 138/138 [00:00<00:00, 788.15it\n",
      "[[0.00051934 0.03072172]]\n",
      "Train Epoch88 out_loss 0.008080879226326942\n",
      "Test Epoch88 layer0 out_loss 0.003045544493943453\n",
      "Train 89 | out_loss 0.004948511719703674: 100%|█| 138/138 [00:00<00:00, 782.49it\n",
      "[[7.14806648e-05 7.26680387e-03]]\n",
      "Train Epoch89 out_loss 0.004948511719703674\n",
      "Test Epoch89 layer0 out_loss 0.005737570580095053\n",
      "Train 90 | out_loss 0.004976965021342039: 100%|█| 138/138 [00:00<00:00, 791.53it\n",
      "[[0.00034762 0.01825776]]\n",
      "Train Epoch90 out_loss 0.004976965021342039\n",
      "Test Epoch90 layer0 out_loss 0.0034920969046652317\n",
      "Train 91 | out_loss 0.003471060423180461: 100%|█| 138/138 [00:00<00:00, 761.46it\n",
      "[[0.00062323 0.00473628]]\n",
      "Train Epoch91 out_loss 0.003471060423180461\n",
      "Test Epoch91 layer0 out_loss 0.0026521615218371153\n",
      "Train 92 | out_loss 0.003961533773690462: 100%|█| 138/138 [00:00<00:00, 765.46it\n",
      "[[8.76842962e-07 5.26388661e-03]]\n",
      "Train Epoch92 out_loss 0.003961533773690462\n",
      "Test Epoch92 layer0 out_loss 0.004032118711620569\n",
      "Train 93 | out_loss 0.009454729035496712: 100%|█| 138/138 [00:00<00:00, 809.63it\n",
      "[[0.00048626 0.06987445]]\n",
      "Train Epoch93 out_loss 0.009454729035496712\n",
      "Test Epoch93 layer0 out_loss 0.004302595276385546\n",
      "Train 94 | out_loss 0.005370086524635553: 100%|█| 138/138 [00:00<00:00, 796.45it\n",
      "[[0.00046492 0.0082297 ]]\n",
      "Train Epoch94 out_loss 0.005370086524635553\n",
      "Test Epoch94 layer0 out_loss 0.003777374280616641\n",
      "Train 95 | out_loss 0.002609327668324113: 100%|█| 138/138 [00:00<00:00, 782.77it\n",
      "[[0.00038687 0.00151331]]\n",
      "Train Epoch95 out_loss 0.002609327668324113\n",
      "Test Epoch95 layer0 out_loss 0.0020337060559540987\n",
      "Train 96 | out_loss 0.0022267878521233797: 100%|█| 138/138 [00:00<00:00, 798.70i\n",
      "[[5.74461261e-05 1.25128466e-03]]\n",
      "Train Epoch96 out_loss 0.0022267878521233797\n",
      "Test Epoch96 layer0 out_loss 0.003049943596124649\n",
      "Train 97 | out_loss 0.0032801933120936155: 100%|█| 138/138 [00:00<00:00, 809.84i\n",
      "[[0.00045605 0.00192568]]\n",
      "Train Epoch97 out_loss 0.0032801933120936155\n",
      "Test Epoch97 layer0 out_loss 0.005674371961504221\n",
      "Train 98 | out_loss 0.0036828976590186357: 100%|█| 138/138 [00:00<00:00, 779.84i\n",
      "[[0.0005079  0.00514404]]\n",
      "Train Epoch98 out_loss 0.0036828976590186357\n",
      "Test Epoch98 layer0 out_loss 0.003074029227718711\n",
      "Train 99 | out_loss 0.011571385897696018: 100%|█| 138/138 [00:00<00:00, 811.84it\n",
      "[[1.24660679e-06 5.69404873e-02]]\n",
      "Train Epoch99 out_loss 0.011571385897696018\n",
      "Test Epoch99 layer0 out_loss 0.027076395228505135\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Start Training\n",
      "  0%|                                                   | 0/138 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 0.10185312479734421: 100%|█| 138/138 [00:00<00:00, 209.42it/s\n",
      "[[1.04030881e-02 2.83335492e+01]\n",
      " [1.31106864e+00 1.10031894e+01]]\n",
      "Train Epoch0 out_loss 0.10185312479734421\n",
      "Test Epoch0 layer0 out_loss 0.10260691493749619\n",
      "Test Epoch0 layer1 out_loss 0.021095719188451767\n",
      "Train 1 | out_loss 0.017262877896428108: 100%|█| 138/138 [00:00<00:00, 485.22it/\n",
      "[[4.07692445e-05 6.02161325e+00]\n",
      " [5.23250801e-06 3.08078111e-01]]\n",
      "Train Epoch1 out_loss 0.017262877896428108\n",
      "Test Epoch1 layer0 out_loss 0.12066184729337692\n",
      "Test Epoch1 layer1 out_loss 0.0171713437885046\n",
      "Train 2 | out_loss 0.011819897219538689: 100%|█| 138/138 [00:00<00:00, 477.70it/\n",
      "[[4.43018930e-05 3.21924575e+00]\n",
      " [4.92971339e-06 1.32313467e-01]]\n",
      "Train Epoch2 out_loss 0.011819897219538689\n",
      "Test Epoch2 layer0 out_loss 0.025391343981027603\n",
      "Test Epoch2 layer1 out_loss 0.008783398196101189\n",
      "Train 3 | out_loss 0.008819958195090294: 100%|█| 138/138 [00:00<00:00, 481.78it/\n",
      "[[4.29238962e-05 1.79716744e+00]\n",
      " [6.62163902e-06 6.97040587e-02]]\n",
      "Train Epoch3 out_loss 0.008819958195090294\n",
      "Test Epoch3 layer0 out_loss 0.03881830722093582\n",
      "Test Epoch3 layer1 out_loss 0.008064265362918377\n",
      "Train 4 | out_loss 0.00724137993529439: 100%|█| 138/138 [00:00<00:00, 470.57it/s\n",
      "[[3.82978606e-05 1.04319700e+00]\n",
      " [8.31292547e-06 3.83084137e-02]]\n",
      "Train Epoch4 out_loss 0.00724137993529439\n",
      "Test Epoch4 layer0 out_loss 0.03238072246313095\n",
      "Test Epoch4 layer1 out_loss 0.008002405986189842\n",
      "Train 5 | out_loss 0.006403529085218906: 100%|█| 138/138 [00:00<00:00, 480.27it/\n",
      "[[3.99928917e-05 8.46078773e-01]\n",
      " [7.80169713e-06 3.33648432e-02]]\n",
      "Train Epoch5 out_loss 0.006403529085218906\n",
      "Test Epoch5 layer0 out_loss 0.08301449567079544\n",
      "Test Epoch5 layer1 out_loss 0.005358897149562836\n",
      "Train 6 | out_loss 0.006444612983614206: 100%|█| 138/138 [00:00<00:00, 477.25it/\n",
      "[[4.17856147e-05 9.74763877e-01]\n",
      " [1.08996064e-05 2.97384226e-02]]\n",
      "Train Epoch6 out_loss 0.006444612983614206\n",
      "Test Epoch6 layer0 out_loss 0.031712740659713745\n",
      "Test Epoch6 layer1 out_loss 0.0048599266447126865\n",
      "Train 7 | out_loss 0.0044703297317028046: 100%|█| 138/138 [00:00<00:00, 457.49it\n",
      "[[4.57061885e-05 6.54165256e-01]\n",
      " [9.27127036e-06 2.27388154e-02]]\n",
      "Train Epoch7 out_loss 0.0044703297317028046\n",
      "Test Epoch7 layer0 out_loss 0.03371886536478996\n",
      "Test Epoch7 layer1 out_loss 0.003094250103458762\n",
      "Train 8 | out_loss 0.0036315848119556904: 100%|█| 138/138 [00:00<00:00, 491.49it\n",
      "[[4.76647239e-05 4.53976642e-01]\n",
      " [1.08199619e-05 1.12392586e-02]]\n",
      "Train Epoch8 out_loss 0.0036315848119556904\n",
      "Test Epoch8 layer0 out_loss 0.015878714621067047\n",
      "Test Epoch8 layer1 out_loss 0.004228621255606413\n",
      "Train 9 | out_loss 0.0035513057373464108: 100%|█| 138/138 [00:00<00:00, 487.35it\n",
      "[[5.24709439e-05 2.57236448e-01]\n",
      " [1.26471591e-05 9.39034509e-03]]\n",
      "Train Epoch9 out_loss 0.0035513057373464108\n",
      "Test Epoch9 layer0 out_loss 0.03411099687218666\n",
      "Test Epoch9 layer1 out_loss 0.004140120465308428\n",
      "Train 10 | out_loss 0.004041366279125214: 100%|█| 138/138 [00:00<00:00, 468.65it\n",
      "[[7.39573513e-05 5.93728707e-01]\n",
      " [1.33765823e-05 1.40698413e-02]]\n",
      "Train Epoch10 out_loss 0.004041366279125214\n",
      "Test Epoch10 layer0 out_loss 0.030875883996486664\n",
      "Test Epoch10 layer1 out_loss 0.0036872713826596737\n",
      "Train 11 | out_loss 0.0038866030517965555: 100%|█| 138/138 [00:00<00:00, 474.22i\n",
      "[[3.00082178e-04 1.58640118e-01]\n",
      " [1.28142869e-05 6.16253358e-03]]\n",
      "Train Epoch11 out_loss 0.0038866030517965555\n",
      "Test Epoch11 layer0 out_loss 0.012098532170057297\n",
      "Test Epoch11 layer1 out_loss 0.004016241990029812\n",
      "Train 12 | out_loss 0.0040171779692173: 100%|█| 138/138 [00:00<00:00, 480.16it/s\n",
      "[[2.08644763e-04 2.40738377e-01]\n",
      " [1.29876165e-05 6.92131769e-03]]\n",
      "Train Epoch12 out_loss 0.0040171779692173\n",
      "Test Epoch12 layer0 out_loss 0.032466065138578415\n",
      "Test Epoch12 layer1 out_loss 0.005873063113540411\n",
      "Train 13 | out_loss 0.004407973960042: 100%|█| 138/138 [00:00<00:00, 475.86it/s]\n",
      "[[4.79541588e-04 4.94777797e-01]\n",
      " [2.22799456e-05 8.23033393e-03]]\n",
      "Train Epoch13 out_loss 0.004407973960042\n",
      "Test Epoch13 layer0 out_loss 0.049794141203165054\n",
      "Test Epoch13 layer1 out_loss 0.005651900079101324\n",
      "Train 14 | out_loss 0.003677977481856942: 100%|█| 138/138 [00:00<00:00, 487.79it\n",
      "[[4.69082472e-04 4.60051475e-01]\n",
      " [2.48185527e-05 7.12543889e-03]]\n",
      "Train Epoch14 out_loss 0.003677977481856942\n",
      "Test Epoch14 layer0 out_loss 0.03136102482676506\n",
      "Test Epoch14 layer1 out_loss 0.0030622906051576138\n",
      "Train 15 | out_loss 0.003251501824706793: 100%|█| 138/138 [00:00<00:00, 474.19it\n",
      "[[3.58641188e-04 3.34960018e-01]\n",
      " [3.17470151e-05 6.23293274e-03]]\n",
      "Train Epoch15 out_loss 0.003251501824706793\n",
      "Test Epoch15 layer0 out_loss 0.021238362416625023\n",
      "Test Epoch15 layer1 out_loss 0.00441717728972435\n",
      "Train 16 | out_loss 0.0041112047620117664: 100%|█| 138/138 [00:00<00:00, 480.77i\n",
      "[[6.36638102e-04 4.07263735e-01]\n",
      " [7.00771263e-05 8.66122212e-03]]\n",
      "Train Epoch16 out_loss 0.0041112047620117664\n",
      "Test Epoch16 layer0 out_loss 0.03839089348912239\n",
      "Test Epoch16 layer1 out_loss 0.0036265901289880276\n",
      "Train 17 | out_loss 0.0026031099259853363: 100%|█| 138/138 [00:00<00:00, 471.13i\n",
      "[[9.36691494e-05 2.45918241e-01]\n",
      " [5.66945422e-05 5.38761342e-03]]\n",
      "Train Epoch17 out_loss 0.0026031099259853363\n",
      "Test Epoch17 layer0 out_loss 0.024624204263091087\n",
      "Test Epoch17 layer1 out_loss 0.002323504537343979\n",
      "Train 18 | out_loss 0.0023515464272350073: 100%|█| 138/138 [00:00<00:00, 485.50i\n",
      "[[3.82165049e-04 9.09358738e-02]\n",
      " [6.96317091e-05 2.34871590e-03]]\n",
      "Train Epoch18 out_loss 0.0023515464272350073\n",
      "Test Epoch18 layer0 out_loss 0.008163820020854473\n",
      "Test Epoch18 layer1 out_loss 0.0024833811912685633\n",
      "Train 19 | out_loss 0.003501740749925375: 100%|█| 138/138 [00:00<00:00, 477.29it\n",
      "[[4.49507915e-04 3.93992280e-01]\n",
      " [1.60454614e-04 6.87146826e-03]]\n",
      "Train Epoch19 out_loss 0.003501740749925375\n",
      "Test Epoch19 layer0 out_loss 0.026847485452890396\n",
      "Test Epoch19 layer1 out_loss 0.0016555074835196137\n",
      "Train 20 | out_loss 0.003462812164798379: 100%|█| 138/138 [00:00<00:00, 481.72it\n",
      "[[0.00038155 0.16508312]\n",
      " [0.00030643 0.00404914]]\n",
      "Train Epoch20 out_loss 0.003462812164798379\n",
      "Test Epoch20 layer0 out_loss 0.011663476936519146\n",
      "Test Epoch20 layer1 out_loss 0.0016896476736292243\n",
      "Train 21 | out_loss 0.0024649114347994328: 100%|█| 138/138 [00:00<00:00, 453.23i\n",
      "[[0.00032378 0.06329048]\n",
      " [0.00020918 0.00247056]]\n",
      "Train Epoch21 out_loss 0.0024649114347994328\n",
      "Test Epoch21 layer0 out_loss 0.00659547932446003\n",
      "Test Epoch21 layer1 out_loss 0.0014166792389005423\n",
      "Train 22 | out_loss 0.0028755743987858295: 100%|█| 138/138 [00:00<00:00, 484.24i\n",
      "[[0.00046827 0.26999618]\n",
      " [0.0004028  0.0060187 ]]\n",
      "Train Epoch22 out_loss 0.0028755743987858295\n",
      "Test Epoch22 layer0 out_loss 0.08278077095746994\n",
      "Test Epoch22 layer1 out_loss 0.004879865795373917\n",
      "Train 23 | out_loss 0.003159131156280637: 100%|█| 138/138 [00:00<00:00, 476.51it\n",
      "[[2.78889220e-04 7.11932943e-01]\n",
      " [2.93744545e-04 5.14381430e-03]]\n",
      "Train Epoch23 out_loss 0.003159131156280637\n",
      "Test Epoch23 layer0 out_loss 0.016912413761019707\n",
      "Test Epoch23 layer1 out_loss 0.002388920169323683\n",
      "Train 24 | out_loss 0.002571456367149949: 100%|█| 138/138 [00:00<00:00, 467.60it\n",
      "[[0.00033792 0.25783646]\n",
      " [0.00046468 0.00433839]]\n",
      "Train Epoch24 out_loss 0.002571456367149949\n",
      "Test Epoch24 layer0 out_loss 0.01621583104133606\n",
      "Test Epoch24 layer1 out_loss 0.002698348369449377\n",
      "Train 25 | out_loss 0.004428178071975708: 100%|█| 138/138 [00:00<00:00, 453.13it\n",
      "[[5.08194822e-04 8.34811432e-01]\n",
      " [4.75513727e-04 9.32842976e-03]]\n",
      "Train Epoch25 out_loss 0.004428178071975708\n",
      "Test Epoch25 layer0 out_loss 0.04609852284193039\n",
      "Test Epoch25 layer1 out_loss 0.002629415364935994\n",
      "Train 26 | out_loss 0.0027346026618033648: 100%|█| 138/138 [00:00<00:00, 473.90i\n",
      "[[0.00056653 0.15768307]\n",
      " [0.00049545 0.00329349]]\n",
      "Train Epoch26 out_loss 0.0027346026618033648\n",
      "Test Epoch26 layer0 out_loss 0.017246214672923088\n",
      "Test Epoch26 layer1 out_loss 0.001405155984684825\n",
      "Train 27 | out_loss 0.0016054403968155384: 100%|█| 138/138 [00:00<00:00, 482.16i\n",
      "[[0.00011095 0.02979172]\n",
      " [0.00058911 0.00182423]]\n",
      "Train Epoch27 out_loss 0.0016054403968155384\n",
      "Test Epoch27 layer0 out_loss 0.007094889879226685\n",
      "Test Epoch27 layer1 out_loss 0.0029614176601171494\n",
      "Train 28 | out_loss 0.0024577518925070763: 100%|█| 138/138 [00:00<00:00, 488.41i\n",
      "[[0.00056686 0.02811934]\n",
      " [0.00039796 0.00183268]]\n",
      "Train Epoch28 out_loss 0.0024577518925070763\n",
      "Test Epoch28 layer0 out_loss 0.00924820825457573\n",
      "Test Epoch28 layer1 out_loss 0.0016334272222593427\n",
      "Train 29 | out_loss 0.0018139522289857268: 100%|█| 138/138 [00:00<00:00, 481.05i\n",
      "[[0.0002442  0.05056551]\n",
      " [0.00035165 0.0022083 ]]\n",
      "Train Epoch29 out_loss 0.0018139522289857268\n",
      "Test Epoch29 layer0 out_loss 0.0072300611063838005\n",
      "Test Epoch29 layer1 out_loss 0.0020048825535923243\n",
      "Train 30 | out_loss 0.0020898934453725815: 100%|█| 138/138 [00:00<00:00, 483.01i\n",
      "[[0.00039899 0.0306014 ]\n",
      " [0.00066078 0.00208527]]\n",
      "Train Epoch30 out_loss 0.0020898934453725815\n",
      "Test Epoch30 layer0 out_loss 0.010521510615944862\n",
      "Test Epoch30 layer1 out_loss 0.0012847103644162416\n",
      "Train 31 | out_loss 0.0020391144789755344: 100%|█| 138/138 [00:00<00:00, 471.00i\n",
      "[[0.00036816 0.06440564]\n",
      " [0.00047129 0.0027677 ]]\n",
      "Train Epoch31 out_loss 0.0020391144789755344\n",
      "Test Epoch31 layer0 out_loss 0.009259643964469433\n",
      "Test Epoch31 layer1 out_loss 0.00139202072750777\n",
      "Train 32 | out_loss 0.0032562457490712404: 100%|█| 138/138 [00:00<00:00, 475.33i\n",
      "[[5.80535529e-04 6.33956983e-01]\n",
      " [6.40443680e-04 7.82326064e-03]]\n",
      "Train Epoch32 out_loss 0.0032562457490712404\n",
      "Test Epoch32 layer0 out_loss 0.02570979669690132\n",
      "Test Epoch32 layer1 out_loss 0.0032738514710217714\n",
      "Train 33 | out_loss 0.0024297500494867563: 100%|█| 138/138 [00:00<00:00, 482.23i\n",
      "[[1.17417665e-04 3.23871193e-01]\n",
      " [4.94012935e-04 5.04441574e-03]]\n",
      "Train Epoch33 out_loss 0.0024297500494867563\n",
      "Test Epoch33 layer0 out_loss 0.019717998802661896\n",
      "Test Epoch33 layer1 out_loss 0.0035435883328318596\n",
      "Train 34 | out_loss 0.0017553151119500399: 100%|█| 138/138 [00:00<00:00, 481.29i\n",
      "[[0.00038922 0.02843077]\n",
      " [0.00046703 0.00148443]]\n",
      "Train Epoch34 out_loss 0.0017553151119500399\n",
      "Test Epoch34 layer0 out_loss 0.005781217012554407\n",
      "Test Epoch34 layer1 out_loss 0.0025251677725464106\n",
      "Train 35 | out_loss 0.0028583623934537172: 100%|█| 138/138 [00:00<00:00, 451.59i\n",
      "[[0.00051416 0.16066923]\n",
      " [0.00083153 0.00448691]]\n",
      "Train Epoch35 out_loss 0.0028583623934537172\n",
      "Test Epoch35 layer0 out_loss 0.005272876936942339\n",
      "Test Epoch35 layer1 out_loss 0.0019086956745013595\n",
      "Train 36 | out_loss 0.0021404719445854425: 100%|█| 138/138 [00:00<00:00, 485.84i\n",
      "[[0.00067808 0.01483657]\n",
      " [0.00044196 0.00113737]]\n",
      "Train Epoch36 out_loss 0.0021404719445854425\n",
      "Test Epoch36 layer0 out_loss 0.013276074081659317\n",
      "Test Epoch36 layer1 out_loss 0.0018673382000997663\n",
      "Train 37 | out_loss 0.001698391861282289: 100%|█| 138/138 [00:00<00:00, 467.66it\n",
      "[[4.34482289e-05 6.64659253e-02]\n",
      " [5.43104859e-04 2.79586341e-03]]\n",
      "Train Epoch37 out_loss 0.001698391861282289\n",
      "Test Epoch37 layer0 out_loss 0.011829596012830734\n",
      "Test Epoch37 layer1 out_loss 0.001774560660123825\n",
      "Train 38 | out_loss 0.0023881574161350727: 100%|█| 138/138 [00:00<00:00, 478.82i\n",
      "[[0.00028656 0.18636445]\n",
      " [0.00069383 0.00393652]]\n",
      "Train Epoch38 out_loss 0.0023881574161350727\n",
      "Test Epoch38 layer0 out_loss 0.006447738967835903\n",
      "Test Epoch38 layer1 out_loss 0.002563533606007695\n",
      "Train 39 | out_loss 0.0018466615583747625: 100%|█| 138/138 [00:00<00:00, 475.04i\n",
      "[[0.00035705 0.04146405]\n",
      " [0.0004534  0.00140949]]\n",
      "Train Epoch39 out_loss 0.0018466615583747625\n",
      "Test Epoch39 layer0 out_loss 0.007230491377413273\n",
      "Test Epoch39 layer1 out_loss 0.002661419101059437\n",
      "Train 40 | out_loss 0.0023192695807665586: 100%|█| 138/138 [00:00<00:00, 482.19i\n",
      "[[0.0004207  0.07123631]\n",
      " [0.00074943 0.00269193]]\n",
      "Train Epoch40 out_loss 0.0023192695807665586\n",
      "Test Epoch40 layer0 out_loss 0.013289893046021461\n",
      "Test Epoch40 layer1 out_loss 0.0009733590413816273\n",
      "Train 41 | out_loss 0.002618401078507304: 100%|█| 138/138 [00:00<00:00, 472.73it\n",
      "[[0.00045303 0.16909207]\n",
      " [0.00046196 0.00455663]]\n",
      "Train Epoch41 out_loss 0.002618401078507304\n",
      "Test Epoch41 layer0 out_loss 0.04176295921206474\n",
      "Test Epoch41 layer1 out_loss 0.0016666994197294116\n",
      "Train 42 | out_loss 0.0020866645500063896: 100%|█| 138/138 [00:00<00:00, 475.37i\n",
      "[[0.00031776 0.10393607]\n",
      " [0.00057944 0.00249228]]\n",
      "Train Epoch42 out_loss 0.0020866645500063896\n",
      "Test Epoch42 layer0 out_loss 0.014625702984631062\n",
      "Test Epoch42 layer1 out_loss 0.0011767185060307384\n",
      "Train 43 | out_loss 0.0018309548031538725: 100%|█| 138/138 [00:00<00:00, 473.50i\n",
      "[[0.00034498 0.02811692]\n",
      " [0.00076522 0.00269241]]\n",
      "Train Epoch43 out_loss 0.0018309548031538725\n",
      "Test Epoch43 layer0 out_loss 0.02283651940524578\n",
      "Test Epoch43 layer1 out_loss 0.000810422352515161\n",
      "Train 44 | out_loss 0.0027545529883354902: 100%|█| 138/138 [00:00<00:00, 474.77i\n",
      "[[0.00036445 0.19080373]\n",
      " [0.00043593 0.00540164]]\n",
      "Train Epoch44 out_loss 0.0027545529883354902\n",
      "Test Epoch44 layer0 out_loss 0.03668675571680069\n",
      "Test Epoch44 layer1 out_loss 0.004071943461894989\n",
      "Train 45 | out_loss 0.0023101246915757656: 100%|█| 138/138 [00:00<00:00, 479.64i\n",
      "[[0.00047301 0.08151769]\n",
      " [0.00053882 0.00384834]]\n",
      "Train Epoch45 out_loss 0.0023101246915757656\n",
      "Test Epoch45 layer0 out_loss 0.00344974547624588\n",
      "Test Epoch45 layer1 out_loss 0.00208791671320796\n",
      "Train 46 | out_loss 0.001459953491576016: 100%|█| 138/138 [00:00<00:00, 483.76it\n",
      "[[0.00024532 0.00764947]\n",
      " [0.0006473  0.00118376]]\n",
      "Train Epoch46 out_loss 0.001459953491576016\n",
      "Test Epoch46 layer0 out_loss 0.0066565824672579765\n",
      "Test Epoch46 layer1 out_loss 0.0016562006203457713\n",
      "Train 47 | out_loss 0.002017334569245577: 100%|█| 138/138 [00:00<00:00, 472.43it\n",
      "[[0.00052788 0.01603107]\n",
      " [0.00056203 0.00138735]]\n",
      "Train Epoch47 out_loss 0.002017334569245577\n",
      "Test Epoch47 layer0 out_loss 0.004458665382117033\n",
      "Test Epoch47 layer1 out_loss 0.0012185475789010525\n",
      "Train 48 | out_loss 0.002257576445117593: 100%|█| 138/138 [00:00<00:00, 489.33it\n",
      "[[0.00036503 0.0689279 ]\n",
      " [0.00058562 0.00321347]]\n",
      "Train Epoch48 out_loss 0.002257576445117593\n",
      "Test Epoch48 layer0 out_loss 0.016105182468891144\n",
      "Test Epoch48 layer1 out_loss 0.0026613592635840178\n",
      "Train 49 | out_loss 0.002604647306725383: 100%|█| 138/138 [00:00<00:00, 485.60it\n",
      "[[2.36298976e-04 2.54552719e-01]\n",
      " [5.06564861e-04 4.63203298e-03]]\n",
      "Train Epoch49 out_loss 0.002604647306725383\n",
      "Test Epoch49 layer0 out_loss 0.016274578869342804\n",
      "Test Epoch49 layer1 out_loss 0.001748765236698091\n",
      "Train 50 | out_loss 0.0027954895049333572: 100%|█| 138/138 [00:00<00:00, 475.66i\n",
      "[[0.00052003 0.12708006]\n",
      " [0.00059045 0.00321165]]\n",
      "Train Epoch50 out_loss 0.0027954895049333572\n",
      "Test Epoch50 layer0 out_loss 0.007151453755795956\n",
      "Test Epoch50 layer1 out_loss 0.0030310002621263266\n",
      "Train 51 | out_loss 0.0017599252751097083: 100%|█| 138/138 [00:00<00:00, 483.83i\n",
      "[[0.00028291 0.03662201]\n",
      " [0.00055182 0.00182032]]\n",
      "Train Epoch51 out_loss 0.0017599252751097083\n",
      "Test Epoch51 layer0 out_loss 0.003754502395167947\n",
      "Test Epoch51 layer1 out_loss 0.0006262660026550293\n",
      "Train 52 | out_loss 0.0022553273010998964: 100%|█| 138/138 [00:00<00:00, 482.24i\n",
      "[[0.00049718 0.06999926]\n",
      " [0.00048431 0.00231979]]\n",
      "Train Epoch52 out_loss 0.0022553273010998964\n",
      "Test Epoch52 layer0 out_loss 0.021198635920882225\n",
      "Test Epoch52 layer1 out_loss 0.0010813310509547591\n",
      "Train 53 | out_loss 0.0017945299623534083: 100%|█| 138/138 [00:00<00:00, 474.92i\n",
      "[[0.00029847 0.05211135]\n",
      " [0.00051429 0.00188971]]\n",
      "Train Epoch53 out_loss 0.0017945299623534083\n",
      "Test Epoch53 layer0 out_loss 0.0036950265057384968\n",
      "Test Epoch53 layer1 out_loss 0.0014197651762515306\n",
      "Train 54 | out_loss 0.0016706022433936596: 100%|█| 138/138 [00:00<00:00, 487.59i\n",
      "[[0.00031641 0.00782279]\n",
      " [0.00054944 0.00132709]]\n",
      "Train Epoch54 out_loss 0.0016706022433936596\n",
      "Test Epoch54 layer0 out_loss 0.0076661682687699795\n",
      "Test Epoch54 layer1 out_loss 0.0006661927909590304\n",
      "Train 55 | out_loss 0.001998273655772209: 100%|█| 138/138 [00:00<00:00, 479.94it\n",
      "[[0.00039123 0.01818481]\n",
      " [0.00053956 0.00171847]]\n",
      "Train Epoch55 out_loss 0.001998273655772209\n",
      "Test Epoch55 layer0 out_loss 0.006447360850870609\n",
      "Test Epoch55 layer1 out_loss 0.0019600428640842438\n",
      "Train 56 | out_loss 0.002490854822099209: 100%|█| 138/138 [00:00<00:00, 478.05it\n",
      "[[0.00045037 0.03794645]\n",
      " [0.0005962  0.0033516 ]]\n",
      "Train Epoch56 out_loss 0.002490854822099209\n",
      "Test Epoch56 layer0 out_loss 0.0033600630704313517\n",
      "Test Epoch56 layer1 out_loss 0.0009043985628522933\n",
      "Train 57 | out_loss 0.002680123783648014: 100%|█| 138/138 [00:00<00:00, 479.28it\n",
      "[[0.00047724 0.20595003]\n",
      " [0.00050724 0.00414468]]\n",
      "Train Epoch57 out_loss 0.002680123783648014\n",
      "Test Epoch57 layer0 out_loss 0.0072308252565562725\n",
      "Test Epoch57 layer1 out_loss 0.001429363968782127\n",
      "Train 58 | out_loss 0.0011819449719041586: 100%|█| 138/138 [00:00<00:00, 481.60i\n",
      "[[6.90482674e-05 1.10603252e-02]\n",
      " [4.37993871e-04 1.39001243e-03]]\n",
      "Train Epoch58 out_loss 0.0011819449719041586\n",
      "Test Epoch58 layer0 out_loss 0.0023852100130170584\n",
      "Test Epoch58 layer1 out_loss 0.0019127788254991174\n",
      "Train 59 | out_loss 0.001692897523753345: 100%|█| 138/138 [00:00<00:00, 475.66it\n",
      "[[0.00033316 0.00466103]\n",
      " [0.00055757 0.00148743]]\n",
      "Train Epoch59 out_loss 0.001692897523753345\n",
      "Test Epoch59 layer0 out_loss 0.003499999875202775\n",
      "Test Epoch59 layer1 out_loss 0.004429998807609081\n",
      "Train 60 | out_loss 0.0022927294485270977: 100%|█| 138/138 [00:00<00:00, 477.01i\n",
      "[[0.00056088 0.02919015]\n",
      " [0.00043393 0.00179473]]\n",
      "Train Epoch60 out_loss 0.0022927294485270977\n",
      "Test Epoch60 layer0 out_loss 0.008493078872561455\n",
      "Test Epoch60 layer1 out_loss 0.0026353609282523394\n",
      "Train 61 | out_loss 0.0021533407270908356: 100%|█| 138/138 [00:00<00:00, 479.52i\n",
      "[[0.00035244 0.07083496]\n",
      " [0.00055273 0.0030423 ]]\n",
      "Train Epoch61 out_loss 0.0021533407270908356\n",
      "Test Epoch61 layer0 out_loss 0.005746237933635712\n",
      "Test Epoch61 layer1 out_loss 0.0006814586813561618\n",
      "Train 62 | out_loss 0.0018388833850622177: 100%|█| 138/138 [00:00<00:00, 474.35i\n",
      "[[0.00033744 0.05034539]\n",
      " [0.00036944 0.00184656]]\n",
      "Train Epoch62 out_loss 0.0018388833850622177\n",
      "Test Epoch62 layer0 out_loss 0.014823787845671177\n",
      "Test Epoch62 layer1 out_loss 0.001486623310483992\n",
      "Train 63 | out_loss 0.0021210673730820417: 100%|█| 138/138 [00:00<00:00, 468.79i\n",
      "[[0.00037597 0.06099298]\n",
      " [0.00059087 0.00270866]]\n",
      "Train Epoch63 out_loss 0.0021210673730820417\n",
      "Test Epoch63 layer0 out_loss 0.0031098315957933664\n",
      "Test Epoch63 layer1 out_loss 0.000653205846901983\n",
      "Train 64 | out_loss 0.0017498083179816604: 100%|█| 138/138 [00:00<00:00, 473.25i\n",
      "[[0.00030915 0.02699475]\n",
      " [0.00041143 0.00181486]]\n",
      "Train Epoch64 out_loss 0.0017498083179816604\n",
      "Test Epoch64 layer0 out_loss 0.0034508255776017904\n",
      "Test Epoch64 layer1 out_loss 0.0015802704729139805\n",
      "Train 65 | out_loss 0.0021884532179683447: 100%|█| 138/138 [00:00<00:00, 476.42i\n",
      "[[0.00039498 0.04004534]\n",
      " [0.00048374 0.00220043]]\n",
      "Train Epoch65 out_loss 0.0021884532179683447\n",
      "Test Epoch65 layer0 out_loss 0.00497063435614109\n",
      "Test Epoch65 layer1 out_loss 0.0024217204190790653\n",
      "Train 66 | out_loss 0.0024169893004000187: 100%|█| 138/138 [00:00<00:00, 476.97i\n",
      "[[0.00044455 0.1443469 ]\n",
      " [0.00043857 0.0034895 ]]\n",
      "Train Epoch66 out_loss 0.0024169893004000187\n",
      "Test Epoch66 layer0 out_loss 0.003646944649517536\n",
      "Test Epoch66 layer1 out_loss 0.0012833131477236748\n",
      "Train 67 | out_loss 0.0017830015858635306: 100%|█| 138/138 [00:00<00:00, 475.83i\n",
      "[[0.00034917 0.00967402]\n",
      " [0.00043281 0.00138362]]\n",
      "Train Epoch67 out_loss 0.0017830015858635306\n",
      "Test Epoch67 layer0 out_loss 0.0030350449960678816\n",
      "Test Epoch67 layer1 out_loss 0.0011277690064162016\n",
      "Train 68 | out_loss 0.0017504187999293208: 100%|█| 138/138 [00:00<00:00, 478.34i\n",
      "[[0.00037152 0.00704823]\n",
      " [0.00040844 0.00152172]]\n",
      "Train Epoch68 out_loss 0.0017504187999293208\n",
      "Test Epoch68 layer0 out_loss 0.0020011216402053833\n",
      "Test Epoch68 layer1 out_loss 0.0006687595159746706\n",
      "Train 69 | out_loss 0.0021590518299490213: 100%|█| 138/138 [00:00<00:00, 481.93i\n",
      "[[0.00045074 0.00402958]\n",
      " [0.0004838  0.00173586]]\n",
      "Train Epoch69 out_loss 0.0021590518299490213\n",
      "Test Epoch69 layer0 out_loss 0.003668213728815317\n",
      "Test Epoch69 layer1 out_loss 0.0006165263475850224\n",
      "Train 70 | out_loss 0.0017161990981549025: 100%|█| 138/138 [00:00<00:00, 472.47i\n",
      "[[0.00036902 0.01395501]\n",
      " [0.00037178 0.0018741 ]]\n",
      "Train Epoch70 out_loss 0.0017161990981549025\n",
      "Test Epoch70 layer0 out_loss 0.01299265120178461\n",
      "Test Epoch70 layer1 out_loss 0.0006572639686055481\n",
      "Train 71 | out_loss 0.0025735103990882635: 100%|█| 138/138 [00:00<00:00, 481.65i\n",
      "[[0.00057537 0.09260713]\n",
      " [0.00042842 0.00352684]]\n",
      "Train Epoch71 out_loss 0.0025735103990882635\n",
      "Test Epoch71 layer0 out_loss 0.002425756538286805\n",
      "Test Epoch71 layer1 out_loss 0.00097733736038208\n",
      "Train 72 | out_loss 0.00079793093027547: 100%|█| 138/138 [00:00<00:00, 455.89it/\n",
      "[[3.57505666e-06 5.55048791e-03]\n",
      " [4.26793553e-04 1.45632257e-03]]\n",
      "Train Epoch72 out_loss 0.00079793093027547\n",
      "Test Epoch72 layer0 out_loss 0.0029138748068362474\n",
      "Test Epoch72 layer1 out_loss 0.0005224052001722157\n",
      "Train 73 | out_loss 0.0019790646620094776: 100%|█| 138/138 [00:00<00:00, 482.01i\n",
      "[[0.00040745 0.01455739]\n",
      " [0.0004134  0.00190772]]\n",
      "Train Epoch73 out_loss 0.0019790646620094776\n",
      "Test Epoch73 layer0 out_loss 0.005547911394387484\n",
      "Test Epoch73 layer1 out_loss 0.001029851147904992\n",
      "Train 74 | out_loss 0.002640805672854185: 100%|█| 138/138 [00:00<00:00, 465.94it\n",
      "[[0.00052475 0.1071196 ]\n",
      " [0.00043044 0.00482286]]\n",
      "Train Epoch74 out_loss 0.002640805672854185\n",
      "Test Epoch74 layer0 out_loss 0.004882224835455418\n",
      "Test Epoch74 layer1 out_loss 0.0010884935036301613\n",
      "Train 75 | out_loss 0.0019355836557224393: 100%|█| 138/138 [00:00<00:00, 475.33i\n",
      "[[0.00046685 0.0087983 ]\n",
      " [0.00034258 0.00134462]]\n",
      "Train Epoch75 out_loss 0.0019355836557224393\n",
      "Test Epoch75 layer0 out_loss 0.0035514822229743004\n",
      "Test Epoch75 layer1 out_loss 0.0015888068592175841\n",
      "Train 76 | out_loss 0.0015956093557178974: 100%|█| 138/138 [00:00<00:00, 480.95i\n",
      "[[0.000379   0.00559897]\n",
      " [0.00051499 0.00165315]]\n",
      "Train Epoch76 out_loss 0.0015956093557178974\n",
      "Test Epoch76 layer0 out_loss 0.007372585590928793\n",
      "Test Epoch76 layer1 out_loss 0.0007188945892266929\n",
      "Train 77 | out_loss 0.00113315146882087: 100%|█| 138/138 [00:00<00:00, 472.89it/\n",
      "[[6.56857937e-05 6.17427725e-03]\n",
      " [4.54928200e-04 1.78034496e-03]]\n",
      "Train Epoch77 out_loss 0.00113315146882087\n",
      "Test Epoch77 layer0 out_loss 0.0033204220235347748\n",
      "Test Epoch77 layer1 out_loss 0.0015396494418382645\n",
      "Train 78 | out_loss 0.001984591130167246: 100%|█| 138/138 [00:00<00:00, 468.66it\n",
      "[[0.00038105 0.0094232 ]\n",
      " [0.00025949 0.00133703]]\n",
      "Train Epoch78 out_loss 0.001984591130167246\n",
      "Test Epoch78 layer0 out_loss 0.003755746642127633\n",
      "Test Epoch78 layer1 out_loss 0.0009103016927838326\n",
      "Train 79 | out_loss 0.002258765045553446: 100%|█| 138/138 [00:00<00:00, 475.05it\n",
      "[[0.00060873 0.03503727]\n",
      " [0.00040649 0.00315236]]\n",
      "Train Epoch79 out_loss 0.002258765045553446\n",
      "Test Epoch79 layer0 out_loss 0.013791228644549847\n",
      "Test Epoch79 layer1 out_loss 0.0028964937664568424\n",
      "Train 80 | out_loss 0.0022149125579744577: 100%|█| 138/138 [00:00<00:00, 478.09i\n",
      "[[0.00038361 0.0331739 ]\n",
      " [0.000384   0.00280617]]\n",
      "Train Epoch80 out_loss 0.0022149125579744577\n",
      "Test Epoch80 layer0 out_loss 0.005361068993806839\n",
      "Test Epoch80 layer1 out_loss 0.0008504907018505037\n",
      "Train 81 | out_loss 0.0020552179776132107: 100%|█| 138/138 [00:00<00:00, 453.76i\n",
      "[[0.00053581 0.0257778 ]\n",
      " [0.00039236 0.00201881]]\n",
      "Train Epoch81 out_loss 0.0020552179776132107\n",
      "Test Epoch81 layer0 out_loss 0.009713425301015377\n",
      "Test Epoch81 layer1 out_loss 0.0009137862361967564\n",
      "Train 82 | out_loss 0.001138694817200303: 100%|█| 138/138 [00:00<00:00, 467.70it\n",
      "[[4.72497181e-05 4.06450633e-02]\n",
      " [2.99221829e-04 2.11030109e-03]]\n",
      "Train Epoch82 out_loss 0.001138694817200303\n",
      "Test Epoch82 layer0 out_loss 0.011135507375001907\n",
      "Test Epoch82 layer1 out_loss 0.0005040072137489915\n",
      "Train 83 | out_loss 0.0018791339825838804: 100%|█| 138/138 [00:00<00:00, 478.09i\n",
      "[[0.00043276 0.01257809]\n",
      " [0.00034448 0.00150999]]\n",
      "Train Epoch83 out_loss 0.0018791339825838804\n",
      "Test Epoch83 layer0 out_loss 0.0037700708489865065\n",
      "Test Epoch83 layer1 out_loss 0.0007282938458956778\n",
      "Train 84 | out_loss 0.001840050332248211: 100%|█| 138/138 [00:00<00:00, 467.60it\n",
      "[[0.00047986 0.00476814]\n",
      " [0.00040323 0.00144696]]\n",
      "Train Epoch84 out_loss 0.001840050332248211\n",
      "Test Epoch84 layer0 out_loss 0.002252246020361781\n",
      "Test Epoch84 layer1 out_loss 0.0006626707618124783\n",
      "Train 85 | out_loss 0.001759762642905116: 100%|█| 138/138 [00:00<00:00, 481.76it\n",
      "[[0.00043796 0.003177  ]\n",
      " [0.00042855 0.001744  ]]\n",
      "Train Epoch85 out_loss 0.001759762642905116\n",
      "Test Epoch85 layer0 out_loss 0.006243044976145029\n",
      "Test Epoch85 layer1 out_loss 0.002460409887135029\n",
      "Train 86 | out_loss 0.00139001349452883: 100%|█| 138/138 [00:00<00:00, 483.08it/\n",
      "[[1.99829284e-05 8.00284944e-03]\n",
      " [2.67045751e-04 1.74194500e-03]]\n",
      "Train Epoch86 out_loss 0.00139001349452883\n",
      "Test Epoch86 layer0 out_loss 0.008752386085689068\n",
      "Test Epoch86 layer1 out_loss 0.0011082380078732967\n",
      "Train 87 | out_loss 0.0023476469796150923: 100%|█| 138/138 [00:00<00:00, 488.09i\n",
      "[[0.00062716 0.06330128]\n",
      " [0.00030527 0.00417598]]\n",
      "Train Epoch87 out_loss 0.0023476469796150923\n",
      "Test Epoch87 layer0 out_loss 0.007726244628429413\n",
      "Test Epoch87 layer1 out_loss 0.0012332957703620195\n",
      "Train 88 | out_loss 0.0016273574437946081: 100%|█| 138/138 [00:00<00:00, 480.33i\n",
      "[[0.00042348 0.0057771 ]\n",
      " [0.00032031 0.00122384]]\n",
      "Train Epoch88 out_loss 0.0016273574437946081\n",
      "Test Epoch88 layer0 out_loss 0.0020740237087011337\n",
      "Test Epoch88 layer1 out_loss 0.0013078893534839153\n",
      "Train 89 | out_loss 0.0017702748300507665: 100%|█| 138/138 [00:00<00:00, 488.67i\n",
      "[[0.00040998 0.01049133]\n",
      " [0.00034222 0.00161819]]\n",
      "Train Epoch89 out_loss 0.0017702748300507665\n",
      "Test Epoch89 layer0 out_loss 0.0035009700804948807\n",
      "Test Epoch89 layer1 out_loss 0.0013794288970530033\n",
      "Train 90 | out_loss 0.001217547571286559: 100%|█| 138/138 [00:00<00:00, 483.24it\n",
      "[[5.63824745e-05 1.19255116e-02]\n",
      " [4.02718918e-04 2.26952424e-03]]\n",
      "Train Epoch90 out_loss 0.001217547571286559\n",
      "Test Epoch90 layer0 out_loss 0.002147807041183114\n",
      "Test Epoch90 layer1 out_loss 0.0006301904795691371\n",
      "Train 91 | out_loss 0.002074102871119976: 100%|█| 138/138 [00:00<00:00, 468.02it\n",
      "[[0.00074313 0.00549174]\n",
      " [0.00027049 0.0015716 ]]\n",
      "Train Epoch91 out_loss 0.002074102871119976\n",
      "Test Epoch91 layer0 out_loss 0.0031879725866019726\n",
      "Test Epoch91 layer1 out_loss 0.0010788793442770839\n",
      "Train 92 | out_loss 0.0028805925976485014: 100%|█| 138/138 [00:00<00:00, 489.97i\n",
      "[[4.60924677e-06 1.22802983e-02]\n",
      " [6.42197649e-03 3.78210347e-02]]\n",
      "Train Epoch92 out_loss 0.0028805925976485014\n",
      "Test Epoch92 layer0 out_loss 0.010450971312820911\n",
      "Test Epoch92 layer1 out_loss 0.009360933676362038\n",
      "Train 93 | out_loss 0.004040162079036236: 100%|█| 138/138 [00:00<00:00, 478.87it\n",
      "[[0.00041623 0.01010897]\n",
      " [0.00134282 0.02551377]]\n",
      "Train Epoch93 out_loss 0.004040162079036236\n",
      "Test Epoch93 layer0 out_loss 0.0032937664072960615\n",
      "Test Epoch93 layer1 out_loss 0.0004945205873809755\n",
      "Train 94 | out_loss 0.001684851828031242: 100%|█| 138/138 [00:00<00:00, 479.88it\n",
      "[[4.30719215e-04 4.06489480e-03]\n",
      " [4.86909557e-06 3.19231572e-04]]\n",
      "Train Epoch94 out_loss 0.001684851828031242\n",
      "Test Epoch94 layer0 out_loss 0.0022569778375327587\n",
      "Test Epoch94 layer1 out_loss 0.0005219695740379393\n",
      "Train 95 | out_loss 0.001783823943696916: 100%|█| 138/138 [00:00<00:00, 484.31it\n",
      "[[4.73961190e-04 6.51893382e-03]\n",
      " [5.56193224e-06 3.95753791e-04]]\n",
      "Train Epoch95 out_loss 0.001783823943696916\n",
      "Test Epoch95 layer0 out_loss 0.010384300723671913\n",
      "Test Epoch95 layer1 out_loss 0.0007193759665824473\n",
      "Train 96 | out_loss 0.002198432805016637: 100%|█| 138/138 [00:00<00:00, 470.54it\n",
      "[[5.72679820e-04 2.18894143e-02]\n",
      " [6.26768666e-06 1.77952245e-03]]\n",
      "Train Epoch96 out_loss 0.002198432805016637\n",
      "Test Epoch96 layer0 out_loss 0.0029236250557005405\n",
      "Test Epoch96 layer1 out_loss 0.0005615565460175276\n",
      "Train 97 | out_loss 0.0008892135811038315: 100%|█| 138/138 [00:00<00:00, 474.37i\n",
      "[[7.57218585e-06 9.76078792e-03]\n",
      " [8.35371742e-05 7.13205838e-04]]\n",
      "Train Epoch97 out_loss 0.0008892135811038315\n",
      "Test Epoch97 layer0 out_loss 0.012209707871079445\n",
      "Test Epoch97 layer1 out_loss 0.003090562531724572\n",
      "Train 98 | out_loss 0.0019378496799618006: 100%|█| 138/138 [00:00<00:00, 460.32i\n",
      "[[4.45866674e-04 1.14340075e-02]\n",
      " [1.81612772e-05 1.41445328e-03]]\n",
      "Train Epoch98 out_loss 0.0019378496799618006\n",
      "Test Epoch98 layer0 out_loss 0.0020399668719619513\n",
      "Test Epoch98 layer1 out_loss 0.0006739139789715409\n",
      "Train 99 | out_loss 0.0017511455807834864: 100%|█| 138/138 [00:00<00:00, 481.11i\n",
      "[[0.00049788 0.00631883]\n",
      " [0.00015467 0.00084454]]\n",
      "Train Epoch99 out_loss 0.0017511455807834864\n",
      "Test Epoch99 layer0 out_loss 0.00914895161986351\n",
      "Test Epoch99 layer1 out_loss 0.0008964852313511074\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Start Training\n",
      "  0%|                                                   | 0/138 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 0.04776887968182564: 100%|█| 138/138 [00:00<00:00, 178.30it/s\n",
      "[[ 0.7306857  27.24037116]\n",
      " [ 1.36852079 10.00273465]\n",
      " [ 0.90174139  4.7005544 ]]\n",
      "Train Epoch0 out_loss 0.04776887968182564\n",
      "Test Epoch0 layer0 out_loss 0.10063321143388748\n",
      "Test Epoch0 layer1 out_loss 0.019004132598638535\n",
      "Test Epoch0 layer2 out_loss 0.003960346803069115\n",
      "Train 1 | out_loss 0.0028528824914246798: 100%|█| 138/138 [00:00<00:00, 347.27it\n",
      "[[3.20904485e-05 6.03156273e+00]\n",
      " [5.17715549e-06 1.73109503e-01]\n",
      " [7.43303675e-06 5.66801155e-02]]\n",
      "Train Epoch1 out_loss 0.0028528824914246798\n",
      "Test Epoch1 layer0 out_loss 0.07366092503070831\n",
      "Test Epoch1 layer1 out_loss 0.00783522892743349\n",
      "Test Epoch1 layer2 out_loss 0.002354196971282363\n",
      "Train 2 | out_loss 0.0020239984150975943: 100%|█| 138/138 [00:00<00:00, 342.51it\n",
      "[[3.13957208e-05 3.31408868e+00]\n",
      " [4.75563770e-06 6.42525247e-02]\n",
      " [1.11422591e-06 1.88777162e-02]]\n",
      "Train Epoch2 out_loss 0.0020239984150975943\n",
      "Test Epoch2 layer0 out_loss 0.04161548241972923\n",
      "Test Epoch2 layer1 out_loss 0.005477570928633213\n",
      "Test Epoch2 layer2 out_loss 0.0019279640400782228\n",
      "Train 3 | out_loss 0.0018019034760072827: 100%|█| 138/138 [00:00<00:00, 338.81it\n",
      "[[3.13822572e-05 3.07651925e+00]\n",
      " [5.02895988e-06 4.02165973e-02]\n",
      " [1.19907188e-06 1.11442892e-02]]\n",
      "Train Epoch3 out_loss 0.0018019034760072827\n",
      "Test Epoch3 layer0 out_loss 0.11855313926935196\n",
      "Test Epoch3 layer1 out_loss 0.004100387450307608\n",
      "Test Epoch3 layer2 out_loss 0.001699423068203032\n",
      "Train 4 | out_loss 0.001522376318462193: 100%|█| 138/138 [00:00<00:00, 344.28it/\n",
      "[[3.11367499e-05 1.77440417e+00]\n",
      " [8.13966367e-06 2.48962746e-02]\n",
      " [1.31763737e-06 6.98324536e-03]]\n",
      "Train Epoch4 out_loss 0.001522376318462193\n",
      "Test Epoch4 layer0 out_loss 0.05722896382212639\n",
      "Test Epoch4 layer1 out_loss 0.002837042324244976\n",
      "Test Epoch4 layer2 out_loss 0.0014306012308225036\n",
      "Train 5 | out_loss 0.001392143894918263: 100%|█| 138/138 [00:00<00:00, 344.39it/\n",
      "[[3.09516805e-05 1.69703350e+00]\n",
      " [9.70986731e-06 1.96741948e-02]\n",
      " [1.56274401e-06 5.47302371e-03]]\n",
      "Train Epoch5 out_loss 0.001392143894918263\n",
      "Test Epoch5 layer0 out_loss 0.03620937839150429\n",
      "Test Epoch5 layer1 out_loss 0.002666901098564267\n",
      "Test Epoch5 layer2 out_loss 0.0013876593438908458\n",
      "Train 6 | out_loss 0.0011636537965387106: 100%|█| 138/138 [00:00<00:00, 343.76it\n",
      "[[3.12941462e-05 1.19970472e+00]\n",
      " [1.16948411e-05 1.28560330e-02]\n",
      " [1.79921868e-06 3.75191536e-03]]\n",
      "Train Epoch6 out_loss 0.0011636537965387106\n",
      "Test Epoch6 layer0 out_loss 0.05660723149776459\n",
      "Test Epoch6 layer1 out_loss 0.0019928021356463432\n",
      "Test Epoch6 layer2 out_loss 0.0012922354508191347\n",
      "Train 7 | out_loss 0.0010525204706937075: 100%|█| 138/138 [00:00<00:00, 345.76it\n",
      "[[3.04327215e-05 8.26986066e-01]\n",
      " [1.19528168e-05 9.65084819e-03]\n",
      " [1.77995342e-06 2.91696301e-03]]\n",
      "Train Epoch7 out_loss 0.0010525204706937075\n",
      "Test Epoch7 layer0 out_loss 0.0350617952644825\n",
      "Test Epoch7 layer1 out_loss 0.0016826210776343942\n",
      "Test Epoch7 layer2 out_loss 0.0011218114523217082\n",
      "Train 8 | out_loss 0.0010084572713822126: 100%|█| 138/138 [00:00<00:00, 341.60it\n",
      "[[3.05094710e-05 1.09236170e+00]\n",
      " [1.35978120e-05 1.01164220e-02]\n",
      " [2.11799516e-06 2.90211553e-03]]\n",
      "Train Epoch8 out_loss 0.0010084572713822126\n",
      "Test Epoch8 layer0 out_loss 0.031097395345568657\n",
      "Test Epoch8 layer1 out_loss 0.001886584679596126\n",
      "Test Epoch8 layer2 out_loss 0.0009101693285629153\n",
      "Train 9 | out_loss 0.0008674132404848933: 100%|█| 138/138 [00:00<00:00, 335.67it\n",
      "[[2.99873391e-05 8.11058977e-01]\n",
      " [1.31947140e-05 7.30491564e-03]\n",
      " [2.28999738e-06 2.21176977e-03]]\n",
      "Train Epoch9 out_loss 0.0008674132404848933\n",
      "Test Epoch9 layer0 out_loss 0.0520627461373806\n",
      "Test Epoch9 layer1 out_loss 0.0014210615772753954\n",
      "Test Epoch9 layer2 out_loss 0.000845481117721647\n",
      "Train 10 | out_loss 0.0009686092380434275: 100%|█| 138/138 [00:00<00:00, 354.29i\n",
      "[[2.94164676e-05 9.98473894e-01]\n",
      " [1.93141538e-05 1.05923506e-02]\n",
      " [3.87586146e-06 2.87285520e-03]]\n",
      "Train Epoch10 out_loss 0.0009686092380434275\n",
      "Test Epoch10 layer0 out_loss 0.04509386420249939\n",
      "Test Epoch10 layer1 out_loss 0.0013802190078422427\n",
      "Test Epoch10 layer2 out_loss 0.000800238223746419\n",
      "Train 11 | out_loss 0.0008820224902592599: 100%|█| 138/138 [00:00<00:00, 350.77i\n",
      "[[2.92131003e-05 1.11837576e+00]\n",
      " [2.53132663e-05 8.40248383e-03]\n",
      " [6.29888704e-06 2.45768380e-03]]\n",
      "Train Epoch11 out_loss 0.0008820224902592599\n",
      "Test Epoch11 layer0 out_loss 0.04442631080746651\n",
      "Test Epoch11 layer1 out_loss 0.0017084678402170539\n",
      "Test Epoch11 layer2 out_loss 0.0010850811377167702\n",
      "Train 12 | out_loss 0.0006797437090426683: 100%|█| 138/138 [00:00<00:00, 350.66i\n",
      "[[2.92879725e-05 2.75315607e-01]\n",
      " [2.61124021e-05 4.12916157e-03]\n",
      " [1.61223671e-05 1.37419939e-03]]\n",
      "Train Epoch12 out_loss 0.0006797437090426683\n",
      "Test Epoch12 layer0 out_loss 0.01412506029009819\n",
      "Test Epoch12 layer1 out_loss 0.0011732315178960562\n",
      "Test Epoch12 layer2 out_loss 0.0006903763278387487\n",
      "Train 13 | out_loss 0.000643600826151669: 100%|█| 138/138 [00:00<00:00, 351.65it\n",
      "[[2.89950931e-05 4.03222147e-01]\n",
      " [3.49359941e-05 4.69601687e-03]\n",
      " [5.39664985e-05 1.39210253e-03]]\n",
      "Train Epoch13 out_loss 0.000643600826151669\n",
      "Test Epoch13 layer0 out_loss 0.012506470084190369\n",
      "Test Epoch13 layer1 out_loss 0.0011198624270036817\n",
      "Test Epoch13 layer2 out_loss 0.0006598240579478443\n",
      "Train 14 | out_loss 0.0006291073514148593: 100%|█| 138/138 [00:00<00:00, 353.56i\n",
      "[[2.79925842e-05 2.76086691e-01]\n",
      " [5.06439816e-05 3.86705857e-03]\n",
      " [3.40140308e-04 1.36406730e-03]]\n",
      "Train Epoch14 out_loss 0.0006291073514148593\n",
      "Test Epoch14 layer0 out_loss 0.035442106425762177\n",
      "Test Epoch14 layer1 out_loss 0.0011973390355706215\n",
      "Test Epoch14 layer2 out_loss 0.0006544981733895838\n",
      "Train 15 | out_loss 0.0006328725721687078: 100%|█| 138/138 [00:00<00:00, 348.01i\n",
      "[[2.69746454e-05 2.86024090e-01]\n",
      " [6.52298030e-05 3.78034684e-03]\n",
      " [4.98254053e-04 1.35088883e-03]]\n",
      "Train Epoch15 out_loss 0.0006328725721687078\n",
      "Test Epoch15 layer0 out_loss 0.010188528336584568\n",
      "Test Epoch15 layer1 out_loss 0.0009685170371085405\n",
      "Test Epoch15 layer2 out_loss 0.0005476393853314221\n",
      "Train 16 | out_loss 0.0006452480447478592: 100%|█| 138/138 [00:00<00:00, 332.58i\n",
      "[[2.69167069e-05 1.13607086e-01]\n",
      " [9.27512188e-05 2.73196219e-03]\n",
      " [6.33329026e-04 1.14482212e-03]]\n",
      "Train Epoch16 out_loss 0.0006452480447478592\n",
      "Test Epoch16 layer0 out_loss 0.023638369515538216\n",
      "Test Epoch16 layer1 out_loss 0.001371902646496892\n",
      "Test Epoch16 layer2 out_loss 0.0006824510055594146\n",
      "Train 17 | out_loss 0.0007684990996494889: 100%|█| 138/138 [00:00<00:00, 346.72i\n",
      "[[2.64045884e-05 6.96020228e-01]\n",
      " [1.35551940e-04 6.11667493e-03]\n",
      " [8.56900378e-04 2.10443116e-03]]\n",
      "Train Epoch17 out_loss 0.0007684990996494889\n",
      "Test Epoch17 layer0 out_loss 0.11715748906135559\n",
      "Test Epoch17 layer1 out_loss 0.004188616760075092\n",
      "Test Epoch17 layer2 out_loss 0.000971358094830066\n",
      "Train 18 | out_loss 0.000807308591902256: 100%|█| 138/138 [00:00<00:00, 349.59it\n",
      "[[2.50574428e-05 1.42561664e+00]\n",
      " [9.97771158e-05 9.27646221e-03]\n",
      " [4.33997228e-04 2.81557556e-03]]\n",
      "Train Epoch18 out_loss 0.000807308591902256\n",
      "Test Epoch18 layer0 out_loss 0.012681166641414165\n",
      "Test Epoch18 layer1 out_loss 0.0010379162849858403\n",
      "Test Epoch18 layer2 out_loss 0.0006036788690835238\n",
      "Train 19 | out_loss 0.0006253996980376542: 100%|█| 138/138 [00:00<00:00, 349.79i\n",
      "[[2.49220672e-05 3.53174500e-01]\n",
      " [1.42591129e-04 3.46278475e-03]\n",
      " [6.88448678e-04 1.45079510e-03]]\n",
      "Train Epoch19 out_loss 0.0006253996980376542\n",
      "Test Epoch19 layer0 out_loss 0.03700437396764755\n",
      "Test Epoch19 layer1 out_loss 0.0014628537464886904\n",
      "Test Epoch19 layer2 out_loss 0.0006510837702080607\n",
      "Train 20 | out_loss 0.0006282678805291653: 100%|█| 138/138 [00:00<00:00, 352.30i\n",
      "[[2.40020527e-05 1.12279723e-01]\n",
      " [1.24880150e-04 2.52529103e-03]\n",
      " [3.95826646e-04 1.07743468e-03]]\n",
      "Train Epoch20 out_loss 0.0006282678805291653\n",
      "Test Epoch20 layer0 out_loss 0.010183833539485931\n",
      "Test Epoch20 layer1 out_loss 0.0009752170299179852\n",
      "Test Epoch20 layer2 out_loss 0.000582888547796756\n",
      "Train 21 | out_loss 0.0006379389087669551: 100%|█| 138/138 [00:00<00:00, 347.81i\n",
      "[[2.49086415e-05 4.36120618e-02]\n",
      " [2.16060619e-04 1.85837814e-03]\n",
      " [8.10039229e-04 1.10669871e-03]]\n",
      "Train Epoch21 out_loss 0.0006379389087669551\n",
      "Test Epoch21 layer0 out_loss 0.0044560241512954235\n",
      "Test Epoch21 layer1 out_loss 0.0011488654417917132\n",
      "Test Epoch21 layer2 out_loss 0.0007465848466381431\n",
      "Train 22 | out_loss 0.0006198432529345155: 100%|█| 138/138 [00:00<00:00, 342.55i\n",
      "[[2.39318589e-05 1.13976277e-01]\n",
      " [2.61385702e-04 2.05651921e-03]\n",
      " [7.63015402e-04 1.12710482e-03]]\n",
      "Train Epoch22 out_loss 0.0006198432529345155\n",
      "Test Epoch22 layer0 out_loss 0.016474658623337746\n",
      "Test Epoch22 layer1 out_loss 0.0009180425549857318\n",
      "Test Epoch22 layer2 out_loss 0.0005813515745103359\n",
      "Train 23 | out_loss 0.0008183514000847936: 100%|█| 138/138 [00:00<00:00, 342.83i\n",
      "[[2.30935053e-05 8.25809780e-01]\n",
      " [4.88339304e-04 4.84228180e-03]\n",
      " [1.18715163e-03 2.14191293e-03]]\n",
      "Train Epoch23 out_loss 0.0008183514000847936\n",
      "Test Epoch23 layer0 out_loss 0.055506836622953415\n",
      "Test Epoch23 layer1 out_loss 0.0011971883941441774\n",
      "Test Epoch23 layer2 out_loss 0.0007448468240909278\n",
      "Train 24 | out_loss 0.0006288066506385803: 100%|█| 138/138 [00:00<00:00, 348.00i\n",
      "[[2.22640255e-05 4.98293982e-01]\n",
      " [1.21744944e-04 2.70921904e-03]\n",
      " [1.98519718e-04 9.96580376e-04]]\n",
      "Train Epoch24 out_loss 0.0006288066506385803\n",
      "Test Epoch24 layer0 out_loss 0.07947233319282532\n",
      "Test Epoch24 layer1 out_loss 0.0016370306257158518\n",
      "Test Epoch24 layer2 out_loss 0.0006600414053536952\n",
      "Train 25 | out_loss 0.0006818242836743593: 100%|█| 138/138 [00:00<00:00, 346.01i\n",
      "[[2.11667255e-05 3.27616030e-01]\n",
      " [3.69241685e-04 2.66701380e-03]\n",
      " [6.78987438e-04 1.38799428e-03]]\n",
      "Train Epoch25 out_loss 0.0006818242836743593\n",
      "Test Epoch25 layer0 out_loss 0.007370012812316418\n",
      "Test Epoch25 layer1 out_loss 0.000861058768350631\n",
      "Test Epoch25 layer2 out_loss 0.0005143832531757653\n",
      "Train 26 | out_loss 0.0005860390956513584: 100%|█| 138/138 [00:00<00:00, 349.38i\n",
      "[[1.93309905e-05 1.03397696e-01]\n",
      " [3.39904351e-04 1.52644415e-03]\n",
      " [6.73463190e-04 9.07840829e-04]]\n",
      "Train Epoch26 out_loss 0.0005860390956513584\n",
      "Test Epoch26 layer0 out_loss 0.012062384746968746\n",
      "Test Epoch26 layer1 out_loss 0.0011621081503108144\n",
      "Test Epoch26 layer2 out_loss 0.0004967835266143084\n",
      "Train 27 | out_loss 0.0006907571805641055: 100%|█| 138/138 [00:00<00:00, 333.91i\n",
      "[[1.94995123e-05 1.44651578e-01]\n",
      " [3.03702487e-04 1.81338764e-03]\n",
      " [4.78574274e-04 9.35949058e-04]]\n",
      "Train Epoch27 out_loss 0.0006907571805641055\n",
      "Test Epoch27 layer0 out_loss 0.004174030851572752\n",
      "Test Epoch27 layer1 out_loss 0.001228079665452242\n",
      "Test Epoch27 layer2 out_loss 0.000808516051620245\n",
      "Train 28 | out_loss 0.0006686834967695177: 100%|█| 138/138 [00:00<00:00, 342.98i\n",
      "[[2.03813855e-05 1.66377789e-01]\n",
      " [4.51545267e-04 2.65541874e-03]\n",
      " [7.48214288e-04 1.28774847e-03]]\n",
      "Train Epoch28 out_loss 0.0006686834967695177\n",
      "Test Epoch28 layer0 out_loss 0.015099631622433662\n",
      "Test Epoch28 layer1 out_loss 0.001087668933905661\n",
      "Test Epoch28 layer2 out_loss 0.0006145446095615625\n",
      "Train 29 | out_loss 0.0007210891926661134: 100%|█| 138/138 [00:00<00:00, 343.94i\n",
      "[[1.84757413e-05 1.59483211e-01]\n",
      " [5.08124288e-04 3.23556855e-03]\n",
      " [8.03928882e-04 1.81596980e-03]]\n",
      "Train Epoch29 out_loss 0.0007210891926661134\n",
      "Test Epoch29 layer0 out_loss 0.028474150225520134\n",
      "Test Epoch29 layer1 out_loss 0.0008197040297091007\n",
      "Test Epoch29 layer2 out_loss 0.0005052998312748969\n",
      "Train 30 | out_loss 0.0006773968925699592: 100%|█| 138/138 [00:00<00:00, 348.57i\n",
      "[[1.82461253e-05 1.74575956e-01]\n",
      " [4.30117479e-04 2.14671347e-03]\n",
      " [6.89559267e-04 1.11842131e-03]]\n",
      "Train Epoch30 out_loss 0.0006773968925699592\n",
      "Test Epoch30 layer0 out_loss 0.015353185124695301\n",
      "Test Epoch30 layer1 out_loss 0.0021598723251372576\n",
      "Test Epoch30 layer2 out_loss 0.0007406247896142304\n",
      "Train 31 | out_loss 0.0005900406395085156: 100%|█| 138/138 [00:00<00:00, 348.61i\n",
      "[[1.96380408e-05 2.77356137e-01]\n",
      " [4.67180436e-04 2.18617144e-03]\n",
      " [6.12754925e-04 1.02791522e-03]]\n",
      "Train Epoch31 out_loss 0.0005900406395085156\n",
      "Test Epoch31 layer0 out_loss 0.01665719598531723\n",
      "Test Epoch31 layer1 out_loss 0.0008330376003868878\n",
      "Test Epoch31 layer2 out_loss 0.0006362443673424423\n",
      "Train 32 | out_loss 0.0005586751503869891: 100%|█| 138/138 [00:00<00:00, 341.42i\n",
      "[[1.68505068e-05 2.63321985e-02]\n",
      " [5.30780685e-04 1.14312745e-03]\n",
      " [8.00478947e-04 1.04549303e-03]]\n",
      "Train Epoch32 out_loss 0.0005586751503869891\n",
      "Test Epoch32 layer0 out_loss 0.008181951008737087\n",
      "Test Epoch32 layer1 out_loss 0.0007811438990756869\n",
      "Test Epoch32 layer2 out_loss 0.0007902255747467279\n",
      "Train 33 | out_loss 0.0006568035460077226: 100%|█| 138/138 [00:00<00:00, 340.31i\n",
      "[[1.62267567e-05 5.85831685e-01]\n",
      " [5.27662324e-04 2.95311931e-03]\n",
      " [6.90615674e-04 1.40233969e-03]]\n",
      "Train Epoch33 out_loss 0.0006568035460077226\n",
      "Test Epoch33 layer0 out_loss 0.03268081322312355\n",
      "Test Epoch33 layer1 out_loss 0.0017138266703113914\n",
      "Test Epoch33 layer2 out_loss 0.0009536215802654624\n",
      "Train 34 | out_loss 0.0006151267443783581: 100%|█| 138/138 [00:00<00:00, 340.67i\n",
      "[[1.86554419e-05 2.15491080e-01]\n",
      " [6.24382871e-04 2.08548025e-03]\n",
      " [1.14312713e-03 1.51428736e-03]]\n",
      "Train Epoch34 out_loss 0.0006151267443783581\n",
      "Test Epoch34 layer0 out_loss 0.023085324093699455\n",
      "Test Epoch34 layer1 out_loss 0.0014032978797331452\n",
      "Test Epoch34 layer2 out_loss 0.0005825269618071616\n",
      "Train 35 | out_loss 0.0005558148841373622: 100%|█| 138/138 [00:00<00:00, 342.49i\n",
      "[[1.37474640e-05 8.26079351e-02]\n",
      " [4.16970709e-04 1.30048496e-03]\n",
      " [5.89125538e-04 8.41876986e-04]]\n",
      "Train Epoch35 out_loss 0.0005558148841373622\n",
      "Test Epoch35 layer0 out_loss 0.004332992248237133\n",
      "Test Epoch35 layer1 out_loss 0.0008084472501650453\n",
      "Test Epoch35 layer2 out_loss 0.0006162318750284612\n",
      "Train 36 | out_loss 0.000622222141828388: 100%|█| 138/138 [00:00<00:00, 337.59it\n",
      "[[1.39331777e-05 3.03333860e-02]\n",
      " [7.20606201e-04 1.40351010e-03]\n",
      " [8.18964175e-04 1.31947252e-03]]\n",
      "Train Epoch36 out_loss 0.000622222141828388\n",
      "Test Epoch36 layer0 out_loss 0.008076004683971405\n",
      "Test Epoch36 layer1 out_loss 0.0007481182110495865\n",
      "Test Epoch36 layer2 out_loss 0.000777142180595547\n",
      "Train 37 | out_loss 0.000656098360195756: 100%|█| 138/138 [00:00<00:00, 337.25it\n",
      "[[1.24813791e-05 2.02170094e-01]\n",
      " [5.64148306e-04 2.39513179e-03]\n",
      " [7.89735075e-04 1.25292270e-03]]\n",
      "Train Epoch37 out_loss 0.000656098360195756\n",
      "Test Epoch37 layer0 out_loss 0.004450303968042135\n",
      "Test Epoch37 layer1 out_loss 0.0008286248194053769\n",
      "Test Epoch37 layer2 out_loss 0.0005898953531868756\n",
      "Train 38 | out_loss 0.0006463163299486041: 100%|█| 138/138 [00:00<00:00, 320.84i\n",
      "[[1.79039022e-05 1.26946875e-02]\n",
      " [3.61655943e-04 9.49675227e-04]\n",
      " [4.79875871e-04 8.17515966e-04]]\n",
      "Train Epoch38 out_loss 0.0006463163299486041\n",
      "Test Epoch38 layer0 out_loss 0.0030162734910845757\n",
      "Test Epoch38 layer1 out_loss 0.0007998632499948144\n",
      "Test Epoch38 layer2 out_loss 0.000555065053049475\n",
      "Train 39 | out_loss 0.0006998342578299344: 100%|█| 138/138 [00:00<00:00, 321.06i\n",
      "[[1.08762534e-05 1.07960630e-01]\n",
      " [6.53126700e-04 1.96392217e-03]\n",
      " [8.12290164e-04 1.40811602e-03]]\n",
      "Train Epoch39 out_loss 0.0006998342578299344\n",
      "Test Epoch39 layer0 out_loss 0.021792389452457428\n",
      "Test Epoch39 layer1 out_loss 0.0009846861939877272\n",
      "Test Epoch39 layer2 out_loss 0.0006497356225736439\n",
      "Train 40 | out_loss 0.0006715767085552216: 100%|█| 138/138 [00:00<00:00, 339.21i\n",
      "[[1.68355806e-05 3.19724819e-01]\n",
      " [5.24529833e-04 2.88460757e-03]\n",
      " [7.46103691e-04 1.57586863e-03]]\n",
      "Train Epoch40 out_loss 0.0006715767085552216\n",
      "Test Epoch40 layer0 out_loss 0.014391796663403511\n",
      "Test Epoch40 layer1 out_loss 0.000901069724932313\n",
      "Test Epoch40 layer2 out_loss 0.0006229366990737617\n",
      "Train 41 | out_loss 0.0007892702706158161: 100%|█| 138/138 [00:00<00:00, 332.86i\n",
      "[[6.56588119e-05 1.19755429e-01]\n",
      " [5.45811093e-04 1.95502333e-03]\n",
      " [6.96895038e-04 1.14534507e-03]]\n",
      "Train Epoch41 out_loss 0.0007892702706158161\n",
      "Test Epoch41 layer0 out_loss 0.005014028400182724\n",
      "Test Epoch41 layer1 out_loss 0.0014306630473583937\n",
      "Test Epoch41 layer2 out_loss 0.0011500540422275662\n",
      "Train 42 | out_loss 0.0011351866414770484: 100%|█| 138/138 [00:00<00:00, 340.77i\n",
      "[[0.00023538 0.03675668]\n",
      " [0.00056359 0.00134326]\n",
      " [0.00065708 0.0012443 ]]\n",
      "Train Epoch42 out_loss 0.0011351866414770484\n",
      "Test Epoch42 layer0 out_loss 0.004326653201133013\n",
      "Test Epoch42 layer1 out_loss 0.001307257218286395\n",
      "Test Epoch42 layer2 out_loss 0.0017191794468089938\n",
      "Train 43 | out_loss 0.0014029723824933171: 100%|█| 138/138 [00:00<00:00, 343.82i\n",
      "[[0.00042672 0.11334134]\n",
      " [0.00057065 0.0028202 ]\n",
      " [0.00076792 0.00153653]]\n",
      "Train Epoch43 out_loss 0.0014029723824933171\n",
      "Test Epoch43 layer0 out_loss 0.002894916571676731\n",
      "Test Epoch43 layer1 out_loss 0.0010668858885765076\n",
      "Test Epoch43 layer2 out_loss 0.0004949909634888172\n",
      "Train 44 | out_loss 0.0011516064405441284: 100%|█| 138/138 [00:00<00:00, 343.23i\n",
      "[[0.000225   0.1407158 ]\n",
      " [0.00060875 0.00196688]\n",
      " [0.0006574  0.00129828]]\n",
      "Train Epoch44 out_loss 0.0011516064405441284\n",
      "Test Epoch44 layer0 out_loss 0.005434306338429451\n",
      "Test Epoch44 layer1 out_loss 0.000961866753641516\n",
      "Test Epoch44 layer2 out_loss 0.0005410870653577149\n",
      "Train 45 | out_loss 0.0012982384068891406: 100%|█| 138/138 [00:00<00:00, 343.12i\n",
      "[[0.00032995 0.19472585]\n",
      " [0.00046381 0.00254726]\n",
      " [0.00061569 0.00133383]]\n",
      "Train Epoch45 out_loss 0.0012982384068891406\n",
      "Test Epoch45 layer0 out_loss 0.007476207800209522\n",
      "Test Epoch45 layer1 out_loss 0.0019198862137272954\n",
      "Test Epoch45 layer2 out_loss 0.0020303798373788595\n",
      "Train 46 | out_loss 0.001213183393701911: 100%|█| 138/138 [00:00<00:00, 343.35it\n",
      "[[0.00027956 0.0755771 ]\n",
      " [0.00068149 0.00200606]\n",
      " [0.00082638 0.00163354]]\n",
      "Train Epoch46 out_loss 0.001213183393701911\n",
      "Test Epoch46 layer0 out_loss 0.00761270709335804\n",
      "Test Epoch46 layer1 out_loss 0.0017795107560232282\n",
      "Test Epoch46 layer2 out_loss 0.0019736613612622023\n",
      "Train 47 | out_loss 0.0014858931535854936: 100%|█| 138/138 [00:00<00:00, 343.05i\n",
      "[[0.00046458 0.03217386]\n",
      " [0.00039807 0.00136893]\n",
      " [0.00054109 0.00107176]]\n",
      "Train Epoch47 out_loss 0.0014858931535854936\n",
      "Test Epoch47 layer0 out_loss 0.004647380672395229\n",
      "Test Epoch47 layer1 out_loss 0.0006530299433507025\n",
      "Test Epoch47 layer2 out_loss 0.000680734752677381\n",
      "Train 48 | out_loss 0.0014411491574719548: 100%|█| 138/138 [00:00<00:00, 350.28i\n",
      "[[0.00038794 0.0464492 ]\n",
      " [0.00064109 0.00195209]\n",
      " [0.00112788 0.00224325]]\n",
      "Train Epoch48 out_loss 0.0014411491574719548\n",
      "Test Epoch48 layer0 out_loss 0.008817676454782486\n",
      "Test Epoch48 layer1 out_loss 0.0014974181540310383\n",
      "Test Epoch48 layer2 out_loss 0.000815286417491734\n",
      "Train 49 | out_loss 0.001038651796989143: 100%|█| 138/138 [00:00<00:00, 345.66it\n",
      "[[0.0002194  0.04652752]\n",
      " [0.0004797  0.00201911]\n",
      " [0.00044507 0.00098956]]\n",
      "Train Epoch49 out_loss 0.001038651796989143\n",
      "Test Epoch49 layer0 out_loss 0.0039199586026370525\n",
      "Test Epoch49 layer1 out_loss 0.000673634756822139\n",
      "Test Epoch49 layer2 out_loss 0.00048677888116799295\n",
      "Train 50 | out_loss 0.0011322408681735396: 100%|█| 138/138 [00:00<00:00, 340.16i\n",
      "[[0.0002248  0.01975885]\n",
      " [0.00052613 0.00166023]\n",
      " [0.00056394 0.00130756]]\n",
      "Train Epoch50 out_loss 0.0011322408681735396\n",
      "Test Epoch50 layer0 out_loss 0.005259979050606489\n",
      "Test Epoch50 layer1 out_loss 0.001032418105751276\n",
      "Test Epoch50 layer2 out_loss 0.00047286582412198186\n",
      "Train 51 | out_loss 0.0012657723855227232: 100%|█| 138/138 [00:00<00:00, 340.10i\n",
      "[[0.00033502 0.13359374]\n",
      " [0.00041032 0.00238258]\n",
      " [0.00047586 0.00111964]]\n",
      "Train Epoch51 out_loss 0.0012657723855227232\n",
      "Test Epoch51 layer0 out_loss 0.014485610648989677\n",
      "Test Epoch51 layer1 out_loss 0.0008314334554597735\n",
      "Test Epoch51 layer2 out_loss 0.0010902117937803268\n",
      "Train 52 | out_loss 0.0013214433565735817: 100%|█| 138/138 [00:00<00:00, 329.89i\n",
      "[[0.00040462 0.02076447]\n",
      " [0.00055488 0.0019845 ]\n",
      " [0.00068217 0.00144816]]\n",
      "Train Epoch52 out_loss 0.0013214433565735817\n",
      "Test Epoch52 layer0 out_loss 0.005161093547940254\n",
      "Test Epoch52 layer1 out_loss 0.0006881087902002037\n",
      "Test Epoch52 layer2 out_loss 0.00043639642535708845\n",
      "Train 53 | out_loss 0.001424709102138877: 100%|█| 138/138 [00:00<00:00, 335.24it\n",
      "[[0.00040891 0.05894017]\n",
      " [0.00062439 0.0024291 ]\n",
      " [0.00073854 0.00160578]]\n",
      "Train Epoch53 out_loss 0.001424709102138877\n",
      "Test Epoch53 layer0 out_loss 0.016078772023320198\n",
      "Test Epoch53 layer1 out_loss 0.0018107951618731022\n",
      "Test Epoch53 layer2 out_loss 0.0004584885318763554\n",
      "Train 54 | out_loss 0.0009061494492925704: 100%|█| 138/138 [00:00<00:00, 338.37i\n",
      "[[0.00013511 0.12345899]\n",
      " [0.00039884 0.00268071]\n",
      " [0.00058683 0.00131829]]\n",
      "Train Epoch54 out_loss 0.0009061494492925704\n",
      "Test Epoch54 layer0 out_loss 0.01296983752399683\n",
      "Test Epoch54 layer1 out_loss 0.0027375041972845793\n",
      "Test Epoch54 layer2 out_loss 0.0023061444517225027\n",
      "Train 55 | out_loss 0.0015307121211662889: 100%|█| 138/138 [00:00<00:00, 342.62i\n",
      "[[0.00045761 0.21246274]\n",
      " [0.00041174 0.00294832]\n",
      " [0.00047304 0.00151412]]\n",
      "Train Epoch55 out_loss 0.0015307121211662889\n",
      "Test Epoch55 layer0 out_loss 0.01186568383127451\n",
      "Test Epoch55 layer1 out_loss 0.0027359637897461653\n",
      "Test Epoch55 layer2 out_loss 0.0005180011503398418\n",
      "Train 56 | out_loss 0.0010665543377399445: 100%|█| 138/138 [00:00<00:00, 345.65i\n",
      "[[0.00018442 0.09626346]\n",
      " [0.00057637 0.00231986]\n",
      " [0.00066395 0.00134207]]\n",
      "Train Epoch56 out_loss 0.0010665543377399445\n",
      "Test Epoch56 layer0 out_loss 0.008059419691562653\n",
      "Test Epoch56 layer1 out_loss 0.0007689226767979562\n",
      "Test Epoch56 layer2 out_loss 0.0005852143513038754\n",
      "Train 57 | out_loss 0.0013783879112452269: 100%|█| 138/138 [00:00<00:00, 333.83i\n",
      "[[0.00041786 0.03878724]\n",
      " [0.00038551 0.00148439]\n",
      " [0.00052936 0.0013795 ]]\n",
      "Train Epoch57 out_loss 0.0013783879112452269\n",
      "Test Epoch57 layer0 out_loss 0.0027489790227264166\n",
      "Test Epoch57 layer1 out_loss 0.0006669863942079246\n",
      "Test Epoch57 layer2 out_loss 0.0007706151227466762\n",
      "Train 58 | out_loss 0.0013733240775763988: 100%|█| 138/138 [00:00<00:00, 339.29i\n",
      "[[0.00039275 0.00632339]\n",
      " [0.00049402 0.0016457 ]\n",
      " [0.00063752 0.00141699]]\n",
      "Train Epoch58 out_loss 0.0013733240775763988\n",
      "Test Epoch58 layer0 out_loss 0.0017758230678737164\n",
      "Test Epoch58 layer1 out_loss 0.0008644127519801259\n",
      "Test Epoch58 layer2 out_loss 0.0005841904203407466\n",
      "Train 59 | out_loss 0.0012039408320561051: 100%|█| 138/138 [00:00<00:00, 344.09i\n",
      "[[0.00027867 0.00740405]\n",
      " [0.00047516 0.00185426]\n",
      " [0.0007061  0.00146152]]\n",
      "Train Epoch59 out_loss 0.0012039408320561051\n",
      "Test Epoch59 layer0 out_loss 0.004677130840718746\n",
      "Test Epoch59 layer1 out_loss 0.0013391675893217325\n",
      "Test Epoch59 layer2 out_loss 0.0013859227765351534\n",
      "Train 60 | out_loss 0.0011251919204369187: 100%|█| 138/138 [00:00<00:00, 336.88i\n",
      "[[2.38603167e-04 2.84400776e-01]\n",
      " [4.34808473e-04 3.23407792e-03]\n",
      " [4.68934721e-04 1.48134563e-03]]\n",
      "Train Epoch60 out_loss 0.0011251919204369187\n",
      "Test Epoch60 layer0 out_loss 0.03509197384119034\n",
      "Test Epoch60 layer1 out_loss 0.0013278510887175798\n",
      "Test Epoch60 layer2 out_loss 0.0006001320434734225\n",
      "Train 61 | out_loss 0.001327713020145893: 100%|█| 138/138 [00:00<00:00, 340.32it\n",
      "[[0.00035679 0.0390945 ]\n",
      " [0.00051682 0.0020105 ]\n",
      " [0.00064839 0.00131593]]\n",
      "Train Epoch61 out_loss 0.001327713020145893\n",
      "Test Epoch61 layer0 out_loss 0.0025536767207086086\n",
      "Test Epoch61 layer1 out_loss 0.0010360615560784936\n",
      "Test Epoch61 layer2 out_loss 0.0005847542197443545\n",
      "Train 62 | out_loss 0.001340712420642376: 100%|█| 138/138 [00:00<00:00, 341.56it\n",
      "[[0.000367   0.00416646]\n",
      " [0.00035997 0.00143981]\n",
      " [0.00050181 0.00117753]]\n",
      "Train Epoch62 out_loss 0.001340712420642376\n",
      "Test Epoch62 layer0 out_loss 0.001613754779100418\n",
      "Test Epoch62 layer1 out_loss 0.0006763447890989482\n",
      "Test Epoch62 layer2 out_loss 0.0005649860831908882\n",
      "Train 63 | out_loss 0.0011964314617216587: 100%|█| 138/138 [00:00<00:00, 336.64i\n",
      "[[0.0002595  0.0182889 ]\n",
      " [0.00043021 0.00192274]\n",
      " [0.00058246 0.00125408]]\n",
      "Train Epoch63 out_loss 0.0011964314617216587\n",
      "Test Epoch63 layer0 out_loss 0.004925093613564968\n",
      "Test Epoch63 layer1 out_loss 0.0006967230001464486\n",
      "Test Epoch63 layer2 out_loss 0.0008517625974491239\n",
      "Train 64 | out_loss 0.0010613491758704185: 100%|█| 138/138 [00:00<00:00, 339.71i\n",
      "[[0.00019345 0.00894689]\n",
      " [0.00043618 0.00194411]\n",
      " [0.00055381 0.00129326]]\n",
      "Train Epoch64 out_loss 0.0010613491758704185\n",
      "Test Epoch64 layer0 out_loss 0.0023126814048737288\n",
      "Test Epoch64 layer1 out_loss 0.0008361894288100302\n",
      "Test Epoch64 layer2 out_loss 0.0010685541201382875\n",
      "Train 65 | out_loss 0.0014463863335549831: 100%|█| 138/138 [00:00<00:00, 339.76i\n",
      "[[0.00040104 0.06502124]\n",
      " [0.00051168 0.00257009]\n",
      " [0.0005027  0.00120909]]\n",
      "Train Epoch65 out_loss 0.0014463863335549831\n",
      "Test Epoch65 layer0 out_loss 0.005403679329901934\n",
      "Test Epoch65 layer1 out_loss 0.0007346056518144906\n",
      "Test Epoch65 layer2 out_loss 0.0004898622282780707\n",
      "Train 66 | out_loss 0.001286352053284645: 100%|█| 138/138 [00:00<00:00, 342.72it\n",
      "[[0.0002876  0.06681915]\n",
      " [0.00043939 0.00293179]\n",
      " [0.00063024 0.00173234]]\n",
      "Train Epoch66 out_loss 0.001286352053284645\n",
      "Test Epoch66 layer0 out_loss 0.006498341914266348\n",
      "Test Epoch66 layer1 out_loss 0.001194658107124269\n",
      "Test Epoch66 layer2 out_loss 0.000498007342685014\n",
      "Train 67 | out_loss 0.0011007095454260707: 100%|█| 138/138 [00:00<00:00, 339.80i\n",
      "[[0.00025127 0.00762669]\n",
      " [0.00034405 0.00154764]\n",
      " [0.00047564 0.0010351 ]]\n",
      "Train Epoch67 out_loss 0.0011007095454260707\n",
      "Test Epoch67 layer0 out_loss 0.001562229823321104\n",
      "Test Epoch67 layer1 out_loss 0.001052694278769195\n",
      "Test Epoch67 layer2 out_loss 0.000437892391346395\n",
      "Train 68 | out_loss 0.001330163679085672: 100%|█| 138/138 [00:00<00:00, 341.40it\n",
      "[[0.00033309 0.00677406]\n",
      " [0.00045947 0.00194993]\n",
      " [0.00076606 0.00143777]]\n",
      "Train Epoch68 out_loss 0.001330163679085672\n",
      "Test Epoch68 layer0 out_loss 0.004481216426938772\n",
      "Test Epoch68 layer1 out_loss 0.0016104519600048661\n",
      "Test Epoch68 layer2 out_loss 0.00046277392539195716\n",
      "Train 69 | out_loss 0.0016891468549147248: 100%|█| 138/138 [00:00<00:00, 341.37i\n",
      "[[0.00062399 0.05013151]\n",
      " [0.000369   0.00250408]\n",
      " [0.00043703 0.00141204]]\n",
      "Train Epoch69 out_loss 0.0016891468549147248\n",
      "Test Epoch69 layer0 out_loss 0.008259965106844902\n",
      "Test Epoch69 layer1 out_loss 0.0007460804772563279\n",
      "Test Epoch69 layer2 out_loss 0.0005284850485622883\n",
      "Train 70 | out_loss 0.0005482397973537445: 100%|█| 138/138 [00:00<00:00, 340.66i\n",
      "[[5.92596631e-06 2.16358817e-02]\n",
      " [4.50470134e-04 2.14198503e-03]\n",
      " [6.40839364e-04 1.45167543e-03]]\n",
      "Train Epoch70 out_loss 0.0005482397973537445\n",
      "Test Epoch70 layer0 out_loss 0.007030931767076254\n",
      "Test Epoch70 layer1 out_loss 0.0015606330707669258\n",
      "Test Epoch70 layer2 out_loss 0.000629407586529851\n",
      "Train 71 | out_loss 0.0013857900630682707: 100%|█| 138/138 [00:00<00:00, 339.03i\n",
      "[[0.00038322 0.10958152]\n",
      " [0.00035958 0.00299514]\n",
      " [0.00042802 0.001351  ]]\n",
      "Train Epoch71 out_loss 0.0013857900630682707\n",
      "Test Epoch71 layer0 out_loss 0.035736333578825\n",
      "Test Epoch71 layer1 out_loss 0.0013554595643654466\n",
      "Test Epoch71 layer2 out_loss 0.000770875602029264\n",
      "Train 72 | out_loss 0.0013460980262607336: 100%|█| 138/138 [00:00<00:00, 339.88i\n",
      "[[0.00034185 0.06712434]\n",
      " [0.00033218 0.00275256]\n",
      " [0.00043837 0.00106568]]\n",
      "Train Epoch72 out_loss 0.0013460980262607336\n",
      "Test Epoch72 layer0 out_loss 0.0046072183176875114\n",
      "Test Epoch72 layer1 out_loss 0.0008502504788339138\n",
      "Test Epoch72 layer2 out_loss 0.0005296496674418449\n",
      "Train 73 | out_loss 0.0013519632630050182: 100%|█| 138/138 [00:00<00:00, 338.80i\n",
      "[[0.00038947 0.00462186]\n",
      " [0.00039175 0.00129723]\n",
      " [0.00045652 0.00095684]]\n",
      "Train Epoch73 out_loss 0.0013519632630050182\n",
      "Test Epoch73 layer0 out_loss 0.004121988080441952\n",
      "Test Epoch73 layer1 out_loss 0.001217121840454638\n",
      "Test Epoch73 layer2 out_loss 0.0007067073020152748\n",
      "Train 74 | out_loss 0.0011395480250939727: 100%|█| 138/138 [00:00<00:00, 339.83i\n",
      "[[0.00023562 0.03395013]\n",
      " [0.00035044 0.002122  ]\n",
      " [0.00054521 0.00121929]]\n",
      "Train Epoch74 out_loss 0.0011395480250939727\n",
      "Test Epoch74 layer0 out_loss 0.006386647000908852\n",
      "Test Epoch74 layer1 out_loss 0.00166204699780792\n",
      "Test Epoch74 layer2 out_loss 0.00044322575558908284\n",
      "Train 75 | out_loss 0.0011833661701530218: 100%|█| 138/138 [00:00<00:00, 342.79i\n",
      "[[0.00029918 0.01017704]\n",
      " [0.00035882 0.00174209]\n",
      " [0.00047721 0.00106149]]\n",
      "Train Epoch75 out_loss 0.0011833661701530218\n",
      "Test Epoch75 layer0 out_loss 0.0020960585679858923\n",
      "Test Epoch75 layer1 out_loss 0.0005516540259122849\n",
      "Test Epoch75 layer2 out_loss 0.0004434312286321074\n",
      "Train 76 | out_loss 0.001171886920928955: 100%|█| 138/138 [00:00<00:00, 347.29it\n",
      "[[0.0002499  0.02144051]\n",
      " [0.0004627  0.0022739 ]\n",
      " [0.00051362 0.00108215]]\n",
      "Train Epoch76 out_loss 0.001171886920928955\n",
      "Test Epoch76 layer0 out_loss 0.005771616939455271\n",
      "Test Epoch76 layer1 out_loss 0.0005321658100001514\n",
      "Test Epoch76 layer2 out_loss 0.0004257859836798161\n",
      "Train 77 | out_loss 0.0013770089717581868: 100%|█| 138/138 [00:00<00:00, 342.75i\n",
      "[[0.00039485 0.07455324]\n",
      " [0.00034951 0.00330072]\n",
      " [0.00058314 0.00149714]]\n",
      "Train Epoch77 out_loss 0.0013770089717581868\n",
      "Test Epoch77 layer0 out_loss 0.004107761196792126\n",
      "Test Epoch77 layer1 out_loss 0.0010461828205734491\n",
      "Test Epoch77 layer2 out_loss 0.0004898153711110353\n",
      "Train 78 | out_loss 0.0010179373202845454: 100%|█| 138/138 [00:00<00:00, 337.60i\n",
      "[[0.00019057 0.02760339]\n",
      " [0.00033141 0.00208624]\n",
      " [0.00042543 0.00097179]]\n",
      "Train Epoch78 out_loss 0.0010179373202845454\n",
      "Test Epoch78 layer0 out_loss 0.0019992361776530743\n",
      "Test Epoch78 layer1 out_loss 0.0012938696891069412\n",
      "Test Epoch78 layer2 out_loss 0.001294901710934937\n",
      "Train 79 | out_loss 0.0015326623106375337: 100%|█| 138/138 [00:00<00:00, 328.88i\n",
      "[[0.0004753  0.02021421]\n",
      " [0.0003347  0.00156916]\n",
      " [0.00038123 0.0008011 ]]\n",
      "Train Epoch79 out_loss 0.0015326623106375337\n",
      "Test Epoch79 layer0 out_loss 0.0034213587641716003\n",
      "Test Epoch79 layer1 out_loss 0.002851337194442749\n",
      "Test Epoch79 layer2 out_loss 0.0018424427835270762\n",
      "Train 80 | out_loss 0.0013488278491422534: 100%|█| 138/138 [00:00<00:00, 340.12i\n",
      "[[0.0003972  0.04357434]\n",
      " [0.00036047 0.00253837]\n",
      " [0.0006955  0.00133467]]\n",
      "Train Epoch80 out_loss 0.0013488278491422534\n",
      "Test Epoch80 layer0 out_loss 0.0038298051804304123\n",
      "Test Epoch80 layer1 out_loss 0.0006272526225075126\n",
      "Test Epoch80 layer2 out_loss 0.0005838677752763033\n",
      "Train 81 | out_loss 0.0006679124780930579: 100%|█| 138/138 [00:00<00:00, 345.10i\n",
      "[[5.05547784e-05 3.85104538e-02]\n",
      " [3.16394925e-04 2.25994576e-03]\n",
      " [3.38644400e-04 9.80673260e-04]]\n",
      "Train Epoch81 out_loss 0.0006679124780930579\n",
      "Test Epoch81 layer0 out_loss 0.0034466562792658806\n",
      "Test Epoch81 layer1 out_loss 0.0008610129007138312\n",
      "Test Epoch81 layer2 out_loss 0.0007809667149558663\n",
      "Train 82 | out_loss 0.001278266659937799: 100%|█| 138/138 [00:00<00:00, 348.29it\n",
      "[[0.00033936 0.0030149 ]\n",
      " [0.00027478 0.00119191]\n",
      " [0.00032374 0.00058066]]\n",
      "Train Epoch82 out_loss 0.001278266659937799\n",
      "Test Epoch82 layer0 out_loss 0.0014954020734876394\n",
      "Test Epoch82 layer1 out_loss 0.0006147174281068146\n",
      "Test Epoch82 layer2 out_loss 0.0005150065408088267\n",
      "Train 83 | out_loss 0.0012957293074578047: 100%|█| 138/138 [00:00<00:00, 339.48i\n",
      "[[0.00033534 0.01205608]\n",
      " [0.00047145 0.0023757 ]\n",
      " [0.00072586 0.00188608]]\n",
      "Train Epoch83 out_loss 0.0012957293074578047\n",
      "Test Epoch83 layer0 out_loss 0.017991425469517708\n",
      "Test Epoch83 layer1 out_loss 0.001367746852338314\n",
      "Test Epoch83 layer2 out_loss 0.0004578908847179264\n",
      "Train 84 | out_loss 0.0014639956643804908: 100%|█| 138/138 [00:00<00:00, 312.88i\n",
      "[[0.00047809 0.03424469]\n",
      " [0.00027325 0.00229502]\n",
      " [0.00041924 0.0008991 ]]\n",
      "Train Epoch84 out_loss 0.0014639956643804908\n",
      "Test Epoch84 layer0 out_loss 0.008427909575402737\n",
      "Test Epoch84 layer1 out_loss 0.0021202366333454847\n",
      "Test Epoch84 layer2 out_loss 0.0011428016005083919\n",
      "Train 85 | out_loss 0.0011844862019643188: 100%|█| 138/138 [00:00<00:00, 341.35i\n",
      "[[0.00028253 0.03392003]\n",
      " [0.00032833 0.00253928]\n",
      " [0.0003564  0.00097981]]\n",
      "Train Epoch85 out_loss 0.0011844862019643188\n",
      "Test Epoch85 layer0 out_loss 0.0031957896426320076\n",
      "Test Epoch85 layer1 out_loss 0.0014343118527904153\n",
      "Test Epoch85 layer2 out_loss 0.0011718550231307745\n",
      "Train 86 | out_loss 0.0011573386145755649: 100%|█| 138/138 [00:00<00:00, 342.29i\n",
      "[[0.00024503 0.02113339]\n",
      " [0.00040193 0.0019958 ]\n",
      " [0.00059625 0.00092441]]\n",
      "Train Epoch86 out_loss 0.0011573386145755649\n",
      "Test Epoch86 layer0 out_loss 0.007179123815149069\n",
      "Test Epoch86 layer1 out_loss 0.00211003003641963\n",
      "Test Epoch86 layer2 out_loss 0.0028665843419730663\n",
      "Train 87 | out_loss 0.001199330436065793: 100%|█| 138/138 [00:00<00:00, 339.25it\n",
      "[[0.00026806 0.00374216]\n",
      " [0.0002231  0.00125361]\n",
      " [0.00050995 0.00135046]]\n",
      "Train Epoch87 out_loss 0.001199330436065793\n",
      "Test Epoch87 layer0 out_loss 0.0021815081126987934\n",
      "Test Epoch87 layer1 out_loss 0.0012188665568828583\n",
      "Test Epoch87 layer2 out_loss 0.0005481057451106608\n",
      "Train 88 | out_loss 0.0011685775825753808: 100%|█| 138/138 [00:00<00:00, 330.88i\n",
      "[[0.00024838 0.01079537]\n",
      " [0.0003232  0.00180725]\n",
      " [0.00044897 0.00063277]]\n",
      "Train Epoch88 out_loss 0.0011685775825753808\n",
      "Test Epoch88 layer0 out_loss 0.02780972234904766\n",
      "Test Epoch88 layer1 out_loss 0.0024766004644334316\n",
      "Test Epoch88 layer2 out_loss 0.0006429117056541145\n",
      "Train 89 | out_loss 0.0012206397950649261: 100%|█| 138/138 [00:00<00:00, 334.23i\n",
      "[[0.00029938 0.08637032]\n",
      " [0.00030584 0.0045235 ]\n",
      " [0.0003338  0.00110693]]\n",
      "Train Epoch89 out_loss 0.0012206397950649261\n",
      "Test Epoch89 layer0 out_loss 0.0024320678785443306\n",
      "Test Epoch89 layer1 out_loss 0.0005140170105732977\n",
      "Test Epoch89 layer2 out_loss 0.00046842213487252593\n",
      "Train 90 | out_loss 0.0013586381683126092: 100%|█| 138/138 [00:00<00:00, 343.51i\n",
      "[[0.00034906 0.0021999 ]\n",
      " [0.00030335 0.00104614]\n",
      " [0.00039164 0.00046614]]\n",
      "Train Epoch90 out_loss 0.0013586381683126092\n",
      "Test Epoch90 layer0 out_loss 0.003189335111528635\n",
      "Test Epoch90 layer1 out_loss 0.0028173341415822506\n",
      "Test Epoch90 layer2 out_loss 0.003159980056807399\n",
      "Train 91 | out_loss 0.0017299739411100745: 100%|█| 138/138 [00:00<00:00, 337.40i\n",
      "[[0.00045543 0.00456734]\n",
      " [0.00099118 0.00728591]\n",
      " [0.00309123 0.01416867]]\n",
      "Train Epoch91 out_loss 0.0017299739411100745\n",
      "Test Epoch91 layer0 out_loss 0.0009919865988194942\n",
      "Test Epoch91 layer1 out_loss 0.0009061054443009198\n",
      "Test Epoch91 layer2 out_loss 0.000731691368855536\n",
      "Train 92 | out_loss 0.0011828282149508595: 100%|█| 138/138 [00:00<00:00, 322.88i\n",
      "[[2.51406106e-04 2.06311751e-03]\n",
      " [3.09454337e-05 3.26053374e-04]\n",
      " [4.51004509e-05 3.46067166e-04]]\n",
      "Train Epoch92 out_loss 0.0011828282149508595\n",
      "Test Epoch92 layer0 out_loss 0.0024538671132177114\n",
      "Test Epoch92 layer1 out_loss 0.0008612120873294771\n",
      "Test Epoch92 layer2 out_loss 0.0012879037531092763\n",
      "Train 93 | out_loss 0.001235655858181417: 100%|█| 138/138 [00:00<00:00, 335.95it\n",
      "[[0.00028948 0.03166889]\n",
      " [0.00020022 0.00241007]\n",
      " [0.00015509 0.00041068]]\n",
      "Train Epoch93 out_loss 0.001235655858181417\n",
      "Test Epoch93 layer0 out_loss 0.0075044273398816586\n",
      "Test Epoch93 layer1 out_loss 0.00044745233026333153\n",
      "Test Epoch93 layer2 out_loss 0.0008189138607122004\n",
      "Train 94 | out_loss 0.0011594786774367094: 100%|█| 138/138 [00:00<00:00, 338.62i\n",
      "[[0.00028068 0.00403791]\n",
      " [0.00020996 0.00097281]\n",
      " [0.00020817 0.00023113]]\n",
      "Train Epoch94 out_loss 0.0011594786774367094\n",
      "Test Epoch94 layer0 out_loss 0.0010029406985267997\n",
      "Test Epoch94 layer1 out_loss 0.0004908303963020444\n",
      "Test Epoch94 layer2 out_loss 0.00040464274934493005\n",
      "Train 95 | out_loss 0.0014948468888178468: 100%|█| 138/138 [00:00<00:00, 340.59i\n",
      "[[0.00047205 0.00435345]\n",
      " [0.00020185 0.0011046 ]\n",
      " [0.00018208 0.00023665]]\n",
      "Train Epoch95 out_loss 0.0014948468888178468\n",
      "Test Epoch95 layer0 out_loss 0.0011691355612128973\n",
      "Test Epoch95 layer1 out_loss 0.0005547880427911878\n",
      "Test Epoch95 layer2 out_loss 0.0005322967190295458\n",
      "Train 96 | out_loss 0.0004623313434422016: 100%|█| 138/138 [00:00<00:00, 341.25i\n",
      "[[3.40436131e-06 1.08796685e-02]\n",
      " [2.46752144e-04 1.78883122e-03]\n",
      " [2.07976007e-04 3.84608918e-04]]\n",
      "Train Epoch96 out_loss 0.0004623313434422016\n",
      "Test Epoch96 layer0 out_loss 0.005385546945035458\n",
      "Test Epoch96 layer1 out_loss 0.0019152120221406221\n",
      "Test Epoch96 layer2 out_loss 0.0006839793641120195\n",
      "Train 97 | out_loss 0.0013041163329035044: 100%|█| 138/138 [00:00<00:00, 342.21i\n",
      "[[0.00036863 0.00914582]\n",
      " [0.00057361 0.00383931]\n",
      " [0.00117322 0.00185999]]\n",
      "Train Epoch97 out_loss 0.0013041163329035044\n",
      "Test Epoch97 layer0 out_loss 0.001718191779218614\n",
      "Test Epoch97 layer1 out_loss 0.002103435341268778\n",
      "Test Epoch97 layer2 out_loss 0.0008577151456847787\n",
      "Train 98 | out_loss 0.001250587054528296: 100%|█| 138/138 [00:00<00:00, 316.61it\n",
      "[[2.52888284e-04 4.69452681e-03]\n",
      " [8.17841316e-05 1.27128959e-03]\n",
      " [2.01876984e-04 1.12184323e-03]]\n",
      "Train Epoch98 out_loss 0.001250587054528296\n",
      "Test Epoch98 layer0 out_loss 0.006183162797242403\n",
      "Test Epoch98 layer1 out_loss 0.0004633171483874321\n",
      "Test Epoch98 layer2 out_loss 0.00044756513671018183\n",
      "Train 99 | out_loss 0.0013343109749257565: 100%|█| 138/138 [00:00<00:00, 342.62i\n",
      "[[0.00038422 0.01266746]\n",
      " [0.00019875 0.0021109 ]\n",
      " [0.0002256  0.00035148]]\n",
      "Train Epoch99 out_loss 0.0013343109749257565\n",
      "Test Epoch99 layer0 out_loss 0.004267524927854538\n",
      "Test Epoch99 layer1 out_loss 0.0009621417266316712\n",
      "Test Epoch99 layer2 out_loss 0.00044109622831456363\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Start Training\n",
      "  0%|                                                   | 0/138 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 0.033156611025333405: 100%|█| 138/138 [00:00<00:00, 151.73it/\n",
      "[[ 0.04483918 26.61860983]\n",
      " [ 1.3054345  11.13079456]\n",
      " [ 0.78841801  5.25049794]\n",
      " [ 0.76409554  2.72479108]]\n",
      "Train Epoch0 out_loss 0.033156611025333405\n",
      "Test Epoch0 layer0 out_loss 0.09326625615358353\n",
      "Test Epoch0 layer1 out_loss 0.01359710842370987\n",
      "Test Epoch0 layer2 out_loss 0.004795412998646498\n",
      "Test Epoch0 layer3 out_loss 0.002374076284468174\n",
      "Train 1 | out_loss 0.001763289561495185: 100%|█| 138/138 [00:00<00:00, 266.30it/\n",
      "[[3.99111771e-05 6.09408514e+00]\n",
      " [5.46081384e-06 2.09721777e-01]\n",
      " [6.65476439e-06 7.98259605e-02]\n",
      " [7.70926469e-05 2.80245684e-02]]\n",
      "Train Epoch1 out_loss 0.001763289561495185\n",
      "Test Epoch1 layer0 out_loss 0.05682261288166046\n",
      "Test Epoch1 layer1 out_loss 0.01184039656072855\n",
      "Test Epoch1 layer2 out_loss 0.002613507444038987\n",
      "Test Epoch1 layer3 out_loss 0.0013920750934630632\n",
      "Train 2 | out_loss 0.001035269582644105: 100%|█| 138/138 [00:00<00:00, 263.00it/\n",
      "[[4.03794296e-05 3.09373849e+00]\n",
      " [5.71212415e-06 8.21649498e-02]\n",
      " [1.25013957e-06 2.81540604e-02]\n",
      " [6.58574264e-07 1.05189170e-02]]\n",
      "Train Epoch2 out_loss 0.001035269582644105\n",
      "Test Epoch2 layer0 out_loss 0.09075858443975449\n",
      "Test Epoch2 layer1 out_loss 0.005608163308352232\n",
      "Test Epoch2 layer2 out_loss 0.0016481098718941212\n",
      "Test Epoch2 layer3 out_loss 0.0007940885261632502\n",
      "Train 3 | out_loss 0.0007437457679770887: 100%|█| 138/138 [00:00<00:00, 258.04it\n",
      "[[3.76598451e-05 1.78566995e+00]\n",
      " [6.90930763e-06 3.98111638e-02]\n",
      " [1.40226391e-06 1.38392473e-02]\n",
      " [1.24795967e-06 5.37237042e-03]]\n",
      "Train Epoch3 out_loss 0.0007437457679770887\n",
      "Test Epoch3 layer0 out_loss 0.04008033126592636\n",
      "Test Epoch3 layer1 out_loss 0.0035919707734137774\n",
      "Test Epoch3 layer2 out_loss 0.0019320546416565776\n",
      "Test Epoch3 layer3 out_loss 0.000756111869122833\n",
      "Train 4 | out_loss 0.0006340591935440898: 100%|█| 138/138 [00:00<00:00, 266.15it\n",
      "[[3.71065712e-05 1.21198712e+00]\n",
      " [7.64687204e-06 2.53529683e-02]\n",
      " [1.47718899e-06 8.65421315e-03]\n",
      " [1.39849114e-06 3.38617314e-03]]\n",
      "Train Epoch4 out_loss 0.0006340591935440898\n",
      "Test Epoch4 layer0 out_loss 0.036607176065444946\n",
      "Test Epoch4 layer1 out_loss 0.0033668254036456347\n",
      "Test Epoch4 layer2 out_loss 0.0013879651669412851\n",
      "Test Epoch4 layer3 out_loss 0.0005811891751363873\n",
      "Train 5 | out_loss 0.0005875361384823918: 100%|█| 138/138 [00:00<00:00, 268.83it\n",
      "[[3.64208368e-05 1.11389713e+00]\n",
      " [7.41468293e-06 1.88294149e-02]\n",
      " [1.43957426e-06 6.13036613e-03]\n",
      " [1.34628215e-06 2.28807304e-03]]\n",
      "Train Epoch5 out_loss 0.0005875361384823918\n",
      "Test Epoch5 layer0 out_loss 0.01762169413268566\n",
      "Test Epoch5 layer1 out_loss 0.002388314576819539\n",
      "Test Epoch5 layer2 out_loss 0.0013113415334373713\n",
      "Test Epoch5 layer3 out_loss 0.0006308286683633924\n",
      "Train 6 | out_loss 0.0006003270973451436: 100%|█| 138/138 [00:00<00:00, 266.77it\n",
      "[[3.70914778e-05 1.12800202e+00]\n",
      " [7.06461596e-06 1.54331104e-02]\n",
      " [1.70920538e-06 4.83735580e-03]\n",
      " [1.90222041e-06 1.75746520e-03]]\n",
      "Train Epoch6 out_loss 0.0006003270973451436\n",
      "Test Epoch6 layer0 out_loss 0.0520707443356514\n",
      "Test Epoch6 layer1 out_loss 0.00207723886705935\n",
      "Test Epoch6 layer2 out_loss 0.0009694688487797976\n",
      "Test Epoch6 layer3 out_loss 0.0005076606757938862\n",
      "Train 7 | out_loss 0.0005673198611475527: 100%|█| 138/138 [00:00<00:00, 265.69it\n",
      "[[3.28824050e-05 1.13680665e+00]\n",
      " [9.76161953e-06 1.27530182e-02]\n",
      " [1.85187038e-06 4.12369057e-03]\n",
      " [2.68940410e-06 1.44122034e-03]]\n",
      "Train Epoch7 out_loss 0.0005673198611475527\n",
      "Test Epoch7 layer0 out_loss 0.023837760090827942\n",
      "Test Epoch7 layer1 out_loss 0.0017539102118462324\n",
      "Test Epoch7 layer2 out_loss 0.0007201822591014206\n",
      "Test Epoch7 layer3 out_loss 0.0005031421314924955\n",
      "Train 8 | out_loss 0.0005174233228899539: 100%|█| 138/138 [00:00<00:00, 259.23it\n",
      "[[3.83716854e-05 3.88709067e-01]\n",
      " [1.00680174e-05 5.87631912e-03]\n",
      " [2.65973474e-06 2.23154723e-03]\n",
      " [4.69320581e-06 8.17968355e-04]]\n",
      "Train Epoch8 out_loss 0.0005174233228899539\n",
      "Test Epoch8 layer0 out_loss 0.031050316989421844\n",
      "Test Epoch8 layer1 out_loss 0.0015554118435829878\n",
      "Test Epoch8 layer2 out_loss 0.0006530344253405929\n",
      "Test Epoch8 layer3 out_loss 0.0004729150969069451\n",
      "Train 9 | out_loss 0.0004877725150436163: 100%|█| 138/138 [00:00<00:00, 264.96it\n",
      "[[3.21358848e-05 6.61855515e-01]\n",
      " [9.51383734e-06 6.26193389e-03]\n",
      " [2.63432188e-06 2.05088960e-03]\n",
      " [6.14716213e-06 7.30844355e-04]]\n",
      "Train Epoch9 out_loss 0.0004877725150436163\n",
      "Test Epoch9 layer0 out_loss 0.050043001770973206\n",
      "Test Epoch9 layer1 out_loss 0.0015205226372927427\n",
      "Test Epoch9 layer2 out_loss 0.0006791596533730626\n",
      "Test Epoch9 layer3 out_loss 0.0006873151287436485\n",
      "Train 10 | out_loss 0.0005008815787732601: 100%|█| 138/138 [00:00<00:00, 266.29i\n",
      "[[3.27703902e-05 9.21108727e-01]\n",
      " [1.01407970e-05 7.44099807e-03]\n",
      " [2.10163550e-06 2.23543816e-03]\n",
      " [3.77511357e-06 7.68234934e-04]]\n",
      "Train Epoch10 out_loss 0.0005008815787732601\n",
      "Test Epoch10 layer0 out_loss 0.017270883545279503\n",
      "Test Epoch10 layer1 out_loss 0.0017591497162356973\n",
      "Test Epoch10 layer2 out_loss 0.0007074673776514828\n",
      "Test Epoch10 layer3 out_loss 0.0005704261129721999\n",
      "Train 11 | out_loss 0.0004658298275899142: 100%|█| 138/138 [00:00<00:00, 262.67i\n",
      "[[3.18160761e-05 2.44768448e-01]\n",
      " [1.11415525e-05 3.52147487e-03]\n",
      " [3.11252989e-06 1.41126013e-03]\n",
      " [6.64998355e-06 5.16239461e-04]]\n",
      "Train Epoch11 out_loss 0.0004658298275899142\n",
      "Test Epoch11 layer0 out_loss 0.03485221043229103\n",
      "Test Epoch11 layer1 out_loss 0.00184188864659518\n",
      "Test Epoch11 layer2 out_loss 0.0005567166954278946\n",
      "Test Epoch11 layer3 out_loss 0.000416598777519539\n",
      "Train 12 | out_loss 0.000479171983897686: 100%|█| 138/138 [00:00<00:00, 263.45it\n",
      "[[3.44382879e-05 2.48129228e-01]\n",
      " [1.53608346e-05 3.09533480e-03]\n",
      " [4.36213707e-06 1.15058287e-03]\n",
      " [1.01541138e-05 4.23886443e-04]]\n",
      "Train Epoch12 out_loss 0.000479171983897686\n",
      "Test Epoch12 layer0 out_loss 0.02803685888648033\n",
      "Test Epoch12 layer1 out_loss 0.0012563061900436878\n",
      "Test Epoch12 layer2 out_loss 0.0008092405623756349\n",
      "Test Epoch12 layer3 out_loss 0.0004892590222880244\n",
      "Train 13 | out_loss 0.0004957533092238009: 100%|█| 138/138 [00:00<00:00, 249.37i\n",
      "[[3.71508259e-05 3.53603618e-01]\n",
      " [1.08964327e-05 3.19708643e-03]\n",
      " [4.78845552e-06 1.10638523e-03]\n",
      " [1.15247619e-05 4.08102174e-04]]\n",
      "Train Epoch13 out_loss 0.0004957533092238009\n",
      "Test Epoch13 layer0 out_loss 0.015506389550864697\n",
      "Test Epoch13 layer1 out_loss 0.002028140937909484\n",
      "Test Epoch13 layer2 out_loss 0.0006593731231987476\n",
      "Test Epoch13 layer3 out_loss 0.0005629619117826223\n",
      "Train 14 | out_loss 0.0004570969904307276: 100%|█| 138/138 [00:00<00:00, 260.51i\n",
      "[[2.61423165e-05 6.56644376e-01]\n",
      " [1.26325357e-05 3.47532377e-03]\n",
      " [5.67905223e-06 1.21648326e-03]\n",
      " [1.20643052e-05 4.35946409e-04]]\n",
      "Train Epoch14 out_loss 0.0004570969904307276\n",
      "Test Epoch14 layer0 out_loss 0.04740382730960846\n",
      "Test Epoch14 layer1 out_loss 0.0017533507198095322\n",
      "Test Epoch14 layer2 out_loss 0.0007905003149062395\n",
      "Test Epoch14 layer3 out_loss 0.00041298745782114565\n",
      "Train 15 | out_loss 0.0005430503515526652: 100%|█| 138/138 [00:00<00:00, 267.12i\n",
      "[[3.91614247e-05 3.92818284e-01]\n",
      " [1.84113755e-05 2.93588633e-03]\n",
      " [7.72096518e-06 1.07808329e-03]\n",
      " [1.63204350e-05 4.01884098e-04]]\n",
      "Train Epoch15 out_loss 0.0005430503515526652\n",
      "Test Epoch15 layer0 out_loss 0.011114410124719143\n",
      "Test Epoch15 layer1 out_loss 0.0009941391181200743\n",
      "Test Epoch15 layer2 out_loss 0.000577244209125638\n",
      "Test Epoch15 layer3 out_loss 0.00046058278530836105\n",
      "Train 16 | out_loss 0.0004641916893888265: 100%|█| 138/138 [00:00<00:00, 264.63i\n",
      "[[2.48820205e-05 2.23052152e-01]\n",
      " [2.17190724e-05 2.35680447e-03]\n",
      " [1.26030799e-04 1.01601420e-03]\n",
      " [2.82642601e-04 5.67743485e-04]]\n",
      "Train Epoch16 out_loss 0.0004641916893888265\n",
      "Test Epoch16 layer0 out_loss 0.0067321620881557465\n",
      "Test Epoch16 layer1 out_loss 0.000910494476556778\n",
      "Test Epoch16 layer2 out_loss 0.0005415512714534998\n",
      "Test Epoch16 layer3 out_loss 0.00038851681165397167\n",
      "Train 17 | out_loss 0.0005512982024811208: 100%|█| 138/138 [00:00<00:00, 261.00i\n",
      "[[3.93950163e-05 2.56893905e-01]\n",
      " [2.54764422e-05 2.41356080e-03]\n",
      " [5.89236142e-04 1.14718705e-03]\n",
      " [1.04909083e-03 1.16421170e-03]]\n",
      "Train Epoch17 out_loss 0.0005512982024811208\n",
      "Test Epoch17 layer0 out_loss 0.008934925310313702\n",
      "Test Epoch17 layer1 out_loss 0.0010119832586497068\n",
      "Test Epoch17 layer2 out_loss 0.0010749134235084057\n",
      "Test Epoch17 layer3 out_loss 0.0008254692074842751\n",
      "Train 18 | out_loss 0.0004967248532921076: 100%|█| 138/138 [00:00<00:00, 260.87i\n",
      "[[2.66082775e-05 2.54566689e-01]\n",
      " [9.56211703e-05 2.28603899e-03]\n",
      " [1.06340499e-03 1.42126785e-03]\n",
      " [1.05133328e-03 1.44163290e-03]]\n",
      "Train Epoch18 out_loss 0.0004967248532921076\n",
      "Test Epoch18 layer0 out_loss 0.006475550122559071\n",
      "Test Epoch18 layer1 out_loss 0.0008836077759042382\n",
      "Test Epoch18 layer2 out_loss 0.0006088340887799859\n",
      "Test Epoch18 layer3 out_loss 0.0004942826926708221\n",
      "Train 19 | out_loss 0.0005729440599679947: 100%|█| 138/138 [00:00<00:00, 265.05i\n",
      "[[3.59573046e-05 7.55960257e-02]\n",
      " [1.02032948e-04 1.49146487e-03]\n",
      " [6.23518338e-04 9.55069884e-04]\n",
      " [4.24142562e-04 7.91212102e-04]]\n",
      "Train Epoch19 out_loss 0.0005729440599679947\n",
      "Test Epoch19 layer0 out_loss 0.0037455405108630657\n",
      "Test Epoch19 layer1 out_loss 0.0008591352379880846\n",
      "Test Epoch19 layer2 out_loss 0.0007476648315787315\n",
      "Test Epoch19 layer3 out_loss 0.0004563185211736709\n",
      "Train 20 | out_loss 0.000826269097160548: 100%|█| 138/138 [00:00<00:00, 267.84it\n",
      "[[0.00010969 0.03931933]\n",
      " [0.00019385 0.00119842]\n",
      " [0.00091584 0.00101433]\n",
      " [0.00051286 0.00090491]]\n",
      "Train Epoch20 out_loss 0.000826269097160548\n",
      "Test Epoch20 layer0 out_loss 0.004778431262820959\n",
      "Test Epoch20 layer1 out_loss 0.0018315570196136832\n",
      "Test Epoch20 layer2 out_loss 0.0019506976241245866\n",
      "Test Epoch20 layer3 out_loss 0.0017539061373099685\n",
      "Train 21 | out_loss 0.0015409888001158834: 100%|█| 138/138 [00:00<00:00, 266.76i\n",
      "[[0.0004544  0.16021373]\n",
      " [0.00018546 0.00163139]\n",
      " [0.00059086 0.00092914]\n",
      " [0.00031041 0.00061918]]\n",
      "Train Epoch21 out_loss 0.0015409888001158834\n",
      "Test Epoch21 layer0 out_loss 0.0377388671040535\n",
      "Test Epoch21 layer1 out_loss 0.0018386917654424906\n",
      "Test Epoch21 layer2 out_loss 0.0019260476110503078\n",
      "Test Epoch21 layer3 out_loss 0.0014020350063219666\n",
      "Train 22 | out_loss 0.0014353947481140494: 100%|█| 138/138 [00:00<00:00, 267.40i\n",
      "[[4.01943415e-04 6.36657101e-01]\n",
      " [2.45944379e-04 3.30387474e-03]\n",
      " [6.45308370e-04 1.53903301e-03]\n",
      " [4.50316358e-04 9.51455489e-04]]\n",
      "Train Epoch22 out_loss 0.0014353947481140494\n",
      "Test Epoch22 layer0 out_loss 0.022845230996608734\n",
      "Test Epoch22 layer1 out_loss 0.0009549212991259992\n",
      "Test Epoch22 layer2 out_loss 0.0005927950260229409\n",
      "Test Epoch22 layer3 out_loss 0.00048248510574921966\n",
      "Train 23 | out_loss 0.001587600796483457: 100%|█| 138/138 [00:00<00:00, 265.63it\n",
      "[[0.00047191 0.12414201]\n",
      " [0.00034266 0.00133386]\n",
      " [0.00077328 0.00104256]\n",
      " [0.0006884  0.00088614]]\n",
      "Train Epoch23 out_loss 0.001587600796483457\n",
      "Test Epoch23 layer0 out_loss 0.034097205847501755\n",
      "Test Epoch23 layer1 out_loss 0.002046531531959772\n",
      "Test Epoch23 layer2 out_loss 0.00175393873360008\n",
      "Test Epoch23 layer3 out_loss 0.0017585461027920246\n",
      "Train 24 | out_loss 0.0011939791729673743: 100%|█| 138/138 [00:00<00:00, 264.04i\n",
      "[[0.00023629 0.17850129]\n",
      " [0.00055594 0.00173122]\n",
      " [0.00096963 0.00134572]\n",
      " [0.00072959 0.00089358]]\n",
      "Train Epoch24 out_loss 0.0011939791729673743\n",
      "Test Epoch24 layer0 out_loss 0.009070045314729214\n",
      "Test Epoch24 layer1 out_loss 0.0035804787185043097\n",
      "Test Epoch24 layer2 out_loss 0.0038118830416351557\n",
      "Test Epoch24 layer3 out_loss 0.004175503272563219\n",
      "Train 25 | out_loss 0.0014394723111763597: 100%|█| 138/138 [00:00<00:00, 248.45i\n",
      "[[0.00041577 0.05370376]\n",
      " [0.00042971 0.00131541]\n",
      " [0.00072423 0.00114286]\n",
      " [0.00061261 0.0009282 ]]\n",
      "Train Epoch25 out_loss 0.0014394723111763597\n",
      "Test Epoch25 layer0 out_loss 0.011369019746780396\n",
      "Test Epoch25 layer1 out_loss 0.0010063601657748222\n",
      "Test Epoch25 layer2 out_loss 0.000773130333982408\n",
      "Test Epoch25 layer3 out_loss 0.0007888571126386523\n",
      "Train 26 | out_loss 0.0012810693588107824: 100%|█| 138/138 [00:00<00:00, 263.90i\n",
      "[[0.00031716 0.2912497 ]\n",
      " [0.0003154  0.00202962]\n",
      " [0.00046677 0.00098047]\n",
      " [0.00100191 0.00086839]]\n",
      "Train Epoch26 out_loss 0.0012810693588107824\n",
      "Test Epoch26 layer0 out_loss 0.008968747220933437\n",
      "Test Epoch26 layer1 out_loss 0.0009098807931877673\n",
      "Test Epoch26 layer2 out_loss 0.0006919278530403972\n",
      "Test Epoch26 layer3 out_loss 0.0005255143041722476\n",
      "Train 27 | out_loss 0.0018280812073498964: 100%|█| 138/138 [00:00<00:00, 264.10i\n",
      "[[6.11088138e-04 7.09691134e-01]\n",
      " [5.03589721e-04 3.54208424e-03]\n",
      " [6.89191591e-04 1.76290522e-03]\n",
      " [5.09568408e-04 1.20859343e-03]]\n",
      "Train Epoch27 out_loss 0.0018280812073498964\n",
      "Test Epoch27 layer0 out_loss 0.05041814595460892\n",
      "Test Epoch27 layer1 out_loss 0.0029501295648515224\n",
      "Test Epoch27 layer2 out_loss 0.0022604973055422306\n",
      "Test Epoch27 layer3 out_loss 0.002603257540613413\n",
      "Train 28 | out_loss 0.0009070891537703574: 100%|█| 138/138 [00:00<00:00, 255.22i\n",
      "[[1.38097240e-04 2.46132923e-01]\n",
      " [5.40988772e-04 1.89553203e-03]\n",
      " [6.79004254e-04 1.10719984e-03]\n",
      " [6.11029291e-04 7.61658350e-04]]\n",
      "Train Epoch28 out_loss 0.0009070891537703574\n",
      "Test Epoch28 layer0 out_loss 0.015131531283259392\n",
      "Test Epoch28 layer1 out_loss 0.0016643119743093848\n",
      "Test Epoch28 layer2 out_loss 0.002383121754974127\n",
      "Test Epoch28 layer3 out_loss 0.001748687238432467\n",
      "Train 29 | out_loss 0.0018474883399903774: 100%|█| 138/138 [00:00<00:00, 263.73i\n",
      "[[0.00060002 0.09264003]\n",
      " [0.00042349 0.00164883]\n",
      " [0.00076828 0.00117118]\n",
      " [0.00077756 0.00126603]]\n",
      "Train Epoch29 out_loss 0.0018474883399903774\n",
      "Test Epoch29 layer0 out_loss 0.008213642984628677\n",
      "Test Epoch29 layer1 out_loss 0.0009558026795275509\n",
      "Test Epoch29 layer2 out_loss 0.0006957098376005888\n",
      "Test Epoch29 layer3 out_loss 0.0012574337888509035\n",
      "Train 30 | out_loss 0.0009437752887606621: 100%|█| 138/138 [00:00<00:00, 252.92i\n",
      "[[0.00015288 0.08081191]\n",
      " [0.00039271 0.00160153]\n",
      " [0.00061465 0.00113159]\n",
      " [0.00062517 0.00114629]]\n",
      "Train Epoch30 out_loss 0.0009437752887606621\n",
      "Test Epoch30 layer0 out_loss 0.010937489569187164\n",
      "Test Epoch30 layer1 out_loss 0.0010410528630018234\n",
      "Test Epoch30 layer2 out_loss 0.0008812954765744507\n",
      "Test Epoch30 layer3 out_loss 0.0009564098436385393\n",
      "Train 31 | out_loss 0.0017423059325665236: 100%|█| 138/138 [00:00<00:00, 253.02i\n",
      "[[0.00059373 0.08399953]\n",
      " [0.00051766 0.00156276]\n",
      " [0.00069993 0.00094779]\n",
      " [0.00051768 0.00066974]]\n",
      "Train Epoch31 out_loss 0.0017423059325665236\n",
      "Test Epoch31 layer0 out_loss 0.037250760942697525\n",
      "Test Epoch31 layer1 out_loss 0.0009757448569871485\n",
      "Test Epoch31 layer2 out_loss 0.0011370355496183038\n",
      "Test Epoch31 layer3 out_loss 0.0009836874669417739\n",
      "Train 32 | out_loss 0.0012292148312553763: 100%|█| 138/138 [00:00<00:00, 257.45i\n",
      "[[2.44594045e-04 2.90024597e-01]\n",
      " [6.17019062e-04 2.50661520e-03]\n",
      " [8.00547675e-04 1.48336631e-03]\n",
      " [5.90134759e-04 1.25497809e-03]]\n",
      "Train Epoch32 out_loss 0.0012292148312553763\n",
      "Test Epoch32 layer0 out_loss 0.07172627002000809\n",
      "Test Epoch32 layer1 out_loss 0.0017717506270855665\n",
      "Test Epoch32 layer2 out_loss 0.0007642386481165886\n",
      "Test Epoch32 layer3 out_loss 0.0007359427982009947\n",
      "Train 33 | out_loss 0.0013320808066055179: 100%|█| 138/138 [00:00<00:00, 250.08i\n",
      "[[3.11388825e-04 3.88518782e-01]\n",
      " [8.06351073e-04 2.63389436e-03]\n",
      " [8.84667265e-04 1.39054020e-03]\n",
      " [6.90070508e-04 1.11003083e-03]]\n",
      "Train Epoch33 out_loss 0.0013320808066055179\n",
      "Test Epoch33 layer0 out_loss 0.006014276295900345\n",
      "Test Epoch33 layer1 out_loss 0.0015378294046968222\n",
      "Test Epoch33 layer2 out_loss 0.0006237495108507574\n",
      "Test Epoch33 layer3 out_loss 0.0008826699340716004\n",
      "Train 34 | out_loss 0.0015708832070231438: 100%|█| 138/138 [00:00<00:00, 265.73i\n",
      "[[0.00047373 0.06851541]\n",
      " [0.00047824 0.00157664]\n",
      " [0.00067046 0.00106941]\n",
      " [0.00052376 0.00084504]]\n",
      "Train Epoch34 out_loss 0.0015708832070231438\n",
      "Test Epoch34 layer0 out_loss 0.007804969325661659\n",
      "Test Epoch34 layer1 out_loss 0.0017879466759040952\n",
      "Test Epoch34 layer2 out_loss 0.002615235513076186\n",
      "Test Epoch34 layer3 out_loss 0.0024857516400516033\n",
      "Train 35 | out_loss 0.0012003695592284203: 100%|█| 138/138 [00:00<00:00, 263.53i\n",
      "[[0.00024846 0.01237571]\n",
      " [0.00069489 0.00113476]\n",
      " [0.00090784 0.00117805]\n",
      " [0.00071972 0.0011988 ]]\n",
      "Train Epoch35 out_loss 0.0012003695592284203\n",
      "Test Epoch35 layer0 out_loss 0.0029308637604117393\n",
      "Test Epoch35 layer1 out_loss 0.0012408930342644453\n",
      "Test Epoch35 layer2 out_loss 0.0009410239872522652\n",
      "Test Epoch35 layer3 out_loss 0.0008202827884815633\n",
      "Train 36 | out_loss 0.001590815605595708: 100%|█| 138/138 [00:00<00:00, 266.34it\n",
      "[[0.00043679 0.02284176]\n",
      " [0.00050347 0.00107908]\n",
      " [0.00083811 0.0010203 ]\n",
      " [0.00061558 0.00082525]]\n",
      "Train Epoch36 out_loss 0.001590815605595708\n",
      "Test Epoch36 layer0 out_loss 0.025036929175257683\n",
      "Test Epoch36 layer1 out_loss 0.002498893067240715\n",
      "Test Epoch36 layer2 out_loss 0.001898587797768414\n",
      "Test Epoch36 layer3 out_loss 0.002057309728115797\n",
      "Train 37 | out_loss 0.0014767363900318742: 100%|█| 138/138 [00:00<00:00, 251.34i\n",
      "[[0.00039749 0.08099668]\n",
      " [0.00050916 0.00159524]\n",
      " [0.00056084 0.00104032]\n",
      " [0.0004752  0.00080753]]\n",
      "Train Epoch37 out_loss 0.0014767363900318742\n",
      "Test Epoch37 layer0 out_loss 0.008035979233682156\n",
      "Test Epoch37 layer1 out_loss 0.0006446255138143897\n",
      "Test Epoch37 layer2 out_loss 0.0006639565690420568\n",
      "Test Epoch37 layer3 out_loss 0.0005554857198148966\n",
      "Train 38 | out_loss 0.001423104666173458: 100%|█| 138/138 [00:00<00:00, 264.02it\n",
      "[[0.0003592  0.02745257]\n",
      " [0.00087479 0.0016498 ]\n",
      " [0.00095241 0.00153263]\n",
      " [0.00070646 0.00125582]]\n",
      "Train Epoch38 out_loss 0.001423104666173458\n",
      "Test Epoch38 layer0 out_loss 0.010480707511305809\n",
      "Test Epoch38 layer1 out_loss 0.003405083669349551\n",
      "Test Epoch38 layer2 out_loss 0.002965556224808097\n",
      "Test Epoch38 layer3 out_loss 0.0032069962471723557\n",
      "Train 39 | out_loss 0.001296403119340539: 100%|█| 138/138 [00:00<00:00, 269.13it\n",
      "[[0.00034265 0.26711782]\n",
      " [0.00047767 0.00276581]\n",
      " [0.00075652 0.00150806]\n",
      " [0.00059674 0.0011834 ]]\n",
      "Train Epoch39 out_loss 0.001296403119340539\n",
      "Test Epoch39 layer0 out_loss 0.0111387362703681\n",
      "Test Epoch39 layer1 out_loss 0.0016651097685098648\n",
      "Test Epoch39 layer2 out_loss 0.0008975203963927925\n",
      "Test Epoch39 layer3 out_loss 0.001012279069982469\n",
      "Train 40 | out_loss 0.0017220409354194999: 100%|█| 138/138 [00:00<00:00, 262.65i\n",
      "[[0.00056114 0.27462743]\n",
      " [0.00055505 0.00217566]\n",
      " [0.00064216 0.00127656]\n",
      " [0.00052738 0.00109345]]\n",
      "Train Epoch40 out_loss 0.0017220409354194999\n",
      "Test Epoch40 layer0 out_loss 0.031318292021751404\n",
      "Test Epoch40 layer1 out_loss 0.0032891829032450914\n",
      "Test Epoch40 layer2 out_loss 0.0028421920724213123\n",
      "Test Epoch40 layer3 out_loss 0.0029984088614583015\n",
      "Train 41 | out_loss 0.001111854100599885: 100%|█| 138/138 [00:00<00:00, 266.31it\n",
      "[[2.10148469e-04 2.63125648e-01]\n",
      " [7.12732369e-04 2.36225967e-03]\n",
      " [9.07634917e-04 1.56881242e-03]\n",
      " [6.46370923e-04 1.34065695e-03]]\n",
      "Train Epoch41 out_loss 0.001111854100599885\n",
      "Test Epoch41 layer0 out_loss 0.016831163316965103\n",
      "Test Epoch41 layer1 out_loss 0.001242796191945672\n",
      "Test Epoch41 layer2 out_loss 0.0006769526517018676\n",
      "Test Epoch41 layer3 out_loss 0.000760265626013279\n",
      "Train 42 | out_loss 0.0014199854340404272: 100%|█| 138/138 [00:00<00:00, 267.95i\n",
      "[[0.00036844 0.0337958 ]\n",
      " [0.00049449 0.00119868]\n",
      " [0.00052738 0.00109969]\n",
      " [0.00047423 0.00085795]]\n",
      "Train Epoch42 out_loss 0.0014199854340404272\n",
      "Test Epoch42 layer0 out_loss 0.02618643455207348\n",
      "Test Epoch42 layer1 out_loss 0.0016946166288107634\n",
      "Test Epoch42 layer2 out_loss 0.0005075832596048713\n",
      "Test Epoch42 layer3 out_loss 0.0007718133274465799\n",
      "Train 43 | out_loss 0.001695617102086544: 100%|█| 138/138 [00:00<00:00, 263.23it\n",
      "[[0.00054628 0.01814347]\n",
      " [0.00071964 0.00158207]\n",
      " [0.00089476 0.00138531]\n",
      " [0.00060695 0.0010304 ]]\n",
      "Train Epoch43 out_loss 0.001695617102086544\n",
      "Test Epoch43 layer0 out_loss 0.0028934311121702194\n",
      "Test Epoch43 layer1 out_loss 0.0012980418978258967\n",
      "Test Epoch43 layer2 out_loss 0.0010744949104264379\n",
      "Test Epoch43 layer3 out_loss 0.001967950025573373\n",
      "Train 44 | out_loss 0.0011134935775771737: 100%|█| 138/138 [00:00<00:00, 264.57i\n",
      "[[0.0002062  0.00813824]\n",
      " [0.00057402 0.0015058 ]\n",
      " [0.00071579 0.00145182]\n",
      " [0.00057951 0.00129393]]\n",
      "Train Epoch44 out_loss 0.0011134935775771737\n",
      "Test Epoch44 layer0 out_loss 0.0035230605863034725\n",
      "Test Epoch44 layer1 out_loss 0.0006812146166339517\n",
      "Test Epoch44 layer2 out_loss 0.0013337202835828066\n",
      "Test Epoch44 layer3 out_loss 0.0005557514377869666\n",
      "Train 45 | out_loss 0.0014126340392977: 100%|█| 138/138 [00:00<00:00, 266.37it/s\n",
      "[[0.00036183 0.04969164]\n",
      " [0.00084658 0.00216309]\n",
      " [0.00094111 0.00167106]\n",
      " [0.00065713 0.00097657]]\n",
      "Train Epoch45 out_loss 0.0014126340392977\n",
      "Test Epoch45 layer0 out_loss 0.008552667684853077\n",
      "Test Epoch45 layer1 out_loss 0.0009938349248841405\n",
      "Test Epoch45 layer2 out_loss 0.000817697262391448\n",
      "Test Epoch45 layer3 out_loss 0.0004226829041726887\n",
      "Train 46 | out_loss 0.0014866185374557972: 100%|█| 138/138 [00:00<00:00, 269.65i\n",
      "[[0.00039957 0.18722512]\n",
      " [0.0003371  0.00258405]\n",
      " [0.00050133 0.00127783]\n",
      " [0.00045306 0.00094067]]\n",
      "Train Epoch46 out_loss 0.0014866185374557972\n",
      "Test Epoch46 layer0 out_loss 0.0064272647723555565\n",
      "Test Epoch46 layer1 out_loss 0.004500625189393759\n",
      "Test Epoch46 layer2 out_loss 0.0026870369911193848\n",
      "Test Epoch46 layer3 out_loss 0.002883303677663207\n",
      "Train 47 | out_loss 0.0014543536817654967: 100%|█| 138/138 [00:00<00:00, 267.97i\n",
      "[[0.00040156 0.03435159]\n",
      " [0.00074162 0.00198685]\n",
      " [0.00084185 0.00156805]\n",
      " [0.00061465 0.00107646]]\n",
      "Train Epoch47 out_loss 0.0014543536817654967\n",
      "Test Epoch47 layer0 out_loss 0.015221277251839638\n",
      "Test Epoch47 layer1 out_loss 0.0014787352411076427\n",
      "Test Epoch47 layer2 out_loss 0.0005425156559795141\n",
      "Test Epoch47 layer3 out_loss 0.0004571923054754734\n",
      "Train 48 | out_loss 0.001208409434184432: 100%|█| 138/138 [00:00<00:00, 266.37it\n",
      "[[0.0002982  0.17939288]\n",
      " [0.00048268 0.00253571]\n",
      " [0.00062374 0.00173789]\n",
      " [0.00048959 0.00100961]]\n",
      "Train Epoch48 out_loss 0.001208409434184432\n",
      "Test Epoch48 layer0 out_loss 0.007061132695525885\n",
      "Test Epoch48 layer1 out_loss 0.0018998704617843032\n",
      "Test Epoch48 layer2 out_loss 0.0012303090188652277\n",
      "Test Epoch48 layer3 out_loss 0.00046952301636338234\n",
      "Train 49 | out_loss 0.0015102055622264743: 100%|█| 138/138 [00:00<00:00, 266.19i\n",
      "[[0.00034475 0.02247611]\n",
      " [0.0007431  0.0019818 ]\n",
      " [0.00098714 0.00175617]\n",
      " [0.00069094 0.00099632]]\n",
      "Train Epoch49 out_loss 0.0015102055622264743\n",
      "Test Epoch49 layer0 out_loss 0.00643913121894002\n",
      "Test Epoch49 layer1 out_loss 0.0015208860859274864\n",
      "Test Epoch49 layer2 out_loss 0.0009516864083707333\n",
      "Test Epoch49 layer3 out_loss 0.0015125590143725276\n",
      "Train 50 | out_loss 0.0016987442504614592: 100%|█| 138/138 [00:00<00:00, 263.68i\n",
      "[[0.00058647 0.06784473]\n",
      " [0.00051776 0.00193975]\n",
      " [0.00060189 0.00128804]\n",
      " [0.00041685 0.00089108]]\n",
      "Train Epoch50 out_loss 0.0016987442504614592\n",
      "Test Epoch50 layer0 out_loss 0.013976509682834148\n",
      "Test Epoch50 layer1 out_loss 0.0030220404732972383\n",
      "Test Epoch50 layer2 out_loss 0.002337705809623003\n",
      "Test Epoch50 layer3 out_loss 0.0022793763782829046\n",
      "Train 51 | out_loss 0.0014301120536401868: 100%|█| 138/138 [00:00<00:00, 265.74i\n",
      "[[0.00037763 0.09789575]\n",
      " [0.00051051 0.00204736]\n",
      " [0.00061755 0.001385  ]\n",
      " [0.0004514  0.00101751]]\n",
      "Train Epoch51 out_loss 0.0014301120536401868\n",
      "Test Epoch51 layer0 out_loss 0.007420433685183525\n",
      "Test Epoch51 layer1 out_loss 0.006738701369613409\n",
      "Test Epoch51 layer2 out_loss 0.003861665725708008\n",
      "Test Epoch51 layer3 out_loss 0.004152864217758179\n",
      "Train 52 | out_loss 0.001024155761115253: 100%|█| 138/138 [00:00<00:00, 246.78it\n",
      "[[0.00018108 0.07452248]\n",
      " [0.00058429 0.0019849 ]\n",
      " [0.0006576  0.00152675]\n",
      " [0.00050916 0.00078743]]\n",
      "Train Epoch52 out_loss 0.001024155761115253\n",
      "Test Epoch52 layer0 out_loss 0.004816792439669371\n",
      "Test Epoch52 layer1 out_loss 0.0007129069999791682\n",
      "Test Epoch52 layer2 out_loss 0.0009695058688521385\n",
      "Test Epoch52 layer3 out_loss 0.00042208112427033484\n",
      "Train 53 | out_loss 0.0014341563219204545: 100%|█| 138/138 [00:00<00:00, 263.96i\n",
      "[[0.00037648 0.05242955]\n",
      " [0.00044441 0.00167762]\n",
      " [0.00058155 0.0018136 ]\n",
      " [0.00053658 0.00105608]]\n",
      "Train Epoch53 out_loss 0.0014341563219204545\n",
      "Test Epoch53 layer0 out_loss 0.003528005676344037\n",
      "Test Epoch53 layer1 out_loss 0.0014822096563875675\n",
      "Test Epoch53 layer2 out_loss 0.00046546608791686594\n",
      "Test Epoch53 layer3 out_loss 0.0005122054717503488\n",
      "Train 54 | out_loss 0.0017213341780006886: 100%|█| 138/138 [00:00<00:00, 261.55i\n",
      "[[0.00054979 0.19560661]\n",
      " [0.00070876 0.00325374]\n",
      " [0.00084372 0.00167859]\n",
      " [0.00049564 0.0008545 ]]\n",
      "Train Epoch54 out_loss 0.0017213341780006886\n",
      "Test Epoch54 layer0 out_loss 0.007398334331810474\n",
      "Test Epoch54 layer1 out_loss 0.003303877543658018\n",
      "Test Epoch54 layer2 out_loss 0.00270243757404387\n",
      "Test Epoch54 layer3 out_loss 0.0030440022237598896\n",
      "Train 55 | out_loss 0.0014508195454254746: 100%|█| 138/138 [00:00<00:00, 261.05i\n",
      "[[0.00043659 0.0361754 ]\n",
      " [0.00049599 0.00164482]\n",
      " [0.00058599 0.00145261]\n",
      " [0.00041866 0.00081924]]\n",
      "Train Epoch55 out_loss 0.0014508195454254746\n",
      "Test Epoch55 layer0 out_loss 0.009944895282387733\n",
      "Test Epoch55 layer1 out_loss 0.003273303620517254\n",
      "Test Epoch55 layer2 out_loss 0.0032785863149911165\n",
      "Test Epoch55 layer3 out_loss 0.003350452985614538\n",
      "Train 56 | out_loss 0.000788909092079848: 100%|█| 138/138 [00:00<00:00, 251.87it\n",
      "[[0.00010974 0.0139699 ]\n",
      " [0.00040533 0.00149976]\n",
      " [0.00048852 0.0013083 ]\n",
      " [0.00040378 0.00085756]]\n",
      "Train Epoch56 out_loss 0.000788909092079848\n",
      "Test Epoch56 layer0 out_loss 0.0055095236748456955\n",
      "Test Epoch56 layer1 out_loss 0.0007315895054489374\n",
      "Test Epoch56 layer2 out_loss 0.0008339178748428822\n",
      "Test Epoch56 layer3 out_loss 0.0010007191449403763\n",
      "Train 57 | out_loss 0.0014118433464318514: 100%|█| 138/138 [00:00<00:00, 267.40i\n",
      "[[0.00037963 0.16598784]\n",
      " [0.00075565 0.00347442]\n",
      " [0.00096408 0.00201335]\n",
      " [0.00066962 0.00123411]]\n",
      "Train Epoch57 out_loss 0.0014118433464318514\n",
      "Test Epoch57 layer0 out_loss 0.006594137288630009\n",
      "Test Epoch57 layer1 out_loss 0.0012419065460562706\n",
      "Test Epoch57 layer2 out_loss 0.0008840681402944028\n",
      "Test Epoch57 layer3 out_loss 0.0011246738722547889\n",
      "Train 58 | out_loss 0.0013638129457831383: 100%|█| 138/138 [00:00<00:00, 262.70i\n",
      "[[0.00034632 0.03173561]\n",
      " [0.00035418 0.00167339]\n",
      " [0.00050052 0.0013432 ]\n",
      " [0.00046412 0.00080962]]\n",
      "Train Epoch58 out_loss 0.0013638129457831383\n",
      "Test Epoch58 layer0 out_loss 0.0031296107918024063\n",
      "Test Epoch58 layer1 out_loss 0.0010992068564519286\n",
      "Test Epoch58 layer2 out_loss 0.001249017659574747\n",
      "Test Epoch58 layer3 out_loss 0.001238188473507762\n",
      "Train 59 | out_loss 0.0016998318023979664: 100%|█| 138/138 [00:00<00:00, 269.41i\n",
      "[[0.00055298 0.04900088]\n",
      " [0.00049146 0.00200087]\n",
      " [0.00061736 0.00141489]\n",
      " [0.000411   0.00061808]]\n",
      "Train Epoch59 out_loss 0.0016998318023979664\n",
      "Test Epoch59 layer0 out_loss 0.007199204992502928\n",
      "Test Epoch59 layer1 out_loss 0.002053025411441922\n",
      "Test Epoch59 layer2 out_loss 0.0016283263685181737\n",
      "Test Epoch59 layer3 out_loss 0.0018025810131803155\n",
      "Train 60 | out_loss 0.001278275391086936: 100%|█| 138/138 [00:00<00:00, 263.65it\n",
      "[[0.00030603 0.09839977]\n",
      " [0.00051394 0.00261229]\n",
      " [0.00063908 0.00125728]\n",
      " [0.00044351 0.0007621 ]]\n",
      "Train Epoch60 out_loss 0.001278275391086936\n",
      "Test Epoch60 layer0 out_loss 0.019460603594779968\n",
      "Test Epoch60 layer1 out_loss 0.0015762754483148456\n",
      "Test Epoch60 layer2 out_loss 0.0005251250695437193\n",
      "Test Epoch60 layer3 out_loss 0.0010182249825447798\n",
      "Train 61 | out_loss 0.0013668147148564458: 100%|█| 138/138 [00:00<00:00, 256.34i\n",
      "[[0.00034943 0.02545583]\n",
      " [0.00047609 0.0018356 ]\n",
      " [0.00061804 0.00151736]\n",
      " [0.00044196 0.00074662]]\n",
      "Train Epoch61 out_loss 0.0013668147148564458\n",
      "Test Epoch61 layer0 out_loss 0.005976149346679449\n",
      "Test Epoch61 layer1 out_loss 0.0007383649935945868\n",
      "Test Epoch61 layer2 out_loss 0.00045650513493455946\n",
      "Test Epoch61 layer3 out_loss 0.0005420316592790186\n",
      "Train 62 | out_loss 0.001360526424832642: 100%|█| 138/138 [00:00<00:00, 262.78it\n",
      "[[0.00033539 0.05885531]\n",
      " [0.00062904 0.00252276]\n",
      " [0.00073422 0.00144144]\n",
      " [0.00053177 0.00078935]]\n",
      "Train Epoch62 out_loss 0.001360526424832642\n",
      "Test Epoch62 layer0 out_loss 0.006879363674670458\n",
      "Test Epoch62 layer1 out_loss 0.002024203073233366\n",
      "Test Epoch62 layer2 out_loss 0.0004929231363348663\n",
      "Test Epoch62 layer3 out_loss 0.0005122227594256401\n",
      "Train 63 | out_loss 0.0013318214332684875: 100%|█| 138/138 [00:00<00:00, 266.15i\n",
      "[[0.00041648 0.08456964]\n",
      " [0.00034514 0.00199053]\n",
      " [0.00050339 0.00144112]\n",
      " [0.0004134  0.00077309]]\n",
      "Train Epoch63 out_loss 0.0013318214332684875\n",
      "Test Epoch63 layer0 out_loss 0.008920878171920776\n",
      "Test Epoch63 layer1 out_loss 0.0007666832534596324\n",
      "Test Epoch63 layer2 out_loss 0.0005677957669831812\n",
      "Test Epoch63 layer3 out_loss 0.00042228400707244873\n",
      "Train 64 | out_loss 0.0012439129641279578: 100%|█| 138/138 [00:00<00:00, 263.96i\n",
      "[[0.00028663 0.0510599 ]\n",
      " [0.00058003 0.00236971]\n",
      " [0.0007326  0.00143571]\n",
      " [0.00042705 0.00062416]]\n",
      "Train Epoch64 out_loss 0.0012439129641279578\n",
      "Test Epoch64 layer0 out_loss 0.01406717300415039\n",
      "Test Epoch64 layer1 out_loss 0.0008212576503865421\n",
      "Test Epoch64 layer2 out_loss 0.00047037299373187125\n",
      "Test Epoch64 layer3 out_loss 0.00042573711834847927\n",
      "Train 65 | out_loss 0.0015679796924814582: 100%|█| 138/138 [00:00<00:00, 265.89i\n",
      "[[0.00049434 0.02538995]\n",
      " [0.00041638 0.00171684]\n",
      " [0.00054947 0.00148038]\n",
      " [0.00041705 0.0006731 ]]\n",
      "Train Epoch65 out_loss 0.0015679796924814582\n",
      "Test Epoch65 layer0 out_loss 0.004266497679054737\n",
      "Test Epoch65 layer1 out_loss 0.0005202099564485252\n",
      "Test Epoch65 layer2 out_loss 0.0004394087882246822\n",
      "Test Epoch65 layer3 out_loss 0.0005157165578566492\n",
      "Train 66 | out_loss 0.0011651149252429605: 100%|█| 138/138 [00:00<00:00, 260.10i\n",
      "[[0.00026065 0.01147657]\n",
      " [0.00049542 0.00217355]\n",
      " [0.00059903 0.00141446]\n",
      " [0.00052535 0.00077597]]\n",
      "Train Epoch66 out_loss 0.0011651149252429605\n",
      "Test Epoch66 layer0 out_loss 0.014337397180497646\n",
      "Test Epoch66 layer1 out_loss 0.0010941846994683146\n",
      "Test Epoch66 layer2 out_loss 0.0004358690057415515\n",
      "Test Epoch66 layer3 out_loss 0.0004493219603318721\n",
      "Train 67 | out_loss 0.0013790726661682129: 100%|█| 138/138 [00:00<00:00, 261.53i\n",
      "[[0.00037223 0.0378422 ]\n",
      " [0.0004583  0.00212808]\n",
      " [0.00062152 0.00120883]\n",
      " [0.00044778 0.00072257]]\n",
      "Train Epoch67 out_loss 0.0013790726661682129\n",
      "Test Epoch67 layer0 out_loss 0.00449708616361022\n",
      "Test Epoch67 layer1 out_loss 0.0020570727065205574\n",
      "Test Epoch67 layer2 out_loss 0.0007666160236112773\n",
      "Test Epoch67 layer3 out_loss 0.0006505897617898881\n",
      "Train 68 | out_loss 0.0014989105984568596: 100%|█| 138/138 [00:00<00:00, 264.60i\n",
      "[[0.00043751 0.01862833]\n",
      " [0.00038121 0.00198123]\n",
      " [0.00048727 0.00127309]\n",
      " [0.00037213 0.00071736]]\n",
      "Train Epoch68 out_loss 0.0014989105984568596\n",
      "Test Epoch68 layer0 out_loss 0.0036494063679128885\n",
      "Test Epoch68 layer1 out_loss 0.0029481041710823774\n",
      "Test Epoch68 layer2 out_loss 0.0031789978966116905\n",
      "Test Epoch68 layer3 out_loss 0.0029000602662563324\n",
      "Train 69 | out_loss 0.001646923366934061: 100%|█| 138/138 [00:00<00:00, 252.71it\n",
      "[[0.00056527 0.00689583]\n",
      " [0.00051083 0.00198394]\n",
      " [0.00063646 0.00128836]\n",
      " [0.00039996 0.0006313 ]]\n",
      "Train Epoch69 out_loss 0.001646923366934061\n",
      "Test Epoch69 layer0 out_loss 0.0030271627474576235\n",
      "Test Epoch69 layer1 out_loss 0.0016605155542492867\n",
      "Test Epoch69 layer2 out_loss 0.0004364746855571866\n",
      "Test Epoch69 layer3 out_loss 0.0006125441868789494\n",
      "Train 70 | out_loss 0.000615146360360086: 100%|█| 138/138 [00:00<00:00, 257.02it\n",
      "[[2.03305796e-05 4.22682950e-02]\n",
      " [3.41010730e-04 2.58107212e-03]\n",
      " [5.38320633e-04 1.41402694e-03]\n",
      " [3.59227579e-04 6.79062280e-04]]\n",
      "Train Epoch70 out_loss 0.000615146360360086\n",
      "Test Epoch70 layer0 out_loss 0.01809864677488804\n",
      "Test Epoch70 layer1 out_loss 0.0007879765471443534\n",
      "Test Epoch70 layer2 out_loss 0.0005031124455854297\n",
      "Test Epoch70 layer3 out_loss 0.0007268682238645852\n",
      "Train 71 | out_loss 0.001428202842362225: 100%|█| 138/138 [00:00<00:00, 262.39it\n",
      "[[0.00038842 0.07316291]\n",
      " [0.00052657 0.00301282]\n",
      " [0.00068193 0.00183348]\n",
      " [0.00054102 0.00079598]]\n",
      "Train Epoch71 out_loss 0.001428202842362225\n",
      "Test Epoch71 layer0 out_loss 0.0055245463736355305\n",
      "Test Epoch71 layer1 out_loss 0.0006277842330746353\n",
      "Test Epoch71 layer2 out_loss 0.0006247126148082316\n",
      "Test Epoch71 layer3 out_loss 0.0006814696243964136\n",
      "Train 72 | out_loss 0.0013381849275901914: 100%|█| 138/138 [00:00<00:00, 257.99i\n",
      "[[0.00033485 0.02675954]\n",
      " [0.00033784 0.00165134]\n",
      " [0.00043746 0.00109703]\n",
      " [0.00028884 0.00055867]]\n",
      "Train Epoch72 out_loss 0.0013381849275901914\n",
      "Test Epoch72 layer0 out_loss 0.0035013044252991676\n",
      "Test Epoch72 layer1 out_loss 0.0009083030745387077\n",
      "Test Epoch72 layer2 out_loss 0.0005227335495874286\n",
      "Test Epoch72 layer3 out_loss 0.0006939057493582368\n",
      "Train 73 | out_loss 0.0013822093605995178: 100%|█| 138/138 [00:00<00:00, 257.31i\n",
      "[[0.00044311 0.10064915]\n",
      " [0.00050886 0.00280187]\n",
      " [0.00060862 0.00142392]\n",
      " [0.00041444 0.00066587]]\n",
      "Train Epoch73 out_loss 0.0013822093605995178\n",
      "Test Epoch73 layer0 out_loss 0.013118486851453781\n",
      "Test Epoch73 layer1 out_loss 0.0009338628151454031\n",
      "Test Epoch73 layer2 out_loss 0.00042904968722723424\n",
      "Test Epoch73 layer3 out_loss 0.00042807229328900576\n",
      "Train 74 | out_loss 0.001663866569288075: 100%|█| 138/138 [00:00<00:00, 265.30it\n",
      "[[0.00057589 0.08903727]\n",
      " [0.00035696 0.00210121]\n",
      " [0.00050493 0.00126217]\n",
      " [0.00036838 0.00068712]]\n",
      "Train Epoch74 out_loss 0.001663866569288075\n",
      "Test Epoch74 layer0 out_loss 0.005419927183538675\n",
      "Test Epoch74 layer1 out_loss 0.0007382085896097124\n",
      "Test Epoch74 layer2 out_loss 0.0007101971423253417\n",
      "Test Epoch74 layer3 out_loss 0.0005188724608160555\n",
      "Train 75 | out_loss 0.0010758575517684221: 100%|█| 138/138 [00:00<00:00, 265.75i\n",
      "[[0.00023074 0.00996307]\n",
      " [0.00045701 0.00188567]\n",
      " [0.00056384 0.00096959]\n",
      " [0.00029205 0.00034253]]\n",
      "Train Epoch75 out_loss 0.0010758575517684221\n",
      "Test Epoch75 layer0 out_loss 0.0036511579528450966\n",
      "Test Epoch75 layer1 out_loss 0.0005803960375487804\n",
      "Test Epoch75 layer2 out_loss 0.0004287222109269351\n",
      "Test Epoch75 layer3 out_loss 0.000600746541749686\n",
      "Train 76 | out_loss 0.0013175109634175897: 100%|█| 138/138 [00:00<00:00, 260.32i\n",
      "[[0.00031532 0.00586083]\n",
      " [0.00043816 0.00203754]\n",
      " [0.00062058 0.00154981]\n",
      " [0.0004474  0.00058581]]\n",
      "Train Epoch76 out_loss 0.0013175109634175897\n",
      "Test Epoch76 layer0 out_loss 0.004005735740065575\n",
      "Test Epoch76 layer1 out_loss 0.000923054525628686\n",
      "Test Epoch76 layer2 out_loss 0.0006420175195671618\n",
      "Test Epoch76 layer3 out_loss 0.0009163468494080007\n",
      "Train 77 | out_loss 0.0015923012979328632: 100%|█| 138/138 [00:00<00:00, 263.95i\n",
      "[[0.00053292 0.03233156]\n",
      " [0.00031051 0.00180052]\n",
      " [0.00041057 0.00097788]\n",
      " [0.00030064 0.00057215]]\n",
      "Train Epoch77 out_loss 0.0015923012979328632\n",
      "Test Epoch77 layer0 out_loss 0.003551516914740205\n",
      "Test Epoch77 layer1 out_loss 0.0009883377933874726\n",
      "Test Epoch77 layer2 out_loss 0.0009046599152497947\n",
      "Test Epoch77 layer3 out_loss 0.0005928570753894746\n",
      "Train 78 | out_loss 0.0013281948631629348: 100%|█| 138/138 [00:00<00:00, 250.32i\n",
      "[[0.00039035 0.0206129 ]\n",
      " [0.00034039 0.00196737]\n",
      " [0.00042555 0.00083621]\n",
      " [0.0002583  0.00043686]]\n",
      "Train Epoch78 out_loss 0.0013281948631629348\n",
      "Test Epoch78 layer0 out_loss 0.0034981966018676758\n",
      "Test Epoch78 layer1 out_loss 0.0005228727823123336\n",
      "Test Epoch78 layer2 out_loss 0.0004846012161578983\n",
      "Test Epoch78 layer3 out_loss 0.00045138681889511645\n",
      "Train 79 | out_loss 0.0011761282803490758: 100%|█| 138/138 [00:00<00:00, 264.16i\n",
      "[[0.00026799 0.05875229]\n",
      " [0.00038319 0.002515  ]\n",
      " [0.00052537 0.00118472]\n",
      " [0.00031033 0.00053827]]\n",
      "Train Epoch79 out_loss 0.0011761282803490758\n",
      "Test Epoch79 layer0 out_loss 0.005112544633448124\n",
      "Test Epoch79 layer1 out_loss 0.0012617637403309345\n",
      "Test Epoch79 layer2 out_loss 0.0014356287429109216\n",
      "Test Epoch79 layer3 out_loss 0.0015166914090514183\n",
      "Train 80 | out_loss 0.0013792980462312698: 100%|█| 138/138 [00:00<00:00, 259.55i\n",
      "[[0.00040086 0.00967541]\n",
      " [0.00039993 0.00193919]\n",
      " [0.0005683  0.00122941]\n",
      " [0.00036113 0.00044717]]\n",
      "Train Epoch80 out_loss 0.0013792980462312698\n",
      "Test Epoch80 layer0 out_loss 0.002600882202386856\n",
      "Test Epoch80 layer1 out_loss 0.0006589706754311919\n",
      "Test Epoch80 layer2 out_loss 0.000509685545694083\n",
      "Test Epoch80 layer3 out_loss 0.0006154889124445617\n",
      "Train 81 | out_loss 0.0013679771218448877: 100%|█| 138/138 [00:00<00:00, 255.83i\n",
      "[[0.0004092  0.00372427]\n",
      " [0.00042193 0.00192034]\n",
      " [0.00058758 0.00115524]\n",
      " [0.00033314 0.00045818]]\n",
      "Train Epoch81 out_loss 0.0013679771218448877\n",
      "Test Epoch81 layer0 out_loss 0.00237708049826324\n",
      "Test Epoch81 layer1 out_loss 0.0017931374022737145\n",
      "Test Epoch81 layer2 out_loss 0.0005132707301527262\n",
      "Test Epoch81 layer3 out_loss 0.0009031901718117297\n",
      "Train 82 | out_loss 0.0014617686392739415: 100%|█| 138/138 [00:00<00:00, 256.33i\n",
      "[[0.00043053 0.04693039]\n",
      " [0.00045072 0.00332086]\n",
      " [0.00059586 0.00165055]\n",
      " [0.00041854 0.00062734]]\n",
      "Train Epoch82 out_loss 0.0014617686392739415\n",
      "Test Epoch82 layer0 out_loss 0.003740588203072548\n",
      "Test Epoch82 layer1 out_loss 0.0012226125691086054\n",
      "Test Epoch82 layer2 out_loss 0.00046790813212282956\n",
      "Test Epoch82 layer3 out_loss 0.0005181693704798818\n",
      "Train 83 | out_loss 0.000686360290274024: 100%|█| 138/138 [00:00<00:00, 262.42it\n",
      "[[5.80386247e-05 4.73082300e-03]\n",
      " [2.26924186e-04 1.42200050e-03]\n",
      " [4.07088789e-04 9.09095091e-04]\n",
      " [3.19023434e-04 4.29498735e-04]]\n",
      "Train Epoch83 out_loss 0.000686360290274024\n",
      "Test Epoch83 layer0 out_loss 0.003844836726784706\n",
      "Test Epoch83 layer1 out_loss 0.0025300730485469103\n",
      "Test Epoch83 layer2 out_loss 0.001890451880171895\n",
      "Test Epoch83 layer3 out_loss 0.0019397151190787554\n",
      "Train 84 | out_loss 0.0015833672368898988: 100%|█| 138/138 [00:00<00:00, 268.37i\n",
      "[[0.00054482 0.01182241]\n",
      " [0.00040125 0.00221271]\n",
      " [0.00051811 0.0009431 ]\n",
      " [0.00028806 0.00040435]]\n",
      "Train Epoch84 out_loss 0.0015833672368898988\n",
      "Test Epoch84 layer0 out_loss 0.006219840608537197\n",
      "Test Epoch84 layer1 out_loss 0.001114311977289617\n",
      "Test Epoch84 layer2 out_loss 0.0011065672151744366\n",
      "Test Epoch84 layer3 out_loss 0.0010690342169255018\n",
      "Train 85 | out_loss 0.0015269186114892364: 100%|█| 138/138 [00:00<00:00, 268.46i\n",
      "[[0.00051868 0.01912792]\n",
      " [0.00030657 0.00224991]\n",
      " [0.00043298 0.00124097]\n",
      " [0.00034071 0.00067893]]\n",
      "Train Epoch85 out_loss 0.0015269186114892364\n",
      "Test Epoch85 layer0 out_loss 0.0026558858808130026\n",
      "Test Epoch85 layer1 out_loss 0.000826378702186048\n",
      "Test Epoch85 layer2 out_loss 0.0005354410968720913\n",
      "Test Epoch85 layer3 out_loss 0.0006942783948034048\n",
      "Train 86 | out_loss 0.0005255892756395042: 100%|█| 138/138 [00:00<00:00, 250.85i\n",
      "[[1.04001259e-05 1.69680816e-02]\n",
      " [4.33907184e-04 2.60891302e-03]\n",
      " [5.70326614e-04 1.57006479e-03]\n",
      " [4.82054127e-04 8.79375970e-04]]\n",
      "Train Epoch86 out_loss 0.0005255892756395042\n",
      "Test Epoch86 layer0 out_loss 0.0046175504103302956\n",
      "Test Epoch86 layer1 out_loss 0.0017914565978571773\n",
      "Test Epoch86 layer2 out_loss 0.0004484382807277143\n",
      "Test Epoch86 layer3 out_loss 0.0004278609703760594\n",
      "Train 87 | out_loss 0.0015672796871513128: 100%|█| 138/138 [00:00<00:00, 244.70i\n",
      "[[0.00052439 0.05496072]\n",
      " [0.00030522 0.0027101 ]\n",
      " [0.00045372 0.00197011]\n",
      " [0.00100836 0.00141934]]\n",
      "Train Epoch87 out_loss 0.0015672796871513128\n",
      "Test Epoch87 layer0 out_loss 0.005467782262712717\n",
      "Test Epoch87 layer1 out_loss 0.0006001836736686528\n",
      "Test Epoch87 layer2 out_loss 0.0005092439241707325\n",
      "Test Epoch87 layer3 out_loss 0.00046726682921871543\n",
      "Train 88 | out_loss 0.0015929127112030983: 100%|█| 138/138 [00:00<00:00, 263.13i\n",
      "[[0.00055117 0.01075262]\n",
      " [0.00028579 0.00136419]\n",
      " [0.00054295 0.0007114 ]\n",
      " [0.00019217 0.00029754]]\n",
      "Train Epoch88 out_loss 0.0015929127112030983\n",
      "Test Epoch88 layer0 out_loss 0.0021138647571206093\n",
      "Test Epoch88 layer1 out_loss 0.00041225130553357303\n",
      "Test Epoch88 layer2 out_loss 0.0005928690661676228\n",
      "Test Epoch88 layer3 out_loss 0.00043993094004690647\n",
      "Train 89 | out_loss 0.0006583936628885567: 100%|█| 138/138 [00:00<00:00, 258.94i\n",
      "[[3.52153255e-05 1.00406491e-02]\n",
      " [4.06985489e-04 2.16710172e-03]\n",
      " [5.67129818e-04 8.78869693e-04]\n",
      " [2.47758739e-04 2.83086757e-04]]\n",
      "Train Epoch89 out_loss 0.0006583936628885567\n",
      "Test Epoch89 layer0 out_loss 0.004766018595546484\n",
      "Test Epoch89 layer1 out_loss 0.0036965245380997658\n",
      "Test Epoch89 layer2 out_loss 0.0030121023301035166\n",
      "Test Epoch89 layer3 out_loss 0.002821733709424734\n",
      "Train 90 | out_loss 0.0013646597508341074: 100%|█| 138/138 [00:00<00:00, 258.52i\n",
      "[[0.00037865 0.01050935]\n",
      " [0.00022687 0.00129176]\n",
      " [0.00025307 0.00046569]\n",
      " [0.00011712 0.00016271]]\n",
      "Train Epoch90 out_loss 0.0013646597508341074\n",
      "Test Epoch90 layer0 out_loss 0.001657410291954875\n",
      "Test Epoch90 layer1 out_loss 0.0004944900865666568\n",
      "Test Epoch90 layer2 out_loss 0.0008947952883318067\n",
      "Test Epoch90 layer3 out_loss 0.0007246811874210835\n",
      "Train 91 | out_loss 0.0018123348709195852: 100%|█| 138/138 [00:00<00:00, 260.49i\n",
      "[[0.00067178 0.0297754 ]\n",
      " [0.00040312 0.00272487]\n",
      " [0.00059696 0.00106114]\n",
      " [0.00027951 0.00036927]]\n",
      "Train Epoch91 out_loss 0.0018123348709195852\n",
      "Test Epoch91 layer0 out_loss 0.004147910047322512\n",
      "Test Epoch91 layer1 out_loss 0.0008658103179186583\n",
      "Test Epoch91 layer2 out_loss 0.0006385570741258562\n",
      "Test Epoch91 layer3 out_loss 0.00041718376451171935\n",
      "Train 92 | out_loss 0.0012322480324655771: 100%|█| 138/138 [00:00<00:00, 261.53i\n",
      "[[0.00026003 0.06164009]\n",
      " [0.00024339 0.0032554 ]\n",
      " [0.00051251 0.00338142]\n",
      " [0.00070272 0.00161708]]\n",
      "Train Epoch92 out_loss 0.0012322480324655771\n",
      "Test Epoch92 layer0 out_loss 0.0033223184291273355\n",
      "Test Epoch92 layer1 out_loss 0.0024115426931530237\n",
      "Test Epoch92 layer2 out_loss 0.002806389005854726\n",
      "Test Epoch92 layer3 out_loss 0.0028728863690048456\n",
      "Train 93 | out_loss 0.00140194536652416: 100%|█| 138/138 [00:00<00:00, 265.91it/\n",
      "[[0.00039922 0.02366569]\n",
      " [0.00029372 0.00169788]\n",
      " [0.00038043 0.00056861]\n",
      " [0.00016106 0.00024325]]\n",
      "Train Epoch93 out_loss 0.00140194536652416\n",
      "Test Epoch93 layer0 out_loss 0.003301741322502494\n",
      "Test Epoch93 layer1 out_loss 0.0008450488094240427\n",
      "Test Epoch93 layer2 out_loss 0.0006422222941182554\n",
      "Test Epoch93 layer3 out_loss 0.0006107851513661444\n",
      "Train 94 | out_loss 0.001508304849267006: 100%|█| 138/138 [00:00<00:00, 261.58it\n",
      "[[0.00050343 0.00648177]\n",
      " [0.0003208  0.00158093]\n",
      " [0.00037251 0.00047935]\n",
      " [0.00017921 0.00021148]]\n",
      "Train Epoch94 out_loss 0.001508304849267006\n",
      "Test Epoch94 layer0 out_loss 0.0035544163547456264\n",
      "Test Epoch94 layer1 out_loss 0.000680035853292793\n",
      "Test Epoch94 layer2 out_loss 0.0008290008991025388\n",
      "Test Epoch94 layer3 out_loss 0.0007490573916584253\n",
      "Train 95 | out_loss 0.0007527318084612489: 100%|█| 138/138 [00:00<00:00, 254.16i\n",
      "[[8.74459026e-05 4.59948146e-03]\n",
      " [2.96949576e-04 1.55744509e-03]\n",
      " [6.57142175e-04 1.30999283e-03]\n",
      " [5.86461906e-04 5.60955079e-04]]\n",
      "Train Epoch95 out_loss 0.0007527318084612489\n",
      "Test Epoch95 layer0 out_loss 0.004401251208037138\n",
      "Test Epoch95 layer1 out_loss 0.0005156001425348222\n",
      "Test Epoch95 layer2 out_loss 0.0004210283514112234\n",
      "Test Epoch95 layer3 out_loss 0.000415935879573226\n",
      "Train 96 | out_loss 0.0034773116931319237: 100%|█| 138/138 [00:00<00:00, 255.53i\n",
      "[[0.0003939  0.00591811]\n",
      " [0.00605035 0.05053538]\n",
      " [0.01715065 0.05933531]\n",
      " [0.03728354 0.07374997]]\n",
      "Train Epoch96 out_loss 0.0034773116931319237\n",
      "Test Epoch96 layer0 out_loss 0.0058342283591628075\n",
      "Test Epoch96 layer1 out_loss 0.004281202796846628\n",
      "Test Epoch96 layer2 out_loss 0.0033923701848834753\n",
      "Test Epoch96 layer3 out_loss 0.0070386603474617004\n",
      "Train 97 | out_loss 0.0030242372304201126: 100%|█| 138/138 [00:00<00:00, 261.78i\n",
      "[[0.00046118 0.01063191]\n",
      " [0.00025835 0.00892595]\n",
      " [0.003576   0.02395717]\n",
      " [0.01439945 0.05767433]]\n",
      "Train Epoch97 out_loss 0.0030242372304201126\n",
      "Test Epoch97 layer0 out_loss 0.0026463852263987064\n",
      "Test Epoch97 layer1 out_loss 0.0006116972654126585\n",
      "Test Epoch97 layer2 out_loss 0.00044961198000237346\n",
      "Test Epoch97 layer3 out_loss 0.0004155850620009005\n",
      "Train 98 | out_loss 0.0016164790140464902: 100%|█| 138/138 [00:00<00:00, 253.04i\n",
      "[[4.11576208e-04 3.20817198e-02]\n",
      " [1.56261888e-05 1.55019042e-03]\n",
      " [1.51423730e-05 4.47622806e-04]\n",
      " [1.91278225e-05 4.03903087e-04]]\n",
      "Train Epoch98 out_loss 0.0016164790140464902\n",
      "Test Epoch98 layer0 out_loss 0.007646806538105011\n",
      "Test Epoch98 layer1 out_loss 0.0011894283816218376\n",
      "Test Epoch98 layer2 out_loss 0.0012319401139393449\n",
      "Test Epoch98 layer3 out_loss 0.001165924477390945\n",
      "Train 99 | out_loss 0.001485598972067237: 100%|█| 138/138 [00:00<00:00, 265.86it\n",
      "[[3.50865877e-04 1.15259578e-02]\n",
      " [4.95873413e-05 6.61681766e-04]\n",
      " [4.51546021e-05 2.32872003e-04]\n",
      " [5.69820164e-05 2.18417439e-04]]\n",
      "Train Epoch99 out_loss 0.001485598972067237\n",
      "Test Epoch99 layer0 out_loss 0.004084690939635038\n",
      "Test Epoch99 layer1 out_loss 0.0021673992741853\n",
      "Test Epoch99 layer2 out_loss 0.0012284234398975968\n",
      "Test Epoch99 layer3 out_loss 0.001238025026395917\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Start Training\n",
      "  0%|                                                   | 0/138 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 0.030016550794243813: 100%|█| 138/138 [00:01<00:00, 137.19it/\n",
      "[[2.17205075e-02 2.54601012e+01]\n",
      " [1.49455173e+00 1.01377479e+01]\n",
      " [7.91125714e-01 5.11652844e+00]\n",
      " [7.33810382e-01 2.74293150e+00]\n",
      " [6.49533965e-01 1.80625880e+00]]\n",
      "Train Epoch0 out_loss 0.030016550794243813\n",
      "Test Epoch0 layer0 out_loss 0.0983453169465065\n",
      "Test Epoch0 layer1 out_loss 0.013761362992227077\n",
      "Test Epoch0 layer2 out_loss 0.00682471739128232\n",
      "Test Epoch0 layer3 out_loss 0.004016099963337183\n",
      "Test Epoch0 layer4 out_loss 0.002157855313271284\n",
      "Train 1 | out_loss 0.0013340977020561695: 100%|█| 138/138 [00:00<00:00, 217.80it\n",
      "[[9.67484963e-06 5.73333894e+00]\n",
      " [6.14372348e-06 2.62016463e-01]\n",
      " [8.58774169e-06 7.73548106e-02]\n",
      " [7.56386675e-05 2.66566144e-02]\n",
      " [5.29730328e-04 1.16155391e-02]]\n",
      "Train Epoch1 out_loss 0.0013340977020561695\n",
      "Test Epoch1 layer0 out_loss 0.0938248559832573\n",
      "Test Epoch1 layer1 out_loss 0.007146567106246948\n",
      "Test Epoch1 layer2 out_loss 0.003173790406435728\n",
      "Test Epoch1 layer3 out_loss 0.0016574434703215957\n",
      "Test Epoch1 layer4 out_loss 0.0009308040607720613\n",
      "Train 2 | out_loss 0.0009071890381164849: 100%|█| 138/138 [00:00<00:00, 215.62it\n",
      "[[9.48074793e-06 3.14049998e+00]\n",
      " [5.79196807e-06 1.02051125e-01]\n",
      " [1.76275451e-06 2.96341466e-02]\n",
      " [7.68416142e-07 1.02581478e-02]\n",
      " [6.14360758e-07 3.97856619e-03]]\n",
      "Train Epoch2 out_loss 0.0009071890381164849\n",
      "Test Epoch2 layer0 out_loss 0.04424034431576729\n",
      "Test Epoch2 layer1 out_loss 0.003925063647329807\n",
      "Test Epoch2 layer2 out_loss 0.002463198034092784\n",
      "Test Epoch2 layer3 out_loss 0.0014693252742290497\n",
      "Test Epoch2 layer4 out_loss 0.0007156303036026657\n",
      "Train 3 | out_loss 0.0007756850100122392: 100%|█| 138/138 [00:00<00:00, 221.45it\n",
      "[[1.05861359e-05 2.35527391e+00]\n",
      " [5.91771889e-06 6.88065296e-02]\n",
      " [2.03326730e-06 1.81023505e-02]\n",
      " [1.41635411e-06 6.07054621e-03]\n",
      " [1.71066226e-06 2.40800728e-03]]\n",
      "Train Epoch3 out_loss 0.0007756850100122392\n",
      "Test Epoch3 layer0 out_loss 0.03533538430929184\n",
      "Test Epoch3 layer1 out_loss 0.004171873442828655\n",
      "Test Epoch3 layer2 out_loss 0.0020834594033658504\n",
      "Test Epoch3 layer3 out_loss 0.0008941060514189303\n",
      "Test Epoch3 layer4 out_loss 0.0007125764386728406\n",
      "Train 4 | out_loss 0.000707004452124238: 100%|█| 138/138 [00:00<00:00, 218.56it/\n",
      "[[8.79199886e-06 1.53636545e+00]\n",
      " [6.63736813e-06 5.05829070e-02]\n",
      " [1.92769807e-06 1.17905998e-02]\n",
      " [1.08979914e-06 3.96692181e-03]\n",
      " [1.25281071e-06 1.71232869e-03]]\n",
      "Train Epoch4 out_loss 0.000707004452124238\n",
      "Test Epoch4 layer0 out_loss 0.07242181152105331\n",
      "Test Epoch4 layer1 out_loss 0.0037094869185239077\n",
      "Test Epoch4 layer2 out_loss 0.0015838672406971455\n",
      "Test Epoch4 layer3 out_loss 0.0008468992309644818\n",
      "Test Epoch4 layer4 out_loss 0.0006760412943549454\n",
      "Train 5 | out_loss 0.0006412147777155042: 100%|█| 138/138 [00:00<00:00, 217.06it\n",
      "[[9.12329046e-06 1.34905775e+00]\n",
      " [8.99394945e-06 2.61663986e-02]\n",
      " [2.33264442e-06 7.16650610e-03]\n",
      " [2.41254445e-06 2.47943214e-03]\n",
      " [3.34588272e-06 1.12065442e-03]]\n",
      "Train Epoch5 out_loss 0.0006412147777155042\n",
      "Test Epoch5 layer0 out_loss 0.0329761765897274\n",
      "Test Epoch5 layer1 out_loss 0.0029810965061187744\n",
      "Test Epoch5 layer2 out_loss 0.0013204766437411308\n",
      "Test Epoch5 layer3 out_loss 0.0007780638406984508\n",
      "Test Epoch5 layer4 out_loss 0.0005619351286441088\n",
      "Train 6 | out_loss 0.0006124631036072969: 100%|█| 138/138 [00:00<00:00, 216.05it\n",
      "[[8.34660616e-06 1.48484807e+00]\n",
      " [9.73235523e-06 1.92193585e-02]\n",
      " [2.55573389e-06 5.16667710e-03]\n",
      " [3.07525245e-06 1.83568448e-03]\n",
      " [6.02355229e-06 8.99264390e-04]]\n",
      "Train Epoch6 out_loss 0.0006124631036072969\n",
      "Test Epoch6 layer0 out_loss 0.030445963144302368\n",
      "Test Epoch6 layer1 out_loss 0.0029183540027588606\n",
      "Test Epoch6 layer2 out_loss 0.0011464973213151097\n",
      "Test Epoch6 layer3 out_loss 0.000700990785844624\n",
      "Test Epoch6 layer4 out_loss 0.000585566449444741\n",
      "Train 7 | out_loss 0.000556906801648438: 100%|█| 138/138 [00:00<00:00, 220.54it/\n",
      "[[7.97861262e-06 6.62697211e-01]\n",
      " [9.26490655e-06 1.17739262e-02]\n",
      " [2.52715839e-06 3.42417869e-03]\n",
      " [3.03400998e-06 1.25687688e-03]\n",
      " [4.55012873e-06 6.40717722e-04]]\n",
      "Train Epoch7 out_loss 0.000556906801648438\n",
      "Test Epoch7 layer0 out_loss 0.01505232322961092\n",
      "Test Epoch7 layer1 out_loss 0.0020143426954746246\n",
      "Test Epoch7 layer2 out_loss 0.0009975642897188663\n",
      "Test Epoch7 layer3 out_loss 0.0006833738880231977\n",
      "Test Epoch7 layer4 out_loss 0.0005576129769906402\n",
      "Train 8 | out_loss 0.0005203443579375744: 100%|█| 138/138 [00:00<00:00, 214.38it\n",
      "[[8.98335220e-06 5.71415700e-01]\n",
      " [9.09647833e-06 9.14176374e-03]\n",
      " [2.74603920e-06 2.64559543e-03]\n",
      " [3.60909839e-06 9.78865242e-04]\n",
      " [6.70387595e-06 4.94378392e-04]]\n",
      "Train Epoch8 out_loss 0.0005203443579375744\n",
      "Test Epoch8 layer0 out_loss 0.021427497267723083\n",
      "Test Epoch8 layer1 out_loss 0.0023289229720830917\n",
      "Test Epoch8 layer2 out_loss 0.0009326183935627341\n",
      "Test Epoch8 layer3 out_loss 0.0006869990029372275\n",
      "Test Epoch8 layer4 out_loss 0.0006516141002066433\n",
      "Train 9 | out_loss 0.0004988627624697983: 100%|█| 138/138 [00:00<00:00, 215.30it\n",
      "[[6.81920386e-06 8.07281405e-01]\n",
      " [1.02612400e-05 1.03747125e-02]\n",
      " [2.90973621e-06 2.52729405e-03]\n",
      " [4.52900917e-06 9.20278632e-04]\n",
      " [1.07641634e-05 4.46318618e-04]]\n",
      "Train Epoch9 out_loss 0.0004988627624697983\n",
      "Test Epoch9 layer0 out_loss 0.027579136192798615\n",
      "Test Epoch9 layer1 out_loss 0.001722704735584557\n",
      "Test Epoch9 layer2 out_loss 0.000844412250444293\n",
      "Test Epoch9 layer3 out_loss 0.0006848534685559571\n",
      "Test Epoch9 layer4 out_loss 0.0005361884832382202\n",
      "Train 10 | out_loss 0.0005027632578276098: 100%|█| 138/138 [00:00<00:00, 219.54i\n",
      "[[8.68381210e-06 7.56706563e-01]\n",
      " [1.10293561e-05 6.58101769e-03]\n",
      " [3.78938802e-06 1.83645416e-03]\n",
      " [7.07163611e-06 7.00906728e-04]\n",
      " [1.14741310e-05 3.85212747e-04]]\n",
      "Train Epoch10 out_loss 0.0005027632578276098\n",
      "Test Epoch10 layer0 out_loss 0.04269943758845329\n",
      "Test Epoch10 layer1 out_loss 0.002610843861475587\n",
      "Test Epoch10 layer2 out_loss 0.0007851250120438635\n",
      "Test Epoch10 layer3 out_loss 0.0006969804526306689\n",
      "Test Epoch10 layer4 out_loss 0.0005731009296141565\n",
      "Train 11 | out_loss 0.0005068302853032947: 100%|█| 138/138 [00:00<00:00, 221.56i\n",
      "[[6.75631117e-06 4.03931162e-01]\n",
      " [1.36203125e-05 4.96026542e-03]\n",
      " [4.10256261e-06 1.45757017e-03]\n",
      " [8.49446809e-06 5.57794015e-04]\n",
      " [1.90277311e-05 2.97116242e-04]]\n",
      "Train Epoch11 out_loss 0.0005068302853032947\n",
      "Test Epoch11 layer0 out_loss 0.020953072234988213\n",
      "Test Epoch11 layer1 out_loss 0.0012873571831732988\n",
      "Test Epoch11 layer2 out_loss 0.0007772190147079527\n",
      "Test Epoch11 layer3 out_loss 0.0005384280811995268\n",
      "Test Epoch11 layer4 out_loss 0.0004576063947752118\n",
      "Train 12 | out_loss 0.000493425119202584: 100%|█| 138/138 [00:00<00:00, 219.40it\n",
      "[[7.00474399e-06 3.79181191e-01]\n",
      " [1.37080926e-05 4.28522812e-03]\n",
      " [3.95822808e-06 1.24340831e-03]\n",
      " [6.92125799e-06 4.73662180e-04]\n",
      " [1.40456091e-05 2.51117006e-04]]\n",
      "Train Epoch12 out_loss 0.000493425119202584\n",
      "Test Epoch12 layer0 out_loss 0.01133833546191454\n",
      "Test Epoch12 layer1 out_loss 0.0016426114598289132\n",
      "Test Epoch12 layer2 out_loss 0.0008585754549130797\n",
      "Test Epoch12 layer3 out_loss 0.0005280367913655937\n",
      "Test Epoch12 layer4 out_loss 0.0004475259920582175\n",
      "Train 13 | out_loss 0.0005036229849793017: 100%|█| 138/138 [00:00<00:00, 202.07i\n",
      "[[6.63018567e-06 5.80005570e-01]\n",
      " [1.51964763e-05 4.57853000e-03]\n",
      " [4.99295505e-06 1.26492770e-03]\n",
      " [9.15246327e-06 4.69390110e-04]\n",
      " [1.19061882e-05 2.58307705e-04]]\n",
      "Train Epoch13 out_loss 0.0005036229849793017\n",
      "Test Epoch13 layer0 out_loss 0.025482427328824997\n",
      "Test Epoch13 layer1 out_loss 0.0015252165030688047\n",
      "Test Epoch13 layer2 out_loss 0.0009656149195507169\n",
      "Test Epoch13 layer3 out_loss 0.0008658837177790701\n",
      "Test Epoch13 layer4 out_loss 0.0008883213740773499\n",
      "Train 14 | out_loss 0.0005260842153802514: 100%|█| 138/138 [00:00<00:00, 220.11i\n",
      "[[1.12837420e-05 1.42278291e-01]\n",
      " [1.74700798e-05 2.73923908e-03]\n",
      " [6.18018029e-06 8.67925023e-04]\n",
      " [1.29599238e-05 3.38344632e-04]\n",
      " [2.62542216e-05 2.09601612e-04]]\n",
      "Train Epoch14 out_loss 0.0005260842153802514\n",
      "Test Epoch14 layer0 out_loss 0.035046327859163284\n",
      "Test Epoch14 layer1 out_loss 0.0011586317559704185\n",
      "Test Epoch14 layer2 out_loss 0.0008395415497943759\n",
      "Test Epoch14 layer3 out_loss 0.0006115558790042996\n",
      "Test Epoch14 layer4 out_loss 0.0004993212060071528\n",
      "Train 15 | out_loss 0.0005844590486958623: 100%|█| 138/138 [00:00<00:00, 207.51i\n",
      "[[1.70398892e-05 5.37230272e-01]\n",
      " [1.80162775e-05 5.44170147e-03]\n",
      " [8.41544472e-06 1.35008507e-03]\n",
      " [1.88707449e-05 4.93051498e-04]\n",
      " [6.17731663e-05 2.77505570e-04]]\n",
      "Train Epoch15 out_loss 0.0005844590486958623\n",
      "Test Epoch15 layer0 out_loss 0.022815527394413948\n",
      "Test Epoch15 layer1 out_loss 0.0016697137616574764\n",
      "Test Epoch15 layer2 out_loss 0.000779526773840189\n",
      "Test Epoch15 layer3 out_loss 0.0005252950941212475\n",
      "Test Epoch15 layer4 out_loss 0.00044885778333991766\n",
      "Train 16 | out_loss 0.0009710333542898297: 100%|█| 138/138 [00:00<00:00, 216.68i\n",
      "[[1.50130546e-04 5.72917946e-01]\n",
      " [2.96824828e-05 3.59313131e-03]\n",
      " [1.90027210e-05 1.00110735e-03]\n",
      " [2.87345107e-05 4.13440189e-04]\n",
      " [3.87783895e-05 2.55636593e-04]]\n",
      "Train Epoch16 out_loss 0.0009710333542898297\n",
      "Test Epoch16 layer0 out_loss 0.021963393315672874\n",
      "Test Epoch16 layer1 out_loss 0.0020113419741392136\n",
      "Test Epoch16 layer2 out_loss 0.0015441913856193423\n",
      "Test Epoch16 layer3 out_loss 0.0015004922170192003\n",
      "Test Epoch16 layer4 out_loss 0.0016356429550796747\n",
      "Train 17 | out_loss 0.0013232900528237224: 100%|█| 138/138 [00:00<00:00, 219.41i\n",
      "[[3.27964597e-04 1.34368395e-01]\n",
      " [2.53531529e-05 2.18378070e-03]\n",
      " [4.60766558e-05 7.04293487e-04]\n",
      " [6.64615995e-05 3.15231171e-04]\n",
      " [6.47201660e-05 1.92669084e-04]]\n",
      "Train Epoch17 out_loss 0.0013232900528237224\n",
      "Test Epoch17 layer0 out_loss 0.006032337434589863\n",
      "Test Epoch17 layer1 out_loss 0.0009887766791507602\n",
      "Test Epoch17 layer2 out_loss 0.0006902461755089462\n",
      "Test Epoch17 layer3 out_loss 0.0006400435813702643\n",
      "Test Epoch17 layer4 out_loss 0.0005542965373024344\n",
      "Train 18 | out_loss 0.0016141296364367008: 100%|█| 138/138 [00:00<00:00, 215.02i\n",
      "[[5.10143344e-04 2.20876139e-01]\n",
      " [4.93498546e-05 2.37985126e-03]\n",
      " [2.09591720e-04 8.47582585e-04]\n",
      " [2.74403280e-04 5.97989765e-04]\n",
      " [1.43027943e-04 4.04468540e-04]]\n",
      "Train Epoch18 out_loss 0.0016141296364367008\n",
      "Test Epoch18 layer0 out_loss 0.028736304491758347\n",
      "Test Epoch18 layer1 out_loss 0.0015964752528816462\n",
      "Test Epoch18 layer2 out_loss 0.0010273363441228867\n",
      "Test Epoch18 layer3 out_loss 0.0016368157230317593\n",
      "Test Epoch18 layer4 out_loss 0.0011571598006412387\n",
      "Train 19 | out_loss 0.001068944693543017: 100%|█| 138/138 [00:00<00:00, 212.47it\n",
      "[[1.77057200e-04 2.53034817e-01]\n",
      " [1.01379100e-04 2.56250421e-03]\n",
      " [8.03900590e-04 1.25140271e-03]\n",
      " [6.43562685e-04 1.16017182e-03]\n",
      " [3.62687511e-04 6.70379291e-04]]\n",
      "Train Epoch19 out_loss 0.001068944693543017\n",
      "Test Epoch19 layer0 out_loss 0.041249364614486694\n",
      "Test Epoch19 layer1 out_loss 0.0016659221146255732\n",
      "Test Epoch19 layer2 out_loss 0.0007773113320581615\n",
      "Test Epoch19 layer3 out_loss 0.0006093864212743938\n",
      "Test Epoch19 layer4 out_loss 0.0006612766301259398\n",
      "Train 20 | out_loss 0.001613912871107459: 100%|█| 138/138 [00:00<00:00, 216.34it\n",
      "[[0.00045422 0.14246177]\n",
      " [0.00015717 0.00183374]\n",
      " [0.00068948 0.00095125]\n",
      " [0.00030393 0.0008119 ]\n",
      " [0.00033416 0.00050599]]\n",
      "Train Epoch20 out_loss 0.001613912871107459\n",
      "Test Epoch20 layer0 out_loss 0.02489476464688778\n",
      "Test Epoch20 layer1 out_loss 0.0009121546754613519\n",
      "Test Epoch20 layer2 out_loss 0.0006320223910734057\n",
      "Test Epoch20 layer3 out_loss 0.000503965129610151\n",
      "Test Epoch20 layer4 out_loss 0.0004577515064738691\n",
      "Train 21 | out_loss 0.0012388703180477023: 100%|█| 138/138 [00:00<00:00, 216.73i\n",
      "[[2.47736442e-04 3.23914470e-01]\n",
      " [2.00044389e-04 2.74889872e-03]\n",
      " [6.73153232e-04 1.18759791e-03]\n",
      " [2.71290532e-04 7.57856965e-04]\n",
      " [4.07611643e-04 4.50412564e-04]]\n",
      "Train Epoch21 out_loss 0.0012388703180477023\n",
      "Test Epoch21 layer0 out_loss 0.025167064741253853\n",
      "Test Epoch21 layer1 out_loss 0.0014494323404505849\n",
      "Test Epoch21 layer2 out_loss 0.0008174550603143871\n",
      "Test Epoch21 layer3 out_loss 0.0015170149272307754\n",
      "Test Epoch21 layer4 out_loss 0.0012765343999490142\n",
      "Train 22 | out_loss 0.001571735367178917: 100%|█| 138/138 [00:00<00:00, 220.02it\n",
      "[[0.00043024 0.24437026]\n",
      " [0.0003578  0.00228354]\n",
      " [0.0008248  0.00127674]\n",
      " [0.00039061 0.00080335]\n",
      " [0.00070178 0.00066329]]\n",
      "Train Epoch22 out_loss 0.001571735367178917\n",
      "Test Epoch22 layer0 out_loss 0.011677699163556099\n",
      "Test Epoch22 layer1 out_loss 0.001121111330576241\n",
      "Test Epoch22 layer2 out_loss 0.0009621792705729604\n",
      "Test Epoch22 layer3 out_loss 0.0006760844262316823\n",
      "Test Epoch22 layer4 out_loss 0.0006632762379013002\n",
      "Train 23 | out_loss 0.0013762086164206266: 100%|█| 138/138 [00:00<00:00, 219.76i\n",
      "[[0.0003219  0.22770299]\n",
      " [0.00031513 0.00194501]\n",
      " [0.00058206 0.0010349 ]\n",
      " [0.00044718 0.00072827]\n",
      " [0.00058073 0.00072611]]\n",
      "Train Epoch23 out_loss 0.0013762086164206266\n",
      "Test Epoch23 layer0 out_loss 0.006296927109360695\n",
      "Test Epoch23 layer1 out_loss 0.002509070560336113\n",
      "Test Epoch23 layer2 out_loss 0.0023921895772218704\n",
      "Test Epoch23 layer3 out_loss 0.002456018002703786\n",
      "Test Epoch23 layer4 out_loss 0.002287334995344281\n",
      "Train 24 | out_loss 0.0012510300148278475: 100%|█| 138/138 [00:00<00:00, 219.73i\n",
      "[[3.08518686e-04 4.15874029e-01]\n",
      " [3.66173143e-04 2.78202648e-03]\n",
      " [5.68477299e-04 1.23019270e-03]\n",
      " [5.64180906e-04 9.35476911e-04]\n",
      " [4.80919006e-04 7.88048789e-04]]\n",
      "Train Epoch24 out_loss 0.0012510300148278475\n",
      "Test Epoch24 layer0 out_loss 0.02563835121691227\n",
      "Test Epoch24 layer1 out_loss 0.002336394740268588\n",
      "Test Epoch24 layer2 out_loss 0.0008792239241302013\n",
      "Test Epoch24 layer3 out_loss 0.000836909981444478\n",
      "Test Epoch24 layer4 out_loss 0.0006992249400354922\n",
      "Train 25 | out_loss 0.0014060745015740395: 100%|█| 138/138 [00:00<00:00, 212.15i\n",
      "[[0.00031484 0.19220584]\n",
      " [0.00056914 0.00221402]\n",
      " [0.00098756 0.00156231]\n",
      " [0.00070394 0.00140967]\n",
      " [0.00064121 0.00108683]]\n",
      "Train Epoch25 out_loss 0.0014060745015740395\n",
      "Test Epoch25 layer0 out_loss 0.008192888461053371\n",
      "Test Epoch25 layer1 out_loss 0.0008299597539007664\n",
      "Test Epoch25 layer2 out_loss 0.0006504515768028796\n",
      "Test Epoch25 layer3 out_loss 0.0005161553272046149\n",
      "Test Epoch25 layer4 out_loss 0.0004504592507146299\n",
      "Train 26 | out_loss 0.0018282695673406124: 100%|█| 138/138 [00:00<00:00, 218.91i\n",
      "[[5.68670115e-04 3.34899385e-01]\n",
      " [1.02747182e-04 2.36193013e-03]\n",
      " [1.48841421e-04 7.97773383e-04]\n",
      " [2.32197725e-04 7.92108110e-04]\n",
      " [2.77777997e-04 6.55775178e-04]]\n",
      "Train Epoch26 out_loss 0.0018282695673406124\n",
      "Test Epoch26 layer0 out_loss 0.009023112244904041\n",
      "Test Epoch26 layer1 out_loss 0.0019483871292322874\n",
      "Test Epoch26 layer2 out_loss 0.0016456505982205272\n",
      "Test Epoch26 layer3 out_loss 0.001966601936146617\n",
      "Test Epoch26 layer4 out_loss 0.0017196092521771789\n",
      "Train 27 | out_loss 0.00128386658616364: 100%|█| 138/138 [00:00<00:00, 208.65it/\n",
      "[[2.52739096e-04 3.29532937e-01]\n",
      " [4.85921578e-04 2.62418975e-03]\n",
      " [6.09745531e-04 1.28842475e-03]\n",
      " [6.31861896e-04 9.24212828e-04]\n",
      " [4.69132627e-04 6.91109639e-04]]\n",
      "Train Epoch27 out_loss 0.00128386658616364\n",
      "Test Epoch27 layer0 out_loss 0.0313635878264904\n",
      "Test Epoch27 layer1 out_loss 0.0018894209060817957\n",
      "Test Epoch27 layer2 out_loss 0.000589418807066977\n",
      "Test Epoch27 layer3 out_loss 0.000499845074955374\n",
      "Test Epoch27 layer4 out_loss 0.0005116097163408995\n",
      "Train 28 | out_loss 0.0015197335742413998: 100%|█| 138/138 [00:00<00:00, 215.47i\n",
      "[[0.00037699 0.23801509]\n",
      " [0.00043167 0.00313336]\n",
      " [0.00062083 0.0014488 ]\n",
      " [0.00060435 0.00143356]\n",
      " [0.00049448 0.00079826]]\n",
      "Train Epoch28 out_loss 0.0015197335742413998\n",
      "Test Epoch28 layer0 out_loss 0.007694867439568043\n",
      "Test Epoch28 layer1 out_loss 0.0012411006027832627\n",
      "Test Epoch28 layer2 out_loss 0.0008626448689028621\n",
      "Test Epoch28 layer3 out_loss 0.001337854890152812\n",
      "Test Epoch28 layer4 out_loss 0.0014465019339695573\n",
      "Train 29 | out_loss 0.0010914746671915054: 100%|█| 138/138 [00:00<00:00, 216.97i\n",
      "[[0.00017173 0.05382776]\n",
      " [0.00051644 0.00141538]\n",
      " [0.0007528  0.00102768]\n",
      " [0.00061147 0.00088523]\n",
      " [0.00048085 0.00067637]]\n",
      "Train Epoch29 out_loss 0.0010914746671915054\n",
      "Test Epoch29 layer0 out_loss 0.007475592195987701\n",
      "Test Epoch29 layer1 out_loss 0.0007599370437674224\n",
      "Test Epoch29 layer2 out_loss 0.000842193840071559\n",
      "Test Epoch29 layer3 out_loss 0.0008017256041057408\n",
      "Test Epoch29 layer4 out_loss 0.0004646392771974206\n",
      "Train 30 | out_loss 0.0015667349798604846: 100%|█| 138/138 [00:00<00:00, 218.80i\n",
      "[[0.00040642 0.04316587]\n",
      " [0.00044571 0.00121451]\n",
      " [0.00083884 0.00112895]\n",
      " [0.00080039 0.00129352]\n",
      " [0.00054568 0.00081332]]\n",
      "Train Epoch30 out_loss 0.0015667349798604846\n",
      "Test Epoch30 layer0 out_loss 0.016721822321414948\n",
      "Test Epoch30 layer1 out_loss 0.002511374419555068\n",
      "Test Epoch30 layer2 out_loss 0.0021574862767010927\n",
      "Test Epoch30 layer3 out_loss 0.0026701530441641808\n",
      "Test Epoch30 layer4 out_loss 0.0030487896874547005\n",
      "Train 31 | out_loss 0.0015762372640892863: 100%|█| 138/138 [00:00<00:00, 212.56i\n",
      "[[0.00041677 0.09527562]\n",
      " [0.0004027  0.00223364]\n",
      " [0.00048582 0.0011884 ]\n",
      " [0.00044889 0.00100133]\n",
      " [0.00087202 0.00096978]]\n",
      "Train Epoch31 out_loss 0.0015762372640892863\n",
      "Test Epoch31 layer0 out_loss 0.009990264661610126\n",
      "Test Epoch31 layer1 out_loss 0.0008027459844015539\n",
      "Test Epoch31 layer2 out_loss 0.0006124032661318779\n",
      "Test Epoch31 layer3 out_loss 0.0005397208733484149\n",
      "Test Epoch31 layer4 out_loss 0.0006651935400441289\n",
      "Train 32 | out_loss 0.0013742507435381413: 100%|█| 138/138 [00:00<00:00, 214.20i\n",
      "[[0.00031552 0.07189006]\n",
      " [0.00059355 0.00188804]\n",
      " [0.00074363 0.0014267 ]\n",
      " [0.00053812 0.00096182]\n",
      " [0.00061134 0.0006754 ]]\n",
      "Train Epoch32 out_loss 0.0013742507435381413\n",
      "Test Epoch32 layer0 out_loss 0.009076900780200958\n",
      "Test Epoch32 layer1 out_loss 0.0007234066142700613\n",
      "Test Epoch32 layer2 out_loss 0.0005883491830900311\n",
      "Test Epoch32 layer3 out_loss 0.0005956895765848458\n",
      "Test Epoch32 layer4 out_loss 0.0004353912372607738\n",
      "Train 33 | out_loss 0.00142246566247195: 100%|█| 138/138 [00:00<00:00, 218.11it/\n",
      "[[2.98023865e-04 5.05284938e-01]\n",
      " [4.57644644e-04 2.92757388e-03]\n",
      " [8.32062048e-04 1.38545799e-03]\n",
      " [6.85370380e-04 1.40580759e-03]\n",
      " [5.35963402e-04 8.32925124e-04]]\n",
      "Train Epoch33 out_loss 0.00142246566247195\n",
      "Test Epoch33 layer0 out_loss 0.012040648609399796\n",
      "Test Epoch33 layer1 out_loss 0.0010135573102161288\n",
      "Test Epoch33 layer2 out_loss 0.000574834062717855\n",
      "Test Epoch33 layer3 out_loss 0.0006218993803486228\n",
      "Test Epoch33 layer4 out_loss 0.0004470951680559665\n",
      "Train 34 | out_loss 0.0012127377558499575: 100%|█| 138/138 [00:00<00:00, 216.84i\n",
      "[[2.34112938e-04 2.80444552e-01]\n",
      " [7.54418990e-04 2.26177745e-03]\n",
      " [7.70881642e-04 1.32831393e-03]\n",
      " [5.84272378e-04 1.08141297e-03]\n",
      " [4.70562239e-04 6.20109143e-04]]\n",
      "Train Epoch34 out_loss 0.0012127377558499575\n",
      "Test Epoch34 layer0 out_loss 0.008204737678170204\n",
      "Test Epoch34 layer1 out_loss 0.0008946896996349096\n",
      "Test Epoch34 layer2 out_loss 0.0005202159518375993\n",
      "Test Epoch34 layer3 out_loss 0.0006249345024116337\n",
      "Test Epoch34 layer4 out_loss 0.000544394482858479\n",
      "Train 35 | out_loss 0.0016396313440054655: 100%|█| 138/138 [00:00<00:00, 219.38i\n",
      "[[0.00046618 0.0878805 ]\n",
      " [0.00034492 0.00119344]\n",
      " [0.0004942  0.00088896]\n",
      " [0.00043612 0.0009256 ]\n",
      " [0.00046276 0.00058431]]\n",
      "Train Epoch35 out_loss 0.0016396313440054655\n",
      "Test Epoch35 layer0 out_loss 0.009692734107375145\n",
      "Test Epoch35 layer1 out_loss 0.0007103118114173412\n",
      "Test Epoch35 layer2 out_loss 0.0005241089384071529\n",
      "Test Epoch35 layer3 out_loss 0.000541358720511198\n",
      "Test Epoch35 layer4 out_loss 0.0005465493304654956\n",
      "Train 36 | out_loss 0.0013832843396812677: 100%|█| 138/138 [00:00<00:00, 219.79i\n",
      "[[0.00036211 0.04563508]\n",
      " [0.00057905 0.00161605]\n",
      " [0.00077921 0.00135519]\n",
      " [0.00060398 0.00093901]\n",
      " [0.00041415 0.00051303]]\n",
      "Train Epoch36 out_loss 0.0013832843396812677\n",
      "Test Epoch36 layer0 out_loss 0.01938115991652012\n",
      "Test Epoch36 layer1 out_loss 0.0007610729662701488\n",
      "Test Epoch36 layer2 out_loss 0.0005217478610575199\n",
      "Test Epoch36 layer3 out_loss 0.0006863691378384829\n",
      "Test Epoch36 layer4 out_loss 0.0004561427340377122\n",
      "Train 37 | out_loss 0.001275059417821467: 100%|█| 138/138 [00:00<00:00, 201.86it\n",
      "[[0.00026653 0.05235693]\n",
      " [0.0005999  0.00191444]\n",
      " [0.00073657 0.00132036]\n",
      " [0.0005576  0.00099058]\n",
      " [0.00039675 0.00051431]]\n",
      "Train Epoch37 out_loss 0.001275059417821467\n",
      "Test Epoch37 layer0 out_loss 0.018646443262696266\n",
      "Test Epoch37 layer1 out_loss 0.001544074504636228\n",
      "Test Epoch37 layer2 out_loss 0.0005000171950086951\n",
      "Test Epoch37 layer3 out_loss 0.0008458422380499542\n",
      "Test Epoch37 layer4 out_loss 0.00043842417653650045\n",
      "Train 38 | out_loss 0.0012883486924692988: 100%|█| 138/138 [00:00<00:00, 217.61i\n",
      "[[2.93126328e-04 6.16183952e-01]\n",
      " [4.27581041e-04 4.09044389e-03]\n",
      " [6.20455011e-04 1.66139655e-03]\n",
      " [4.81553097e-04 1.19726167e-03]\n",
      " [4.33758062e-04 7.45059416e-04]]\n",
      "Train Epoch38 out_loss 0.0012883486924692988\n",
      "Test Epoch38 layer0 out_loss 0.020999301224946976\n",
      "Test Epoch38 layer1 out_loss 0.001142896362580359\n",
      "Test Epoch38 layer2 out_loss 0.0005082451389171183\n",
      "Test Epoch38 layer3 out_loss 0.0004802730691153556\n",
      "Test Epoch38 layer4 out_loss 0.00044989248272031546\n",
      "Train 39 | out_loss 0.0015018280828371644: 100%|█| 138/138 [00:00<00:00, 217.46i\n",
      "[[0.00038043 0.10131278]\n",
      " [0.00065612 0.00210093]\n",
      " [0.00070008 0.00140084]\n",
      " [0.0004827  0.00108207]\n",
      " [0.00042284 0.00052617]]\n",
      "Train Epoch39 out_loss 0.0015018280828371644\n",
      "Test Epoch39 layer0 out_loss 0.02350756712257862\n",
      "Test Epoch39 layer1 out_loss 0.0043134624138474464\n",
      "Test Epoch39 layer2 out_loss 0.0035136062651872635\n",
      "Test Epoch39 layer3 out_loss 0.0029131940100342035\n",
      "Test Epoch39 layer4 out_loss 0.002873367629945278\n",
      "Train 40 | out_loss 0.0012794097419828176: 100%|█| 138/138 [00:00<00:00, 194.43i\n",
      "[[0.00027853 0.038326  ]\n",
      " [0.00062644 0.00160803]\n",
      " [0.00079609 0.00143241]\n",
      " [0.00061024 0.00120313]\n",
      " [0.00049412 0.0006006 ]]\n",
      "Train Epoch40 out_loss 0.0012794097419828176\n",
      "Test Epoch40 layer0 out_loss 0.011181366629898548\n",
      "Test Epoch40 layer1 out_loss 0.001768139423802495\n",
      "Test Epoch40 layer2 out_loss 0.0023701649624854326\n",
      "Test Epoch40 layer3 out_loss 0.0017585055902600288\n",
      "Test Epoch40 layer4 out_loss 0.001725043635815382\n",
      "Train 41 | out_loss 0.0015212141443043947: 100%|█| 138/138 [00:00<00:00, 215.62i\n",
      "[[0.00039005 0.01017383]\n",
      " [0.00059729 0.00117555]\n",
      " [0.00074698 0.0013556 ]\n",
      " [0.00069412 0.00100167]\n",
      " [0.0004113  0.00058734]]\n",
      "Train Epoch41 out_loss 0.0015212141443043947\n",
      "Test Epoch41 layer0 out_loss 0.004653480835258961\n",
      "Test Epoch41 layer1 out_loss 0.0007308793137781322\n",
      "Test Epoch41 layer2 out_loss 0.0005737587925978005\n",
      "Test Epoch41 layer3 out_loss 0.0005814175237901509\n",
      "Test Epoch41 layer4 out_loss 0.0005287544336169958\n",
      "Train 42 | out_loss 0.0013114468893036246: 100%|█| 138/138 [00:00<00:00, 207.11i\n",
      "[[0.0003274  0.01289798]\n",
      " [0.00041976 0.00102425]\n",
      " [0.000502   0.00135487]\n",
      " [0.00045288 0.00105131]\n",
      " [0.00047141 0.00049181]]\n",
      "Train Epoch42 out_loss 0.0013114468893036246\n",
      "Test Epoch42 layer0 out_loss 0.005637127906084061\n",
      "Test Epoch42 layer1 out_loss 0.0010492056608200073\n",
      "Test Epoch42 layer2 out_loss 0.0005271367263048887\n",
      "Test Epoch42 layer3 out_loss 0.0008266391814686358\n",
      "Test Epoch42 layer4 out_loss 0.0007329144864343107\n",
      "Train 43 | out_loss 0.0015169569524005055: 100%|█| 138/138 [00:00<00:00, 218.65i\n",
      "[[0.00042161 0.33361128]\n",
      " [0.00060655 0.00366577]\n",
      " [0.0006911  0.00180833]\n",
      " [0.00047455 0.00116376]\n",
      " [0.0003652  0.00057039]]\n",
      "Train Epoch43 out_loss 0.0015169569524005055\n",
      "Test Epoch43 layer0 out_loss 0.018730375915765762\n",
      "Test Epoch43 layer1 out_loss 0.0006776372902095318\n",
      "Test Epoch43 layer2 out_loss 0.0005838451907038689\n",
      "Test Epoch43 layer3 out_loss 0.0009250306757166982\n",
      "Test Epoch43 layer4 out_loss 0.00043274505878798664\n",
      "Train 44 | out_loss 0.0015436442336067557: 100%|█| 138/138 [00:00<00:00, 215.16i\n",
      "[[0.00040785 0.07628324]\n",
      " [0.00051452 0.00147946]\n",
      " [0.00061494 0.00141181]\n",
      " [0.00048991 0.00099636]\n",
      " [0.00041923 0.00047851]]\n",
      "Train Epoch44 out_loss 0.0015436442336067557\n",
      "Test Epoch44 layer0 out_loss 0.006174163892865181\n",
      "Test Epoch44 layer1 out_loss 0.0006612389115616679\n",
      "Test Epoch44 layer2 out_loss 0.0005508247995749116\n",
      "Test Epoch44 layer3 out_loss 0.0009246622212231159\n",
      "Test Epoch44 layer4 out_loss 0.0006102270563133061\n",
      "Train 45 | out_loss 0.0017509660683572292: 100%|█| 138/138 [00:00<00:00, 217.23i\n",
      "[[0.00055811 0.02038411]\n",
      " [0.00066121 0.00159426]\n",
      " [0.00089734 0.00167948]\n",
      " [0.00067626 0.00123784]\n",
      " [0.0004859  0.0005581 ]]\n",
      "Train Epoch45 out_loss 0.0017509660683572292\n",
      "Test Epoch45 layer0 out_loss 0.004932627081871033\n",
      "Test Epoch45 layer1 out_loss 0.0006813130457885563\n",
      "Test Epoch45 layer2 out_loss 0.0005335230962373316\n",
      "Test Epoch45 layer3 out_loss 0.0011194340186193585\n",
      "Test Epoch45 layer4 out_loss 0.0004362133622635156\n",
      "Train 46 | out_loss 0.0005026377039030194: 100%|█| 138/138 [00:00<00:00, 210.52i\n",
      "[[5.23573196e-06 2.55876715e-02]\n",
      " [6.10847218e-04 1.41726618e-03]\n",
      " [6.35183938e-04 1.69498490e-03]\n",
      " [4.46253234e-04 1.02187700e-03]\n",
      " [3.95020000e-04 5.38282855e-04]]\n",
      "Train Epoch46 out_loss 0.0005026377039030194\n",
      "Test Epoch46 layer0 out_loss 0.007972966879606247\n",
      "Test Epoch46 layer1 out_loss 0.0007036879542283714\n",
      "Test Epoch46 layer2 out_loss 0.0005090984632261097\n",
      "Test Epoch46 layer3 out_loss 0.0004741911543533206\n",
      "Test Epoch46 layer4 out_loss 0.00043444556649774313\n",
      "Train 47 | out_loss 0.0015609456459060311: 100%|█| 138/138 [00:00<00:00, 216.88i\n",
      "[[0.00044251 0.13256897]\n",
      " [0.0005104  0.00248077]\n",
      " [0.00069625 0.001445  ]\n",
      " [0.00049608 0.00097997]\n",
      " [0.00037756 0.00048506]]\n",
      "Train Epoch47 out_loss 0.0015609456459060311\n",
      "Test Epoch47 layer0 out_loss 0.007039976771920919\n",
      "Test Epoch47 layer1 out_loss 0.0015200339257717133\n",
      "Test Epoch47 layer2 out_loss 0.0014708020025864244\n",
      "Test Epoch47 layer3 out_loss 0.0004900566418655217\n",
      "Test Epoch47 layer4 out_loss 0.0006233808817341924\n",
      "Train 48 | out_loss 0.0014569725608453155: 100%|█| 138/138 [00:00<00:00, 215.18i\n",
      "[[0.0003825  0.08918951]\n",
      " [0.000541   0.00199779]\n",
      " [0.00062918 0.00158192]\n",
      " [0.00046551 0.00103741]\n",
      " [0.00050068 0.0006513 ]]\n",
      "Train Epoch48 out_loss 0.0014569725608453155\n",
      "Test Epoch48 layer0 out_loss 0.009065073914825916\n",
      "Test Epoch48 layer1 out_loss 0.0010867550736293197\n",
      "Test Epoch48 layer2 out_loss 0.0005438090302050114\n",
      "Test Epoch48 layer3 out_loss 0.00045862988918088377\n",
      "Test Epoch48 layer4 out_loss 0.0005211798124946654\n",
      "Train 49 | out_loss 0.0012067655334249139: 100%|█| 138/138 [00:00<00:00, 211.21i\n",
      "[[0.00023765 0.09008304]\n",
      " [0.00047967 0.00194236]\n",
      " [0.00053048 0.00151765]\n",
      " [0.00048839 0.00095671]\n",
      " [0.00041675 0.00058776]]\n",
      "Train Epoch49 out_loss 0.0012067655334249139\n",
      "Test Epoch49 layer0 out_loss 0.014307428151369095\n",
      "Test Epoch49 layer1 out_loss 0.0009993810672312975\n",
      "Test Epoch49 layer2 out_loss 0.0007083837408572435\n",
      "Test Epoch49 layer3 out_loss 0.000757266883738339\n",
      "Test Epoch49 layer4 out_loss 0.000430632964707911\n",
      "Train 50 | out_loss 0.0012054045218974352: 100%|█| 138/138 [00:00<00:00, 220.09i\n",
      "[[0.0002498  0.16442632]\n",
      " [0.00066358 0.00269803]\n",
      " [0.00080714 0.00193386]\n",
      " [0.00058651 0.00100928]\n",
      " [0.00043882 0.00056563]]\n",
      "Train Epoch50 out_loss 0.0012054045218974352\n",
      "Test Epoch50 layer0 out_loss 0.006150680128484964\n",
      "Test Epoch50 layer1 out_loss 0.0011136274551972747\n",
      "Test Epoch50 layer2 out_loss 0.0005240695900283754\n",
      "Test Epoch50 layer3 out_loss 0.0008904554415494204\n",
      "Test Epoch50 layer4 out_loss 0.001189565984532237\n",
      "Train 51 | out_loss 0.001389473443850875: 100%|█| 138/138 [00:00<00:00, 213.21it\n",
      "[[0.00034057 0.02192932]\n",
      " [0.00047544 0.00148769]\n",
      " [0.00053484 0.00165807]\n",
      " [0.00056657 0.00127792]\n",
      " [0.00071158 0.00081862]]\n",
      "Train Epoch51 out_loss 0.001389473443850875\n",
      "Test Epoch51 layer0 out_loss 0.006526764016598463\n",
      "Test Epoch51 layer1 out_loss 0.000734629575163126\n",
      "Test Epoch51 layer2 out_loss 0.0006338884704746306\n",
      "Test Epoch51 layer3 out_loss 0.0006002066074870527\n",
      "Test Epoch51 layer4 out_loss 0.0009381247800774872\n",
      "Train 52 | out_loss 0.0015437795082107186: 100%|█| 138/138 [00:00<00:00, 214.27i\n",
      "[[0.00046732 0.00978216]\n",
      " [0.00050934 0.0015286 ]\n",
      " [0.00060109 0.00126464]\n",
      " [0.00046408 0.00072539]\n",
      " [0.00039913 0.00049191]]\n",
      "Train Epoch52 out_loss 0.0015437795082107186\n",
      "Test Epoch52 layer0 out_loss 0.004453879315406084\n",
      "Test Epoch52 layer1 out_loss 0.0018095592968165874\n",
      "Test Epoch52 layer2 out_loss 0.0018299082294106483\n",
      "Test Epoch52 layer3 out_loss 0.0014557004906237125\n",
      "Test Epoch52 layer4 out_loss 0.0015889835776761174\n",
      "Train 53 | out_loss 0.0013651426415890455: 100%|█| 138/138 [00:00<00:00, 209.96i\n",
      "[[0.00035302 0.04585496]\n",
      " [0.00056028 0.0020344 ]\n",
      " [0.00061276 0.00168775]\n",
      " [0.00054778 0.00095514]\n",
      " [0.00065291 0.00084637]]\n",
      "Train Epoch53 out_loss 0.0013651426415890455\n",
      "Test Epoch53 layer0 out_loss 0.009088709019124508\n",
      "Test Epoch53 layer1 out_loss 0.0010710700880736113\n",
      "Test Epoch53 layer2 out_loss 0.0005446533905342221\n",
      "Test Epoch53 layer3 out_loss 0.0004780385352205485\n",
      "Test Epoch53 layer4 out_loss 0.0004342357278801501\n",
      "Train 54 | out_loss 0.0016133610624819994: 100%|█| 138/138 [00:00<00:00, 218.23i\n",
      "[[0.00052709 0.05977102]\n",
      " [0.00044712 0.00203269]\n",
      " [0.0005613  0.00138967]\n",
      " [0.00034993 0.00066087]\n",
      " [0.00033212 0.00046959]]\n",
      "Train Epoch54 out_loss 0.0016133610624819994\n",
      "Test Epoch54 layer0 out_loss 0.0074153379537165165\n",
      "Test Epoch54 layer1 out_loss 0.0008668671362102032\n",
      "Test Epoch54 layer2 out_loss 0.0005825582193210721\n",
      "Test Epoch54 layer3 out_loss 0.00045370723819360137\n",
      "Test Epoch54 layer4 out_loss 0.0004894603043794632\n",
      "Train 55 | out_loss 0.0005099595291540027: 100%|█| 138/138 [00:00<00:00, 215.61i\n",
      "[[7.15092268e-06 1.64021125e-01]\n",
      " [5.10087639e-04 2.81649196e-03]\n",
      " [6.48867567e-04 1.68111126e-03]\n",
      " [4.13148027e-04 1.01459258e-03]\n",
      " [4.19901313e-04 6.22332333e-04]]\n",
      "Train Epoch55 out_loss 0.0005099595291540027\n",
      "Test Epoch55 layer0 out_loss 0.016450893133878708\n",
      "Test Epoch55 layer1 out_loss 0.00150633929297328\n",
      "Test Epoch55 layer2 out_loss 0.0012032241793349385\n",
      "Test Epoch55 layer3 out_loss 0.0009255232289433479\n",
      "Test Epoch55 layer4 out_loss 0.0009169447002932429\n",
      "Train 56 | out_loss 0.0013861401239410043: 100%|█| 138/138 [00:00<00:00, 208.86i\n",
      "[[0.00036905 0.14726592]\n",
      " [0.0005308  0.00310292]\n",
      " [0.00059469 0.00185054]\n",
      " [0.00043308 0.00086211]\n",
      " [0.00034169 0.00044433]]\n",
      "Train Epoch56 out_loss 0.0013861401239410043\n",
      "Test Epoch56 layer0 out_loss 0.032526616007089615\n",
      "Test Epoch56 layer1 out_loss 0.0036172668915241957\n",
      "Test Epoch56 layer2 out_loss 0.0037650703452527523\n",
      "Test Epoch56 layer3 out_loss 0.003946084529161453\n",
      "Test Epoch56 layer4 out_loss 0.004149661865085363\n",
      "Train 57 | out_loss 0.0013041187776252627: 100%|█| 138/138 [00:00<00:00, 216.66i\n",
      "[[0.00033651 0.03378663]\n",
      " [0.000454   0.00167064]\n",
      " [0.00053244 0.00107854]\n",
      " [0.00031386 0.00052894]\n",
      " [0.0002124  0.00029946]]\n",
      "Train Epoch57 out_loss 0.0013041187776252627\n",
      "Test Epoch57 layer0 out_loss 0.010923542082309723\n",
      "Test Epoch57 layer1 out_loss 0.003181049833074212\n",
      "Test Epoch57 layer2 out_loss 0.0034684487618505955\n",
      "Test Epoch57 layer3 out_loss 0.0031800330616533756\n",
      "Test Epoch57 layer4 out_loss 0.003164023859426379\n",
      "Train 58 | out_loss 0.0015960910823196173: 100%|█| 138/138 [00:00<00:00, 216.74i\n",
      "[[0.00055319 0.03763906]\n",
      " [0.00054118 0.00197767]\n",
      " [0.00062994 0.00143209]\n",
      " [0.00046876 0.00086827]\n",
      " [0.00039911 0.00047681]]\n",
      "Train Epoch58 out_loss 0.0015960910823196173\n",
      "Test Epoch58 layer0 out_loss 0.004746938589960337\n",
      "Test Epoch58 layer1 out_loss 0.0030257843900471926\n",
      "Test Epoch58 layer2 out_loss 0.0007071380969136953\n",
      "Test Epoch58 layer3 out_loss 0.0010308008641004562\n",
      "Test Epoch58 layer4 out_loss 0.0009897989220917225\n",
      "Train 59 | out_loss 0.0012065254850313067: 100%|█| 138/138 [00:00<00:00, 216.06i\n",
      "[[0.00028763 0.03074429]\n",
      " [0.00048898 0.00172437]\n",
      " [0.00059668 0.00145497]\n",
      " [0.00053616 0.00091909]\n",
      " [0.00042118 0.00052143]]\n",
      "Train Epoch59 out_loss 0.0012065254850313067\n",
      "Test Epoch59 layer0 out_loss 0.0038154625799506903\n",
      "Test Epoch59 layer1 out_loss 0.0031942245550453663\n",
      "Test Epoch59 layer2 out_loss 0.0020631393417716026\n",
      "Test Epoch59 layer3 out_loss 0.0019270542543381453\n",
      "Test Epoch59 layer4 out_loss 0.0021438931580632925\n",
      "Train 60 | out_loss 0.001407716190442443: 100%|█| 138/138 [00:00<00:00, 207.55it\n",
      "[[0.00042776 0.01298269]\n",
      " [0.00044821 0.00168862]\n",
      " [0.00055382 0.00145647]\n",
      " [0.00041949 0.00075852]\n",
      " [0.00029817 0.00036088]]\n",
      "Train Epoch60 out_loss 0.001407716190442443\n",
      "Test Epoch60 layer0 out_loss 0.003927896730601788\n",
      "Test Epoch60 layer1 out_loss 0.0016429985407739878\n",
      "Test Epoch60 layer2 out_loss 0.0014916679356247187\n",
      "Test Epoch60 layer3 out_loss 0.0017233012476935983\n",
      "Test Epoch60 layer4 out_loss 0.001671785139478743\n",
      "Train 61 | out_loss 0.0006316019571386278: 100%|█| 138/138 [00:00<00:00, 216.76i\n",
      "[[5.80852044e-05 3.80789540e-02]\n",
      " [4.55424404e-04 1.85749651e-03]\n",
      " [5.53153963e-04 1.47160476e-03]\n",
      " [5.30121143e-04 8.70127736e-04]\n",
      " [2.89723078e-04 3.96672970e-04]]\n",
      "Train Epoch61 out_loss 0.0006316019571386278\n",
      "Test Epoch61 layer0 out_loss 0.008800090290606022\n",
      "Test Epoch61 layer1 out_loss 0.0007851402624510229\n",
      "Test Epoch61 layer2 out_loss 0.0005921583506278694\n",
      "Test Epoch61 layer3 out_loss 0.0005745302187278867\n",
      "Test Epoch61 layer4 out_loss 0.0005011718021705747\n",
      "Train 62 | out_loss 0.0013065707171335816: 100%|█| 138/138 [00:00<00:00, 220.55i\n",
      "[[0.00039726 0.01684865]\n",
      " [0.0004548  0.00200547]\n",
      " [0.00058428 0.00153431]\n",
      " [0.00043656 0.00065959]\n",
      " [0.00027335 0.00030922]]\n",
      "Train Epoch62 out_loss 0.0013065707171335816\n",
      "Test Epoch62 layer0 out_loss 0.005936090834438801\n",
      "Test Epoch62 layer1 out_loss 0.0006943938788026571\n",
      "Test Epoch62 layer2 out_loss 0.001304489211179316\n",
      "Test Epoch62 layer3 out_loss 0.0004933699383400381\n",
      "Test Epoch62 layer4 out_loss 0.00044018414337188005\n",
      "Train 63 | out_loss 0.001325820223428309: 100%|█| 138/138 [00:00<00:00, 211.55it\n",
      "[[0.00033993 0.20416463]\n",
      " [0.00058208 0.00373141]\n",
      " [0.00072469 0.00242966]\n",
      " [0.00073132 0.00140135]\n",
      " [0.00050767 0.00071282]]\n",
      "Train Epoch63 out_loss 0.001325820223428309\n",
      "Test Epoch63 layer0 out_loss 0.007971711456775665\n",
      "Test Epoch63 layer1 out_loss 0.0010874936124309897\n",
      "Test Epoch63 layer2 out_loss 0.0015292788157239556\n",
      "Test Epoch63 layer3 out_loss 0.0006656140903942287\n",
      "Test Epoch63 layer4 out_loss 0.0005464484565891325\n",
      "Train 64 | out_loss 0.001214831368997693: 100%|█| 138/138 [00:00<00:00, 216.13it\n",
      "[[0.00030795 0.16289053]\n",
      " [0.00044271 0.00311553]\n",
      " [0.00062596 0.00169787]\n",
      " [0.00053829 0.00105348]\n",
      " [0.00046964 0.00063719]]\n",
      "Train Epoch64 out_loss 0.001214831368997693\n",
      "Test Epoch64 layer0 out_loss 0.006521391216665506\n",
      "Test Epoch64 layer1 out_loss 0.0006697840290144086\n",
      "Test Epoch64 layer2 out_loss 0.00043379602720960975\n",
      "Test Epoch64 layer3 out_loss 0.0004749918880406767\n",
      "Test Epoch64 layer4 out_loss 0.00042864118586294353\n",
      "Train 65 | out_loss 0.001528963795863092: 100%|█| 138/138 [00:00<00:00, 217.61it\n",
      "[[0.00051261 0.00613364]\n",
      " [0.00038483 0.00127971]\n",
      " [0.00045878 0.00107833]\n",
      " [0.00047486 0.00065462]\n",
      " [0.00036972 0.00041795]]\n",
      "Train Epoch65 out_loss 0.001528963795863092\n",
      "Test Epoch65 layer0 out_loss 0.003174570854753256\n",
      "Test Epoch65 layer1 out_loss 0.0005884796846657991\n",
      "Test Epoch65 layer2 out_loss 0.0006260814261622727\n",
      "Test Epoch65 layer3 out_loss 0.00048285943921655416\n",
      "Test Epoch65 layer4 out_loss 0.0004944929387420416\n",
      "Train 66 | out_loss 0.0014900421956554055: 100%|█| 138/138 [00:00<00:00, 208.83i\n",
      "[[0.00046663 0.0048271 ]\n",
      " [0.00047668 0.00152716]\n",
      " [0.00054501 0.00100554]\n",
      " [0.00034671 0.00053358]\n",
      " [0.00020023 0.0002542 ]]\n",
      "Train Epoch66 out_loss 0.0014900421956554055\n",
      "Test Epoch66 layer0 out_loss 0.0032541907858103514\n",
      "Test Epoch66 layer1 out_loss 0.0018695954931899905\n",
      "Test Epoch66 layer2 out_loss 0.0004917841288261116\n",
      "Test Epoch66 layer3 out_loss 0.0005767568363808095\n",
      "Test Epoch66 layer4 out_loss 0.0004383693158160895\n",
      "Train 67 | out_loss 0.0005156817496754229: 100%|█| 138/138 [00:00<00:00, 215.76i\n",
      "[[1.87910901e-05 5.38676096e-03]\n",
      " [3.78192211e-04 1.31040198e-03]\n",
      " [4.57243958e-04 9.54381709e-04]\n",
      " [3.22922450e-04 5.44967589e-04]\n",
      " [2.18226483e-04 2.79102928e-04]]\n",
      "Train Epoch67 out_loss 0.0005156817496754229\n",
      "Test Epoch67 layer0 out_loss 0.0031888028606772423\n",
      "Test Epoch67 layer1 out_loss 0.0005693183047696948\n",
      "Test Epoch67 layer2 out_loss 0.0004421811318024993\n",
      "Test Epoch67 layer3 out_loss 0.0004893153673037887\n",
      "Test Epoch67 layer4 out_loss 0.0004324390320107341\n",
      "Train 68 | out_loss 0.0012219514464959502: 100%|█| 138/138 [00:00<00:00, 217.25i\n",
      "[[0.00032618 0.05465033]\n",
      " [0.00046129 0.00311628]\n",
      " [0.00056056 0.00174891]\n",
      " [0.00052463 0.00085056]\n",
      " [0.00025235 0.00045271]]\n",
      "Train Epoch68 out_loss 0.0012219514464959502\n",
      "Test Epoch68 layer0 out_loss 0.011913944967091084\n",
      "Test Epoch68 layer1 out_loss 0.0013577271020039916\n",
      "Test Epoch68 layer2 out_loss 0.00048186894855462015\n",
      "Test Epoch68 layer3 out_loss 0.00046617581392638385\n",
      "Test Epoch68 layer4 out_loss 0.0004410471592564136\n",
      "Train 69 | out_loss 0.00127751927357167: 100%|█| 138/138 [00:00<00:00, 210.41it/\n",
      "[[0.00032339 0.02646854]\n",
      " [0.0004643  0.00213534]\n",
      " [0.00052239 0.00137542]\n",
      " [0.00042803 0.00082628]\n",
      " [0.00036033 0.00041214]]\n",
      "Train Epoch69 out_loss 0.00127751927357167\n",
      "Test Epoch69 layer0 out_loss 0.007384678814560175\n",
      "Test Epoch69 layer1 out_loss 0.0009509334340691566\n",
      "Test Epoch69 layer2 out_loss 0.0012128769885748625\n",
      "Test Epoch69 layer3 out_loss 0.0004976605996489525\n",
      "Test Epoch69 layer4 out_loss 0.00043213978642597795\n",
      "Train 70 | out_loss 0.0013400001917034388: 100%|█| 138/138 [00:00<00:00, 202.94i\n",
      "[[0.00039224 0.04883056]\n",
      " [0.00045989 0.00284534]\n",
      " [0.00067259 0.00197372]\n",
      " [0.00051411 0.00079569]\n",
      " [0.00030965 0.00041115]]\n",
      "Train Epoch70 out_loss 0.0013400001917034388\n",
      "Test Epoch70 layer0 out_loss 0.003211093135178089\n",
      "Test Epoch70 layer1 out_loss 0.0006844549207016826\n",
      "Test Epoch70 layer2 out_loss 0.001218734192661941\n",
      "Test Epoch70 layer3 out_loss 0.0004339840088505298\n",
      "Test Epoch70 layer4 out_loss 0.0004324990150053054\n",
      "Train 71 | out_loss 0.001134257297962904: 100%|█| 138/138 [00:00<00:00, 216.54it\n",
      "[[0.00025709 0.02863085]\n",
      " [0.00043033 0.00211884]\n",
      " [0.00050613 0.0012464 ]\n",
      " [0.00030204 0.00051693]\n",
      " [0.00022173 0.00030024]]\n",
      "Train Epoch71 out_loss 0.001134257297962904\n",
      "Test Epoch71 layer0 out_loss 0.005392587743699551\n",
      "Test Epoch71 layer1 out_loss 0.0017497733933851123\n",
      "Test Epoch71 layer2 out_loss 0.0004465926322154701\n",
      "Test Epoch71 layer3 out_loss 0.0004681322898250073\n",
      "Test Epoch71 layer4 out_loss 0.0004611761833075434\n",
      "Train 72 | out_loss 0.0013889442197978497: 100%|█| 138/138 [00:00<00:00, 216.17i\n",
      "[[0.00040833 0.01477672]\n",
      " [0.00040053 0.00180172]\n",
      " [0.00065558 0.00184957]\n",
      " [0.00044421 0.0006265 ]\n",
      " [0.00026775 0.00036694]]\n",
      "Train Epoch72 out_loss 0.0013889442197978497\n",
      "Test Epoch72 layer0 out_loss 0.002561025321483612\n",
      "Test Epoch72 layer1 out_loss 0.000571357028093189\n",
      "Test Epoch72 layer2 out_loss 0.000538841646630317\n",
      "Test Epoch72 layer3 out_loss 0.0006053577526472509\n",
      "Test Epoch72 layer4 out_loss 0.0006066035130061209\n",
      "Train 73 | out_loss 0.0013806821079924703: 100%|█| 138/138 [00:00<00:00, 219.12i\n",
      "[[0.00039581 0.02219047]\n",
      " [0.0004251  0.00191928]\n",
      " [0.00060849 0.00119708]\n",
      " [0.00033255 0.00050526]\n",
      " [0.00022284 0.00028025]]\n",
      "Train Epoch73 out_loss 0.0013806821079924703\n",
      "Test Epoch73 layer0 out_loss 0.004382604267448187\n",
      "Test Epoch73 layer1 out_loss 0.0012769217137247324\n",
      "Test Epoch73 layer2 out_loss 0.0009584613726474345\n",
      "Test Epoch73 layer3 out_loss 0.0004357628640718758\n",
      "Test Epoch73 layer4 out_loss 0.00048469085595570505\n",
      "Train 74 | out_loss 0.0013476632302626967: 100%|█| 138/138 [00:00<00:00, 213.96i\n",
      "[[0.00038656 0.00529375]\n",
      " [0.00042054 0.00168856]\n",
      " [0.00042552 0.00083369]\n",
      " [0.00027524 0.00047706]\n",
      " [0.00023451 0.00023926]]\n",
      "Train Epoch74 out_loss 0.0013476632302626967\n",
      "Test Epoch74 layer0 out_loss 0.007328086532652378\n",
      "Test Epoch74 layer1 out_loss 0.0009663979290053248\n",
      "Test Epoch74 layer2 out_loss 0.0004930690047331154\n",
      "Test Epoch74 layer3 out_loss 0.0008557356777600944\n",
      "Test Epoch74 layer4 out_loss 0.0005731118726544082\n",
      "Train 75 | out_loss 0.0013815390411764383: 100%|█| 138/138 [00:00<00:00, 215.89i\n",
      "[[0.00043031 0.02584812]\n",
      " [0.00036119 0.00226892]\n",
      " [0.00040174 0.00100037]\n",
      " [0.00027369 0.00058219]\n",
      " [0.00027944 0.00038846]]\n",
      "Train Epoch75 out_loss 0.0013815390411764383\n",
      "Test Epoch75 layer0 out_loss 0.005355009809136391\n",
      "Test Epoch75 layer1 out_loss 0.0007705726311542094\n",
      "Test Epoch75 layer2 out_loss 0.000428483122959733\n",
      "Test Epoch75 layer3 out_loss 0.000594136246945709\n",
      "Test Epoch75 layer4 out_loss 0.000485023861983791\n",
      "Train 76 | out_loss 0.001225608168169856: 100%|█| 138/138 [00:00<00:00, 209.77it\n",
      "[[0.00031455 0.04423326]\n",
      " [0.00040459 0.00237802]\n",
      " [0.00041724 0.00107063]\n",
      " [0.00028182 0.00051668]\n",
      " [0.00023255 0.00029196]]\n",
      "Train Epoch76 out_loss 0.001225608168169856\n",
      "Test Epoch76 layer0 out_loss 0.009296278469264507\n",
      "Test Epoch76 layer1 out_loss 0.0037074857391417027\n",
      "Test Epoch76 layer2 out_loss 0.0026854209136217833\n",
      "Test Epoch76 layer3 out_loss 0.0021275896579027176\n",
      "Test Epoch76 layer4 out_loss 0.001975516090169549\n",
      "Train 77 | out_loss 0.0007891342975199223: 100%|█| 138/138 [00:00<00:00, 204.87i\n",
      "[[0.0001177  0.01391153]\n",
      " [0.00034366 0.001914  ]\n",
      " [0.00047276 0.00136893]\n",
      " [0.00035024 0.00063987]\n",
      " [0.0005373  0.00051861]]\n",
      "Train Epoch77 out_loss 0.0007891342975199223\n",
      "Test Epoch77 layer0 out_loss 0.005155693739652634\n",
      "Test Epoch77 layer1 out_loss 0.0006589960539713502\n",
      "Test Epoch77 layer2 out_loss 0.0005318148760125041\n",
      "Test Epoch77 layer3 out_loss 0.00044497085036709905\n",
      "Test Epoch77 layer4 out_loss 0.00045151999802328646\n",
      "Train 78 | out_loss 0.001503409817814827: 100%|█| 138/138 [00:00<00:00, 211.46it\n",
      "[[0.00052816 0.01510998]\n",
      " [0.00033428 0.00185438]\n",
      " [0.00044688 0.00150646]\n",
      " [0.00037089 0.00054964]\n",
      " [0.00035466 0.00039472]]\n",
      "Train Epoch78 out_loss 0.001503409817814827\n",
      "Test Epoch78 layer0 out_loss 0.024904757738113403\n",
      "Test Epoch78 layer1 out_loss 0.00177057518158108\n",
      "Test Epoch78 layer2 out_loss 0.0008000044035725296\n",
      "Test Epoch78 layer3 out_loss 0.0004522355447988957\n",
      "Test Epoch78 layer4 out_loss 0.0005659297457896173\n",
      "Train 79 | out_loss 0.0014566488098353148: 100%|█| 138/138 [00:00<00:00, 216.01i\n",
      "[[0.00045663 0.06920686]\n",
      " [0.00040324 0.00304868]\n",
      " [0.00056074 0.0015529 ]\n",
      " [0.00038251 0.00066049]\n",
      " [0.00026246 0.00031483]]\n",
      "Train Epoch79 out_loss 0.0014566488098353148\n",
      "Test Epoch79 layer0 out_loss 0.017998874187469482\n",
      "Test Epoch79 layer1 out_loss 0.0012932580430060625\n",
      "Test Epoch79 layer2 out_loss 0.0011335943127050996\n",
      "Test Epoch79 layer3 out_loss 0.0012124167988076806\n",
      "Test Epoch79 layer4 out_loss 0.001230349880643189\n",
      "Train 80 | out_loss 0.0005019395030103624: 100%|█| 138/138 [00:00<00:00, 211.54i\n",
      "[[1.51997797e-05 3.42188081e-02]\n",
      " [4.58639902e-04 2.33120412e-03]\n",
      " [5.67113457e-04 1.11615705e-03]\n",
      " [3.20104327e-04 4.57461124e-04]\n",
      " [2.24140505e-04 2.87138832e-04]]\n",
      "Train Epoch80 out_loss 0.0005019395030103624\n",
      "Test Epoch80 layer0 out_loss 0.0037898519076406956\n",
      "Test Epoch80 layer1 out_loss 0.0006861255969852209\n",
      "Test Epoch80 layer2 out_loss 0.0006434741662815213\n",
      "Test Epoch80 layer3 out_loss 0.0007884028600528836\n",
      "Test Epoch80 layer4 out_loss 0.0005905544385313988\n",
      "Train 81 | out_loss 0.001393776386976242: 100%|█| 138/138 [00:00<00:00, 206.26it\n",
      "[[0.00041475 0.01333359]\n",
      " [0.00024767 0.00167978]\n",
      " [0.00045509 0.00124736]\n",
      " [0.00030759 0.00063963]\n",
      " [0.00037714 0.00042358]]\n",
      "Train Epoch81 out_loss 0.001393776386976242\n",
      "Test Epoch81 layer0 out_loss 0.004167583305388689\n",
      "Test Epoch81 layer1 out_loss 0.0006373067735694349\n",
      "Test Epoch81 layer2 out_loss 0.0004669009358622134\n",
      "Test Epoch81 layer3 out_loss 0.0004330226220190525\n",
      "Test Epoch81 layer4 out_loss 0.00043531606206670403\n",
      "Train 82 | out_loss 0.001414286787621677: 100%|█| 138/138 [00:00<00:00, 211.23it\n",
      "[[0.00042467 0.01379448]\n",
      " [0.00035261 0.00198515]\n",
      " [0.00037992 0.00091197]\n",
      " [0.00028046 0.00046024]\n",
      " [0.00027099 0.0002976 ]]\n",
      "Train Epoch82 out_loss 0.001414286787621677\n",
      "Test Epoch82 layer0 out_loss 0.00427457457408309\n",
      "Test Epoch82 layer1 out_loss 0.001325259916484356\n",
      "Test Epoch82 layer2 out_loss 0.0005694545689038932\n",
      "Test Epoch82 layer3 out_loss 0.0006579839391633868\n",
      "Test Epoch82 layer4 out_loss 0.0005335944588296115\n",
      "Train 83 | out_loss 0.001437170198187232: 100%|█| 138/138 [00:00<00:00, 216.96it\n",
      "[[0.00046483 0.04868227]\n",
      " [0.0003985  0.00322763]\n",
      " [0.00056821 0.00163613]\n",
      " [0.00038413 0.00065796]\n",
      " [0.00025717 0.00030261]]\n",
      "Train Epoch83 out_loss 0.001437170198187232\n",
      "Test Epoch83 layer0 out_loss 0.005338565446436405\n",
      "Test Epoch83 layer1 out_loss 0.0010007170494645834\n",
      "Test Epoch83 layer2 out_loss 0.000948677770793438\n",
      "Test Epoch83 layer3 out_loss 0.0007801774190738797\n",
      "Test Epoch83 layer4 out_loss 0.0006729107117280364\n",
      "Train 84 | out_loss 0.0004772277898155153: 100%|█| 138/138 [00:00<00:00, 211.72i\n",
      "[[5.89505684e-06 3.08589611e-02]\n",
      " [3.40900426e-04 2.24565130e-03]\n",
      " [3.76004439e-04 9.30806339e-04]\n",
      " [2.26480231e-04 3.81441735e-04]\n",
      " [1.32258393e-04 1.80637182e-04]]\n",
      "Train Epoch84 out_loss 0.0004772277898155153\n",
      "Test Epoch84 layer0 out_loss 0.0020871381275355816\n",
      "Test Epoch84 layer1 out_loss 0.0005793410819023848\n",
      "Test Epoch84 layer2 out_loss 0.0010216364171355963\n",
      "Test Epoch84 layer3 out_loss 0.0010105387773364782\n",
      "Test Epoch84 layer4 out_loss 0.0008160878205671906\n",
      "Train 85 | out_loss 0.0014064544811844826: 100%|█| 138/138 [00:00<00:00, 205.56i\n",
      "[[0.00044577 0.00399963]\n",
      " [0.00035483 0.00139033]\n",
      " [0.00046425 0.00084375]\n",
      " [0.00028761 0.00036028]\n",
      " [0.00022478 0.00024253]]\n",
      "Train Epoch85 out_loss 0.0014064544811844826\n",
      "Test Epoch85 layer0 out_loss 0.004876674618571997\n",
      "Test Epoch85 layer1 out_loss 0.0006946493522264063\n",
      "Test Epoch85 layer2 out_loss 0.00045314672752283514\n",
      "Test Epoch85 layer3 out_loss 0.0004557786451186985\n",
      "Test Epoch85 layer4 out_loss 0.0004829679674003273\n",
      "Train 86 | out_loss 0.0014209282817319036: 100%|█| 138/138 [00:00<00:00, 209.92i\n",
      "[[0.00039655 0.00659127]\n",
      " [0.00039578 0.00179748]\n",
      " [0.00055337 0.00100535]\n",
      " [0.0003278  0.00041844]\n",
      " [0.00020595 0.00028975]]\n",
      "Train Epoch86 out_loss 0.0014209282817319036\n",
      "Test Epoch86 layer0 out_loss 0.0039022425189614296\n",
      "Test Epoch86 layer1 out_loss 0.001505105523392558\n",
      "Test Epoch86 layer2 out_loss 0.0007817407022230327\n",
      "Test Epoch86 layer3 out_loss 0.00047055320465005934\n",
      "Test Epoch86 layer4 out_loss 0.0004343569453340024\n",
      "Train 87 | out_loss 0.0013045889791101217: 100%|█| 138/138 [00:00<00:00, 214.76i\n",
      "[[0.00036633 0.02726096]\n",
      " [0.00028309 0.00280394]\n",
      " [0.00035914 0.00097867]\n",
      " [0.00020903 0.00044425]\n",
      " [0.00023456 0.0003262 ]]\n",
      "Train Epoch87 out_loss 0.0013045889791101217\n",
      "Test Epoch87 layer0 out_loss 0.00208682450465858\n",
      "Test Epoch87 layer1 out_loss 0.0005103735020384192\n",
      "Test Epoch87 layer2 out_loss 0.00045604383922182024\n",
      "Test Epoch87 layer3 out_loss 0.000456394103821367\n",
      "Test Epoch87 layer4 out_loss 0.0004344443732406944\n",
      "Train 88 | out_loss 0.0014846691628918052: 100%|█| 138/138 [00:00<00:00, 209.55i\n",
      "[[0.00047669 0.00542439]\n",
      " [0.00042887 0.00176308]\n",
      " [0.0005458  0.0011228 ]\n",
      " [0.00035496 0.00045341]\n",
      " [0.00031023 0.00034958]]\n",
      "Train Epoch88 out_loss 0.0014846691628918052\n",
      "Test Epoch88 layer0 out_loss 0.0037523123901337385\n",
      "Test Epoch88 layer1 out_loss 0.0012872667284682393\n",
      "Test Epoch88 layer2 out_loss 0.0009699185029603541\n",
      "Test Epoch88 layer3 out_loss 0.0010476158931851387\n",
      "Test Epoch88 layer4 out_loss 0.001012858934700489\n",
      "Train 89 | out_loss 0.0008747417014092207: 100%|█| 138/138 [00:00<00:00, 210.29i\n",
      "[[6.15347790e-06 1.02102785e-02]\n",
      " [5.17149904e-04 3.70519131e-03]\n",
      " [1.35479846e-03 8.10613453e-03]\n",
      " [2.67368089e-03 7.94654929e-03]\n",
      " [5.39360383e-03 1.41194312e-02]]\n",
      "Train Epoch89 out_loss 0.0008747417014092207\n",
      "Test Epoch89 layer0 out_loss 0.016351303085684776\n",
      "Test Epoch89 layer1 out_loss 0.0012769635068252683\n",
      "Test Epoch89 layer2 out_loss 0.0005927194142714143\n",
      "Test Epoch89 layer3 out_loss 0.000472658866783604\n",
      "Test Epoch89 layer4 out_loss 0.0017362661892548203\n",
      "Train 90 | out_loss 0.0014783393125981092: 100%|█| 138/138 [00:00<00:00, 212.76i\n",
      "[[0.00041645 0.02911665]\n",
      " [0.0003238  0.0036026 ]\n",
      " [0.00048205 0.00089112]\n",
      " [0.00029221 0.00048453]\n",
      " [0.00014108 0.00036045]]\n",
      "Train Epoch90 out_loss 0.0014783393125981092\n",
      "Test Epoch90 layer0 out_loss 0.0018504279432818294\n",
      "Test Epoch90 layer1 out_loss 0.0006386054446920753\n",
      "Test Epoch90 layer2 out_loss 0.0006023423047736287\n",
      "Test Epoch90 layer3 out_loss 0.0011280786711722612\n",
      "Test Epoch90 layer4 out_loss 0.0004980993107892573\n",
      "Train 91 | out_loss 0.0015775392530485988: 100%|█| 138/138 [00:00<00:00, 210.50i\n",
      "[[5.03631091e-04 2.44710956e-02]\n",
      " [1.62938958e-04 2.26079807e-03]\n",
      " [2.09664611e-04 5.62279449e-04]\n",
      " [1.93970258e-04 2.75069986e-04]\n",
      " [6.12788183e-05 1.06050019e-04]]\n",
      "Train Epoch91 out_loss 0.0015775392530485988\n",
      "Test Epoch91 layer0 out_loss 0.003632857697084546\n",
      "Test Epoch91 layer1 out_loss 0.0009278543875552714\n",
      "Test Epoch91 layer2 out_loss 0.000545022077858448\n",
      "Test Epoch91 layer3 out_loss 0.0005249936948530376\n",
      "Test Epoch91 layer4 out_loss 0.0005933924694545567\n",
      "Train 92 | out_loss 0.0013250529300421476: 100%|█| 138/138 [00:00<00:00, 207.02i\n",
      "[[3.80947189e-04 9.51720409e-03]\n",
      " [3.05129950e-04 1.37051053e-03]\n",
      " [3.23659663e-04 4.06579925e-04]\n",
      " [1.40602465e-04 1.43468858e-04]\n",
      " [7.46458526e-05 7.99961345e-05]]\n",
      "Train Epoch92 out_loss 0.0013250529300421476\n",
      "Test Epoch92 layer0 out_loss 0.00444021774455905\n",
      "Test Epoch92 layer1 out_loss 0.0005264118080958724\n",
      "Test Epoch92 layer2 out_loss 0.0005308836116455495\n",
      "Test Epoch92 layer3 out_loss 0.00072569987969473\n",
      "Test Epoch92 layer4 out_loss 0.0008255571592599154\n",
      "Train 93 | out_loss 0.0006565633229911327: 100%|█| 138/138 [00:00<00:00, 214.65i\n",
      "[[5.84817485e-05 2.00113448e-02]\n",
      " [2.98498013e-04 1.91901797e-03]\n",
      " [2.59544979e-04 5.39059969e-04]\n",
      " [1.17499932e-04 2.00823063e-04]\n",
      " [1.26015922e-04 1.26812700e-04]]\n",
      "Train Epoch93 out_loss 0.0006565633229911327\n",
      "Test Epoch93 layer0 out_loss 0.0031250659376382828\n",
      "Test Epoch93 layer1 out_loss 0.0008062275592237711\n",
      "Test Epoch93 layer2 out_loss 0.0004515446489676833\n",
      "Test Epoch93 layer3 out_loss 0.0004426803207024932\n",
      "Test Epoch93 layer4 out_loss 0.0004879049665760249\n",
      "Train 94 | out_loss 0.00169654400087893: 100%|█| 138/138 [00:00<00:00, 215.92it/\n",
      "[[6.47731469e-04 5.35110450e-03]\n",
      " [2.63665788e-04 1.26134226e-03]\n",
      " [3.67056381e-04 5.13893118e-04]\n",
      " [1.45770838e-04 2.16237291e-04]\n",
      " [1.01126378e-04 9.80281894e-05]]\n",
      "Train Epoch94 out_loss 0.00169654400087893\n",
      "Test Epoch94 layer0 out_loss 0.0022293259389698505\n",
      "Test Epoch94 layer1 out_loss 0.0004818382440134883\n",
      "Test Epoch94 layer2 out_loss 0.0004516766930464655\n",
      "Test Epoch94 layer3 out_loss 0.0005935620865784585\n",
      "Test Epoch94 layer4 out_loss 0.0005845303530804813\n",
      "Train 95 | out_loss 0.0004626762820407748: 100%|█| 138/138 [00:00<00:00, 214.79i\n",
      "[[1.41289377e-06 8.81499460e-03]\n",
      " [2.83386272e-04 1.30997472e-03]\n",
      " [3.15635107e-04 4.66681558e-04]\n",
      " [1.31162283e-04 2.00724974e-04]\n",
      " [1.02912144e-04 1.05190026e-04]]\n",
      "Train Epoch95 out_loss 0.0004626762820407748\n",
      "Test Epoch95 layer0 out_loss 0.0023505978751927614\n",
      "Test Epoch95 layer1 out_loss 0.0014598304405808449\n",
      "Test Epoch95 layer2 out_loss 0.0011181223671883345\n",
      "Test Epoch95 layer3 out_loss 0.0011017045471817255\n",
      "Test Epoch95 layer4 out_loss 0.0010516442125663161\n",
      "Train 96 | out_loss 0.0014215245610103011: 100%|█| 138/138 [00:00<00:00, 201.34i\n",
      "[[3.88628892e-04 1.03647810e-02]\n",
      " [2.81916436e-04 1.99874106e-03]\n",
      " [3.84610552e-04 6.58749333e-04]\n",
      " [1.77542296e-04 2.25427993e-04]\n",
      " [9.50741935e-05 1.00548960e-04]]\n",
      "Train Epoch96 out_loss 0.0014215245610103011\n",
      "Test Epoch96 layer0 out_loss 0.0023776916787028313\n",
      "Test Epoch96 layer1 out_loss 0.0008166228071786463\n",
      "Test Epoch96 layer2 out_loss 0.0004673001531045884\n",
      "Test Epoch96 layer3 out_loss 0.0005165314651094377\n",
      "Test Epoch96 layer4 out_loss 0.0004387393710203469\n",
      "Train 97 | out_loss 0.0013762337621301413: 100%|█| 138/138 [00:00<00:00, 216.64i\n",
      "[[4.20149622e-04 6.48641635e-03]\n",
      " [2.61391186e-04 1.51389049e-03]\n",
      " [3.06284361e-04 7.18943768e-04]\n",
      " [1.60724317e-04 2.43904772e-04]\n",
      " [9.69335899e-05 1.13119889e-04]]\n",
      "Train Epoch97 out_loss 0.0013762337621301413\n",
      "Test Epoch97 layer0 out_loss 0.0022595133632421494\n",
      "Test Epoch97 layer1 out_loss 0.0005588913918472826\n",
      "Test Epoch97 layer2 out_loss 0.0004940483486279845\n",
      "Test Epoch97 layer3 out_loss 0.0004751177621074021\n",
      "Test Epoch97 layer4 out_loss 0.0004371296672616154\n",
      "Train 98 | out_loss 0.005132479593157768: 100%|█| 138/138 [00:00<00:00, 204.60it\n",
      "[[0.00037327 0.02320932]\n",
      " [0.0091633  0.0703949 ]\n",
      " [0.02555012 0.10097862]\n",
      " [0.06387918 0.13020393]\n",
      " [0.16621361 0.23359564]]\n",
      "Train Epoch98 out_loss 0.005132479593157768\n",
      "Test Epoch98 layer0 out_loss 0.009317541494965553\n",
      "Test Epoch98 layer1 out_loss 0.0018806798616424203\n",
      "Test Epoch98 layer2 out_loss 0.001115206046961248\n",
      "Test Epoch98 layer3 out_loss 0.0020634972024708986\n",
      "Test Epoch98 layer4 out_loss 0.003632336389273405\n",
      "Train 99 | out_loss 0.002084019361063838: 100%|█| 138/138 [00:00<00:00, 213.37it\n",
      "[[4.61592113e-04 1.44435631e-02]\n",
      " [1.71957407e-05 2.57630756e-03]\n",
      " [1.24543652e-04 2.83644963e-03]\n",
      " [7.85054574e-04 4.88218779e-03]\n",
      " [2.50756623e-03 1.30452789e-02]]\n",
      "Train Epoch99 out_loss 0.002084019361063838\n",
      "Test Epoch99 layer0 out_loss 0.001368626137264073\n",
      "Test Epoch99 layer1 out_loss 0.0005317934555932879\n",
      "Test Epoch99 layer2 out_loss 0.00046559126349166036\n",
      "Test Epoch99 layer3 out_loss 0.0004721488803625107\n",
      "Test Epoch99 layer4 out_loss 0.0004408860404510051\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Start Training\n",
      "  0%|                                                   | 0/138 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 0.04180939495563507: 100%|█| 138/138 [00:01<00:00, 122.54it/s\n",
      "[[ 0.09581946 23.02257334]\n",
      " [ 1.49246262  9.44846838]\n",
      " [ 0.8207328   5.03269379]\n",
      " [ 0.75571799  3.00030475]\n",
      " [ 0.72502434  1.68797261]\n",
      " [ 0.64515252  1.1903018 ]]\n",
      "Train Epoch0 out_loss 0.04180939495563507\n",
      "Test Epoch0 layer0 out_loss 0.09904657304286957\n",
      "Test Epoch0 layer1 out_loss 0.012986129149794579\n",
      "Test Epoch0 layer2 out_loss 0.007715401705354452\n",
      "Test Epoch0 layer3 out_loss 0.001525343395769596\n",
      "Test Epoch0 layer4 out_loss 0.0014051615726202726\n",
      "Test Epoch0 layer5 out_loss 0.002658917335793376\n",
      "Train 1 | out_loss 0.0010139395017176867: 100%|█| 138/138 [00:00<00:00, 170.08it\n",
      "[[5.58115965e-05 5.64900064e+00]\n",
      " [5.02355082e-06 2.06729131e-01]\n",
      " [7.71546064e-06 7.23081070e-02]\n",
      " [9.85002949e-05 2.71634317e-02]\n",
      " [8.14755422e-04 1.28594156e-02]\n",
      " [5.26496657e-03 1.24507448e-02]]\n",
      "Train Epoch1 out_loss 0.0010139395017176867\n",
      "Test Epoch1 layer0 out_loss 0.06999990344047546\n",
      "Test Epoch1 layer1 out_loss 0.008841166272759438\n",
      "Test Epoch1 layer2 out_loss 0.003866293467581272\n",
      "Test Epoch1 layer3 out_loss 0.0007536316406913102\n",
      "Test Epoch1 layer4 out_loss 0.0006334306090138853\n",
      "Test Epoch1 layer5 out_loss 0.0005140882567502558\n",
      "Train 2 | out_loss 0.0005111735663376749: 100%|█| 138/138 [00:00<00:00, 180.94it\n",
      "[[5.35658928e-05 2.92336282e+00]\n",
      " [4.51997824e-06 8.41076999e-02]\n",
      " [1.30337934e-06 2.82898149e-02]\n",
      " [5.73239516e-07 1.13274277e-02]\n",
      " [5.21062175e-07 4.10993872e-03]\n",
      " [4.48644502e-07 1.91451832e-03]]\n",
      "Train Epoch2 out_loss 0.0005111735663376749\n",
      "Test Epoch2 layer0 out_loss 0.10790595412254333\n",
      "Test Epoch2 layer1 out_loss 0.006254762876778841\n",
      "Test Epoch2 layer2 out_loss 0.002658897079527378\n",
      "Test Epoch2 layer3 out_loss 0.0005681070033460855\n",
      "Test Epoch2 layer4 out_loss 0.0006305034039542079\n",
      "Test Epoch2 layer5 out_loss 0.0005250839167274535\n",
      "Train 3 | out_loss 0.0005007811705581844: 100%|█| 138/138 [00:00<00:00, 184.76it\n",
      "[[5.42708558e-05 2.17285381e+00]\n",
      " [4.65069082e-06 5.87524790e-02]\n",
      " [1.53019951e-06 1.79024787e-02]\n",
      " [1.22103662e-06 6.99675339e-03]\n",
      " [1.28822077e-06 2.57712242e-03]\n",
      " [1.00130869e-06 1.25789372e-03]]\n",
      "Train Epoch3 out_loss 0.0005007811705581844\n",
      "Test Epoch3 layer0 out_loss 0.05459968000650406\n",
      "Test Epoch3 layer1 out_loss 0.004114796873182058\n",
      "Test Epoch3 layer2 out_loss 0.0021049424540251493\n",
      "Test Epoch3 layer3 out_loss 0.000691018532961607\n",
      "Test Epoch3 layer4 out_loss 0.0005568759515881538\n",
      "Test Epoch3 layer5 out_loss 0.0005254537682048976\n",
      "Train 4 | out_loss 0.000493627623654902: 100%|█| 138/138 [00:00<00:00, 178.10it/\n",
      "[[5.40844100e-05 1.47283363e+00]\n",
      " [4.65494693e-06 3.91545907e-02]\n",
      " [1.61026425e-06 1.15911581e-02]\n",
      " [1.45974330e-06 4.57659872e-03]\n",
      " [1.88882901e-06 1.72799349e-03]\n",
      " [1.72003420e-06 9.29351147e-04]]\n",
      "Train Epoch4 out_loss 0.000493627623654902\n",
      "Test Epoch4 layer0 out_loss 0.026921000331640244\n",
      "Test Epoch4 layer1 out_loss 0.0032516231294721365\n",
      "Test Epoch4 layer2 out_loss 0.0014505471335723996\n",
      "Test Epoch4 layer3 out_loss 0.0005840035155415535\n",
      "Test Epoch4 layer4 out_loss 0.0005591132794506848\n",
      "Test Epoch4 layer5 out_loss 0.0005350414430722594\n",
      "Train 5 | out_loss 0.0004929925198666751: 100%|█| 138/138 [00:00<00:00, 187.24it\n",
      "[[5.29410284e-05 5.47414400e-01]\n",
      " [4.63908805e-06 2.40292475e-02]\n",
      " [1.60673237e-06 7.32354118e-03]\n",
      " [1.43120937e-06 3.06511841e-03]\n",
      " [2.01573741e-06 1.21127269e-03]\n",
      " [1.80754758e-06 6.99607182e-04]]\n",
      "Train Epoch5 out_loss 0.0004929925198666751\n",
      "Test Epoch5 layer0 out_loss 0.03584545478224754\n",
      "Test Epoch5 layer1 out_loss 0.0028934499714523554\n",
      "Test Epoch5 layer2 out_loss 0.0010760348523035645\n",
      "Test Epoch5 layer3 out_loss 0.0005384109681472182\n",
      "Test Epoch5 layer4 out_loss 0.0005368171841837466\n",
      "Test Epoch5 layer5 out_loss 0.0005196245037950575\n",
      "Train 6 | out_loss 0.0004820069298148155: 100%|█| 138/138 [00:00<00:00, 178.44it\n",
      "[[5.21689704e-05 6.80251556e-01]\n",
      " [4.68681782e-06 2.17050269e-02]\n",
      " [1.65524473e-06 6.05806238e-03]\n",
      " [1.79916295e-06 2.44122240e-03]\n",
      " [3.38632176e-06 9.88686156e-04]\n",
      " [3.06179945e-06 5.71440252e-04]]\n",
      "Train Epoch6 out_loss 0.0004820069298148155\n",
      "Test Epoch6 layer0 out_loss 0.025930043309926987\n",
      "Test Epoch6 layer1 out_loss 0.002560900989919901\n",
      "Test Epoch6 layer2 out_loss 0.000969635380897671\n",
      "Test Epoch6 layer3 out_loss 0.0004752233508042991\n",
      "Test Epoch6 layer4 out_loss 0.00044094258919358253\n",
      "Test Epoch6 layer5 out_loss 0.00044653748045675457\n",
      "Train 7 | out_loss 0.00048144900938495994: 100%|█| 138/138 [00:00<00:00, 180.05i\n",
      "[[5.24334034e-05 3.84080343e-01]\n",
      " [4.75216519e-06 1.14062265e-02]\n",
      " [1.92981548e-06 3.96835898e-03]\n",
      " [2.99113445e-06 1.69066344e-03]\n",
      " [5.52794273e-06 7.15777060e-04]\n",
      " [5.61564382e-06 4.41708437e-04]]\n",
      "Train Epoch7 out_loss 0.00048144900938495994\n",
      "Test Epoch7 layer0 out_loss 0.03872383385896683\n",
      "Test Epoch7 layer1 out_loss 0.0025629678275436163\n",
      "Test Epoch7 layer2 out_loss 0.001002470962703228\n",
      "Test Epoch7 layer3 out_loss 0.0004784469783771783\n",
      "Test Epoch7 layer4 out_loss 0.0004336744896136224\n",
      "Test Epoch7 layer5 out_loss 0.00044264612370170653\n",
      "Train 8 | out_loss 0.0004662755236495286: 100%|█| 138/138 [00:00<00:00, 180.89it\n",
      "[[4.86517726e-05 8.06392798e-01]\n",
      " [4.74812895e-06 9.48136935e-03]\n",
      " [2.11323689e-06 3.22395567e-03]\n",
      " [3.96562317e-06 1.37404485e-03]\n",
      " [6.95329059e-06 6.00307676e-04]\n",
      " [8.16468137e-06 3.87475885e-04]]\n",
      "Train Epoch8 out_loss 0.0004662755236495286\n",
      "Test Epoch8 layer0 out_loss 0.02694987878203392\n",
      "Test Epoch8 layer1 out_loss 0.0020815369207412004\n",
      "Test Epoch8 layer2 out_loss 0.0008798306807875633\n",
      "Test Epoch8 layer3 out_loss 0.0005368682905100286\n",
      "Test Epoch8 layer4 out_loss 0.0005240377504378557\n",
      "Test Epoch8 layer5 out_loss 0.0005365361575968564\n",
      "Train 9 | out_loss 0.00045555562246590853: 100%|█| 138/138 [00:00<00:00, 171.01i\n",
      "[[4.58960832e-05 1.25087278e+00]\n",
      " [4.65134873e-06 8.43995900e-03]\n",
      " [1.72994027e-06 2.86487626e-03]\n",
      " [2.48850968e-06 1.20042323e-03]\n",
      " [4.70350467e-06 5.22067043e-04]\n",
      " [7.18760023e-06 3.38551399e-04]]\n",
      "Train Epoch9 out_loss 0.00045555562246590853\n",
      "Test Epoch9 layer0 out_loss 0.04583656042814255\n",
      "Test Epoch9 layer1 out_loss 0.0016643183771520853\n",
      "Test Epoch9 layer2 out_loss 0.0007701427675783634\n",
      "Test Epoch9 layer3 out_loss 0.0004470626590773463\n",
      "Test Epoch9 layer4 out_loss 0.00044499619980342686\n",
      "Test Epoch9 layer5 out_loss 0.00046387093607336283\n",
      "Train 10 | out_loss 0.0004689595371019095: 100%|█| 138/138 [00:00<00:00, 180.60i\n",
      "[[4.85436754e-05 4.16671714e-01]\n",
      " [4.81013739e-06 4.90944491e-03]\n",
      " [1.91800440e-06 1.85864321e-03]\n",
      " [2.69655277e-06 8.31968378e-04]\n",
      " [5.31510885e-06 3.60113733e-04]\n",
      " [6.45710848e-06 2.48591279e-04]]\n",
      "Train Epoch10 out_loss 0.0004689595371019095\n",
      "Test Epoch10 layer0 out_loss 0.03214618191123009\n",
      "Test Epoch10 layer1 out_loss 0.0016060387715697289\n",
      "Test Epoch10 layer2 out_loss 0.0007115978514775634\n",
      "Test Epoch10 layer3 out_loss 0.00045607489300891757\n",
      "Test Epoch10 layer4 out_loss 0.0004185537400189787\n",
      "Test Epoch10 layer5 out_loss 0.00043991737766191363\n",
      "Train 11 | out_loss 0.00045951365609653294: 100%|█| 138/138 [00:00<00:00, 179.51\n",
      "[[4.45545403e-05 6.78641065e-01]\n",
      " [5.29044998e-06 4.71038929e-03]\n",
      " [2.31950608e-06 1.71928725e-03]\n",
      " [5.04678305e-06 7.97095261e-04]\n",
      " [9.57294464e-06 3.69127517e-04]\n",
      " [1.23343291e-05 2.56528268e-04]]\n",
      "Train Epoch11 out_loss 0.00045951365609653294\n",
      "Test Epoch11 layer0 out_loss 0.027578899636864662\n",
      "Test Epoch11 layer1 out_loss 0.0016669294564053416\n",
      "Test Epoch11 layer2 out_loss 0.0007641770062036812\n",
      "Test Epoch11 layer3 out_loss 0.00043215046753175557\n",
      "Test Epoch11 layer4 out_loss 0.0004108810389880091\n",
      "Test Epoch11 layer5 out_loss 0.00044831426930613816\n",
      "Train 12 | out_loss 0.00045617861906066537: 100%|█| 138/138 [00:00<00:00, 178.18\n",
      "[[4.16792061e-05 1.24840618e-01]\n",
      " [6.73289339e-06 3.02100543e-03]\n",
      " [2.45147220e-06 1.21349889e-03]\n",
      " [6.38792680e-06 5.46612432e-04]\n",
      " [1.22639493e-05 2.47004438e-04]\n",
      " [2.50618704e-05 2.04659125e-04]]\n",
      "Train Epoch12 out_loss 0.00045617861906066537\n",
      "Test Epoch12 layer0 out_loss 0.020441971719264984\n",
      "Test Epoch12 layer1 out_loss 0.0013225829461589456\n",
      "Test Epoch12 layer2 out_loss 0.0009426871547475457\n",
      "Test Epoch12 layer3 out_loss 0.000636311830021441\n",
      "Test Epoch12 layer4 out_loss 0.0006301756366156042\n",
      "Test Epoch12 layer5 out_loss 0.0006545833894051611\n",
      "Train 13 | out_loss 0.0004901827778667212: 100%|█| 138/138 [00:00<00:00, 173.39i\n",
      "[[4.59546628e-05 6.09035959e-01]\n",
      " [7.89928557e-06 3.38730938e-03]\n",
      " [3.26599002e-06 1.26782216e-03]\n",
      " [7.43530557e-06 6.28230063e-04]\n",
      " [1.68365426e-05 2.80993596e-04]\n",
      " [3.57040054e-05 2.18100898e-04]]\n",
      "Train Epoch13 out_loss 0.0004901827778667212\n",
      "Test Epoch13 layer0 out_loss 0.021994486451148987\n",
      "Test Epoch13 layer1 out_loss 0.0012829351471737027\n",
      "Test Epoch13 layer2 out_loss 0.0006825461168773472\n",
      "Test Epoch13 layer3 out_loss 0.00043175017344765365\n",
      "Test Epoch13 layer4 out_loss 0.0004099321668036282\n",
      "Test Epoch13 layer5 out_loss 0.00042752933222800493\n",
      "Train 14 | out_loss 0.00044529300066642463: 100%|█| 138/138 [00:00<00:00, 185.90\n",
      "[[3.69738638e-05 1.32699812e-01]\n",
      " [8.82704460e-06 2.31144123e-03]\n",
      " [3.46488540e-06 9.27859588e-04]\n",
      " [9.58239090e-06 4.13584034e-04]\n",
      " [2.29316117e-05 1.89789796e-04]\n",
      " [5.93798717e-05 1.69433358e-04]]\n",
      "Train Epoch14 out_loss 0.00044529300066642463\n",
      "Test Epoch14 layer0 out_loss 0.010184471495449543\n",
      "Test Epoch14 layer1 out_loss 0.0009992816485464573\n",
      "Test Epoch14 layer2 out_loss 0.0006240063812583685\n",
      "Test Epoch14 layer3 out_loss 0.0004364920314401388\n",
      "Test Epoch14 layer4 out_loss 0.00040685271960683167\n",
      "Test Epoch14 layer5 out_loss 0.0004266221367288381\n",
      "Train 15 | out_loss 0.00046194385504350066: 100%|█| 138/138 [00:00<00:00, 182.76\n",
      "[[3.74808005e-05 1.42690411e-01]\n",
      " [1.69563700e-05 2.07453607e-03]\n",
      " [2.05318557e-04 9.24978859e-04]\n",
      " [2.81955912e-04 5.64833740e-04]\n",
      " [1.30873678e-04 2.84788271e-04]\n",
      " [2.22173274e-04 2.01381840e-04]]\n",
      "Train Epoch15 out_loss 0.00046194385504350066\n",
      "Test Epoch15 layer0 out_loss 0.005651639308780432\n",
      "Test Epoch15 layer1 out_loss 0.001021582167595625\n",
      "Test Epoch15 layer2 out_loss 0.0006048068753443658\n",
      "Test Epoch15 layer3 out_loss 0.00048576793051324785\n",
      "Test Epoch15 layer4 out_loss 0.0004163571575190872\n",
      "Test Epoch15 layer5 out_loss 0.00042545856558717787\n",
      "Train 16 | out_loss 0.00048226965009234846: 100%|█| 138/138 [00:00<00:00, 183.58\n",
      "[[3.97205585e-05 7.31021848e-02]\n",
      " [1.06575333e-05 1.71154604e-03]\n",
      " [3.40353246e-04 8.54966189e-04]\n",
      " [4.27660871e-04 6.33358011e-04]\n",
      " [2.02832938e-04 3.44879363e-04]\n",
      " [3.02356849e-04 2.20646352e-04]]\n",
      "Train Epoch16 out_loss 0.00048226965009234846\n",
      "Test Epoch16 layer0 out_loss 0.004992489702999592\n",
      "Test Epoch16 layer1 out_loss 0.0009103093179874122\n",
      "Test Epoch16 layer2 out_loss 0.000579056388232857\n",
      "Test Epoch16 layer3 out_loss 0.00043741660192608833\n",
      "Test Epoch16 layer4 out_loss 0.00043664415716193616\n",
      "Test Epoch16 layer5 out_loss 0.00044129096204414964\n",
      "Train 17 | out_loss 0.0004986311541870236: 100%|█| 138/138 [00:00<00:00, 185.96i\n",
      "[[3.89911939e-05 2.56225041e-01]\n",
      " [1.45239161e-05 1.86001957e-03]\n",
      " [2.61574405e-04 8.11743964e-04]\n",
      " [2.94609355e-04 5.48725984e-04]\n",
      " [1.73621657e-04 2.93988965e-04]\n",
      " [2.21135211e-04 2.00893226e-04]]\n",
      "Train Epoch17 out_loss 0.0004986311541870236\n",
      "Test Epoch17 layer0 out_loss 0.012761147692799568\n",
      "Test Epoch17 layer1 out_loss 0.0009140492184087634\n",
      "Test Epoch17 layer2 out_loss 0.0006376320379786193\n",
      "Test Epoch17 layer3 out_loss 0.00047303480096161366\n",
      "Test Epoch17 layer4 out_loss 0.0004134751798119396\n",
      "Test Epoch17 layer5 out_loss 0.00042485789163038135\n",
      "Train 18 | out_loss 0.00048552799853496253: 100%|█| 138/138 [00:00<00:00, 174.27\n",
      "[[3.46949108e-05 1.60005781e-01]\n",
      " [1.93239308e-05 1.51300577e-03]\n",
      " [4.06137896e-04 7.72967639e-04]\n",
      " [4.07873145e-04 6.11063356e-04]\n",
      " [2.62248878e-04 3.53259560e-04]\n",
      " [3.23947760e-04 2.48920049e-04]]\n",
      "Train Epoch18 out_loss 0.00048552799853496253\n",
      "Test Epoch18 layer0 out_loss 0.013060163706541061\n",
      "Test Epoch18 layer1 out_loss 0.0009462621528655291\n",
      "Test Epoch18 layer2 out_loss 0.0005999702261760831\n",
      "Test Epoch18 layer3 out_loss 0.0004587955481838435\n",
      "Test Epoch18 layer4 out_loss 0.00047035139868967235\n",
      "Test Epoch18 layer5 out_loss 0.0005069263279438019\n",
      "Train 19 | out_loss 0.000489661528263241: 100%|█| 138/138 [00:00<00:00, 178.31it\n",
      "[[3.15932587e-05 5.18313584e-01]\n",
      " [3.30620736e-05 2.28303035e-03]\n",
      " [7.03860843e-04 1.13675355e-03]\n",
      " [6.16752612e-04 9.47761982e-04]\n",
      " [3.27834957e-04 4.93000440e-04]\n",
      " [4.13558510e-04 2.89254836e-04]]\n",
      "Train Epoch19 out_loss 0.000489661528263241\n",
      "Test Epoch19 layer0 out_loss 0.016998613253235817\n",
      "Test Epoch19 layer1 out_loss 0.0009726754506118596\n",
      "Test Epoch19 layer2 out_loss 0.0006427281768992543\n",
      "Test Epoch19 layer3 out_loss 0.0005537187680602074\n",
      "Test Epoch19 layer4 out_loss 0.0005217422731220722\n",
      "Test Epoch19 layer5 out_loss 0.0005909985047765076\n",
      "Train 20 | out_loss 0.0004940949729643762: 100%|█| 138/138 [00:00<00:00, 179.02i\n",
      "[[3.23735910e-05 1.63931815e-01]\n",
      " [5.70600194e-05 1.50724842e-03]\n",
      " [1.65334931e-04 6.51703093e-04]\n",
      " [1.19042313e-04 3.72539200e-04]\n",
      " [2.04198879e-04 2.39006268e-04]\n",
      " [1.62813582e-04 2.06004897e-04]]\n",
      "Train Epoch20 out_loss 0.0004940949729643762\n",
      "Test Epoch20 layer0 out_loss 0.016304781660437584\n",
      "Test Epoch20 layer1 out_loss 0.0008047459414228797\n",
      "Test Epoch20 layer2 out_loss 0.0005618727300316095\n",
      "Test Epoch20 layer3 out_loss 0.0004278013948351145\n",
      "Test Epoch20 layer4 out_loss 0.00039877198287285864\n",
      "Test Epoch20 layer5 out_loss 0.0004156848881393671\n",
      "Train 21 | out_loss 0.0005465596914291382: 100%|█| 138/138 [00:00<00:00, 178.98i\n",
      "[[3.67221134e-05 1.47256185e-01]\n",
      " [1.27047624e-04 1.47438787e-03]\n",
      " [7.56861233e-04 9.59079573e-04]\n",
      " [3.87441089e-04 7.36924185e-04]\n",
      " [5.75547075e-04 3.72083605e-04]\n",
      " [4.37469134e-04 3.38488258e-04]]\n",
      "Train Epoch21 out_loss 0.0005465596914291382\n",
      "Test Epoch21 layer0 out_loss 0.01647028885781765\n",
      "Test Epoch21 layer1 out_loss 0.0008423510007560253\n",
      "Test Epoch21 layer2 out_loss 0.0005550251225940883\n",
      "Test Epoch21 layer3 out_loss 0.00042390794260427356\n",
      "Test Epoch21 layer4 out_loss 0.0004031917196698487\n",
      "Test Epoch21 layer5 out_loss 0.0004155586939305067\n",
      "Train 22 | out_loss 0.0006782598211430013: 100%|█| 138/138 [00:00<00:00, 178.98i\n",
      "[[3.66290885e-05 6.12954627e-01]\n",
      " [2.28158604e-04 2.55339982e-03]\n",
      " [8.79254623e-04 1.37911468e-03]\n",
      " [4.50579855e-04 1.00223004e-03]\n",
      " [8.19291511e-04 5.74401125e-04]\n",
      " [5.17127274e-04 5.12945880e-04]]\n",
      "Train Epoch22 out_loss 0.0006782598211430013\n",
      "Test Epoch22 layer0 out_loss 0.04398972913622856\n",
      "Test Epoch22 layer1 out_loss 0.0009980280883610249\n",
      "Test Epoch22 layer2 out_loss 0.0005361959338188171\n",
      "Test Epoch22 layer3 out_loss 0.000421704666223377\n",
      "Test Epoch22 layer4 out_loss 0.0004009048570878804\n",
      "Test Epoch22 layer5 out_loss 0.0004165356222074479\n",
      "Train 23 | out_loss 0.0006545547512359917: 100%|█| 138/138 [00:00<00:00, 178.53i\n",
      "[[2.49358397e-05 2.30176054e-01]\n",
      " [2.01084710e-04 2.12223274e-03]\n",
      " [4.76884507e-04 9.93237978e-04]\n",
      " [2.75885866e-04 6.23757736e-04]\n",
      " [4.35048857e-04 3.95422967e-04]\n",
      " [2.28472753e-04 3.04788365e-04]]\n",
      "Train Epoch23 out_loss 0.0006545547512359917\n",
      "Test Epoch23 layer0 out_loss 0.011360038071870804\n",
      "Test Epoch23 layer1 out_loss 0.0018828782485798001\n",
      "Test Epoch23 layer2 out_loss 0.001490168273448944\n",
      "Test Epoch23 layer3 out_loss 0.0012389045441523194\n",
      "Test Epoch23 layer4 out_loss 0.0013041406637057662\n",
      "Test Epoch23 layer5 out_loss 0.0011959410039708018\n",
      "Train 24 | out_loss 0.0007194915669970214: 100%|█| 138/138 [00:00<00:00, 181.46i\n",
      "[[3.66261637e-05 5.60276773e-02]\n",
      " [2.93446546e-04 1.41178638e-03]\n",
      " [6.08863001e-04 8.55856565e-04]\n",
      " [6.09914020e-04 7.61306225e-04]\n",
      " [6.02254678e-04 6.54241717e-04]\n",
      " [3.20637231e-04 4.05122111e-04]]\n",
      "Train Epoch24 out_loss 0.0007194915669970214\n",
      "Test Epoch24 layer0 out_loss 0.006096411030739546\n",
      "Test Epoch24 layer1 out_loss 0.000843576795887202\n",
      "Test Epoch24 layer2 out_loss 0.0007328586652874947\n",
      "Test Epoch24 layer3 out_loss 0.00059151416644454\n",
      "Test Epoch24 layer4 out_loss 0.000502849870827049\n",
      "Test Epoch24 layer5 out_loss 0.0005613002576865256\n",
      "Train 25 | out_loss 0.0008153630769811571: 100%|█| 138/138 [00:00<00:00, 177.73i\n",
      "[[6.66691376e-05 3.94904600e-02]\n",
      " [5.20920155e-04 1.37428840e-03]\n",
      " [1.04482448e-03 1.09060124e-03]\n",
      " [9.90621628e-04 1.12012922e-03]\n",
      " [9.03453508e-04 8.55354566e-04]\n",
      " [5.47107132e-04 5.54814727e-04]]\n",
      "Train Epoch25 out_loss 0.0008153630769811571\n",
      "Test Epoch25 layer0 out_loss 0.008271848782896996\n",
      "Test Epoch25 layer1 out_loss 0.0009384701843373477\n",
      "Test Epoch25 layer2 out_loss 0.0008424230036325753\n",
      "Test Epoch25 layer3 out_loss 0.0009761996916495264\n",
      "Test Epoch25 layer4 out_loss 0.0010225871810689569\n",
      "Test Epoch25 layer5 out_loss 0.0010629332391545177\n",
      "Train 26 | out_loss 0.0011129226768389344: 100%|█| 138/138 [00:00<00:00, 176.13i\n",
      "[[1.72405224e-04 5.49651551e-01]\n",
      " [4.11300147e-04 3.21387085e-03]\n",
      " [7.28657467e-04 1.30947607e-03]\n",
      " [4.87137823e-04 1.04978215e-03]\n",
      " [3.49695886e-04 5.42244967e-04]\n",
      " [5.53946255e-04 5.75233184e-04]]\n",
      "Train Epoch26 out_loss 0.0011129226768389344\n",
      "Test Epoch26 layer0 out_loss 0.06426036357879639\n",
      "Test Epoch26 layer1 out_loss 0.0010323369642719626\n",
      "Test Epoch26 layer2 out_loss 0.0008925165748223662\n",
      "Test Epoch26 layer3 out_loss 0.0011393229942768812\n",
      "Test Epoch26 layer4 out_loss 0.000830529083032161\n",
      "Test Epoch26 layer5 out_loss 0.0008136369870044291\n",
      "Train 27 | out_loss 0.0015710524749010801: 100%|█| 138/138 [00:00<00:00, 181.57i\n",
      "[[4.56524600e-04 7.15296416e-01]\n",
      " [3.56414342e-04 3.19497766e-03]\n",
      " [4.41523063e-04 1.16307546e-03]\n",
      " [3.26954113e-04 8.12387065e-04]\n",
      " [3.68412519e-04 4.69666023e-04]\n",
      " [4.23571624e-04 4.66347337e-04]]\n",
      "Train Epoch27 out_loss 0.0015710524749010801\n",
      "Test Epoch27 layer0 out_loss 0.015012014657258987\n",
      "Test Epoch27 layer1 out_loss 0.0012138228630647063\n",
      "Test Epoch27 layer2 out_loss 0.0009965314529836178\n",
      "Test Epoch27 layer3 out_loss 0.001098410109989345\n",
      "Test Epoch27 layer4 out_loss 0.0010146769927814603\n",
      "Test Epoch27 layer5 out_loss 0.00101080269087106\n",
      "Train 28 | out_loss 0.0013161968672648072: 100%|█| 138/138 [00:00<00:00, 182.54i\n",
      "[[0.00035438 0.08531971]\n",
      " [0.00045456 0.00163541]\n",
      " [0.00061861 0.00090264]\n",
      " [0.00055296 0.00088963]\n",
      " [0.0003944  0.00052205]\n",
      " [0.00081722 0.00065659]]\n",
      "Train Epoch28 out_loss 0.0013161968672648072\n",
      "Test Epoch28 layer0 out_loss 0.01367891114205122\n",
      "Test Epoch28 layer1 out_loss 0.0017590302741155028\n",
      "Test Epoch28 layer2 out_loss 0.0014490479370579123\n",
      "Test Epoch28 layer3 out_loss 0.001436432357877493\n",
      "Test Epoch28 layer4 out_loss 0.0014000431401655078\n",
      "Test Epoch28 layer5 out_loss 0.0013728406047448516\n",
      "Train 29 | out_loss 0.00143529346678406: 100%|█| 138/138 [00:00<00:00, 186.19it/\n",
      "[[0.00034356 0.02013398]\n",
      " [0.00068907 0.00139714]\n",
      " [0.00108101 0.00108701]\n",
      " [0.00101067 0.0010576 ]\n",
      " [0.00058273 0.00077209]\n",
      " [0.00044802 0.00042708]]\n",
      "Train Epoch29 out_loss 0.00143529346678406\n",
      "Test Epoch29 layer0 out_loss 0.00478952843695879\n",
      "Test Epoch29 layer1 out_loss 0.0016900172922760248\n",
      "Test Epoch29 layer2 out_loss 0.0013106391998007894\n",
      "Test Epoch29 layer3 out_loss 0.0015484383329749107\n",
      "Test Epoch29 layer4 out_loss 0.0015501839807257056\n",
      "Test Epoch29 layer5 out_loss 0.001654214458540082\n",
      "Train 30 | out_loss 0.0013840869069099426: 100%|█| 138/138 [00:00<00:00, 178.07i\n",
      "[[0.00033827 0.04421428]\n",
      " [0.00025067 0.00110394]\n",
      " [0.00030918 0.00063451]\n",
      " [0.00029437 0.00054323]\n",
      " [0.00029525 0.00033035]\n",
      " [0.00034497 0.0003528 ]]\n",
      "Train Epoch30 out_loss 0.0013840869069099426\n",
      "Test Epoch30 layer0 out_loss 0.009997926652431488\n",
      "Test Epoch30 layer1 out_loss 0.001066582859493792\n",
      "Test Epoch30 layer2 out_loss 0.0011271577095612884\n",
      "Test Epoch30 layer3 out_loss 0.001004476915113628\n",
      "Test Epoch30 layer4 out_loss 0.0010836503934115171\n",
      "Test Epoch30 layer5 out_loss 0.0010121180675923824\n",
      "Train 31 | out_loss 0.0016004210337996483: 100%|█| 138/138 [00:00<00:00, 184.06i\n",
      "[[0.00045806 0.10116103]\n",
      " [0.00040011 0.00160036]\n",
      " [0.00051573 0.00086576]\n",
      " [0.00042051 0.00066934]\n",
      " [0.00032151 0.00037759]\n",
      " [0.00023277 0.00028722]]\n",
      "Train Epoch31 out_loss 0.0016004210337996483\n",
      "Test Epoch31 layer0 out_loss 0.03300602361559868\n",
      "Test Epoch31 layer1 out_loss 0.0013040434569120407\n",
      "Test Epoch31 layer2 out_loss 0.0018601857591420412\n",
      "Test Epoch31 layer3 out_loss 0.002041670959442854\n",
      "Test Epoch31 layer4 out_loss 0.0020135799422860146\n",
      "Test Epoch31 layer5 out_loss 0.0018098307773470879\n",
      "Train 32 | out_loss 0.0012856905814260244: 100%|█| 138/138 [00:00<00:00, 178.35i\n",
      "[[0.00028441 0.13725514]\n",
      " [0.00055238 0.00206109]\n",
      " [0.00095752 0.00135805]\n",
      " [0.00092259 0.00145281]\n",
      " [0.00065948 0.0008979 ]\n",
      " [0.0005889  0.0005617 ]]\n",
      "Train Epoch32 out_loss 0.0012856905814260244\n",
      "Test Epoch32 layer0 out_loss 0.005819518119096756\n",
      "Test Epoch32 layer1 out_loss 0.0012551432009786367\n",
      "Test Epoch32 layer2 out_loss 0.0006830072961747646\n",
      "Test Epoch32 layer3 out_loss 0.000608205737080425\n",
      "Test Epoch32 layer4 out_loss 0.0005760638159699738\n",
      "Test Epoch32 layer5 out_loss 0.0006275481428019702\n",
      "Train 33 | out_loss 0.0015741537790745497: 100%|█| 138/138 [00:00<00:00, 174.90i\n",
      "[[0.00044574 0.12528897]\n",
      " [0.00058737 0.00197822]\n",
      " [0.00064357 0.00105269]\n",
      " [0.00067448 0.00098104]\n",
      " [0.00049101 0.00064087]\n",
      " [0.00044107 0.00044209]]\n",
      "Train Epoch33 out_loss 0.0015741537790745497\n",
      "Test Epoch33 layer0 out_loss 0.031045349314808846\n",
      "Test Epoch33 layer1 out_loss 0.0007342066965065897\n",
      "Test Epoch33 layer2 out_loss 0.0008976784301921725\n",
      "Test Epoch33 layer3 out_loss 0.0010926485992968082\n",
      "Test Epoch33 layer4 out_loss 0.0009089785162359476\n",
      "Test Epoch33 layer5 out_loss 0.0010071973083540797\n",
      "Train 34 | out_loss 0.0015617810422554612: 100%|█| 138/138 [00:00<00:00, 180.89i\n",
      "[[0.00042518 0.06977941]\n",
      " [0.00056663 0.00183488]\n",
      " [0.00059127 0.00106834]\n",
      " [0.00058983 0.00087894]\n",
      " [0.00043412 0.00058449]\n",
      " [0.00036831 0.00038985]]\n",
      "Train Epoch34 out_loss 0.0015617810422554612\n",
      "Test Epoch34 layer0 out_loss 0.011548897251486778\n",
      "Test Epoch34 layer1 out_loss 0.0007015555165708065\n",
      "Test Epoch34 layer2 out_loss 0.00089411367662251\n",
      "Test Epoch34 layer3 out_loss 0.0008970873896032572\n",
      "Test Epoch34 layer4 out_loss 0.0009185901726596057\n",
      "Test Epoch34 layer5 out_loss 0.0010633935453370214\n",
      "Train 35 | out_loss 0.0012905255425721407: 100%|█| 138/138 [00:00<00:00, 185.11i\n",
      "[[0.00030537 0.07627049]\n",
      " [0.00048523 0.00170663]\n",
      " [0.00082188 0.0011902 ]\n",
      " [0.0006293  0.00102209]\n",
      " [0.00042284 0.00054165]\n",
      " [0.00049208 0.00046771]]\n",
      "Train Epoch35 out_loss 0.0012905255425721407\n",
      "Test Epoch35 layer0 out_loss 0.004103980027139187\n",
      "Test Epoch35 layer1 out_loss 0.0007384851342067122\n",
      "Test Epoch35 layer2 out_loss 0.0005829068832099438\n",
      "Test Epoch35 layer3 out_loss 0.0004205270088277757\n",
      "Test Epoch35 layer4 out_loss 0.0004069418355356902\n",
      "Test Epoch35 layer5 out_loss 0.0004174871719442308\n",
      "Train 36 | out_loss 0.0013195173814892769: 100%|█| 138/138 [00:00<00:00, 173.27i\n",
      "[[0.00034775 0.10233134]\n",
      " [0.0006757  0.00202251]\n",
      " [0.00084264 0.00137085]\n",
      " [0.00067139 0.00111869]\n",
      " [0.0005053  0.00063094]\n",
      " [0.00044074 0.00040807]]\n",
      "Train Epoch36 out_loss 0.0013195173814892769\n",
      "Test Epoch36 layer0 out_loss 0.004870153497904539\n",
      "Test Epoch36 layer1 out_loss 0.000986540224403143\n",
      "Test Epoch36 layer2 out_loss 0.0007664492004550993\n",
      "Test Epoch36 layer3 out_loss 0.0007993528852239251\n",
      "Test Epoch36 layer4 out_loss 0.0009234398021362722\n",
      "Test Epoch36 layer5 out_loss 0.000784976698923856\n",
      "Train 37 | out_loss 0.0012797537492588162: 100%|█| 138/138 [00:00<00:00, 184.41i\n",
      "[[0.00028384 0.18268187]\n",
      " [0.00054611 0.0023374 ]\n",
      " [0.00068176 0.00119027]\n",
      " [0.00052177 0.00088126]\n",
      " [0.00041137 0.00051837]\n",
      " [0.00041662 0.00039701]]\n",
      "Train Epoch37 out_loss 0.0012797537492588162\n",
      "Test Epoch37 layer0 out_loss 0.04418819025158882\n",
      "Test Epoch37 layer1 out_loss 0.0017210545483976603\n",
      "Test Epoch37 layer2 out_loss 0.00048161810263991356\n",
      "Test Epoch37 layer3 out_loss 0.0007150565506890416\n",
      "Test Epoch37 layer4 out_loss 0.00046264356933534145\n",
      "Test Epoch37 layer5 out_loss 0.0004988961154595017\n",
      "Train 38 | out_loss 0.0018059458816424012: 100%|█| 138/138 [00:00<00:00, 183.12i\n",
      "[[0.00057873 0.32404751]\n",
      " [0.0006528  0.00280177]\n",
      " [0.00077271 0.00142881]\n",
      " [0.00053876 0.00095958]\n",
      " [0.00054299 0.0006657 ]\n",
      " [0.0004717  0.00052595]]\n",
      "Train Epoch38 out_loss 0.0018059458816424012\n",
      "Test Epoch38 layer0 out_loss 0.02935658022761345\n",
      "Test Epoch38 layer1 out_loss 0.0009364557918161154\n",
      "Test Epoch38 layer2 out_loss 0.0004091588198207319\n",
      "Test Epoch38 layer3 out_loss 0.00042034368379972875\n",
      "Test Epoch38 layer4 out_loss 0.00044309566146694124\n",
      "Test Epoch38 layer5 out_loss 0.00045589267392642796\n",
      "Train 39 | out_loss 0.0013951500877738: 100%|█| 138/138 [00:00<00:00, 182.82it/s\n",
      "[[0.00033095 0.13954429]\n",
      " [0.00053629 0.0019484 ]\n",
      " [0.00055405 0.0010737 ]\n",
      " [0.00040735 0.00060435]\n",
      " [0.00036973 0.00038233]\n",
      " [0.00031214 0.00033031]]\n",
      "Train Epoch39 out_loss 0.0013951500877738\n",
      "Test Epoch39 layer0 out_loss 0.005128741730004549\n",
      "Test Epoch39 layer1 out_loss 0.000848234340082854\n",
      "Test Epoch39 layer2 out_loss 0.0004261569119989872\n",
      "Test Epoch39 layer3 out_loss 0.0006635645404458046\n",
      "Test Epoch39 layer4 out_loss 0.0005876955692656338\n",
      "Test Epoch39 layer5 out_loss 0.0006486157653853297\n",
      "Train 40 | out_loss 0.0014023988042026758: 100%|█| 138/138 [00:00<00:00, 179.31i\n",
      "[[0.00035906 0.02850411]\n",
      " [0.00075848 0.00177717]\n",
      " [0.00085357 0.00152001]\n",
      " [0.00056307 0.00092749]\n",
      " [0.0005294  0.00060179]\n",
      " [0.00045052 0.00047202]]\n",
      "Train Epoch40 out_loss 0.0014023988042026758\n",
      "Test Epoch40 layer0 out_loss 0.004922318272292614\n",
      "Test Epoch40 layer1 out_loss 0.002381781814619899\n",
      "Test Epoch40 layer2 out_loss 0.002085448009893298\n",
      "Test Epoch40 layer3 out_loss 0.002181361662223935\n",
      "Test Epoch40 layer4 out_loss 0.0024647433310747147\n",
      "Test Epoch40 layer5 out_loss 0.002437828341498971\n",
      "Train 41 | out_loss 0.0012473005335777998: 100%|█| 138/138 [00:00<00:00, 182.77i\n",
      "[[0.00030095 0.02791777]\n",
      " [0.00039155 0.00139513]\n",
      " [0.00060398 0.00104757]\n",
      " [0.00040483 0.00075469]\n",
      " [0.00037069 0.00046027]\n",
      " [0.0002491  0.00027062]]\n",
      "Train Epoch41 out_loss 0.0012473005335777998\n",
      "Test Epoch41 layer0 out_loss 0.005615071393549442\n",
      "Test Epoch41 layer1 out_loss 0.001225291402079165\n",
      "Test Epoch41 layer2 out_loss 0.0006127500091679394\n",
      "Test Epoch41 layer3 out_loss 0.0008524860022589564\n",
      "Test Epoch41 layer4 out_loss 0.0007613124325871468\n",
      "Test Epoch41 layer5 out_loss 0.0007565370760858059\n",
      "Train 42 | out_loss 0.0017003454267978668: 100%|█| 138/138 [00:00<00:00, 182.75i\n",
      "[[0.00049546 0.07813233]\n",
      " [0.00067576 0.00220636]\n",
      " [0.00081204 0.00155053]\n",
      " [0.00059484 0.00118173]\n",
      " [0.00051746 0.00060644]\n",
      " [0.0003523  0.00035523]]\n",
      "Train Epoch42 out_loss 0.0017003454267978668\n",
      "Test Epoch42 layer0 out_loss 0.01132881548255682\n",
      "Test Epoch42 layer1 out_loss 0.002242921618744731\n",
      "Test Epoch42 layer2 out_loss 0.0021133581176400185\n",
      "Test Epoch42 layer3 out_loss 0.001969029661267996\n",
      "Test Epoch42 layer4 out_loss 0.0021257151383906603\n",
      "Test Epoch42 layer5 out_loss 0.0019755333196371794\n",
      "Train 43 | out_loss 0.001306316815316677: 100%|█| 138/138 [00:00<00:00, 181.39it\n",
      "[[0.00030222 0.11959238]\n",
      " [0.00051816 0.0023964 ]\n",
      " [0.00063487 0.00133823]\n",
      " [0.00050583 0.00104051]\n",
      " [0.00044354 0.00053424]\n",
      " [0.0003457  0.0003395 ]]\n",
      "Train Epoch43 out_loss 0.001306316815316677\n",
      "Test Epoch43 layer0 out_loss 0.01396212074905634\n",
      "Test Epoch43 layer1 out_loss 0.0011839965591207147\n",
      "Test Epoch43 layer2 out_loss 0.0016182748368009925\n",
      "Test Epoch43 layer3 out_loss 0.0012402546126395464\n",
      "Test Epoch43 layer4 out_loss 0.0013761201407760382\n",
      "Test Epoch43 layer5 out_loss 0.0013029082911089063\n",
      "Train 44 | out_loss 0.0014250784879550338: 100%|█| 138/138 [00:00<00:00, 182.03i\n",
      "[[0.00036042 0.05959095]\n",
      " [0.00058613 0.00182419]\n",
      " [0.00072552 0.00145777]\n",
      " [0.00053481 0.00101151]\n",
      " [0.0004547  0.00051393]\n",
      " [0.00028419 0.00033481]]\n",
      "Train Epoch44 out_loss 0.0014250784879550338\n",
      "Test Epoch44 layer0 out_loss 0.004294468089938164\n",
      "Test Epoch44 layer1 out_loss 0.0020637877751141787\n",
      "Test Epoch44 layer2 out_loss 0.0017172391526401043\n",
      "Test Epoch44 layer3 out_loss 0.0018147643422707915\n",
      "Test Epoch44 layer4 out_loss 0.0017221514135599136\n",
      "Test Epoch44 layer5 out_loss 0.0016676194500178099\n",
      "Train 45 | out_loss 0.0012379033723846078: 100%|█| 138/138 [00:00<00:00, 183.21i\n",
      "[[0.00028576 0.03409142]\n",
      " [0.0006371  0.00178476]\n",
      " [0.00069153 0.00144827]\n",
      " [0.00052639 0.00092556]\n",
      " [0.00049913 0.00052746]\n",
      " [0.000303   0.00029629]]\n",
      "Train Epoch45 out_loss 0.0012379033723846078\n",
      "Test Epoch45 layer0 out_loss 0.006499846000224352\n",
      "Test Epoch45 layer1 out_loss 0.0009360751137137413\n",
      "Test Epoch45 layer2 out_loss 0.0012716632336378098\n",
      "Test Epoch45 layer3 out_loss 0.0006531463586725295\n",
      "Test Epoch45 layer4 out_loss 0.0006549698300659657\n",
      "Test Epoch45 layer5 out_loss 0.0006770334439352155\n",
      "Train 46 | out_loss 0.0015872936928644776: 100%|█| 138/138 [00:00<00:00, 182.59i\n",
      "[[0.00047597 0.01251107]\n",
      " [0.00062897 0.00158046]\n",
      " [0.00067534 0.00129341]\n",
      " [0.0004869  0.00097876]\n",
      " [0.00051588 0.00058034]\n",
      " [0.00034649 0.00035155]]\n",
      "Train Epoch46 out_loss 0.0015872936928644776\n",
      "Test Epoch46 layer0 out_loss 0.004956014920026064\n",
      "Test Epoch46 layer1 out_loss 0.0028035242576152086\n",
      "Test Epoch46 layer2 out_loss 0.0014409037539735436\n",
      "Test Epoch46 layer3 out_loss 0.0017777321627363563\n",
      "Test Epoch46 layer4 out_loss 0.0017263732152059674\n",
      "Test Epoch46 layer5 out_loss 0.0016390127129852772\n",
      "Train 47 | out_loss 0.001318153808824718: 100%|█| 138/138 [00:00<00:00, 182.81it\n",
      "[[2.92319106e-04 6.34593521e-01]\n",
      " [5.05454602e-04 4.53269613e-03]\n",
      " [6.03429627e-04 1.95055541e-03]\n",
      " [4.87001969e-04 1.06612126e-03]\n",
      " [3.68853293e-04 6.15388056e-04]\n",
      " [2.52489829e-04 3.46780770e-04]]\n",
      "Train Epoch47 out_loss 0.001318153808824718\n",
      "Test Epoch47 layer0 out_loss 0.023417865857481956\n",
      "Test Epoch47 layer1 out_loss 0.0010124295949935913\n",
      "Test Epoch47 layer2 out_loss 0.0004243372241035104\n",
      "Test Epoch47 layer3 out_loss 0.0005473719793371856\n",
      "Test Epoch47 layer4 out_loss 0.000672602909617126\n",
      "Test Epoch47 layer5 out_loss 0.0006012706435285509\n",
      "Train 48 | out_loss 0.001330332481302321: 100%|█| 138/138 [00:00<00:00, 169.50it\n",
      "[[0.00030131 0.08596349]\n",
      " [0.0006023  0.0018741 ]\n",
      " [0.00082756 0.00153322]\n",
      " [0.00053147 0.00085237]\n",
      " [0.00036674 0.00041707]\n",
      " [0.00023904 0.0002265 ]]\n",
      "Train Epoch48 out_loss 0.001330332481302321\n",
      "Test Epoch48 layer0 out_loss 0.01920928619801998\n",
      "Test Epoch48 layer1 out_loss 0.0009463418391533196\n",
      "Test Epoch48 layer2 out_loss 0.0006048287032172084\n",
      "Test Epoch48 layer3 out_loss 0.0006191814318299294\n",
      "Test Epoch48 layer4 out_loss 0.0005257717566564679\n",
      "Test Epoch48 layer5 out_loss 0.0006981667829677463\n",
      "Train 49 | out_loss 0.0017352936556562781: 100%|█| 138/138 [00:00<00:00, 179.97i\n",
      "[[0.00055364 0.01936432]\n",
      " [0.00073788 0.00173239]\n",
      " [0.00077531 0.00130528]\n",
      " [0.00059333 0.00084284]\n",
      " [0.00048045 0.00049203]\n",
      " [0.00029727 0.00024998]]\n",
      "Train Epoch49 out_loss 0.0017352936556562781\n",
      "Test Epoch49 layer0 out_loss 0.003458070568740368\n",
      "Test Epoch49 layer1 out_loss 0.0009317463263869286\n",
      "Test Epoch49 layer2 out_loss 0.0006788735627196729\n",
      "Test Epoch49 layer3 out_loss 0.0006716102361679077\n",
      "Test Epoch49 layer4 out_loss 0.0007538103964179754\n",
      "Test Epoch49 layer5 out_loss 0.0007902710931375623\n",
      "Train 50 | out_loss 0.0013584562111645937: 100%|█| 138/138 [00:00<00:00, 180.32i\n",
      "[[0.00033713 0.00794014]\n",
      " [0.00040331 0.00117164]\n",
      " [0.00052787 0.00102116]\n",
      " [0.00038735 0.00074136]\n",
      " [0.00031947 0.00039269]\n",
      " [0.00027085 0.00024863]]\n",
      "Train Epoch50 out_loss 0.0013584562111645937\n",
      "Test Epoch50 layer0 out_loss 0.004350719973444939\n",
      "Test Epoch50 layer1 out_loss 0.0006714247865602374\n",
      "Test Epoch50 layer2 out_loss 0.000494945386890322\n",
      "Test Epoch50 layer3 out_loss 0.0004821046313736588\n",
      "Test Epoch50 layer4 out_loss 0.0004755561240017414\n",
      "Test Epoch50 layer5 out_loss 0.0004932022420689464\n",
      "Train 51 | out_loss 0.001179307233542204: 100%|█| 138/138 [00:00<00:00, 176.43it\n",
      "[[0.00025319 0.00677471]\n",
      " [0.00064745 0.00176177]\n",
      " [0.00072545 0.00176426]\n",
      " [0.00062743 0.00111616]\n",
      " [0.00052507 0.00050926]\n",
      " [0.00035749 0.00029672]]\n",
      "Train Epoch51 out_loss 0.001179307233542204\n",
      "Test Epoch51 layer0 out_loss 0.004197601228952408\n",
      "Test Epoch51 layer1 out_loss 0.0008229283266700804\n",
      "Test Epoch51 layer2 out_loss 0.0020222095772624016\n",
      "Test Epoch51 layer3 out_loss 0.0008477997616864741\n",
      "Test Epoch51 layer4 out_loss 0.0008787523256614804\n",
      "Test Epoch51 layer5 out_loss 0.0008801156072877347\n",
      "Train 52 | out_loss 0.0015736259520053864: 100%|█| 138/138 [00:00<00:00, 175.84i\n",
      "[[0.00044986 0.06606179]\n",
      " [0.00048916 0.00236754]\n",
      " [0.00072864 0.00164694]\n",
      " [0.00045755 0.00111009]\n",
      " [0.00048255 0.00054437]\n",
      " [0.00034226 0.00036147]]\n",
      "Train Epoch52 out_loss 0.0015736259520053864\n",
      "Test Epoch52 layer0 out_loss 0.021683059632778168\n",
      "Test Epoch52 layer1 out_loss 0.0014399640494957566\n",
      "Test Epoch52 layer2 out_loss 0.0015797101659700274\n",
      "Test Epoch52 layer3 out_loss 0.0015336063224822283\n",
      "Test Epoch52 layer4 out_loss 0.0012932548997923732\n",
      "Test Epoch52 layer5 out_loss 0.0012491553789004683\n",
      "Train 53 | out_loss 0.001436628750525415: 100%|█| 138/138 [00:00<00:00, 184.60it\n",
      "[[0.00038301 0.11090462]\n",
      " [0.00068608 0.00308674]\n",
      " [0.00076546 0.0017986 ]\n",
      " [0.00055047 0.00100979]\n",
      " [0.00041761 0.00047517]\n",
      " [0.00026739 0.00026556]]\n",
      "Train Epoch53 out_loss 0.001436628750525415\n",
      "Test Epoch53 layer0 out_loss 0.039134569466114044\n",
      "Test Epoch53 layer1 out_loss 0.0008855126798152924\n",
      "Test Epoch53 layer2 out_loss 0.0006639890489168465\n",
      "Test Epoch53 layer3 out_loss 0.00068209896562621\n",
      "Test Epoch53 layer4 out_loss 0.0006976323784328997\n",
      "Test Epoch53 layer5 out_loss 0.0007505144458264112\n",
      "Train 54 | out_loss 0.0013271537609398365: 100%|█| 138/138 [00:00<00:00, 175.27i\n",
      "[[0.00028157 0.1660804 ]\n",
      " [0.00053797 0.0028874 ]\n",
      " [0.00057306 0.00129996]\n",
      " [0.00041879 0.00078253]\n",
      " [0.00030802 0.00047285]\n",
      " [0.00019842 0.00026401]]\n",
      "Train Epoch54 out_loss 0.0013271537609398365\n",
      "Test Epoch54 layer0 out_loss 0.004814767278730869\n",
      "Test Epoch54 layer1 out_loss 0.0013813064433634281\n",
      "Test Epoch54 layer2 out_loss 0.0003854700189549476\n",
      "Test Epoch54 layer3 out_loss 0.0005210621748119593\n",
      "Test Epoch54 layer4 out_loss 0.0005675991415046155\n",
      "Test Epoch54 layer5 out_loss 0.0005701941554434597\n",
      "Train 55 | out_loss 0.001199452206492424: 100%|█| 138/138 [00:00<00:00, 180.87it\n",
      "[[0.00034408 0.00875415]\n",
      " [0.0004979  0.00145031]\n",
      " [0.00071663 0.00146441]\n",
      " [0.00059265 0.00081219]\n",
      " [0.00035763 0.00039049]\n",
      " [0.00031746 0.00031716]]\n",
      "Train Epoch55 out_loss 0.001199452206492424\n",
      "Test Epoch55 layer0 out_loss 0.0024762265384197235\n",
      "Test Epoch55 layer1 out_loss 0.0009382987627759576\n",
      "Test Epoch55 layer2 out_loss 0.0004560278030112386\n",
      "Test Epoch55 layer3 out_loss 0.000411584391258657\n",
      "Test Epoch55 layer4 out_loss 0.0004260966379661113\n",
      "Test Epoch55 layer5 out_loss 0.00046667311107739806\n",
      "Train 56 | out_loss 0.0013986474368721247: 100%|█| 138/138 [00:00<00:00, 171.83i\n",
      "[[0.00038897 0.00515889]\n",
      " [0.0004687  0.00139613]\n",
      " [0.00059167 0.00145761]\n",
      " [0.00060372 0.00112074]\n",
      " [0.00048341 0.00053163]\n",
      " [0.00047124 0.00041198]]\n",
      "Train Epoch56 out_loss 0.0013986474368721247\n",
      "Test Epoch56 layer0 out_loss 0.00256431195884943\n",
      "Test Epoch56 layer1 out_loss 0.0006690119043923914\n",
      "Test Epoch56 layer2 out_loss 0.00048587031778879464\n",
      "Test Epoch56 layer3 out_loss 0.000849574280437082\n",
      "Test Epoch56 layer4 out_loss 0.0008099796832539141\n",
      "Test Epoch56 layer5 out_loss 0.0007124745170585811\n",
      "Train 57 | out_loss 0.0016593957552686334: 100%|█| 138/138 [00:00<00:00, 175.26i\n",
      "[[0.00052238 0.04862145]\n",
      " [0.00065063 0.00264163]\n",
      " [0.00069996 0.00135942]\n",
      " [0.00043326 0.00081218]\n",
      " [0.00032369 0.00039146]\n",
      " [0.00032278 0.00028043]]\n",
      "Train Epoch57 out_loss 0.0016593957552686334\n",
      "Test Epoch57 layer0 out_loss 0.005783150438219309\n",
      "Test Epoch57 layer1 out_loss 0.0014109249459579587\n",
      "Test Epoch57 layer2 out_loss 0.00040998184704221785\n",
      "Test Epoch57 layer3 out_loss 0.0005626346101053059\n",
      "Test Epoch57 layer4 out_loss 0.0005191845120862126\n",
      "Test Epoch57 layer5 out_loss 0.0004859522741753608\n",
      "Train 58 | out_loss 0.0011367680272087455: 100%|█| 138/138 [00:00<00:00, 180.06i\n",
      "[[0.00023996 0.02327878]\n",
      " [0.00038154 0.00157892]\n",
      " [0.00055826 0.00135426]\n",
      " [0.00033938 0.00062474]\n",
      " [0.00026366 0.00027841]\n",
      " [0.00020562 0.00017108]]\n",
      "Train Epoch58 out_loss 0.0011367680272087455\n",
      "Test Epoch58 layer0 out_loss 0.007448462303727865\n",
      "Test Epoch58 layer1 out_loss 0.001020409632474184\n",
      "Test Epoch58 layer2 out_loss 0.0005425952258519828\n",
      "Test Epoch58 layer3 out_loss 0.0005283086211420596\n",
      "Test Epoch58 layer4 out_loss 0.0005421093082986772\n",
      "Test Epoch58 layer5 out_loss 0.0005883376579731703\n",
      "Train 59 | out_loss 0.0017323960782960057: 100%|█| 138/138 [00:00<00:00, 175.20i\n",
      "[[0.00058338 0.09387885]\n",
      " [0.00065919 0.00346833]\n",
      " [0.00072033 0.0018168 ]\n",
      " [0.00050356 0.00094754]\n",
      " [0.00041309 0.00046478]\n",
      " [0.00033633 0.000323  ]]\n",
      "Train Epoch59 out_loss 0.0017323960782960057\n",
      "Test Epoch59 layer0 out_loss 0.011320291087031364\n",
      "Test Epoch59 layer1 out_loss 0.0013027617242187262\n",
      "Test Epoch59 layer2 out_loss 0.00042675508302636445\n",
      "Test Epoch59 layer3 out_loss 0.0004181894182693213\n",
      "Test Epoch59 layer4 out_loss 0.00041418883483856916\n",
      "Test Epoch59 layer5 out_loss 0.0004105971020180732\n",
      "Train 60 | out_loss 0.000835977669339627: 100%|█| 138/138 [00:00<00:00, 179.45it\n",
      "[[0.00011749 0.01553335]\n",
      " [0.00049443 0.00177023]\n",
      " [0.00063497 0.00124689]\n",
      " [0.00038275 0.00054535]\n",
      " [0.00033617 0.00036025]\n",
      " [0.00021363 0.00023354]]\n",
      "Train Epoch60 out_loss 0.000835977669339627\n",
      "Test Epoch60 layer0 out_loss 0.008230860345065594\n",
      "Test Epoch60 layer1 out_loss 0.0033977883867919445\n",
      "Test Epoch60 layer2 out_loss 0.004037571605294943\n",
      "Test Epoch60 layer3 out_loss 0.004053982440382242\n",
      "Test Epoch60 layer4 out_loss 0.004060632083564997\n",
      "Test Epoch60 layer5 out_loss 0.004178284667432308\n",
      "Train 61 | out_loss 0.0013645217986777425: 100%|█| 138/138 [00:00<00:00, 181.33i\n",
      "[[0.00039745 0.02436927]\n",
      " [0.00041158 0.00160941]\n",
      " [0.00050512 0.00131135]\n",
      " [0.00032623 0.00063612]\n",
      " [0.00029622 0.00033259]\n",
      " [0.00024885 0.00023956]]\n",
      "Train Epoch61 out_loss 0.0013645217986777425\n",
      "Test Epoch61 layer0 out_loss 0.010982837527990341\n",
      "Test Epoch61 layer1 out_loss 0.0013537013437598944\n",
      "Test Epoch61 layer2 out_loss 0.0005773359443992376\n",
      "Test Epoch61 layer3 out_loss 0.00048771779984235764\n",
      "Test Epoch61 layer4 out_loss 0.0005073405336588621\n",
      "Test Epoch61 layer5 out_loss 0.0006311130709946156\n",
      "Train 62 | out_loss 0.0015939236618578434: 100%|█| 138/138 [00:00<00:00, 175.38i\n",
      "[[0.00050679 0.04891037]\n",
      " [0.00053986 0.00283126]\n",
      " [0.00073793 0.00162636]\n",
      " [0.00053729 0.00094167]\n",
      " [0.00054908 0.00053294]\n",
      " [0.00043164 0.00042418]]\n",
      "Train Epoch62 out_loss 0.0015939236618578434\n",
      "Test Epoch62 layer0 out_loss 0.011341282166540623\n",
      "Test Epoch62 layer1 out_loss 0.0019063083454966545\n",
      "Test Epoch62 layer2 out_loss 0.0005079743568785489\n",
      "Test Epoch62 layer3 out_loss 0.0007060535135678947\n",
      "Test Epoch62 layer4 out_loss 0.0004431657143868506\n",
      "Test Epoch62 layer5 out_loss 0.0004796232678927481\n",
      "Train 63 | out_loss 0.0012777309166267514: 100%|█| 138/138 [00:00<00:00, 180.96i\n",
      "[[0.0002999  0.04387996]\n",
      " [0.00046306 0.00263233]\n",
      " [0.00052667 0.00127789]\n",
      " [0.0003511  0.00063954]\n",
      " [0.00060236 0.00063503]\n",
      " [0.00027901 0.00032314]]\n",
      "Train Epoch63 out_loss 0.0012777309166267514\n",
      "Test Epoch63 layer0 out_loss 0.007825491949915886\n",
      "Test Epoch63 layer1 out_loss 0.0010349141666665673\n",
      "Test Epoch63 layer2 out_loss 0.0007840838516131043\n",
      "Test Epoch63 layer3 out_loss 0.0006571835256181657\n",
      "Test Epoch63 layer4 out_loss 0.0006870977813377976\n",
      "Test Epoch63 layer5 out_loss 0.0006455408874899149\n",
      "Train 64 | out_loss 0.0012865569442510605: 100%|█| 138/138 [00:00<00:00, 180.32i\n",
      "[[0.00028782 0.01341786]\n",
      " [0.00049449 0.00183207]\n",
      " [0.00068906 0.00154802]\n",
      " [0.00075606 0.00097486]\n",
      " [0.00037293 0.00048999]\n",
      " [0.00025817 0.00027728]]\n",
      "Train Epoch64 out_loss 0.0012865569442510605\n",
      "Test Epoch64 layer0 out_loss 0.0030044002924114466\n",
      "Test Epoch64 layer1 out_loss 0.0005986798205412924\n",
      "Test Epoch64 layer2 out_loss 0.0006432843510992825\n",
      "Test Epoch64 layer3 out_loss 0.0008247597143054008\n",
      "Test Epoch64 layer4 out_loss 0.0007571950554847717\n",
      "Test Epoch64 layer5 out_loss 0.0007706646574661136\n",
      "Train 65 | out_loss 0.001302066259086132: 100%|█| 138/138 [00:00<00:00, 179.28it\n",
      "[[0.00032818 0.00964974]\n",
      " [0.00055876 0.00192173]\n",
      " [0.00066029 0.0012701 ]\n",
      " [0.00038139 0.00055785]\n",
      " [0.00028014 0.00030471]\n",
      " [0.00025714 0.00024388]]\n",
      "Train Epoch65 out_loss 0.001302066259086132\n",
      "Test Epoch65 layer0 out_loss 0.003628696780651808\n",
      "Test Epoch65 layer1 out_loss 0.0008346220711246133\n",
      "Test Epoch65 layer2 out_loss 0.0004565538256429136\n",
      "Test Epoch65 layer3 out_loss 0.00041543319821357727\n",
      "Test Epoch65 layer4 out_loss 0.0004644850851036608\n",
      "Test Epoch65 layer5 out_loss 0.00042696387390606105\n",
      "Train 66 | out_loss 0.0012913848040625453: 100%|█| 138/138 [00:00<00:00, 178.91i\n",
      "[[0.00030441 0.06024817]\n",
      " [0.00031829 0.00242934]\n",
      " [0.00042744 0.00160752]\n",
      " [0.00054688 0.00088713]\n",
      " [0.00029661 0.00043882]\n",
      " [0.00023074 0.00024257]]\n",
      "Train Epoch66 out_loss 0.0012913848040625453\n",
      "Test Epoch66 layer0 out_loss 0.017936429008841515\n",
      "Test Epoch66 layer1 out_loss 0.0006229962455108762\n",
      "Test Epoch66 layer2 out_loss 0.0003981613554060459\n",
      "Test Epoch66 layer3 out_loss 0.0004615603538695723\n",
      "Test Epoch66 layer4 out_loss 0.000528743548784405\n",
      "Test Epoch66 layer5 out_loss 0.0005546837346628308\n",
      "Train 67 | out_loss 0.0014098738320171833: 100%|█| 138/138 [00:00<00:00, 169.65i\n",
      "[[0.00038916 0.03517777]\n",
      " [0.00062454 0.00253861]\n",
      " [0.00081636 0.00151476]\n",
      " [0.00046291 0.00062363]\n",
      " [0.00028246 0.00033394]\n",
      " [0.0002399  0.00026384]]\n",
      "Train Epoch67 out_loss 0.0014098738320171833\n",
      "Test Epoch67 layer0 out_loss 0.007038411218672991\n",
      "Test Epoch67 layer1 out_loss 0.0012818233808502555\n",
      "Test Epoch67 layer2 out_loss 0.00042165242484770715\n",
      "Test Epoch67 layer3 out_loss 0.0004121960955671966\n",
      "Test Epoch67 layer4 out_loss 0.00044239236740395427\n",
      "Test Epoch67 layer5 out_loss 0.0005153482197783887\n",
      "Train 68 | out_loss 0.0013830071547999978: 100%|█| 138/138 [00:00<00:00, 181.63i\n",
      "[[0.00035587 0.00612623]\n",
      " [0.00041309 0.00164599]\n",
      " [0.00070801 0.00158688]\n",
      " [0.00044818 0.00066504]\n",
      " [0.00030366 0.00031721]\n",
      " [0.00021453 0.00026102]]\n",
      "Train Epoch68 out_loss 0.0013830071547999978\n",
      "Test Epoch68 layer0 out_loss 0.006967902183532715\n",
      "Test Epoch68 layer1 out_loss 0.0006272939499467611\n",
      "Test Epoch68 layer2 out_loss 0.0007399489404633641\n",
      "Test Epoch68 layer3 out_loss 0.0007033172878436744\n",
      "Test Epoch68 layer4 out_loss 0.00070940051227808\n",
      "Test Epoch68 layer5 out_loss 0.0007400556933134794\n",
      "Train 69 | out_loss 0.0012445999309420586: 100%|█| 138/138 [00:00<00:00, 177.31i\n",
      "[[0.00027253 0.05508112]\n",
      " [0.00042119 0.002747  ]\n",
      " [0.00047086 0.00107828]\n",
      " [0.00024265 0.00045758]\n",
      " [0.0001922  0.00030821]\n",
      " [0.00027021 0.00032973]]\n",
      "Train Epoch69 out_loss 0.0012445999309420586\n",
      "Test Epoch69 layer0 out_loss 0.005899823270738125\n",
      "Test Epoch69 layer1 out_loss 0.001076782587915659\n",
      "Test Epoch69 layer2 out_loss 0.0008974412339739501\n",
      "Test Epoch69 layer3 out_loss 0.0009034036193042994\n",
      "Test Epoch69 layer4 out_loss 0.0010538852075114846\n",
      "Test Epoch69 layer5 out_loss 0.0007802702602930367\n",
      "Train 70 | out_loss 0.0013915362069383264: 100%|█| 138/138 [00:00<00:00, 173.45i\n",
      "[[0.00039106 0.1550616 ]\n",
      " [0.00046206 0.00549646]\n",
      " [0.00049022 0.00176368]\n",
      " [0.0003554  0.00078914]\n",
      " [0.00025474 0.00045047]\n",
      " [0.00027721 0.0003592 ]]\n",
      "Train Epoch70 out_loss 0.0013915362069383264\n",
      "Test Epoch70 layer0 out_loss 0.009651364758610725\n",
      "Test Epoch70 layer1 out_loss 0.0012854003580287099\n",
      "Test Epoch70 layer2 out_loss 0.0015292515745386481\n",
      "Test Epoch70 layer3 out_loss 0.0012639376800507307\n",
      "Test Epoch70 layer4 out_loss 0.0012234350433573127\n",
      "Test Epoch70 layer5 out_loss 0.0011492911726236343\n",
      "Train 71 | out_loss 0.0017043591942638159: 100%|█| 138/138 [00:00<00:00, 177.41i\n",
      "[[0.00060026 0.01224481]\n",
      " [0.00035348 0.00127322]\n",
      " [0.00043633 0.0008497 ]\n",
      " [0.00025124 0.00038575]\n",
      " [0.00020171 0.00021767]\n",
      " [0.00025288 0.00023983]]\n",
      "Train Epoch71 out_loss 0.0017043591942638159\n",
      "Test Epoch71 layer0 out_loss 0.002945483196526766\n",
      "Test Epoch71 layer1 out_loss 0.0009797554230317473\n",
      "Test Epoch71 layer2 out_loss 0.0004102261445950717\n",
      "Test Epoch71 layer3 out_loss 0.0004253866500221193\n",
      "Test Epoch71 layer4 out_loss 0.0004276632098481059\n",
      "Test Epoch71 layer5 out_loss 0.00044422681094147265\n",
      "Train 72 | out_loss 0.0013472131686285138: 100%|█| 138/138 [00:00<00:00, 180.27i\n",
      "[[0.00039704 0.00579898]\n",
      " [0.000568   0.00162611]\n",
      " [0.00075655 0.00119352]\n",
      " [0.00041517 0.00052624]\n",
      " [0.00031243 0.00026526]\n",
      " [0.00021058 0.00017673]]\n",
      "Train Epoch72 out_loss 0.0013472131686285138\n",
      "Test Epoch72 layer0 out_loss 0.002820183290168643\n",
      "Test Epoch72 layer1 out_loss 0.0038926571141928434\n",
      "Test Epoch72 layer2 out_loss 0.0017077584052458405\n",
      "Test Epoch72 layer3 out_loss 0.0015681643271818757\n",
      "Test Epoch72 layer4 out_loss 0.0015832632780075073\n",
      "Test Epoch72 layer5 out_loss 0.001577250543050468\n",
      "Train 73 | out_loss 0.0007022100035101175: 100%|█| 138/138 [00:00<00:00, 172.62i\n",
      "[[6.42955337e-05 3.04516574e-03]\n",
      " [4.86310000e-04 1.68458993e-03]\n",
      " [8.51501796e-04 2.11033309e-03]\n",
      " [5.25100525e-04 9.47552785e-04]\n",
      " [4.92947177e-04 5.57714080e-04]\n",
      " [3.26628388e-04 3.14327854e-04]]\n",
      "Train Epoch73 out_loss 0.0007022100035101175\n",
      "Test Epoch73 layer0 out_loss 0.0021192249841988087\n",
      "Test Epoch73 layer1 out_loss 0.0005847893189638853\n",
      "Test Epoch73 layer2 out_loss 0.0007018075557425618\n",
      "Test Epoch73 layer3 out_loss 0.0005319060292094946\n",
      "Test Epoch73 layer4 out_loss 0.0005431405734270811\n",
      "Test Epoch73 layer5 out_loss 0.0005773844313807786\n",
      "Train 74 | out_loss 0.001341381692327559: 100%|█| 138/138 [00:00<00:00, 178.20it\n",
      "[[0.00033356 0.02820109]\n",
      " [0.00040557 0.00214303]\n",
      " [0.00047074 0.00121199]\n",
      " [0.00032824 0.000551  ]\n",
      " [0.00042848 0.00049281]\n",
      " [0.00032986 0.00034949]]\n",
      "Train Epoch74 out_loss 0.001341381692327559\n",
      "Test Epoch74 layer0 out_loss 0.020942192524671555\n",
      "Test Epoch74 layer1 out_loss 0.0016111611621454358\n",
      "Test Epoch74 layer2 out_loss 0.0016233846545219421\n",
      "Test Epoch74 layer3 out_loss 0.0011135486420243979\n",
      "Test Epoch74 layer4 out_loss 0.0011331058340147138\n",
      "Test Epoch74 layer5 out_loss 0.0011249422095716\n",
      "Train 75 | out_loss 0.0013964790850877762: 100%|█| 138/138 [00:00<00:00, 178.70i\n",
      "[[0.00040053 0.13049668]\n",
      " [0.00032812 0.00353716]\n",
      " [0.0003876  0.00120401]\n",
      " [0.0002341  0.00065446]\n",
      " [0.0002075  0.0003908 ]\n",
      " [0.00017658 0.00026445]]\n",
      "Train Epoch75 out_loss 0.0013964790850877762\n",
      "Test Epoch75 layer0 out_loss 0.010487569496035576\n",
      "Test Epoch75 layer1 out_loss 0.0008732245769351721\n",
      "Test Epoch75 layer2 out_loss 0.0003848290944006294\n",
      "Test Epoch75 layer3 out_loss 0.0004378468729555607\n",
      "Test Epoch75 layer4 out_loss 0.00044318209984339774\n",
      "Test Epoch75 layer5 out_loss 0.0004114290059078485\n",
      "Train 76 | out_loss 0.0015088298823684454: 100%|█| 138/138 [00:00<00:00, 183.18i\n",
      "[[0.00042226 0.00750441]\n",
      " [0.00038432 0.00129218]\n",
      " [0.00043894 0.00082334]\n",
      " [0.00024786 0.0003602 ]\n",
      " [0.00022619 0.00026085]\n",
      " [0.00017008 0.00018791]]\n",
      "Train Epoch76 out_loss 0.0015088298823684454\n",
      "Test Epoch76 layer0 out_loss 0.0022080743219703436\n",
      "Test Epoch76 layer1 out_loss 0.0005916220252402127\n",
      "Test Epoch76 layer2 out_loss 0.0004729091888293624\n",
      "Test Epoch76 layer3 out_loss 0.0005047874292358756\n",
      "Test Epoch76 layer4 out_loss 0.0005578406853601336\n",
      "Test Epoch76 layer5 out_loss 0.0005202299216762185\n",
      "Train 77 | out_loss 0.0012819052208214998: 100%|█| 138/138 [00:00<00:00, 172.41i\n",
      "[[0.00030437 0.0032852 ]\n",
      " [0.00047038 0.00158355]\n",
      " [0.00066275 0.00128929]\n",
      " [0.00048108 0.00076446]\n",
      " [0.00032545 0.00035887]\n",
      " [0.00027162 0.00024522]]\n",
      "Train Epoch77 out_loss 0.0012819052208214998\n",
      "Test Epoch77 layer0 out_loss 0.0032623407896608114\n",
      "Test Epoch77 layer1 out_loss 0.0007077716290950775\n",
      "Test Epoch77 layer2 out_loss 0.000503124319948256\n",
      "Test Epoch77 layer3 out_loss 0.00041649953345768154\n",
      "Test Epoch77 layer4 out_loss 0.0004688784247264266\n",
      "Test Epoch77 layer5 out_loss 0.0004563432594295591\n",
      "Train 78 | out_loss 0.0011760967317968607: 100%|█| 138/138 [00:00<00:00, 179.19i\n",
      "[[0.00032038 0.00749266]\n",
      " [0.00038931 0.00171393]\n",
      " [0.00056424 0.00135744]\n",
      " [0.00040558 0.00054265]\n",
      " [0.00028672 0.00028004]\n",
      " [0.00020685 0.00019098]]\n",
      "Train Epoch78 out_loss 0.0011760967317968607\n",
      "Test Epoch78 layer0 out_loss 0.00403450895100832\n",
      "Test Epoch78 layer1 out_loss 0.0007849875837564468\n",
      "Test Epoch78 layer2 out_loss 0.0007215128862299025\n",
      "Test Epoch78 layer3 out_loss 0.0005725115770474076\n",
      "Test Epoch78 layer4 out_loss 0.0006127472152002156\n",
      "Test Epoch78 layer5 out_loss 0.0006440079305320978\n",
      "Train 79 | out_loss 0.0013351230882108212: 100%|█| 138/138 [00:00<00:00, 173.16i\n",
      "[[0.00034598 0.00937665]\n",
      " [0.00031564 0.00191417]\n",
      " [0.00040862 0.00097718]\n",
      " [0.00024199 0.00038438]\n",
      " [0.00016262 0.00017074]\n",
      " [0.00013803 0.00012321]]\n",
      "Train Epoch79 out_loss 0.0013351230882108212\n",
      "Test Epoch79 layer0 out_loss 0.001728506525978446\n",
      "Test Epoch79 layer1 out_loss 0.0005423355614766479\n",
      "Test Epoch79 layer2 out_loss 0.00044293596874922514\n",
      "Test Epoch79 layer3 out_loss 0.00042080425191670656\n",
      "Test Epoch79 layer4 out_loss 0.0004158240626566112\n",
      "Test Epoch79 layer5 out_loss 0.00042229308746755123\n",
      "Train 80 | out_loss 0.0015896166441962123: 100%|█| 138/138 [00:00<00:00, 183.10i\n",
      "[[0.00049103 0.02828149]\n",
      " [0.00045438 0.0023331 ]\n",
      " [0.00069939 0.00156472]\n",
      " [0.00039361 0.00061478]\n",
      " [0.00025568 0.00026465]\n",
      " [0.00020531 0.00023213]]\n",
      "Train Epoch80 out_loss 0.0015896166441962123\n",
      "Test Epoch80 layer0 out_loss 0.009403292089700699\n",
      "Test Epoch80 layer1 out_loss 0.0013778489083051682\n",
      "Test Epoch80 layer2 out_loss 0.0005330251296982169\n",
      "Test Epoch80 layer3 out_loss 0.0004101870290469378\n",
      "Test Epoch80 layer4 out_loss 0.00041218200931325555\n",
      "Test Epoch80 layer5 out_loss 0.0004148604639340192\n",
      "Train 81 | out_loss 0.0016281778225675225: 100%|█| 138/138 [00:00<00:00, 176.14i\n",
      "[[0.00056513 0.04751378]\n",
      " [0.00039728 0.00319967]\n",
      " [0.00045768 0.00123423]\n",
      " [0.00026841 0.00051411]\n",
      " [0.00017239 0.0002455 ]\n",
      " [0.00013191 0.00016664]]\n",
      "Train Epoch81 out_loss 0.0016281778225675225\n",
      "Test Epoch81 layer0 out_loss 0.0040884860791265965\n",
      "Test Epoch81 layer1 out_loss 0.0007037046016193926\n",
      "Test Epoch81 layer2 out_loss 0.0004977937787771225\n",
      "Test Epoch81 layer3 out_loss 0.0004604724235832691\n",
      "Test Epoch81 layer4 out_loss 0.0004450890119187534\n",
      "Test Epoch81 layer5 out_loss 0.0004505810793489218\n",
      "Train 82 | out_loss 0.0009125101496465504: 100%|█| 138/138 [00:00<00:00, 178.68i\n",
      "[[0.00014172 0.02202458]\n",
      " [0.00038661 0.00207616]\n",
      " [0.00057179 0.00100435]\n",
      " [0.00029045 0.00050384]\n",
      " [0.0002134  0.00021928]\n",
      " [0.00016169 0.00013818]]\n",
      "Train Epoch82 out_loss 0.0009125101496465504\n",
      "Test Epoch82 layer0 out_loss 0.00871998444199562\n",
      "Test Epoch82 layer1 out_loss 0.0060350773856043816\n",
      "Test Epoch82 layer2 out_loss 0.003884027013555169\n",
      "Test Epoch82 layer3 out_loss 0.003981317859143019\n",
      "Test Epoch82 layer4 out_loss 0.004106175620108843\n",
      "Test Epoch82 layer5 out_loss 0.004101538099348545\n",
      "Train 83 | out_loss 0.0013357987627387047: 100%|█| 138/138 [00:00<00:00, 180.07i\n",
      "[[0.0004671  0.03442388]\n",
      " [0.00032727 0.00277934]\n",
      " [0.00047833 0.00118081]\n",
      " [0.00033501 0.00056842]\n",
      " [0.00023798 0.00029594]\n",
      " [0.0001885  0.00021403]]\n",
      "Train Epoch83 out_loss 0.0013357987627387047\n",
      "Test Epoch83 layer0 out_loss 0.0036758959759026766\n",
      "Test Epoch83 layer1 out_loss 0.003146308707073331\n",
      "Test Epoch83 layer2 out_loss 0.0024209115654230118\n",
      "Test Epoch83 layer3 out_loss 0.0025972998701035976\n",
      "Test Epoch83 layer4 out_loss 0.0025277542881667614\n",
      "Test Epoch83 layer5 out_loss 0.002546036383137107\n",
      "Train 84 | out_loss 0.0007868031389079988: 100%|█| 138/138 [00:00<00:00, 179.97i\n",
      "[[0.00013179 0.00355279]\n",
      " [0.00042433 0.00136924]\n",
      " [0.00047996 0.00085558]\n",
      " [0.00031909 0.00037981]\n",
      " [0.000276   0.00030533]\n",
      " [0.00023775 0.00024058]]\n",
      "Train Epoch84 out_loss 0.0007868031389079988\n",
      "Test Epoch84 layer0 out_loss 0.004836730659008026\n",
      "Test Epoch84 layer1 out_loss 0.0034388054627925158\n",
      "Test Epoch84 layer2 out_loss 0.004177385475486517\n",
      "Test Epoch84 layer3 out_loss 0.0037034256383776665\n",
      "Test Epoch84 layer4 out_loss 0.003576482878997922\n",
      "Test Epoch84 layer5 out_loss 0.003574221394956112\n",
      "Train 85 | out_loss 0.0013404169585555792: 100%|█| 138/138 [00:00<00:00, 176.95i\n",
      "[[0.0004534  0.00316417]\n",
      " [0.00030005 0.00137329]\n",
      " [0.00042995 0.00096238]\n",
      " [0.00038011 0.00043279]\n",
      " [0.00041492 0.00037933]\n",
      " [0.00021064 0.0002008 ]]\n",
      "Train Epoch85 out_loss 0.0013404169585555792\n",
      "Test Epoch85 layer0 out_loss 0.005633579101413488\n",
      "Test Epoch85 layer1 out_loss 0.0005164375179447234\n",
      "Test Epoch85 layer2 out_loss 0.0004969765432178974\n",
      "Test Epoch85 layer3 out_loss 0.0005147296469658613\n",
      "Test Epoch85 layer4 out_loss 0.00055423763114959\n",
      "Test Epoch85 layer5 out_loss 0.0005369485588744283\n",
      "Train 86 | out_loss 0.001336598303169012: 100%|█| 138/138 [00:00<00:00, 179.26it\n",
      "[[0.00038107 0.01943776]\n",
      " [0.00037083 0.00272667]\n",
      " [0.00046208 0.00096935]\n",
      " [0.00024311 0.00040947]\n",
      " [0.00031624 0.00035252]\n",
      " [0.00019785 0.00021189]]\n",
      "Train Epoch86 out_loss 0.001336598303169012\n",
      "Test Epoch86 layer0 out_loss 0.0023518025409430265\n",
      "Test Epoch86 layer1 out_loss 0.0011359148193150759\n",
      "Test Epoch86 layer2 out_loss 0.0005213989061303437\n",
      "Test Epoch86 layer3 out_loss 0.0005129510536789894\n",
      "Test Epoch86 layer4 out_loss 0.0005254402058199048\n",
      "Test Epoch86 layer5 out_loss 0.0004879098851233721\n",
      "Train 87 | out_loss 0.0014509472530335188: 100%|█| 138/138 [00:00<00:00, 180.69i\n",
      "[[0.00043594 0.01205469]\n",
      " [0.00039082 0.00210048]\n",
      " [0.00071628 0.00178839]\n",
      " [0.00050263 0.00072198]\n",
      " [0.00031585 0.00038283]\n",
      " [0.00025526 0.00025949]]\n",
      "Train Epoch87 out_loss 0.0014509472530335188\n",
      "Test Epoch87 layer0 out_loss 0.013161348178982735\n",
      "Test Epoch87 layer1 out_loss 0.000623682513833046\n",
      "Test Epoch87 layer2 out_loss 0.00042325910180807114\n",
      "Test Epoch87 layer3 out_loss 0.0004052516305819154\n",
      "Test Epoch87 layer4 out_loss 0.00040954709402285516\n",
      "Test Epoch87 layer5 out_loss 0.00040682120015844703\n",
      "Train 88 | out_loss 0.0013841703766956925: 100%|█| 138/138 [00:00<00:00, 180.94i\n",
      "[[0.00035852 0.01026328]\n",
      " [0.00042698 0.00207099]\n",
      " [0.00058513 0.00093515]\n",
      " [0.00028242 0.00033569]\n",
      " [0.00017853 0.00018283]\n",
      " [0.00013498 0.00013389]]\n",
      "Train Epoch88 out_loss 0.0013841703766956925\n",
      "Test Epoch88 layer0 out_loss 0.0036007878370583057\n",
      "Test Epoch88 layer1 out_loss 0.0005922988057136536\n",
      "Test Epoch88 layer2 out_loss 0.00041457064799033105\n",
      "Test Epoch88 layer3 out_loss 0.0004221577837597579\n",
      "Test Epoch88 layer4 out_loss 0.0004306542396079749\n",
      "Test Epoch88 layer5 out_loss 0.00043107502278871834\n",
      "Train 89 | out_loss 0.0013284118613228202: 100%|█| 138/138 [00:00<00:00, 165.34i\n",
      "[[0.00042051 0.02867951]\n",
      " [0.00032571 0.00280557]\n",
      " [0.00042657 0.00105432]\n",
      " [0.00028815 0.00048845]\n",
      " [0.00022481 0.00029501]\n",
      " [0.00021272 0.00022077]]\n",
      "Train Epoch89 out_loss 0.0013284118613228202\n",
      "Test Epoch89 layer0 out_loss 0.009215171448886395\n",
      "Test Epoch89 layer1 out_loss 0.0008943838765844703\n",
      "Test Epoch89 layer2 out_loss 0.0004044293309561908\n",
      "Test Epoch89 layer3 out_loss 0.00040802298462949693\n",
      "Test Epoch89 layer4 out_loss 0.00041318361763842404\n",
      "Test Epoch89 layer5 out_loss 0.0004099355428479612\n",
      "Train 90 | out_loss 0.0014300929615274072: 100%|█| 138/138 [00:00<00:00, 175.69i\n",
      "[[0.00042869 0.01513731]\n",
      " [0.00028676 0.0022475 ]\n",
      " [0.00032728 0.00083788]\n",
      " [0.00028195 0.00044357]\n",
      " [0.00023413 0.00030234]\n",
      " [0.00024628 0.00023559]]\n",
      "Train Epoch90 out_loss 0.0014300929615274072\n",
      "Test Epoch90 layer0 out_loss 0.0032713108230382204\n",
      "Test Epoch90 layer1 out_loss 0.0012686082627624273\n",
      "Test Epoch90 layer2 out_loss 0.0013080177595838904\n",
      "Test Epoch90 layer3 out_loss 0.0014242606703191996\n",
      "Test Epoch90 layer4 out_loss 0.0013593698386102915\n",
      "Test Epoch90 layer5 out_loss 0.001403141301125288\n",
      "Train 91 | out_loss 0.0007302315207198262: 100%|█| 138/138 [00:00<00:00, 176.78i\n",
      "[[6.79862947e-05 3.69348989e-03]\n",
      " [3.30373061e-04 1.26285374e-03]\n",
      " [4.00202604e-04 5.65894156e-04]\n",
      " [3.00207901e-04 3.59574551e-04]\n",
      " [2.06982283e-04 2.26085093e-04]\n",
      " [2.30240357e-04 2.13753636e-04]]\n",
      "Train Epoch91 out_loss 0.0007302315207198262\n",
      "Test Epoch91 layer0 out_loss 0.002465492347255349\n",
      "Test Epoch91 layer1 out_loss 0.0006331650074571371\n",
      "Test Epoch91 layer2 out_loss 0.0007850154070183635\n",
      "Test Epoch91 layer3 out_loss 0.0006252831663005054\n",
      "Test Epoch91 layer4 out_loss 0.0005810863804072142\n",
      "Test Epoch91 layer5 out_loss 0.0005857610958628356\n",
      "Train 92 | out_loss 0.0015150276012718678: 100%|█| 138/138 [00:00<00:00, 178.79i\n",
      "[[0.00050573 0.00959006]\n",
      " [0.00041784 0.00212342]\n",
      " [0.00063478 0.00120455]\n",
      " [0.0004042  0.00043615]\n",
      " [0.00023725 0.00023423]\n",
      " [0.00030288 0.00027388]]\n",
      "Train Epoch92 out_loss 0.0015150276012718678\n",
      "Test Epoch92 layer0 out_loss 0.013958594761788845\n",
      "Test Epoch92 layer1 out_loss 0.0005675043794326484\n",
      "Test Epoch92 layer2 out_loss 0.000912398798391223\n",
      "Test Epoch92 layer3 out_loss 0.0004924891982227564\n",
      "Test Epoch92 layer4 out_loss 0.0006531746475957334\n",
      "Test Epoch92 layer5 out_loss 0.0006466201739385724\n",
      "Train 93 | out_loss 0.0013944045640528202: 100%|█| 138/138 [00:00<00:00, 181.80i\n",
      "[[0.00042645 0.02819257]\n",
      " [0.00026472 0.00398767]\n",
      " [0.00040835 0.00247645]\n",
      " [0.0004652  0.0011439 ]\n",
      " [0.00065847 0.00100335]\n",
      " [0.00074093 0.00119431]]\n",
      "Train Epoch93 out_loss 0.0013944045640528202\n",
      "Test Epoch93 layer0 out_loss 0.001607273006811738\n",
      "Test Epoch93 layer1 out_loss 0.0007633983041159809\n",
      "Test Epoch93 layer2 out_loss 0.00069218291901052\n",
      "Test Epoch93 layer3 out_loss 0.000594231067225337\n",
      "Test Epoch93 layer4 out_loss 0.0005393840256147087\n",
      "Test Epoch93 layer5 out_loss 0.000557745632249862\n",
      "Train 94 | out_loss 0.0013576846104115248: 100%|█| 138/138 [00:00<00:00, 172.69i\n",
      "[[4.69027126e-04 3.07184408e-02]\n",
      " [3.08656729e-04 3.08809120e-03]\n",
      " [4.22910575e-04 9.74762492e-04]\n",
      " [2.29866325e-04 3.72723917e-04]\n",
      " [1.42444772e-04 1.71930318e-04]\n",
      " [8.96104691e-05 8.47693559e-05]]\n",
      "Train Epoch94 out_loss 0.0013576846104115248\n",
      "Test Epoch94 layer0 out_loss 0.0018614173168316483\n",
      "Test Epoch94 layer1 out_loss 0.0019202724797651172\n",
      "Test Epoch94 layer2 out_loss 0.0015808527823537588\n",
      "Test Epoch94 layer3 out_loss 0.0014828471466898918\n",
      "Test Epoch94 layer4 out_loss 0.0014435792108997703\n",
      "Test Epoch94 layer5 out_loss 0.0014708269154652953\n",
      "Train 95 | out_loss 0.0007359052542597055: 100%|█| 138/138 [00:00<00:00, 169.81i\n",
      "[[8.17383182e-05 4.84098999e-03]\n",
      " [2.64056240e-04 1.00353625e-03]\n",
      " [3.54924761e-04 4.05168877e-04]\n",
      " [1.63444562e-04 1.89763656e-04]\n",
      " [1.42992173e-04 1.41782154e-04]\n",
      " [1.41469951e-04 1.05545211e-04]]\n",
      "Train Epoch95 out_loss 0.0007359052542597055\n",
      "Test Epoch95 layer0 out_loss 0.0016124697867780924\n",
      "Test Epoch95 layer1 out_loss 0.0007238281541503966\n",
      "Test Epoch95 layer2 out_loss 0.00047665880993008614\n",
      "Test Epoch95 layer3 out_loss 0.00046158244367688894\n",
      "Test Epoch95 layer4 out_loss 0.0004659566911868751\n",
      "Test Epoch95 layer5 out_loss 0.00046273370389826596\n",
      "Train 96 | out_loss 0.0015882994048297405: 100%|█| 138/138 [00:00<00:00, 183.29i\n",
      "[[0.00053798 0.00534924]\n",
      " [0.00038827 0.00148908]\n",
      " [0.00068626 0.00165242]\n",
      " [0.00060292 0.00066016]\n",
      " [0.0006429  0.00058171]\n",
      " [0.00045074 0.00035736]]\n",
      "Train Epoch96 out_loss 0.0015882994048297405\n",
      "Test Epoch96 layer0 out_loss 0.0026441668160259724\n",
      "Test Epoch96 layer1 out_loss 0.0007222119020298123\n",
      "Test Epoch96 layer2 out_loss 0.0004518024798016995\n",
      "Test Epoch96 layer3 out_loss 0.0004109466390218586\n",
      "Test Epoch96 layer4 out_loss 0.0004164556448813528\n",
      "Test Epoch96 layer5 out_loss 0.00041652884101495147\n",
      "Train 97 | out_loss 0.006989127956330776: 100%|█| 138/138 [00:00<00:00, 178.17it\n",
      "[[0.00041997 0.00849017]\n",
      " [0.01712459 0.09309714]\n",
      " [0.03977645 0.11237242]\n",
      " [0.06949639 0.11786626]\n",
      " [0.09954585 0.14014877]\n",
      " [0.11610206 0.15256918]]\n",
      "Train Epoch97 out_loss 0.006989127956330776\n",
      "Test Epoch97 layer0 out_loss 0.004384271334856749\n",
      "Test Epoch97 layer1 out_loss 0.018084023147821426\n",
      "Test Epoch97 layer2 out_loss 0.004684039391577244\n",
      "Test Epoch97 layer3 out_loss 0.004272405058145523\n",
      "Test Epoch97 layer4 out_loss 0.0009832617361098528\n",
      "Test Epoch97 layer5 out_loss 0.013396048918366432\n",
      "Train 98 | out_loss 0.007416378241032362: 100%|█| 138/138 [00:00<00:00, 176.21it\n",
      "[[6.54555679e-05 1.54651598e-02]\n",
      " [8.86908653e-03 6.02698056e-02]\n",
      " [4.12119106e-02 1.02784093e-01]\n",
      " [8.20120713e-02 1.79219450e-01]\n",
      " [1.64972154e-01 2.97516574e-01]\n",
      " [2.25425464e-01 4.02654895e-01]]\n",
      "Train Epoch98 out_loss 0.007416378241032362\n",
      "Test Epoch98 layer0 out_loss 0.002969239139929414\n",
      "Test Epoch98 layer1 out_loss 0.0005603934405371547\n",
      "Test Epoch98 layer2 out_loss 0.0004893752629868686\n",
      "Test Epoch98 layer3 out_loss 0.0005237366422079504\n",
      "Test Epoch98 layer4 out_loss 0.00045717263128608465\n",
      "Test Epoch98 layer5 out_loss 0.000435458030551672\n",
      "Train 99 | out_loss 0.0015866979956626892: 100%|█| 138/138 [00:00<00:00, 177.82i\n",
      "[[3.90275238e-04 6.60981822e-03]\n",
      " [4.38665496e-06 5.05468273e-04]\n",
      " [1.92419943e-06 4.29472302e-04]\n",
      " [1.14993078e-05 4.70411753e-04]\n",
      " [3.21175351e-05 5.02677874e-04]\n",
      " [3.65690473e-05 6.44217643e-04]]\n",
      "Train Epoch99 out_loss 0.0015866979956626892\n",
      "Test Epoch99 layer0 out_loss 0.0014292160049080849\n",
      "Test Epoch99 layer1 out_loss 0.0006682219100184739\n",
      "Test Epoch99 layer2 out_loss 0.0004350935632828623\n",
      "Test Epoch99 layer3 out_loss 0.0004712298687081784\n",
      "Test Epoch99 layer4 out_loss 0.00042457450763322413\n",
      "Test Epoch99 layer5 out_loss 0.0003857018891721964\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Start Training\n",
      "  0%|                                                   | 0/138 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 0.04499353840947151: 100%|█| 138/138 [00:01<00:00, 109.56it/s\n",
      "[[ 0.83551611 28.33964567]\n",
      " [ 1.36062511 11.44785361]\n",
      " [ 0.92050755  4.82284237]\n",
      " [ 0.76342615  2.6132792 ]\n",
      " [ 0.67003212  1.5961833 ]\n",
      " [ 0.57883713  1.21434192]\n",
      " [ 0.59546544  0.88889005]]\n",
      "Train Epoch0 out_loss 0.04499353840947151\n",
      "Test Epoch0 layer0 out_loss 0.15552276372909546\n",
      "Test Epoch0 layer1 out_loss 0.016627298668026924\n",
      "Test Epoch0 layer2 out_loss 0.004767211154103279\n",
      "Test Epoch0 layer3 out_loss 0.0022721856366842985\n",
      "Test Epoch0 layer4 out_loss 0.0023551739286631346\n",
      "Test Epoch0 layer5 out_loss 0.0006184516241773963\n",
      "Test Epoch0 layer6 out_loss 0.0015126308426260948\n",
      "Train 1 | out_loss 0.0006085108034312725: 100%|█| 138/138 [00:00<00:00, 157.77it\n",
      "[[1.19447426e-05 5.40955310e+00]\n",
      " [7.31053982e-06 2.82890619e-01]\n",
      " [9.20717073e-06 9.11631088e-02]\n",
      " [1.21383197e-04 3.31524318e-02]\n",
      " [8.63290641e-04 1.36704425e-02]\n",
      " [2.91680034e-03 1.07504435e-02]\n",
      " [1.04899592e-02 1.44174479e-02]]\n",
      "Train Epoch1 out_loss 0.0006085108034312725\n",
      "Test Epoch1 layer0 out_loss 0.0523807629942894\n",
      "Test Epoch1 layer1 out_loss 0.010888384655117989\n",
      "Test Epoch1 layer2 out_loss 0.0025026004295796156\n",
      "Test Epoch1 layer3 out_loss 0.0011055804789066315\n",
      "Test Epoch1 layer4 out_loss 0.0006743783596903086\n",
      "Test Epoch1 layer5 out_loss 0.000451510219136253\n",
      "Test Epoch1 layer6 out_loss 0.0004518692148849368\n",
      "Train 2 | out_loss 0.0004447905230335891: 100%|█| 138/138 [00:00<00:00, 153.47it\n",
      "[[1.14161666e-05 2.82702022e+00]\n",
      " [9.90663750e-06 1.14337481e-01]\n",
      " [1.81898827e-06 3.39580560e-02]\n",
      " [9.27318348e-07 1.13561551e-02]\n",
      " [1.32069727e-06 4.35275997e-03]\n",
      " [1.77130802e-06 1.97837234e-03]\n",
      " [2.59343209e-06 9.95486280e-04]]\n",
      "Train Epoch2 out_loss 0.0004447905230335891\n",
      "Test Epoch2 layer0 out_loss 0.03176604211330414\n",
      "Test Epoch2 layer1 out_loss 0.01023594569414854\n",
      "Test Epoch2 layer2 out_loss 0.0020352050196379423\n",
      "Test Epoch2 layer3 out_loss 0.0009163080831058323\n",
      "Test Epoch2 layer4 out_loss 0.0005623094039037824\n",
      "Test Epoch2 layer5 out_loss 0.0004224414296913892\n",
      "Test Epoch2 layer6 out_loss 0.00043857211130671203\n",
      "Train 3 | out_loss 0.0004397665325086564: 100%|█| 138/138 [00:00<00:00, 152.48it\n",
      "[[1.14621801e-05 1.89769228e+00]\n",
      " [1.02476562e-05 6.28407159e-02]\n",
      " [1.97162225e-06 1.75028932e-02]\n",
      " [1.37544727e-06 5.95189267e-03]\n",
      " [2.00634917e-06 2.53056816e-03]\n",
      " [5.51091772e-06 1.23217758e-03]\n",
      " [8.21694827e-06 6.83319615e-04]]\n",
      "Train Epoch3 out_loss 0.0004397665325086564\n",
      "Test Epoch3 layer0 out_loss 0.03217293322086334\n",
      "Test Epoch3 layer1 out_loss 0.004908964037895203\n",
      "Test Epoch3 layer2 out_loss 0.0014661590103060007\n",
      "Test Epoch3 layer3 out_loss 0.0008264965144917369\n",
      "Test Epoch3 layer4 out_loss 0.0006035506376065314\n",
      "Test Epoch3 layer5 out_loss 0.0004546818963717669\n",
      "Test Epoch3 layer6 out_loss 0.000459932693047449\n",
      "Train 4 | out_loss 0.0004485365061555058: 100%|█| 138/138 [00:00<00:00, 154.12it\n",
      "[[1.14844166e-05 1.85004573e+00]\n",
      " [1.41717010e-05 4.68901834e-02]\n",
      " [2.12934312e-06 1.14678225e-02]\n",
      " [1.94072519e-06 4.04353182e-03]\n",
      " [4.15820297e-06 1.81779836e-03]\n",
      " [1.19348625e-05 8.75931021e-04]\n",
      " [1.63402813e-05 5.08082455e-04]]\n",
      "Train Epoch4 out_loss 0.0004485365061555058\n",
      "Test Epoch4 layer0 out_loss 0.06348934024572372\n",
      "Test Epoch4 layer1 out_loss 0.004913020879030228\n",
      "Test Epoch4 layer2 out_loss 0.0010204024147242308\n",
      "Test Epoch4 layer3 out_loss 0.0007559561636298895\n",
      "Test Epoch4 layer4 out_loss 0.00048183256876654923\n",
      "Test Epoch4 layer5 out_loss 0.00043984263902530074\n",
      "Test Epoch4 layer6 out_loss 0.00041778796003200114\n",
      "Train 5 | out_loss 0.00044257071567699313: 100%|█| 138/138 [00:00<00:00, 157.18i\n",
      "[[1.15062294e-05 1.66979710e+00]\n",
      " [1.43893124e-05 2.82539559e-02]\n",
      " [2.47143563e-06 7.36882796e-03]\n",
      " [3.04908840e-06 2.62990348e-03]\n",
      " [7.27728456e-06 1.30909340e-03]\n",
      " [1.89351233e-05 6.79310642e-04]\n",
      " [2.57652915e-05 3.95873769e-04]]\n",
      "Train Epoch5 out_loss 0.00044257071567699313\n",
      "Test Epoch5 layer0 out_loss 0.05464717000722885\n",
      "Test Epoch5 layer1 out_loss 0.0030092650558799505\n",
      "Test Epoch5 layer2 out_loss 0.000793313782196492\n",
      "Test Epoch5 layer3 out_loss 0.0006408548215404153\n",
      "Test Epoch5 layer4 out_loss 0.000481628580018878\n",
      "Test Epoch5 layer5 out_loss 0.00045494342339225113\n",
      "Test Epoch5 layer6 out_loss 0.00043736366205848753\n",
      "Train 6 | out_loss 0.0004458259209059179: 100%|█| 138/138 [00:00<00:00, 152.59it\n",
      "[[1.13510207e-05 7.48683587e-01]\n",
      " [2.17302915e-05 1.65724101e-02]\n",
      " [2.87282026e-06 4.72718492e-03]\n",
      " [3.89756999e-06 1.62284591e-03]\n",
      " [9.81148371e-06 8.38623888e-04]\n",
      " [3.51165476e-05 4.86659413e-04]\n",
      " [5.25129003e-05 3.13665775e-04]]\n",
      "Train Epoch6 out_loss 0.0004458259209059179\n",
      "Test Epoch6 layer0 out_loss 0.016280541196465492\n",
      "Test Epoch6 layer1 out_loss 0.002756877103820443\n",
      "Test Epoch6 layer2 out_loss 0.0007021629717200994\n",
      "Test Epoch6 layer3 out_loss 0.0005907985032536089\n",
      "Test Epoch6 layer4 out_loss 0.00041895732283592224\n",
      "Test Epoch6 layer5 out_loss 0.0004514276224654168\n",
      "Test Epoch6 layer6 out_loss 0.0004799905582331121\n",
      "Train 7 | out_loss 0.000447389465989545: 100%|█| 138/138 [00:00<00:00, 154.03it/\n",
      "[[1.10684506e-05 4.24972530e-01]\n",
      " [2.41355859e-05 1.12354739e-02]\n",
      " [3.28494778e-06 3.37246718e-03]\n",
      " [4.47835257e-06 1.12505263e-03]\n",
      " [1.62176093e-05 6.46668173e-04]\n",
      " [3.54297671e-05 3.88175861e-04]\n",
      " [4.88164451e-05 2.53378805e-04]]\n",
      "Train Epoch7 out_loss 0.000447389465989545\n",
      "Test Epoch7 layer0 out_loss 0.012754647992551327\n",
      "Test Epoch7 layer1 out_loss 0.002481489209458232\n",
      "Test Epoch7 layer2 out_loss 0.0007154691847972572\n",
      "Test Epoch7 layer3 out_loss 0.0005419501103460789\n",
      "Test Epoch7 layer4 out_loss 0.0004077597404830158\n",
      "Test Epoch7 layer5 out_loss 0.00041092836181633174\n",
      "Test Epoch7 layer6 out_loss 0.00040977488970384\n",
      "Train 8 | out_loss 0.0004420712066348642: 100%|█| 138/138 [00:00<00:00, 150.59it\n",
      "[[1.10744808e-05 2.61658968e-01]\n",
      " [2.54065827e-05 7.78744211e-03]\n",
      " [4.05592572e-06 2.46947350e-03]\n",
      " [7.13836312e-06 8.02541833e-04]\n",
      " [2.27602121e-05 4.39677868e-04]\n",
      " [5.74598386e-05 2.87258654e-04]\n",
      " [8.15551842e-05 2.19822285e-04]]\n",
      "Train Epoch8 out_loss 0.0004420712066348642\n",
      "Test Epoch8 layer0 out_loss 0.012316807173192501\n",
      "Test Epoch8 layer1 out_loss 0.0021252580918371677\n",
      "Test Epoch8 layer2 out_loss 0.0006344147841446102\n",
      "Test Epoch8 layer3 out_loss 0.0004942200612276793\n",
      "Test Epoch8 layer4 out_loss 0.00040942299528978765\n",
      "Test Epoch8 layer5 out_loss 0.0004115574702154845\n",
      "Test Epoch8 layer6 out_loss 0.0004116823256481439\n",
      "Train 9 | out_loss 0.0004484224773477763: 100%|█| 138/138 [00:00<00:00, 153.63it\n",
      "[[1.08507531e-05 9.21884683e-01]\n",
      " [3.22108604e-05 8.78160947e-03]\n",
      " [5.43699130e-06 2.41428838e-03]\n",
      " [7.52219628e-06 7.53095248e-04]\n",
      " [1.58307550e-05 3.99086455e-04]\n",
      " [4.03396506e-05 2.51706866e-04]\n",
      " [5.70745107e-05 1.80250099e-04]]\n",
      "Train Epoch9 out_loss 0.0004484224773477763\n",
      "Test Epoch9 layer0 out_loss 0.020477397367358208\n",
      "Test Epoch9 layer1 out_loss 0.002079743891954422\n",
      "Test Epoch9 layer2 out_loss 0.00055792520288378\n",
      "Test Epoch9 layer3 out_loss 0.0005214313277974725\n",
      "Test Epoch9 layer4 out_loss 0.0004285623726900667\n",
      "Test Epoch9 layer5 out_loss 0.00043116798042319715\n",
      "Test Epoch9 layer6 out_loss 0.00043197988998144865\n",
      "Train 10 | out_loss 0.0004637148231267929: 100%|█| 138/138 [00:00<00:00, 155.84i\n",
      "[[1.06916307e-05 3.83993672e-01]\n",
      " [3.64946774e-05 5.42709260e-03]\n",
      " [7.39675265e-06 1.73215339e-03]\n",
      " [1.08507423e-05 5.62686093e-04]\n",
      " [3.53031193e-05 2.95826611e-04]\n",
      " [4.03132487e-05 1.92267803e-04]\n",
      " [5.54588201e-05 1.43444696e-04]]\n",
      "Train Epoch10 out_loss 0.0004637148231267929\n",
      "Test Epoch10 layer0 out_loss 0.03165173903107643\n",
      "Test Epoch10 layer1 out_loss 0.0018002886790782213\n",
      "Test Epoch10 layer2 out_loss 0.0005276292795315385\n",
      "Test Epoch10 layer3 out_loss 0.0005463560810312629\n",
      "Test Epoch10 layer4 out_loss 0.0005094377556815743\n",
      "Test Epoch10 layer5 out_loss 0.0005209703231230378\n",
      "Test Epoch10 layer6 out_loss 0.0005074957734905183\n",
      "Train 11 | out_loss 0.00046701845712959766: 100%|█| 138/138 [00:00<00:00, 157.74\n",
      "[[1.10053886e-05 4.99438662e-01]\n",
      " [4.16969653e-05 5.15339484e-03]\n",
      " [1.09481891e-05 1.58192247e-03]\n",
      " [1.68884768e-05 5.11180349e-04]\n",
      " [3.79765196e-05 2.88409594e-04]\n",
      " [8.50806526e-05 1.98832413e-04]\n",
      " [1.15095223e-04 2.13996363e-04]]\n",
      "Train Epoch11 out_loss 0.00046701845712959766\n",
      "Test Epoch11 layer0 out_loss 0.0190111193805933\n",
      "Test Epoch11 layer1 out_loss 0.0015355199575424194\n",
      "Test Epoch11 layer2 out_loss 0.0005662154289893806\n",
      "Test Epoch11 layer3 out_loss 0.0004830314719583839\n",
      "Test Epoch11 layer4 out_loss 0.0004063438391312957\n",
      "Test Epoch11 layer5 out_loss 0.00040714495116844773\n",
      "Test Epoch11 layer6 out_loss 0.00040954467840492725\n",
      "Train 12 | out_loss 0.0004759338335134089: 100%|█| 138/138 [00:00<00:00, 160.07i\n",
      "[[1.05116025e-05 6.15986450e-01]\n",
      " [4.68806815e-05 5.10928846e-03]\n",
      " [8.70222535e-05 1.51091521e-03]\n",
      " [8.56774726e-05 5.48180628e-04]\n",
      " [7.23022848e-05 3.64175454e-04]\n",
      " [1.41546437e-04 2.49709294e-04]\n",
      " [1.88057440e-04 2.60618931e-04]]\n",
      "Train Epoch12 out_loss 0.0004759338335134089\n",
      "Test Epoch12 layer0 out_loss 0.016947055235505104\n",
      "Test Epoch12 layer1 out_loss 0.0015123410848900676\n",
      "Test Epoch12 layer2 out_loss 0.0005165504990145564\n",
      "Test Epoch12 layer3 out_loss 0.0005262783961370587\n",
      "Test Epoch12 layer4 out_loss 0.00040585474926047027\n",
      "Test Epoch12 layer5 out_loss 0.00040796236135065556\n",
      "Test Epoch12 layer6 out_loss 0.0004353865224402398\n",
      "Train 13 | out_loss 0.00047897512558847666: 100%|█| 138/138 [00:00<00:00, 153.24\n",
      "[[1.04948935e-05 3.58741447e-01]\n",
      " [7.21887048e-05 3.63983101e-03]\n",
      " [4.12892009e-04 1.33423185e-03]\n",
      " [4.49199978e-04 7.28514332e-04]\n",
      " [2.33892074e-04 4.55926706e-04]\n",
      " [3.13728656e-04 2.82257852e-04]\n",
      " [3.22837433e-04 2.75211735e-04]]\n",
      "Train Epoch13 out_loss 0.00047897512558847666\n",
      "Test Epoch13 layer0 out_loss 0.009103664197027683\n",
      "Test Epoch13 layer1 out_loss 0.001290008658543229\n",
      "Test Epoch13 layer2 out_loss 0.0005222241161391139\n",
      "Test Epoch13 layer3 out_loss 0.0005126653704792261\n",
      "Test Epoch13 layer4 out_loss 0.00041246964246965945\n",
      "Test Epoch13 layer5 out_loss 0.00042176811257377267\n",
      "Test Epoch13 layer6 out_loss 0.00043171498691663146\n",
      "Train 14 | out_loss 0.0005319294868968427: 100%|█| 138/138 [00:00<00:00, 155.36i\n",
      "[[1.04623309e-05 1.38813225e-01]\n",
      " [1.44725196e-04 2.89033659e-03]\n",
      " [1.01371034e-03 1.34899863e-03]\n",
      " [8.49199042e-04 1.08149385e-03]\n",
      " [4.22988216e-04 6.76085784e-04]\n",
      " [7.11989465e-04 4.51839670e-04]\n",
      " [6.86952613e-04 5.94051399e-04]]\n",
      "Train Epoch14 out_loss 0.0005319294868968427\n",
      "Test Epoch14 layer0 out_loss 0.014664596877992153\n",
      "Test Epoch14 layer1 out_loss 0.0011146588949486613\n",
      "Test Epoch14 layer2 out_loss 0.0005288150277920067\n",
      "Test Epoch14 layer3 out_loss 0.0006488467333838344\n",
      "Test Epoch14 layer4 out_loss 0.0005289533291943371\n",
      "Test Epoch14 layer5 out_loss 0.0004876418097410351\n",
      "Test Epoch14 layer6 out_loss 0.0005693520070053637\n",
      "Train 15 | out_loss 0.0004643651773221791: 100%|█| 138/138 [00:00<00:00, 157.50i\n",
      "[[9.83747211e-06 2.33849456e-01]\n",
      " [1.07142257e-04 3.12228638e-03]\n",
      " [5.64582091e-04 1.17853716e-03]\n",
      " [3.30968638e-04 6.89485384e-04]\n",
      " [1.86605211e-04 3.62619282e-04]\n",
      " [3.05741155e-04 2.38296944e-04]\n",
      " [2.83115952e-04 2.97736211e-04]]\n",
      "Train Epoch15 out_loss 0.0004643651773221791\n",
      "Test Epoch15 layer0 out_loss 0.042572375386953354\n",
      "Test Epoch15 layer1 out_loss 0.001345479628071189\n",
      "Test Epoch15 layer2 out_loss 0.00046506430953741074\n",
      "Test Epoch15 layer3 out_loss 0.0005745295784436166\n",
      "Test Epoch15 layer4 out_loss 0.0004913484444841743\n",
      "Test Epoch15 layer5 out_loss 0.0005346729303710163\n",
      "Test Epoch15 layer6 out_loss 0.0005340229254215956\n",
      "Train 16 | out_loss 0.0004792308318428695: 100%|█| 138/138 [00:00<00:00, 151.92i\n",
      "[[1.00048371e-05 3.94002393e-01]\n",
      " [1.41120291e-04 3.71261102e-03]\n",
      " [5.46177676e-04 1.19812361e-03]\n",
      " [2.73917071e-04 6.86416693e-04]\n",
      " [2.22141994e-04 3.76006149e-04]\n",
      " [4.31118207e-04 3.38151230e-04]\n",
      " [4.23474035e-04 4.65638348e-04]]\n",
      "Train Epoch16 out_loss 0.0004792308318428695\n",
      "Test Epoch16 layer0 out_loss 0.06566725671291351\n",
      "Test Epoch16 layer1 out_loss 0.0024059428833425045\n",
      "Test Epoch16 layer2 out_loss 0.000609524839092046\n",
      "Test Epoch16 layer3 out_loss 0.0004963820101693273\n",
      "Test Epoch16 layer4 out_loss 0.0004896327154710889\n",
      "Test Epoch16 layer5 out_loss 0.00043739608372561634\n",
      "Test Epoch16 layer6 out_loss 0.00043611254659481347\n",
      "Train 17 | out_loss 0.0004994319751858711: 100%|█| 138/138 [00:00<00:00, 158.07i\n",
      "[[9.59996161e-06 6.22117061e-01]\n",
      " [1.75833114e-04 5.04132740e-03]\n",
      " [7.66683437e-04 1.74433333e-03]\n",
      " [3.33184840e-04 1.01411923e-03]\n",
      " [3.47355493e-04 6.68238282e-04]\n",
      " [5.78641454e-04 5.46035670e-04]\n",
      " [5.59774479e-04 8.75066405e-04]]\n",
      "Train Epoch17 out_loss 0.0004994319751858711\n",
      "Test Epoch17 layer0 out_loss 0.03654913604259491\n",
      "Test Epoch17 layer1 out_loss 0.001814197632484138\n",
      "Test Epoch17 layer2 out_loss 0.0006168526597321033\n",
      "Test Epoch17 layer3 out_loss 0.0005718126776628196\n",
      "Test Epoch17 layer4 out_loss 0.0007788146031089127\n",
      "Test Epoch17 layer5 out_loss 0.0007003503269515932\n",
      "Test Epoch17 layer6 out_loss 0.000596987025346607\n",
      "Train 18 | out_loss 0.00045757071347907186: 100%|█| 138/138 [00:00<00:00, 149.66\n",
      "[[9.76879683e-06 2.16242024e-01]\n",
      " [2.54753687e-04 2.83551764e-03]\n",
      " [6.98243357e-04 1.20417919e-03]\n",
      " [3.24854960e-04 7.95244550e-04]\n",
      " [5.47907460e-04 7.01228321e-04]\n",
      " [3.75416935e-04 4.81078765e-04]\n",
      " [3.75394734e-04 3.93563425e-04]]\n",
      "Train Epoch18 out_loss 0.00045757071347907186\n",
      "Test Epoch18 layer0 out_loss 0.044087041169404984\n",
      "Test Epoch18 layer1 out_loss 0.002325118286535144\n",
      "Test Epoch18 layer2 out_loss 0.0008874097256921232\n",
      "Test Epoch18 layer3 out_loss 0.0006904490292072296\n",
      "Test Epoch18 layer4 out_loss 0.0007731679943390191\n",
      "Test Epoch18 layer5 out_loss 0.0007019502227194607\n",
      "Test Epoch18 layer6 out_loss 0.0006894842954352498\n",
      "Train 19 | out_loss 0.0004456106689758599: 100%|█| 138/138 [00:00<00:00, 157.85i\n",
      "[[9.10771862e-06 7.87003826e-02]\n",
      " [2.10793561e-04 2.09914569e-03]\n",
      " [5.81598833e-04 9.53262373e-04]\n",
      " [2.34406667e-04 5.78707356e-04]\n",
      " [4.95115231e-04 4.29194075e-04]\n",
      " [3.79843625e-04 3.61636451e-04]\n",
      " [3.47421059e-04 3.76738025e-04]]\n",
      "Train Epoch19 out_loss 0.0004456106689758599\n",
      "Test Epoch19 layer0 out_loss 0.01395114604383707\n",
      "Test Epoch19 layer1 out_loss 0.0011803526431322098\n",
      "Test Epoch19 layer2 out_loss 0.00048581892042420805\n",
      "Test Epoch19 layer3 out_loss 0.000570557895116508\n",
      "Test Epoch19 layer4 out_loss 0.0005050507024861872\n",
      "Test Epoch19 layer5 out_loss 0.0005101586575619876\n",
      "Test Epoch19 layer6 out_loss 0.00044854177394881845\n",
      "Train 20 | out_loss 0.00047885411186143756: 100%|█| 138/138 [00:00<00:00, 155.94\n",
      "[[8.86238166e-06 1.03658794e-01]\n",
      " [4.36224516e-04 2.07291736e-03]\n",
      " [1.09297767e-03 1.14242433e-03]\n",
      " [4.70392761e-04 8.00027997e-04]\n",
      " [1.02711216e-03 6.20268347e-04]\n",
      " [5.82598521e-04 5.95977495e-04]\n",
      " [5.67037812e-04 5.64586687e-04]]\n",
      "Train Epoch20 out_loss 0.00047885411186143756\n",
      "Test Epoch20 layer0 out_loss 0.023939751088619232\n",
      "Test Epoch20 layer1 out_loss 0.001077056396752596\n",
      "Test Epoch20 layer2 out_loss 0.00046894175466150045\n",
      "Test Epoch20 layer3 out_loss 0.00046861651935614645\n",
      "Test Epoch20 layer4 out_loss 0.0004310971708036959\n",
      "Test Epoch20 layer5 out_loss 0.0004267828771844506\n",
      "Test Epoch20 layer6 out_loss 0.00042004024726338685\n",
      "Train 21 | out_loss 0.00043986327364109457: 100%|█| 138/138 [00:00<00:00, 153.77\n",
      "[[8.83191889e-06 4.93258838e-01]\n",
      " [2.52341453e-04 3.00390641e-03]\n",
      " [3.73276754e-04 1.06385696e-03]\n",
      " [3.76225433e-04 7.07872400e-04]\n",
      " [5.30241352e-04 7.23899979e-04]\n",
      " [4.46228769e-04 4.81983577e-04]\n",
      " [4.67974781e-04 4.97980624e-04]]\n",
      "Train Epoch21 out_loss 0.00043986327364109457\n",
      "Test Epoch21 layer0 out_loss 0.029985561966896057\n",
      "Test Epoch21 layer1 out_loss 0.0016736036632210016\n",
      "Test Epoch21 layer2 out_loss 0.0005085960146971047\n",
      "Test Epoch21 layer3 out_loss 0.0005397307686507702\n",
      "Test Epoch21 layer4 out_loss 0.0005444351118057966\n",
      "Test Epoch21 layer5 out_loss 0.0005593911628238857\n",
      "Test Epoch21 layer6 out_loss 0.00041654682718217373\n",
      "Train 22 | out_loss 0.0005131384823471308: 100%|█| 138/138 [00:00<00:00, 159.57i\n",
      "[[8.37046386e-06 2.63223998e-01]\n",
      " [5.25410634e-04 2.45982429e-03]\n",
      " [1.03138341e-03 1.26999691e-03]\n",
      " [5.77300122e-04 8.99665069e-04]\n",
      " [8.26364840e-04 9.37931912e-04]\n",
      " [4.66832864e-04 6.03370969e-04]\n",
      " [4.48468636e-04 4.73276795e-04]]\n",
      "Train Epoch22 out_loss 0.0005131384823471308\n",
      "Test Epoch22 layer0 out_loss 0.026394542306661606\n",
      "Test Epoch22 layer1 out_loss 0.0013334340183064342\n",
      "Test Epoch22 layer2 out_loss 0.00047216066741384566\n",
      "Test Epoch22 layer3 out_loss 0.00047242658911272883\n",
      "Test Epoch22 layer4 out_loss 0.0004236349486745894\n",
      "Test Epoch22 layer5 out_loss 0.00043084193021059036\n",
      "Test Epoch22 layer6 out_loss 0.0004066789988428354\n",
      "Train 23 | out_loss 0.0004319859144743532: 100%|█| 138/138 [00:00<00:00, 152.01i\n",
      "[[8.32514788e-06 2.18993898e-01]\n",
      " [2.50849781e-04 2.21004669e-03]\n",
      " [2.72707113e-04 7.93892857e-04]\n",
      " [5.32090944e-04 6.27825300e-04]\n",
      " [6.59302735e-04 7.84851440e-04]\n",
      " [5.19004347e-04 6.16739069e-04]\n",
      " [4.74673536e-04 5.15884698e-04]]\n",
      "Train Epoch23 out_loss 0.0004319859144743532\n",
      "Test Epoch23 layer0 out_loss 0.02663702517747879\n",
      "Test Epoch23 layer1 out_loss 0.0010876413434743881\n",
      "Test Epoch23 layer2 out_loss 0.00047729580546729267\n",
      "Test Epoch23 layer3 out_loss 0.0005336957983672619\n",
      "Test Epoch23 layer4 out_loss 0.00044556381180882454\n",
      "Test Epoch23 layer5 out_loss 0.0004561614478006959\n",
      "Test Epoch23 layer6 out_loss 0.0004742434830404818\n",
      "Train 24 | out_loss 0.0004848108219448477: 100%|█| 138/138 [00:00<00:00, 155.34i\n",
      "[[8.08259855e-06 1.08594288e-01]\n",
      " [6.94201327e-04 1.90700516e-03]\n",
      " [9.81630371e-04 1.07127148e-03]\n",
      " [7.93239871e-04 9.09584111e-04]\n",
      " [6.44231243e-04 7.64204798e-04]\n",
      " [4.35594594e-04 4.65790003e-04]\n",
      " [4.16402196e-04 4.00379538e-04]]\n",
      "Train Epoch24 out_loss 0.0004848108219448477\n",
      "Test Epoch24 layer0 out_loss 0.009132115170359612\n",
      "Test Epoch24 layer1 out_loss 0.0011820112122222781\n",
      "Test Epoch24 layer2 out_loss 0.00047349819215014577\n",
      "Test Epoch24 layer3 out_loss 0.00043908547377213836\n",
      "Test Epoch24 layer4 out_loss 0.0004079291538801044\n",
      "Test Epoch24 layer5 out_loss 0.00042001507245004177\n",
      "Test Epoch24 layer6 out_loss 0.00041171032353304327\n",
      "Train 25 | out_loss 0.0004451111308299005: 100%|█| 138/138 [00:00<00:00, 154.06i\n",
      "[[7.56812336e-06 1.44476654e-01]\n",
      " [2.12770804e-04 1.80342405e-03]\n",
      " [3.97519707e-04 7.45883776e-04]\n",
      " [6.93129420e-04 8.02682595e-04]\n",
      " [4.35761043e-04 7.23664745e-04]\n",
      " [4.28670285e-04 4.01503819e-04]\n",
      " [3.27209959e-04 4.11477363e-04]]\n",
      "Train Epoch25 out_loss 0.0004451111308299005\n",
      "Test Epoch25 layer0 out_loss 0.02159672975540161\n",
      "Test Epoch25 layer1 out_loss 0.0010635682847350836\n",
      "Test Epoch25 layer2 out_loss 0.00047639815602451563\n",
      "Test Epoch25 layer3 out_loss 0.0004873678844887763\n",
      "Test Epoch25 layer4 out_loss 0.00040918367449194193\n",
      "Test Epoch25 layer5 out_loss 0.00040762717253528535\n",
      "Test Epoch25 layer6 out_loss 0.00041089087608270347\n",
      "Train 26 | out_loss 0.0005005087587051094: 100%|█| 138/138 [00:00<00:00, 147.78i\n",
      "[[8.07581163e-06 2.46487194e-01]\n",
      " [5.43683064e-04 2.58250573e-03]\n",
      " [7.31939260e-04 1.24365860e-03]\n",
      " [4.84331922e-04 8.48721047e-04]\n",
      " [4.60904605e-04 5.97914385e-04]\n",
      " [4.05971605e-04 4.65451668e-04]\n",
      " [3.84482730e-04 4.42980262e-04]]\n",
      "Train Epoch26 out_loss 0.0005005087587051094\n",
      "Test Epoch26 layer0 out_loss 0.049013394862413406\n",
      "Test Epoch26 layer1 out_loss 0.0012691243318840861\n",
      "Test Epoch26 layer2 out_loss 0.0004674834490288049\n",
      "Test Epoch26 layer3 out_loss 0.00042934270459227264\n",
      "Test Epoch26 layer4 out_loss 0.0004356221470516175\n",
      "Test Epoch26 layer5 out_loss 0.0004061438958160579\n",
      "Test Epoch26 layer6 out_loss 0.00040714553324505687\n",
      "Train 27 | out_loss 0.0004766792990267277: 100%|█| 138/138 [00:00<00:00, 158.67i\n",
      "[[6.85467161e-06 1.86737741e-01]\n",
      " [4.73061462e-04 2.27041988e-03]\n",
      " [7.70586257e-04 1.08477066e-03]\n",
      " [6.06582142e-04 9.10743401e-04]\n",
      " [4.39538891e-04 6.19867016e-04]\n",
      " [3.30358982e-04 3.79127566e-04]\n",
      " [2.43762935e-04 2.86276609e-04]]\n",
      "Train Epoch27 out_loss 0.0004766792990267277\n",
      "Test Epoch27 layer0 out_loss 0.021261010318994522\n",
      "Test Epoch27 layer1 out_loss 0.0010108804563060403\n",
      "Test Epoch27 layer2 out_loss 0.0004613596829585731\n",
      "Test Epoch27 layer3 out_loss 0.0004990602610632777\n",
      "Test Epoch27 layer4 out_loss 0.00045936438255012035\n",
      "Test Epoch27 layer5 out_loss 0.0004454852023627609\n",
      "Test Epoch27 layer6 out_loss 0.00044005291420035064\n",
      "Train 28 | out_loss 0.00044188890024088323: 100%|█| 138/138 [00:00<00:00, 153.71\n",
      "[[7.04431343e-06 5.82626249e-02]\n",
      " [3.29744699e-04 1.63110608e-03]\n",
      " [7.23363496e-04 8.52981814e-04]\n",
      " [7.44313472e-04 9.50886690e-04]\n",
      " [5.11962733e-04 8.34656624e-04]\n",
      " [4.88446894e-04 5.60322287e-04]\n",
      " [3.95064555e-04 4.92998994e-04]]\n",
      "Train Epoch28 out_loss 0.00044188890024088323\n",
      "Test Epoch28 layer0 out_loss 0.008504870347678661\n",
      "Test Epoch28 layer1 out_loss 0.0009434517123736441\n",
      "Test Epoch28 layer2 out_loss 0.000526438991073519\n",
      "Test Epoch28 layer3 out_loss 0.0004650558403227478\n",
      "Test Epoch28 layer4 out_loss 0.0005194522673264146\n",
      "Test Epoch28 layer5 out_loss 0.0005029339226894081\n",
      "Test Epoch28 layer6 out_loss 0.0004996714415028691\n",
      "Train 29 | out_loss 0.0005425419076345861: 100%|█| 138/138 [00:00<00:00, 153.81i\n",
      "[[7.16057224e-06 7.33388797e-02]\n",
      " [4.73589975e-04 1.63556015e-03]\n",
      " [5.42265823e-04 8.64213253e-04]\n",
      " [3.65643549e-04 6.12497580e-04]\n",
      " [4.71850362e-04 4.75624603e-04]\n",
      " [4.50444990e-04 5.32513201e-04]\n",
      " [3.25358644e-04 4.90573951e-04]]\n",
      "Train Epoch29 out_loss 0.0005425419076345861\n",
      "Test Epoch29 layer0 out_loss 0.007293121889233589\n",
      "Test Epoch29 layer1 out_loss 0.0015136462170630693\n",
      "Test Epoch29 layer2 out_loss 0.0005703748320229352\n",
      "Test Epoch29 layer3 out_loss 0.00042515399400144815\n",
      "Test Epoch29 layer4 out_loss 0.0005648066871799529\n",
      "Test Epoch29 layer5 out_loss 0.0005355129251256585\n",
      "Test Epoch29 layer6 out_loss 0.0004939713981002569\n",
      "Train 30 | out_loss 0.0005125296884216368: 100%|█| 138/138 [00:00<00:00, 152.52i\n",
      "[[7.00490227e-06 3.62202925e-01]\n",
      " [5.73090708e-04 2.78472827e-03]\n",
      " [8.77061200e-04 1.33136638e-03]\n",
      " [6.10761835e-04 1.05258086e-03]\n",
      " [5.37102894e-04 8.02616343e-04]\n",
      " [4.60014960e-04 5.98797603e-04]\n",
      " [4.24288361e-04 5.17819118e-04]]\n",
      "Train Epoch30 out_loss 0.0005125296884216368\n",
      "Test Epoch30 layer0 out_loss 0.019211621955037117\n",
      "Test Epoch30 layer1 out_loss 0.0023591830395162106\n",
      "Test Epoch30 layer2 out_loss 0.0013253549113869667\n",
      "Test Epoch30 layer3 out_loss 0.0011006364366039634\n",
      "Test Epoch30 layer4 out_loss 0.001394999329932034\n",
      "Test Epoch30 layer5 out_loss 0.0014880192466080189\n",
      "Test Epoch30 layer6 out_loss 0.0013613010523840785\n",
      "Train 31 | out_loss 0.0005735380691476166: 100%|█| 138/138 [00:00<00:00, 155.58i\n",
      "[[5.82327260e-06 1.95958922e-01]\n",
      " [5.34304403e-04 1.93874628e-03]\n",
      " [8.93621509e-04 1.19977722e-03]\n",
      " [6.42051808e-04 1.17064121e-03]\n",
      " [4.80906506e-04 9.30266616e-04]\n",
      " [4.83813578e-04 6.33706027e-04]\n",
      " [6.02971382e-04 6.23627593e-04]]\n",
      "Train Epoch31 out_loss 0.0005735380691476166\n",
      "Test Epoch31 layer0 out_loss 0.015852054581046104\n",
      "Test Epoch31 layer1 out_loss 0.0010567023418843746\n",
      "Test Epoch31 layer2 out_loss 0.00046039288281463087\n",
      "Test Epoch31 layer3 out_loss 0.0004215665103401989\n",
      "Test Epoch31 layer4 out_loss 0.0004415695439092815\n",
      "Test Epoch31 layer5 out_loss 0.00042274079169146717\n",
      "Test Epoch31 layer6 out_loss 0.0004162179247941822\n",
      "Train 32 | out_loss 0.0004744059988297522: 100%|█| 138/138 [00:00<00:00, 153.31i\n",
      "[[5.72394883e-06 4.85196923e-02]\n",
      " [4.32858146e-04 1.37272987e-03]\n",
      " [5.28659899e-04 7.54674222e-04]\n",
      " [3.80238177e-04 6.70131581e-04]\n",
      " [5.07204121e-04 6.40766809e-04]\n",
      " [4.60707035e-04 6.19728885e-04]\n",
      " [3.76665764e-04 3.94134345e-04]]\n",
      "Train Epoch32 out_loss 0.0004744059988297522\n",
      "Test Epoch32 layer0 out_loss 0.008534415625035763\n",
      "Test Epoch32 layer1 out_loss 0.0009332853369414806\n",
      "Test Epoch32 layer2 out_loss 0.0005566604668274522\n",
      "Test Epoch32 layer3 out_loss 0.00048078232794068754\n",
      "Test Epoch32 layer4 out_loss 0.0006050945376046002\n",
      "Test Epoch32 layer5 out_loss 0.0005419929511845112\n",
      "Test Epoch32 layer6 out_loss 0.0005988923367112875\n",
      "Train 33 | out_loss 0.00047683651791885495: 100%|█| 138/138 [00:00<00:00, 151.42\n",
      "[[5.26605800e-06 2.89125555e-01]\n",
      " [7.84309465e-04 3.40422608e-03]\n",
      " [1.02877843e-03 1.51167422e-03]\n",
      " [6.58663767e-04 1.17425746e-03]\n",
      " [5.45752709e-04 8.00690803e-04]\n",
      " [4.79233253e-04 6.19835407e-04]\n",
      " [3.83532142e-04 4.42288778e-04]]\n",
      "Train Epoch33 out_loss 0.00047683651791885495\n",
      "Test Epoch33 layer0 out_loss 0.02050926350057125\n",
      "Test Epoch33 layer1 out_loss 0.0015412559732794762\n",
      "Test Epoch33 layer2 out_loss 0.0007364976336248219\n",
      "Test Epoch33 layer3 out_loss 0.00043265975546091795\n",
      "Test Epoch33 layer4 out_loss 0.0004172037006355822\n",
      "Test Epoch33 layer5 out_loss 0.0004166803846601397\n",
      "Test Epoch33 layer6 out_loss 0.00040880567394196987\n",
      "Train 34 | out_loss 0.0004905800451524556: 100%|█| 138/138 [00:00<00:00, 159.13i\n",
      "[[6.24445048e-06 8.70836154e-02]\n",
      " [3.75773312e-04 1.75756891e-03]\n",
      " [6.78643632e-04 9.96908905e-04]\n",
      " [5.26875597e-04 1.06204476e-03]\n",
      " [5.16970501e-04 7.96885762e-04]\n",
      " [4.19793295e-04 6.07181452e-04]\n",
      " [2.78024621e-04 3.39028131e-04]]\n",
      "Train Epoch34 out_loss 0.0004905800451524556\n",
      "Test Epoch34 layer0 out_loss 0.005861939396709204\n",
      "Test Epoch34 layer1 out_loss 0.0009862047154456377\n",
      "Test Epoch34 layer2 out_loss 0.0005129180499352515\n",
      "Test Epoch34 layer3 out_loss 0.0005452304030768573\n",
      "Test Epoch34 layer4 out_loss 0.0005400466616265476\n",
      "Test Epoch34 layer5 out_loss 0.0005056812660768628\n",
      "Test Epoch34 layer6 out_loss 0.0005120395799167454\n",
      "Train 35 | out_loss 0.0005714037106372416: 100%|█| 138/138 [00:00<00:00, 157.53i\n",
      "[[4.41854206e-06 4.27693880e-02]\n",
      " [6.50247605e-04 1.66877132e-03]\n",
      " [7.18051550e-04 9.88252612e-04]\n",
      " [5.04044183e-04 6.98455773e-04]\n",
      " [3.58698238e-04 4.12921220e-04]\n",
      " [2.74686150e-04 2.91663690e-04]\n",
      " [1.64275799e-04 1.81519825e-04]]\n",
      "Train Epoch35 out_loss 0.0005714037106372416\n",
      "Test Epoch35 layer0 out_loss 0.01661725901067257\n",
      "Test Epoch35 layer1 out_loss 0.0011049164459109306\n",
      "Test Epoch35 layer2 out_loss 0.0007436568266712129\n",
      "Test Epoch35 layer3 out_loss 0.0008371608564630151\n",
      "Test Epoch35 layer4 out_loss 0.0007214111392386258\n",
      "Test Epoch35 layer5 out_loss 0.0007120410446077585\n",
      "Test Epoch35 layer6 out_loss 0.0007580412202514708\n",
      "Train 36 | out_loss 0.0004701721773017198: 100%|█| 138/138 [00:00<00:00, 157.06i\n",
      "[[4.78507542e-06 7.67164967e-02]\n",
      " [4.01840918e-04 1.67116897e-03]\n",
      " [4.84023260e-04 9.90450298e-04]\n",
      " [4.06302100e-04 9.42578081e-04]\n",
      " [4.39054088e-04 5.61275626e-04]\n",
      " [3.45558310e-04 3.87609504e-04]\n",
      " [2.37872283e-04 2.33697446e-04]]\n",
      "Train Epoch36 out_loss 0.0004701721773017198\n",
      "Test Epoch36 layer0 out_loss 0.015574146062135696\n",
      "Test Epoch36 layer1 out_loss 0.0010314499959349632\n",
      "Test Epoch36 layer2 out_loss 0.0005280491895973682\n",
      "Test Epoch36 layer3 out_loss 0.0005052796332165599\n",
      "Test Epoch36 layer4 out_loss 0.00041954952757805586\n",
      "Test Epoch36 layer5 out_loss 0.00043205576366744936\n",
      "Test Epoch36 layer6 out_loss 0.00043990573612973094\n",
      "Train 37 | out_loss 0.0005073530483059585: 100%|█| 138/138 [00:00<00:00, 152.63i\n",
      "[[5.16891806e-06 1.15490908e-01]\n",
      " [8.95179624e-04 2.94439669e-03]\n",
      " [1.15965687e-03 1.90003219e-03]\n",
      " [8.85761962e-04 1.82397160e-03]\n",
      " [6.90143082e-04 9.91768892e-04]\n",
      " [6.05427368e-04 5.95260805e-04]\n",
      " [3.26816007e-04 3.25013730e-04]]\n",
      "Train Epoch37 out_loss 0.0005073530483059585\n",
      "Test Epoch37 layer0 out_loss 0.013295698910951614\n",
      "Test Epoch37 layer1 out_loss 0.0011330689303576946\n",
      "Test Epoch37 layer2 out_loss 0.0005175876431167126\n",
      "Test Epoch37 layer3 out_loss 0.00041217482066713274\n",
      "Test Epoch37 layer4 out_loss 0.0005215847631916404\n",
      "Test Epoch37 layer5 out_loss 0.0004738720890600234\n",
      "Test Epoch37 layer6 out_loss 0.00045409536687657237\n",
      "Train 38 | out_loss 0.0005390147562138736: 100%|█| 138/138 [00:00<00:00, 156.56i\n",
      "[[4.30292691e-06 2.71177233e-01]\n",
      " [3.85132326e-04 2.85648618e-03]\n",
      " [6.30020852e-04 1.20123959e-03]\n",
      " [4.78220937e-04 1.06823892e-03]\n",
      " [4.41522546e-04 5.73728246e-04]\n",
      " [3.10550193e-04 3.79414112e-04]\n",
      " [2.03249690e-04 2.31731580e-04]]\n",
      "Train Epoch38 out_loss 0.0005390147562138736\n",
      "Test Epoch38 layer0 out_loss 0.024351395666599274\n",
      "Test Epoch38 layer1 out_loss 0.002259664935991168\n",
      "Test Epoch38 layer2 out_loss 0.0008159926510415971\n",
      "Test Epoch38 layer3 out_loss 0.0007027327083051205\n",
      "Test Epoch38 layer4 out_loss 0.0006731321336701512\n",
      "Test Epoch38 layer5 out_loss 0.0006166311795823276\n",
      "Test Epoch38 layer6 out_loss 0.0006250232108868659\n",
      "Train 39 | out_loss 0.0005026152357459068: 100%|█| 138/138 [00:00<00:00, 155.77i\n",
      "[[6.91160347e-06 2.87329243e-01]\n",
      " [4.60143137e-04 2.42476585e-03]\n",
      " [5.28944547e-04 1.32736048e-03]\n",
      " [5.45792142e-04 1.11339758e-03]\n",
      " [5.60990302e-04 6.63139434e-04]\n",
      " [4.94387417e-04 4.94181552e-04]\n",
      " [3.23876952e-04 3.24237225e-04]]\n",
      "Train Epoch39 out_loss 0.0005026152357459068\n",
      "Test Epoch39 layer0 out_loss 0.01209925301373005\n",
      "Test Epoch39 layer1 out_loss 0.0007982847164385021\n",
      "Test Epoch39 layer2 out_loss 0.0008348890114575624\n",
      "Test Epoch39 layer3 out_loss 0.0007951012812554836\n",
      "Test Epoch39 layer4 out_loss 0.0007700305432081223\n",
      "Test Epoch39 layer5 out_loss 0.0007845652871765196\n",
      "Test Epoch39 layer6 out_loss 0.0007708680350333452\n",
      "Train 40 | out_loss 0.0005043321289122105: 100%|█| 138/138 [00:00<00:00, 153.70i\n",
      "[[6.82468177e-06 2.42358847e-02]\n",
      " [6.20680915e-04 1.42002461e-03]\n",
      " [8.15217783e-04 1.28293209e-03]\n",
      " [5.44767131e-04 9.15076590e-04]\n",
      " [5.36460725e-04 6.50377823e-04]\n",
      " [4.50499128e-04 5.02958364e-04]\n",
      " [3.87683026e-04 3.84812403e-04]]\n",
      "Train Epoch40 out_loss 0.0005043321289122105\n",
      "Test Epoch40 layer0 out_loss 0.0026980957482010126\n",
      "Test Epoch40 layer1 out_loss 0.0007475267047993839\n",
      "Test Epoch40 layer2 out_loss 0.0005060686962679029\n",
      "Test Epoch40 layer3 out_loss 0.0004109014989808202\n",
      "Test Epoch40 layer4 out_loss 0.0004746538179460913\n",
      "Test Epoch40 layer5 out_loss 0.00045124415191821754\n",
      "Test Epoch40 layer6 out_loss 0.00044620633707381785\n",
      "Train 41 | out_loss 0.0005311791319400072: 100%|█| 138/138 [00:00<00:00, 152.29i\n",
      "[[6.63607362e-06 3.34472387e-02]\n",
      " [6.21122901e-04 1.59421911e-03]\n",
      " [6.86800088e-04 1.19343242e-03]\n",
      " [4.90805195e-04 8.71546355e-04]\n",
      " [5.25175365e-04 6.16710500e-04]\n",
      " [3.92921430e-04 3.92622220e-04]\n",
      " [2.52856206e-04 2.30716613e-04]]\n",
      "Train Epoch41 out_loss 0.0005311791319400072\n",
      "Test Epoch41 layer0 out_loss 0.0077470517717301846\n",
      "Test Epoch41 layer1 out_loss 0.001068468438461423\n",
      "Test Epoch41 layer2 out_loss 0.0004987724241800606\n",
      "Test Epoch41 layer3 out_loss 0.0004339923325460404\n",
      "Test Epoch41 layer4 out_loss 0.0004128857690375298\n",
      "Test Epoch41 layer5 out_loss 0.0004134178743697703\n",
      "Test Epoch41 layer6 out_loss 0.0004152549954596907\n",
      "Train 42 | out_loss 0.0012610056437551975: 100%|█| 138/138 [00:00<00:00, 151.25i\n",
      "[[0.00029004 0.07399026]\n",
      " [0.00056757 0.00212498]\n",
      " [0.00070681 0.00136328]\n",
      " [0.00048215 0.00104557]\n",
      " [0.00040181 0.00059243]\n",
      " [0.00031843 0.00036067]\n",
      " [0.00031586 0.00026113]]\n",
      "Train Epoch42 out_loss 0.0012610056437551975\n",
      "Test Epoch42 layer0 out_loss 0.006975347641855478\n",
      "Test Epoch42 layer1 out_loss 0.0035162316635251045\n",
      "Test Epoch42 layer2 out_loss 0.00310615380294621\n",
      "Test Epoch42 layer3 out_loss 0.0029487465508282185\n",
      "Test Epoch42 layer4 out_loss 0.0030470003839582205\n",
      "Test Epoch42 layer5 out_loss 0.0030876377131789923\n",
      "Test Epoch42 layer6 out_loss 0.0030746778938919306\n",
      "Train 43 | out_loss 0.001442110282368958: 100%|█| 138/138 [00:00<00:00, 157.01it\n",
      "[[4.45431950e-04 1.89197267e-01]\n",
      " [4.96166142e-04 3.28291162e-03]\n",
      " [6.01990322e-04 1.40212077e-03]\n",
      " [5.22441083e-04 1.18063921e-03]\n",
      " [4.30798243e-04 6.37841774e-04]\n",
      " [2.93829570e-04 2.92542759e-04]\n",
      " [2.07373839e-04 1.74979727e-04]]\n",
      "Train Epoch43 out_loss 0.001442110282368958\n",
      "Test Epoch43 layer0 out_loss 0.010259239934384823\n",
      "Test Epoch43 layer1 out_loss 0.0008401881786994636\n",
      "Test Epoch43 layer2 out_loss 0.0008468583109788597\n",
      "Test Epoch43 layer3 out_loss 0.0005939026596024632\n",
      "Test Epoch43 layer4 out_loss 0.0006991287809796631\n",
      "Test Epoch43 layer5 out_loss 0.0006322252447716892\n",
      "Test Epoch43 layer6 out_loss 0.000639815058093518\n",
      "Train 44 | out_loss 0.0009753117919899523: 100%|█| 138/138 [00:00<00:00, 157.53i\n",
      "[[0.00021484 0.10756578]\n",
      " [0.00059241 0.00193371]\n",
      " [0.00084842 0.00140525]\n",
      " [0.00060656 0.00100554]\n",
      " [0.00045558 0.00061622]\n",
      " [0.00038387 0.00036096]\n",
      " [0.00031203 0.00024955]]\n",
      "Train Epoch44 out_loss 0.0009753117919899523\n",
      "Test Epoch44 layer0 out_loss 0.008236929774284363\n",
      "Test Epoch44 layer1 out_loss 0.0014984597219154239\n",
      "Test Epoch44 layer2 out_loss 0.0015062622260302305\n",
      "Test Epoch44 layer3 out_loss 0.0011027874425053596\n",
      "Test Epoch44 layer4 out_loss 0.001193074625916779\n",
      "Test Epoch44 layer5 out_loss 0.0011497657978907228\n",
      "Test Epoch44 layer6 out_loss 0.00112211424857378\n",
      "Train 45 | out_loss 0.001234976458363235: 100%|█| 138/138 [00:00<00:00, 155.70it\n",
      "[[0.00033693 0.04198218]\n",
      " [0.00059308 0.00185514]\n",
      " [0.00085708 0.00149058]\n",
      " [0.00065564 0.00109148]\n",
      " [0.00046712 0.00061518]\n",
      " [0.0003696  0.00036858]\n",
      " [0.00027745 0.00022675]]\n",
      "Train Epoch45 out_loss 0.001234976458363235\n",
      "Test Epoch45 layer0 out_loss 0.004412749782204628\n",
      "Test Epoch45 layer1 out_loss 0.0009105628705583513\n",
      "Test Epoch45 layer2 out_loss 0.0004659702826756984\n",
      "Test Epoch45 layer3 out_loss 0.0004739401047118008\n",
      "Test Epoch45 layer4 out_loss 0.0005124033777974546\n",
      "Test Epoch45 layer5 out_loss 0.0005086733144707978\n",
      "Test Epoch45 layer6 out_loss 0.0005017968942411244\n",
      "Train 46 | out_loss 0.0014018660876899958: 100%|█| 138/138 [00:00<00:00, 147.03i\n",
      "[[0.00039498 0.04608254]\n",
      " [0.00046272 0.0014844 ]\n",
      " [0.00051876 0.00111242]\n",
      " [0.00050521 0.00081922]\n",
      " [0.00042872 0.0005453 ]\n",
      " [0.00033642 0.00032516]\n",
      " [0.00025321 0.00019903]]\n",
      "Train Epoch46 out_loss 0.0014018660876899958\n",
      "Test Epoch46 layer0 out_loss 0.006896734703332186\n",
      "Test Epoch46 layer1 out_loss 0.005053909029811621\n",
      "Test Epoch46 layer2 out_loss 0.0043641310185194016\n",
      "Test Epoch46 layer3 out_loss 0.004387155175209045\n",
      "Test Epoch46 layer4 out_loss 0.004671505652368069\n",
      "Test Epoch46 layer5 out_loss 0.004603957757353783\n",
      "Test Epoch46 layer6 out_loss 0.004708915017545223\n",
      "Train 47 | out_loss 0.0012512289686128497: 100%|█| 138/138 [00:00<00:00, 156.13i\n",
      "[[0.00034767 0.02341572]\n",
      " [0.00055409 0.00147614]\n",
      " [0.00059182 0.00138959]\n",
      " [0.00070675 0.00133748]\n",
      " [0.00053419 0.00080629]\n",
      " [0.00052018 0.00048906]\n",
      " [0.00032976 0.00029979]]\n",
      "Train Epoch47 out_loss 0.0012512289686128497\n",
      "Test Epoch47 layer0 out_loss 0.0031211962923407555\n",
      "Test Epoch47 layer1 out_loss 0.0007060186471790075\n",
      "Test Epoch47 layer2 out_loss 0.0004891621065326035\n",
      "Test Epoch47 layer3 out_loss 0.0004910840652883053\n",
      "Test Epoch47 layer4 out_loss 0.0004550656012725085\n",
      "Test Epoch47 layer5 out_loss 0.0004318036953918636\n",
      "Test Epoch47 layer6 out_loss 0.0004249787307344377\n",
      "Train 48 | out_loss 0.001267179730348289: 100%|█| 138/138 [00:00<00:00, 154.90it\n",
      "[[0.00032165 0.03104236]\n",
      " [0.00054316 0.00208591]\n",
      " [0.00073902 0.00153951]\n",
      " [0.00062818 0.00122106]\n",
      " [0.00042397 0.00054602]\n",
      " [0.00033564 0.00031772]\n",
      " [0.00022638 0.00021589]]\n",
      "Train Epoch48 out_loss 0.001267179730348289\n",
      "Test Epoch48 layer0 out_loss 0.004390632268041372\n",
      "Test Epoch48 layer1 out_loss 0.0007344140321947634\n",
      "Test Epoch48 layer2 out_loss 0.0005273928982205689\n",
      "Test Epoch48 layer3 out_loss 0.00043494231067597866\n",
      "Test Epoch48 layer4 out_loss 0.0004550998564809561\n",
      "Test Epoch48 layer5 out_loss 0.0004418049065861851\n",
      "Test Epoch48 layer6 out_loss 0.00043366517638787627\n",
      "Train 49 | out_loss 0.0014980204869061708: 100%|█| 138/138 [00:00<00:00, 151.10i\n",
      "[[0.00049279 0.11155206]\n",
      " [0.00052765 0.00253325]\n",
      " [0.00062163 0.00160078]\n",
      " [0.00055609 0.00101917]\n",
      " [0.00035535 0.00046006]\n",
      " [0.00026052 0.00027262]\n",
      " [0.00017591 0.00016742]]\n",
      "Train Epoch49 out_loss 0.0014980204869061708\n",
      "Test Epoch49 layer0 out_loss 0.008454525843262672\n",
      "Test Epoch49 layer1 out_loss 0.001063745585270226\n",
      "Test Epoch49 layer2 out_loss 0.0006585970986634493\n",
      "Test Epoch49 layer3 out_loss 0.00043159848428331316\n",
      "Test Epoch49 layer4 out_loss 0.00042068323818966746\n",
      "Test Epoch49 layer5 out_loss 0.0004067127010785043\n",
      "Test Epoch49 layer6 out_loss 0.0004079659120179713\n",
      "Train 50 | out_loss 0.0012528406223282218: 100%|█| 138/138 [00:00<00:00, 150.37i\n",
      "[[0.00033834 0.09963156]\n",
      " [0.00055229 0.00233711]\n",
      " [0.00072531 0.00166434]\n",
      " [0.00049711 0.00104222]\n",
      " [0.00045038 0.00052887]\n",
      " [0.00035013 0.00033058]\n",
      " [0.00025392 0.00022459]]\n",
      "Train Epoch50 out_loss 0.0012528406223282218\n",
      "Test Epoch50 layer0 out_loss 0.010281398892402649\n",
      "Test Epoch50 layer1 out_loss 0.001154298079200089\n",
      "Test Epoch50 layer2 out_loss 0.0006428424967452884\n",
      "Test Epoch50 layer3 out_loss 0.0007037339964881539\n",
      "Test Epoch50 layer4 out_loss 0.000629478832706809\n",
      "Test Epoch50 layer5 out_loss 0.0005968057084828615\n",
      "Test Epoch50 layer6 out_loss 0.0005619542789645493\n",
      "Train 51 | out_loss 0.001526471460238099: 100%|█| 138/138 [00:00<00:00, 156.99it\n",
      "[[0.00044341 0.04314585]\n",
      " [0.0004373  0.00173308]\n",
      " [0.00056875 0.00121035]\n",
      " [0.00041178 0.00081524]\n",
      " [0.00036347 0.00038684]\n",
      " [0.00027256 0.00024568]\n",
      " [0.00017368 0.00016462]]\n",
      "Train Epoch51 out_loss 0.001526471460238099\n",
      "Test Epoch51 layer0 out_loss 0.006549234967678785\n",
      "Test Epoch51 layer1 out_loss 0.0012831874191761017\n",
      "Test Epoch51 layer2 out_loss 0.0008064024732448161\n",
      "Test Epoch51 layer3 out_loss 0.0004617350350599736\n",
      "Test Epoch51 layer4 out_loss 0.0005342612857930362\n",
      "Test Epoch51 layer5 out_loss 0.0005034147179685533\n",
      "Test Epoch51 layer6 out_loss 0.00048817472998052835\n",
      "Train 52 | out_loss 0.0013219477841630578: 100%|█| 138/138 [00:00<00:00, 153.13i\n",
      "[[0.00039463 0.06327643]\n",
      " [0.0006831  0.00262434]\n",
      " [0.00082017 0.00167434]\n",
      " [0.00054343 0.00106514]\n",
      " [0.00046249 0.00044997]\n",
      " [0.00038299 0.00033586]\n",
      " [0.00020359 0.00016985]]\n",
      "Train Epoch52 out_loss 0.0013219477841630578\n",
      "Test Epoch52 layer0 out_loss 0.00402861088514328\n",
      "Test Epoch52 layer1 out_loss 0.0011419797083362937\n",
      "Test Epoch52 layer2 out_loss 0.00048490779590792954\n",
      "Test Epoch52 layer3 out_loss 0.0008951598429121077\n",
      "Test Epoch52 layer4 out_loss 0.0009260063525289297\n",
      "Test Epoch52 layer5 out_loss 0.0008901833207346499\n",
      "Test Epoch52 layer6 out_loss 0.0008866203716024756\n",
      "Train 53 | out_loss 0.0008265511714853346: 100%|█| 138/138 [00:00<00:00, 153.36i\n",
      "[[9.39136909e-05 3.15531351e-02]\n",
      " [4.14217500e-04 1.81827103e-03]\n",
      " [5.59236325e-04 1.52291633e-03]\n",
      " [4.62383152e-04 7.75555700e-04]\n",
      " [3.45673052e-04 3.76700435e-04]\n",
      " [2.46541717e-04 2.18242086e-04]\n",
      " [1.86888273e-04 1.71632332e-04]]\n",
      "Train Epoch53 out_loss 0.0008265511714853346\n",
      "Test Epoch53 layer0 out_loss 0.008069963194429874\n",
      "Test Epoch53 layer1 out_loss 0.0030584395863115788\n",
      "Test Epoch53 layer2 out_loss 0.0025233004707843065\n",
      "Test Epoch53 layer3 out_loss 0.0023298824671655893\n",
      "Test Epoch53 layer4 out_loss 0.0025104747619479895\n",
      "Test Epoch53 layer5 out_loss 0.002511352300643921\n",
      "Test Epoch53 layer6 out_loss 0.0025071599520742893\n",
      "Train 54 | out_loss 0.0016030763508751988: 100%|█| 138/138 [00:00<00:00, 151.33i\n",
      "[[5.70748961e-04 2.41783639e-01]\n",
      " [4.85417698e-04 3.93853241e-03]\n",
      " [6.26968475e-04 1.64553105e-03]\n",
      " [3.80571873e-04 8.85094255e-04]\n",
      " [3.09839312e-04 4.44470665e-04]\n",
      " [2.47517368e-04 2.50323863e-04]\n",
      " [2.21908929e-04 1.91778558e-04]]\n",
      "Train Epoch54 out_loss 0.0016030763508751988\n",
      "Test Epoch54 layer0 out_loss 0.004446025472134352\n",
      "Test Epoch54 layer1 out_loss 0.0012983130291104317\n",
      "Test Epoch54 layer2 out_loss 0.0006536573055200279\n",
      "Test Epoch54 layer3 out_loss 0.0004152445471845567\n",
      "Test Epoch54 layer4 out_loss 0.0004242058494128287\n",
      "Test Epoch54 layer5 out_loss 0.00040851326775737107\n",
      "Test Epoch54 layer6 out_loss 0.000407939514843747\n",
      "Train 55 | out_loss 0.0014135076198726892: 100%|█| 138/138 [00:00<00:00, 153.68i\n",
      "[[0.00035509 0.02444301]\n",
      " [0.00057292 0.00172648]\n",
      " [0.00077861 0.00164517]\n",
      " [0.00044832 0.00082004]\n",
      " [0.00051511 0.00054772]\n",
      " [0.00025541 0.00029072]\n",
      " [0.00022036 0.00020936]]\n",
      "Train Epoch55 out_loss 0.0014135076198726892\n",
      "Test Epoch55 layer0 out_loss 0.003656565910205245\n",
      "Test Epoch55 layer1 out_loss 0.002299559535458684\n",
      "Test Epoch55 layer2 out_loss 0.001132663688622415\n",
      "Test Epoch55 layer3 out_loss 0.0014255851274356246\n",
      "Test Epoch55 layer4 out_loss 0.0012837608810514212\n",
      "Test Epoch55 layer5 out_loss 0.001304213423281908\n",
      "Test Epoch55 layer6 out_loss 0.0012990006944164634\n",
      "Train 56 | out_loss 0.0012844960438087583: 100%|█| 138/138 [00:00<00:00, 149.73i\n",
      "[[0.00032738 0.00770257]\n",
      " [0.00050114 0.00149339]\n",
      " [0.00062213 0.00151846]\n",
      " [0.0004672  0.00079972]\n",
      " [0.00105404 0.00107393]\n",
      " [0.00044404 0.00046788]\n",
      " [0.00032294 0.00021998]]\n",
      "Train Epoch56 out_loss 0.0012844960438087583\n",
      "Test Epoch56 layer0 out_loss 0.004788018297404051\n",
      "Test Epoch56 layer1 out_loss 0.0036283074878156185\n",
      "Test Epoch56 layer2 out_loss 0.003075273707509041\n",
      "Test Epoch56 layer3 out_loss 0.002607589354738593\n",
      "Test Epoch56 layer4 out_loss 0.002632543910294771\n",
      "Test Epoch56 layer5 out_loss 0.002668845234438777\n",
      "Test Epoch56 layer6 out_loss 0.0026542458217591047\n",
      "Train 57 | out_loss 0.0011521675623953342: 100%|█| 138/138 [00:00<00:00, 151.10i\n",
      "[[0.00027515 0.01572581]\n",
      " [0.00046999 0.00174506]\n",
      " [0.00055679 0.00103578]\n",
      " [0.00036586 0.00057075]\n",
      " [0.00036723 0.00045696]\n",
      " [0.00029443 0.00033997]\n",
      " [0.00030061 0.00025145]]\n",
      "Train Epoch57 out_loss 0.0011521675623953342\n",
      "Test Epoch57 layer0 out_loss 0.012261111289262772\n",
      "Test Epoch57 layer1 out_loss 0.0032272476237267256\n",
      "Test Epoch57 layer2 out_loss 0.002194776199758053\n",
      "Test Epoch57 layer3 out_loss 0.002129996195435524\n",
      "Test Epoch57 layer4 out_loss 0.0020357854664325714\n",
      "Test Epoch57 layer5 out_loss 0.0020494412165135145\n",
      "Test Epoch57 layer6 out_loss 0.0019973646849393845\n",
      "Train 58 | out_loss 0.0012385320151224732: 100%|█| 138/138 [00:00<00:00, 156.18i\n",
      "[[0.00032835 0.1907639 ]\n",
      " [0.00037601 0.003233  ]\n",
      " [0.00048177 0.00143036]\n",
      " [0.00036422 0.00079523]\n",
      " [0.00031252 0.00041097]\n",
      " [0.00030203 0.00036174]\n",
      " [0.00026086 0.00022649]]\n",
      "Train Epoch58 out_loss 0.0012385320151224732\n",
      "Test Epoch58 layer0 out_loss 0.009205399081110954\n",
      "Test Epoch58 layer1 out_loss 0.0010676388628780842\n",
      "Test Epoch58 layer2 out_loss 0.00044304190669208765\n",
      "Test Epoch58 layer3 out_loss 0.0005150180659256876\n",
      "Test Epoch58 layer4 out_loss 0.0004625525325536728\n",
      "Test Epoch58 layer5 out_loss 0.0004724531027022749\n",
      "Test Epoch58 layer6 out_loss 0.00045863341074436903\n",
      "Train 59 | out_loss 0.001097197295166552: 100%|█| 138/138 [00:00<00:00, 157.33it\n",
      "[[0.0002438  0.0146012 ]\n",
      " [0.00053569 0.00182281]\n",
      " [0.00070508 0.0015402 ]\n",
      " [0.00042964 0.0008346 ]\n",
      " [0.00035819 0.00042389]\n",
      " [0.00034689 0.00036243]\n",
      " [0.00021986 0.00019702]]\n",
      "Train Epoch59 out_loss 0.001097197295166552\n",
      "Test Epoch59 layer0 out_loss 0.002549991710111499\n",
      "Test Epoch59 layer1 out_loss 0.0007338619325309992\n",
      "Test Epoch59 layer2 out_loss 0.0004910653224214911\n",
      "Test Epoch59 layer3 out_loss 0.0004668081528507173\n",
      "Test Epoch59 layer4 out_loss 0.0004678492550738156\n",
      "Test Epoch59 layer5 out_loss 0.000465852819615975\n",
      "Test Epoch59 layer6 out_loss 0.0004680629645008594\n",
      "Train 60 | out_loss 0.0012565231882035732: 100%|█| 138/138 [00:00<00:00, 150.70i\n",
      "[[0.00033657 0.01177372]\n",
      " [0.00053981 0.00181873]\n",
      " [0.00073314 0.00162987]\n",
      " [0.00050389 0.00077776]\n",
      " [0.00035108 0.0004316 ]\n",
      " [0.00030638 0.00031122]\n",
      " [0.0002822  0.00024571]]\n",
      "Train Epoch60 out_loss 0.0012565231882035732\n",
      "Test Epoch60 layer0 out_loss 0.003764309221878648\n",
      "Test Epoch60 layer1 out_loss 0.000985478051006794\n",
      "Test Epoch60 layer2 out_loss 0.0007372019463218749\n",
      "Test Epoch60 layer3 out_loss 0.0007016366580501199\n",
      "Test Epoch60 layer4 out_loss 0.000655047595500946\n",
      "Test Epoch60 layer5 out_loss 0.000666956533677876\n",
      "Test Epoch60 layer6 out_loss 0.0006926732021383941\n",
      "Train 61 | out_loss 0.0016180393286049366: 100%|█| 138/138 [00:00<00:00, 156.97i\n",
      "[[0.00050905 0.02242121]\n",
      " [0.00040684 0.00186854]\n",
      " [0.00056602 0.00149917]\n",
      " [0.000454   0.00083013]\n",
      " [0.00035328 0.00040333]\n",
      " [0.00028181 0.00027783]\n",
      " [0.0002516  0.00022308]]\n",
      "Train Epoch61 out_loss 0.0016180393286049366\n",
      "Test Epoch61 layer0 out_loss 0.02689531072974205\n",
      "Test Epoch61 layer1 out_loss 0.0007970207370817661\n",
      "Test Epoch61 layer2 out_loss 0.0007436228916049004\n",
      "Test Epoch61 layer3 out_loss 0.001025524688884616\n",
      "Test Epoch61 layer4 out_loss 0.0008988716872408986\n",
      "Test Epoch61 layer5 out_loss 0.0008915301295928657\n",
      "Test Epoch61 layer6 out_loss 0.0008984101004898548\n",
      "Train 62 | out_loss 0.0011568848276510835: 100%|█| 138/138 [00:00<00:00, 154.72i\n",
      "[[0.00027341 0.0826224 ]\n",
      " [0.00047692 0.00320054]\n",
      " [0.00061533 0.00156061]\n",
      " [0.00042986 0.00089285]\n",
      " [0.0003572  0.00040128]\n",
      " [0.00027482 0.0002458 ]\n",
      " [0.00022608 0.00018264]]\n",
      "Train Epoch62 out_loss 0.0011568848276510835\n",
      "Test Epoch62 layer0 out_loss 0.00444366317242384\n",
      "Test Epoch62 layer1 out_loss 0.0007119012880139053\n",
      "Test Epoch62 layer2 out_loss 0.0005543747683987021\n",
      "Test Epoch62 layer3 out_loss 0.0004250412748660892\n",
      "Test Epoch62 layer4 out_loss 0.00044060981599614024\n",
      "Test Epoch62 layer5 out_loss 0.00042458620737306774\n",
      "Test Epoch62 layer6 out_loss 0.0004358983424026519\n",
      "Train 63 | out_loss 0.0012382660061120987: 100%|█| 138/138 [00:00<00:00, 151.25i\n",
      "[[0.00029708 0.10435633]\n",
      " [0.00030776 0.00255386]\n",
      " [0.00043843 0.00108442]\n",
      " [0.00027925 0.00055026]\n",
      " [0.00023379 0.00026513]\n",
      " [0.00017273 0.00018092]\n",
      " [0.00015194 0.00013169]]\n",
      "Train Epoch63 out_loss 0.0012382660061120987\n",
      "Test Epoch63 layer0 out_loss 0.015432163141667843\n",
      "Test Epoch63 layer1 out_loss 0.0017888437723740935\n",
      "Test Epoch63 layer2 out_loss 0.00048337201587855816\n",
      "Test Epoch63 layer3 out_loss 0.00043225311674177647\n",
      "Test Epoch63 layer4 out_loss 0.0004875789163634181\n",
      "Test Epoch63 layer5 out_loss 0.00046072862460277975\n",
      "Test Epoch63 layer6 out_loss 0.00045491012861020863\n",
      "Train 64 | out_loss 0.0013098648050799966: 100%|█| 138/138 [00:00<00:00, 153.57i\n",
      "[[0.00032699 0.04949702]\n",
      " [0.00053653 0.00239686]\n",
      " [0.00064064 0.00174851]\n",
      " [0.00048672 0.00096566]\n",
      " [0.00050347 0.00049145]\n",
      " [0.00028544 0.0002553 ]\n",
      " [0.00021435 0.00016685]]\n",
      "Train Epoch64 out_loss 0.0013098648050799966\n",
      "Test Epoch64 layer0 out_loss 0.0026914195623248816\n",
      "Test Epoch64 layer1 out_loss 0.000545065850019455\n",
      "Test Epoch64 layer2 out_loss 0.00043456017738208175\n",
      "Test Epoch64 layer3 out_loss 0.0006815193337388337\n",
      "Test Epoch64 layer4 out_loss 0.0005549831548705697\n",
      "Test Epoch64 layer5 out_loss 0.0005553007940761745\n",
      "Test Epoch64 layer6 out_loss 0.0005244673229753971\n",
      "Train 65 | out_loss 0.0011851873714476824: 100%|█| 138/138 [00:00<00:00, 150.85i\n",
      "[[0.00026364 0.00448529]\n",
      " [0.00047077 0.00162144]\n",
      " [0.00074789 0.00147598]\n",
      " [0.000468   0.00067775]\n",
      " [0.00029258 0.0003458 ]\n",
      " [0.00026502 0.00026525]\n",
      " [0.00023233 0.00018244]]\n",
      "Train Epoch65 out_loss 0.0011851873714476824\n",
      "Test Epoch65 layer0 out_loss 0.002879174891859293\n",
      "Test Epoch65 layer1 out_loss 0.0008578579872846603\n",
      "Test Epoch65 layer2 out_loss 0.0007120402879081666\n",
      "Test Epoch65 layer3 out_loss 0.0005370326107367873\n",
      "Test Epoch65 layer4 out_loss 0.0005347695550881326\n",
      "Test Epoch65 layer5 out_loss 0.0005591046647168696\n",
      "Test Epoch65 layer6 out_loss 0.0005401110975071788\n",
      "Train 66 | out_loss 0.0016536804614588618: 100%|█| 138/138 [00:00<00:00, 151.39i\n",
      "[[0.00057428 0.02343456]\n",
      " [0.00034569 0.00160129]\n",
      " [0.00042161 0.00108242]\n",
      " [0.00030807 0.00050681]\n",
      " [0.00023378 0.00028433]\n",
      " [0.00023216 0.00022499]\n",
      " [0.00021235 0.00018471]]\n",
      "Train Epoch66 out_loss 0.0016536804614588618\n",
      "Test Epoch66 layer0 out_loss 0.01478955615311861\n",
      "Test Epoch66 layer1 out_loss 0.0009417994297109544\n",
      "Test Epoch66 layer2 out_loss 0.0004378484154585749\n",
      "Test Epoch66 layer3 out_loss 0.00043447446660138667\n",
      "Test Epoch66 layer4 out_loss 0.0004138289368711412\n",
      "Test Epoch66 layer5 out_loss 0.00040779999108053744\n",
      "Test Epoch66 layer6 out_loss 0.0004077760095242411\n",
      "Train 67 | out_loss 0.0014017969369888306: 100%|█| 138/138 [00:00<00:00, 154.04i\n",
      "[[0.0003808  0.05278427]\n",
      " [0.0004155  0.00244365]\n",
      " [0.00057832 0.00134959]\n",
      " [0.00033422 0.0007047 ]\n",
      " [0.00025434 0.00034815]\n",
      " [0.00027782 0.00026431]\n",
      " [0.00015758 0.00013807]]\n",
      "Train Epoch67 out_loss 0.0014017969369888306\n",
      "Test Epoch67 layer0 out_loss 0.004922961816191673\n",
      "Test Epoch67 layer1 out_loss 0.0006697645294480026\n",
      "Test Epoch67 layer2 out_loss 0.0006233603926375508\n",
      "Test Epoch67 layer3 out_loss 0.0005225351196713746\n",
      "Test Epoch67 layer4 out_loss 0.0005286438390612602\n",
      "Test Epoch67 layer5 out_loss 0.0005248484085313976\n",
      "Test Epoch67 layer6 out_loss 0.0005368729471229017\n",
      "Train 68 | out_loss 0.0011477001244202256: 100%|█| 138/138 [00:00<00:00, 151.43i\n",
      "[[0.00030105 0.02511086]\n",
      " [0.0004354  0.00202054]\n",
      " [0.0005409  0.00113578]\n",
      " [0.00033992 0.0006954 ]\n",
      " [0.00030033 0.00030633]\n",
      " [0.00042371 0.00045458]\n",
      " [0.00019459 0.0001694 ]]\n",
      "Train Epoch68 out_loss 0.0011477001244202256\n",
      "Test Epoch68 layer0 out_loss 0.003959399648010731\n",
      "Test Epoch68 layer1 out_loss 0.0006461996235884726\n",
      "Test Epoch68 layer2 out_loss 0.0009646295802667737\n",
      "Test Epoch68 layer3 out_loss 0.00044166113366372883\n",
      "Test Epoch68 layer4 out_loss 0.0004204097203910351\n",
      "Test Epoch68 layer5 out_loss 0.00040704302955418825\n",
      "Test Epoch68 layer6 out_loss 0.0004074323223903775\n",
      "Train 69 | out_loss 0.0015768053708598018: 100%|█| 138/138 [00:00<00:00, 157.45i\n",
      "[[4.95463856e-04 6.16817963e-03]\n",
      " [3.62294403e-04 1.59456183e-03]\n",
      " [5.08927884e-04 1.26422707e-03]\n",
      " [3.61921245e-04 5.63263499e-04]\n",
      " [2.93686665e-04 2.64741901e-04]\n",
      " [1.74839654e-04 1.61424302e-04]\n",
      " [1.01812317e-04 9.33479331e-05]]\n",
      "Train Epoch69 out_loss 0.0015768053708598018\n",
      "Test Epoch69 layer0 out_loss 0.002594039076939225\n",
      "Test Epoch69 layer1 out_loss 0.0005689465906471014\n",
      "Test Epoch69 layer2 out_loss 0.0005412076134234667\n",
      "Test Epoch69 layer3 out_loss 0.0004959569778293371\n",
      "Test Epoch69 layer4 out_loss 0.0004963916726410389\n",
      "Test Epoch69 layer5 out_loss 0.0005291927955113351\n",
      "Test Epoch69 layer6 out_loss 0.0005214419215917587\n",
      "Train 70 | out_loss 0.0011842309031635523: 100%|█| 138/138 [00:00<00:00, 154.22i\n",
      "[[0.00025372 0.03221705]\n",
      " [0.00048018 0.00291491]\n",
      " [0.0007054  0.00147244]\n",
      " [0.00043897 0.00080713]\n",
      " [0.00030604 0.00032256]\n",
      " [0.000309   0.00032867]\n",
      " [0.00019957 0.00018841]]\n",
      "Train Epoch70 out_loss 0.0011842309031635523\n",
      "Test Epoch70 layer0 out_loss 0.008438507094979286\n",
      "Test Epoch70 layer1 out_loss 0.003985450137406588\n",
      "Test Epoch70 layer2 out_loss 0.0034512896090745926\n",
      "Test Epoch70 layer3 out_loss 0.0031733354553580284\n",
      "Test Epoch70 layer4 out_loss 0.0031342236325144768\n",
      "Test Epoch70 layer5 out_loss 0.003198408056050539\n",
      "Test Epoch70 layer6 out_loss 0.0032015887554734945\n",
      "Train 71 | out_loss 0.0008527395548298955: 100%|█| 138/138 [00:00<00:00, 157.83i\n",
      "[[1.36021791e-04 1.59138563e-01]\n",
      " [3.23309187e-04 3.78460969e-03]\n",
      " [4.83439516e-04 1.89221852e-03]\n",
      " [3.96175099e-04 8.43004795e-04]\n",
      " [2.77263131e-04 4.41265176e-04]\n",
      " [3.47774924e-04 4.17441010e-04]\n",
      " [3.46184440e-04 3.51408127e-04]]\n",
      "Train Epoch71 out_loss 0.0008527395548298955\n",
      "Test Epoch71 layer0 out_loss 0.011673777364194393\n",
      "Test Epoch71 layer1 out_loss 0.0016779518919065595\n",
      "Test Epoch71 layer2 out_loss 0.000927526387386024\n",
      "Test Epoch71 layer3 out_loss 0.0010982126696035266\n",
      "Test Epoch71 layer4 out_loss 0.001208230503834784\n",
      "Test Epoch71 layer5 out_loss 0.0013053412549197674\n",
      "Test Epoch71 layer6 out_loss 0.0013172861654311419\n",
      "Train 72 | out_loss 0.0013223737478256226: 100%|█| 138/138 [00:00<00:00, 155.21i\n",
      "[[0.00037781 0.01052986]\n",
      " [0.00042758 0.00158878]\n",
      " [0.00056952 0.00097925]\n",
      " [0.00038032 0.00044078]\n",
      " [0.00022018 0.00024478]\n",
      " [0.00017129 0.00016646]\n",
      " [0.00018065 0.00013123]]\n",
      "Train Epoch72 out_loss 0.0013223737478256226\n",
      "Test Epoch72 layer0 out_loss 0.002546131843701005\n",
      "Test Epoch72 layer1 out_loss 0.0005974790547043085\n",
      "Test Epoch72 layer2 out_loss 0.0004927255213260651\n",
      "Test Epoch72 layer3 out_loss 0.0004634341166820377\n",
      "Test Epoch72 layer4 out_loss 0.0004308159404899925\n",
      "Test Epoch72 layer5 out_loss 0.0004265646857675165\n",
      "Test Epoch72 layer6 out_loss 0.00042439650860615075\n",
      "Train 73 | out_loss 0.0014385097892954946: 100%|█| 138/138 [00:00<00:00, 152.39i\n",
      "[[0.00040923 0.01423528]\n",
      " [0.00039802 0.00179526]\n",
      " [0.0005617  0.00132631]\n",
      " [0.0005508  0.00078235]\n",
      " [0.00029733 0.00035376]\n",
      " [0.00023651 0.00024344]\n",
      " [0.00027467 0.0002522 ]]\n",
      "Train Epoch73 out_loss 0.0014385097892954946\n",
      "Test Epoch73 layer0 out_loss 0.003503356594592333\n",
      "Test Epoch73 layer1 out_loss 0.0007090746657922864\n",
      "Test Epoch73 layer2 out_loss 0.00045412080362439156\n",
      "Test Epoch73 layer3 out_loss 0.0004200573021080345\n",
      "Test Epoch73 layer4 out_loss 0.0004157372750341892\n",
      "Test Epoch73 layer5 out_loss 0.0004133782349526882\n",
      "Test Epoch73 layer6 out_loss 0.00040978228207677603\n",
      "Train 74 | out_loss 0.0013573839096352458: 100%|█| 138/138 [00:00<00:00, 153.29i\n",
      "[[0.00037922 0.01314607]\n",
      " [0.00031917 0.00163082]\n",
      " [0.00041516 0.0009307 ]\n",
      " [0.00026614 0.00042617]\n",
      " [0.00021223 0.00025438]\n",
      " [0.00017465 0.00017686]\n",
      " [0.00018256 0.0001279 ]]\n",
      "Train Epoch74 out_loss 0.0013573839096352458\n",
      "Test Epoch74 layer0 out_loss 0.0024614008143544197\n",
      "Test Epoch74 layer1 out_loss 0.0007608455489389598\n",
      "Test Epoch74 layer2 out_loss 0.000431373919127509\n",
      "Test Epoch74 layer3 out_loss 0.0004658265970647335\n",
      "Test Epoch74 layer4 out_loss 0.0004962605307810009\n",
      "Test Epoch74 layer5 out_loss 0.0005210801609791815\n",
      "Test Epoch74 layer6 out_loss 0.0005308892577886581\n",
      "Train 75 | out_loss 0.0014872066676616669: 100%|█| 138/138 [00:00<00:00, 157.91i\n",
      "[[4.62687892e-04 7.49737098e-03]\n",
      " [4.87726666e-04 2.12718664e-03]\n",
      " [6.85782115e-04 1.21112547e-03]\n",
      " [3.60015081e-04 4.74727271e-04]\n",
      " [2.68051049e-04 2.56498568e-04]\n",
      " [1.65750705e-04 1.48936599e-04]\n",
      " [1.22690865e-04 9.78482979e-05]]\n",
      "Train Epoch75 out_loss 0.0014872066676616669\n",
      "Test Epoch75 layer0 out_loss 0.0037323643919080496\n",
      "Test Epoch75 layer1 out_loss 0.0008817767957225442\n",
      "Test Epoch75 layer2 out_loss 0.0004964962136000395\n",
      "Test Epoch75 layer3 out_loss 0.0006189754931256175\n",
      "Test Epoch75 layer4 out_loss 0.0005269727553240955\n",
      "Test Epoch75 layer5 out_loss 0.0005380813381634653\n",
      "Test Epoch75 layer6 out_loss 0.0005524347652681172\n",
      "Train 76 | out_loss 0.0016329053323715925: 100%|█| 138/138 [00:00<00:00, 153.82i\n",
      "[[0.00057873 0.02851662]\n",
      " [0.00035327 0.00286065]\n",
      " [0.00052743 0.00128297]\n",
      " [0.00032063 0.00062677]\n",
      " [0.00030083 0.00030747]\n",
      " [0.00020259 0.00020203]\n",
      " [0.00016601 0.00013027]]\n",
      "Train Epoch76 out_loss 0.0016329053323715925\n",
      "Test Epoch76 layer0 out_loss 0.039844412356615067\n",
      "Test Epoch76 layer1 out_loss 0.004371084272861481\n",
      "Test Epoch76 layer2 out_loss 0.0014216576237231493\n",
      "Test Epoch76 layer3 out_loss 0.0007463002693839371\n",
      "Test Epoch76 layer4 out_loss 0.0006403133738785982\n",
      "Test Epoch76 layer5 out_loss 0.0005878315423615277\n",
      "Test Epoch76 layer6 out_loss 0.0006299985689111054\n",
      "Train 77 | out_loss 0.0006013013771735132: 100%|█| 138/138 [00:00<00:00, 154.35i\n",
      "[[3.15187263e-05 2.70343540e-02]\n",
      " [3.77915158e-04 2.62956031e-03]\n",
      " [5.34558793e-04 1.24589203e-03]\n",
      " [3.14610947e-04 5.77601282e-04]\n",
      " [5.90351838e-04 6.66988656e-04]\n",
      " [2.99026786e-04 3.44041707e-04]\n",
      " [2.45007800e-04 1.99151006e-04]]\n",
      "Train Epoch77 out_loss 0.0006013013771735132\n",
      "Test Epoch77 layer0 out_loss 0.0027161140460520983\n",
      "Test Epoch77 layer1 out_loss 0.0007527839043177664\n",
      "Test Epoch77 layer2 out_loss 0.0003992914280388504\n",
      "Test Epoch77 layer3 out_loss 0.000507563236169517\n",
      "Test Epoch77 layer4 out_loss 0.00046899335575290024\n",
      "Test Epoch77 layer5 out_loss 0.0004854911530856043\n",
      "Test Epoch77 layer6 out_loss 0.00047743599861860275\n",
      "Train 78 | out_loss 0.0012659886851906776: 100%|█| 138/138 [00:00<00:00, 154.00i\n",
      "[[0.0003492  0.00599763]\n",
      " [0.00040583 0.00150744]\n",
      " [0.0005696  0.00109457]\n",
      " [0.00030855 0.00048201]\n",
      " [0.00035069 0.00034957]\n",
      " [0.00017466 0.000157  ]\n",
      " [0.00014419 0.00010663]]\n",
      "Train Epoch78 out_loss 0.0012659886851906776\n",
      "Test Epoch78 layer0 out_loss 0.00201502931304276\n",
      "Test Epoch78 layer1 out_loss 0.0006458606221713126\n",
      "Test Epoch78 layer2 out_loss 0.0008137438562698662\n",
      "Test Epoch78 layer3 out_loss 0.0004126694693695754\n",
      "Test Epoch78 layer4 out_loss 0.0004269119235686958\n",
      "Test Epoch78 layer5 out_loss 0.000433759210864082\n",
      "Test Epoch78 layer6 out_loss 0.0004082895757164806\n",
      "Train 79 | out_loss 0.0012332032201811671: 100%|█| 138/138 [00:00<00:00, 147.72i\n",
      "[[0.00032209 0.00649453]\n",
      " [0.0003179  0.00140058]\n",
      " [0.00041175 0.00100936]\n",
      " [0.0002854  0.00044291]\n",
      " [0.00024093 0.00026157]\n",
      " [0.0001697  0.00018302]\n",
      " [0.00020385 0.00017073]]\n",
      "Train Epoch79 out_loss 0.0012332032201811671\n",
      "Test Epoch79 layer0 out_loss 0.0033113209065049887\n",
      "Test Epoch79 layer1 out_loss 0.0007132422178983688\n",
      "Test Epoch79 layer2 out_loss 0.0008195469272322953\n",
      "Test Epoch79 layer3 out_loss 0.0005408570868894458\n",
      "Test Epoch79 layer4 out_loss 0.0005812991294078529\n",
      "Test Epoch79 layer5 out_loss 0.0005386322154663503\n",
      "Test Epoch79 layer6 out_loss 0.0005556937539950013\n",
      "Train 80 | out_loss 0.0012730656890198588: 100%|█| 138/138 [00:00<00:00, 153.12i\n",
      "[[0.0003456  0.03327541]\n",
      " [0.00036317 0.0030197 ]\n",
      " [0.00052926 0.00163628]\n",
      " [0.00031531 0.00059462]\n",
      " [0.00024617 0.00028941]\n",
      " [0.00019473 0.00020998]\n",
      " [0.00018485 0.00013275]]\n",
      "Train Epoch80 out_loss 0.0012730656890198588\n",
      "Test Epoch80 layer0 out_loss 0.013228064402937889\n",
      "Test Epoch80 layer1 out_loss 0.001190385315567255\n",
      "Test Epoch80 layer2 out_loss 0.000537036219611764\n",
      "Test Epoch80 layer3 out_loss 0.0005012530600652099\n",
      "Test Epoch80 layer4 out_loss 0.00043577069300226867\n",
      "Test Epoch80 layer5 out_loss 0.0004596949729602784\n",
      "Test Epoch80 layer6 out_loss 0.000446300400653854\n",
      "Train 81 | out_loss 0.0014332259306684136: 100%|█| 138/138 [00:00<00:00, 154.60i\n",
      "[[0.00043962 0.04785949]\n",
      " [0.00025946 0.00376044]\n",
      " [0.00034584 0.00112354]\n",
      " [0.00021998 0.0005758 ]\n",
      " [0.00021756 0.000293  ]\n",
      " [0.00016037 0.00019493]\n",
      " [0.00014878 0.00013301]]\n",
      "Train Epoch81 out_loss 0.0014332259306684136\n",
      "Test Epoch81 layer0 out_loss 0.013233768753707409\n",
      "Test Epoch81 layer1 out_loss 0.001116065657697618\n",
      "Test Epoch81 layer2 out_loss 0.0006207957630977035\n",
      "Test Epoch81 layer3 out_loss 0.0005793909658677876\n",
      "Test Epoch81 layer4 out_loss 0.0005628546932712197\n",
      "Test Epoch81 layer5 out_loss 0.0004692522925324738\n",
      "Test Epoch81 layer6 out_loss 0.0004876211751252413\n",
      "Train 82 | out_loss 0.0016952559817582369: 100%|█| 138/138 [00:00<00:00, 154.89i\n",
      "[[0.0005952  0.03819145]\n",
      " [0.00037638 0.00271678]\n",
      " [0.00056249 0.00107914]\n",
      " [0.0002905  0.00052578]\n",
      " [0.00022881 0.00031142]\n",
      " [0.00018432 0.00020929]\n",
      " [0.00017218 0.00014188]]\n",
      "Train Epoch82 out_loss 0.0016952559817582369\n",
      "Test Epoch82 layer0 out_loss 0.002972259884700179\n",
      "Test Epoch82 layer1 out_loss 0.0005700078909285367\n",
      "Test Epoch82 layer2 out_loss 0.0005769492127001286\n",
      "Test Epoch82 layer3 out_loss 0.0006758145173080266\n",
      "Test Epoch82 layer4 out_loss 0.0006483036559075117\n",
      "Test Epoch82 layer5 out_loss 0.0006011931109242141\n",
      "Test Epoch82 layer6 out_loss 0.0006298098596744239\n",
      "Train 83 | out_loss 0.000486145872855559: 100%|█| 138/138 [00:00<00:00, 149.37it\n",
      "[[8.75286521e-06 1.33512913e-02]\n",
      " [2.94861495e-04 1.43465719e-03]\n",
      " [3.62562283e-04 9.43548483e-04]\n",
      " [2.55274776e-04 4.21461539e-04]\n",
      " [2.46552996e-04 2.22723425e-04]\n",
      " [1.56018537e-04 1.51525910e-04]\n",
      " [1.29829992e-04 9.93016504e-05]]\n",
      "Train Epoch83 out_loss 0.000486145872855559\n",
      "Test Epoch83 layer0 out_loss 0.0024811504408717155\n",
      "Test Epoch83 layer1 out_loss 0.0006837491528131068\n",
      "Test Epoch83 layer2 out_loss 0.0006838408298790455\n",
      "Test Epoch83 layer3 out_loss 0.0005345781682990491\n",
      "Test Epoch83 layer4 out_loss 0.0005962160648778081\n",
      "Test Epoch83 layer5 out_loss 0.0004943237290717661\n",
      "Test Epoch83 layer6 out_loss 0.0004991330206394196\n",
      "Train 84 | out_loss 0.0015689728315919638: 100%|█| 138/138 [00:00<00:00, 152.32i\n",
      "[[0.00052906 0.00420257]\n",
      " [0.00038597 0.00148969]\n",
      " [0.0006026  0.00119539]\n",
      " [0.00034251 0.0004339 ]\n",
      " [0.00039668 0.00037753]\n",
      " [0.00030199 0.00027184]\n",
      " [0.00018017 0.00015309]]\n",
      "Train Epoch84 out_loss 0.0015689728315919638\n",
      "Test Epoch84 layer0 out_loss 0.003433695761486888\n",
      "Test Epoch84 layer1 out_loss 0.000493965984787792\n",
      "Test Epoch84 layer2 out_loss 0.000462078838609159\n",
      "Test Epoch84 layer3 out_loss 0.00048260990297421813\n",
      "Test Epoch84 layer4 out_loss 0.0004697550320997834\n",
      "Test Epoch84 layer5 out_loss 0.00048725909437052906\n",
      "Test Epoch84 layer6 out_loss 0.00047552213072776794\n",
      "Train 85 | out_loss 0.001454086392186582: 100%|█| 138/138 [00:00<00:00, 156.55it\n",
      "[[0.00045117 0.01076992]\n",
      " [0.0002854  0.00170789]\n",
      " [0.00043558 0.00099998]\n",
      " [0.00030419 0.00054473]\n",
      " [0.0002806  0.00032598]\n",
      " [0.00029188 0.00027209]\n",
      " [0.00021243 0.00017268]]\n",
      "Train Epoch85 out_loss 0.001454086392186582\n",
      "Test Epoch85 layer0 out_loss 0.005918755196034908\n",
      "Test Epoch85 layer1 out_loss 0.0040507749654352665\n",
      "Test Epoch85 layer2 out_loss 0.005070158746093512\n",
      "Test Epoch85 layer3 out_loss 0.004595999140292406\n",
      "Test Epoch85 layer4 out_loss 0.004633744712918997\n",
      "Test Epoch85 layer5 out_loss 0.0045510404743254185\n",
      "Test Epoch85 layer6 out_loss 0.004626641049981117\n",
      "Train 86 | out_loss 0.002765597077086568: 100%|█| 138/138 [00:00<00:00, 142.13it\n",
      "[[0.00020384 0.04398983]\n",
      " [0.01004473 0.05585011]\n",
      " [0.02982489 0.07089659]\n",
      " [0.04225345 0.08185668]\n",
      " [0.07428815 0.12453193]\n",
      " [0.12691592 0.15098232]\n",
      " [0.13373353 0.18103082]]\n",
      "Train Epoch86 out_loss 0.002765597077086568\n",
      "Test Epoch86 layer0 out_loss 0.0028046038933098316\n",
      "Test Epoch86 layer1 out_loss 0.01157226599752903\n",
      "Test Epoch86 layer2 out_loss 0.005928659811615944\n",
      "Test Epoch86 layer3 out_loss 0.002304425463080406\n",
      "Test Epoch86 layer4 out_loss 0.0019216110231354833\n",
      "Test Epoch86 layer5 out_loss 0.012335248291492462\n",
      "Test Epoch86 layer6 out_loss 0.004009529948234558\n",
      "Train 87 | out_loss 0.010645316913723946: 100%|█| 138/138 [00:00<00:00, 146.25it\n",
      "[[0.00045276 0.01760966]\n",
      " [0.00081054 0.01654141]\n",
      " [0.00557616 0.02563663]\n",
      " [0.01629248 0.054472  ]\n",
      " [0.0576308  0.10824082]\n",
      " [0.09847686 0.19375485]\n",
      " [0.14071674 0.20736529]]\n",
      "Train Epoch87 out_loss 0.010645316913723946\n",
      "Test Epoch87 layer0 out_loss 0.002538159256801009\n",
      "Test Epoch87 layer1 out_loss 0.0007214834331534803\n",
      "Test Epoch87 layer2 out_loss 0.0006068223738111556\n",
      "Test Epoch87 layer3 out_loss 0.0006192910950630903\n",
      "Test Epoch87 layer4 out_loss 0.0006188160623423755\n",
      "Test Epoch87 layer5 out_loss 0.0006478857831098139\n",
      "Test Epoch87 layer6 out_loss 0.0019186175195500255\n",
      "Train 88 | out_loss 0.0010246799793094397: 100%|█| 138/138 [00:00<00:00, 151.50i\n",
      "[[3.62531365e-06 4.28128341e-03]\n",
      " [6.30468489e-06 3.71793983e-04]\n",
      " [3.80849052e-06 2.25771885e-04]\n",
      " [1.35006327e-05 2.98991816e-04]\n",
      " [4.49500750e-06 6.41631352e-04]\n",
      " [6.16144745e-06 5.83684753e-04]\n",
      " [8.68234215e-06 6.90901213e-04]]\n",
      "Train Epoch88 out_loss 0.0010246799793094397\n",
      "Test Epoch88 layer0 out_loss 0.0019760322757065296\n",
      "Test Epoch88 layer1 out_loss 0.0008889249875210226\n",
      "Test Epoch88 layer2 out_loss 0.00046847251360304654\n",
      "Test Epoch88 layer3 out_loss 0.0004674658121075481\n",
      "Test Epoch88 layer4 out_loss 0.00043097787420265377\n",
      "Test Epoch88 layer5 out_loss 0.000522140646353364\n",
      "Test Epoch88 layer6 out_loss 0.000871466938406229\n",
      "Train 89 | out_loss 0.0023741922341287136: 100%|█| 138/138 [00:00<00:00, 153.88i\n",
      "[[8.28596485e-04 1.64707300e-02]\n",
      " [6.76270628e-06 9.94121239e-04]\n",
      " [4.61956085e-06 2.84334028e-04]\n",
      " [8.65027251e-06 2.63913467e-04]\n",
      " [5.52778718e-06 4.41728256e-04]\n",
      " [6.06529564e-06 4.66047294e-04]\n",
      " [4.48509336e-06 4.94485729e-04]]\n",
      "Train Epoch89 out_loss 0.0023741922341287136\n",
      "Test Epoch89 layer0 out_loss 0.002584078349173069\n",
      "Test Epoch89 layer1 out_loss 0.00045265330118127167\n",
      "Test Epoch89 layer2 out_loss 0.0004501983057707548\n",
      "Test Epoch89 layer3 out_loss 0.00043071480467915535\n",
      "Test Epoch89 layer4 out_loss 0.0004395936557557434\n",
      "Test Epoch89 layer5 out_loss 0.0005434169434010983\n",
      "Test Epoch89 layer6 out_loss 0.0008521076524630189\n",
      "Train 90 | out_loss 0.0007764152833260596: 100%|█| 138/138 [00:00<00:00, 155.57i\n",
      "[[3.50064103e-09 3.59771241e-03]\n",
      " [6.69536673e-06 3.23460262e-04]\n",
      " [5.87049285e-06 1.33664756e-04]\n",
      " [2.27417687e-05 1.33899073e-04]\n",
      " [8.05944699e-06 2.22780220e-04]\n",
      " [8.77230764e-06 3.05311468e-04]\n",
      " [7.16445738e-06 3.57808407e-04]]\n",
      "Train Epoch90 out_loss 0.0007764152833260596\n",
      "Test Epoch90 layer0 out_loss 0.003617621958255768\n",
      "Test Epoch90 layer1 out_loss 0.0009100871393457055\n",
      "Test Epoch90 layer2 out_loss 0.0005059834220446646\n",
      "Test Epoch90 layer3 out_loss 0.00047682112199254334\n",
      "Test Epoch90 layer4 out_loss 0.0005143158487044275\n",
      "Test Epoch90 layer5 out_loss 0.0004944910178892314\n",
      "Test Epoch90 layer6 out_loss 0.0007319796131923795\n",
      "Train 91 | out_loss 0.002162402495741844: 100%|█| 138/138 [00:00<00:00, 154.91it\n",
      "[[7.21955077e-04 1.80561507e-02]\n",
      " [7.08030088e-06 1.16145664e-03]\n",
      " [5.00636070e-06 2.61619401e-04]\n",
      " [2.37664370e-05 2.10067252e-04]\n",
      " [7.19762858e-06 2.65810603e-04]\n",
      " [8.73314958e-06 3.22370586e-04]\n",
      " [7.04061355e-06 3.55203707e-04]]\n",
      "Train Epoch91 out_loss 0.002162402495741844\n",
      "Test Epoch91 layer0 out_loss 0.004137665033340454\n",
      "Test Epoch91 layer1 out_loss 0.0008448771550320089\n",
      "Test Epoch91 layer2 out_loss 0.00042460401891730726\n",
      "Test Epoch91 layer3 out_loss 0.0004146546998526901\n",
      "Test Epoch91 layer4 out_loss 0.0004247404867783189\n",
      "Test Epoch91 layer5 out_loss 0.0005289143300615251\n",
      "Test Epoch91 layer6 out_loss 0.0007522233063355088\n",
      "Train 92 | out_loss 0.0006752656190656126: 100%|█| 138/138 [00:00<00:00, 151.13i\n",
      "[[5.74679975e-08 4.36213290e-03]\n",
      " [8.62408356e-05 4.58429030e-04]\n",
      " [8.51977626e-05 1.94858771e-04]\n",
      " [1.01390140e-04 1.79185613e-04]\n",
      " [9.89923224e-05 2.41823529e-04]\n",
      " [1.19675517e-04 3.36359862e-04]\n",
      " [9.52272181e-05 3.50143538e-04]]\n",
      "Train Epoch92 out_loss 0.0006752656190656126\n",
      "Test Epoch92 layer0 out_loss 0.002872622339054942\n",
      "Test Epoch92 layer1 out_loss 0.0004734765680041164\n",
      "Test Epoch92 layer2 out_loss 0.0004163270932622254\n",
      "Test Epoch92 layer3 out_loss 0.00041498057544231415\n",
      "Test Epoch92 layer4 out_loss 0.0004130791639909148\n",
      "Test Epoch92 layer5 out_loss 0.00046557257883250713\n",
      "Test Epoch92 layer6 out_loss 0.0006328265881165862\n",
      "Train 93 | out_loss 0.002070146845653653: 100%|█| 138/138 [00:00<00:00, 149.98it\n",
      "[[6.89217412e-04 2.04305782e-02]\n",
      " [7.90532056e-06 2.01723681e-03]\n",
      " [5.54426697e-06 3.76577475e-04]\n",
      " [1.01625921e-05 2.46220305e-04]\n",
      " [5.81579472e-06 3.03625858e-04]\n",
      " [5.73526770e-06 2.89063520e-04]\n",
      " [4.77805222e-06 3.20976493e-04]]\n",
      "Train Epoch93 out_loss 0.002070146845653653\n",
      "Test Epoch93 layer0 out_loss 0.003134567989036441\n",
      "Test Epoch93 layer1 out_loss 0.00048328936100006104\n",
      "Test Epoch93 layer2 out_loss 0.00041674060048535466\n",
      "Test Epoch93 layer3 out_loss 0.00041732980753295124\n",
      "Test Epoch93 layer4 out_loss 0.0004381677426863462\n",
      "Test Epoch93 layer5 out_loss 0.0004397227894514799\n",
      "Test Epoch93 layer6 out_loss 0.0006316896178759634\n",
      "Train 94 | out_loss 0.0007107597193680704: 100%|█| 138/138 [00:00<00:00, 150.12i\n",
      "[[9.48090946e-08 4.58615173e-02]\n",
      " [7.48499491e-06 4.89688034e-03]\n",
      " [7.50169185e-06 9.44584729e-04]\n",
      " [5.39574952e-05 5.90539208e-04]\n",
      " [1.50430488e-05 5.79720086e-04]\n",
      " [1.89353297e-05 5.12322002e-04]\n",
      " [1.46861041e-05 5.15062465e-04]]\n",
      "Train Epoch94 out_loss 0.0007107597193680704\n",
      "Test Epoch94 layer0 out_loss 0.0030843899585306644\n",
      "Test Epoch94 layer1 out_loss 0.0009139423491433263\n",
      "Test Epoch94 layer2 out_loss 0.00043858919525519013\n",
      "Test Epoch94 layer3 out_loss 0.0004311867814976722\n",
      "Test Epoch94 layer4 out_loss 0.0004033747536595911\n",
      "Test Epoch94 layer5 out_loss 0.0004036622995045036\n",
      "Test Epoch94 layer6 out_loss 0.0005804327665828168\n",
      "Train 95 | out_loss 0.002135076792910695: 100%|█| 138/138 [00:00<00:00, 155.31it\n",
      "[[7.81884825e-04 2.94494058e-03]\n",
      " [4.94547586e-05 3.93877049e-04]\n",
      " [5.43759902e-05 1.92474375e-04]\n",
      " [1.40548123e-04 1.80485637e-04]\n",
      " [4.55100794e-05 1.77849793e-04]\n",
      " [5.22100696e-05 1.98492977e-04]\n",
      " [3.90542876e-05 2.10498160e-04]]\n",
      "Train Epoch95 out_loss 0.002135076792910695\n",
      "Test Epoch95 layer0 out_loss 0.002269319025799632\n",
      "Test Epoch95 layer1 out_loss 0.0005135095561854541\n",
      "Test Epoch95 layer2 out_loss 0.0004840228066314012\n",
      "Test Epoch95 layer3 out_loss 0.0005547465407289565\n",
      "Test Epoch95 layer4 out_loss 0.0004397148732095957\n",
      "Test Epoch95 layer5 out_loss 0.0004897290491499007\n",
      "Test Epoch95 layer6 out_loss 0.0005817027413286269\n",
      "Train 96 | out_loss 0.0005978594999760389: 100%|█| 138/138 [00:00<00:00, 153.52i\n",
      "[[5.60558107e-08 7.61531755e-03]\n",
      " [1.47083027e-04 1.12152294e-03]\n",
      " [1.44120638e-04 2.92824559e-04]\n",
      " [1.59710988e-04 2.37856244e-04]\n",
      " [9.04511271e-05 2.56476647e-04]\n",
      " [9.57430489e-05 2.67758173e-04]\n",
      " [8.16178782e-05 2.44721054e-04]]\n",
      "Train Epoch96 out_loss 0.0005978594999760389\n",
      "Test Epoch96 layer0 out_loss 0.001829840475693345\n",
      "Test Epoch96 layer1 out_loss 0.0005869744927622378\n",
      "Test Epoch96 layer2 out_loss 0.00048791654990054667\n",
      "Test Epoch96 layer3 out_loss 0.00042657522135414183\n",
      "Test Epoch96 layer4 out_loss 0.0004206908924970776\n",
      "Test Epoch96 layer5 out_loss 0.0004575617494992912\n",
      "Test Epoch96 layer6 out_loss 0.0005488558090291917\n",
      "Train 97 | out_loss 0.0014688472729176283: 100%|█| 138/138 [00:00<00:00, 149.07i\n",
      "[[3.83694455e-04 2.34253158e-03]\n",
      " [9.24591307e-05 5.21152566e-04]\n",
      " [1.00804457e-04 1.90442611e-04]\n",
      " [5.62451615e-05 1.25452158e-04]\n",
      " [3.81956615e-05 1.36335117e-04]\n",
      " [4.36694788e-05 1.52960266e-04]\n",
      " [3.34004005e-05 1.59015584e-04]]\n",
      "Train Epoch97 out_loss 0.0014688472729176283\n",
      "Test Epoch97 layer0 out_loss 0.0023721486795693636\n",
      "Test Epoch97 layer1 out_loss 0.0006460893782787025\n",
      "Test Epoch97 layer2 out_loss 0.00043252401519566774\n",
      "Test Epoch97 layer3 out_loss 0.00042851900798268616\n",
      "Test Epoch97 layer4 out_loss 0.0004136433999519795\n",
      "Test Epoch97 layer5 out_loss 0.00041292014066129923\n",
      "Test Epoch97 layer6 out_loss 0.0004921883810311556\n",
      "Train 98 | out_loss 0.0015528940130025148: 100%|█| 138/138 [00:00<00:00, 152.36i\n",
      "[[4.57372994e-04 2.36881834e-03]\n",
      " [2.23608680e-04 6.96096709e-04]\n",
      " [2.23251506e-04 3.15700473e-04]\n",
      " [1.10305896e-04 1.62273577e-04]\n",
      " [5.76121375e-05 1.79219698e-04]\n",
      " [5.93720390e-05 1.82153812e-04]\n",
      " [4.63943548e-05 1.66429139e-04]]\n",
      "Train Epoch98 out_loss 0.0015528940130025148\n",
      "Test Epoch98 layer0 out_loss 0.0016938390908762813\n",
      "Test Epoch98 layer1 out_loss 0.0008529822807759047\n",
      "Test Epoch98 layer2 out_loss 0.0004236767708789557\n",
      "Test Epoch98 layer3 out_loss 0.0004181214317213744\n",
      "Test Epoch98 layer4 out_loss 0.0004121208912692964\n",
      "Test Epoch98 layer5 out_loss 0.0004148551670368761\n",
      "Test Epoch98 layer6 out_loss 0.00048050156328827143\n",
      "Train 99 | out_loss 0.001528954366222024: 100%|█| 138/138 [00:00<00:00, 157.09it\n",
      "[[4.50492115e-04 4.06365095e-02]\n",
      " [1.47427413e-04 4.63968414e-03]\n",
      " [1.72150612e-04 1.14340611e-03]\n",
      " [1.31155491e-04 6.12448537e-04]\n",
      " [7.28461822e-05 6.00838636e-04]\n",
      " [1.00746583e-04 4.55421440e-04]\n",
      " [7.75598529e-05 3.53569461e-04]]\n",
      "Train Epoch99 out_loss 0.001528954366222024\n",
      "Test Epoch99 layer0 out_loss 0.011511755175888538\n",
      "Test Epoch99 layer1 out_loss 0.002632052404806018\n",
      "Test Epoch99 layer2 out_loss 0.0007062898948788643\n",
      "Test Epoch99 layer3 out_loss 0.0009105337085202336\n",
      "Test Epoch99 layer4 out_loss 0.0011041549732908607\n",
      "Test Epoch99 layer5 out_loss 0.001175455516204238\n",
      "Test Epoch99 layer6 out_loss 0.0013225399889051914\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Start Training\n",
      "  0%|                                                   | 0/138 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 0.027640430256724358: 100%|█| 138/138 [00:01<00:00, 98.91it/s\n",
      "[[8.19586439e-03 2.54713911e+01]\n",
      " [1.56574458e+00 1.12356714e+01]\n",
      " [9.34288520e-01 5.36292179e+00]\n",
      " [9.07793756e-01 2.85887996e+00]\n",
      " [6.60456895e-01 1.84988194e+00]\n",
      " [7.56090616e-01 1.39551313e+00]\n",
      " [6.85103481e-01 1.00986331e+00]\n",
      " [5.64116210e-01 8.48144067e-01]]\n",
      "Train Epoch0 out_loss 0.027640430256724358\n",
      "Test Epoch0 layer0 out_loss 0.08215098828077316\n",
      "Test Epoch0 layer1 out_loss 0.02213970199227333\n",
      "Test Epoch0 layer2 out_loss 0.007520867511630058\n",
      "Test Epoch0 layer3 out_loss 0.003972274251282215\n",
      "Test Epoch0 layer4 out_loss 0.0021367522422224283\n",
      "Test Epoch0 layer5 out_loss 0.0019367908826097846\n",
      "Test Epoch0 layer6 out_loss 0.003145004855468869\n",
      "Test Epoch0 layer7 out_loss 0.003949040547013283\n",
      "Train 1 | out_loss 0.0021424053702503443: 100%|█| 138/138 [00:00<00:00, 141.48it\n",
      "[[1.64390795e-05 5.91806348e+00]\n",
      " [5.40196243e-06 3.63605339e-01]\n",
      " [6.53189010e-06 1.06286026e-01]\n",
      " [6.05382140e-05 3.37542883e-02]\n",
      " [4.37250020e-04 1.46278993e-02]\n",
      " [2.09238163e-03 1.05558040e-02]\n",
      " [5.53172233e-03 1.00892883e-02]\n",
      " [9.68518775e-03 1.13660299e-02]]\n",
      "Train Epoch1 out_loss 0.0021424053702503443\n",
      "Test Epoch1 layer0 out_loss 0.07975377887487411\n",
      "Test Epoch1 layer1 out_loss 0.015323513187468052\n",
      "Test Epoch1 layer2 out_loss 0.0038804144132882357\n",
      "Test Epoch1 layer3 out_loss 0.001635574852116406\n",
      "Test Epoch1 layer4 out_loss 0.0010113336611539125\n",
      "Test Epoch1 layer5 out_loss 0.0009312305483035743\n",
      "Test Epoch1 layer6 out_loss 0.000655774085316807\n",
      "Test Epoch1 layer7 out_loss 0.0008060227264650166\n",
      "Train 2 | out_loss 0.0007272834773175418: 100%|█| 138/138 [00:00<00:00, 138.31it\n",
      "[[1.69598477e-05 3.21615505e+00]\n",
      " [5.07484283e-06 1.53158465e-01]\n",
      " [1.18897809e-06 4.08658641e-02]\n",
      " [1.01241462e-06 1.23771494e-02]\n",
      " [3.52258107e-06 5.27777741e-03]\n",
      " [3.62608675e-06 2.68139893e-03]\n",
      " [5.00058316e-06 1.45629769e-03]\n",
      " [7.33238418e-06 5.16835735e-04]]\n",
      "Train Epoch2 out_loss 0.0007272834773175418\n",
      "Test Epoch2 layer0 out_loss 0.03670702874660492\n",
      "Test Epoch2 layer1 out_loss 0.0069708744995296\n",
      "Test Epoch2 layer2 out_loss 0.0026867904234677553\n",
      "Test Epoch2 layer3 out_loss 0.0011549595510587096\n",
      "Test Epoch2 layer4 out_loss 0.0008100255508907139\n",
      "Test Epoch2 layer5 out_loss 0.0006572635029442608\n",
      "Test Epoch2 layer6 out_loss 0.0006010623765178025\n",
      "Test Epoch2 layer7 out_loss 0.0006263999384827912\n",
      "Train 3 | out_loss 0.000623489439021796: 100%|█| 138/138 [00:01<00:00, 137.02it/\n",
      "[[1.63201791e-05 1.98346260e+00]\n",
      " [5.14044401e-06 9.80885004e-02]\n",
      " [1.37721871e-06 2.36714197e-02]\n",
      " [1.81026480e-06 7.18951880e-03]\n",
      " [1.05702438e-05 3.19997927e-03]\n",
      " [9.58734611e-06 1.78982808e-03]\n",
      " [1.26322185e-05 1.03279628e-03]\n",
      " [1.87783028e-05 3.89850863e-04]]\n",
      "Train Epoch3 out_loss 0.000623489439021796\n",
      "Test Epoch3 layer0 out_loss 0.09656679630279541\n",
      "Test Epoch3 layer1 out_loss 0.007748556323349476\n",
      "Test Epoch3 layer2 out_loss 0.0029610488563776016\n",
      "Test Epoch3 layer3 out_loss 0.001079292967915535\n",
      "Test Epoch3 layer4 out_loss 0.0007442197529599071\n",
      "Test Epoch3 layer5 out_loss 0.0006876059924252331\n",
      "Test Epoch3 layer6 out_loss 0.0006117291050031781\n",
      "Test Epoch3 layer7 out_loss 0.0005623846082016826\n",
      "Train 4 | out_loss 0.0006059175939299166: 100%|█| 138/138 [00:01<00:00, 133.94it\n",
      "[[1.58795012e-05 1.73951981e+00]\n",
      " [5.76940494e-06 1.02156179e-01]\n",
      " [1.37766175e-06 2.01877494e-02]\n",
      " [1.68499022e-06 5.86694024e-03]\n",
      " [1.32590535e-05 2.46791343e-03]\n",
      " [8.74177588e-06 1.40869322e-03]\n",
      " [1.27757138e-05 8.44546323e-04]\n",
      " [1.83262275e-05 3.29666693e-04]]\n",
      "Train Epoch4 out_loss 0.0006059175939299166\n",
      "Test Epoch4 layer0 out_loss 0.03979168459773064\n",
      "Test Epoch4 layer1 out_loss 0.004882380366325378\n",
      "Test Epoch4 layer2 out_loss 0.0017747067613527179\n",
      "Test Epoch4 layer3 out_loss 0.0007987014250829816\n",
      "Test Epoch4 layer4 out_loss 0.0005925883306190372\n",
      "Test Epoch4 layer5 out_loss 0.000497885630466044\n",
      "Test Epoch4 layer6 out_loss 0.0006190069834701717\n",
      "Test Epoch4 layer7 out_loss 0.0005854706396348774\n",
      "Train 5 | out_loss 0.0005253636627458036: 100%|█| 138/138 [00:01<00:00, 137.59it\n",
      "[[1.73230965e-05 1.11919169e+00]\n",
      " [6.80852767e-06 6.15502445e-02]\n",
      " [1.31287495e-06 1.27527397e-02]\n",
      " [1.67072816e-06 3.61140920e-03]\n",
      " [9.40209322e-06 1.48050533e-03]\n",
      " [1.34861554e-05 8.52149939e-04]\n",
      " [1.82493336e-05 5.32612629e-04]\n",
      " [2.59587462e-05 2.09330082e-04]]\n",
      "Train Epoch5 out_loss 0.0005253636627458036\n",
      "Test Epoch5 layer0 out_loss 0.03314458951354027\n",
      "Test Epoch5 layer1 out_loss 0.00982370413839817\n",
      "Test Epoch5 layer2 out_loss 0.001340414397418499\n",
      "Test Epoch5 layer3 out_loss 0.001459592953324318\n",
      "Test Epoch5 layer4 out_loss 0.0005312896682880819\n",
      "Test Epoch5 layer5 out_loss 0.0009304769919253886\n",
      "Test Epoch5 layer6 out_loss 0.00060852529713884\n",
      "Test Epoch5 layer7 out_loss 0.0007806755020283163\n",
      "Train 6 | out_loss 0.0005072488565929234: 100%|█| 138/138 [00:01<00:00, 137.28it\n",
      "[[1.67978107e-05 8.88467129e-01]\n",
      " [7.37211109e-06 3.67643834e-02]\n",
      " [1.61396717e-06 8.60526054e-03]\n",
      " [2.47288821e-06 2.52775345e-03]\n",
      " [1.82298538e-05 1.01859126e-03]\n",
      " [2.03990130e-05 6.31035168e-04]\n",
      " [2.69250282e-05 3.96081593e-04]\n",
      " [4.02290223e-05 1.69051309e-04]]\n",
      "Train Epoch6 out_loss 0.0005072488565929234\n",
      "Test Epoch6 layer0 out_loss 0.029683558270335197\n",
      "Test Epoch6 layer1 out_loss 0.004983796738088131\n",
      "Test Epoch6 layer2 out_loss 0.001114681363105774\n",
      "Test Epoch6 layer3 out_loss 0.0008408557623624802\n",
      "Test Epoch6 layer4 out_loss 0.0005063929711468518\n",
      "Test Epoch6 layer5 out_loss 0.0004746185732074082\n",
      "Test Epoch6 layer6 out_loss 0.00067388970637694\n",
      "Test Epoch6 layer7 out_loss 0.0006717123906128109\n",
      "Train 7 | out_loss 0.0005394812324084342: 100%|█| 138/138 [00:00<00:00, 138.89it\n",
      "[[2.12322971e-05 6.58552898e-01]\n",
      " [7.74635005e-06 3.65912460e-02]\n",
      " [1.66980549e-06 7.09107951e-03]\n",
      " [3.09736312e-06 2.07146573e-03]\n",
      " [2.54602706e-05 8.25519053e-04]\n",
      " [4.34041429e-05 5.40958757e-04]\n",
      " [6.05353274e-05 3.57771088e-04]\n",
      " [8.52861574e-05 1.78286910e-04]]\n",
      "Train Epoch7 out_loss 0.0005394812324084342\n",
      "Test Epoch7 layer0 out_loss 0.027657393366098404\n",
      "Test Epoch7 layer1 out_loss 0.004181649535894394\n",
      "Test Epoch7 layer2 out_loss 0.001693106023594737\n",
      "Test Epoch7 layer3 out_loss 0.0007373158587142825\n",
      "Test Epoch7 layer4 out_loss 0.0006253304309211671\n",
      "Test Epoch7 layer5 out_loss 0.000780633999966085\n",
      "Test Epoch7 layer6 out_loss 0.00048073605285026133\n",
      "Test Epoch7 layer7 out_loss 0.000550069788005203\n",
      "Train 8 | out_loss 0.0005449442542158067: 100%|█| 138/138 [00:00<00:00, 138.05it\n",
      "[[1.96019064e-05 1.05599035e+00]\n",
      " [6.99825331e-06 3.97456463e-02]\n",
      " [2.39742685e-06 7.55212217e-03]\n",
      " [6.72437456e-06 2.17990838e-03]\n",
      " [5.06989417e-05 9.47496593e-04]\n",
      " [7.99729432e-05 6.03356877e-04]\n",
      " [1.07116428e-04 3.90638481e-04]\n",
      " [1.50664300e-04 2.15099541e-04]]\n",
      "Train Epoch8 out_loss 0.0005449442542158067\n",
      "Test Epoch8 layer0 out_loss 0.04442821815609932\n",
      "Test Epoch8 layer1 out_loss 0.0037971828132867813\n",
      "Test Epoch8 layer2 out_loss 0.001572490786202252\n",
      "Test Epoch8 layer3 out_loss 0.0009539202437736094\n",
      "Test Epoch8 layer4 out_loss 0.0005452741752378643\n",
      "Test Epoch8 layer5 out_loss 0.0005220041493885219\n",
      "Test Epoch8 layer6 out_loss 0.0005960951675660908\n",
      "Test Epoch8 layer7 out_loss 0.0006676897755824029\n",
      "Train 9 | out_loss 0.0006783964927308261: 100%|█| 138/138 [00:01<00:00, 134.79it\n",
      "[[3.57100281e-05 1.04166810e+00]\n",
      " [9.51234121e-06 3.32420819e-02]\n",
      " [2.09882666e-06 6.26556139e-03]\n",
      " [5.64057038e-06 2.06220009e-03]\n",
      " [5.22151751e-05 1.02684898e-03]\n",
      " [6.44987574e-05 7.19342874e-04]\n",
      " [9.21372298e-05 4.40188671e-04]\n",
      " [1.25375822e-04 2.23328010e-04]]\n",
      "Train Epoch9 out_loss 0.0006783964927308261\n",
      "Test Epoch9 layer0 out_loss 0.010612670332193375\n",
      "Test Epoch9 layer1 out_loss 0.002500107977539301\n",
      "Test Epoch9 layer2 out_loss 0.0008557456312701106\n",
      "Test Epoch9 layer3 out_loss 0.0008183029713109136\n",
      "Test Epoch9 layer4 out_loss 0.0010882506612688303\n",
      "Test Epoch9 layer5 out_loss 0.0010602123802527785\n",
      "Test Epoch9 layer6 out_loss 0.0005189854418858886\n",
      "Test Epoch9 layer7 out_loss 0.0006758439121767879\n",
      "Train 10 | out_loss 0.0014005796983838081: 100%|█| 138/138 [00:00<00:00, 139.85i\n",
      "[[3.32792246e-04 3.97408360e-01]\n",
      " [1.15407340e-05 1.38945775e-02]\n",
      " [2.55550807e-06 3.46913986e-03]\n",
      " [6.55673493e-06 1.14226215e-03]\n",
      " [7.95879871e-05 5.48632881e-04]\n",
      " [6.62700974e-05 4.32701284e-04]\n",
      " [9.85468307e-05 2.83961552e-04]\n",
      " [1.35062732e-04 1.79050155e-04]]\n",
      "Train Epoch10 out_loss 0.0014005796983838081\n",
      "Test Epoch10 layer0 out_loss 0.03505499288439751\n",
      "Test Epoch10 layer1 out_loss 0.0021935515105724335\n",
      "Test Epoch10 layer2 out_loss 0.0028009400703012943\n",
      "Test Epoch10 layer3 out_loss 0.0024009067565202713\n",
      "Test Epoch10 layer4 out_loss 0.0026564807631075382\n",
      "Test Epoch10 layer5 out_loss 0.002650658832862973\n",
      "Test Epoch10 layer6 out_loss 0.002269831718876958\n",
      "Test Epoch10 layer7 out_loss 0.0021359617821872234\n",
      "Train 11 | out_loss 0.0013001264305785298: 100%|█| 138/138 [00:00<00:00, 138.58i\n",
      "[[2.97210685e-04 3.44900395e-01]\n",
      " [1.12998904e-05 1.24885490e-02]\n",
      " [3.25276196e-06 2.85205477e-03]\n",
      " [1.12209860e-05 9.43223616e-04]\n",
      " [6.67928552e-05 4.29983806e-04]\n",
      " [1.09099807e-04 3.18510173e-04]\n",
      " [1.52845301e-04 2.39517921e-04]\n",
      " [1.96415854e-04 1.80991892e-04]]\n",
      "Train Epoch11 out_loss 0.0013001264305785298\n",
      "Test Epoch11 layer0 out_loss 0.035386525094509125\n",
      "Test Epoch11 layer1 out_loss 0.003587448038160801\n",
      "Test Epoch11 layer2 out_loss 0.0018041797447949648\n",
      "Test Epoch11 layer3 out_loss 0.002004342619329691\n",
      "Test Epoch11 layer4 out_loss 0.002045091474428773\n",
      "Test Epoch11 layer5 out_loss 0.002217827131971717\n",
      "Test Epoch11 layer6 out_loss 0.0016377372667193413\n",
      "Test Epoch11 layer7 out_loss 0.0012906610500067472\n",
      "Train 12 | out_loss 0.0014499579556286335: 100%|█| 138/138 [00:01<00:00, 137.66i\n",
      "[[3.60592727e-04 1.07432714e+00]\n",
      " [9.53022182e-06 3.14524800e-02]\n",
      " [4.64165124e-06 5.48385043e-03]\n",
      " [2.66748853e-05 1.78762538e-03]\n",
      " [2.14168107e-04 1.12233751e-03]\n",
      " [2.09550905e-04 7.04531699e-04]\n",
      " [3.04412704e-04 4.36526165e-04]\n",
      " [3.77539090e-04 3.22779629e-04]]\n",
      "Train Epoch12 out_loss 0.0014499579556286335\n",
      "Test Epoch12 layer0 out_loss 0.04332232475280762\n",
      "Test Epoch12 layer1 out_loss 0.003715761471539736\n",
      "Test Epoch12 layer2 out_loss 0.0013187621952965856\n",
      "Test Epoch12 layer3 out_loss 0.0010403377236798406\n",
      "Test Epoch12 layer4 out_loss 0.002004565903916955\n",
      "Test Epoch12 layer5 out_loss 0.0021864576265215874\n",
      "Test Epoch12 layer6 out_loss 0.0014092588098719716\n",
      "Test Epoch12 layer7 out_loss 0.0009045006008818746\n",
      "Train 13 | out_loss 0.0014544706791639328: 100%|█| 138/138 [00:00<00:00, 139.02i\n",
      "[[3.72588743e-04 7.23165029e-01]\n",
      " [1.27129029e-05 1.88047085e-02]\n",
      " [4.40446468e-06 3.74222731e-03]\n",
      " [2.14483644e-05 1.20052324e-03]\n",
      " [1.30699575e-04 1.13607402e-03]\n",
      " [1.76916428e-04 8.67366137e-04]\n",
      " [2.31670868e-04 5.56984655e-04]\n",
      " [2.71904184e-04 3.31151825e-04]]\n",
      "Train Epoch13 out_loss 0.0014544706791639328\n",
      "Test Epoch13 layer0 out_loss 0.021376553922891617\n",
      "Test Epoch13 layer1 out_loss 0.0015145851066336036\n",
      "Test Epoch13 layer2 out_loss 0.0006579718901775777\n",
      "Test Epoch13 layer3 out_loss 0.0005110044730827212\n",
      "Test Epoch13 layer4 out_loss 0.0007099162321537733\n",
      "Test Epoch13 layer5 out_loss 0.0006812182255089283\n",
      "Test Epoch13 layer6 out_loss 0.00043530488619580865\n",
      "Test Epoch13 layer7 out_loss 0.00041958512156270444\n",
      "Train 14 | out_loss 0.0014808252453804016: 100%|█| 138/138 [00:01<00:00, 137.79i\n",
      "[[4.14256898e-04 3.15728507e-01]\n",
      " [1.66308802e-05 9.97488158e-03]\n",
      " [5.72617404e-06 2.06136746e-03]\n",
      " [2.74566991e-05 7.06786445e-04]\n",
      " [1.69707925e-04 4.79293949e-04]\n",
      " [1.90378213e-04 3.86597632e-04]\n",
      " [2.61499159e-04 2.81257621e-04]\n",
      " [2.90993265e-04 2.43885763e-04]]\n",
      "Train Epoch14 out_loss 0.0014808252453804016\n",
      "Test Epoch14 layer0 out_loss 0.03582540526986122\n",
      "Test Epoch14 layer1 out_loss 0.002676490694284439\n",
      "Test Epoch14 layer2 out_loss 0.0028115003369748592\n",
      "Test Epoch14 layer3 out_loss 0.0028987815603613853\n",
      "Test Epoch14 layer4 out_loss 0.003181766951456666\n",
      "Test Epoch14 layer5 out_loss 0.002959516132250428\n",
      "Test Epoch14 layer6 out_loss 0.0025790431536734104\n",
      "Test Epoch14 layer7 out_loss 0.002606680616736412\n",
      "Train 15 | out_loss 0.0015054796822369099: 100%|█| 138/138 [00:01<00:00, 132.38i\n",
      "[[4.47881434e-04 2.28249362e-01]\n",
      " [2.18172770e-05 8.44998499e-03]\n",
      " [1.81290216e-05 1.88845699e-03]\n",
      " [4.46060430e-05 6.12727952e-04]\n",
      " [1.50324958e-04 3.73242771e-04]\n",
      " [1.57583714e-04 2.74450606e-04]\n",
      " [2.07685070e-04 2.07641566e-04]\n",
      " [2.16541791e-04 1.81031723e-04]]\n",
      "Train Epoch15 out_loss 0.0015054796822369099\n",
      "Test Epoch15 layer0 out_loss 0.020763322710990906\n",
      "Test Epoch15 layer1 out_loss 0.0015994595596566796\n",
      "Test Epoch15 layer2 out_loss 0.0005646990612149239\n",
      "Test Epoch15 layer3 out_loss 0.0007514152093790472\n",
      "Test Epoch15 layer4 out_loss 0.0006458836141973734\n",
      "Test Epoch15 layer5 out_loss 0.0007824030471965671\n",
      "Test Epoch15 layer6 out_loss 0.0006330398609861732\n",
      "Test Epoch15 layer7 out_loss 0.0005726122763007879\n",
      "Train 16 | out_loss 0.0013963941019028425: 100%|█| 138/138 [00:01<00:00, 135.70i\n",
      "[[3.45633859e-04 4.97366111e-01]\n",
      " [2.10417200e-05 1.93183955e-02]\n",
      " [1.57744638e-04 3.25171276e-03]\n",
      " [2.73161971e-04 1.18328018e-03]\n",
      " [2.72504079e-04 6.94454946e-04]\n",
      " [3.73974048e-04 4.31745065e-04]\n",
      " [4.41600478e-04 3.60793716e-04]\n",
      " [4.02571938e-04 3.31033212e-04]]\n",
      "Train Epoch16 out_loss 0.0013963941019028425\n",
      "Test Epoch16 layer0 out_loss 0.07795385271310806\n",
      "Test Epoch16 layer1 out_loss 0.004131598863750696\n",
      "Test Epoch16 layer2 out_loss 0.0017801292706280947\n",
      "Test Epoch16 layer3 out_loss 0.0005976552492938936\n",
      "Test Epoch16 layer4 out_loss 0.0006424097809940577\n",
      "Test Epoch16 layer5 out_loss 0.0005468674935400486\n",
      "Test Epoch16 layer6 out_loss 0.0010295386891812086\n",
      "Test Epoch16 layer7 out_loss 0.0009574758587405086\n",
      "Train 17 | out_loss 0.0014487850712612271: 100%|█| 138/138 [00:00<00:00, 139.88i\n",
      "[[3.65966655e-04 3.95067373e-01]\n",
      " [2.66573197e-05 1.35536525e-02]\n",
      " [2.09084776e-04 3.34270760e-03]\n",
      " [3.23527430e-04 1.63120098e-03]\n",
      " [2.84811346e-04 1.56082218e-03]\n",
      " [3.42456179e-04 8.65775859e-04]\n",
      " [3.67587543e-04 4.99979871e-04]\n",
      " [3.14027672e-04 3.17255048e-04]]\n",
      "Train Epoch17 out_loss 0.0014487850712612271\n",
      "Test Epoch17 layer0 out_loss 0.01575426012277603\n",
      "Test Epoch17 layer1 out_loss 0.002167960163205862\n",
      "Test Epoch17 layer2 out_loss 0.000586962909437716\n",
      "Test Epoch17 layer3 out_loss 0.0005794077296741307\n",
      "Test Epoch17 layer4 out_loss 0.0005206125788390636\n",
      "Test Epoch17 layer5 out_loss 0.0005482079577632248\n",
      "Test Epoch17 layer6 out_loss 0.0006315988139249384\n",
      "Test Epoch17 layer7 out_loss 0.000691933324560523\n",
      "Train 18 | out_loss 0.0013698196271434426: 100%|█| 138/138 [00:01<00:00, 137.19i\n",
      "[[3.54259734e-04 1.18421526e-01]\n",
      " [3.27939378e-05 4.56687991e-03]\n",
      " [4.87862989e-04 1.39308300e-03]\n",
      " [6.27251692e-04 9.02904259e-04]\n",
      " [4.09416885e-04 5.54383516e-04]\n",
      " [4.68875436e-04 3.61982103e-04]\n",
      " [4.57408780e-04 3.02402810e-04]\n",
      " [3.46368924e-04 2.84304344e-04]]\n",
      "Train Epoch18 out_loss 0.0013698196271434426\n",
      "Test Epoch18 layer0 out_loss 0.010643077082931995\n",
      "Test Epoch18 layer1 out_loss 0.001642000861465931\n",
      "Test Epoch18 layer2 out_loss 0.0021205225493758917\n",
      "Test Epoch18 layer3 out_loss 0.002213713014498353\n",
      "Test Epoch18 layer4 out_loss 0.002085284795612097\n",
      "Test Epoch18 layer5 out_loss 0.0022167935967445374\n",
      "Test Epoch18 layer6 out_loss 0.002520191017538309\n",
      "Test Epoch18 layer7 out_loss 0.0022675537038594484\n",
      "Train 19 | out_loss 0.0015434680972248316: 100%|█| 138/138 [00:01<00:00, 136.76i\n",
      "[[4.30538966e-04 6.44126274e-02]\n",
      " [4.69559759e-05 4.06697519e-03]\n",
      " [4.01519725e-04 1.22946548e-03]\n",
      " [4.00010565e-04 7.11026004e-04]\n",
      " [5.26367306e-04 5.24256122e-04]\n",
      " [4.92902218e-04 4.31523990e-04]\n",
      " [4.82684764e-04 3.55180754e-04]\n",
      " [3.92435747e-04 3.12263750e-04]]\n",
      "Train Epoch19 out_loss 0.0015434680972248316\n",
      "Test Epoch19 layer0 out_loss 0.006984816864132881\n",
      "Test Epoch19 layer1 out_loss 0.0019831322133541107\n",
      "Test Epoch19 layer2 out_loss 0.0006195672322064638\n",
      "Test Epoch19 layer3 out_loss 0.0006002078298479319\n",
      "Test Epoch19 layer4 out_loss 0.0005598397110588849\n",
      "Test Epoch19 layer5 out_loss 0.0007423640345223248\n",
      "Test Epoch19 layer6 out_loss 0.0008229748927988112\n",
      "Test Epoch19 layer7 out_loss 0.0005603653262369335\n",
      "Train 20 | out_loss 0.0012689298018813133: 100%|█| 138/138 [00:01<00:00, 133.80i\n",
      "[[2.57863491e-04 5.42509800e-01]\n",
      " [4.95336814e-05 1.56800913e-02]\n",
      " [5.13399031e-04 3.49166361e-03]\n",
      " [4.31788842e-04 1.79252543e-03]\n",
      " [4.38936756e-04 1.90254688e-03]\n",
      " [3.68050727e-04 9.90546355e-04]\n",
      " [3.27984029e-04 5.45283454e-04]\n",
      " [2.40802355e-04 3.00156402e-04]]\n",
      "Train Epoch20 out_loss 0.0012689298018813133\n",
      "Test Epoch20 layer0 out_loss 0.03282557800412178\n",
      "Test Epoch20 layer1 out_loss 0.001591954380273819\n",
      "Test Epoch20 layer2 out_loss 0.0006473292014561594\n",
      "Test Epoch20 layer3 out_loss 0.0006122402264736593\n",
      "Test Epoch20 layer4 out_loss 0.0006856619729660451\n",
      "Test Epoch20 layer5 out_loss 0.0012750140158459544\n",
      "Test Epoch20 layer6 out_loss 0.0009143559727817774\n",
      "Test Epoch20 layer7 out_loss 0.0006858461420051754\n",
      "Train 21 | out_loss 0.0015644761733710766: 100%|█| 138/138 [00:01<00:00, 137.06i\n",
      "[[4.54112302e-04 1.23742580e+00]\n",
      " [8.56130288e-05 7.40980376e-03]\n",
      " [6.25800722e-04 2.39913535e-03]\n",
      " [4.71995877e-04 1.37821115e-03]\n",
      " [6.26238277e-04 9.39184222e-04]\n",
      " [4.32859689e-04 5.30075000e-04]\n",
      " [4.09515913e-04 3.48854673e-04]\n",
      " [2.96362551e-04 2.58991077e-04]]\n",
      "Train Epoch21 out_loss 0.0015644761733710766\n",
      "Test Epoch21 layer0 out_loss 0.030871933326125145\n",
      "Test Epoch21 layer1 out_loss 0.001411680830642581\n",
      "Test Epoch21 layer2 out_loss 0.0006985249347053468\n",
      "Test Epoch21 layer3 out_loss 0.0005286163068376482\n",
      "Test Epoch21 layer4 out_loss 0.0007593008340336382\n",
      "Test Epoch21 layer5 out_loss 0.0004396995063871145\n",
      "Test Epoch21 layer6 out_loss 0.00046201571240089834\n",
      "Test Epoch21 layer7 out_loss 0.000509892008267343\n",
      "Train 22 | out_loss 0.0010647219605743885: 100%|█| 138/138 [00:00<00:00, 139.56i\n",
      "[[2.51033309e-04 2.96029379e-01]\n",
      " [1.78895504e-04 3.65096242e-03]\n",
      " [9.90174734e-04 1.47141494e-03]\n",
      " [7.56545200e-04 1.07277961e-03]\n",
      " [1.28597618e-03 8.81565810e-04]\n",
      " [7.20483506e-04 6.78323160e-04]\n",
      " [6.52466497e-04 4.73149140e-04]\n",
      " [4.15112011e-04 3.94651557e-04]]\n",
      "Train Epoch22 out_loss 0.0010647219605743885\n",
      "Test Epoch22 layer0 out_loss 0.011000731028616428\n",
      "Test Epoch22 layer1 out_loss 0.0018083443865180016\n",
      "Test Epoch22 layer2 out_loss 0.0005519508849829435\n",
      "Test Epoch22 layer3 out_loss 0.0005526816239580512\n",
      "Test Epoch22 layer4 out_loss 0.0010183131089434028\n",
      "Test Epoch22 layer5 out_loss 0.0009118453599512577\n",
      "Test Epoch22 layer6 out_loss 0.0006920485757291317\n",
      "Test Epoch22 layer7 out_loss 0.0005073234206065536\n",
      "Train 23 | out_loss 0.001396754989400506: 100%|█| 138/138 [00:01<00:00, 136.47it\n",
      "[[0.00033074 0.09669113]\n",
      " [0.00017815 0.00173803]\n",
      " [0.00063604 0.00088226]\n",
      " [0.00039862 0.00051823]\n",
      " [0.00053677 0.00033889]\n",
      " [0.00041281 0.00033192]\n",
      " [0.00035563 0.00028943]\n",
      " [0.00022192 0.00024103]]\n",
      "Train Epoch23 out_loss 0.001396754989400506\n",
      "Test Epoch23 layer0 out_loss 0.035484638065099716\n",
      "Test Epoch23 layer1 out_loss 0.004292066674679518\n",
      "Test Epoch23 layer2 out_loss 0.004950040485709906\n",
      "Test Epoch23 layer3 out_loss 0.004789293278008699\n",
      "Test Epoch23 layer4 out_loss 0.004880886059254408\n",
      "Test Epoch23 layer5 out_loss 0.004715132061392069\n",
      "Test Epoch23 layer6 out_loss 0.004639295861124992\n",
      "Test Epoch23 layer7 out_loss 0.00473239179700613\n",
      "Train 24 | out_loss 0.0017492066835984588: 100%|█| 138/138 [00:00<00:00, 140.62i\n",
      "[[5.54890693e-04 2.41899612e-01]\n",
      " [3.73708780e-04 3.13515160e-03]\n",
      " [9.55639543e-04 1.42739854e-03]\n",
      " [5.66725754e-04 8.36349435e-04]\n",
      " [6.08529612e-04 5.00717082e-04]\n",
      " [4.46565363e-04 4.11033019e-04]\n",
      " [3.06501359e-04 3.17021952e-04]\n",
      " [1.95660165e-04 2.17685130e-04]]\n",
      "Train Epoch24 out_loss 0.0017492066835984588\n",
      "Test Epoch24 layer0 out_loss 0.014208709821105003\n",
      "Test Epoch24 layer1 out_loss 0.000990942120552063\n",
      "Test Epoch24 layer2 out_loss 0.0006304925191216171\n",
      "Test Epoch24 layer3 out_loss 0.0004790879029314965\n",
      "Test Epoch24 layer4 out_loss 0.0008033296908251941\n",
      "Test Epoch24 layer5 out_loss 0.0005381234805099666\n",
      "Test Epoch24 layer6 out_loss 0.00045119907008484006\n",
      "Test Epoch24 layer7 out_loss 0.0006422335864044726\n",
      "Train 25 | out_loss 0.0010461858473718166: 100%|█| 138/138 [00:01<00:00, 137.65i\n",
      "[[0.00024391 0.06016447]\n",
      " [0.00027271 0.0014898 ]\n",
      " [0.00054755 0.00074081]\n",
      " [0.00062137 0.00063344]\n",
      " [0.00046648 0.00055686]\n",
      " [0.00038261 0.00036882]\n",
      " [0.00028033 0.00025199]\n",
      " [0.00019918 0.00021216]]\n",
      "Train Epoch25 out_loss 0.0010461858473718166\n",
      "Test Epoch25 layer0 out_loss 0.01747024990618229\n",
      "Test Epoch25 layer1 out_loss 0.0012349275639280677\n",
      "Test Epoch25 layer2 out_loss 0.0009148630779236555\n",
      "Test Epoch25 layer3 out_loss 0.0007941910298541188\n",
      "Test Epoch25 layer4 out_loss 0.0008498684037476778\n",
      "Test Epoch25 layer5 out_loss 0.000736317306291312\n",
      "Test Epoch25 layer6 out_loss 0.0008333707228302956\n",
      "Test Epoch25 layer7 out_loss 0.0009656916372478008\n",
      "Train 26 | out_loss 0.0014776724856346846: 100%|█| 138/138 [00:01<00:00, 135.17i\n",
      "[[4.25977531e-04 3.70684273e-01]\n",
      " [2.85338391e-04 2.57001652e-03]\n",
      " [5.76431758e-04 1.03107412e-03]\n",
      " [5.17504022e-04 6.25214711e-04]\n",
      " [4.95945509e-04 5.36215472e-04]\n",
      " [4.48196958e-04 4.50268297e-04]\n",
      " [2.97725977e-04 3.19807542e-04]\n",
      " [2.01716580e-04 2.28452192e-04]]\n",
      "Train Epoch26 out_loss 0.0014776724856346846\n",
      "Test Epoch26 layer0 out_loss 0.033253736793994904\n",
      "Test Epoch26 layer1 out_loss 0.002155276481062174\n",
      "Test Epoch26 layer2 out_loss 0.0010339656146243215\n",
      "Test Epoch26 layer3 out_loss 0.000595487654209137\n",
      "Test Epoch26 layer4 out_loss 0.0008769282721914351\n",
      "Test Epoch26 layer5 out_loss 0.0006163469515740871\n",
      "Test Epoch26 layer6 out_loss 0.0004857706662733108\n",
      "Test Epoch26 layer7 out_loss 0.0004971224698238075\n",
      "Train 27 | out_loss 0.0013913888251408935: 100%|█| 138/138 [00:01<00:00, 136.08i\n",
      "[[3.37045714e-04 3.68193223e-01]\n",
      " [4.67368648e-04 3.05883183e-03]\n",
      " [8.17082153e-04 1.46875170e-03]\n",
      " [8.09752304e-04 1.08088294e-03]\n",
      " [5.73678663e-04 1.04476840e-03]\n",
      " [4.32683636e-04 6.02609410e-04]\n",
      " [2.79797107e-04 3.34793202e-04]\n",
      " [1.71675979e-04 2.20245128e-04]]\n",
      "Train Epoch27 out_loss 0.0013913888251408935\n",
      "Test Epoch27 layer0 out_loss 0.016154978424310684\n",
      "Test Epoch27 layer1 out_loss 0.0010637992527335882\n",
      "Test Epoch27 layer2 out_loss 0.00054502411512658\n",
      "Test Epoch27 layer3 out_loss 0.00043629430001601577\n",
      "Test Epoch27 layer4 out_loss 0.0004311212105676532\n",
      "Test Epoch27 layer5 out_loss 0.00043431163066998124\n",
      "Test Epoch27 layer6 out_loss 0.00042071129428222775\n",
      "Test Epoch27 layer7 out_loss 0.000427858904004097\n",
      "Train 28 | out_loss 0.001358273671939969: 100%|█| 138/138 [00:01<00:00, 136.13it\n",
      "[[0.00033697 0.11812063]\n",
      " [0.00032452 0.0016894 ]\n",
      " [0.00054788 0.00071946]\n",
      " [0.00071625 0.00072339]\n",
      " [0.00053837 0.00065279]\n",
      " [0.00054089 0.0005289 ]\n",
      " [0.00037162 0.00041133]\n",
      " [0.00030751 0.00036544]]\n",
      "Train Epoch28 out_loss 0.001358273671939969\n",
      "Test Epoch28 layer0 out_loss 0.02469860389828682\n",
      "Test Epoch28 layer1 out_loss 0.0023764148354530334\n",
      "Test Epoch28 layer2 out_loss 0.0006428789347410202\n",
      "Test Epoch28 layer3 out_loss 0.0007680814014747739\n",
      "Test Epoch28 layer4 out_loss 0.0008505196892656386\n",
      "Test Epoch28 layer5 out_loss 0.0010565337724983692\n",
      "Test Epoch28 layer6 out_loss 0.0007441400084644556\n",
      "Test Epoch28 layer7 out_loss 0.000758638430852443\n",
      "Train 29 | out_loss 0.0015318554360419512: 100%|█| 138/138 [00:01<00:00, 136.57i\n",
      "[[0.00044214 0.08692665]\n",
      " [0.0004647  0.0021072 ]\n",
      " [0.00076015 0.00114853]\n",
      " [0.00062053 0.00091585]\n",
      " [0.00062031 0.00072193]\n",
      " [0.00046571 0.00052651]\n",
      " [0.0003941  0.00039876]\n",
      " [0.00027355 0.00033587]]\n",
      "Train Epoch29 out_loss 0.0015318554360419512\n",
      "Test Epoch29 layer0 out_loss 0.004161573480814695\n",
      "Test Epoch29 layer1 out_loss 0.0011360362404957414\n",
      "Test Epoch29 layer2 out_loss 0.00047832561540417373\n",
      "Test Epoch29 layer3 out_loss 0.00041283690370619297\n",
      "Test Epoch29 layer4 out_loss 0.000437278242316097\n",
      "Test Epoch29 layer5 out_loss 0.0004772869870066643\n",
      "Test Epoch29 layer6 out_loss 0.0004238408000674099\n",
      "Test Epoch29 layer7 out_loss 0.0004458705661818385\n",
      "Train 30 | out_loss 0.0013668712927028537: 100%|█| 138/138 [00:01<00:00, 133.82i\n",
      "[[0.00034674 0.01931881]\n",
      " [0.00072604 0.00137358]\n",
      " [0.00088042 0.00100253]\n",
      " [0.00105746 0.0007208 ]\n",
      " [0.00052221 0.00053926]\n",
      " [0.00042618 0.00037787]\n",
      " [0.00033022 0.00034183]\n",
      " [0.00029637 0.00038971]]\n",
      "Train Epoch30 out_loss 0.0013668712927028537\n",
      "Test Epoch30 layer0 out_loss 0.006104723550379276\n",
      "Test Epoch30 layer1 out_loss 0.0008065482252277434\n",
      "Test Epoch30 layer2 out_loss 0.0005741862114518881\n",
      "Test Epoch30 layer3 out_loss 0.0004315256664995104\n",
      "Test Epoch30 layer4 out_loss 0.0005353111191652715\n",
      "Test Epoch30 layer5 out_loss 0.0005583091406151652\n",
      "Test Epoch30 layer6 out_loss 0.00043065263889729977\n",
      "Test Epoch30 layer7 out_loss 0.0006665857508778572\n",
      "Train 31 | out_loss 0.001543549937196076: 100%|█| 138/138 [00:01<00:00, 137.77it\n",
      "[[0.00046506 0.16132191]\n",
      " [0.00036391 0.00265524]\n",
      " [0.00069618 0.00106387]\n",
      " [0.00049496 0.0008625 ]\n",
      " [0.00031095 0.00052302]\n",
      " [0.00023386 0.00025751]\n",
      " [0.00021528 0.00020888]\n",
      " [0.00017103 0.00020421]]\n",
      "Train Epoch31 out_loss 0.001543549937196076\n",
      "Test Epoch31 layer0 out_loss 0.027555644512176514\n",
      "Test Epoch31 layer1 out_loss 0.0030664843507111073\n",
      "Test Epoch31 layer2 out_loss 0.0006560793844982982\n",
      "Test Epoch31 layer3 out_loss 0.0004084091051481664\n",
      "Test Epoch31 layer4 out_loss 0.00043826590990647674\n",
      "Test Epoch31 layer5 out_loss 0.0005528355832211673\n",
      "Test Epoch31 layer6 out_loss 0.0005244754138402641\n",
      "Test Epoch31 layer7 out_loss 0.0004164983984082937\n",
      "Train 32 | out_loss 0.0011367588303983212: 100%|█| 138/138 [00:00<00:00, 138.24i\n",
      "[[0.00019363 0.10544323]\n",
      " [0.00051768 0.00310466]\n",
      " [0.00087903 0.00156477]\n",
      " [0.00062084 0.00139143]\n",
      " [0.00044098 0.00086173]\n",
      " [0.00033929 0.00043056]\n",
      " [0.00033069 0.00031952]\n",
      " [0.0002122  0.00026879]]\n",
      "Train Epoch32 out_loss 0.0011367588303983212\n",
      "Test Epoch32 layer0 out_loss 0.013067703694105148\n",
      "Test Epoch32 layer1 out_loss 0.0009181913919746876\n",
      "Test Epoch32 layer2 out_loss 0.0004484709643293172\n",
      "Test Epoch32 layer3 out_loss 0.0004165294230915606\n",
      "Test Epoch32 layer4 out_loss 0.0004439553595148027\n",
      "Test Epoch32 layer5 out_loss 0.0006688137073069811\n",
      "Test Epoch32 layer6 out_loss 0.0004494866880122572\n",
      "Test Epoch32 layer7 out_loss 0.0006148756947368383\n",
      "Train 33 | out_loss 0.0014902575640007854: 100%|█| 138/138 [00:01<00:00, 137.52i\n",
      "[[0.00038922 0.22831807]\n",
      " [0.00057783 0.00257479]\n",
      " [0.00073577 0.00116864]\n",
      " [0.00053728 0.00087519]\n",
      " [0.00043559 0.00052902]\n",
      " [0.00035463 0.00037057]\n",
      " [0.0003415  0.00032818]\n",
      " [0.00025087 0.00032415]]\n",
      "Train Epoch33 out_loss 0.0014902575640007854\n",
      "Test Epoch33 layer0 out_loss 0.03973861038684845\n",
      "Test Epoch33 layer1 out_loss 0.0016997947823256254\n",
      "Test Epoch33 layer2 out_loss 0.0008259332971647382\n",
      "Test Epoch33 layer3 out_loss 0.0008430746383965015\n",
      "Test Epoch33 layer4 out_loss 0.0004453904402907938\n",
      "Test Epoch33 layer5 out_loss 0.00048365633119829\n",
      "Test Epoch33 layer6 out_loss 0.0007119151996448636\n",
      "Test Epoch33 layer7 out_loss 0.0011073850328102708\n",
      "Train 34 | out_loss 0.0013417601585388184: 100%|█| 138/138 [00:01<00:00, 135.89i\n",
      "[[3.12205722e-04 4.68477005e-01]\n",
      " [4.31636441e-04 6.02147031e-03]\n",
      " [6.98246057e-04 2.08840016e-03]\n",
      " [5.58344116e-04 1.68421228e-03]\n",
      " [3.97305859e-04 1.01936378e-03]\n",
      " [2.75367709e-04 5.42569678e-04]\n",
      " [2.99571675e-04 3.71196395e-04]\n",
      " [2.25927362e-04 3.01061431e-04]]\n",
      "Train Epoch34 out_loss 0.0013417601585388184\n",
      "Test Epoch34 layer0 out_loss 0.004855444189161062\n",
      "Test Epoch34 layer1 out_loss 0.0010042880894616246\n",
      "Test Epoch34 layer2 out_loss 0.00047679865383543074\n",
      "Test Epoch34 layer3 out_loss 0.0004393646668177098\n",
      "Test Epoch34 layer4 out_loss 0.0004377940495032817\n",
      "Test Epoch34 layer5 out_loss 0.00043415321852080524\n",
      "Test Epoch34 layer6 out_loss 0.00043683729018084705\n",
      "Test Epoch34 layer7 out_loss 0.00041978625813499093\n",
      "Train 35 | out_loss 0.0014889081940054893: 100%|█| 138/138 [00:01<00:00, 134.95i\n",
      "[[0.00043888 0.03192591]\n",
      " [0.00064842 0.00159138]\n",
      " [0.00085615 0.00099008]\n",
      " [0.00065862 0.00073856]\n",
      " [0.00045075 0.00047104]\n",
      " [0.0003546  0.00031995]\n",
      " [0.00039627 0.00034613]\n",
      " [0.00027882 0.0003378 ]]\n",
      "Train Epoch35 out_loss 0.0014889081940054893\n",
      "Test Epoch35 layer0 out_loss 0.003813420655205846\n",
      "Test Epoch35 layer1 out_loss 0.00161027314607054\n",
      "Test Epoch35 layer2 out_loss 0.0013118194183334708\n",
      "Test Epoch35 layer3 out_loss 0.0012942686444148421\n",
      "Test Epoch35 layer4 out_loss 0.001171111362054944\n",
      "Test Epoch35 layer5 out_loss 0.0013525509275496006\n",
      "Test Epoch35 layer6 out_loss 0.0014803102239966393\n",
      "Test Epoch35 layer7 out_loss 0.0013843280030414462\n",
      "Train 36 | out_loss 0.001296218135394156: 100%|█| 138/138 [00:00<00:00, 139.16it\n",
      "[[0.00028373 0.07410721]\n",
      " [0.00045876 0.00149368]\n",
      " [0.00059681 0.0008674 ]\n",
      " [0.00043226 0.0007281 ]\n",
      " [0.00033267 0.00047034]\n",
      " [0.00038095 0.00035775]\n",
      " [0.00028386 0.0002815 ]\n",
      " [0.00024194 0.00027832]]\n",
      "Train Epoch36 out_loss 0.001296218135394156\n",
      "Test Epoch36 layer0 out_loss 0.010204159654676914\n",
      "Test Epoch36 layer1 out_loss 0.0016614842461422086\n",
      "Test Epoch36 layer2 out_loss 0.0004527160490397364\n",
      "Test Epoch36 layer3 out_loss 0.0006266282871365547\n",
      "Test Epoch36 layer4 out_loss 0.0005481233238242567\n",
      "Test Epoch36 layer5 out_loss 0.0009288080036640167\n",
      "Test Epoch36 layer6 out_loss 0.0007408700184896588\n",
      "Test Epoch36 layer7 out_loss 0.0004988078726455569\n",
      "Train 37 | out_loss 0.0018182090716436505: 100%|█| 138/138 [00:00<00:00, 141.33i\n",
      "[[0.00059348 0.22633609]\n",
      " [0.00073552 0.00415587]\n",
      " [0.00097675 0.00173452]\n",
      " [0.0007448  0.00144063]\n",
      " [0.00057069 0.00094721]\n",
      " [0.00074443 0.00073661]\n",
      " [0.00044013 0.00051349]\n",
      " [0.00037326 0.00041159]]\n",
      "Train Epoch37 out_loss 0.0018182090716436505\n",
      "Test Epoch37 layer0 out_loss 0.007915331050753593\n",
      "Test Epoch37 layer1 out_loss 0.000816437357570976\n",
      "Test Epoch37 layer2 out_loss 0.0011504782596603036\n",
      "Test Epoch37 layer3 out_loss 0.0009259845246560872\n",
      "Test Epoch37 layer4 out_loss 0.0010401640320196748\n",
      "Test Epoch37 layer5 out_loss 0.0012306844582781196\n",
      "Test Epoch37 layer6 out_loss 0.0011213688412681222\n",
      "Test Epoch37 layer7 out_loss 0.0013818871229887009\n",
      "Train 38 | out_loss 0.001101026893593371: 100%|█| 138/138 [00:00<00:00, 143.67it\n",
      "[[0.0002214  0.04570278]\n",
      " [0.00052999 0.00175906]\n",
      " [0.00066603 0.00097995]\n",
      " [0.00047945 0.00081361]\n",
      " [0.00037073 0.00051859]\n",
      " [0.00041564 0.00038928]\n",
      " [0.00026249 0.0002587 ]\n",
      " [0.00017389 0.00017503]]\n",
      "Train Epoch38 out_loss 0.001101026893593371\n",
      "Test Epoch38 layer0 out_loss 0.0039446293376386166\n",
      "Test Epoch38 layer1 out_loss 0.002333250595256686\n",
      "Test Epoch38 layer2 out_loss 0.002073581563308835\n",
      "Test Epoch38 layer3 out_loss 0.0020003553945571184\n",
      "Test Epoch38 layer4 out_loss 0.002156407805159688\n",
      "Test Epoch38 layer5 out_loss 0.0024735245388001204\n",
      "Test Epoch38 layer6 out_loss 0.0024120882153511047\n",
      "Test Epoch38 layer7 out_loss 0.0020902471151202917\n",
      "Train 39 | out_loss 0.0013391308020800352: 100%|█| 138/138 [00:00<00:00, 140.10i\n",
      "[[0.0003647  0.01683137]\n",
      " [0.00058838 0.00109796]\n",
      " [0.00069251 0.00089048]\n",
      " [0.00053829 0.0007206 ]\n",
      " [0.0004495  0.00050824]\n",
      " [0.00048303 0.00040449]\n",
      " [0.0002335  0.00025366]\n",
      " [0.00015329 0.00016903]]\n",
      "Train Epoch39 out_loss 0.0013391308020800352\n",
      "Test Epoch39 layer0 out_loss 0.03005475178360939\n",
      "Test Epoch39 layer1 out_loss 0.0015577080193907022\n",
      "Test Epoch39 layer2 out_loss 0.0005062843556515872\n",
      "Test Epoch39 layer3 out_loss 0.0006072082323953509\n",
      "Test Epoch39 layer4 out_loss 0.0006726668798364699\n",
      "Test Epoch39 layer5 out_loss 0.0007821553735993803\n",
      "Test Epoch39 layer6 out_loss 0.0007354479166679084\n",
      "Test Epoch39 layer7 out_loss 0.0005244691274128854\n",
      "Train 40 | out_loss 0.0014050252502784133: 100%|█| 138/138 [00:00<00:00, 139.09i\n",
      "[[3.59955846e-04 7.28256735e-01]\n",
      " [6.81373083e-04 7.49903089e-03]\n",
      " [8.70383680e-04 2.26563528e-03]\n",
      " [6.49315706e-04 1.80487773e-03]\n",
      " [6.58539311e-04 1.14263825e-03]\n",
      " [6.12574371e-04 6.48458724e-04]\n",
      " [3.19061275e-04 3.56448722e-04]\n",
      " [2.84314160e-04 2.72544524e-04]]\n",
      "Train Epoch40 out_loss 0.0014050252502784133\n",
      "Test Epoch40 layer0 out_loss 0.03616683557629585\n",
      "Test Epoch40 layer1 out_loss 0.0014874594053253531\n",
      "Test Epoch40 layer2 out_loss 0.0009822098072618246\n",
      "Test Epoch40 layer3 out_loss 0.0004402495105750859\n",
      "Test Epoch40 layer4 out_loss 0.00046641286462545395\n",
      "Test Epoch40 layer5 out_loss 0.000452585460152477\n",
      "Test Epoch40 layer6 out_loss 0.00042801996460184455\n",
      "Test Epoch40 layer7 out_loss 0.0004170220054220408\n",
      "Train 41 | out_loss 0.0012884939787909389: 100%|█| 138/138 [00:00<00:00, 142.26i\n",
      "[[0.00029454 0.09870974]\n",
      " [0.0006178  0.00266948]\n",
      " [0.00076855 0.00117013]\n",
      " [0.00061968 0.00078055]\n",
      " [0.00074988 0.00078961]\n",
      " [0.0003325  0.0004448 ]\n",
      " [0.00021588 0.00021583]\n",
      " [0.00016506 0.00018799]]\n",
      "Train Epoch41 out_loss 0.0012884939787909389\n",
      "Test Epoch41 layer0 out_loss 0.0042375498451292515\n",
      "Test Epoch41 layer1 out_loss 0.0007049458799883723\n",
      "Test Epoch41 layer2 out_loss 0.0005375107866711915\n",
      "Test Epoch41 layer3 out_loss 0.0006567545351572335\n",
      "Test Epoch41 layer4 out_loss 0.00048412353498861194\n",
      "Test Epoch41 layer5 out_loss 0.0005774420569650829\n",
      "Test Epoch41 layer6 out_loss 0.0005560538847930729\n",
      "Test Epoch41 layer7 out_loss 0.0009404083248227835\n",
      "Train 42 | out_loss 0.0013487158576026559: 100%|█| 138/138 [00:00<00:00, 140.84i\n",
      "[[0.00037363 0.00969215]\n",
      " [0.00049121 0.00103311]\n",
      " [0.00068365 0.00087495]\n",
      " [0.00052841 0.00078407]\n",
      " [0.00049143 0.00052634]\n",
      " [0.00029097 0.00029761]\n",
      " [0.00026559 0.00027729]\n",
      " [0.0002714  0.00030669]]\n",
      "Train Epoch42 out_loss 0.0013487158576026559\n",
      "Test Epoch42 layer0 out_loss 0.0036072295624762774\n",
      "Test Epoch42 layer1 out_loss 0.0007033812580630183\n",
      "Test Epoch42 layer2 out_loss 0.0004746420308947563\n",
      "Test Epoch42 layer3 out_loss 0.0004392299451865256\n",
      "Test Epoch42 layer4 out_loss 0.0005734556470997632\n",
      "Test Epoch42 layer5 out_loss 0.0005850926390849054\n",
      "Test Epoch42 layer6 out_loss 0.0004899505875073373\n",
      "Test Epoch42 layer7 out_loss 0.00041521541425026953\n",
      "Train 43 | out_loss 0.0013307963963598013: 100%|█| 138/138 [00:00<00:00, 140.59i\n",
      "[[0.00035806 0.02828758]\n",
      " [0.00051907 0.0015827 ]\n",
      " [0.00066107 0.00103296]\n",
      " [0.00050666 0.00091686]\n",
      " [0.00053785 0.00058757]\n",
      " [0.00032228 0.00033722]\n",
      " [0.00024723 0.00025669]\n",
      " [0.00018443 0.00019973]]\n",
      "Train Epoch43 out_loss 0.0013307963963598013\n",
      "Test Epoch43 layer0 out_loss 0.008085915818810463\n",
      "Test Epoch43 layer1 out_loss 0.0014416290214285254\n",
      "Test Epoch43 layer2 out_loss 0.0004907315596938133\n",
      "Test Epoch43 layer3 out_loss 0.0004972456954419613\n",
      "Test Epoch43 layer4 out_loss 0.0005663856863975525\n",
      "Test Epoch43 layer5 out_loss 0.0004346331406850368\n",
      "Test Epoch43 layer6 out_loss 0.0004174691566731781\n",
      "Test Epoch43 layer7 out_loss 0.0007219662074930966\n",
      "Train 44 | out_loss 0.0017216525739058852: 100%|█| 138/138 [00:00<00:00, 139.35i\n",
      "[[0.00054067 0.17943082]\n",
      " [0.00069048 0.00492008]\n",
      " [0.00086069 0.001911  ]\n",
      " [0.00068401 0.00151184]\n",
      " [0.00046007 0.00085739]\n",
      " [0.00036028 0.00045748]\n",
      " [0.00027677 0.00031853]\n",
      " [0.00026224 0.00028158]]\n",
      "Train Epoch44 out_loss 0.0017216525739058852\n",
      "Test Epoch44 layer0 out_loss 0.011997299268841743\n",
      "Test Epoch44 layer1 out_loss 0.0007287581684067845\n",
      "Test Epoch44 layer2 out_loss 0.00042035107617266476\n",
      "Test Epoch44 layer3 out_loss 0.00041537394281476736\n",
      "Test Epoch44 layer4 out_loss 0.0004289563512429595\n",
      "Test Epoch44 layer5 out_loss 0.0005439305678009987\n",
      "Test Epoch44 layer6 out_loss 0.0008007356664165854\n",
      "Test Epoch44 layer7 out_loss 0.0005744021036662161\n",
      "Train 45 | out_loss 0.0013975222827866673: 100%|█| 138/138 [00:00<00:00, 142.76i\n",
      "[[0.00036608 0.01754502]\n",
      " [0.00061781 0.00141481]\n",
      " [0.00075493 0.00109715]\n",
      " [0.00054371 0.00097557]\n",
      " [0.00083945 0.00083005]\n",
      " [0.00057274 0.00059348]\n",
      " [0.00031392 0.000323  ]\n",
      " [0.00023673 0.00026781]]\n",
      "Train Epoch45 out_loss 0.0013975222827866673\n",
      "Test Epoch45 layer0 out_loss 0.007231897208839655\n",
      "Test Epoch45 layer1 out_loss 0.0025600853841751814\n",
      "Test Epoch45 layer2 out_loss 0.0025481106713414192\n",
      "Test Epoch45 layer3 out_loss 0.0022080198395997286\n",
      "Test Epoch45 layer4 out_loss 0.0025037345476448536\n",
      "Test Epoch45 layer5 out_loss 0.0022452722769230604\n",
      "Test Epoch45 layer6 out_loss 0.0023577085230499506\n",
      "Test Epoch45 layer7 out_loss 0.0021284716203808784\n",
      "Train 46 | out_loss 0.0007668780162930489: 100%|█| 138/138 [00:00<00:00, 140.81i\n",
      "[[7.59185176e-05 8.08883523e-03]\n",
      " [5.66317317e-04 1.01553803e-03]\n",
      " [6.23532934e-04 1.06150789e-03]\n",
      " [5.68169408e-04 9.86561628e-04]\n",
      " [7.81283400e-04 7.09109092e-04]\n",
      " [4.15085757e-04 4.12084209e-04]\n",
      " [2.95255728e-04 2.49334972e-04]\n",
      " [2.31997221e-04 2.45859372e-04]]\n",
      "Train Epoch46 out_loss 0.0007668780162930489\n",
      "Test Epoch46 layer0 out_loss 0.005922737531363964\n",
      "Test Epoch46 layer1 out_loss 0.0010807682992890477\n",
      "Test Epoch46 layer2 out_loss 0.0009902587626129389\n",
      "Test Epoch46 layer3 out_loss 0.0010263400617986917\n",
      "Test Epoch46 layer4 out_loss 0.0012162207858636975\n",
      "Test Epoch46 layer5 out_loss 0.001047144760377705\n",
      "Test Epoch46 layer6 out_loss 0.0008195948321372271\n",
      "Test Epoch46 layer7 out_loss 0.001126553281210363\n",
      "Train 47 | out_loss 0.0015367224114015698: 100%|█| 138/138 [00:00<00:00, 139.78i\n",
      "[[0.00044838 0.01702563]\n",
      " [0.00067229 0.00138749]\n",
      " [0.00077566 0.0013178 ]\n",
      " [0.00057198 0.00098797]\n",
      " [0.00052994 0.00052278]\n",
      " [0.00033808 0.00039672]\n",
      " [0.00029835 0.00030746]\n",
      " [0.00026265 0.00032341]]\n",
      "Train Epoch47 out_loss 0.0015367224114015698\n",
      "Test Epoch47 layer0 out_loss 0.004224882461130619\n",
      "Test Epoch47 layer1 out_loss 0.0037007108330726624\n",
      "Test Epoch47 layer2 out_loss 0.0035175911616533995\n",
      "Test Epoch47 layer3 out_loss 0.0036807728465646505\n",
      "Test Epoch47 layer4 out_loss 0.003708458738401532\n",
      "Test Epoch47 layer5 out_loss 0.0034497312735766172\n",
      "Test Epoch47 layer6 out_loss 0.003800275968387723\n",
      "Test Epoch47 layer7 out_loss 0.003746605943888426\n",
      "Train 48 | out_loss 0.0013432144187390804: 100%|█| 138/138 [00:00<00:00, 141.11i\n",
      "[[0.00038626 0.13603106]\n",
      " [0.00053654 0.00261152]\n",
      " [0.00064431 0.0013855 ]\n",
      " [0.00053592 0.00114866]\n",
      " [0.00069354 0.00069301]\n",
      " [0.00052431 0.00052128]\n",
      " [0.00039016 0.00033964]\n",
      " [0.00029526 0.00027915]]\n",
      "Train Epoch48 out_loss 0.0013432144187390804\n",
      "Test Epoch48 layer0 out_loss 0.08598136156797409\n",
      "Test Epoch48 layer1 out_loss 0.0023002924863249063\n",
      "Test Epoch48 layer2 out_loss 0.0014117907267063856\n",
      "Test Epoch48 layer3 out_loss 0.0008841979433782399\n",
      "Test Epoch48 layer4 out_loss 0.0008819553186185658\n",
      "Test Epoch48 layer5 out_loss 0.0008016930660232902\n",
      "Test Epoch48 layer6 out_loss 0.0005226788343861699\n",
      "Test Epoch48 layer7 out_loss 0.0007340918527916074\n",
      "Train 49 | out_loss 0.001535586779937148: 100%|█| 138/138 [00:00<00:00, 139.12it\n",
      "[[4.50216036e-04 1.83248254e-01]\n",
      " [6.61161623e-04 3.90532591e-03]\n",
      " [8.03554095e-04 1.79355822e-03]\n",
      " [6.34860192e-04 1.26738516e-03]\n",
      " [5.22775056e-04 6.25305584e-04]\n",
      " [3.49143636e-04 3.94173600e-04]\n",
      " [2.30842297e-04 2.57356722e-04]\n",
      " [1.51181698e-04 1.76230673e-04]]\n",
      "Train Epoch49 out_loss 0.001535586779937148\n",
      "Test Epoch49 layer0 out_loss 0.009013237431645393\n",
      "Test Epoch49 layer1 out_loss 0.0005449401214718819\n",
      "Test Epoch49 layer2 out_loss 0.0005894008208997548\n",
      "Test Epoch49 layer3 out_loss 0.0004189252504147589\n",
      "Test Epoch49 layer4 out_loss 0.00042347406269982457\n",
      "Test Epoch49 layer5 out_loss 0.0005143671296536922\n",
      "Test Epoch49 layer6 out_loss 0.0006071708630770445\n",
      "Test Epoch49 layer7 out_loss 0.0005066821468062699\n",
      "Train 50 | out_loss 0.0014739737380295992: 100%|█| 138/138 [00:00<00:00, 142.10i\n",
      "[[0.00042168 0.0302668 ]\n",
      " [0.00051116 0.00152087]\n",
      " [0.00075402 0.00125495]\n",
      " [0.00072603 0.00097503]\n",
      " [0.00045928 0.00054697]\n",
      " [0.00039004 0.00041164]\n",
      " [0.00034589 0.0003023 ]\n",
      " [0.00024342 0.00023303]]\n",
      "Train Epoch50 out_loss 0.0014739737380295992\n",
      "Test Epoch50 layer0 out_loss 0.012570984661579132\n",
      "Test Epoch50 layer1 out_loss 0.0007938372436910868\n",
      "Test Epoch50 layer2 out_loss 0.0004253302759025246\n",
      "Test Epoch50 layer3 out_loss 0.0005927898455411196\n",
      "Test Epoch50 layer4 out_loss 0.000530499208252877\n",
      "Test Epoch50 layer5 out_loss 0.00043462429312057793\n",
      "Test Epoch50 layer6 out_loss 0.0004186154983472079\n",
      "Test Epoch50 layer7 out_loss 0.00046082999324426055\n",
      "Train 51 | out_loss 0.0012550005922093987: 100%|█| 138/138 [00:00<00:00, 140.50i\n",
      "[[0.00032476 0.10721922]\n",
      " [0.00046037 0.00216908]\n",
      " [0.00055441 0.00117063]\n",
      " [0.00037729 0.00079236]\n",
      " [0.00036722 0.00042185]\n",
      " [0.0003012  0.00029188]\n",
      " [0.00022664 0.00025585]\n",
      " [0.00020148 0.00022314]]\n",
      "Train Epoch51 out_loss 0.0012550005922093987\n",
      "Test Epoch51 layer0 out_loss 0.01539971586316824\n",
      "Test Epoch51 layer1 out_loss 0.0025275880470871925\n",
      "Test Epoch51 layer2 out_loss 0.0018215738236904144\n",
      "Test Epoch51 layer3 out_loss 0.001981115434318781\n",
      "Test Epoch51 layer4 out_loss 0.0020662571769207716\n",
      "Test Epoch51 layer5 out_loss 0.0019234739011153579\n",
      "Test Epoch51 layer6 out_loss 0.002163881668820977\n",
      "Test Epoch51 layer7 out_loss 0.0020815900061279535\n",
      "Train 52 | out_loss 0.0008796768961474299: 100%|█| 138/138 [00:00<00:00, 142.25i\n",
      "[[1.19648847e-04 2.21793936e-01]\n",
      " [7.69166070e-04 4.35033426e-03]\n",
      " [8.79896964e-04 1.87144682e-03]\n",
      " [7.39393192e-04 1.23475626e-03]\n",
      " [4.83413437e-04 5.99422722e-04]\n",
      " [4.09959477e-04 4.04290590e-04]\n",
      " [2.79207906e-04 2.55095563e-04]\n",
      " [2.01635797e-04 1.92509592e-04]]\n",
      "Train Epoch52 out_loss 0.0008796768961474299\n",
      "Test Epoch52 layer0 out_loss 0.05940802022814751\n",
      "Test Epoch52 layer1 out_loss 0.0011249567614868283\n",
      "Test Epoch52 layer2 out_loss 0.0010114811593666673\n",
      "Test Epoch52 layer3 out_loss 0.0004449580446816981\n",
      "Test Epoch52 layer4 out_loss 0.00042505041346885264\n",
      "Test Epoch52 layer5 out_loss 0.00041829541441984475\n",
      "Test Epoch52 layer6 out_loss 0.0006681012455374002\n",
      "Test Epoch52 layer7 out_loss 0.0005449666059575975\n",
      "Train 53 | out_loss 0.001479725819081068: 100%|█| 138/138 [00:00<00:00, 140.33it\n",
      "[[0.00043608 0.0674359 ]\n",
      " [0.00038186 0.00202266]\n",
      " [0.00053929 0.00108133]\n",
      " [0.00034084 0.00064081]\n",
      " [0.0002646  0.00036857]\n",
      " [0.00027552 0.00028805]\n",
      " [0.00021212 0.00020418]\n",
      " [0.00016156 0.00018145]]\n",
      "Train Epoch53 out_loss 0.001479725819081068\n",
      "Test Epoch53 layer0 out_loss 0.0030511508230119944\n",
      "Test Epoch53 layer1 out_loss 0.0006365118315443397\n",
      "Test Epoch53 layer2 out_loss 0.0004151997563894838\n",
      "Test Epoch53 layer3 out_loss 0.0004185973375570029\n",
      "Test Epoch53 layer4 out_loss 0.0004320674343034625\n",
      "Test Epoch53 layer5 out_loss 0.00045093498192727566\n",
      "Test Epoch53 layer6 out_loss 0.00042519293492659926\n",
      "Test Epoch53 layer7 out_loss 0.0004198252863716334\n",
      "Train 54 | out_loss 0.0013124599354341626: 100%|█| 138/138 [00:01<00:00, 137.79i\n",
      "[[0.00033355 0.01071643]\n",
      " [0.00061393 0.00136059]\n",
      " [0.00072148 0.00125812]\n",
      " [0.00049619 0.00066063]\n",
      " [0.00036287 0.00038265]\n",
      " [0.00036664 0.00034048]\n",
      " [0.00028462 0.00022976]\n",
      " [0.00020036 0.00019573]]\n",
      "Train Epoch54 out_loss 0.0013124599354341626\n",
      "Test Epoch54 layer0 out_loss 0.003509392961859703\n",
      "Test Epoch54 layer1 out_loss 0.0006830612546764314\n",
      "Test Epoch54 layer2 out_loss 0.0006248262943699956\n",
      "Test Epoch54 layer3 out_loss 0.0007512952433899045\n",
      "Test Epoch54 layer4 out_loss 0.00048396195052191615\n",
      "Test Epoch54 layer5 out_loss 0.0005066634621471167\n",
      "Test Epoch54 layer6 out_loss 0.0005692432168871164\n",
      "Test Epoch54 layer7 out_loss 0.0004143917467445135\n",
      "Train 55 | out_loss 0.0015076547861099243: 100%|█| 138/138 [00:01<00:00, 136.55i\n",
      "[[0.00048335 0.00576043]\n",
      " [0.00052068 0.00118763]\n",
      " [0.00057661 0.00109259]\n",
      " [0.00036655 0.00056465]\n",
      " [0.00030014 0.00033008]\n",
      " [0.00021712 0.00018453]\n",
      " [0.00018455 0.00017192]\n",
      " [0.00013121 0.00014186]]\n",
      "Train Epoch55 out_loss 0.0015076547861099243\n",
      "Test Epoch55 layer0 out_loss 0.0029952663462609053\n",
      "Test Epoch55 layer1 out_loss 0.0006270144367590547\n",
      "Test Epoch55 layer2 out_loss 0.0005606494378298521\n",
      "Test Epoch55 layer3 out_loss 0.0004739011637866497\n",
      "Test Epoch55 layer4 out_loss 0.0006032430101186037\n",
      "Test Epoch55 layer5 out_loss 0.000437404029071331\n",
      "Test Epoch55 layer6 out_loss 0.000450842926511541\n",
      "Test Epoch55 layer7 out_loss 0.0005123698501847684\n",
      "Train 56 | out_loss 0.0015010163187980652: 100%|█| 138/138 [00:00<00:00, 139.75i\n",
      "[[0.00046188 0.01272875]\n",
      " [0.00045362 0.00136853]\n",
      " [0.00071025 0.00134679]\n",
      " [0.00045692 0.00073239]\n",
      " [0.00038518 0.00041445]\n",
      " [0.00044046 0.00045519]\n",
      " [0.00029212 0.00027964]\n",
      " [0.00020847 0.00022028]]\n",
      "Train Epoch56 out_loss 0.0015010163187980652\n",
      "Test Epoch56 layer0 out_loss 0.006668123882263899\n",
      "Test Epoch56 layer1 out_loss 0.0013620390091091394\n",
      "Test Epoch56 layer2 out_loss 0.0010441249469295144\n",
      "Test Epoch56 layer3 out_loss 0.0008902692352421582\n",
      "Test Epoch56 layer4 out_loss 0.00075256556738168\n",
      "Test Epoch56 layer5 out_loss 0.0007290610810741782\n",
      "Test Epoch56 layer6 out_loss 0.0009276493801735342\n",
      "Test Epoch56 layer7 out_loss 0.0007436854648403823\n",
      "Train 57 | out_loss 0.0009871466318145394: 100%|█| 138/138 [00:00<00:00, 143.07i\n",
      "[[0.00016254 0.02928478]\n",
      " [0.0006211  0.00240229]\n",
      " [0.00070916 0.00157646]\n",
      " [0.00055278 0.00074639]\n",
      " [0.00031995 0.00039953]\n",
      " [0.00038388 0.00040607]\n",
      " [0.00023834 0.00025241]\n",
      " [0.00021609 0.00023076]]\n",
      "Train Epoch57 out_loss 0.0009871466318145394\n",
      "Test Epoch57 layer0 out_loss 0.019532395526766777\n",
      "Test Epoch57 layer1 out_loss 0.0055944244377315044\n",
      "Test Epoch57 layer2 out_loss 0.005696738138794899\n",
      "Test Epoch57 layer3 out_loss 0.005773212295025587\n",
      "Test Epoch57 layer4 out_loss 0.005889838561415672\n",
      "Test Epoch57 layer5 out_loss 0.005410613026469946\n",
      "Test Epoch57 layer6 out_loss 0.005318289622664452\n",
      "Test Epoch57 layer7 out_loss 0.0051056197844445705\n",
      "Train 58 | out_loss 0.0012249662540853024: 100%|█| 138/138 [00:00<00:00, 139.12i\n",
      "[[0.00032928 0.01595947]\n",
      " [0.00049715 0.00208247]\n",
      " [0.0006426  0.00138239]\n",
      " [0.00047029 0.00078972]\n",
      " [0.00043819 0.00044248]\n",
      " [0.00029251 0.00027082]\n",
      " [0.00016062 0.0001694 ]\n",
      " [0.00014345 0.00018996]]\n",
      "Train Epoch58 out_loss 0.0012249662540853024\n",
      "Test Epoch58 layer0 out_loss 0.0034118294715881348\n",
      "Test Epoch58 layer1 out_loss 0.0006082929321564734\n",
      "Test Epoch58 layer2 out_loss 0.000416807975852862\n",
      "Test Epoch58 layer3 out_loss 0.0004207405145280063\n",
      "Test Epoch58 layer4 out_loss 0.0004502349183894694\n",
      "Test Epoch58 layer5 out_loss 0.00041535100899636745\n",
      "Test Epoch58 layer6 out_loss 0.000416395312640816\n",
      "Test Epoch58 layer7 out_loss 0.00043346965685486794\n",
      "Train 59 | out_loss 0.0015989976236596704: 100%|█| 138/138 [00:00<00:00, 142.66i\n",
      "[[0.00051537 0.02358365]\n",
      " [0.00045145 0.00202262]\n",
      " [0.00060501 0.00127964]\n",
      " [0.00039625 0.00065884]\n",
      " [0.00030321 0.00032256]\n",
      " [0.00018779 0.00019316]\n",
      " [0.00016009 0.00019938]\n",
      " [0.00019313 0.00024863]]\n",
      "Train Epoch59 out_loss 0.0015989976236596704\n",
      "Test Epoch59 layer0 out_loss 0.00659874128177762\n",
      "Test Epoch59 layer1 out_loss 0.000712642096914351\n",
      "Test Epoch59 layer2 out_loss 0.0004636523372028023\n",
      "Test Epoch59 layer3 out_loss 0.0007572848699055612\n",
      "Test Epoch59 layer4 out_loss 0.0004327959904912859\n",
      "Test Epoch59 layer5 out_loss 0.0004651756607927382\n",
      "Test Epoch59 layer6 out_loss 0.0004810007812920958\n",
      "Test Epoch59 layer7 out_loss 0.000679953780490905\n",
      "Train 60 | out_loss 0.0016934401355683804: 100%|█| 138/138 [00:00<00:00, 142.36i\n",
      "[[0.0005796  0.10195298]\n",
      " [0.00063219 0.0044309 ]\n",
      " [0.00077499 0.00188598]\n",
      " [0.00049761 0.00090639]\n",
      " [0.00033282 0.00048095]\n",
      " [0.00025722 0.00027754]\n",
      " [0.00022437 0.00025533]\n",
      " [0.00026914 0.00033056]]\n",
      "Train Epoch60 out_loss 0.0016934401355683804\n",
      "Test Epoch60 layer0 out_loss 0.02302877977490425\n",
      "Test Epoch60 layer1 out_loss 0.0015550378011539578\n",
      "Test Epoch60 layer2 out_loss 0.0005143570597283542\n",
      "Test Epoch60 layer3 out_loss 0.00099085527472198\n",
      "Test Epoch60 layer4 out_loss 0.0015202919021248817\n",
      "Test Epoch60 layer5 out_loss 0.0013313255039975047\n",
      "Test Epoch60 layer6 out_loss 0.0014992126962170005\n",
      "Test Epoch60 layer7 out_loss 0.000861218897625804\n",
      "Train 61 | out_loss 0.0006752423942089081: 100%|█| 138/138 [00:00<00:00, 142.77i\n",
      "[[3.60831696e-05 1.19697898e-01]\n",
      " [4.46098404e-04 3.70520556e-03]\n",
      " [5.88400043e-04 1.58771049e-03]\n",
      " [3.89561210e-04 7.54695920e-04]\n",
      " [2.96137390e-04 4.90277350e-04]\n",
      " [2.31365084e-04 3.02796473e-04]\n",
      " [2.02340447e-04 1.78424207e-04]\n",
      " [1.77167476e-04 1.97441292e-04]]\n",
      "Train Epoch61 out_loss 0.0006752423942089081\n",
      "Test Epoch61 layer0 out_loss 0.00825875997543335\n",
      "Test Epoch61 layer1 out_loss 0.0009399395785294473\n",
      "Test Epoch61 layer2 out_loss 0.0004441802157089114\n",
      "Test Epoch61 layer3 out_loss 0.0004390620451886207\n",
      "Test Epoch61 layer4 out_loss 0.0004957029013894498\n",
      "Test Epoch61 layer5 out_loss 0.0004888916155323386\n",
      "Test Epoch61 layer6 out_loss 0.00041655582026578486\n",
      "Test Epoch61 layer7 out_loss 0.00046328987809829414\n",
      "Train 62 | out_loss 0.0013576134806498885: 100%|█| 138/138 [00:00<00:00, 141.58i\n",
      "[[0.00038813 0.00981733]\n",
      " [0.00055809 0.00134134]\n",
      " [0.00066745 0.00124615]\n",
      " [0.00046867 0.00068576]\n",
      " [0.00040551 0.00043365]\n",
      " [0.00024315 0.00024095]\n",
      " [0.00020569 0.00017735]\n",
      " [0.00019874 0.00021147]]\n",
      "Train Epoch62 out_loss 0.0013576134806498885\n",
      "Test Epoch62 layer0 out_loss 0.0022107400000095367\n",
      "Test Epoch62 layer1 out_loss 0.0005715356091968715\n",
      "Test Epoch62 layer2 out_loss 0.000637597928289324\n",
      "Test Epoch62 layer3 out_loss 0.0005315372836776078\n",
      "Test Epoch62 layer4 out_loss 0.00041654237429611385\n",
      "Test Epoch62 layer5 out_loss 0.00041847137617878616\n",
      "Test Epoch62 layer6 out_loss 0.00042106874752789736\n",
      "Test Epoch62 layer7 out_loss 0.000416381488321349\n",
      "Train 63 | out_loss 0.0016139722429215908: 100%|█| 138/138 [00:00<00:00, 143.29i\n",
      "[[0.00050954 0.00582353]\n",
      " [0.00045504 0.00138059]\n",
      " [0.00071652 0.00139346]\n",
      " [0.00047055 0.00062955]\n",
      " [0.00032598 0.00035568]\n",
      " [0.00020118 0.00018301]\n",
      " [0.0001544  0.00014343]\n",
      " [0.0001223  0.00013535]]\n",
      "Train Epoch63 out_loss 0.0016139722429215908\n",
      "Test Epoch63 layer0 out_loss 0.003322965232655406\n",
      "Test Epoch63 layer1 out_loss 0.0008117606630548835\n",
      "Test Epoch63 layer2 out_loss 0.0006654008175246418\n",
      "Test Epoch63 layer3 out_loss 0.0005226649227552116\n",
      "Test Epoch63 layer4 out_loss 0.0005088371108286083\n",
      "Test Epoch63 layer5 out_loss 0.0005633090622723103\n",
      "Test Epoch63 layer6 out_loss 0.000640922924503684\n",
      "Test Epoch63 layer7 out_loss 0.000542441732250154\n",
      "Train 64 | out_loss 0.0009302416583523154: 100%|█| 138/138 [00:01<00:00, 137.71i\n",
      "[[0.00018102 0.01197368]\n",
      " [0.00042019 0.00140466]\n",
      " [0.00046943 0.00104286]\n",
      " [0.00036083 0.00057332]\n",
      " [0.00034195 0.00040406]\n",
      " [0.00035831 0.00035772]\n",
      " [0.00046022 0.00042827]\n",
      " [0.00036194 0.00034   ]]\n",
      "Train Epoch64 out_loss 0.0009302416583523154\n",
      "Test Epoch64 layer0 out_loss 0.01380077376961708\n",
      "Test Epoch64 layer1 out_loss 0.0076691689901053905\n",
      "Test Epoch64 layer2 out_loss 0.004758074879646301\n",
      "Test Epoch64 layer3 out_loss 0.004750845488160849\n",
      "Test Epoch64 layer4 out_loss 0.004912867210805416\n",
      "Test Epoch64 layer5 out_loss 0.004638849291950464\n",
      "Test Epoch64 layer6 out_loss 0.004519103094935417\n",
      "Test Epoch64 layer7 out_loss 0.004233246203511953\n",
      "Train 65 | out_loss 0.0009500400628894567: 100%|█| 138/138 [00:00<00:00, 139.87i\n",
      "[[0.00027299 0.07903973]\n",
      " [0.00046011 0.00357635]\n",
      " [0.00057651 0.00144766]\n",
      " [0.00045647 0.00092191]\n",
      " [0.00031126 0.00044761]\n",
      " [0.00022065 0.00021923]\n",
      " [0.00019643 0.00017863]\n",
      " [0.00016491 0.00018578]]\n",
      "Train Epoch65 out_loss 0.0009500400628894567\n",
      "Test Epoch65 layer0 out_loss 0.009179182350635529\n",
      "Test Epoch65 layer1 out_loss 0.0007383979391306639\n",
      "Test Epoch65 layer2 out_loss 0.000654237752314657\n",
      "Test Epoch65 layer3 out_loss 0.00044777648872695863\n",
      "Test Epoch65 layer4 out_loss 0.0005147845367901027\n",
      "Test Epoch65 layer5 out_loss 0.00047613063361495733\n",
      "Test Epoch65 layer6 out_loss 0.0005444227135740221\n",
      "Test Epoch65 layer7 out_loss 0.00044743961188942194\n",
      "Train 66 | out_loss 0.0013408552622422576: 100%|█| 138/138 [00:00<00:00, 141.42i\n",
      "[[0.00036186 0.06972767]\n",
      " [0.00050595 0.00324222]\n",
      " [0.00067694 0.00163222]\n",
      " [0.00053503 0.00090701]\n",
      " [0.00038865 0.00050271]\n",
      " [0.00026685 0.00025191]\n",
      " [0.00017665 0.00017651]\n",
      " [0.00015527 0.00017863]]\n",
      "Train Epoch66 out_loss 0.0013408552622422576\n",
      "Test Epoch66 layer0 out_loss 0.01141891535371542\n",
      "Test Epoch66 layer1 out_loss 0.0013311767252162099\n",
      "Test Epoch66 layer2 out_loss 0.00049429084174335\n",
      "Test Epoch66 layer3 out_loss 0.0006723168771713972\n",
      "Test Epoch66 layer4 out_loss 0.00043296872172504663\n",
      "Test Epoch66 layer5 out_loss 0.00041365440119989216\n",
      "Test Epoch66 layer6 out_loss 0.00043750525219365954\n",
      "Test Epoch66 layer7 out_loss 0.0004419803444761783\n",
      "Train 67 | out_loss 0.0014037693617865443: 100%|█| 138/138 [00:01<00:00, 135.77i\n",
      "[[0.00040277 0.02890043]\n",
      " [0.00061264 0.00229324]\n",
      " [0.00077728 0.00134623]\n",
      " [0.00042074 0.00068773]\n",
      " [0.00028931 0.00032691]\n",
      " [0.00020429 0.00021055]\n",
      " [0.00017896 0.00016614]\n",
      " [0.0001468  0.00014502]]\n",
      "Train Epoch67 out_loss 0.0014037693617865443\n",
      "Test Epoch67 layer0 out_loss 0.0033964638132601976\n",
      "Test Epoch67 layer1 out_loss 0.0007438732427544892\n",
      "Test Epoch67 layer2 out_loss 0.0006021095905452967\n",
      "Test Epoch67 layer3 out_loss 0.0005253595300018787\n",
      "Test Epoch67 layer4 out_loss 0.0006081982864998281\n",
      "Test Epoch67 layer5 out_loss 0.0006734022754244506\n",
      "Test Epoch67 layer6 out_loss 0.0008817662019282579\n",
      "Test Epoch67 layer7 out_loss 0.0006358054233714938\n",
      "Train 68 | out_loss 0.0014392341254279017: 100%|█| 138/138 [00:00<00:00, 138.10i\n",
      "[[0.00038673 0.00995062]\n",
      " [0.00035514 0.00144592]\n",
      " [0.00050168 0.00096547]\n",
      " [0.00031483 0.0004436 ]\n",
      " [0.00024383 0.0002574 ]\n",
      " [0.00016367 0.00015823]\n",
      " [0.00013673 0.0001178 ]\n",
      " [0.00010455 0.00011838]]\n",
      "Train Epoch68 out_loss 0.0014392341254279017\n",
      "Test Epoch68 layer0 out_loss 0.008257604204118252\n",
      "Test Epoch68 layer1 out_loss 0.0006773671484552324\n",
      "Test Epoch68 layer2 out_loss 0.0004153333720751107\n",
      "Test Epoch68 layer3 out_loss 0.0004184824647381902\n",
      "Test Epoch68 layer4 out_loss 0.00044511628220789135\n",
      "Test Epoch68 layer5 out_loss 0.0004497942281886935\n",
      "Test Epoch68 layer6 out_loss 0.0004812765109818429\n",
      "Test Epoch68 layer7 out_loss 0.0004727209743577987\n",
      "Train 69 | out_loss 0.001747902831993997: 100%|█| 138/138 [00:00<00:00, 138.68it\n",
      "[[0.00063632 0.01119596]\n",
      " [0.00045501 0.0019497 ]\n",
      " [0.00067333 0.00148444]\n",
      " [0.00064671 0.0007994 ]\n",
      " [0.00030999 0.00038021]\n",
      " [0.00020308 0.00022978]\n",
      " [0.00018955 0.00020977]\n",
      " [0.0001791  0.0002095 ]]\n",
      "Train Epoch69 out_loss 0.001747902831993997\n",
      "Test Epoch69 layer0 out_loss 0.007173182908445597\n",
      "Test Epoch69 layer1 out_loss 0.0006107031367719173\n",
      "Test Epoch69 layer2 out_loss 0.0014879860682412982\n",
      "Test Epoch69 layer3 out_loss 0.0007076741894707084\n",
      "Test Epoch69 layer4 out_loss 0.0005805495311506093\n",
      "Test Epoch69 layer5 out_loss 0.0007529521244578063\n",
      "Test Epoch69 layer6 out_loss 0.0007169367163442075\n",
      "Test Epoch69 layer7 out_loss 0.0007141117239370942\n",
      "Train 70 | out_loss 0.0004649119218811393: 100%|█| 138/138 [00:00<00:00, 140.62i\n",
      "[[1.70249286e-06 5.51923290e-02]\n",
      " [4.98943590e-04 3.96990610e-03]\n",
      " [5.85275751e-04 1.45515371e-03]\n",
      " [3.60480215e-04 7.10261794e-04]\n",
      " [2.62499035e-04 3.48298548e-04]\n",
      " [2.45113721e-04 2.42169210e-04]\n",
      " [2.20799565e-04 2.01028522e-04]\n",
      " [1.35551505e-04 1.37524696e-04]]\n",
      "Train Epoch70 out_loss 0.0004649119218811393\n",
      "Test Epoch70 layer0 out_loss 0.003977675456553698\n",
      "Test Epoch70 layer1 out_loss 0.0009441861184313893\n",
      "Test Epoch70 layer2 out_loss 0.0005538647528737783\n",
      "Test Epoch70 layer3 out_loss 0.00044921343214809895\n",
      "Test Epoch70 layer4 out_loss 0.0005121825961396098\n",
      "Test Epoch70 layer5 out_loss 0.00043530436232686043\n",
      "Test Epoch70 layer6 out_loss 0.0007406518561765552\n",
      "Test Epoch70 layer7 out_loss 0.0004904716624878347\n",
      "Train 71 | out_loss 0.0013961473014205694: 100%|█| 138/138 [00:00<00:00, 140.41i\n",
      "[[0.00039768 0.04335154]\n",
      " [0.00033322 0.00255913]\n",
      " [0.00041874 0.00106706]\n",
      " [0.00026855 0.0004752 ]\n",
      " [0.00023294 0.00028314]\n",
      " [0.00023241 0.00025762]\n",
      " [0.00020668 0.00017681]\n",
      " [0.00014503 0.00014622]]\n",
      "Train Epoch71 out_loss 0.0013961473014205694\n",
      "Test Epoch71 layer0 out_loss 0.046588510274887085\n",
      "Test Epoch71 layer1 out_loss 0.005277850665152073\n",
      "Test Epoch71 layer2 out_loss 0.0014029672602191567\n",
      "Test Epoch71 layer3 out_loss 0.0004438917967490852\n",
      "Test Epoch71 layer4 out_loss 0.00041800973122008145\n",
      "Test Epoch71 layer5 out_loss 0.0004501019138842821\n",
      "Test Epoch71 layer6 out_loss 0.0004920342471450567\n",
      "Test Epoch71 layer7 out_loss 0.0004573666665237397\n",
      "Train 72 | out_loss 0.0018087520729750395: 100%|█| 138/138 [00:00<00:00, 140.80i\n",
      "[[5.79646975e-04 1.79100208e-01]\n",
      " [3.84752139e-04 5.73317228e-03]\n",
      " [5.19280825e-04 1.92200389e-03]\n",
      " [3.51077253e-04 9.66547167e-04]\n",
      " [3.32059789e-04 5.72396945e-04]\n",
      " [3.21112498e-04 3.74864307e-04]\n",
      " [1.85488088e-04 1.84091084e-04]\n",
      " [1.24362940e-04 1.29054389e-04]]\n",
      "Train Epoch72 out_loss 0.0018087520729750395\n",
      "Test Epoch72 layer0 out_loss 0.007216060534119606\n",
      "Test Epoch72 layer1 out_loss 0.0010118171339854598\n",
      "Test Epoch72 layer2 out_loss 0.0004113081959076226\n",
      "Test Epoch72 layer3 out_loss 0.00042487477185204625\n",
      "Test Epoch72 layer4 out_loss 0.0004227616882417351\n",
      "Test Epoch72 layer5 out_loss 0.0004347980138845742\n",
      "Test Epoch72 layer6 out_loss 0.0004168545419815928\n",
      "Test Epoch72 layer7 out_loss 0.0004263554874341935\n",
      "Train 73 | out_loss 0.0007790930103510618: 100%|█| 138/138 [00:00<00:00, 139.34i\n",
      "[[7.97010003e-05 7.16156927e-03]\n",
      " [4.77673553e-04 1.23602518e-03]\n",
      " [6.79274590e-04 9.31762191e-04]\n",
      " [3.43244614e-04 4.95936993e-04]\n",
      " [2.63374485e-04 3.10007443e-04]\n",
      " [3.40930294e-04 2.91797534e-04]\n",
      " [2.08162130e-04 1.51535189e-04]\n",
      " [1.42217600e-04 1.35637692e-04]]\n",
      "Train Epoch73 out_loss 0.0007790930103510618\n",
      "Test Epoch73 layer0 out_loss 0.0061427573673427105\n",
      "Test Epoch73 layer1 out_loss 0.005245617590844631\n",
      "Test Epoch73 layer2 out_loss 0.003658342408016324\n",
      "Test Epoch73 layer3 out_loss 0.004366687498986721\n",
      "Test Epoch73 layer4 out_loss 0.004306149668991566\n",
      "Test Epoch73 layer5 out_loss 0.00420500710606575\n",
      "Test Epoch73 layer6 out_loss 0.004205682314932346\n",
      "Test Epoch73 layer7 out_loss 0.004098351113498211\n",
      "Train 74 | out_loss 0.001194986398331821: 100%|█| 138/138 [00:00<00:00, 140.36it\n",
      "[[0.00033281 0.00292524]\n",
      " [0.00050372 0.00119427]\n",
      " [0.00061712 0.00121438]\n",
      " [0.00047679 0.00055922]\n",
      " [0.00032377 0.00030967]\n",
      " [0.00034126 0.00032373]\n",
      " [0.00023005 0.00018007]\n",
      " [0.00016503 0.00016808]]\n",
      "Train Epoch74 out_loss 0.001194986398331821\n",
      "Test Epoch74 layer0 out_loss 0.0035887607373297215\n",
      "Test Epoch74 layer1 out_loss 0.0005165744805708528\n",
      "Test Epoch74 layer2 out_loss 0.0004628908063750714\n",
      "Test Epoch74 layer3 out_loss 0.0004623986897058785\n",
      "Test Epoch74 layer4 out_loss 0.00043460101005621254\n",
      "Test Epoch74 layer5 out_loss 0.0004512036102823913\n",
      "Test Epoch74 layer6 out_loss 0.0005533061339519918\n",
      "Test Epoch74 layer7 out_loss 0.0005151109071448445\n",
      "Train 75 | out_loss 0.0018494605319574475: 100%|█| 138/138 [00:01<00:00, 135.76i\n",
      "[[0.00072119 0.003098  ]\n",
      " [0.0003546  0.00096715]\n",
      " [0.00052338 0.00089168]\n",
      " [0.00038464 0.0004301 ]\n",
      " [0.00019738 0.00023047]\n",
      " [0.00019037 0.00018897]\n",
      " [0.00014551 0.00013529]\n",
      " [0.00010776 0.00013479]]\n",
      "Train Epoch75 out_loss 0.0018494605319574475\n",
      "Test Epoch75 layer0 out_loss 0.005561372265219688\n",
      "Test Epoch75 layer1 out_loss 0.0005376543267630041\n",
      "Test Epoch75 layer2 out_loss 0.0005532020586542785\n",
      "Test Epoch75 layer3 out_loss 0.00041962272371165454\n",
      "Test Epoch75 layer4 out_loss 0.00041800865437835455\n",
      "Test Epoch75 layer5 out_loss 0.0004334413097240031\n",
      "Test Epoch75 layer6 out_loss 0.0004157901566941291\n",
      "Test Epoch75 layer7 out_loss 0.0004173785273451358\n",
      "Train 76 | out_loss 0.00045380345545709133: 100%|█| 138/138 [00:00<00:00, 141.42\n",
      "[[2.06676690e-07 3.95369792e-03]\n",
      " [4.29078745e-04 1.38451930e-03]\n",
      " [5.63662110e-04 9.37802951e-04]\n",
      " [3.06868344e-04 4.70924212e-04]\n",
      " [2.32275016e-04 2.31551903e-04]\n",
      " [1.71796988e-04 1.45664974e-04]\n",
      " [1.18983101e-04 1.03898767e-04]\n",
      " [9.25692834e-05 1.07851407e-04]]\n",
      "Train Epoch76 out_loss 0.00045380345545709133\n",
      "Test Epoch76 layer0 out_loss 0.0035233304370194674\n",
      "Test Epoch76 layer1 out_loss 0.0007062437944114208\n",
      "Test Epoch76 layer2 out_loss 0.0004919728962704539\n",
      "Test Epoch76 layer3 out_loss 0.00042962603038176894\n",
      "Test Epoch76 layer4 out_loss 0.0004211037012282759\n",
      "Test Epoch76 layer5 out_loss 0.00041265093022957444\n",
      "Test Epoch76 layer6 out_loss 0.0004149666929151863\n",
      "Test Epoch76 layer7 out_loss 0.00041544355917721987\n",
      "Train 77 | out_loss 0.001402283669449389: 100%|█| 138/138 [00:01<00:00, 137.22it\n",
      "[[4.32814469e-04 2.72729476e-02]\n",
      " [4.77199542e-04 2.84446132e-03]\n",
      " [5.78189803e-04 1.24713847e-03]\n",
      " [3.90756368e-04 6.35798072e-04]\n",
      " [2.70618747e-04 3.06456603e-04]\n",
      " [1.95018998e-04 1.72304793e-04]\n",
      " [1.19652697e-04 1.21983173e-04]\n",
      " [8.60585995e-05 1.06153778e-04]]\n",
      "Train Epoch77 out_loss 0.001402283669449389\n",
      "Test Epoch77 layer0 out_loss 0.003183389315381646\n",
      "Test Epoch77 layer1 out_loss 0.000600694736931473\n",
      "Test Epoch77 layer2 out_loss 0.00042752348235808313\n",
      "Test Epoch77 layer3 out_loss 0.0004512620798777789\n",
      "Test Epoch77 layer4 out_loss 0.0004524185205809772\n",
      "Test Epoch77 layer5 out_loss 0.0005229500238783658\n",
      "Test Epoch77 layer6 out_loss 0.0005429625161923468\n",
      "Test Epoch77 layer7 out_loss 0.00048721826169639826\n",
      "Train 78 | out_loss 0.0015051710652187467: 100%|█| 138/138 [00:01<00:00, 137.17i\n",
      "[[0.00052273 0.0079636 ]\n",
      " [0.00028508 0.00140337]\n",
      " [0.00039676 0.00082113]\n",
      " [0.00026006 0.00041211]\n",
      " [0.000201   0.00023412]\n",
      " [0.0001786  0.00015617]\n",
      " [0.00015564 0.00013732]\n",
      " [0.00010781 0.00012732]]\n",
      "Train Epoch78 out_loss 0.0015051710652187467\n",
      "Test Epoch78 layer0 out_loss 0.005084489472210407\n",
      "Test Epoch78 layer1 out_loss 0.0005309896660037339\n",
      "Test Epoch78 layer2 out_loss 0.0005213685799390078\n",
      "Test Epoch78 layer3 out_loss 0.00048544618766754866\n",
      "Test Epoch78 layer4 out_loss 0.0005203168839216232\n",
      "Test Epoch78 layer5 out_loss 0.0005303943762555718\n",
      "Test Epoch78 layer6 out_loss 0.0006496829446405172\n",
      "Test Epoch78 layer7 out_loss 0.000611968629527837\n",
      "Train 79 | out_loss 0.001417296240106225: 100%|█| 138/138 [00:00<00:00, 140.21it\n",
      "[[0.00043286 0.01078519]\n",
      " [0.00049225 0.00177408]\n",
      " [0.00060401 0.00118563]\n",
      " [0.00037545 0.00049217]\n",
      " [0.0002457  0.00027593]\n",
      " [0.00017726 0.00015834]\n",
      " [0.00016817 0.00015452]\n",
      " [0.00010008 0.00011389]]\n",
      "Train Epoch79 out_loss 0.001417296240106225\n",
      "Test Epoch79 layer0 out_loss 0.009212457574903965\n",
      "Test Epoch79 layer1 out_loss 0.0033277214970439672\n",
      "Test Epoch79 layer2 out_loss 0.001966266892850399\n",
      "Test Epoch79 layer3 out_loss 0.0013978290371596813\n",
      "Test Epoch79 layer4 out_loss 0.0018746311543509364\n",
      "Test Epoch79 layer5 out_loss 0.001778998295776546\n",
      "Test Epoch79 layer6 out_loss 0.001945825875736773\n",
      "Test Epoch79 layer7 out_loss 0.0018302608514204621\n",
      "Train 80 | out_loss 0.0005591022199951112: 100%|█| 138/138 [00:00<00:00, 138.51i\n",
      "[[4.30557214e-05 4.87074915e-02]\n",
      " [3.16809815e-04 3.41925204e-03]\n",
      " [4.63939726e-04 1.37652662e-03]\n",
      " [2.88135763e-04 6.25848309e-04]\n",
      " [2.24331679e-04 3.28225112e-04]\n",
      " [1.99521460e-04 1.88805662e-04]\n",
      " [1.63559460e-04 1.54945297e-04]\n",
      " [1.09990845e-04 1.52204015e-04]]\n",
      "Train Epoch80 out_loss 0.0005591022199951112\n",
      "Test Epoch80 layer0 out_loss 0.0036569496151059866\n",
      "Test Epoch80 layer1 out_loss 0.002658272860571742\n",
      "Test Epoch80 layer2 out_loss 0.0004696959804277867\n",
      "Test Epoch80 layer3 out_loss 0.000548187003005296\n",
      "Test Epoch80 layer4 out_loss 0.0005900135729461908\n",
      "Test Epoch80 layer5 out_loss 0.0004190316249150783\n",
      "Test Epoch80 layer6 out_loss 0.0004265706811565906\n",
      "Test Epoch80 layer7 out_loss 0.0004331502423156053\n",
      "Train 81 | out_loss 0.0015170914120972157: 100%|█| 138/138 [00:00<00:00, 143.70i\n",
      "[[0.00057656 0.04589984]\n",
      " [0.00047017 0.00337789]\n",
      " [0.00060785 0.00157691]\n",
      " [0.00044674 0.00071293]\n",
      " [0.00031348 0.00043634]\n",
      " [0.00027591 0.00028314]\n",
      " [0.00021995 0.00020755]\n",
      " [0.00016492 0.0002044 ]]\n",
      "Train Epoch81 out_loss 0.0015170914120972157\n",
      "Test Epoch81 layer0 out_loss 0.0035930362064391375\n",
      "Test Epoch81 layer1 out_loss 0.0011864155530929565\n",
      "Test Epoch81 layer2 out_loss 0.00045577550190500915\n",
      "Test Epoch81 layer3 out_loss 0.0004832893318962306\n",
      "Test Epoch81 layer4 out_loss 0.0004722540907096118\n",
      "Test Epoch81 layer5 out_loss 0.000429860083386302\n",
      "Test Epoch81 layer6 out_loss 0.0004172000626567751\n",
      "Test Epoch81 layer7 out_loss 0.0004671542264986783\n",
      "Train 82 | out_loss 0.0015915343537926674: 100%|█| 138/138 [00:00<00:00, 138.26i\n",
      "[[0.00053522 0.02351872]\n",
      " [0.00042852 0.00249368]\n",
      " [0.00069176 0.00133457]\n",
      " [0.00044938 0.00059815]\n",
      " [0.00033723 0.00035639]\n",
      " [0.00025777 0.00024355]\n",
      " [0.00032422 0.00030412]\n",
      " [0.00022027 0.00023314]]\n",
      "Train Epoch82 out_loss 0.0015915343537926674\n",
      "Test Epoch82 layer0 out_loss 0.009078389964997768\n",
      "Test Epoch82 layer1 out_loss 0.0012240131618455052\n",
      "Test Epoch82 layer2 out_loss 0.00048330664867535233\n",
      "Test Epoch82 layer3 out_loss 0.0006917931605130434\n",
      "Test Epoch82 layer4 out_loss 0.0006572676356881857\n",
      "Test Epoch82 layer5 out_loss 0.000538953288923949\n",
      "Test Epoch82 layer6 out_loss 0.000514285871759057\n",
      "Test Epoch82 layer7 out_loss 0.0005594094400294125\n",
      "Train 83 | out_loss 0.000696966249961406: 100%|█| 138/138 [00:00<00:00, 141.68it\n",
      "[[5.06145547e-05 1.01622865e-02]\n",
      " [4.29323670e-04 1.70787704e-03]\n",
      " [6.54470726e-04 1.00995469e-03]\n",
      " [3.25499642e-04 4.96103897e-04]\n",
      " [2.57322854e-04 2.87800062e-04]\n",
      " [2.25972761e-04 1.91777330e-04]\n",
      " [1.52631872e-04 1.45314739e-04]\n",
      " [1.11319860e-04 1.60048403e-04]]\n",
      "Train Epoch83 out_loss 0.000696966249961406\n",
      "Test Epoch83 layer0 out_loss 0.0021487721242010593\n",
      "Test Epoch83 layer1 out_loss 0.00047813370474614203\n",
      "Test Epoch83 layer2 out_loss 0.0004892305587418377\n",
      "Test Epoch83 layer3 out_loss 0.00042979943100363016\n",
      "Test Epoch83 layer4 out_loss 0.0005050870240665972\n",
      "Test Epoch83 layer5 out_loss 0.0004593021294567734\n",
      "Test Epoch83 layer6 out_loss 0.00043856180855073035\n",
      "Test Epoch83 layer7 out_loss 0.00044546936987899244\n",
      "Train 84 | out_loss 0.0015175623120740056: 100%|█| 138/138 [00:01<00:00, 137.89i\n",
      "[[0.00054711 0.0208402 ]\n",
      " [0.00026397 0.00237268]\n",
      " [0.00048418 0.00097378]\n",
      " [0.00026549 0.00041341]\n",
      " [0.00021644 0.00025133]\n",
      " [0.00018882 0.00021639]\n",
      " [0.0001906  0.00015904]\n",
      " [0.00016839 0.00015961]]\n",
      "Train Epoch84 out_loss 0.0015175623120740056\n",
      "Test Epoch84 layer0 out_loss 0.01238442026078701\n",
      "Test Epoch84 layer1 out_loss 0.0019997090566903353\n",
      "Test Epoch84 layer2 out_loss 0.000451629632152617\n",
      "Test Epoch84 layer3 out_loss 0.0004662876599468291\n",
      "Test Epoch84 layer4 out_loss 0.00045386978308670223\n",
      "Test Epoch84 layer5 out_loss 0.0004130839370191097\n",
      "Test Epoch84 layer6 out_loss 0.0004266236210241914\n",
      "Test Epoch84 layer7 out_loss 0.00046106893569231033\n",
      "Train 85 | out_loss 0.0012167446548119187: 100%|█| 138/138 [00:00<00:00, 138.38i\n",
      "[[0.00027123 0.01593981]\n",
      " [0.00038269 0.00252438]\n",
      " [0.00041448 0.00086447]\n",
      " [0.00027321 0.00045796]\n",
      " [0.00019414 0.00027468]\n",
      " [0.00015724 0.0001662 ]\n",
      " [0.00014127 0.00012708]\n",
      " [0.00011506 0.00013378]]\n",
      "Train Epoch85 out_loss 0.0012167446548119187\n",
      "Test Epoch85 layer0 out_loss 0.023570289835333824\n",
      "Test Epoch85 layer1 out_loss 0.004155271220952272\n",
      "Test Epoch85 layer2 out_loss 0.003150228876620531\n",
      "Test Epoch85 layer3 out_loss 0.002852541860193014\n",
      "Test Epoch85 layer4 out_loss 0.002935239113867283\n",
      "Test Epoch85 layer5 out_loss 0.0029321559704840183\n",
      "Test Epoch85 layer6 out_loss 0.0028769834898412228\n",
      "Test Epoch85 layer7 out_loss 0.002985780593007803\n",
      "Train 86 | out_loss 0.000795586674939841: 100%|█| 138/138 [00:01<00:00, 137.64it\n",
      "[[0.00012743 0.01909418]\n",
      " [0.00034442 0.00207001]\n",
      " [0.00034751 0.00081774]\n",
      " [0.00024227 0.00043487]\n",
      " [0.00024518 0.00030473]\n",
      " [0.00019427 0.00021981]\n",
      " [0.00021622 0.00015736]\n",
      " [0.00012105 0.00013076]]\n",
      "Train Epoch86 out_loss 0.000795586674939841\n",
      "Test Epoch86 layer0 out_loss 0.007866978645324707\n",
      "Test Epoch86 layer1 out_loss 0.0023753575515002012\n",
      "Test Epoch86 layer2 out_loss 0.0006057033897377551\n",
      "Test Epoch86 layer3 out_loss 0.0006197388865984976\n",
      "Test Epoch86 layer4 out_loss 0.0005674709100276232\n",
      "Test Epoch86 layer5 out_loss 0.000714939262252301\n",
      "Test Epoch86 layer6 out_loss 0.000599876104388386\n",
      "Test Epoch86 layer7 out_loss 0.0007809298695065081\n",
      "Train 87 | out_loss 0.0013048817636445165: 100%|█| 138/138 [00:00<00:00, 142.54i\n",
      "[[3.73731218e-04 2.78756068e-02]\n",
      " [2.72478269e-04 3.10005391e-03]\n",
      " [3.60339045e-04 1.09664129e-03]\n",
      " [2.29963713e-04 4.84529908e-04]\n",
      " [2.56907632e-04 2.79169255e-04]\n",
      " [1.48375755e-04 1.43815509e-04]\n",
      " [9.28619723e-05 9.03706097e-05]\n",
      " [6.64431590e-05 8.33976849e-05]]\n",
      "Train Epoch87 out_loss 0.0013048817636445165\n",
      "Test Epoch87 layer0 out_loss 0.0023759377654641867\n",
      "Test Epoch87 layer1 out_loss 0.0006228938000276685\n",
      "Test Epoch87 layer2 out_loss 0.0005184758920222521\n",
      "Test Epoch87 layer3 out_loss 0.0004285298637114465\n",
      "Test Epoch87 layer4 out_loss 0.000490560254547745\n",
      "Test Epoch87 layer5 out_loss 0.0004163804114796221\n",
      "Test Epoch87 layer6 out_loss 0.00042195379501208663\n",
      "Test Epoch87 layer7 out_loss 0.0004205669683869928\n",
      "Train 88 | out_loss 0.0013826240319758654: 100%|█| 138/138 [00:01<00:00, 137.58i\n",
      "[[4.45940388e-04 1.15941742e-02]\n",
      " [4.03012823e-04 2.03304252e-03]\n",
      " [6.02643465e-04 1.00864071e-03]\n",
      " [4.75390137e-04 5.15349350e-04]\n",
      " [2.90880042e-04 2.66099617e-04]\n",
      " [1.49031909e-04 1.30799640e-04]\n",
      " [9.72380817e-05 1.02646409e-04]\n",
      " [8.49774715e-05 1.14193745e-04]]\n",
      "Train Epoch88 out_loss 0.0013826240319758654\n",
      "Test Epoch88 layer0 out_loss 0.01450090017169714\n",
      "Test Epoch88 layer1 out_loss 0.0006457630661316216\n",
      "Test Epoch88 layer2 out_loss 0.0004381075850687921\n",
      "Test Epoch88 layer3 out_loss 0.00041827952372841537\n",
      "Test Epoch88 layer4 out_loss 0.0004247916513122618\n",
      "Test Epoch88 layer5 out_loss 0.0004154908237978816\n",
      "Test Epoch88 layer6 out_loss 0.0004230384074617177\n",
      "Test Epoch88 layer7 out_loss 0.000416792492615059\n",
      "Train 89 | out_loss 0.0012688144342973828: 100%|█| 138/138 [00:01<00:00, 133.48i\n",
      "[[3.27708861e-04 4.79312082e-02]\n",
      " [3.51966638e-04 4.80900502e-03]\n",
      " [4.55403957e-04 1.17264949e-03]\n",
      " [2.41897626e-04 5.52848695e-04]\n",
      " [2.37208295e-04 3.57238646e-04]\n",
      " [1.87889144e-04 1.65700101e-04]\n",
      " [1.32030846e-04 1.20518754e-04]\n",
      " [9.72973304e-05 1.15208330e-04]]\n",
      "Train Epoch89 out_loss 0.0012688144342973828\n",
      "Test Epoch89 layer0 out_loss 0.0037596160545945168\n",
      "Test Epoch89 layer1 out_loss 0.0010637451196089387\n",
      "Test Epoch89 layer2 out_loss 0.0004032767319586128\n",
      "Test Epoch89 layer3 out_loss 0.000447882863227278\n",
      "Test Epoch89 layer4 out_loss 0.0004185708239674568\n",
      "Test Epoch89 layer5 out_loss 0.00041815725853666663\n",
      "Test Epoch89 layer6 out_loss 0.00042305211536586285\n",
      "Test Epoch89 layer7 out_loss 0.00041681923903524876\n",
      "Train 90 | out_loss 0.0015319930389523506: 100%|█| 138/138 [00:00<00:00, 138.92i\n",
      "[[0.00055073 0.00595401]\n",
      " [0.00045357 0.00165631]\n",
      " [0.00084469 0.00140524]\n",
      " [0.00081231 0.0008731 ]\n",
      " [0.00052817 0.00050964]\n",
      " [0.00027446 0.0002012 ]\n",
      " [0.00017127 0.00015658]\n",
      " [0.00011272 0.00014846]]\n",
      "Train Epoch90 out_loss 0.0015319930389523506\n",
      "Test Epoch90 layer0 out_loss 0.004185579717159271\n",
      "Test Epoch90 layer1 out_loss 0.0008200820884667337\n",
      "Test Epoch90 layer2 out_loss 0.0004824358911719173\n",
      "Test Epoch90 layer3 out_loss 0.0005522649735212326\n",
      "Test Epoch90 layer4 out_loss 0.0005764325032941997\n",
      "Test Epoch90 layer5 out_loss 0.0004192588967271149\n",
      "Test Epoch90 layer6 out_loss 0.0005900560645386577\n",
      "Test Epoch90 layer7 out_loss 0.0005071043851785362\n",
      "Train 91 | out_loss 0.0011540510458871722: 100%|█| 138/138 [00:00<00:00, 139.67i\n",
      "[[0.00028813 0.00293571]\n",
      " [0.00025877 0.00082576]\n",
      " [0.00031849 0.00052319]\n",
      " [0.00025302 0.00045027]\n",
      " [0.00035281 0.00042652]\n",
      " [0.00030527 0.00032486]\n",
      " [0.00031585 0.0003345 ]\n",
      " [0.00027207 0.00042083]]\n",
      "Train Epoch91 out_loss 0.0011540510458871722\n",
      "Test Epoch91 layer0 out_loss 0.0026740061584860086\n",
      "Test Epoch91 layer1 out_loss 0.001401296118274331\n",
      "Test Epoch91 layer2 out_loss 0.0013853730633854866\n",
      "Test Epoch91 layer3 out_loss 0.001557047595269978\n",
      "Test Epoch91 layer4 out_loss 0.001503816805779934\n",
      "Test Epoch91 layer5 out_loss 0.0011915412032976747\n",
      "Test Epoch91 layer6 out_loss 0.0012514683185145259\n",
      "Test Epoch91 layer7 out_loss 0.001175228040665388\n",
      "Train 92 | out_loss 0.0008117640973068774: 100%|█| 138/138 [00:01<00:00, 134.90i\n",
      "[[1.09202220e-04 9.28340193e-03]\n",
      " [2.63145718e-04 2.07809377e-03]\n",
      " [2.99796177e-04 7.22021626e-04]\n",
      " [1.63931405e-04 3.14401786e-04]\n",
      " [2.02317491e-04 2.09353750e-04]\n",
      " [1.58376487e-04 1.54351771e-04]\n",
      " [1.25832459e-04 1.17637132e-04]\n",
      " [7.08453185e-05 8.45096155e-05]]\n",
      "Train Epoch92 out_loss 0.0008117640973068774\n",
      "Test Epoch92 layer0 out_loss 0.001939381705597043\n",
      "Test Epoch92 layer1 out_loss 0.0010264066513627768\n",
      "Test Epoch92 layer2 out_loss 0.0009332866757176816\n",
      "Test Epoch92 layer3 out_loss 0.001075955806300044\n",
      "Test Epoch92 layer4 out_loss 0.001055424683727324\n",
      "Test Epoch92 layer5 out_loss 0.0010039007756859064\n",
      "Test Epoch92 layer6 out_loss 0.0010199823882430792\n",
      "Test Epoch92 layer7 out_loss 0.0010685157030820847\n",
      "Train 93 | out_loss 0.012832934968173504: 100%|█| 138/138 [00:01<00:00, 128.80it\n",
      "[[0.00035983 0.00392008]\n",
      " [0.00846113 0.03505503]\n",
      " [0.0200075  0.05525312]\n",
      " [0.04034286 0.06742509]\n",
      " [0.0727711  0.10135337]\n",
      " [0.10893199 0.11846626]\n",
      " [0.09682859 0.12873462]\n",
      " [0.08458259 0.10754303]]\n",
      "Train Epoch93 out_loss 0.012832934968173504\n",
      "Test Epoch93 layer0 out_loss 0.003279666183516383\n",
      "Test Epoch93 layer1 out_loss 0.02381664142012596\n",
      "Test Epoch93 layer2 out_loss 0.00512054655700922\n",
      "Test Epoch93 layer3 out_loss 0.003114495426416397\n",
      "Test Epoch93 layer4 out_loss 0.013702023774385452\n",
      "Test Epoch93 layer5 out_loss 0.04514053836464882\n",
      "Test Epoch93 layer6 out_loss 0.07632553577423096\n",
      "Test Epoch93 layer7 out_loss 0.03308439254760742\n",
      "Train 94 | out_loss 0.031815823167562485: 100%|█| 138/138 [00:01<00:00, 131.62it\n",
      "[[0.00043079 0.01098296]\n",
      " [0.002878   0.02336141]\n",
      " [0.00918639 0.03484762]\n",
      " [0.02537778 0.06890118]\n",
      " [0.09713506 0.18399037]\n",
      " [0.19867797 0.26408375]\n",
      " [0.21729768 0.34173367]\n",
      " [0.21981617 0.34188222]]\n",
      "Train Epoch94 out_loss 0.031815823167562485\n",
      "Test Epoch94 layer0 out_loss 0.00360596994869411\n",
      "Test Epoch94 layer1 out_loss 0.0016092066653072834\n",
      "Test Epoch94 layer2 out_loss 0.0004861873749177903\n",
      "Test Epoch94 layer3 out_loss 0.00048161085578612983\n",
      "Test Epoch94 layer4 out_loss 0.00046581975766457617\n",
      "Test Epoch94 layer5 out_loss 0.00043375836685299873\n",
      "Test Epoch94 layer6 out_loss 0.0006373168434947729\n",
      "Test Epoch94 layer7 out_loss 0.0007475125603377819\n",
      "Train 95 | out_loss 0.0019086258253082633: 100%|█| 138/138 [00:01<00:00, 131.38i\n",
      "[[5.55222821e-04 3.34013886e-02]\n",
      " [5.60848610e-06 2.97332579e-03]\n",
      " [2.58329472e-06 6.97678875e-04]\n",
      " [3.75101632e-06 6.52228201e-04]\n",
      " [5.47696979e-06 6.43847690e-04]\n",
      " [5.39675530e-06 8.21907375e-04]\n",
      " [3.83466910e-05 7.68212876e-04]\n",
      " [1.52198558e-04 1.11593892e-03]]\n",
      "Train Epoch95 out_loss 0.0019086258253082633\n",
      "Test Epoch95 layer0 out_loss 0.0025017494335770607\n",
      "Test Epoch95 layer1 out_loss 0.0006217701593413949\n",
      "Test Epoch95 layer2 out_loss 0.00043557328172028065\n",
      "Test Epoch95 layer3 out_loss 0.0007067535188980401\n",
      "Test Epoch95 layer4 out_loss 0.00042284041410312057\n",
      "Test Epoch95 layer5 out_loss 0.000417738629039377\n",
      "Test Epoch95 layer6 out_loss 0.0005018465453758836\n",
      "Test Epoch95 layer7 out_loss 0.0004963952233083546\n",
      "Train 96 | out_loss 0.0014250403037294745: 100%|█| 138/138 [00:01<00:00, 127.50i\n",
      "[[2.93799395e-04 4.65164594e-03]\n",
      " [5.79843449e-06 3.54078039e-04]\n",
      " [3.76686527e-06 1.52529118e-04]\n",
      " [5.37004106e-06 1.75402777e-04]\n",
      " [6.16700844e-06 1.88915472e-04]\n",
      " [5.31588685e-06 3.06023927e-04]\n",
      " [7.53285783e-06 2.80357350e-04]\n",
      " [8.23968157e-06 2.31560289e-04]]\n",
      "Train Epoch96 out_loss 0.0014250403037294745\n",
      "Test Epoch96 layer0 out_loss 0.004199004732072353\n",
      "Test Epoch96 layer1 out_loss 0.004471634514629841\n",
      "Test Epoch96 layer2 out_loss 0.0043144491501152515\n",
      "Test Epoch96 layer3 out_loss 0.004419830162078142\n",
      "Test Epoch96 layer4 out_loss 0.004385122563689947\n",
      "Test Epoch96 layer5 out_loss 0.0044043478555977345\n",
      "Test Epoch96 layer6 out_loss 0.004498306196182966\n",
      "Test Epoch96 layer7 out_loss 0.004426795523613691\n",
      "Train 97 | out_loss 0.0010105737019330263: 100%|█| 138/138 [00:01<00:00, 128.77i\n",
      "[[1.65937371e-04 7.24400625e-03]\n",
      " [5.63802455e-06 4.18102458e-04]\n",
      " [3.23648347e-06 1.50954191e-04]\n",
      " [4.84085054e-06 1.36287328e-04]\n",
      " [5.61257986e-06 1.52624689e-04]\n",
      " [5.22818298e-06 2.40122480e-04]\n",
      " [8.41457472e-06 2.19319985e-04]\n",
      " [8.65030484e-06 1.69410974e-04]]\n",
      "Train Epoch97 out_loss 0.0010105737019330263\n",
      "Test Epoch97 layer0 out_loss 0.006354425568133593\n",
      "Test Epoch97 layer1 out_loss 0.0005983121227473021\n",
      "Test Epoch97 layer2 out_loss 0.00044255881221033633\n",
      "Test Epoch97 layer3 out_loss 0.00047387799713760614\n",
      "Test Epoch97 layer4 out_loss 0.00040842112503014505\n",
      "Test Epoch97 layer5 out_loss 0.00040376553079113364\n",
      "Test Epoch97 layer6 out_loss 0.0005763848312199116\n",
      "Test Epoch97 layer7 out_loss 0.00047597449156455696\n",
      "Train 98 | out_loss 0.001962287351489067: 100%|█| 138/138 [00:01<00:00, 130.66it\n",
      "[[6.33764992e-04 1.07829956e-02]\n",
      " [6.53330529e-06 1.16715760e-03]\n",
      " [5.50001484e-06 3.45888624e-04]\n",
      " [9.52142757e-06 2.39830643e-04]\n",
      " [2.03249896e-05 2.60555122e-04]\n",
      " [1.48274752e-05 3.16124055e-04]\n",
      " [3.33304019e-05 2.81345880e-04]\n",
      " [3.19872677e-05 2.66653530e-04]]\n",
      "Train Epoch98 out_loss 0.001962287351489067\n",
      "Test Epoch98 layer0 out_loss 0.004488716367632151\n",
      "Test Epoch98 layer1 out_loss 0.00047012310824356973\n",
      "Test Epoch98 layer2 out_loss 0.0006150177214294672\n",
      "Test Epoch98 layer3 out_loss 0.0005015477654524148\n",
      "Test Epoch98 layer4 out_loss 0.00043253155308775604\n",
      "Test Epoch98 layer5 out_loss 0.0004620814579539001\n",
      "Test Epoch98 layer6 out_loss 0.0004426630330272019\n",
      "Test Epoch98 layer7 out_loss 0.0004553228209260851\n",
      "Train 99 | out_loss 0.00045583813334815204: 100%|█| 138/138 [00:01<00:00, 128.46\n",
      "[[3.37434461e-06 2.58252681e-03]\n",
      " [5.78466490e-06 3.21125050e-04]\n",
      " [5.61083669e-06 1.03709803e-04]\n",
      " [8.34534215e-06 1.07032205e-04]\n",
      " [8.53334056e-06 1.16653727e-04]\n",
      " [8.32909720e-06 1.77283406e-04]\n",
      " [1.14499563e-05 1.52781635e-04]\n",
      " [1.27610011e-05 1.22393562e-04]]\n",
      "Train Epoch99 out_loss 0.00045583813334815204\n",
      "Test Epoch99 layer0 out_loss 0.002205279655754566\n",
      "Test Epoch99 layer1 out_loss 0.0013980884104967117\n",
      "Test Epoch99 layer2 out_loss 0.00109473941847682\n",
      "Test Epoch99 layer3 out_loss 0.0010666173184290528\n",
      "Test Epoch99 layer4 out_loss 0.0011259212624281645\n",
      "Test Epoch99 layer5 out_loss 0.0011686767684295774\n",
      "Test Epoch99 layer6 out_loss 0.0012899553403258324\n",
      "Test Epoch99 layer7 out_loss 0.001197493402287364\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Start Training\n",
      "  0%|                                                   | 0/138 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 0.04898292198777199: 100%|█| 138/138 [00:01<00:00, 89.84it/s]\n",
      "[[ 0.39534058 26.58267528]\n",
      " [ 1.37420621 13.18869081]\n",
      " [ 0.859597    5.46863195]\n",
      " [ 0.73139495  2.90603202]\n",
      " [ 0.68331785  1.76558798]\n",
      " [ 0.74699236  1.13885501]\n",
      " [ 0.62229473  0.84933645]\n",
      " [ 0.5986294   0.74676752]\n",
      " [ 0.5148411   0.67486429]]\n",
      "Train Epoch0 out_loss 0.04898292198777199\n",
      "Test Epoch0 layer0 out_loss 0.09138745069503784\n",
      "Test Epoch0 layer1 out_loss 0.018840758129954338\n",
      "Test Epoch0 layer2 out_loss 0.005586095154285431\n",
      "Test Epoch0 layer3 out_loss 0.0027445871382951736\n",
      "Test Epoch0 layer4 out_loss 0.00216649379581213\n",
      "Test Epoch0 layer5 out_loss 0.0026104843709617853\n",
      "Test Epoch0 layer6 out_loss 0.00131601735483855\n",
      "Test Epoch0 layer7 out_loss 0.003705242183059454\n",
      "Test Epoch0 layer8 out_loss 0.0019366296473890543\n",
      "Train 1 | out_loss 0.0009310445166192949: 100%|█| 138/138 [00:01<00:00, 114.96it\n",
      "[[7.97221236e-06 6.33307882e+00]\n",
      " [8.23605113e-06 4.04301444e-01]\n",
      " [7.98474594e-06 8.75317017e-02]\n",
      " [7.98021272e-05 3.32990630e-02]\n",
      " [6.25673469e-04 1.55364111e-02]\n",
      " [2.66792693e-03 1.01279146e-02]\n",
      " [5.42590668e-03 1.29158438e-02]\n",
      " [8.69579350e-03 1.10137597e-02]\n",
      " [7.64071766e-03 7.51993646e-03]]\n",
      "Train Epoch1 out_loss 0.0009310445166192949\n",
      "Test Epoch1 layer0 out_loss 0.051511600613594055\n",
      "Test Epoch1 layer1 out_loss 0.007616401184350252\n",
      "Test Epoch1 layer2 out_loss 0.004047743044793606\n",
      "Test Epoch1 layer3 out_loss 0.0014706816291436553\n",
      "Test Epoch1 layer4 out_loss 0.0012149792164564133\n",
      "Test Epoch1 layer5 out_loss 0.0009584934450685978\n",
      "Test Epoch1 layer6 out_loss 0.0007078477647155523\n",
      "Test Epoch1 layer7 out_loss 0.0005110041820444167\n",
      "Test Epoch1 layer8 out_loss 0.00045636435970664024\n",
      "Train 2 | out_loss 0.00040472261025570333: 100%|█| 138/138 [00:01<00:00, 117.67i\n",
      "[[7.70652384e-06 3.90455342e+00]\n",
      " [8.04053241e-06 1.45661709e-01]\n",
      " [1.68483097e-06 3.20634539e-02]\n",
      " [1.21913669e-06 1.16552980e-02]\n",
      " [1.27694892e-06 4.60117590e-03]\n",
      " [1.99977364e-06 1.80058751e-03]\n",
      " [1.65899110e-06 8.74754907e-04]\n",
      " [1.64433400e-06 3.31949224e-04]\n",
      " [9.66129122e-07 1.44287139e-04]]\n",
      "Train Epoch2 out_loss 0.00040472261025570333\n",
      "Test Epoch2 layer0 out_loss 0.051780011504888535\n",
      "Test Epoch2 layer1 out_loss 0.0072310324758291245\n",
      "Test Epoch2 layer2 out_loss 0.0030257883481681347\n",
      "Test Epoch2 layer3 out_loss 0.0009466995834372938\n",
      "Test Epoch2 layer4 out_loss 0.000850723881740123\n",
      "Test Epoch2 layer5 out_loss 0.0006101076141931117\n",
      "Test Epoch2 layer6 out_loss 0.0006093845004215837\n",
      "Test Epoch2 layer7 out_loss 0.0005498459213413298\n",
      "Test Epoch2 layer8 out_loss 0.000425722828367725\n",
      "Train 3 | out_loss 0.00040021282620728016: 100%|█| 138/138 [00:01<00:00, 114.35i\n",
      "[[7.54814836e-06 2.68062515e+00]\n",
      " [9.34340498e-06 8.97182200e-02]\n",
      " [1.72735549e-06 1.80220144e-02]\n",
      " [1.28613075e-06 6.15330698e-03]\n",
      " [1.23510212e-06 2.43635729e-03]\n",
      " [1.37384613e-06 1.03705802e-03]\n",
      " [1.42537481e-06 4.91518687e-04]\n",
      " [1.20982563e-06 1.92342344e-04]\n",
      " [6.64376011e-07 8.31905371e-05]]\n",
      "Train Epoch3 out_loss 0.00040021282620728016\n",
      "Test Epoch3 layer0 out_loss 0.033046379685401917\n",
      "Test Epoch3 layer1 out_loss 0.007777488324791193\n",
      "Test Epoch3 layer2 out_loss 0.0015996780712157488\n",
      "Test Epoch3 layer3 out_loss 0.0009241852094419301\n",
      "Test Epoch3 layer4 out_loss 0.0006565836956724524\n",
      "Test Epoch3 layer5 out_loss 0.0006066397181712091\n",
      "Test Epoch3 layer6 out_loss 0.0006701675010845065\n",
      "Test Epoch3 layer7 out_loss 0.0004834375868085772\n",
      "Test Epoch3 layer8 out_loss 0.00045406981371343136\n",
      "Train 4 | out_loss 0.0004121109377592802: 100%|█| 138/138 [00:01<00:00, 116.83it\n",
      "[[7.52107954e-06 1.87499349e+00]\n",
      " [9.38364103e-06 1.00039989e-01]\n",
      " [1.92175538e-06 1.39591855e-02]\n",
      " [2.00516511e-06 4.37674607e-03]\n",
      " [2.66807896e-06 1.69995449e-03]\n",
      " [3.23078100e-06 7.66346080e-04]\n",
      " [3.47856095e-06 3.74323861e-04]\n",
      " [2.96130981e-06 1.51194584e-04]\n",
      " [1.45698030e-06 6.43132286e-05]]\n",
      "Train Epoch4 out_loss 0.0004121109377592802\n",
      "Test Epoch4 layer0 out_loss 0.0669761598110199\n",
      "Test Epoch4 layer1 out_loss 0.003725900314748287\n",
      "Test Epoch4 layer2 out_loss 0.0015526614151895046\n",
      "Test Epoch4 layer3 out_loss 0.0006508262013085186\n",
      "Test Epoch4 layer4 out_loss 0.0005193360848352313\n",
      "Test Epoch4 layer5 out_loss 0.0005198174621909857\n",
      "Test Epoch4 layer6 out_loss 0.0004833589482586831\n",
      "Test Epoch4 layer7 out_loss 0.0004542083479464054\n",
      "Test Epoch4 layer8 out_loss 0.00041458976920694113\n",
      "Train 5 | out_loss 0.0004055681638419628: 100%|█| 138/138 [00:01<00:00, 111.17it\n",
      "[[7.42530268e-06 1.34575584e+00]\n",
      " [9.96151527e-06 4.99169550e-02]\n",
      " [2.02769183e-06 8.44956557e-03]\n",
      " [2.20197015e-06 2.65732451e-03]\n",
      " [3.25637114e-06 1.11370321e-03]\n",
      " [4.06136569e-06 5.26335795e-04]\n",
      " [4.18983201e-06 2.53151991e-04]\n",
      " [3.75887043e-06 1.04165758e-04]\n",
      " [1.83446114e-06 4.30644116e-05]]\n",
      "Train Epoch5 out_loss 0.0004055681638419628\n",
      "Test Epoch5 layer0 out_loss 0.09755866229534149\n",
      "Test Epoch5 layer1 out_loss 0.003081629518419504\n",
      "Test Epoch5 layer2 out_loss 0.001382755464874208\n",
      "Test Epoch5 layer3 out_loss 0.0006161431083455682\n",
      "Test Epoch5 layer4 out_loss 0.0006044695037417114\n",
      "Test Epoch5 layer5 out_loss 0.0005558696575462818\n",
      "Test Epoch5 layer6 out_loss 0.0005099309491924942\n",
      "Test Epoch5 layer7 out_loss 0.0005206324276514351\n",
      "Test Epoch5 layer8 out_loss 0.0004117659409530461\n",
      "Train 6 | out_loss 0.0004103334795217961: 100%|█| 138/138 [00:01<00:00, 113.42it\n",
      "[[7.46527245e-06 9.90546221e-01]\n",
      " [1.11386509e-05 6.24170344e-02]\n",
      " [2.53529630e-06 8.18343399e-03]\n",
      " [3.73920528e-06 2.50380217e-03]\n",
      " [5.77813334e-06 1.05652145e-03]\n",
      " [8.25907484e-06 4.91012712e-04]\n",
      " [8.49897482e-06 2.64739938e-04]\n",
      " [7.77020899e-06 1.13354669e-04]\n",
      " [3.90218509e-06 4.78346703e-05]]\n",
      "Train Epoch6 out_loss 0.0004103334795217961\n",
      "Test Epoch6 layer0 out_loss 0.04343372583389282\n",
      "Test Epoch6 layer1 out_loss 0.002902909182012081\n",
      "Test Epoch6 layer2 out_loss 0.0010608067968860269\n",
      "Test Epoch6 layer3 out_loss 0.0006018410203978419\n",
      "Test Epoch6 layer4 out_loss 0.00048027391312643886\n",
      "Test Epoch6 layer5 out_loss 0.00045525559107773006\n",
      "Test Epoch6 layer6 out_loss 0.00047346571227535605\n",
      "Test Epoch6 layer7 out_loss 0.00044044540845789015\n",
      "Test Epoch6 layer8 out_loss 0.00041818711906671524\n",
      "Train 7 | out_loss 0.00040651203016750515: 100%|█| 138/138 [00:01<00:00, 113.52i\n",
      "[[7.37963769e-06 8.99899852e-01]\n",
      " [9.95614201e-06 3.09865147e-02]\n",
      " [2.61694689e-06 5.21394875e-03]\n",
      " [4.73230345e-06 1.60221077e-03]\n",
      " [8.73441604e-06 6.96839367e-04]\n",
      " [1.01995288e-05 3.53283407e-04]\n",
      " [1.15324932e-05 1.94190485e-04]\n",
      " [1.03883134e-05 8.81068200e-05]\n",
      " [5.50738220e-06 3.71297252e-05]]\n",
      "Train Epoch7 out_loss 0.00040651203016750515\n",
      "Test Epoch7 layer0 out_loss 0.025199810042977333\n",
      "Test Epoch7 layer1 out_loss 0.0023209673818200827\n",
      "Test Epoch7 layer2 out_loss 0.0009322942933067679\n",
      "Test Epoch7 layer3 out_loss 0.0005690352409146726\n",
      "Test Epoch7 layer4 out_loss 0.0005061805131845176\n",
      "Test Epoch7 layer5 out_loss 0.00046767486492171884\n",
      "Test Epoch7 layer6 out_loss 0.00045853055780753493\n",
      "Test Epoch7 layer7 out_loss 0.00044576270738616586\n",
      "Test Epoch7 layer8 out_loss 0.00041533709736540914\n",
      "Train 8 | out_loss 0.0004146313585806638: 100%|█| 138/138 [00:01<00:00, 117.85it\n",
      "[[7.36809880e-06 8.88400433e-01]\n",
      " [1.31426205e-05 2.95105099e-02]\n",
      " [3.13717508e-06 4.49366919e-03]\n",
      " [6.36093985e-06 1.39538076e-03]\n",
      " [1.20036361e-05 6.03413871e-04]\n",
      " [3.24163717e-05 3.10715285e-04]\n",
      " [3.63248102e-05 1.96743513e-04]\n",
      " [3.78606750e-05 1.03895607e-04]\n",
      " [2.08229547e-05 5.41855130e-05]]\n",
      "Train Epoch8 out_loss 0.0004146313585806638\n",
      "Test Epoch8 layer0 out_loss 0.024896057322621346\n",
      "Test Epoch8 layer1 out_loss 0.0019338279962539673\n",
      "Test Epoch8 layer2 out_loss 0.0007279254496097565\n",
      "Test Epoch8 layer3 out_loss 0.0005397428176365793\n",
      "Test Epoch8 layer4 out_loss 0.0004596868238877505\n",
      "Test Epoch8 layer5 out_loss 0.0004586329741869122\n",
      "Test Epoch8 layer6 out_loss 0.000495606567710638\n",
      "Test Epoch8 layer7 out_loss 0.00044724889448843896\n",
      "Test Epoch8 layer8 out_loss 0.00045159232104197145\n",
      "Train 9 | out_loss 0.000421012140577659: 100%|█| 138/138 [00:01<00:00, 118.82it/\n",
      "[[7.38797600e-06 1.26664960e+00]\n",
      " [8.42280673e-06 3.60490083e-02]\n",
      " [3.43323503e-06 5.01254068e-03]\n",
      " [8.00747156e-06 1.54075235e-03]\n",
      " [1.65356627e-05 6.72058318e-04]\n",
      " [2.97963175e-05 3.53253670e-04]\n",
      " [3.06774236e-05 2.28541155e-04]\n",
      " [2.94510869e-05 1.18187998e-04]\n",
      " [1.50332994e-05 5.47360134e-05]]\n",
      "Train Epoch9 out_loss 0.000421012140577659\n",
      "Test Epoch9 layer0 out_loss 0.018805313855409622\n",
      "Test Epoch9 layer1 out_loss 0.00268915225751698\n",
      "Test Epoch9 layer2 out_loss 0.0009560610633343458\n",
      "Test Epoch9 layer3 out_loss 0.0005437659565359354\n",
      "Test Epoch9 layer4 out_loss 0.0005112169310450554\n",
      "Test Epoch9 layer5 out_loss 0.0004913393640890718\n",
      "Test Epoch9 layer6 out_loss 0.000590226671192795\n",
      "Test Epoch9 layer7 out_loss 0.0005332460859790444\n",
      "Test Epoch9 layer8 out_loss 0.00046199007192626595\n",
      "Train 10 | out_loss 0.0004145668353885412: 100%|█| 138/138 [00:01<00:00, 117.45i\n",
      "[[7.11352450e-06 6.36652518e-01]\n",
      " [1.09972848e-05 1.66724949e-02]\n",
      " [3.45202829e-06 3.12114789e-03]\n",
      " [6.26873638e-06 9.99158405e-04]\n",
      " [1.43463610e-05 4.62934478e-04]\n",
      " [2.45756238e-05 2.47428765e-04]\n",
      " [2.76486768e-05 1.65165164e-04]\n",
      " [2.73092890e-05 8.48616145e-05]\n",
      " [1.41903025e-05 4.08492395e-05]]\n",
      "Train Epoch10 out_loss 0.0004145668353885412\n",
      "Test Epoch10 layer0 out_loss 0.02106352150440216\n",
      "Test Epoch10 layer1 out_loss 0.0022353525273501873\n",
      "Test Epoch10 layer2 out_loss 0.0008126436732709408\n",
      "Test Epoch10 layer3 out_loss 0.0004948723944835365\n",
      "Test Epoch10 layer4 out_loss 0.0004373301344458014\n",
      "Test Epoch10 layer5 out_loss 0.00047007211833260953\n",
      "Test Epoch10 layer6 out_loss 0.0004455852904357016\n",
      "Test Epoch10 layer7 out_loss 0.0004510596627369523\n",
      "Test Epoch10 layer8 out_loss 0.0004156827344559133\n",
      "Train 11 | out_loss 0.00040998696931637824: 100%|█| 138/138 [00:01<00:00, 111.25\n",
      "[[6.94698169e-06 5.74264862e-01]\n",
      " [1.08352233e-05 1.26507441e-02]\n",
      " [3.63208822e-06 2.46058919e-03]\n",
      " [8.17314495e-06 8.11537755e-04]\n",
      " [2.10282232e-05 3.59552251e-04]\n",
      " [3.44425245e-05 2.02750024e-04]\n",
      " [3.75256653e-05 1.37702559e-04]\n",
      " [3.66634497e-05 7.55891565e-05]\n",
      " [1.88715024e-05 3.85000699e-05]]\n",
      "Train Epoch11 out_loss 0.00040998696931637824\n",
      "Test Epoch11 layer0 out_loss 0.010481739416718483\n",
      "Test Epoch11 layer1 out_loss 0.0017118885880336165\n",
      "Test Epoch11 layer2 out_loss 0.0009108898229897022\n",
      "Test Epoch11 layer3 out_loss 0.00047280811122618616\n",
      "Test Epoch11 layer4 out_loss 0.0004895811434835196\n",
      "Test Epoch11 layer5 out_loss 0.0004891049466095865\n",
      "Test Epoch11 layer6 out_loss 0.0004353058757260442\n",
      "Test Epoch11 layer7 out_loss 0.00042499531991779804\n",
      "Test Epoch11 layer8 out_loss 0.0004149892192799598\n",
      "Train 12 | out_loss 0.0004146287974435836: 100%|█| 138/138 [00:01<00:00, 116.37i\n",
      "[[6.83419545e-06 8.95511031e-01]\n",
      " [1.16901692e-05 8.83593936e-03]\n",
      " [4.06720915e-06 2.05134445e-03]\n",
      " [9.35747511e-06 7.82424230e-04]\n",
      " [2.30379475e-05 4.04476063e-04]\n",
      " [4.98428695e-05 2.33363432e-04]\n",
      " [6.92685043e-05 1.69982686e-04]\n",
      " [6.88763886e-05 1.10710895e-04]\n",
      " [4.12209655e-05 6.84459059e-05]]\n",
      "Train Epoch12 out_loss 0.0004146287974435836\n",
      "Test Epoch12 layer0 out_loss 0.042459048330783844\n",
      "Test Epoch12 layer1 out_loss 0.0017340016784146428\n",
      "Test Epoch12 layer2 out_loss 0.0007121610105969012\n",
      "Test Epoch12 layer3 out_loss 0.0004722023440990597\n",
      "Test Epoch12 layer4 out_loss 0.0005152194644324481\n",
      "Test Epoch12 layer5 out_loss 0.0004495520261116326\n",
      "Test Epoch12 layer6 out_loss 0.00042468347237445414\n",
      "Test Epoch12 layer7 out_loss 0.0004171020700596273\n",
      "Test Epoch12 layer8 out_loss 0.000416705064708367\n",
      "Train 13 | out_loss 0.0004241377755533904: 100%|█| 138/138 [00:01<00:00, 119.99i\n",
      "[[6.78302975e-06 8.97765966e-01]\n",
      " [1.52366516e-05 9.35486959e-03]\n",
      " [6.02445957e-06 2.06439656e-03]\n",
      " [1.70972057e-05 7.77843672e-04]\n",
      " [3.76537764e-05 3.72724599e-04]\n",
      " [5.12633202e-05 2.11945549e-04]\n",
      " [7.68467632e-05 1.73761884e-04]\n",
      " [6.86533935e-05 1.19185128e-04]\n",
      " [4.14456669e-05 6.85296452e-05]]\n",
      "Train Epoch13 out_loss 0.0004241377755533904\n",
      "Test Epoch13 layer0 out_loss 0.0237968061119318\n",
      "Test Epoch13 layer1 out_loss 0.0013324362225830555\n",
      "Test Epoch13 layer2 out_loss 0.0005880831158719957\n",
      "Test Epoch13 layer3 out_loss 0.0004420188197400421\n",
      "Test Epoch13 layer4 out_loss 0.0004701465368270874\n",
      "Test Epoch13 layer5 out_loss 0.0006187086110003293\n",
      "Test Epoch13 layer6 out_loss 0.0005272894049994648\n",
      "Test Epoch13 layer7 out_loss 0.00045032898196950555\n",
      "Test Epoch13 layer8 out_loss 0.0005222997860983014\n",
      "Train 14 | out_loss 0.00041859244811348617: 100%|█| 138/138 [00:01<00:00, 112.46\n",
      "[[6.44363032e-06 2.06004287e-01]\n",
      " [1.54997515e-05 3.66676161e-03]\n",
      " [7.31588543e-06 1.04964976e-03]\n",
      " [2.13402129e-05 4.33470505e-04]\n",
      " [2.62086849e-05 2.24954757e-04]\n",
      " [4.96722933e-05 1.40939298e-04]\n",
      " [6.18297996e-05 1.15028622e-04]\n",
      " [5.84835368e-05 8.21978854e-05]\n",
      " [3.44069129e-05 5.00659355e-05]]\n",
      "Train Epoch14 out_loss 0.00041859244811348617\n",
      "Test Epoch14 layer0 out_loss 0.006160823628306389\n",
      "Test Epoch14 layer1 out_loss 0.001066574128344655\n",
      "Test Epoch14 layer2 out_loss 0.0005615547997877002\n",
      "Test Epoch14 layer3 out_loss 0.0004717032134067267\n",
      "Test Epoch14 layer4 out_loss 0.0005046423757448792\n",
      "Test Epoch14 layer5 out_loss 0.0004392791597638279\n",
      "Test Epoch14 layer6 out_loss 0.00043390897917561233\n",
      "Test Epoch14 layer7 out_loss 0.0004158498777542263\n",
      "Test Epoch14 layer8 out_loss 0.00041527385474182665\n",
      "Train 15 | out_loss 0.00042064659646712244: 100%|█| 138/138 [00:01<00:00, 117.27\n",
      "[[6.46563444e-06 1.83627064e-01]\n",
      " [2.07204749e-05 3.38303066e-03]\n",
      " [2.47572479e-04 9.80450713e-04]\n",
      " [8.80042066e-04 8.41083967e-04]\n",
      " [4.40384216e-04 6.82391047e-04]\n",
      " [6.33719709e-04 3.72915069e-04]\n",
      " [6.86336592e-04 3.91238714e-04]\n",
      " [3.82844151e-04 3.13043396e-04]\n",
      " [2.16229720e-04 2.09003527e-04]]\n",
      "Train Epoch15 out_loss 0.00042064659646712244\n",
      "Test Epoch15 layer0 out_loss 0.02990764193236828\n",
      "Test Epoch15 layer1 out_loss 0.0011696614092215896\n",
      "Test Epoch15 layer2 out_loss 0.0007483050576411188\n",
      "Test Epoch15 layer3 out_loss 0.000517841603141278\n",
      "Test Epoch15 layer4 out_loss 0.0004406666266731918\n",
      "Test Epoch15 layer5 out_loss 0.0005150813376531005\n",
      "Test Epoch15 layer6 out_loss 0.0005860862438566983\n",
      "Test Epoch15 layer7 out_loss 0.0005147687625139952\n",
      "Test Epoch15 layer8 out_loss 0.0005589078646153212\n",
      "Train 16 | out_loss 0.0004432307032402605: 100%|█| 138/138 [00:01<00:00, 118.41i\n",
      "[[6.83205885e-06 1.11356542e+00]\n",
      " [2.11023235e-05 5.70818586e-03]\n",
      " [1.98959879e-04 1.43546945e-03]\n",
      " [5.31494720e-04 9.16677368e-04]\n",
      " [2.89387464e-04 6.22386391e-04]\n",
      " [4.47673264e-04 3.50315158e-04]\n",
      " [3.94577275e-04 3.60978477e-04]\n",
      " [2.62892841e-04 2.56270196e-04]\n",
      " [1.34892704e-04 1.59920707e-04]]\n",
      "Train Epoch16 out_loss 0.0004432307032402605\n",
      "Test Epoch16 layer0 out_loss 0.029503997415304184\n",
      "Test Epoch16 layer1 out_loss 0.0013522566296160221\n",
      "Test Epoch16 layer2 out_loss 0.0007345969206653535\n",
      "Test Epoch16 layer3 out_loss 0.0005055628716945648\n",
      "Test Epoch16 layer4 out_loss 0.0008026493014767766\n",
      "Test Epoch16 layer5 out_loss 0.0006883777095936239\n",
      "Test Epoch16 layer6 out_loss 0.0004514861502684653\n",
      "Test Epoch16 layer7 out_loss 0.00041658198460936546\n",
      "Test Epoch16 layer8 out_loss 0.0004528268182184547\n",
      "Train 17 | out_loss 0.00044146954314783216: 100%|█| 138/138 [00:01<00:00, 118.01\n",
      "[[6.38626291e-06 9.02888094e-01]\n",
      " [2.76791782e-05 4.53712872e-03]\n",
      " [3.99845509e-04 1.26585761e-03]\n",
      " [8.52722837e-04 1.01228382e-03]\n",
      " [4.31265579e-04 7.83390029e-04]\n",
      " [5.76165552e-04 4.21784804e-04]\n",
      " [4.73175422e-04 3.61997999e-04]\n",
      " [2.74857982e-04 2.59772010e-04]\n",
      " [1.41382903e-04 1.56182789e-04]]\n",
      "Train Epoch17 out_loss 0.00044146954314783216\n",
      "Test Epoch17 layer0 out_loss 0.01368650607764721\n",
      "Test Epoch17 layer1 out_loss 0.0009734926279634237\n",
      "Test Epoch17 layer2 out_loss 0.000499721325468272\n",
      "Test Epoch17 layer3 out_loss 0.0004426749364938587\n",
      "Test Epoch17 layer4 out_loss 0.00048770735156722367\n",
      "Test Epoch17 layer5 out_loss 0.0005083848955109715\n",
      "Test Epoch17 layer6 out_loss 0.00043647942948155105\n",
      "Test Epoch17 layer7 out_loss 0.0004398691526148468\n",
      "Test Epoch17 layer8 out_loss 0.0004333295801188797\n",
      "Train 18 | out_loss 0.0004384032799862325: 100%|█| 138/138 [00:01<00:00, 120.52i\n",
      "[[5.89000475e-06 1.77893315e-01]\n",
      " [2.89846061e-05 2.23792066e-03]\n",
      " [2.74067431e-04 6.92268876e-04]\n",
      " [4.68549935e-04 5.97488592e-04]\n",
      " [2.38560034e-04 4.39961744e-04]\n",
      " [3.25074104e-04 2.53595008e-04]\n",
      " [2.56341601e-04 2.45274785e-04]\n",
      " [1.73430069e-04 1.85925210e-04]\n",
      " [9.27283037e-05 1.15325697e-04]]\n",
      "Train Epoch18 out_loss 0.0004384032799862325\n",
      "Test Epoch18 layer0 out_loss 0.013310558162629604\n",
      "Test Epoch18 layer1 out_loss 0.0009491420350968838\n",
      "Test Epoch18 layer2 out_loss 0.0004825207288376987\n",
      "Test Epoch18 layer3 out_loss 0.0004236110835336149\n",
      "Test Epoch18 layer4 out_loss 0.00047348556108772755\n",
      "Test Epoch18 layer5 out_loss 0.00042723456863313913\n",
      "Test Epoch18 layer6 out_loss 0.0004163502890150994\n",
      "Test Epoch18 layer7 out_loss 0.00043774189543910325\n",
      "Test Epoch18 layer8 out_loss 0.00041606739978305995\n",
      "Train 19 | out_loss 0.0004381934995763004: 100%|█| 138/138 [00:01<00:00, 117.44i\n",
      "[[5.78136124e-06 6.20845914e-02]\n",
      " [4.55038275e-05 1.88938961e-03]\n",
      " [4.40782869e-04 7.00115211e-04]\n",
      " [6.40933327e-04 7.37168614e-04]\n",
      " [4.37986999e-04 5.86365717e-04]\n",
      " [4.91110195e-04 3.80461544e-04]\n",
      " [4.14116915e-04 3.47452391e-04]\n",
      " [2.75666438e-04 2.70860067e-04]\n",
      " [1.35996562e-04 1.65700919e-04]]\n",
      "Train Epoch19 out_loss 0.0004381934995763004\n",
      "Test Epoch19 layer0 out_loss 0.01891445554792881\n",
      "Test Epoch19 layer1 out_loss 0.0009462528978474438\n",
      "Test Epoch19 layer2 out_loss 0.0006181460921652615\n",
      "Test Epoch19 layer3 out_loss 0.0006628691335208714\n",
      "Test Epoch19 layer4 out_loss 0.0009466967894695699\n",
      "Test Epoch19 layer5 out_loss 0.0008225292549468577\n",
      "Test Epoch19 layer6 out_loss 0.0006465433980338275\n",
      "Test Epoch19 layer7 out_loss 0.0004919522325508296\n",
      "Test Epoch19 layer8 out_loss 0.0007153126061894\n",
      "Train 20 | out_loss 0.00044426656677387655: 100%|█| 138/138 [00:01<00:00, 123.24\n",
      "[[5.57640175e-06 6.11575658e-01]\n",
      " [4.29315031e-05 3.22758817e-03]\n",
      " [3.55797715e-04 9.39338322e-04]\n",
      " [4.27639345e-04 7.08745041e-04]\n",
      " [3.22779519e-04 4.90830261e-04]\n",
      " [3.98150043e-04 3.60735714e-04]\n",
      " [2.98119128e-04 3.17921696e-04]\n",
      " [2.19621062e-04 2.23629302e-04]\n",
      " [9.93792281e-05 1.24006988e-04]]\n",
      "Train Epoch20 out_loss 0.00044426656677387655\n",
      "Test Epoch20 layer0 out_loss 0.02526303008198738\n",
      "Test Epoch20 layer1 out_loss 0.0009789082687348127\n",
      "Test Epoch20 layer2 out_loss 0.0007161592948250473\n",
      "Test Epoch20 layer3 out_loss 0.0007276001269929111\n",
      "Test Epoch20 layer4 out_loss 0.0008419871446676552\n",
      "Test Epoch20 layer5 out_loss 0.0008332640281878412\n",
      "Test Epoch20 layer6 out_loss 0.0006006256444379687\n",
      "Test Epoch20 layer7 out_loss 0.00048199036973528564\n",
      "Test Epoch20 layer8 out_loss 0.00048778008203953505\n",
      "Train 21 | out_loss 0.0005228349473327398: 100%|█| 138/138 [00:01<00:00, 119.61i\n",
      "[[5.57346273e-06 5.41229861e-01]\n",
      " [9.66334951e-05 2.84578857e-03]\n",
      " [8.27225346e-04 1.12355236e-03]\n",
      " [6.78028292e-04 1.01414497e-03]\n",
      " [5.72642228e-04 6.74058728e-04]\n",
      " [6.26542007e-04 4.24181540e-04]\n",
      " [3.63573731e-04 3.75576110e-04]\n",
      " [2.45848872e-04 2.50713881e-04]\n",
      " [1.30551144e-04 1.56181958e-04]]\n",
      "Train Epoch21 out_loss 0.0005228349473327398\n",
      "Test Epoch21 layer0 out_loss 0.02531307376921177\n",
      "Test Epoch21 layer1 out_loss 0.0015020581195130944\n",
      "Test Epoch21 layer2 out_loss 0.0006697113276459277\n",
      "Test Epoch21 layer3 out_loss 0.0005468343733809888\n",
      "Test Epoch21 layer4 out_loss 0.0004974870826117694\n",
      "Test Epoch21 layer5 out_loss 0.0004945301916450262\n",
      "Test Epoch21 layer6 out_loss 0.0005125860334374011\n",
      "Test Epoch21 layer7 out_loss 0.0005596365081146359\n",
      "Test Epoch21 layer8 out_loss 0.000538029067683965\n",
      "Train 22 | out_loss 0.0005034856148995459: 100%|█| 138/138 [00:01<00:00, 116.75i\n",
      "[[5.68516002e-06 2.27599927e-01]\n",
      " [1.64467909e-04 1.69113713e-03]\n",
      " [6.24798011e-04 7.70168031e-04]\n",
      " [3.18669185e-04 5.72074094e-04]\n",
      " [5.81622180e-04 3.46530398e-04]\n",
      " [5.15278330e-04 3.52078643e-04]\n",
      " [3.14051623e-04 3.21033940e-04]\n",
      " [2.21449090e-04 2.31833229e-04]\n",
      " [1.24507663e-04 1.63729440e-04]]\n",
      "Train Epoch22 out_loss 0.0005034856148995459\n",
      "Test Epoch22 layer0 out_loss 0.016010664403438568\n",
      "Test Epoch22 layer1 out_loss 0.0008876649080775678\n",
      "Test Epoch22 layer2 out_loss 0.00045932421926409006\n",
      "Test Epoch22 layer3 out_loss 0.0005669420352205634\n",
      "Test Epoch22 layer4 out_loss 0.000437890732428059\n",
      "Test Epoch22 layer5 out_loss 0.0004585078277159482\n",
      "Test Epoch22 layer6 out_loss 0.0004451857239473611\n",
      "Test Epoch22 layer7 out_loss 0.0004573033656924963\n",
      "Test Epoch22 layer8 out_loss 0.00043113090214319527\n",
      "Train 23 | out_loss 0.0005310710985213518: 100%|█| 138/138 [00:01<00:00, 119.37i\n",
      "[[4.87045241e-06 9.47154453e-02]\n",
      " [3.84608525e-04 1.63964202e-03]\n",
      " [1.09751931e-03 9.85921319e-04]\n",
      " [6.18776759e-04 8.06550926e-04]\n",
      " [8.07941830e-04 5.54661393e-04]\n",
      " [5.87055669e-04 4.64961507e-04]\n",
      " [3.83249051e-04 3.64814544e-04]\n",
      " [2.42011000e-04 2.41834199e-04]\n",
      " [1.24025885e-04 1.48516058e-04]]\n",
      "Train Epoch23 out_loss 0.0005310710985213518\n",
      "Test Epoch23 layer0 out_loss 0.01795731671154499\n",
      "Test Epoch23 layer1 out_loss 0.0009189257398247719\n",
      "Test Epoch23 layer2 out_loss 0.0007963803363963962\n",
      "Test Epoch23 layer3 out_loss 0.0004326194175519049\n",
      "Test Epoch23 layer4 out_loss 0.0007143237162381411\n",
      "Test Epoch23 layer5 out_loss 0.0007606869330629706\n",
      "Test Epoch23 layer6 out_loss 0.00042373762698844075\n",
      "Test Epoch23 layer7 out_loss 0.00042801391100510955\n",
      "Test Epoch23 layer8 out_loss 0.0004511282895691693\n",
      "Train 24 | out_loss 0.0005062593263573945: 100%|█| 138/138 [00:01<00:00, 126.66i\n",
      "[[5.93270002e-06 6.13264896e-01]\n",
      " [1.53865265e-04 3.80160746e-03]\n",
      " [2.61775105e-04 1.56573546e-03]\n",
      " [4.00842922e-04 8.70031379e-04]\n",
      " [7.04500618e-04 9.21556237e-04]\n",
      " [4.99875727e-04 8.15980180e-04]\n",
      " [4.06547414e-04 5.63288376e-04]\n",
      " [2.61515506e-04 3.28173305e-04]\n",
      " [1.39564997e-04 1.81250382e-04]]\n",
      "Train Epoch24 out_loss 0.0005062593263573945\n",
      "Test Epoch24 layer0 out_loss 0.01801222190260887\n",
      "Test Epoch24 layer1 out_loss 0.0009345508879050612\n",
      "Test Epoch24 layer2 out_loss 0.0005919592222198844\n",
      "Test Epoch24 layer3 out_loss 0.0004358354490250349\n",
      "Test Epoch24 layer4 out_loss 0.0005547393811866641\n",
      "Test Epoch24 layer5 out_loss 0.0005828269058838487\n",
      "Test Epoch24 layer6 out_loss 0.0005042531411163509\n",
      "Test Epoch24 layer7 out_loss 0.0005714164581149817\n",
      "Test Epoch24 layer8 out_loss 0.00043107219971716404\n",
      "Train 25 | out_loss 0.0005603555473499: 100%|█| 138/138 [00:01<00:00, 126.33it/s\n",
      "[[5.81122663e-06 1.90194300e-01]\n",
      " [3.51128971e-04 1.65130120e-03]\n",
      " [7.34095889e-04 8.72943279e-04]\n",
      " [5.44233521e-04 7.22749265e-04]\n",
      " [6.99107923e-04 6.48045063e-04]\n",
      " [4.87922976e-04 5.77101721e-04]\n",
      " [3.38150576e-04 4.14140549e-04]\n",
      " [2.19632595e-04 2.49960832e-04]\n",
      " [1.46722167e-04 1.81403560e-04]]\n",
      "Train Epoch25 out_loss 0.0005603555473499\n",
      "Test Epoch25 layer0 out_loss 0.015906764194369316\n",
      "Test Epoch25 layer1 out_loss 0.000932471826672554\n",
      "Test Epoch25 layer2 out_loss 0.0008174180402420461\n",
      "Test Epoch25 layer3 out_loss 0.0005083144642412663\n",
      "Test Epoch25 layer4 out_loss 0.0005360131617635489\n",
      "Test Epoch25 layer5 out_loss 0.0005927154561504722\n",
      "Test Epoch25 layer6 out_loss 0.0008287816308438778\n",
      "Test Epoch25 layer7 out_loss 0.00096742162713781\n",
      "Test Epoch25 layer8 out_loss 0.0005567350890487432\n",
      "Train 26 | out_loss 0.0005926855956204236: 100%|█| 138/138 [00:01<00:00, 122.94i\n",
      "[[5.13672094e-06 8.08491788e-02]\n",
      " [5.13305538e-04 1.39204622e-03]\n",
      " [8.85643101e-04 8.56312395e-04]\n",
      " [8.79504580e-04 8.25981400e-04]\n",
      " [7.50529283e-04 8.78992615e-04]\n",
      " [5.33124887e-04 6.79571583e-04]\n",
      " [4.20766033e-04 4.79218248e-04]\n",
      " [2.50308778e-04 2.83758633e-04]\n",
      " [1.32588687e-04 1.64487923e-04]]\n",
      "Train Epoch26 out_loss 0.0005926855956204236\n",
      "Test Epoch26 layer0 out_loss 0.010580996982753277\n",
      "Test Epoch26 layer1 out_loss 0.0007608971791341901\n",
      "Test Epoch26 layer2 out_loss 0.000563965120818466\n",
      "Test Epoch26 layer3 out_loss 0.0006577406893484294\n",
      "Test Epoch26 layer4 out_loss 0.0007039654301479459\n",
      "Test Epoch26 layer5 out_loss 0.0005603223107755184\n",
      "Test Epoch26 layer6 out_loss 0.0006012741359882057\n",
      "Test Epoch26 layer7 out_loss 0.0004396348667796701\n",
      "Test Epoch26 layer8 out_loss 0.00045900954864919186\n",
      "Train 27 | out_loss 0.0005030175088904798: 100%|█| 138/138 [00:01<00:00, 127.96i\n",
      "[[4.47760664e-06 2.79337056e-01]\n",
      " [2.19684498e-04 2.24010992e-03]\n",
      " [3.63887624e-04 9.26584717e-04]\n",
      " [2.91000992e-04 6.56958395e-04]\n",
      " [2.56775381e-04 4.49657595e-04]\n",
      " [2.07466137e-04 3.05377331e-04]\n",
      " [1.73065265e-04 2.78260130e-04]\n",
      " [1.35500850e-04 1.80942636e-04]\n",
      " [1.05449397e-04 1.33952242e-04]]\n",
      "Train Epoch27 out_loss 0.0005030175088904798\n",
      "Test Epoch27 layer0 out_loss 0.03100559674203396\n",
      "Test Epoch27 layer1 out_loss 0.000851667020469904\n",
      "Test Epoch27 layer2 out_loss 0.0004249116173014045\n",
      "Test Epoch27 layer3 out_loss 0.00040636889752931893\n",
      "Test Epoch27 layer4 out_loss 0.0004627353046089411\n",
      "Test Epoch27 layer5 out_loss 0.0005154538666829467\n",
      "Test Epoch27 layer6 out_loss 0.0005428984295576811\n",
      "Test Epoch27 layer7 out_loss 0.0004717693664133549\n",
      "Test Epoch27 layer8 out_loss 0.0005468616727739573\n",
      "Train 28 | out_loss 0.0005337727488949895: 100%|█| 138/138 [00:01<00:00, 125.77i\n",
      "[[5.30324254e-06 2.77910820e-01]\n",
      " [4.76222447e-04 1.94460450e-03]\n",
      " [1.02644853e-03 1.24637627e-03]\n",
      " [9.95459243e-04 1.34535935e-03]\n",
      " [6.58682369e-04 1.08811787e-03]\n",
      " [4.96484568e-04 6.49569800e-04]\n",
      " [3.42434610e-04 4.56885504e-04]\n",
      " [2.56507463e-04 2.79941334e-04]\n",
      " [1.63022291e-04 2.00345824e-04]]\n",
      "Train Epoch28 out_loss 0.0005337727488949895\n",
      "Test Epoch28 layer0 out_loss 0.010969074442982674\n",
      "Test Epoch28 layer1 out_loss 0.000754227046854794\n",
      "Test Epoch28 layer2 out_loss 0.0005931815248914063\n",
      "Test Epoch28 layer3 out_loss 0.0004107396234758198\n",
      "Test Epoch28 layer4 out_loss 0.00044111587340012193\n",
      "Test Epoch28 layer5 out_loss 0.0008843443356454372\n",
      "Test Epoch28 layer6 out_loss 0.001233449438586831\n",
      "Test Epoch28 layer7 out_loss 0.0008550399797968566\n",
      "Test Epoch28 layer8 out_loss 0.0010280375136062503\n",
      "Train 29 | out_loss 0.0005620549782179296: 100%|█| 138/138 [00:01<00:00, 124.98i\n",
      "[[5.61552301e-06 1.57825217e-01]\n",
      " [4.39689324e-04 1.87157032e-03]\n",
      " [6.48737640e-04 9.76229110e-04]\n",
      " [5.57755357e-04 8.62956422e-04]\n",
      " [4.60890061e-04 5.89783704e-04]\n",
      " [8.82624334e-04 8.32207115e-04]\n",
      " [6.26382452e-04 9.01016418e-04]\n",
      " [4.89938647e-04 5.58660766e-04]\n",
      " [2.70226388e-04 3.60733831e-04]]\n",
      "Train Epoch29 out_loss 0.0005620549782179296\n",
      "Test Epoch29 layer0 out_loss 0.013423046097159386\n",
      "Test Epoch29 layer1 out_loss 0.0009710541344247758\n",
      "Test Epoch29 layer2 out_loss 0.0004269128548912704\n",
      "Test Epoch29 layer3 out_loss 0.00041358175803907216\n",
      "Test Epoch29 layer4 out_loss 0.0004600306856445968\n",
      "Test Epoch29 layer5 out_loss 0.0005480227409861982\n",
      "Test Epoch29 layer6 out_loss 0.00042160021257586777\n",
      "Test Epoch29 layer7 out_loss 0.0005291800480335951\n",
      "Test Epoch29 layer8 out_loss 0.0005425099516287446\n",
      "Train 30 | out_loss 0.0005558137781918049: 100%|█| 138/138 [00:01<00:00, 124.97i\n",
      "[[5.04262252e-06 6.99201209e-02]\n",
      " [5.08925568e-04 1.31164224e-03]\n",
      " [6.88755037e-04 8.11890454e-04]\n",
      " [4.85749877e-04 7.17409204e-04]\n",
      " [4.71789042e-04 5.57089547e-04]\n",
      " [6.47521156e-04 5.92082839e-04]\n",
      " [4.02219733e-04 6.28554190e-04]\n",
      " [2.68380508e-04 3.42988144e-04]\n",
      " [1.52962599e-04 2.04053661e-04]]\n",
      "Train Epoch30 out_loss 0.0005558137781918049\n",
      "Test Epoch30 layer0 out_loss 0.02400466427206993\n",
      "Test Epoch30 layer1 out_loss 0.0007434788276441395\n",
      "Test Epoch30 layer2 out_loss 0.0005290378467179835\n",
      "Test Epoch30 layer3 out_loss 0.00042783020762726665\n",
      "Test Epoch30 layer4 out_loss 0.00047496636398136616\n",
      "Test Epoch30 layer5 out_loss 0.00042482875869609416\n",
      "Test Epoch30 layer6 out_loss 0.0004278098640497774\n",
      "Test Epoch30 layer7 out_loss 0.00041904428508132696\n",
      "Test Epoch30 layer8 out_loss 0.0004332578682806343\n",
      "Train 31 | out_loss 0.0005162769230082631: 100%|█| 138/138 [00:01<00:00, 125.62i\n",
      "[[3.97291184e-06 6.66830707e-01]\n",
      " [5.24592716e-04 4.94443049e-03]\n",
      " [7.03208417e-04 1.93901435e-03]\n",
      " [4.29573897e-04 1.18374691e-03]\n",
      " [3.01429403e-04 5.68350110e-04]\n",
      " [2.59791238e-04 2.93945907e-04]\n",
      " [1.62869486e-04 2.68880359e-04]\n",
      " [1.41050508e-04 1.91077617e-04]\n",
      " [1.18899883e-04 1.71954537e-04]]\n",
      "Train Epoch31 out_loss 0.0005162769230082631\n",
      "Test Epoch31 layer0 out_loss 0.0730399340391159\n",
      "Test Epoch31 layer1 out_loss 0.0018764722626656294\n",
      "Test Epoch31 layer2 out_loss 0.0006748068262822926\n",
      "Test Epoch31 layer3 out_loss 0.0004375572025310248\n",
      "Test Epoch31 layer4 out_loss 0.00043528329115360975\n",
      "Test Epoch31 layer5 out_loss 0.00043054859270341694\n",
      "Test Epoch31 layer6 out_loss 0.00043678696965798736\n",
      "Test Epoch31 layer7 out_loss 0.00041842719656415284\n",
      "Test Epoch31 layer8 out_loss 0.00042927739559672773\n",
      "Train 32 | out_loss 0.0004946058033965528: 100%|█| 138/138 [00:01<00:00, 123.10i\n",
      "[[3.90882354e-06 2.27550265e-01]\n",
      " [5.70886819e-04 2.27315094e-03]\n",
      " [9.70186564e-04 1.19543996e-03]\n",
      " [6.62051196e-04 1.04186576e-03]\n",
      " [3.75458621e-04 5.59500632e-04]\n",
      " [2.94360849e-04 2.95077413e-04]\n",
      " [1.60257802e-04 2.20397153e-04]\n",
      " [1.28610027e-04 1.43899530e-04]\n",
      " [8.69222052e-05 1.18114045e-04]]\n",
      "Train Epoch32 out_loss 0.0004946058033965528\n",
      "Test Epoch32 layer0 out_loss 0.009757939726114273\n",
      "Test Epoch32 layer1 out_loss 0.0007069968269206583\n",
      "Test Epoch32 layer2 out_loss 0.0005935712833888829\n",
      "Test Epoch32 layer3 out_loss 0.0008000343805179\n",
      "Test Epoch32 layer4 out_loss 0.0004771019157487899\n",
      "Test Epoch32 layer5 out_loss 0.00042198540177196264\n",
      "Test Epoch32 layer6 out_loss 0.0005654247361235321\n",
      "Test Epoch32 layer7 out_loss 0.00047932929010130465\n",
      "Test Epoch32 layer8 out_loss 0.00044416423770599067\n",
      "Train 33 | out_loss 0.0005486675654537976: 100%|█| 138/138 [00:01<00:00, 128.31i\n",
      "[[5.09562350e-06 1.05912112e-01]\n",
      " [9.11956308e-04 1.63441011e-03]\n",
      " [1.00165470e-03 1.18766062e-03]\n",
      " [6.08088710e-04 7.00223888e-04]\n",
      " [3.55649868e-04 4.02458137e-04]\n",
      " [2.23728951e-04 2.32515812e-04]\n",
      " [1.26871070e-04 1.67389966e-04]\n",
      " [1.26075535e-04 1.27205746e-04]\n",
      " [8.55564611e-05 1.07047746e-04]]\n",
      "Train Epoch33 out_loss 0.0005486675654537976\n",
      "Test Epoch33 layer0 out_loss 0.0056459843181073666\n",
      "Test Epoch33 layer1 out_loss 0.0008556083193980157\n",
      "Test Epoch33 layer2 out_loss 0.0004648993199225515\n",
      "Test Epoch33 layer3 out_loss 0.000443491357145831\n",
      "Test Epoch33 layer4 out_loss 0.0004538286302704364\n",
      "Test Epoch33 layer5 out_loss 0.000426094833528623\n",
      "Test Epoch33 layer6 out_loss 0.0005187674541957676\n",
      "Test Epoch33 layer7 out_loss 0.000644342799205333\n",
      "Test Epoch33 layer8 out_loss 0.0005919162067584693\n",
      "Train 34 | out_loss 0.0005685084033757448: 100%|█| 138/138 [00:01<00:00, 129.01i\n",
      "[[7.12658976e-06 1.30133366e-01]\n",
      " [2.77542125e-04 1.19631861e-03]\n",
      " [4.14091838e-04 6.58552347e-04]\n",
      " [3.59815202e-04 7.44526992e-04]\n",
      " [2.76530457e-04 5.04798900e-04]\n",
      " [2.63019515e-04 3.18279463e-04]\n",
      " [1.80593024e-04 2.69919782e-04]\n",
      " [1.85973145e-04 2.68920812e-04]\n",
      " [1.83630775e-04 2.82399740e-04]]\n",
      "Train Epoch34 out_loss 0.0005685084033757448\n",
      "Test Epoch34 layer0 out_loss 0.05185927823185921\n",
      "Test Epoch34 layer1 out_loss 0.0009184314403682947\n",
      "Test Epoch34 layer2 out_loss 0.0006657385965809226\n",
      "Test Epoch34 layer3 out_loss 0.00044655249803327024\n",
      "Test Epoch34 layer4 out_loss 0.0005247052758932114\n",
      "Test Epoch34 layer5 out_loss 0.0004181633412372321\n",
      "Test Epoch34 layer6 out_loss 0.00044994489871896803\n",
      "Test Epoch34 layer7 out_loss 0.00046701100654900074\n",
      "Test Epoch34 layer8 out_loss 0.0005289961118251085\n",
      "Train 35 | out_loss 0.0005539017147384584: 100%|█| 138/138 [00:01<00:00, 128.36i\n",
      "[[1.23355022e-05 3.78996714e-01]\n",
      " [4.57863484e-04 3.15478168e-03]\n",
      " [7.02905923e-04 1.11574100e-03]\n",
      " [5.47812110e-04 1.26398793e-03]\n",
      " [4.14210742e-04 7.17988682e-04]\n",
      " [3.25664837e-04 3.51328726e-04]\n",
      " [1.83621077e-04 2.14931189e-04]\n",
      " [1.20529871e-04 1.28038000e-04]\n",
      " [7.72346791e-05 9.56164308e-05]]\n",
      "Train Epoch35 out_loss 0.0005539017147384584\n",
      "Test Epoch35 layer0 out_loss 0.01480263751000166\n",
      "Test Epoch35 layer1 out_loss 0.0018588153179734945\n",
      "Test Epoch35 layer2 out_loss 0.0006937181460671127\n",
      "Test Epoch35 layer3 out_loss 0.0006874852115288377\n",
      "Test Epoch35 layer4 out_loss 0.00042815995402634144\n",
      "Test Epoch35 layer5 out_loss 0.0005549713969230652\n",
      "Test Epoch35 layer6 out_loss 0.0005831886664964259\n",
      "Test Epoch35 layer7 out_loss 0.0006962016923353076\n",
      "Test Epoch35 layer8 out_loss 0.0006043621688149869\n",
      "Train 36 | out_loss 0.0012606438249349594: 100%|█| 138/138 [00:01<00:00, 124.93i\n",
      "[[0.00028341 0.08121627]\n",
      " [0.00071342 0.0017817 ]\n",
      " [0.00088198 0.00128084]\n",
      " [0.0006604  0.00114859]\n",
      " [0.00048563 0.00065056]\n",
      " [0.00032802 0.00035085]\n",
      " [0.00020355 0.00023641]\n",
      " [0.00021131 0.00022441]\n",
      " [0.00021064 0.00030211]]\n",
      "Train Epoch36 out_loss 0.0012606438249349594\n",
      "Test Epoch36 layer0 out_loss 0.004828762263059616\n",
      "Test Epoch36 layer1 out_loss 0.0008272552513517439\n",
      "Test Epoch36 layer2 out_loss 0.0006748594460077584\n",
      "Test Epoch36 layer3 out_loss 0.0007445629453286529\n",
      "Test Epoch36 layer4 out_loss 0.0007091019651852548\n",
      "Test Epoch36 layer5 out_loss 0.0007019912009127438\n",
      "Test Epoch36 layer6 out_loss 0.0004913675365969539\n",
      "Test Epoch36 layer7 out_loss 0.0008984631858766079\n",
      "Test Epoch36 layer8 out_loss 0.0007436617161147296\n",
      "Train 37 | out_loss 0.0017283657798543572: 100%|█| 138/138 [00:01<00:00, 117.62i\n",
      "[[0.0005606  0.01825997]\n",
      " [0.00052798 0.00104796]\n",
      " [0.00084797 0.00109809]\n",
      " [0.00060414 0.00126023]\n",
      " [0.0004331  0.00062901]\n",
      " [0.00037919 0.00042836]\n",
      " [0.00025143 0.00028745]\n",
      " [0.00025978 0.00025198]\n",
      " [0.00018191 0.00020036]]\n",
      "Train Epoch37 out_loss 0.0017283657798543572\n",
      "Test Epoch37 layer0 out_loss 0.00457192026078701\n",
      "Test Epoch37 layer1 out_loss 0.002079194178804755\n",
      "Test Epoch37 layer2 out_loss 0.0017638754798099399\n",
      "Test Epoch37 layer3 out_loss 0.0021464789751917124\n",
      "Test Epoch37 layer4 out_loss 0.002178640104830265\n",
      "Test Epoch37 layer5 out_loss 0.0019530567806214094\n",
      "Test Epoch37 layer6 out_loss 0.0021572564728558064\n",
      "Test Epoch37 layer7 out_loss 0.002120849909260869\n",
      "Test Epoch37 layer8 out_loss 0.0017278543673455715\n",
      "Train 38 | out_loss 0.0011805023532360792: 100%|█| 138/138 [00:01<00:00, 111.85i\n",
      "[[0.00021189 0.05789254]\n",
      " [0.0005459  0.00138124]\n",
      " [0.00057809 0.00103785]\n",
      " [0.00046992 0.00114929]\n",
      " [0.00045765 0.00057988]\n",
      " [0.00040674 0.00037421]\n",
      " [0.00024282 0.00027474]\n",
      " [0.00016557 0.00017223]\n",
      " [0.00011732 0.00014021]]\n",
      "Train Epoch38 out_loss 0.0011805023532360792\n",
      "Test Epoch38 layer0 out_loss 0.006579369306564331\n",
      "Test Epoch38 layer1 out_loss 0.002916037803515792\n",
      "Test Epoch38 layer2 out_loss 0.002516683656722307\n",
      "Test Epoch38 layer3 out_loss 0.0029057462234050035\n",
      "Test Epoch38 layer4 out_loss 0.003212654497474432\n",
      "Test Epoch38 layer5 out_loss 0.0032968379091471434\n",
      "Test Epoch38 layer6 out_loss 0.0025535658933222294\n",
      "Test Epoch38 layer7 out_loss 0.0022567284759134054\n",
      "Test Epoch38 layer8 out_loss 0.002653170609846711\n",
      "Train 39 | out_loss 0.0017870052251964808: 100%|█| 138/138 [00:01<00:00, 116.67i\n",
      "[[5.61525499e-04 3.27900346e-01]\n",
      " [6.40895403e-04 3.08871628e-03]\n",
      " [7.63725207e-04 1.41204162e-03]\n",
      " [5.49940817e-04 1.15115474e-03]\n",
      " [4.37335930e-04 6.31632888e-04]\n",
      " [4.03635651e-04 4.06569453e-04]\n",
      " [3.60775030e-04 3.68247999e-04]\n",
      " [2.53182769e-04 2.86121495e-04]\n",
      " [1.71568178e-04 2.24758763e-04]]\n",
      "Train Epoch39 out_loss 0.0017870052251964808\n",
      "Test Epoch39 layer0 out_loss 0.011859112419188023\n",
      "Test Epoch39 layer1 out_loss 0.0032874371390789747\n",
      "Test Epoch39 layer2 out_loss 0.002521112561225891\n",
      "Test Epoch39 layer3 out_loss 0.0022204003762453794\n",
      "Test Epoch39 layer4 out_loss 0.0023856395855545998\n",
      "Test Epoch39 layer5 out_loss 0.002615409903228283\n",
      "Test Epoch39 layer6 out_loss 0.0027455883100628853\n",
      "Test Epoch39 layer7 out_loss 0.0028613489121198654\n",
      "Test Epoch39 layer8 out_loss 0.002506934106349945\n",
      "Train 40 | out_loss 0.0014260412426665425: 100%|█| 138/138 [00:01<00:00, 119.54i\n",
      "[[3.61635025e-04 2.20154408e-01]\n",
      " [6.36315153e-04 3.31554551e-03]\n",
      " [7.39394212e-04 1.48088863e-03]\n",
      " [4.96606099e-04 1.43780838e-03]\n",
      " [4.75411415e-04 7.33100794e-04]\n",
      " [3.71585342e-04 3.91943979e-04]\n",
      " [3.91480665e-04 4.23283553e-04]\n",
      " [2.42436459e-04 2.94522972e-04]\n",
      " [1.79775720e-04 2.45466222e-04]]\n",
      "Train Epoch40 out_loss 0.0014260412426665425\n",
      "Test Epoch40 layer0 out_loss 0.020823264494538307\n",
      "Test Epoch40 layer1 out_loss 0.0023770222906023264\n",
      "Test Epoch40 layer2 out_loss 0.000450832856586203\n",
      "Test Epoch40 layer3 out_loss 0.00041102521936409175\n",
      "Test Epoch40 layer4 out_loss 0.0006155312294140458\n",
      "Test Epoch40 layer5 out_loss 0.0004268928023520857\n",
      "Test Epoch40 layer6 out_loss 0.0004602377593982965\n",
      "Test Epoch40 layer7 out_loss 0.0005508752074092627\n",
      "Test Epoch40 layer8 out_loss 0.0004668131878133863\n",
      "Train 41 | out_loss 0.0011443325784057379: 100%|█| 138/138 [00:01<00:00, 118.35i\n",
      "[[0.00024238 0.07999254]\n",
      " [0.00054586 0.00183106]\n",
      " [0.00068954 0.00129037]\n",
      " [0.00067758 0.00154037]\n",
      " [0.00054951 0.0007553 ]\n",
      " [0.00040104 0.00037694]\n",
      " [0.00034645 0.00034733]\n",
      " [0.00022055 0.00025575]\n",
      " [0.00015118 0.0001964 ]]\n",
      "Train Epoch41 out_loss 0.0011443325784057379\n",
      "Test Epoch41 layer0 out_loss 0.017797308042645454\n",
      "Test Epoch41 layer1 out_loss 0.0018456850666552782\n",
      "Test Epoch41 layer2 out_loss 0.0025368304923176765\n",
      "Test Epoch41 layer3 out_loss 0.0028167739510536194\n",
      "Test Epoch41 layer4 out_loss 0.0024498957209289074\n",
      "Test Epoch41 layer5 out_loss 0.002475283807143569\n",
      "Test Epoch41 layer6 out_loss 0.0024868096224963665\n",
      "Test Epoch41 layer7 out_loss 0.002311606891453266\n",
      "Test Epoch41 layer8 out_loss 0.0024359954986721277\n",
      "Train 42 | out_loss 0.0014212713576853275: 100%|█| 138/138 [00:01<00:00, 118.84i\n",
      "[[0.00038583 0.10596605]\n",
      " [0.00058094 0.00225685]\n",
      " [0.00074671 0.0014283 ]\n",
      " [0.00052241 0.00120793]\n",
      " [0.00048851 0.0006187 ]\n",
      " [0.00041153 0.00042989]\n",
      " [0.00045767 0.0005034 ]\n",
      " [0.00025223 0.0003252 ]\n",
      " [0.00017064 0.00023409]]\n",
      "Train Epoch42 out_loss 0.0014212713576853275\n",
      "Test Epoch42 layer0 out_loss 0.005968127865344286\n",
      "Test Epoch42 layer1 out_loss 0.0006973523995839059\n",
      "Test Epoch42 layer2 out_loss 0.0008878976805135608\n",
      "Test Epoch42 layer3 out_loss 0.00045742455404251814\n",
      "Test Epoch42 layer4 out_loss 0.000595973979216069\n",
      "Test Epoch42 layer5 out_loss 0.0007677762187086046\n",
      "Test Epoch42 layer6 out_loss 0.0012034670216962695\n",
      "Test Epoch42 layer7 out_loss 0.0007324215839616954\n",
      "Test Epoch42 layer8 out_loss 0.0007240247214213014\n",
      "Train 43 | out_loss 0.0013493240112438798: 100%|█| 138/138 [00:01<00:00, 113.73i\n",
      "[[0.00029397 0.0243494 ]\n",
      " [0.00070473 0.00145057]\n",
      " [0.00072824 0.00157092]\n",
      " [0.00062113 0.00108997]\n",
      " [0.00048501 0.00067112]\n",
      " [0.00046115 0.00045278]\n",
      " [0.00033613 0.00037086]\n",
      " [0.00026881 0.00032463]\n",
      " [0.00028869 0.00044186]]\n",
      "Train Epoch43 out_loss 0.0013493240112438798\n",
      "Test Epoch43 layer0 out_loss 0.006656528450548649\n",
      "Test Epoch43 layer1 out_loss 0.0013678462710231543\n",
      "Test Epoch43 layer2 out_loss 0.0011630784720182419\n",
      "Test Epoch43 layer3 out_loss 0.000997986295260489\n",
      "Test Epoch43 layer4 out_loss 0.0008312170975841582\n",
      "Test Epoch43 layer5 out_loss 0.0010053978767246008\n",
      "Test Epoch43 layer6 out_loss 0.0012196688912808895\n",
      "Test Epoch43 layer7 out_loss 0.0011864709667861462\n",
      "Test Epoch43 layer8 out_loss 0.0009290205198340118\n",
      "Train 44 | out_loss 0.0016542918747290969: 100%|█| 138/138 [00:01<00:00, 112.67i\n",
      "[[0.00044665 0.02065664]\n",
      " [0.00076901 0.00148096]\n",
      " [0.00117994 0.00197013]\n",
      " [0.00058659 0.00134357]\n",
      " [0.00044916 0.00067427]\n",
      " [0.0003345  0.00036833]\n",
      " [0.00024303 0.00026398]\n",
      " [0.00022537 0.00023145]\n",
      " [0.00020939 0.00023388]]\n",
      "Train Epoch44 out_loss 0.0016542918747290969\n",
      "Test Epoch44 layer0 out_loss 0.007255535572767258\n",
      "Test Epoch44 layer1 out_loss 0.001047256519086659\n",
      "Test Epoch44 layer2 out_loss 0.0007579026860184968\n",
      "Test Epoch44 layer3 out_loss 0.0010723909363150597\n",
      "Test Epoch44 layer4 out_loss 0.0008796562324278057\n",
      "Test Epoch44 layer5 out_loss 0.0013470982667058706\n",
      "Test Epoch44 layer6 out_loss 0.0016386499628424644\n",
      "Test Epoch44 layer7 out_loss 0.0010002193739637733\n",
      "Test Epoch44 layer8 out_loss 0.001352748367935419\n",
      "Train 45 | out_loss 0.0017129260813817382: 100%|█| 138/138 [00:01<00:00, 119.95i\n",
      "[[0.00051685 0.07604266]\n",
      " [0.00043717 0.00153376]\n",
      " [0.00052374 0.0015285 ]\n",
      " [0.00049085 0.00115408]\n",
      " [0.00052794 0.00084322]\n",
      " [0.00048772 0.00052814]\n",
      " [0.00030163 0.00029571]\n",
      " [0.00019644 0.00018722]\n",
      " [0.00016024 0.00018886]]\n",
      "Train Epoch45 out_loss 0.0017129260813817382\n",
      "Test Epoch45 layer0 out_loss 0.004810221493244171\n",
      "Test Epoch45 layer1 out_loss 0.0008337491890415549\n",
      "Test Epoch45 layer2 out_loss 0.0005410127341747284\n",
      "Test Epoch45 layer3 out_loss 0.0004585048009175807\n",
      "Test Epoch45 layer4 out_loss 0.0007237911922857165\n",
      "Test Epoch45 layer5 out_loss 0.0005182000459171832\n",
      "Test Epoch45 layer6 out_loss 0.0004532401799224317\n",
      "Test Epoch45 layer7 out_loss 0.0005941172130405903\n",
      "Test Epoch45 layer8 out_loss 0.0005386093980632722\n",
      "Train 46 | out_loss 0.000996487564407289: 100%|█| 138/138 [00:01<00:00, 117.42it\n",
      "[[1.53498466e-04 3.74792280e-01]\n",
      " [5.86156803e-04 2.91125216e-03]\n",
      " [6.14242303e-04 1.46566861e-03]\n",
      " [4.49284949e-04 1.25782426e-03]\n",
      " [6.08560763e-04 7.46779324e-04]\n",
      " [3.79622458e-04 4.04512368e-04]\n",
      " [2.25910140e-04 2.24038235e-04]\n",
      " [1.56674398e-04 1.41995025e-04]\n",
      " [1.31270161e-04 1.52566964e-04]]\n",
      "Train Epoch46 out_loss 0.000996487564407289\n",
      "Test Epoch46 layer0 out_loss 0.052667830139398575\n",
      "Test Epoch46 layer1 out_loss 0.0025711730122566223\n",
      "Test Epoch46 layer2 out_loss 0.0015901849837973714\n",
      "Test Epoch46 layer3 out_loss 0.0007765894988551736\n",
      "Test Epoch46 layer4 out_loss 0.0006663707317784429\n",
      "Test Epoch46 layer5 out_loss 0.0009545437642373145\n",
      "Test Epoch46 layer6 out_loss 0.0008476082002744079\n",
      "Test Epoch46 layer7 out_loss 0.0006631938158534467\n",
      "Test Epoch46 layer8 out_loss 0.000676000548992306\n",
      "Train 47 | out_loss 0.0015841051936149597: 100%|█| 138/138 [00:01<00:00, 114.41i\n",
      "[[5.08088390e-04 2.28391495e-01]\n",
      " [5.99994798e-04 2.36277935e-03]\n",
      " [6.84947622e-04 1.64093817e-03]\n",
      " [5.16915991e-04 1.37939004e-03]\n",
      " [6.57005178e-04 8.15095496e-04]\n",
      " [4.31029493e-04 4.76474943e-04]\n",
      " [2.35015938e-04 2.46571757e-04]\n",
      " [1.67452047e-04 1.76191161e-04]\n",
      " [1.59790371e-04 1.80174167e-04]]\n",
      "Train Epoch47 out_loss 0.0015841051936149597\n",
      "Test Epoch47 layer0 out_loss 0.013870717026293278\n",
      "Test Epoch47 layer1 out_loss 0.0006540311733260751\n",
      "Test Epoch47 layer2 out_loss 0.0006487827049568295\n",
      "Test Epoch47 layer3 out_loss 0.0005811675218865275\n",
      "Test Epoch47 layer4 out_loss 0.000472700921818614\n",
      "Test Epoch47 layer5 out_loss 0.0005426898715086281\n",
      "Test Epoch47 layer6 out_loss 0.0006917293067090213\n",
      "Test Epoch47 layer7 out_loss 0.0004328062350396067\n",
      "Test Epoch47 layer8 out_loss 0.0004386703367345035\n",
      "Train 48 | out_loss 0.0012247591512277722: 100%|█| 138/138 [00:01<00:00, 119.68i\n",
      "[[0.00027442 0.03296363]\n",
      " [0.00049957 0.00152488]\n",
      " [0.00061818 0.00140236]\n",
      " [0.00048518 0.00125388]\n",
      " [0.00057092 0.00063871]\n",
      " [0.00031234 0.00036124]\n",
      " [0.00017431 0.00016614]\n",
      " [0.00011515 0.00011504]\n",
      " [0.00011566 0.00014557]]\n",
      "Train Epoch48 out_loss 0.0012247591512277722\n",
      "Test Epoch48 layer0 out_loss 0.0052848150953650475\n",
      "Test Epoch48 layer1 out_loss 0.0007961808587424457\n",
      "Test Epoch48 layer2 out_loss 0.0009455844410695136\n",
      "Test Epoch48 layer3 out_loss 0.0004832102276850492\n",
      "Test Epoch48 layer4 out_loss 0.00043681261013261974\n",
      "Test Epoch48 layer5 out_loss 0.0006160715711303055\n",
      "Test Epoch48 layer6 out_loss 0.00043158745393157005\n",
      "Test Epoch48 layer7 out_loss 0.00047974285553209484\n",
      "Test Epoch48 layer8 out_loss 0.0004231736820656806\n",
      "Train 49 | out_loss 0.0015515019185841084: 100%|█| 138/138 [00:01<00:00, 117.13i\n",
      "[[0.00045191 0.01427193]\n",
      " [0.0005841  0.00148761]\n",
      " [0.0006587  0.001334  ]\n",
      " [0.00039976 0.00066918]\n",
      " [0.00028655 0.00032663]\n",
      " [0.00021229 0.00022084]\n",
      " [0.00014072 0.00015197]\n",
      " [0.00014541 0.00015716]\n",
      " [0.00018527 0.0002248 ]]\n",
      "Train Epoch49 out_loss 0.0015515019185841084\n",
      "Test Epoch49 layer0 out_loss 0.004371142480522394\n",
      "Test Epoch49 layer1 out_loss 0.0010679971892386675\n",
      "Test Epoch49 layer2 out_loss 0.0007848988170735538\n",
      "Test Epoch49 layer3 out_loss 0.0008419651421718299\n",
      "Test Epoch49 layer4 out_loss 0.0008589486824348569\n",
      "Test Epoch49 layer5 out_loss 0.0008082073763944209\n",
      "Test Epoch49 layer6 out_loss 0.001006562728434801\n",
      "Test Epoch49 layer7 out_loss 0.0008394467877224088\n",
      "Test Epoch49 layer8 out_loss 0.0009652685839682817\n",
      "Train 50 | out_loss 0.0011856129858642817: 100%|█| 138/138 [00:01<00:00, 109.98i\n",
      "[[0.00027337 0.04129514]\n",
      " [0.00049111 0.00164746]\n",
      " [0.00065416 0.00169518]\n",
      " [0.00043251 0.00088715]\n",
      " [0.00034517 0.00047265]\n",
      " [0.00026694 0.00028596]\n",
      " [0.0002045  0.00019655]\n",
      " [0.00016325 0.00015365]\n",
      " [0.00013857 0.00015364]]\n",
      "Train Epoch50 out_loss 0.0011856129858642817\n",
      "Test Epoch50 layer0 out_loss 0.010661985725164413\n",
      "Test Epoch50 layer1 out_loss 0.0007486643153242767\n",
      "Test Epoch50 layer2 out_loss 0.0008625893387943506\n",
      "Test Epoch50 layer3 out_loss 0.000733218970708549\n",
      "Test Epoch50 layer4 out_loss 0.0007283809827640653\n",
      "Test Epoch50 layer5 out_loss 0.0009148709941655397\n",
      "Test Epoch50 layer6 out_loss 0.0009446783224120736\n",
      "Test Epoch50 layer7 out_loss 0.0006117763114161789\n",
      "Test Epoch50 layer8 out_loss 0.0009668652201071382\n",
      "Train 51 | out_loss 0.0013966497499495745: 100%|█| 138/138 [00:01<00:00, 118.85i\n",
      "[[0.00035484 0.17250886]\n",
      " [0.00073245 0.0033124 ]\n",
      " [0.00090342 0.00211084]\n",
      " [0.00070676 0.00152018]\n",
      " [0.00055873 0.00068713]\n",
      " [0.00038995 0.0003858 ]\n",
      " [0.00026199 0.00026095]\n",
      " [0.00023099 0.00024041]\n",
      " [0.00018596 0.0002203 ]]\n",
      "Train Epoch51 out_loss 0.0013966497499495745\n",
      "Test Epoch51 layer0 out_loss 0.016300633549690247\n",
      "Test Epoch51 layer1 out_loss 0.0013127507409080863\n",
      "Test Epoch51 layer2 out_loss 0.0020528698805719614\n",
      "Test Epoch51 layer3 out_loss 0.0018158898456022143\n",
      "Test Epoch51 layer4 out_loss 0.001967988908290863\n",
      "Test Epoch51 layer5 out_loss 0.0016683903522789478\n",
      "Test Epoch51 layer6 out_loss 0.0014678798615932465\n",
      "Test Epoch51 layer7 out_loss 0.0015979543095454574\n",
      "Test Epoch51 layer8 out_loss 0.0017068205634132028\n",
      "Train 52 | out_loss 0.0017695992719382048: 100%|█| 138/138 [00:01<00:00, 115.84i\n",
      "[[0.00063155 0.08679661]\n",
      " [0.00045464 0.00207314]\n",
      " [0.00053336 0.00148455]\n",
      " [0.00041892 0.00093306]\n",
      " [0.0003519  0.00051298]\n",
      " [0.00029264 0.00034197]\n",
      " [0.00025309 0.00024194]\n",
      " [0.00019779 0.00019565]\n",
      " [0.00014788 0.00017568]]\n",
      "Train Epoch52 out_loss 0.0017695992719382048\n",
      "Test Epoch52 layer0 out_loss 0.016720561310648918\n",
      "Test Epoch52 layer1 out_loss 0.001781404484063387\n",
      "Test Epoch52 layer2 out_loss 0.0004700009012594819\n",
      "Test Epoch52 layer3 out_loss 0.00048118014819920063\n",
      "Test Epoch52 layer4 out_loss 0.0004885416128672659\n",
      "Test Epoch52 layer5 out_loss 0.00043328586616553366\n",
      "Test Epoch52 layer6 out_loss 0.00042829508311115205\n",
      "Test Epoch52 layer7 out_loss 0.000678692536894232\n",
      "Test Epoch52 layer8 out_loss 0.0005080149276182055\n",
      "Train 53 | out_loss 0.0015222708461806178: 100%|█| 138/138 [00:01<00:00, 119.28i\n",
      "[[0.00042609 0.06865376]\n",
      " [0.00058594 0.00212208]\n",
      " [0.00064813 0.00129276]\n",
      " [0.00038984 0.00072934]\n",
      " [0.00028684 0.00041278]\n",
      " [0.00025663 0.00029385]\n",
      " [0.00024381 0.0002403 ]\n",
      " [0.00024854 0.00022196]\n",
      " [0.00020105 0.00023906]]\n",
      "Train Epoch53 out_loss 0.0015222708461806178\n",
      "Test Epoch53 layer0 out_loss 0.008109892718493938\n",
      "Test Epoch53 layer1 out_loss 0.0028457671869546175\n",
      "Test Epoch53 layer2 out_loss 0.00254919589497149\n",
      "Test Epoch53 layer3 out_loss 0.0028319554403424263\n",
      "Test Epoch53 layer4 out_loss 0.0026668510399758816\n",
      "Test Epoch53 layer5 out_loss 0.0025028118398040533\n",
      "Test Epoch53 layer6 out_loss 0.0027482369914650917\n",
      "Test Epoch53 layer7 out_loss 0.002893475815653801\n",
      "Test Epoch53 layer8 out_loss 0.002729649655520916\n",
      "Train 54 | out_loss 0.0011216128477826715: 100%|█| 138/138 [00:01<00:00, 111.31i\n",
      "[[0.00022862 0.00698408]\n",
      " [0.00050481 0.0014659 ]\n",
      " [0.00071815 0.00179392]\n",
      " [0.00049522 0.00113391]\n",
      " [0.00052746 0.000635  ]\n",
      " [0.00035647 0.00035574]\n",
      " [0.00026818 0.00027552]\n",
      " [0.00018275 0.00018096]\n",
      " [0.00019566 0.0002234 ]]\n",
      "Train Epoch54 out_loss 0.0011216128477826715\n",
      "Test Epoch54 layer0 out_loss 0.003600803203880787\n",
      "Test Epoch54 layer1 out_loss 0.0005808331770822406\n",
      "Test Epoch54 layer2 out_loss 0.00044450501445680857\n",
      "Test Epoch54 layer3 out_loss 0.0005727449315600097\n",
      "Test Epoch54 layer4 out_loss 0.00046457754797302186\n",
      "Test Epoch54 layer5 out_loss 0.0004351733950898051\n",
      "Test Epoch54 layer6 out_loss 0.00042728777043521404\n",
      "Test Epoch54 layer7 out_loss 0.00044682648149318993\n",
      "Test Epoch54 layer8 out_loss 0.00042247725650668144\n",
      "Train 55 | out_loss 0.0014664182672277093: 100%|█| 138/138 [00:01<00:00, 119.83i\n",
      "[[0.00039969 0.07597058]\n",
      " [0.00050774 0.00253694]\n",
      " [0.00058051 0.00165827]\n",
      " [0.00049444 0.00091328]\n",
      " [0.00031408 0.00043641]\n",
      " [0.00024908 0.0002729 ]\n",
      " [0.00020634 0.0002065 ]\n",
      " [0.00018591 0.00015878]\n",
      " [0.00015111 0.00014406]]\n",
      "Train Epoch55 out_loss 0.0014664182672277093\n",
      "Test Epoch55 layer0 out_loss 0.016067449003458023\n",
      "Test Epoch55 layer1 out_loss 0.0005806639674119651\n",
      "Test Epoch55 layer2 out_loss 0.0005613917019218206\n",
      "Test Epoch55 layer3 out_loss 0.0008235303102992475\n",
      "Test Epoch55 layer4 out_loss 0.00044707037159241736\n",
      "Test Epoch55 layer5 out_loss 0.0005289852269925177\n",
      "Test Epoch55 layer6 out_loss 0.0005367789417505264\n",
      "Test Epoch55 layer7 out_loss 0.0005926540470682085\n",
      "Test Epoch55 layer8 out_loss 0.0006893033278174698\n",
      "Train 56 | out_loss 0.0013761866139248013: 100%|█| 138/138 [00:01<00:00, 114.50i\n",
      "[[0.00035417 0.12399562]\n",
      " [0.00071495 0.00313869]\n",
      " [0.00080925 0.00184057]\n",
      " [0.00049721 0.0009782 ]\n",
      " [0.00040786 0.00050745]\n",
      " [0.00034981 0.00039266]\n",
      " [0.00026317 0.00025125]\n",
      " [0.00023002 0.00020923]\n",
      " [0.00019291 0.00021081]]\n",
      "Train Epoch56 out_loss 0.0013761866139248013\n",
      "Test Epoch56 layer0 out_loss 0.01679825596511364\n",
      "Test Epoch56 layer1 out_loss 0.0012176698073744774\n",
      "Test Epoch56 layer2 out_loss 0.0010582886170595884\n",
      "Test Epoch56 layer3 out_loss 0.00040930448449216783\n",
      "Test Epoch56 layer4 out_loss 0.0004298881976865232\n",
      "Test Epoch56 layer5 out_loss 0.0004541620728559792\n",
      "Test Epoch56 layer6 out_loss 0.00045593761024065316\n",
      "Test Epoch56 layer7 out_loss 0.0004304472531657666\n",
      "Test Epoch56 layer8 out_loss 0.0005071248742751777\n",
      "Train 57 | out_loss 0.0012642258079722524: 100%|█| 138/138 [00:01<00:00, 118.81i\n",
      "[[0.00026095 0.17199102]\n",
      " [0.0004565  0.00261616]\n",
      " [0.00062876 0.00146123]\n",
      " [0.0004231  0.00108782]\n",
      " [0.00041939 0.00060736]\n",
      " [0.00039869 0.00038624]\n",
      " [0.00026398 0.00026104]\n",
      " [0.0002388  0.00021666]\n",
      " [0.0001891  0.00019357]]\n",
      "Train Epoch57 out_loss 0.0012642258079722524\n",
      "Test Epoch57 layer0 out_loss 0.012770112603902817\n",
      "Test Epoch57 layer1 out_loss 0.003112821141257882\n",
      "Test Epoch57 layer2 out_loss 0.0029057885985821486\n",
      "Test Epoch57 layer3 out_loss 0.002961144084110856\n",
      "Test Epoch57 layer4 out_loss 0.0030475531239062548\n",
      "Test Epoch57 layer5 out_loss 0.0027939036954194307\n",
      "Test Epoch57 layer6 out_loss 0.00268217152915895\n",
      "Test Epoch57 layer7 out_loss 0.002911515533924103\n",
      "Test Epoch57 layer8 out_loss 0.0029143178835511208\n",
      "Train 58 | out_loss 0.0016393271507695317: 100%|█| 138/138 [00:01<00:00, 119.37i\n",
      "[[0.00055989 0.01374153]\n",
      " [0.00042615 0.00156778]\n",
      " [0.00058723 0.00146027]\n",
      " [0.00040639 0.0009177 ]\n",
      " [0.00051254 0.00063556]\n",
      " [0.00045506 0.00044843]\n",
      " [0.00030041 0.00024779]\n",
      " [0.00024368 0.00021955]\n",
      " [0.00017528 0.00017995]]\n",
      "Train Epoch58 out_loss 0.0016393271507695317\n",
      "Test Epoch58 layer0 out_loss 0.003568182932212949\n",
      "Test Epoch58 layer1 out_loss 0.0009739365195855498\n",
      "Test Epoch58 layer2 out_loss 0.000650434463750571\n",
      "Test Epoch58 layer3 out_loss 0.0007161807734519243\n",
      "Test Epoch58 layer4 out_loss 0.000638820871245116\n",
      "Test Epoch58 layer5 out_loss 0.000602065643761307\n",
      "Test Epoch58 layer6 out_loss 0.0005552982911467552\n",
      "Test Epoch58 layer7 out_loss 0.0005016042268835008\n",
      "Test Epoch58 layer8 out_loss 0.00047565464046783745\n",
      "Train 59 | out_loss 0.0013105145189911127: 100%|█| 138/138 [00:01<00:00, 112.46i\n",
      "[[0.00031902 0.10970044]\n",
      " [0.00048846 0.00239193]\n",
      " [0.00057831 0.00174194]\n",
      " [0.00043966 0.00094991]\n",
      " [0.00035276 0.00044229]\n",
      " [0.00029244 0.00030673]\n",
      " [0.000199   0.00018145]\n",
      " [0.00014483 0.00014649]\n",
      " [0.00011861 0.00014459]]\n",
      "Train Epoch59 out_loss 0.0013105145189911127\n",
      "Test Epoch59 layer0 out_loss 0.009644555859267712\n",
      "Test Epoch59 layer1 out_loss 0.0008873195620253682\n",
      "Test Epoch59 layer2 out_loss 0.0009046274935826659\n",
      "Test Epoch59 layer3 out_loss 0.0005821969825774431\n",
      "Test Epoch59 layer4 out_loss 0.0005395087646320462\n",
      "Test Epoch59 layer5 out_loss 0.000605928071308881\n",
      "Test Epoch59 layer6 out_loss 0.0006708690198138356\n",
      "Test Epoch59 layer7 out_loss 0.0005123201990500093\n",
      "Test Epoch59 layer8 out_loss 0.0006340702529996634\n",
      "Train 60 | out_loss 0.0011822872329503298: 100%|█| 138/138 [00:01<00:00, 119.68i\n",
      "[[0.00025996 0.02315217]\n",
      " [0.00043458 0.00165812]\n",
      " [0.00065506 0.00163223]\n",
      " [0.00039545 0.00082724]\n",
      " [0.00032042 0.00050046]\n",
      " [0.00056815 0.00057995]\n",
      " [0.00033509 0.00034076]\n",
      " [0.00025262 0.00023551]\n",
      " [0.00018449 0.00018675]]\n",
      "Train Epoch60 out_loss 0.0011822872329503298\n",
      "Test Epoch60 layer0 out_loss 0.007787381298840046\n",
      "Test Epoch60 layer1 out_loss 0.0005878275260329247\n",
      "Test Epoch60 layer2 out_loss 0.0004707181069534272\n",
      "Test Epoch60 layer3 out_loss 0.0006815423257648945\n",
      "Test Epoch60 layer4 out_loss 0.0010153568582609296\n",
      "Test Epoch60 layer5 out_loss 0.00045887313899584115\n",
      "Test Epoch60 layer6 out_loss 0.0006534767453558743\n",
      "Test Epoch60 layer7 out_loss 0.0006838737172074616\n",
      "Test Epoch60 layer8 out_loss 0.000653451366815716\n",
      "Train 61 | out_loss 0.002115881070494652: 100%|█| 138/138 [00:01<00:00, 119.77it\n",
      "[[0.00085591 0.01022494]\n",
      " [0.00060096 0.00192168]\n",
      " [0.00074433 0.00185537]\n",
      " [0.00050102 0.00100013]\n",
      " [0.00034911 0.00054886]\n",
      " [0.00037953 0.00037098]\n",
      " [0.00032561 0.00036866]\n",
      " [0.00021218 0.00022477]\n",
      " [0.00017581 0.0001993 ]]\n",
      "Train Epoch61 out_loss 0.002115881070494652\n",
      "Test Epoch61 layer0 out_loss 0.018474437296390533\n",
      "Test Epoch61 layer1 out_loss 0.0005616003763861954\n",
      "Test Epoch61 layer2 out_loss 0.0006121342303231359\n",
      "Test Epoch61 layer3 out_loss 0.00046232171007432044\n",
      "Test Epoch61 layer4 out_loss 0.00043675091001205146\n",
      "Test Epoch61 layer5 out_loss 0.0004676439566537738\n",
      "Test Epoch61 layer6 out_loss 0.00042612969991751015\n",
      "Test Epoch61 layer7 out_loss 0.0004315579717513174\n",
      "Test Epoch61 layer8 out_loss 0.00044547070865519345\n",
      "Train 62 | out_loss 0.00043293333146721125: 100%|█| 138/138 [00:01<00:00, 109.55\n",
      "[[1.04760525e-06 2.50906358e-01]\n",
      " [4.99514944e-04 4.09369965e-03]\n",
      " [5.61947909e-04 1.61777355e-03]\n",
      " [4.29504980e-04 9.11599016e-04]\n",
      " [2.79560700e-04 3.67157946e-04]\n",
      " [1.60449236e-04 1.69023581e-04]\n",
      " [1.04080823e-04 1.15261555e-04]\n",
      " [8.04789788e-05 9.13972151e-05]\n",
      " [7.95662758e-05 1.06099113e-04]]\n",
      "Train Epoch62 out_loss 0.00043293333146721125\n",
      "Test Epoch62 layer0 out_loss 0.005356964655220509\n",
      "Test Epoch62 layer1 out_loss 0.0005920167895965278\n",
      "Test Epoch62 layer2 out_loss 0.0006434281240217388\n",
      "Test Epoch62 layer3 out_loss 0.0004662065184675157\n",
      "Test Epoch62 layer4 out_loss 0.0004598932573571801\n",
      "Test Epoch62 layer5 out_loss 0.00043944711796939373\n",
      "Test Epoch62 layer6 out_loss 0.0004963917890563607\n",
      "Test Epoch62 layer7 out_loss 0.0005278799217194319\n",
      "Test Epoch62 layer8 out_loss 0.00046342695713974535\n",
      "Train 63 | out_loss 0.0016509511042386293: 100%|█| 138/138 [00:01<00:00, 115.80i\n",
      "[[0.00046879 0.00714704]\n",
      " [0.00048177 0.00154951]\n",
      " [0.00055428 0.0016522 ]\n",
      " [0.00039745 0.00079237]\n",
      " [0.00030782 0.00035963]\n",
      " [0.00021862 0.00017769]\n",
      " [0.00014659 0.0001691 ]\n",
      " [0.00012157 0.00013507]\n",
      " [0.00011998 0.00014122]]\n",
      "Train Epoch63 out_loss 0.0016509511042386293\n",
      "Test Epoch63 layer0 out_loss 0.0030235908925533295\n",
      "Test Epoch63 layer1 out_loss 0.0014953167410567403\n",
      "Test Epoch63 layer2 out_loss 0.0012898490531370044\n",
      "Test Epoch63 layer3 out_loss 0.0006415053503587842\n",
      "Test Epoch63 layer4 out_loss 0.0005094964290037751\n",
      "Test Epoch63 layer5 out_loss 0.0005130353383719921\n",
      "Test Epoch63 layer6 out_loss 0.00047668538172729313\n",
      "Test Epoch63 layer7 out_loss 0.0005988439661450684\n",
      "Test Epoch63 layer8 out_loss 0.000541825604159385\n",
      "Train 64 | out_loss 0.001247346168383956: 100%|█| 138/138 [00:01<00:00, 113.04it\n",
      "[[3.25631217e-04 6.79296086e-03]\n",
      " [3.64604668e-04 1.50418896e-03]\n",
      " [5.66441198e-04 1.71020552e-03]\n",
      " [4.62789977e-04 1.01514608e-03]\n",
      " [4.28202790e-04 5.07239358e-04]\n",
      " [2.53233814e-04 2.16038227e-04]\n",
      " [1.84039543e-04 1.86016174e-04]\n",
      " [1.26787186e-04 1.22549526e-04]\n",
      " [9.67917207e-05 1.08342410e-04]]\n",
      "Train Epoch64 out_loss 0.001247346168383956\n",
      "Test Epoch64 layer0 out_loss 0.004442974459379911\n",
      "Test Epoch64 layer1 out_loss 0.0006397241959348321\n",
      "Test Epoch64 layer2 out_loss 0.0004202353593427688\n",
      "Test Epoch64 layer3 out_loss 0.000659121316857636\n",
      "Test Epoch64 layer4 out_loss 0.0009821420535445213\n",
      "Test Epoch64 layer5 out_loss 0.0005856862408109009\n",
      "Test Epoch64 layer6 out_loss 0.0004572887846734375\n",
      "Test Epoch64 layer7 out_loss 0.00044546707067638636\n",
      "Test Epoch64 layer8 out_loss 0.0004616271471604705\n",
      "Train 65 | out_loss 0.0011373807210475206: 100%|█| 138/138 [00:01<00:00, 114.11i\n",
      "[[0.00023795 0.00820731]\n",
      " [0.00048201 0.00170686]\n",
      " [0.00058629 0.00120698]\n",
      " [0.00035088 0.00076627]\n",
      " [0.00028954 0.00034598]\n",
      " [0.00020271 0.00017407]\n",
      " [0.00012642 0.00014359]\n",
      " [0.00013454 0.00014019]\n",
      " [0.00012005 0.00015749]]\n",
      "Train Epoch65 out_loss 0.0011373807210475206\n",
      "Test Epoch65 layer0 out_loss 0.0040552131831645966\n",
      "Test Epoch65 layer1 out_loss 0.0008646037895232439\n",
      "Test Epoch65 layer2 out_loss 0.000554045953322202\n",
      "Test Epoch65 layer3 out_loss 0.00043708947487175465\n",
      "Test Epoch65 layer4 out_loss 0.0006734744529239833\n",
      "Test Epoch65 layer5 out_loss 0.0005329482955858111\n",
      "Test Epoch65 layer6 out_loss 0.0004260842688381672\n",
      "Test Epoch65 layer7 out_loss 0.00043946458026766777\n",
      "Test Epoch65 layer8 out_loss 0.00044301265734247863\n",
      "Train 66 | out_loss 0.0015769362216815352: 100%|█| 138/138 [00:01<00:00, 118.76i\n",
      "[[5.34211779e-04 1.14906817e-02]\n",
      " [4.36178505e-04 1.90247291e-03]\n",
      " [4.81399020e-04 1.24826605e-03]\n",
      " [2.92380987e-04 6.17989325e-04]\n",
      " [2.39424212e-04 3.44360633e-04]\n",
      " [2.02539251e-04 1.86256156e-04]\n",
      " [1.49094491e-04 1.45909240e-04]\n",
      " [1.38455112e-04 1.28136061e-04]\n",
      " [9.64270782e-05 1.15029335e-04]]\n",
      "Train Epoch66 out_loss 0.0015769362216815352\n",
      "Test Epoch66 layer0 out_loss 0.00676474254578352\n",
      "Test Epoch66 layer1 out_loss 0.0010689040645956993\n",
      "Test Epoch66 layer2 out_loss 0.0007774386322125793\n",
      "Test Epoch66 layer3 out_loss 0.0004293512611184269\n",
      "Test Epoch66 layer4 out_loss 0.0004503566597122699\n",
      "Test Epoch66 layer5 out_loss 0.0004891255521215498\n",
      "Test Epoch66 layer6 out_loss 0.00045993211097083986\n",
      "Test Epoch66 layer7 out_loss 0.0007216302328743041\n",
      "Test Epoch66 layer8 out_loss 0.00045183338806964457\n",
      "Train 67 | out_loss 0.0015070593217387795: 100%|█| 138/138 [00:01<00:00, 111.59i\n",
      "[[0.00043688 0.17022211]\n",
      " [0.00047814 0.00404281]\n",
      " [0.00096301 0.00253509]\n",
      " [0.00053976 0.00107781]\n",
      " [0.00031707 0.00045901]\n",
      " [0.00026376 0.00029388]\n",
      " [0.00023794 0.00027982]\n",
      " [0.00023503 0.00022762]\n",
      " [0.00018077 0.00019147]]\n",
      "Train Epoch67 out_loss 0.0015070593217387795\n",
      "Test Epoch67 layer0 out_loss 0.03633532300591469\n",
      "Test Epoch67 layer1 out_loss 0.001349335303530097\n",
      "Test Epoch67 layer2 out_loss 0.0004971114103682339\n",
      "Test Epoch67 layer3 out_loss 0.0006976632867008448\n",
      "Test Epoch67 layer4 out_loss 0.0005838113720528781\n",
      "Test Epoch67 layer5 out_loss 0.0007842328632250428\n",
      "Test Epoch67 layer6 out_loss 0.000487359007820487\n",
      "Test Epoch67 layer7 out_loss 0.0009375696536153555\n",
      "Test Epoch67 layer8 out_loss 0.0005970211350359023\n",
      "Train 68 | out_loss 0.0013346446212381124: 100%|█| 138/138 [00:01<00:00, 112.59i\n",
      "[[0.00035301 0.07363907]\n",
      " [0.00039521 0.00211809]\n",
      " [0.0004292  0.00146672]\n",
      " [0.00035945 0.00068909]\n",
      " [0.00025663 0.00043703]\n",
      " [0.00028424 0.00033062]\n",
      " [0.00032955 0.00034478]\n",
      " [0.00035084 0.00037743]\n",
      " [0.0003118  0.00034393]]\n",
      "Train Epoch68 out_loss 0.0013346446212381124\n",
      "Test Epoch68 layer0 out_loss 0.0033709113486111164\n",
      "Test Epoch68 layer1 out_loss 0.0011920573888346553\n",
      "Test Epoch68 layer2 out_loss 0.0006527036312036216\n",
      "Test Epoch68 layer3 out_loss 0.000610288348980248\n",
      "Test Epoch68 layer4 out_loss 0.0006893871468491852\n",
      "Test Epoch68 layer5 out_loss 0.000565186666790396\n",
      "Test Epoch68 layer6 out_loss 0.0013335924595594406\n",
      "Test Epoch68 layer7 out_loss 0.0004600789106916636\n",
      "Test Epoch68 layer8 out_loss 0.0008687682566232979\n",
      "Train 69 | out_loss 0.0012096016434952617: 100%|█| 138/138 [00:01<00:00, 119.83i\n",
      "[[0.00026774 0.01021793]\n",
      " [0.00049518 0.00176071]\n",
      " [0.00051897 0.0012129 ]\n",
      " [0.00032591 0.00067896]\n",
      " [0.00025662 0.00035446]\n",
      " [0.00029443 0.00027852]\n",
      " [0.00028886 0.00033488]\n",
      " [0.00020559 0.00022638]\n",
      " [0.00013657 0.00015057]]\n",
      "Train Epoch69 out_loss 0.0012096016434952617\n",
      "Test Epoch69 layer0 out_loss 0.0038228360936045647\n",
      "Test Epoch69 layer1 out_loss 0.0013116414193063974\n",
      "Test Epoch69 layer2 out_loss 0.0007121653761714697\n",
      "Test Epoch69 layer3 out_loss 0.0004613202763721347\n",
      "Test Epoch69 layer4 out_loss 0.0005180767038837075\n",
      "Test Epoch69 layer5 out_loss 0.0009606534149497747\n",
      "Test Epoch69 layer6 out_loss 0.000644052168354392\n",
      "Test Epoch69 layer7 out_loss 0.000760406837798655\n",
      "Test Epoch69 layer8 out_loss 0.000606335757765919\n",
      "Train 70 | out_loss 0.0015845063608139753: 100%|█| 138/138 [00:01<00:00, 122.61i\n",
      "[[5.44704583e-04 1.83996332e-02]\n",
      " [3.96692078e-04 1.82909627e-03]\n",
      " [4.94102107e-04 1.28159788e-03]\n",
      " [3.36428470e-04 7.21207256e-04]\n",
      " [2.83308682e-04 3.38862965e-04]\n",
      " [2.53747296e-04 2.40799574e-04]\n",
      " [1.20866168e-04 1.06475456e-04]\n",
      " [9.20280431e-05 9.46398966e-05]\n",
      " [5.69768197e-05 7.18314838e-05]]\n",
      "Train Epoch70 out_loss 0.0015845063608139753\n",
      "Test Epoch70 layer0 out_loss 0.003429318778216839\n",
      "Test Epoch70 layer1 out_loss 0.001260328688658774\n",
      "Test Epoch70 layer2 out_loss 0.0007943838136270642\n",
      "Test Epoch70 layer3 out_loss 0.000804568117018789\n",
      "Test Epoch70 layer4 out_loss 0.0005149889038875699\n",
      "Test Epoch70 layer5 out_loss 0.0005462782573886216\n",
      "Test Epoch70 layer6 out_loss 0.000580065418034792\n",
      "Test Epoch70 layer7 out_loss 0.00068333261879161\n",
      "Test Epoch70 layer8 out_loss 0.0006400785059668124\n",
      "Train 71 | out_loss 0.0013775968691334128: 100%|█| 138/138 [00:01<00:00, 121.62i\n",
      "[[3.54394697e-04 6.64423242e-03]\n",
      " [3.69081932e-04 1.51762375e-03]\n",
      " [4.77572453e-04 1.70755283e-03]\n",
      " [3.87859229e-04 7.13827110e-04]\n",
      " [2.96794624e-04 4.01511708e-04]\n",
      " [3.25689910e-04 2.94658979e-04]\n",
      " [1.87693340e-04 1.51911660e-04]\n",
      " [1.31771665e-04 1.22482193e-04]\n",
      " [7.07960801e-05 8.88302458e-05]]\n",
      "Train Epoch71 out_loss 0.0013775968691334128\n",
      "Test Epoch71 layer0 out_loss 0.004099181387573481\n",
      "Test Epoch71 layer1 out_loss 0.0005477354279719293\n",
      "Test Epoch71 layer2 out_loss 0.000751162355300039\n",
      "Test Epoch71 layer3 out_loss 0.000696711940690875\n",
      "Test Epoch71 layer4 out_loss 0.000592001888435334\n",
      "Test Epoch71 layer5 out_loss 0.0004487306287046522\n",
      "Test Epoch71 layer6 out_loss 0.000767068937420845\n",
      "Test Epoch71 layer7 out_loss 0.0006022507441230118\n",
      "Test Epoch71 layer8 out_loss 0.0006328920135274529\n",
      "Train 72 | out_loss 0.001482505234889686: 100%|█| 138/138 [00:01<00:00, 123.09it\n",
      "[[0.00045337 0.08457229]\n",
      " [0.00042411 0.00368313]\n",
      " [0.00058592 0.00164831]\n",
      " [0.00034981 0.00074463]\n",
      " [0.00025031 0.00044564]\n",
      " [0.00027637 0.00031017]\n",
      " [0.00019313 0.00017564]\n",
      " [0.00017528 0.00017954]\n",
      " [0.00010827 0.00012813]]\n",
      "Train Epoch72 out_loss 0.001482505234889686\n",
      "Test Epoch72 layer0 out_loss 0.0034038464073091745\n",
      "Test Epoch72 layer1 out_loss 0.0016311554936692119\n",
      "Test Epoch72 layer2 out_loss 0.0008277521119453013\n",
      "Test Epoch72 layer3 out_loss 0.0006760889082215726\n",
      "Test Epoch72 layer4 out_loss 0.0005961987772025168\n",
      "Test Epoch72 layer5 out_loss 0.0008793743909336627\n",
      "Test Epoch72 layer6 out_loss 0.0008895205100998282\n",
      "Test Epoch72 layer7 out_loss 0.0009640209027566016\n",
      "Test Epoch72 layer8 out_loss 0.0009677934576757252\n",
      "Train 73 | out_loss 0.0007855463190935552: 100%|█| 138/138 [00:01<00:00, 117.54i\n",
      "[[7.73397082e-05 1.48210727e-02]\n",
      " [4.10994349e-04 1.79669797e-03]\n",
      " [5.43606431e-04 1.58036646e-03]\n",
      " [3.49712743e-04 5.56725693e-04]\n",
      " [2.11602662e-04 2.23747819e-04]\n",
      " [1.32690763e-04 1.03173102e-04]\n",
      " [7.08096990e-05 6.48951914e-05]\n",
      " [7.45327879e-05 7.96122140e-05]\n",
      " [6.39825448e-05 9.29065124e-05]]\n",
      "Train Epoch73 out_loss 0.0007855463190935552\n",
      "Test Epoch73 layer0 out_loss 0.01514508482068777\n",
      "Test Epoch73 layer1 out_loss 0.004155507776886225\n",
      "Test Epoch73 layer2 out_loss 0.0027218563482165337\n",
      "Test Epoch73 layer3 out_loss 0.002547613810747862\n",
      "Test Epoch73 layer4 out_loss 0.0025263989809900522\n",
      "Test Epoch73 layer5 out_loss 0.002860383363440633\n",
      "Test Epoch73 layer6 out_loss 0.002778333146125078\n",
      "Test Epoch73 layer7 out_loss 0.0028178957290947437\n",
      "Test Epoch73 layer8 out_loss 0.0027366026770323515\n",
      "Train 74 | out_loss 0.0015904864994809031: 100%|█| 138/138 [00:01<00:00, 123.80i\n",
      "[[5.41237779e-04 1.12857976e-02]\n",
      " [3.78321822e-04 1.68945101e-03]\n",
      " [4.61766324e-04 1.25827293e-03]\n",
      " [2.61657894e-04 5.00747978e-04]\n",
      " [1.77774721e-04 2.25861969e-04]\n",
      " [1.35964032e-04 1.16791067e-04]\n",
      " [7.93977050e-05 7.57917396e-05]\n",
      " [7.56847520e-05 7.73648884e-05]\n",
      " [5.98674455e-05 8.32219110e-05]]\n",
      "Train Epoch74 out_loss 0.0015904864994809031\n",
      "Test Epoch74 layer0 out_loss 0.004254292696714401\n",
      "Test Epoch74 layer1 out_loss 0.0006672446615993977\n",
      "Test Epoch74 layer2 out_loss 0.0004617957165464759\n",
      "Test Epoch74 layer3 out_loss 0.0004377572622615844\n",
      "Test Epoch74 layer4 out_loss 0.000421409698901698\n",
      "Test Epoch74 layer5 out_loss 0.0005958934198133647\n",
      "Test Epoch74 layer6 out_loss 0.000622148101683706\n",
      "Test Epoch74 layer7 out_loss 0.0005608380306512117\n",
      "Test Epoch74 layer8 out_loss 0.0006551601109094918\n",
      "Train 75 | out_loss 0.0013429372338578105: 100%|█| 138/138 [00:01<00:00, 121.02i\n",
      "[[0.00036822 0.07252681]\n",
      " [0.00040776 0.00370673]\n",
      " [0.00063114 0.00164577]\n",
      " [0.00039001 0.00069853]\n",
      " [0.00020716 0.00028236]\n",
      " [0.00015485 0.00016534]\n",
      " [0.00012032 0.00012961]\n",
      " [0.00014998 0.00015707]\n",
      " [0.00012445 0.00016503]]\n",
      "Train Epoch75 out_loss 0.0013429372338578105\n",
      "Test Epoch75 layer0 out_loss 0.004680552054196596\n",
      "Test Epoch75 layer1 out_loss 0.0010402880143374205\n",
      "Test Epoch75 layer2 out_loss 0.0009192695142701268\n",
      "Test Epoch75 layer3 out_loss 0.000879709143191576\n",
      "Test Epoch75 layer4 out_loss 0.0006385835586115718\n",
      "Test Epoch75 layer5 out_loss 0.0006960567552596331\n",
      "Test Epoch75 layer6 out_loss 0.0006868066266179085\n",
      "Test Epoch75 layer7 out_loss 0.000597342208493501\n",
      "Test Epoch75 layer8 out_loss 0.000644835177809\n",
      "Train 76 | out_loss 0.0015192651189863682: 100%|█| 138/138 [00:01<00:00, 119.57i\n",
      "[[4.78586056e-04 1.01057438e-01]\n",
      " [5.10736101e-04 3.26683901e-03]\n",
      " [7.08516784e-04 1.95072955e-03]\n",
      " [4.38720454e-04 8.47075862e-04]\n",
      " [2.48679827e-04 3.14775977e-04]\n",
      " [1.49342158e-04 1.42095100e-04]\n",
      " [8.95859543e-05 1.01643925e-04]\n",
      " [7.49116658e-05 8.77469636e-05]\n",
      " [7.19493367e-05 1.05852885e-04]]\n",
      "Train Epoch76 out_loss 0.0015192651189863682\n",
      "Test Epoch76 layer0 out_loss 0.005374503321945667\n",
      "Test Epoch76 layer1 out_loss 0.0009018175769597292\n",
      "Test Epoch76 layer2 out_loss 0.0014101762790232897\n",
      "Test Epoch76 layer3 out_loss 0.0008237704751081765\n",
      "Test Epoch76 layer4 out_loss 0.0009029488428495824\n",
      "Test Epoch76 layer5 out_loss 0.0007382331532426178\n",
      "Test Epoch76 layer6 out_loss 0.0006102532497607172\n",
      "Test Epoch76 layer7 out_loss 0.0007198858074843884\n",
      "Test Epoch76 layer8 out_loss 0.000691436929628253\n",
      "Train 77 | out_loss 0.0011923514539375901: 100%|█| 138/138 [00:01<00:00, 121.46i\n",
      "[[0.0002383  0.02258326]\n",
      " [0.00034291 0.00213483]\n",
      " [0.00051736 0.00184833]\n",
      " [0.00054191 0.00099153]\n",
      " [0.00036856 0.00051143]\n",
      " [0.0003216  0.00031621]\n",
      " [0.00023581 0.00024168]\n",
      " [0.00024979 0.00025056]\n",
      " [0.0002098  0.00024641]]\n",
      "Train Epoch77 out_loss 0.0011923514539375901\n",
      "Test Epoch77 layer0 out_loss 0.004652491305023432\n",
      "Test Epoch77 layer1 out_loss 0.0016353754326701164\n",
      "Test Epoch77 layer2 out_loss 0.0005182983004488051\n",
      "Test Epoch77 layer3 out_loss 0.0006113499402999878\n",
      "Test Epoch77 layer4 out_loss 0.0006661582156084478\n",
      "Test Epoch77 layer5 out_loss 0.0005536938551813364\n",
      "Test Epoch77 layer6 out_loss 0.0004439815820660442\n",
      "Test Epoch77 layer7 out_loss 0.0007137383217923343\n",
      "Test Epoch77 layer8 out_loss 0.0005686905351467431\n",
      "Train 78 | out_loss 0.00149213254917413: 100%|█| 138/138 [00:01<00:00, 121.72it/\n",
      "[[0.00042851 0.00694361]\n",
      " [0.00031502 0.00131048]\n",
      " [0.00042864 0.00081963]\n",
      " [0.00023479 0.00044098]\n",
      " [0.00019373 0.00030625]\n",
      " [0.00019022 0.00020664]\n",
      " [0.00017232 0.0001992 ]\n",
      " [0.00018911 0.000162  ]\n",
      " [0.00010056 0.00013764]]\n",
      "Train Epoch78 out_loss 0.00149213254917413\n",
      "Test Epoch78 layer0 out_loss 0.0028336045797914267\n",
      "Test Epoch78 layer1 out_loss 0.0010042625945061445\n",
      "Test Epoch78 layer2 out_loss 0.0004212809435557574\n",
      "Test Epoch78 layer3 out_loss 0.0004309900978114456\n",
      "Test Epoch78 layer4 out_loss 0.0004279236018192023\n",
      "Test Epoch78 layer5 out_loss 0.0004218394751660526\n",
      "Test Epoch78 layer6 out_loss 0.00042449808097444475\n",
      "Test Epoch78 layer7 out_loss 0.0004294291720725596\n",
      "Test Epoch78 layer8 out_loss 0.0004313535464461893\n",
      "Train 79 | out_loss 0.001478990656323731: 100%|█| 138/138 [00:01<00:00, 122.85it\n",
      "[[4.37588573e-04 3.18631039e-03]\n",
      " [3.97990785e-04 1.41630107e-03]\n",
      " [5.06565712e-04 1.08517284e-03]\n",
      " [2.92305419e-04 4.14834159e-04]\n",
      " [2.01236393e-04 2.28780440e-04]\n",
      " [1.44446081e-04 1.34739922e-04]\n",
      " [1.06156749e-04 1.16217150e-04]\n",
      " [9.91926756e-05 9.62208610e-05]\n",
      " [7.19042118e-05 8.66426857e-05]]\n",
      "Train Epoch79 out_loss 0.001478990656323731\n",
      "Test Epoch79 layer0 out_loss 0.0040641045197844505\n",
      "Test Epoch79 layer1 out_loss 0.0006408343324437737\n",
      "Test Epoch79 layer2 out_loss 0.00047415567678399384\n",
      "Test Epoch79 layer3 out_loss 0.0005475975922308862\n",
      "Test Epoch79 layer4 out_loss 0.000484137621242553\n",
      "Test Epoch79 layer5 out_loss 0.00043848270433954895\n",
      "Test Epoch79 layer6 out_loss 0.00043617410119622946\n",
      "Test Epoch79 layer7 out_loss 0.0005327634862624109\n",
      "Test Epoch79 layer8 out_loss 0.0004499843344092369\n",
      "Train 80 | out_loss 0.0013929881388321519: 100%|█| 138/138 [00:01<00:00, 119.46i\n",
      "[[3.78271465e-04 1.21990399e-01]\n",
      " [3.33878621e-04 3.96458786e-03]\n",
      " [3.85268557e-04 1.37192005e-03]\n",
      " [1.90972696e-04 4.94347549e-04]\n",
      " [1.48009093e-04 3.34336964e-04]\n",
      " [1.62206794e-04 1.95250108e-04]\n",
      " [1.29740763e-04 1.42131332e-04]\n",
      " [1.04220990e-04 1.05306801e-04]\n",
      " [7.32357192e-05 9.11317953e-05]]\n",
      "Train Epoch80 out_loss 0.0013929881388321519\n",
      "Test Epoch80 layer0 out_loss 0.008345428854227066\n",
      "Test Epoch80 layer1 out_loss 0.003442104673013091\n",
      "Test Epoch80 layer2 out_loss 0.0031236731447279453\n",
      "Test Epoch80 layer3 out_loss 0.0030533610843122005\n",
      "Test Epoch80 layer4 out_loss 0.0034619325306266546\n",
      "Test Epoch80 layer5 out_loss 0.002969955326989293\n",
      "Test Epoch80 layer6 out_loss 0.003106864169239998\n",
      "Test Epoch80 layer7 out_loss 0.002872454933822155\n",
      "Test Epoch80 layer8 out_loss 0.003087818855419755\n",
      "Train 81 | out_loss 0.0007102058152668178: 100%|█| 138/138 [00:01<00:00, 124.29i\n",
      "[[8.85328841e-05 4.39995686e-03]\n",
      " [3.72612629e-04 1.46694136e-03]\n",
      " [5.29323042e-04 1.37262401e-03]\n",
      " [2.89670577e-04 6.51193996e-04]\n",
      " [2.80642328e-04 3.40442856e-04]\n",
      " [2.36645538e-04 1.75925844e-04]\n",
      " [1.21989984e-04 1.01723794e-04]\n",
      " [7.23690094e-05 6.80663873e-05]\n",
      " [4.80288086e-05 6.04092510e-05]]\n",
      "Train Epoch81 out_loss 0.0007102058152668178\n",
      "Test Epoch81 layer0 out_loss 0.0027685503009706736\n",
      "Test Epoch81 layer1 out_loss 0.000760611321311444\n",
      "Test Epoch81 layer2 out_loss 0.0009130125399678946\n",
      "Test Epoch81 layer3 out_loss 0.0005627675564028323\n",
      "Test Epoch81 layer4 out_loss 0.0006468524807132781\n",
      "Test Epoch81 layer5 out_loss 0.0004748131614178419\n",
      "Test Epoch81 layer6 out_loss 0.00045517945545725524\n",
      "Test Epoch81 layer7 out_loss 0.0004771194653585553\n",
      "Test Epoch81 layer8 out_loss 0.000497996574267745\n",
      "Train 82 | out_loss 0.0014312014682218432: 100%|█| 138/138 [00:01<00:00, 118.06i\n",
      "[[4.18783371e-04 5.14191193e-03]\n",
      " [3.16745571e-04 1.12977229e-03]\n",
      " [3.80818069e-04 7.73273712e-04]\n",
      " [1.94174576e-04 4.06430153e-04]\n",
      " [1.71800513e-04 2.13656799e-04]\n",
      " [1.52100369e-04 1.45611392e-04]\n",
      " [1.23001170e-04 9.45899664e-05]\n",
      " [6.30983949e-05 7.00336656e-05]\n",
      " [4.86474473e-05 7.41408052e-05]]\n",
      "Train Epoch82 out_loss 0.0014312014682218432\n",
      "Test Epoch82 layer0 out_loss 0.004671717062592506\n",
      "Test Epoch82 layer1 out_loss 0.0005651538958773017\n",
      "Test Epoch82 layer2 out_loss 0.0006808811449445784\n",
      "Test Epoch82 layer3 out_loss 0.0005389592843130231\n",
      "Test Epoch82 layer4 out_loss 0.00046892775571905077\n",
      "Test Epoch82 layer5 out_loss 0.000508749159052968\n",
      "Test Epoch82 layer6 out_loss 0.0004977092612534761\n",
      "Test Epoch82 layer7 out_loss 0.0005333434673957527\n",
      "Test Epoch82 layer8 out_loss 0.0005082543939352036\n",
      "Train 83 | out_loss 0.001306750113144517: 100%|█| 138/138 [00:01<00:00, 118.57it\n",
      "[[0.00030938 0.00387982]\n",
      " [0.00047828 0.00200699]\n",
      " [0.00082613 0.0031416 ]\n",
      " [0.00097263 0.00152044]\n",
      " [0.00112707 0.00132968]\n",
      " [0.00053922 0.00042095]\n",
      " [0.00029104 0.00023357]\n",
      " [0.00017593 0.00019191]\n",
      " [0.00014047 0.00019449]]\n",
      "Train Epoch83 out_loss 0.001306750113144517\n",
      "Test Epoch83 layer0 out_loss 0.006411659996956587\n",
      "Test Epoch83 layer1 out_loss 0.0013799414737150073\n",
      "Test Epoch83 layer2 out_loss 0.0005054608336649835\n",
      "Test Epoch83 layer3 out_loss 0.0008621889865025878\n",
      "Test Epoch83 layer4 out_loss 0.0013827052898705006\n",
      "Test Epoch83 layer5 out_loss 0.0009401619900017977\n",
      "Test Epoch83 layer6 out_loss 0.0010399158345535398\n",
      "Test Epoch83 layer7 out_loss 0.0009855201933532953\n",
      "Test Epoch83 layer8 out_loss 0.0009231344447471201\n",
      "Train 84 | out_loss 0.0019418400479480624: 100%|█| 138/138 [00:01<00:00, 116.61i\n",
      "[[0.00039772 0.03174546]\n",
      " [0.0002546  0.00255888]\n",
      " [0.00038974 0.00101848]\n",
      " [0.0002105  0.00055985]\n",
      " [0.00052151 0.00116929]\n",
      " [0.00123124 0.00229269]\n",
      " [0.0021907  0.00405957]\n",
      " [0.00363546 0.00690684]\n",
      " [0.00726588 0.016751  ]]\n",
      "Train Epoch84 out_loss 0.0019418400479480624\n",
      "Test Epoch84 layer0 out_loss 0.008027423173189163\n",
      "Test Epoch84 layer1 out_loss 0.0013876830926164985\n",
      "Test Epoch84 layer2 out_loss 0.0005469719180837274\n",
      "Test Epoch84 layer3 out_loss 0.0004654600634239614\n",
      "Test Epoch84 layer4 out_loss 0.0004655818338505924\n",
      "Test Epoch84 layer5 out_loss 0.0004990138113498688\n",
      "Test Epoch84 layer6 out_loss 0.0005264366045594215\n",
      "Test Epoch84 layer7 out_loss 0.0004904066445305943\n",
      "Test Epoch84 layer8 out_loss 0.0005453541525639594\n",
      "Train 85 | out_loss 0.0016687088645994663: 100%|█| 138/138 [00:01<00:00, 122.71i\n",
      "[[5.40911724e-04 1.27993516e-02]\n",
      " [3.70204443e-04 1.98396390e-03]\n",
      " [4.30997269e-04 7.63926882e-04]\n",
      " [2.03037086e-04 3.27993109e-04]\n",
      " [1.24590754e-04 1.27881642e-04]\n",
      " [8.37549612e-05 7.63086704e-05]\n",
      " [6.14536841e-05 6.70600437e-05]\n",
      " [4.75991517e-05 7.38528859e-05]\n",
      " [4.79496429e-05 1.70178714e-04]]\n",
      "Train Epoch85 out_loss 0.0016687088645994663\n",
      "Test Epoch85 layer0 out_loss 0.00222252169623971\n",
      "Test Epoch85 layer1 out_loss 0.0005872054607607424\n",
      "Test Epoch85 layer2 out_loss 0.0007052019936963916\n",
      "Test Epoch85 layer3 out_loss 0.00041682241135276854\n",
      "Test Epoch85 layer4 out_loss 0.0004225913726259023\n",
      "Test Epoch85 layer5 out_loss 0.00043135054875165224\n",
      "Test Epoch85 layer6 out_loss 0.00044889302807860076\n",
      "Test Epoch85 layer7 out_loss 0.00042676887824200094\n",
      "Test Epoch85 layer8 out_loss 0.00043952721171081066\n",
      "Train 86 | out_loss 0.0013531565200537443: 100%|█| 138/138 [00:01<00:00, 120.62i\n",
      "[[3.50578434e-04 1.06237545e-02]\n",
      " [3.03077327e-04 1.99382247e-03]\n",
      " [4.34768549e-04 9.02002873e-04]\n",
      " [2.28300378e-04 3.63877606e-04]\n",
      " [1.33827369e-04 1.25357765e-04]\n",
      " [8.64375617e-05 7.30296182e-05]\n",
      " [5.37767702e-05 5.52206598e-05]\n",
      " [3.51783169e-05 5.20188934e-05]\n",
      " [2.99884205e-05 9.19307250e-05]]\n",
      "Train Epoch86 out_loss 0.0013531565200537443\n",
      "Test Epoch86 layer0 out_loss 0.017149653285741806\n",
      "Test Epoch86 layer1 out_loss 0.0008737100288271904\n",
      "Test Epoch86 layer2 out_loss 0.0005342891672626138\n",
      "Test Epoch86 layer3 out_loss 0.000624073320068419\n",
      "Test Epoch86 layer4 out_loss 0.0005112056969664991\n",
      "Test Epoch86 layer5 out_loss 0.0005473784985952079\n",
      "Test Epoch86 layer6 out_loss 0.0004969298606738448\n",
      "Test Epoch86 layer7 out_loss 0.0005603129975497723\n",
      "Test Epoch86 layer8 out_loss 0.0005625378107652068\n",
      "Train 87 | out_loss 0.0013442510971799493: 100%|█| 138/138 [00:01<00:00, 113.89i\n",
      "[[3.40903327e-04 7.68953240e-02]\n",
      " [3.78800102e-04 4.02875360e-03]\n",
      " [4.62823225e-04 1.21484118e-03]\n",
      " [2.43882710e-04 5.53374034e-04]\n",
      " [1.74517244e-04 2.02264661e-04]\n",
      " [9.43979726e-05 9.37794084e-05]\n",
      " [5.56334440e-05 7.97767013e-05]\n",
      " [6.23519640e-05 7.15840789e-05]\n",
      " [4.24158279e-05 1.22580760e-04]]\n",
      "Train Epoch87 out_loss 0.0013442510971799493\n",
      "Test Epoch87 layer0 out_loss 0.008923494257032871\n",
      "Test Epoch87 layer1 out_loss 0.0005561786238104105\n",
      "Test Epoch87 layer2 out_loss 0.00044536564382724464\n",
      "Test Epoch87 layer3 out_loss 0.0005541872815228999\n",
      "Test Epoch87 layer4 out_loss 0.00046611903235316277\n",
      "Test Epoch87 layer5 out_loss 0.0005264085484668612\n",
      "Test Epoch87 layer6 out_loss 0.0004305352340452373\n",
      "Test Epoch87 layer7 out_loss 0.0004554550687316805\n",
      "Test Epoch87 layer8 out_loss 0.0004451680579222739\n",
      "Train 88 | out_loss 0.0018646626267582178: 100%|█| 138/138 [00:01<00:00, 118.86i\n",
      "[[7.07468827e-04 1.43131410e-02]\n",
      " [3.90748991e-04 2.14431467e-03]\n",
      " [7.33503229e-04 2.83873771e-03]\n",
      " [8.21563408e-04 1.20928734e-03]\n",
      " [4.84367839e-04 4.24735093e-04]\n",
      " [2.04865352e-04 1.64549299e-04]\n",
      " [1.06077589e-04 1.12423017e-04]\n",
      " [8.96510866e-05 1.06449675e-04]\n",
      " [6.74025015e-05 1.59708438e-04]]\n",
      "Train Epoch88 out_loss 0.0018646626267582178\n",
      "Test Epoch88 layer0 out_loss 0.0022305715829133987\n",
      "Test Epoch88 layer1 out_loss 0.0007895119488239288\n",
      "Test Epoch88 layer2 out_loss 0.0004247101314831525\n",
      "Test Epoch88 layer3 out_loss 0.000442536169430241\n",
      "Test Epoch88 layer4 out_loss 0.0004107880231458694\n",
      "Test Epoch88 layer5 out_loss 0.0004361966566648334\n",
      "Test Epoch88 layer6 out_loss 0.0004302037414163351\n",
      "Test Epoch88 layer7 out_loss 0.0004215126973576844\n",
      "Test Epoch88 layer8 out_loss 0.00042379589285701513\n",
      "Train 89 | out_loss 0.0004699814599007368: 100%|█| 138/138 [00:01<00:00, 118.03i\n",
      "[[1.30391686e-06 4.57828260e-03]\n",
      " [2.89951770e-04 1.19390601e-03]\n",
      " [3.77549824e-04 5.95168708e-04]\n",
      " [2.07163321e-04 3.41674268e-04]\n",
      " [1.58545767e-04 1.78547774e-04]\n",
      " [1.58239999e-04 1.11571959e-04]\n",
      " [8.98176746e-05 7.91334487e-05]\n",
      " [6.11964162e-05 7.07138794e-05]\n",
      " [3.79647038e-05 1.04801714e-04]]\n",
      "Train Epoch89 out_loss 0.0004699814599007368\n",
      "Test Epoch89 layer0 out_loss 0.0034613737370818853\n",
      "Test Epoch89 layer1 out_loss 0.000939267803914845\n",
      "Test Epoch89 layer2 out_loss 0.00040821198490448296\n",
      "Test Epoch89 layer3 out_loss 0.0004399167955853045\n",
      "Test Epoch89 layer4 out_loss 0.0004215322551317513\n",
      "Test Epoch89 layer5 out_loss 0.0004977153148502111\n",
      "Test Epoch89 layer6 out_loss 0.00043217078200541437\n",
      "Test Epoch89 layer7 out_loss 0.000450912892119959\n",
      "Test Epoch89 layer8 out_loss 0.0004394768038764596\n",
      "Train 90 | out_loss 0.0013951265718787909: 100%|█| 138/138 [00:01<00:00, 116.72i\n",
      "[[4.07163769e-04 2.44032420e-02]\n",
      " [3.32498173e-04 2.36628487e-03]\n",
      " [4.48643400e-04 9.84531853e-04]\n",
      " [2.13141037e-04 4.16459390e-04]\n",
      " [1.81412460e-04 2.48856317e-04]\n",
      " [2.09451255e-04 1.57024101e-04]\n",
      " [1.16798746e-04 1.02448460e-04]\n",
      " [7.24448378e-05 8.72904171e-05]\n",
      " [4.75304564e-05 1.53034808e-04]]\n",
      "Train Epoch90 out_loss 0.0013951265718787909\n",
      "Test Epoch90 layer0 out_loss 0.010538621805608273\n",
      "Test Epoch90 layer1 out_loss 0.0006363109569065273\n",
      "Test Epoch90 layer2 out_loss 0.00043024049955420196\n",
      "Test Epoch90 layer3 out_loss 0.0005024743149988353\n",
      "Test Epoch90 layer4 out_loss 0.0006389007903635502\n",
      "Test Epoch90 layer5 out_loss 0.00045239165774546564\n",
      "Test Epoch90 layer6 out_loss 0.0004702589358203113\n",
      "Test Epoch90 layer7 out_loss 0.00046784908045083284\n",
      "Test Epoch90 layer8 out_loss 0.000437633105320856\n",
      "Train 91 | out_loss 0.0015053797978907824: 100%|█| 138/138 [00:01<00:00, 113.53i\n",
      "[[4.40994277e-04 2.57707046e-02]\n",
      " [2.72224461e-04 2.26320125e-03]\n",
      " [3.24461243e-04 8.66372929e-04]\n",
      " [2.29512179e-04 3.82987160e-04]\n",
      " [1.76901281e-04 2.13035348e-04]\n",
      " [1.21805030e-04 1.45394760e-04]\n",
      " [1.16056924e-04 1.12015107e-04]\n",
      " [7.58923938e-05 9.10493226e-05]\n",
      " [4.43053742e-05 1.27872712e-04]]\n",
      "Train Epoch91 out_loss 0.0015053797978907824\n",
      "Test Epoch91 layer0 out_loss 0.00226274854503572\n",
      "Test Epoch91 layer1 out_loss 0.0006022430607117712\n",
      "Test Epoch91 layer2 out_loss 0.0004266088653821498\n",
      "Test Epoch91 layer3 out_loss 0.0004623306158464402\n",
      "Test Epoch91 layer4 out_loss 0.00042191005195491016\n",
      "Test Epoch91 layer5 out_loss 0.0005146476323716342\n",
      "Test Epoch91 layer6 out_loss 0.0004897573380731046\n",
      "Test Epoch91 layer7 out_loss 0.0004925913526676595\n",
      "Test Epoch91 layer8 out_loss 0.0004696271207649261\n",
      "Train 92 | out_loss 0.001398582593537867: 100%|█| 138/138 [00:01<00:00, 120.98it\n",
      "[[3.73363198e-04 3.39861768e-03]\n",
      " [3.40945114e-04 1.60899751e-03]\n",
      " [3.89891017e-04 7.31284211e-04]\n",
      " [1.94888650e-04 2.68745868e-04]\n",
      " [1.37561840e-04 1.50851066e-04]\n",
      " [1.25681973e-04 9.51085960e-05]\n",
      " [6.62833667e-05 6.32834515e-05]\n",
      " [3.75659231e-05 5.11949778e-05]\n",
      " [2.72887081e-05 6.72397212e-05]]\n",
      "Train Epoch92 out_loss 0.001398582593537867\n",
      "Test Epoch92 layer0 out_loss 0.003136152634397149\n",
      "Test Epoch92 layer1 out_loss 0.00045315653551369905\n",
      "Test Epoch92 layer2 out_loss 0.0005973929655738175\n",
      "Test Epoch92 layer3 out_loss 0.00043326165177859366\n",
      "Test Epoch92 layer4 out_loss 0.00044856034219264984\n",
      "Test Epoch92 layer5 out_loss 0.00044768082443624735\n",
      "Test Epoch92 layer6 out_loss 0.000434199464507401\n",
      "Test Epoch92 layer7 out_loss 0.00043101649498566985\n",
      "Test Epoch92 layer8 out_loss 0.0004396281437948346\n",
      "Train 93 | out_loss 0.0013623933773487806: 100%|█| 138/138 [00:01<00:00, 114.98i\n",
      "[[3.78823023e-04 3.65816165e-02]\n",
      " [2.13725447e-04 2.88953957e-03]\n",
      " [3.82557172e-04 1.37820736e-03]\n",
      " [2.44938320e-04 5.00731587e-04]\n",
      " [2.83901266e-04 3.34819119e-04]\n",
      " [1.93565040e-04 1.57779198e-04]\n",
      " [1.09696100e-04 9.06721038e-05]\n",
      " [5.61970355e-05 7.47584749e-05]\n",
      " [4.03543765e-05 9.31570575e-05]]\n",
      "Train Epoch93 out_loss 0.0013623933773487806\n",
      "Test Epoch93 layer0 out_loss 0.004045541863888502\n",
      "Test Epoch93 layer1 out_loss 0.0008913284400478005\n",
      "Test Epoch93 layer2 out_loss 0.000417762843426317\n",
      "Test Epoch93 layer3 out_loss 0.00042233552085235715\n",
      "Test Epoch93 layer4 out_loss 0.0004588748561218381\n",
      "Test Epoch93 layer5 out_loss 0.00043387647019699216\n",
      "Test Epoch93 layer6 out_loss 0.00045098934788256884\n",
      "Test Epoch93 layer7 out_loss 0.00046894088154658675\n",
      "Test Epoch93 layer8 out_loss 0.00048248001257888973\n",
      "Train 94 | out_loss 0.03326139971613884: 100%|█| 138/138 [00:01<00:00, 115.72it/\n",
      "[[4.27315611e-04 9.16403761e-03]\n",
      " [1.31941505e-02 1.09133529e-01]\n",
      " [4.53387593e-02 1.54740376e-01]\n",
      " [9.01956784e-02 2.09762457e-01]\n",
      " [2.26136788e-01 3.54887335e-01]\n",
      " [4.28614447e-01 5.51419052e-01]\n",
      " [4.38483758e-01 6.28789577e-01]\n",
      " [4.13219134e-01 6.25269137e-01]\n",
      " [4.34230280e-01 6.55939398e-01]]\n",
      "Train Epoch94 out_loss 0.03326139971613884\n",
      "Test Epoch94 layer0 out_loss 0.003333408385515213\n",
      "Test Epoch94 layer1 out_loss 0.002040011575445533\n",
      "Test Epoch94 layer2 out_loss 0.0035321293398737907\n",
      "Test Epoch94 layer3 out_loss 0.003698113840073347\n",
      "Test Epoch94 layer4 out_loss 0.0045413426123559475\n",
      "Test Epoch94 layer5 out_loss 0.0043453555554151535\n",
      "Test Epoch94 layer6 out_loss 0.048725347965955734\n",
      "Test Epoch94 layer7 out_loss 0.09650938212871552\n",
      "Test Epoch94 layer8 out_loss 0.03799000382423401\n",
      "Train 95 | out_loss 0.03200275078415871: 100%|█| 138/138 [00:01<00:00, 117.68it/\n",
      "[[3.85466969e-04 5.00757950e-02]\n",
      " [2.08043917e-05 3.39026121e-03]\n",
      " [1.84486563e-04 3.49035651e-03]\n",
      " [9.11808993e-04 5.40417479e-03]\n",
      " [4.34967876e-03 1.79000582e-02]\n",
      " [1.20727988e-02 6.06502046e-02]\n",
      " [3.59361017e-02 9.01888293e-02]\n",
      " [7.21768634e-02 2.16551871e-01]\n",
      " [1.07817612e-01 1.89103328e-01]]\n",
      "Train Epoch95 out_loss 0.03200275078415871\n",
      "Test Epoch95 layer0 out_loss 0.0033382996916770935\n",
      "Test Epoch95 layer1 out_loss 0.0005868974258191884\n",
      "Test Epoch95 layer2 out_loss 0.0004773041291628033\n",
      "Test Epoch95 layer3 out_loss 0.0006767769227735698\n",
      "Test Epoch95 layer4 out_loss 0.000990866799838841\n",
      "Test Epoch95 layer5 out_loss 0.0008191290544345975\n",
      "Test Epoch95 layer6 out_loss 0.002456424990668893\n",
      "Test Epoch95 layer7 out_loss 0.002186121419072151\n",
      "Test Epoch95 layer8 out_loss 0.00504812179133296\n",
      "Train 96 | out_loss 0.0048061213456094265: 100%|█| 138/138 [00:01<00:00, 117.36i\n",
      "[[4.18000404e-04 8.64686293e-03]\n",
      " [8.01538074e-05 6.59255314e-04]\n",
      " [1.35232407e-04 5.49713132e-04]\n",
      " [3.39735312e-04 6.63604523e-04]\n",
      " [2.78078463e-04 8.35734076e-04]\n",
      " [3.41383929e-04 1.02691570e-03]\n",
      " [5.06562631e-04 1.61430149e-03]\n",
      " [5.87511917e-04 2.18499965e-03]\n",
      " [1.02556751e-03 3.19651449e-03]]\n",
      "Train Epoch96 out_loss 0.0048061213456094265\n",
      "Test Epoch96 layer0 out_loss 0.001832056324928999\n",
      "Test Epoch96 layer1 out_loss 0.0007256341632455587\n",
      "Test Epoch96 layer2 out_loss 0.0008119532139971852\n",
      "Test Epoch96 layer3 out_loss 0.0009878140408545732\n",
      "Test Epoch96 layer4 out_loss 0.0009797147940844297\n",
      "Test Epoch96 layer5 out_loss 0.0009392466745339334\n",
      "Test Epoch96 layer6 out_loss 0.0018313882173970342\n",
      "Test Epoch96 layer7 out_loss 0.001125236856751144\n",
      "Test Epoch96 layer8 out_loss 0.003455810248851776\n",
      "Train 97 | out_loss 0.0031316843815147877: 100%|█| 138/138 [00:01<00:00, 113.15i\n",
      "[[3.38692375e-05 2.36628890e-03]\n",
      " [6.31369096e-06 1.99614596e-04]\n",
      " [4.36002511e-06 1.77761813e-04]\n",
      " [4.24750198e-06 1.86915103e-04]\n",
      " [4.50727943e-06 2.67058117e-04]\n",
      " [5.40334776e-06 3.50925002e-04]\n",
      " [4.99530314e-06 7.18398701e-04]\n",
      " [7.62478824e-06 1.15690939e-03]\n",
      " [1.18614281e-05 1.22042128e-03]]\n",
      "Train Epoch97 out_loss 0.0031316843815147877\n",
      "Test Epoch97 layer0 out_loss 0.0024116188287734985\n",
      "Test Epoch97 layer1 out_loss 0.0017934073694050312\n",
      "Test Epoch97 layer2 out_loss 0.0018968157237395644\n",
      "Test Epoch97 layer3 out_loss 0.0018445424502715468\n",
      "Test Epoch97 layer4 out_loss 0.0018511746311560273\n",
      "Test Epoch97 layer5 out_loss 0.0018486990593373775\n",
      "Test Epoch97 layer6 out_loss 0.0022036232985556126\n",
      "Test Epoch97 layer7 out_loss 0.002035219455137849\n",
      "Test Epoch97 layer8 out_loss 0.0030438117682933807\n",
      "Train 98 | out_loss 0.0031191534362733364: 100%|█| 138/138 [00:01<00:00, 112.68i\n",
      "[[5.04242655e-04 4.13045590e-03]\n",
      " [9.27176446e-05 3.50802844e-04]\n",
      " [1.36243476e-04 3.94674543e-04]\n",
      " [2.84506959e-04 5.20957459e-04]\n",
      " [2.32597016e-04 5.19375174e-04]\n",
      " [2.73964790e-04 6.13916364e-04]\n",
      " [3.72725587e-04 8.85470183e-04]\n",
      " [3.91103084e-04 1.30131752e-03]\n",
      " [5.78582010e-04 1.45292527e-03]]\n",
      "Train Epoch98 out_loss 0.0031191534362733364\n",
      "Test Epoch98 layer0 out_loss 0.003241750644519925\n",
      "Test Epoch98 layer1 out_loss 0.00041996498475782573\n",
      "Test Epoch98 layer2 out_loss 0.0003920033050235361\n",
      "Test Epoch98 layer3 out_loss 0.00044933712342754006\n",
      "Test Epoch98 layer4 out_loss 0.0005969065823592246\n",
      "Test Epoch98 layer5 out_loss 0.0004857525054831058\n",
      "Test Epoch98 layer6 out_loss 0.0011354634771123528\n",
      "Test Epoch98 layer7 out_loss 0.0008497879025526345\n",
      "Test Epoch98 layer8 out_loss 0.002239032881334424\n",
      "Train 99 | out_loss 0.00292225438170135: 100%|█| 138/138 [00:01<00:00, 111.97it/\n",
      "[[5.45718229e-04 3.25448690e-03]\n",
      " [7.20999791e-06 2.00301884e-04]\n",
      " [5.77192509e-06 1.94316484e-04]\n",
      " [4.52111843e-06 1.94188949e-04]\n",
      " [6.30136455e-06 2.05923548e-04]\n",
      " [8.33184965e-06 2.20532917e-04]\n",
      " [5.45047216e-06 4.54043339e-04]\n",
      " [1.23642722e-05 8.39413738e-04]\n",
      " [1.57029325e-05 6.91276289e-04]]\n",
      "Train Epoch99 out_loss 0.00292225438170135\n",
      "Test Epoch99 layer0 out_loss 0.0017163957236334682\n",
      "Test Epoch99 layer1 out_loss 0.0005171409575268626\n",
      "Test Epoch99 layer2 out_loss 0.00041961035458371043\n",
      "Test Epoch99 layer3 out_loss 0.0005303283105604351\n",
      "Test Epoch99 layer4 out_loss 0.000643409148324281\n",
      "Test Epoch99 layer5 out_loss 0.00046819442650303245\n",
      "Test Epoch99 layer6 out_loss 0.0009988660458475351\n",
      "Test Epoch99 layer7 out_loss 0.0007489430718123913\n",
      "Test Epoch99 layer8 out_loss 0.002196995308622718\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Start Training\n",
      "  0%|                                                   | 0/138 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 0.034207869321107864: 100%|█| 138/138 [00:01<00:00, 79.45it/s\n",
      "[[ 0.03036923 27.59988485]\n",
      " [ 1.47151177  9.04567116]\n",
      " [ 1.01649168  4.21404915]\n",
      " [ 0.78874938  2.25183033]\n",
      " [ 0.70377354  1.3824599 ]\n",
      " [ 0.69385449  1.02231035]\n",
      " [ 0.57419085  0.91301889]\n",
      " [ 0.60175531  0.75020591]\n",
      " [ 0.57220295  0.72363118]\n",
      " [ 0.62701474  0.62349533]]\n",
      "Train Epoch0 out_loss 0.034207869321107864\n",
      "Test Epoch0 layer0 out_loss 0.13406267762184143\n",
      "Test Epoch0 layer1 out_loss 0.012473316863179207\n",
      "Test Epoch0 layer2 out_loss 0.005582129582762718\n",
      "Test Epoch0 layer3 out_loss 0.0019087597029283643\n",
      "Test Epoch0 layer4 out_loss 0.001495896722190082\n",
      "Test Epoch0 layer5 out_loss 0.0013149643782526255\n",
      "Test Epoch0 layer6 out_loss 0.007696142420172691\n",
      "Test Epoch0 layer7 out_loss 0.0033170711249113083\n",
      "Test Epoch0 layer8 out_loss 0.001427257782779634\n",
      "Test Epoch0 layer9 out_loss 0.0009615569142624736\n",
      "Train 1 | out_loss 0.0010258316760882735: 100%|█| 138/138 [00:01<00:00, 107.97it\n",
      "[[2.35252863e-05 5.46333106e+00]\n",
      " [5.88550140e-06 2.08082349e-01]\n",
      " [8.77672348e-06 6.18068362e-02]\n",
      " [7.64566612e-05 2.42028806e-02]\n",
      " [4.52048273e-04 9.20010257e-03]\n",
      " [3.52554843e-03 9.48099087e-03]\n",
      " [6.43990344e-03 1.82567441e-02]\n",
      " [1.33262684e-02 1.99044842e-02]\n",
      " [1.33287702e-02 2.08854973e-02]\n",
      " [1.09136397e-02 1.56647597e-02]]\n",
      "Train Epoch1 out_loss 0.0010258316760882735\n",
      "Test Epoch1 layer0 out_loss 0.09172248840332031\n",
      "Test Epoch1 layer1 out_loss 0.008281071670353413\n",
      "Test Epoch1 layer2 out_loss 0.0031450267415493727\n",
      "Test Epoch1 layer3 out_loss 0.0013614650815725327\n",
      "Test Epoch1 layer4 out_loss 0.0008772820583544672\n",
      "Test Epoch1 layer5 out_loss 0.0007159390370361507\n",
      "Test Epoch1 layer6 out_loss 0.0006481258315034211\n",
      "Test Epoch1 layer7 out_loss 0.0005302270292304456\n",
      "Test Epoch1 layer8 out_loss 0.00040344023727811873\n",
      "Test Epoch1 layer9 out_loss 0.00039987152558751404\n",
      "Train 2 | out_loss 0.00042092162766493857: 100%|█| 138/138 [00:01<00:00, 106.47i\n",
      "[[2.34994866e-05 3.17157443e+00]\n",
      " [5.62936978e-06 9.12054607e-02]\n",
      " [1.92388696e-06 2.45493334e-02]\n",
      " [1.18994834e-06 9.11276455e-03]\n",
      " [1.22586462e-06 2.99206319e-03]\n",
      " [9.44463387e-07 1.55619813e-03]\n",
      " [1.06882340e-06 8.65218942e-04]\n",
      " [1.08004991e-06 3.02728600e-04]\n",
      " [8.65433067e-07 1.53033470e-04]\n",
      " [1.16627363e-06 5.08246140e-05]]\n",
      "Train Epoch2 out_loss 0.00042092162766493857\n",
      "Test Epoch2 layer0 out_loss 0.12202951312065125\n",
      "Test Epoch2 layer1 out_loss 0.006681646686047316\n",
      "Test Epoch2 layer2 out_loss 0.002101738238707185\n",
      "Test Epoch2 layer3 out_loss 0.0010110518196597695\n",
      "Test Epoch2 layer4 out_loss 0.000578593579120934\n",
      "Test Epoch2 layer5 out_loss 0.0005631971289403737\n",
      "Test Epoch2 layer6 out_loss 0.0004820001486223191\n",
      "Test Epoch2 layer7 out_loss 0.000473305321065709\n",
      "Test Epoch2 layer8 out_loss 0.0003980924084316939\n",
      "Test Epoch2 layer9 out_loss 0.0004034127341583371\n",
      "Train 3 | out_loss 0.00041660526767373085: 100%|█| 138/138 [00:01<00:00, 103.24i\n",
      "[[2.23596516e-05 1.98771827e+00]\n",
      " [7.11076410e-06 5.11858874e-02]\n",
      " [2.03136928e-06 1.32449272e-02]\n",
      " [9.78909263e-07 4.78741246e-03]\n",
      " [1.45864334e-06 1.72091545e-03]\n",
      " [1.15219523e-06 8.76123135e-04]\n",
      " [1.36443702e-06 4.74864106e-04]\n",
      " [1.30112094e-06 1.71826059e-04]\n",
      " [5.47373272e-07 8.72675105e-05]\n",
      " [4.71509393e-07 2.78629906e-05]]\n",
      "Train Epoch3 out_loss 0.00041660526767373085\n",
      "Test Epoch3 layer0 out_loss 0.04887619987130165\n",
      "Test Epoch3 layer1 out_loss 0.004013261292129755\n",
      "Test Epoch3 layer2 out_loss 0.0018660541391000152\n",
      "Test Epoch3 layer3 out_loss 0.0007713449303992093\n",
      "Test Epoch3 layer4 out_loss 0.000588445458561182\n",
      "Test Epoch3 layer5 out_loss 0.0007023461512289941\n",
      "Test Epoch3 layer6 out_loss 0.0006303840200416744\n",
      "Test Epoch3 layer7 out_loss 0.0004869262920692563\n",
      "Test Epoch3 layer8 out_loss 0.0005155679536983371\n",
      "Test Epoch3 layer9 out_loss 0.0005479580722749233\n",
      "Train 4 | out_loss 0.0004263160517439246: 100%|█| 138/138 [00:01<00:00, 104.56it\n",
      "[[2.31802936e-05 1.20772632e+00]\n",
      " [7.29934134e-06 3.15532467e-02]\n",
      " [2.88535214e-06 8.07540008e-03]\n",
      " [2.41006761e-06 2.91922444e-03]\n",
      " [3.05760811e-06 1.15458166e-03]\n",
      " [2.25664483e-06 6.17790389e-04]\n",
      " [2.78883372e-06 3.33151683e-04]\n",
      " [2.51241650e-06 1.19741423e-04]\n",
      " [1.16559537e-06 5.86891693e-05]\n",
      " [9.08805276e-07 1.91193488e-05]]\n",
      "Train Epoch4 out_loss 0.0004263160517439246\n",
      "Test Epoch4 layer0 out_loss 0.04485616460442543\n",
      "Test Epoch4 layer1 out_loss 0.0031894249841570854\n",
      "Test Epoch4 layer2 out_loss 0.0013408720260486007\n",
      "Test Epoch4 layer3 out_loss 0.0005791674484498799\n",
      "Test Epoch4 layer4 out_loss 0.0005073010106571019\n",
      "Test Epoch4 layer5 out_loss 0.0004878388426732272\n",
      "Test Epoch4 layer6 out_loss 0.00046880391892045736\n",
      "Test Epoch4 layer7 out_loss 0.0004402379272505641\n",
      "Test Epoch4 layer8 out_loss 0.000406445877160877\n",
      "Test Epoch4 layer9 out_loss 0.0004065298708155751\n",
      "Train 5 | out_loss 0.00042347697308287024: 100%|█| 138/138 [00:01<00:00, 103.52i\n",
      "[[2.19170847e-05 8.78334201e-01]\n",
      " [8.15991032e-06 2.16054232e-02]\n",
      " [2.90774525e-06 5.44272379e-03]\n",
      " [1.95437581e-06 1.95866544e-03]\n",
      " [3.09454308e-06 8.24302449e-04]\n",
      " [2.53791064e-06 4.65281638e-04]\n",
      " [2.96626687e-06 2.54176232e-04]\n",
      " [2.91138114e-06 9.46251411e-05]\n",
      " [1.26345692e-06 4.88234814e-05]\n",
      " [1.06465292e-06 1.61392665e-05]]\n",
      "Train Epoch5 out_loss 0.00042347697308287024\n",
      "Test Epoch5 layer0 out_loss 0.04986328259110451\n",
      "Test Epoch5 layer1 out_loss 0.0033409500028938055\n",
      "Test Epoch5 layer2 out_loss 0.0012286393903195858\n",
      "Test Epoch5 layer3 out_loss 0.0005298733012750745\n",
      "Test Epoch5 layer4 out_loss 0.00044170665205456316\n",
      "Test Epoch5 layer5 out_loss 0.00046832190128043294\n",
      "Test Epoch5 layer6 out_loss 0.0006085943896323442\n",
      "Test Epoch5 layer7 out_loss 0.00045764970127493143\n",
      "Test Epoch5 layer8 out_loss 0.00046184862731024623\n",
      "Test Epoch5 layer9 out_loss 0.0004685882886406034\n",
      "Train 6 | out_loss 0.0004265878233127296: 100%|█| 138/138 [00:01<00:00, 111.65it\n",
      "[[2.16486048e-05 9.28816808e-01]\n",
      " [7.34505949e-06 1.58711433e-02]\n",
      " [2.69082518e-06 4.04831260e-03]\n",
      " [2.99309204e-06 1.42810198e-03]\n",
      " [5.36031111e-06 6.43340913e-04]\n",
      " [4.34937449e-06 3.80804015e-04]\n",
      " [5.70996771e-06 2.06539374e-04]\n",
      " [5.41913449e-06 7.92063891e-05]\n",
      " [2.57487253e-06 4.17835090e-05]\n",
      " [2.02697988e-06 1.50057829e-05]]\n",
      "Train Epoch6 out_loss 0.0004265878233127296\n",
      "Test Epoch6 layer0 out_loss 0.02744249440729618\n",
      "Test Epoch6 layer1 out_loss 0.002441573655232787\n",
      "Test Epoch6 layer2 out_loss 0.0009921586606651545\n",
      "Test Epoch6 layer3 out_loss 0.0004660460108425468\n",
      "Test Epoch6 layer4 out_loss 0.0004580609092954546\n",
      "Test Epoch6 layer5 out_loss 0.0004488253325689584\n",
      "Test Epoch6 layer6 out_loss 0.00046012442908249795\n",
      "Test Epoch6 layer7 out_loss 0.0004322841705288738\n",
      "Test Epoch6 layer8 out_loss 0.000427710561780259\n",
      "Test Epoch6 layer9 out_loss 0.00042618022416718304\n",
      "Train 7 | out_loss 0.0004255901731085032: 100%|█| 138/138 [00:01<00:00, 109.32it\n",
      "[[2.09807636e-05 2.59031078e-01]\n",
      " [7.52795561e-06 9.22234591e-03]\n",
      " [3.25564066e-06 2.65211273e-03]\n",
      " [4.14913800e-06 1.00636628e-03]\n",
      " [8.26589613e-06 4.97424176e-04]\n",
      " [7.74675236e-06 3.11129083e-04]\n",
      " [9.13465314e-06 1.75795305e-04]\n",
      " [8.88806185e-06 6.73173195e-05]\n",
      " [3.87225823e-06 3.33128746e-05]\n",
      " [3.25413300e-06 1.23038665e-05]]\n",
      "Train Epoch7 out_loss 0.0004255901731085032\n",
      "Test Epoch7 layer0 out_loss 0.04235595464706421\n",
      "Test Epoch7 layer1 out_loss 0.003805052023380995\n",
      "Test Epoch7 layer2 out_loss 0.0008223485201597214\n",
      "Test Epoch7 layer3 out_loss 0.00043690160964615643\n",
      "Test Epoch7 layer4 out_loss 0.00043708886369131505\n",
      "Test Epoch7 layer5 out_loss 0.0004729924548882991\n",
      "Test Epoch7 layer6 out_loss 0.00042212539119645953\n",
      "Test Epoch7 layer7 out_loss 0.00045869682799093425\n",
      "Test Epoch7 layer8 out_loss 0.0004389520036056638\n",
      "Test Epoch7 layer9 out_loss 0.00042455369839444757\n",
      "Train 8 | out_loss 0.0004201280535198748: 100%|█| 138/138 [00:01<00:00, 101.19it\n",
      "[[1.87520506e-05 5.39630019e-01]\n",
      " [7.72560194e-06 7.83079330e-03]\n",
      " [3.14321064e-06 2.17118803e-03]\n",
      " [4.17230580e-06 8.20895634e-04]\n",
      " [8.42700493e-06 4.08823058e-04]\n",
      " [8.09429722e-06 2.56052641e-04]\n",
      " [1.07385241e-05 1.53096874e-04]\n",
      " [1.02966109e-05 6.19216762e-05]\n",
      " [5.53682876e-06 3.40677499e-05]\n",
      " [3.97064581e-06 1.33140489e-05]]\n",
      "Train Epoch8 out_loss 0.0004201280535198748\n",
      "Test Epoch8 layer0 out_loss 0.057370398193597794\n",
      "Test Epoch8 layer1 out_loss 0.0031548647675663233\n",
      "Test Epoch8 layer2 out_loss 0.0007455668528564274\n",
      "Test Epoch8 layer3 out_loss 0.0005200151354074478\n",
      "Test Epoch8 layer4 out_loss 0.0005009480519220233\n",
      "Test Epoch8 layer5 out_loss 0.0004812932456843555\n",
      "Test Epoch8 layer6 out_loss 0.00047023079241625965\n",
      "Test Epoch8 layer7 out_loss 0.0004946704139001667\n",
      "Test Epoch8 layer8 out_loss 0.000482549105072394\n",
      "Test Epoch8 layer9 out_loss 0.0004899961641058326\n",
      "Train 9 | out_loss 0.00044161768164485693: 100%|█| 138/138 [00:01<00:00, 106.79i\n",
      "[[2.13480587e-05 7.98016195e-01]\n",
      " [1.05378790e-05 7.29646359e-03]\n",
      " [4.34083227e-06 1.93045516e-03]\n",
      " [7.89207146e-06 7.18015667e-04]\n",
      " [2.15923764e-05 3.42291123e-04]\n",
      " [1.71616980e-05 2.15047186e-04]\n",
      " [2.30088411e-05 1.33509824e-04]\n",
      " [2.24056216e-05 5.89088329e-05]\n",
      " [9.48564697e-06 3.19432455e-05]\n",
      " [8.39430803e-06 1.33141776e-05]]\n",
      "Train Epoch9 out_loss 0.00044161768164485693\n",
      "Test Epoch9 layer0 out_loss 0.0382668599486351\n",
      "Test Epoch9 layer1 out_loss 0.0029463814571499825\n",
      "Test Epoch9 layer2 out_loss 0.0007446518866345286\n",
      "Test Epoch9 layer3 out_loss 0.0004212459025438875\n",
      "Test Epoch9 layer4 out_loss 0.00041876063914969563\n",
      "Test Epoch9 layer5 out_loss 0.0004371562390588224\n",
      "Test Epoch9 layer6 out_loss 0.0003970643738284707\n",
      "Test Epoch9 layer7 out_loss 0.00043027239735238254\n",
      "Test Epoch9 layer8 out_loss 0.0004207530291751027\n",
      "Test Epoch9 layer9 out_loss 0.00040809932397678494\n",
      "Train 10 | out_loss 0.00043314561480656266: 100%|█| 138/138 [00:01<00:00, 101.93\n",
      "[[1.88250623e-05 5.58597403e-01]\n",
      " [9.94841118e-06 5.32826452e-03]\n",
      " [4.79959358e-06 1.51184420e-03]\n",
      " [1.48723842e-05 5.98031777e-04]\n",
      " [4.41035945e-05 3.09807240e-04]\n",
      " [3.39300290e-05 2.14160786e-04]\n",
      " [4.22273626e-05 1.45541969e-04]\n",
      " [4.07743244e-05 6.91788791e-05]\n",
      " [1.56930162e-05 3.74249413e-05]\n",
      " [1.47383631e-05 1.74394428e-05]]\n",
      "Train Epoch10 out_loss 0.00043314561480656266\n",
      "Test Epoch10 layer0 out_loss 0.01669788546860218\n",
      "Test Epoch10 layer1 out_loss 0.0027213036082684994\n",
      "Test Epoch10 layer2 out_loss 0.0008038196829147637\n",
      "Test Epoch10 layer3 out_loss 0.0006574979051947594\n",
      "Test Epoch10 layer4 out_loss 0.0006855857209302485\n",
      "Test Epoch10 layer5 out_loss 0.0004966221167705953\n",
      "Test Epoch10 layer6 out_loss 0.0004127057909499854\n",
      "Test Epoch10 layer7 out_loss 0.0005845246487297118\n",
      "Test Epoch10 layer8 out_loss 0.0005138967535458505\n",
      "Test Epoch10 layer9 out_loss 0.0005080131813883781\n",
      "Train 11 | out_loss 0.0004560972738545388: 100%|█| 138/138 [00:01<00:00, 107.47i\n",
      "[[2.09685397e-05 5.73752558e-01]\n",
      " [1.16888157e-05 4.75594845e-03]\n",
      " [5.86353883e-06 1.32379046e-03]\n",
      " [1.60989033e-05 5.12966944e-04]\n",
      " [3.02350473e-05 2.45967477e-04]\n",
      " [3.16233450e-05 1.67904723e-04]\n",
      " [3.54307086e-05 1.24732612e-04]\n",
      " [3.61264459e-05 6.48269306e-05]\n",
      " [1.39057896e-05 3.80473057e-05]\n",
      " [1.32292208e-05 1.69559730e-05]]\n",
      "Train Epoch11 out_loss 0.0004560972738545388\n",
      "Test Epoch11 layer0 out_loss 0.013731037266552448\n",
      "Test Epoch11 layer1 out_loss 0.0020812421571463346\n",
      "Test Epoch11 layer2 out_loss 0.0007846697117201984\n",
      "Test Epoch11 layer3 out_loss 0.0004289842618163675\n",
      "Test Epoch11 layer4 out_loss 0.0004260640707798302\n",
      "Test Epoch11 layer5 out_loss 0.00044017910840921104\n",
      "Test Epoch11 layer6 out_loss 0.0003898385330103338\n",
      "Test Epoch11 layer7 out_loss 0.00041051808511838317\n",
      "Test Epoch11 layer8 out_loss 0.0004029519041068852\n",
      "Test Epoch11 layer9 out_loss 0.00040003086905926466\n",
      "Train 12 | out_loss 0.00043644459219649434: 100%|█| 138/138 [00:01<00:00, 109.22\n",
      "[[1.69124156e-05 3.84097712e-01]\n",
      " [1.21424179e-05 4.84727405e-03]\n",
      " [3.58972216e-06 1.29206778e-03]\n",
      " [1.64429242e-05 5.07086349e-04]\n",
      " [2.61424650e-05 2.62269107e-04]\n",
      " [2.32082219e-05 1.72191446e-04]\n",
      " [3.49658991e-05 1.32210215e-04]\n",
      " [3.00747388e-05 6.47792481e-05]\n",
      " [1.65948704e-05 3.65796228e-05]\n",
      " [1.14066428e-05 1.62645330e-05]]\n",
      "Train Epoch12 out_loss 0.00043644459219649434\n",
      "Test Epoch12 layer0 out_loss 0.03378588706254959\n",
      "Test Epoch12 layer1 out_loss 0.0018665780080482364\n",
      "Test Epoch12 layer2 out_loss 0.0006808295147493482\n",
      "Test Epoch12 layer3 out_loss 0.0004033754812553525\n",
      "Test Epoch12 layer4 out_loss 0.0004158677184022963\n",
      "Test Epoch12 layer5 out_loss 0.0004886355600319803\n",
      "Test Epoch12 layer6 out_loss 0.00040295510552823544\n",
      "Test Epoch12 layer7 out_loss 0.00040866280323825777\n",
      "Test Epoch12 layer8 out_loss 0.00041148357558995485\n",
      "Test Epoch12 layer9 out_loss 0.00041075420449487865\n",
      "Train 13 | out_loss 0.000448871694970876: 100%|█| 138/138 [00:01<00:00, 106.51it\n",
      "[[1.74547312e-05 2.87091483e-01]\n",
      " [1.56516092e-05 3.70530143e-03]\n",
      " [6.53225975e-06 1.02763167e-03]\n",
      " [2.38156594e-05 4.21980049e-04]\n",
      " [5.88585609e-05 2.35798975e-04]\n",
      " [5.14388302e-05 1.66950553e-04]\n",
      " [5.99815235e-05 1.28393263e-04]\n",
      " [5.78792945e-05 7.36221844e-05]\n",
      " [2.38948079e-05 4.51700262e-05]\n",
      " [2.09038576e-05 2.27733646e-05]]\n",
      "Train Epoch13 out_loss 0.000448871694970876\n",
      "Test Epoch13 layer0 out_loss 0.010878668166697025\n",
      "Test Epoch13 layer1 out_loss 0.001785892527550459\n",
      "Test Epoch13 layer2 out_loss 0.000697673880495131\n",
      "Test Epoch13 layer3 out_loss 0.0004832479462493211\n",
      "Test Epoch13 layer4 out_loss 0.0004119399527553469\n",
      "Test Epoch13 layer5 out_loss 0.00042395995114929974\n",
      "Test Epoch13 layer6 out_loss 0.0004792225663550198\n",
      "Test Epoch13 layer7 out_loss 0.00047176438965834677\n",
      "Test Epoch13 layer8 out_loss 0.00046817888505756855\n",
      "Test Epoch13 layer9 out_loss 0.00044976494973525405\n",
      "Train 14 | out_loss 0.00048801011871546507: 100%|█| 138/138 [00:01<00:00, 104.99\n",
      "[[2.24897130e-05 9.83605838e-02]\n",
      " [2.27706812e-05 2.71975026e-03]\n",
      " [8.51039213e-06 8.14701942e-04]\n",
      " [3.15869488e-05 3.57312734e-04]\n",
      " [6.08910455e-05 2.16968923e-04]\n",
      " [4.75957716e-05 1.49599016e-04]\n",
      " [5.64087301e-05 1.24452190e-04]\n",
      " [5.21966438e-05 7.33106433e-05]\n",
      " [2.24237872e-05 4.37807548e-05]\n",
      " [1.94268085e-05 2.09911184e-05]]\n",
      "Train Epoch14 out_loss 0.00048801011871546507\n",
      "Test Epoch14 layer0 out_loss 0.010586832650005817\n",
      "Test Epoch14 layer1 out_loss 0.0015330748865380883\n",
      "Test Epoch14 layer2 out_loss 0.0005859395023435354\n",
      "Test Epoch14 layer3 out_loss 0.00040912156691774726\n",
      "Test Epoch14 layer4 out_loss 0.00043892423855140805\n",
      "Test Epoch14 layer5 out_loss 0.000454350229119882\n",
      "Test Epoch14 layer6 out_loss 0.0004060393839608878\n",
      "Test Epoch14 layer7 out_loss 0.0004061964573338628\n",
      "Test Epoch14 layer8 out_loss 0.00040439938311465085\n",
      "Test Epoch14 layer9 out_loss 0.0004023200017400086\n",
      "Train 15 | out_loss 0.000448087346740067: 100%|█| 138/138 [00:01<00:00, 108.13it\n",
      "[[1.54144734e-05 1.38264295e-01]\n",
      " [3.61859751e-05 2.57304970e-03]\n",
      " [1.36878363e-05 7.55177777e-04]\n",
      " [5.42070823e-05 3.78207937e-04]\n",
      " [6.70655695e-05 2.37897621e-04]\n",
      " [6.39096428e-05 1.70782575e-04]\n",
      " [7.30230421e-05 1.65039576e-04]\n",
      " [6.91422562e-05 1.05969298e-04]\n",
      " [2.92594481e-05 6.54122061e-05]\n",
      " [2.57728796e-05 2.91375327e-05]]\n",
      "Train Epoch15 out_loss 0.000448087346740067\n",
      "Test Epoch15 layer0 out_loss 0.011687316931784153\n",
      "Test Epoch15 layer1 out_loss 0.0013015159638598561\n",
      "Test Epoch15 layer2 out_loss 0.0006079572485759854\n",
      "Test Epoch15 layer3 out_loss 0.0004104567051399499\n",
      "Test Epoch15 layer4 out_loss 0.00044133493793196976\n",
      "Test Epoch15 layer5 out_loss 0.0004158485389780253\n",
      "Test Epoch15 layer6 out_loss 0.0004361550381872803\n",
      "Test Epoch15 layer7 out_loss 0.00040820243884809315\n",
      "Test Epoch15 layer8 out_loss 0.0004042720829602331\n",
      "Test Epoch15 layer9 out_loss 0.0004050679854117334\n",
      "Train 16 | out_loss 0.00052338105160743: 100%|█| 138/138 [00:01<00:00, 113.65it/\n",
      "[[2.41420917e-05 4.81855204e-01]\n",
      " [3.17893395e-05 3.14008417e-03]\n",
      " [2.41679069e-05 8.62672734e-04]\n",
      " [1.84536717e-04 4.90140241e-04]\n",
      " [1.35279249e-04 3.55757776e-04]\n",
      " [1.26026165e-04 2.20703350e-04]\n",
      " [1.55173745e-04 2.22325011e-04]\n",
      " [1.38050731e-04 1.73471761e-04]\n",
      " [6.85256057e-05 1.11767267e-04]\n",
      " [5.22324500e-05 5.35839431e-05]]\n",
      "Train Epoch16 out_loss 0.00052338105160743\n",
      "Test Epoch16 layer0 out_loss 0.07703555375337601\n",
      "Test Epoch16 layer1 out_loss 0.0019094434101134539\n",
      "Test Epoch16 layer2 out_loss 0.0006668080459348857\n",
      "Test Epoch16 layer3 out_loss 0.000613136391621083\n",
      "Test Epoch16 layer4 out_loss 0.000694232527166605\n",
      "Test Epoch16 layer5 out_loss 0.0004043316876050085\n",
      "Test Epoch16 layer6 out_loss 0.00045563525054603815\n",
      "Test Epoch16 layer7 out_loss 0.0005346256657503545\n",
      "Test Epoch16 layer8 out_loss 0.00045735511230304837\n",
      "Test Epoch16 layer9 out_loss 0.0004355587298050523\n",
      "Train 17 | out_loss 0.0005757837789133191: 100%|█| 138/138 [00:01<00:00, 111.36i\n",
      "[[3.50783843e-05 6.20756373e-01]\n",
      " [4.08820954e-05 3.06386147e-03]\n",
      " [2.77587056e-04 1.02798389e-03]\n",
      " [1.51428181e-03 1.39918299e-03]\n",
      " [5.14420425e-04 1.09932240e-03]\n",
      " [4.33449473e-04 4.47771702e-04]\n",
      " [3.47911199e-04 3.62209897e-04]\n",
      " [2.21851116e-04 2.30260581e-04]\n",
      " [1.06279670e-04 1.32731898e-04]\n",
      " [7.30587859e-05 6.31039769e-05]]\n",
      "Train Epoch17 out_loss 0.0005757837789133191\n",
      "Test Epoch17 layer0 out_loss 0.01641334779560566\n",
      "Test Epoch17 layer1 out_loss 0.0012477694544941187\n",
      "Test Epoch17 layer2 out_loss 0.0005584164755418897\n",
      "Test Epoch17 layer3 out_loss 0.0004324581823311746\n",
      "Test Epoch17 layer4 out_loss 0.0004602105764206499\n",
      "Test Epoch17 layer5 out_loss 0.0004427136736921966\n",
      "Test Epoch17 layer6 out_loss 0.00042566427146084607\n",
      "Test Epoch17 layer7 out_loss 0.0004056333564221859\n",
      "Test Epoch17 layer8 out_loss 0.00040924266795627773\n",
      "Test Epoch17 layer9 out_loss 0.00040348796756006777\n",
      "Train 18 | out_loss 0.0009763870621100068: 100%|█| 138/138 [00:01<00:00, 112.01i\n",
      "[[1.28437779e-04 1.83839684e-01]\n",
      " [9.41492933e-05 2.29390056e-03]\n",
      " [5.17684299e-04 9.56395992e-04]\n",
      " [1.20414616e-03 1.29081987e-03]\n",
      " [5.07925718e-04 9.07996127e-04]\n",
      " [4.47358966e-04 4.43756648e-04]\n",
      " [3.43331655e-04 4.15804425e-04]\n",
      " [2.85637237e-04 3.05431094e-04]\n",
      " [1.42298518e-04 2.08634200e-04]\n",
      " [1.41934515e-04 1.54591370e-04]]\n",
      "Train Epoch18 out_loss 0.0009763870621100068\n",
      "Test Epoch18 layer0 out_loss 0.01981167122721672\n",
      "Test Epoch18 layer1 out_loss 0.0026084145065397024\n",
      "Test Epoch18 layer2 out_loss 0.002414311747997999\n",
      "Test Epoch18 layer3 out_loss 0.002321557141840458\n",
      "Test Epoch18 layer4 out_loss 0.0022930814884603024\n",
      "Test Epoch18 layer5 out_loss 0.002392915543168783\n",
      "Test Epoch18 layer6 out_loss 0.0022302225697785616\n",
      "Test Epoch18 layer7 out_loss 0.0023967239540070295\n",
      "Test Epoch18 layer8 out_loss 0.002385698026046157\n",
      "Test Epoch18 layer9 out_loss 0.0023059798404574394\n",
      "Train 19 | out_loss 0.001453843549825251: 100%|█| 138/138 [00:01<00:00, 110.97it\n",
      "[[3.68256448e-04 8.84846516e-02]\n",
      " [8.63461714e-05 1.83582056e-03]\n",
      " [4.56975289e-04 8.24050550e-04]\n",
      " [6.83796646e-04 9.45292621e-04]\n",
      " [3.50892441e-04 6.05414447e-04]\n",
      " [3.05443665e-04 3.16658909e-04]\n",
      " [2.30223798e-04 3.16704251e-04]\n",
      " [1.95453455e-04 2.44996984e-04]\n",
      " [1.03565820e-04 1.88035175e-04]\n",
      " [1.10612789e-04 1.38738117e-04]]\n",
      "Train Epoch19 out_loss 0.001453843549825251\n",
      "Test Epoch19 layer0 out_loss 0.00946775171905756\n",
      "Test Epoch19 layer1 out_loss 0.001684322371147573\n",
      "Test Epoch19 layer2 out_loss 0.0007570506422780454\n",
      "Test Epoch19 layer3 out_loss 0.0009195399470627308\n",
      "Test Epoch19 layer4 out_loss 0.00064982904586941\n",
      "Test Epoch19 layer5 out_loss 0.0006372658535838127\n",
      "Test Epoch19 layer6 out_loss 0.0005932876374572515\n",
      "Test Epoch19 layer7 out_loss 0.000770826474763453\n",
      "Test Epoch19 layer8 out_loss 0.0007538547506555915\n",
      "Test Epoch19 layer9 out_loss 0.0009043714380823076\n",
      "Train 20 | out_loss 0.0017414080211892724: 100%|█| 138/138 [00:01<00:00, 114.38i\n",
      "[[5.10635786e-04 4.27851617e-01]\n",
      " [1.68500552e-04 2.58965567e-03]\n",
      " [5.28750699e-04 1.09929330e-03]\n",
      " [4.55053177e-04 9.28248177e-04]\n",
      " [3.81941593e-04 5.06467390e-04]\n",
      " [2.79406867e-04 3.21339859e-04]\n",
      " [2.20634708e-04 3.03787964e-04]\n",
      " [1.79661912e-04 2.08438506e-04]\n",
      " [8.12648053e-05 1.45691308e-04]\n",
      " [9.00055624e-05 1.19731374e-04]]\n",
      "Train Epoch20 out_loss 0.0017414080211892724\n",
      "Test Epoch20 layer0 out_loss 0.025886526331305504\n",
      "Test Epoch20 layer1 out_loss 0.003582166973501444\n",
      "Test Epoch20 layer2 out_loss 0.0007591572357341647\n",
      "Test Epoch20 layer3 out_loss 0.0006298531079664826\n",
      "Test Epoch20 layer4 out_loss 0.0005740905180573463\n",
      "Test Epoch20 layer5 out_loss 0.0009056180133484304\n",
      "Test Epoch20 layer6 out_loss 0.000853661447763443\n",
      "Test Epoch20 layer7 out_loss 0.0006921081221662462\n",
      "Test Epoch20 layer8 out_loss 0.0008261738694272935\n",
      "Test Epoch20 layer9 out_loss 0.0008211776148527861\n",
      "Train 21 | out_loss 0.001133978832513094: 100%|█| 138/138 [00:01<00:00, 112.50it\n",
      "[[2.27799740e-04 6.21415041e-01]\n",
      " [1.71575829e-04 3.38155024e-03]\n",
      " [4.79483579e-04 1.32706811e-03]\n",
      " [3.44410998e-04 1.04348841e-03]\n",
      " [3.38549118e-04 6.50865036e-04]\n",
      " [2.44792012e-04 3.40840617e-04]\n",
      " [1.94582306e-04 2.69915180e-04]\n",
      " [1.47833431e-04 1.67854208e-04]\n",
      " [6.68938188e-05 1.08110631e-04]\n",
      " [6.40472206e-05 7.01753734e-05]]\n",
      "Train Epoch21 out_loss 0.001133978832513094\n",
      "Test Epoch21 layer0 out_loss 0.012778573669493198\n",
      "Test Epoch21 layer1 out_loss 0.0012252462329342961\n",
      "Test Epoch21 layer2 out_loss 0.0006739700911566615\n",
      "Test Epoch21 layer3 out_loss 0.0006503529148176312\n",
      "Test Epoch21 layer4 out_loss 0.0005553860100917518\n",
      "Test Epoch21 layer5 out_loss 0.0005323642981238663\n",
      "Test Epoch21 layer6 out_loss 0.0005587967461906374\n",
      "Test Epoch21 layer7 out_loss 0.0005707942182198167\n",
      "Test Epoch21 layer8 out_loss 0.0005796042387373745\n",
      "Test Epoch21 layer9 out_loss 0.0005732129793614149\n",
      "Train 22 | out_loss 0.001544089405797422: 100%|█| 138/138 [00:01<00:00, 112.80it\n",
      "[[3.74233005e-04 2.03926228e-01]\n",
      " [3.35743959e-04 1.75447145e-03]\n",
      " [6.94027254e-04 9.99163410e-04]\n",
      " [5.02454983e-04 8.47097005e-04]\n",
      " [5.83237669e-04 5.78625127e-04]\n",
      " [3.61388919e-04 3.92336362e-04]\n",
      " [3.17458745e-04 3.40501767e-04]\n",
      " [2.24880199e-04 2.48964270e-04]\n",
      " [1.00918000e-04 1.77361338e-04]\n",
      " [1.01212438e-04 1.25083266e-04]]\n",
      "Train Epoch22 out_loss 0.001544089405797422\n",
      "Test Epoch22 layer0 out_loss 0.01428187359124422\n",
      "Test Epoch22 layer1 out_loss 0.001971660880371928\n",
      "Test Epoch22 layer2 out_loss 0.002553978469222784\n",
      "Test Epoch22 layer3 out_loss 0.002316651865839958\n",
      "Test Epoch22 layer4 out_loss 0.002647851128131151\n",
      "Test Epoch22 layer5 out_loss 0.0027784763369709253\n",
      "Test Epoch22 layer6 out_loss 0.002365544205531478\n",
      "Test Epoch22 layer7 out_loss 0.002566607901826501\n",
      "Test Epoch22 layer8 out_loss 0.002538941102102399\n",
      "Test Epoch22 layer9 out_loss 0.002537161111831665\n",
      "Train 23 | out_loss 0.0015330525347962976: 100%|█| 138/138 [00:01<00:00, 108.47i\n",
      "[[3.96656595e-04 3.52576021e-01]\n",
      " [3.60474637e-04 2.44194726e-03]\n",
      " [9.20830636e-04 1.31190419e-03]\n",
      " [1.03908631e-03 1.54546844e-03]\n",
      " [8.01114914e-04 1.20892753e-03]\n",
      " [5.77397560e-04 6.68355616e-04]\n",
      " [4.63549104e-04 5.21300872e-04]\n",
      " [3.02152877e-04 3.19414721e-04]\n",
      " [1.26187722e-04 1.94604157e-04]\n",
      " [1.10877862e-04 1.17027057e-04]]\n",
      "Train Epoch23 out_loss 0.0015330525347962976\n",
      "Test Epoch23 layer0 out_loss 0.04927653819322586\n",
      "Test Epoch23 layer1 out_loss 0.0022778126876801252\n",
      "Test Epoch23 layer2 out_loss 0.0009698952781036496\n",
      "Test Epoch23 layer3 out_loss 0.00045737007167190313\n",
      "Test Epoch23 layer4 out_loss 0.0007658714312128723\n",
      "Test Epoch23 layer5 out_loss 0.00047989224549382925\n",
      "Test Epoch23 layer6 out_loss 0.0011691413819789886\n",
      "Test Epoch23 layer7 out_loss 0.00052590825362131\n",
      "Test Epoch23 layer8 out_loss 0.0006388056208379567\n",
      "Test Epoch23 layer9 out_loss 0.0006484051700681448\n",
      "Train 24 | out_loss 0.0014989060582593083: 100%|█| 138/138 [00:01<00:00, 99.56it\n",
      "[[3.60780604e-04 6.44668601e-01]\n",
      " [1.99697090e-04 3.80002618e-03]\n",
      " [3.29747296e-04 1.27718921e-03]\n",
      " [4.02037888e-04 8.91708510e-04]\n",
      " [4.12874395e-04 7.60564559e-04]\n",
      " [3.68691913e-04 4.93798086e-04]\n",
      " [3.50393829e-04 5.33615056e-04]\n",
      " [3.03186072e-04 4.27333114e-04]\n",
      " [1.76979403e-04 3.18359183e-04]\n",
      " [2.00976876e-04 2.56825566e-04]]\n",
      "Train Epoch24 out_loss 0.0014989060582593083\n",
      "Test Epoch24 layer0 out_loss 0.03061225824058056\n",
      "Test Epoch24 layer1 out_loss 0.003967648837715387\n",
      "Test Epoch24 layer2 out_loss 0.0027635067235678434\n",
      "Test Epoch24 layer3 out_loss 0.0026381334755569696\n",
      "Test Epoch24 layer4 out_loss 0.0029058398213237524\n",
      "Test Epoch24 layer5 out_loss 0.0030112252570688725\n",
      "Test Epoch24 layer6 out_loss 0.002809688448905945\n",
      "Test Epoch24 layer7 out_loss 0.002982212696224451\n",
      "Test Epoch24 layer8 out_loss 0.003019261872395873\n",
      "Test Epoch24 layer9 out_loss 0.0028879682067781687\n",
      "Train 25 | out_loss 0.0014448167057707906: 100%|█| 138/138 [00:01<00:00, 105.62i\n",
      "[[3.58057828e-04 8.86091134e-02]\n",
      " [3.72028690e-04 1.56541705e-03]\n",
      " [5.94440710e-04 8.80759310e-04]\n",
      " [4.55038768e-04 6.93166775e-04]\n",
      " [4.54725322e-04 4.79859967e-04]\n",
      " [3.73696328e-04 4.12641169e-04]\n",
      " [3.05733735e-04 3.78747576e-04]\n",
      " [2.36727658e-04 2.62044879e-04]\n",
      " [1.01634945e-04 1.52173020e-04]\n",
      " [8.31709960e-05 8.65733659e-05]]\n",
      "Train Epoch25 out_loss 0.0014448167057707906\n",
      "Test Epoch25 layer0 out_loss 0.015290205366909504\n",
      "Test Epoch25 layer1 out_loss 0.0007332616951316595\n",
      "Test Epoch25 layer2 out_loss 0.0006465328042395413\n",
      "Test Epoch25 layer3 out_loss 0.00041495400364510715\n",
      "Test Epoch25 layer4 out_loss 0.0004176984366495162\n",
      "Test Epoch25 layer5 out_loss 0.00040268711745738983\n",
      "Test Epoch25 layer6 out_loss 0.000757887726649642\n",
      "Test Epoch25 layer7 out_loss 0.0006439578719437122\n",
      "Test Epoch25 layer8 out_loss 0.000542776717338711\n",
      "Test Epoch25 layer9 out_loss 0.0005790002178400755\n",
      "Train 26 | out_loss 0.0015367459272965789: 100%|█| 138/138 [00:01<00:00, 106.21i\n",
      "[[4.04882908e-04 6.64566100e-02]\n",
      " [4.00890642e-04 1.68749626e-03]\n",
      " [7.49618766e-04 1.06438426e-03]\n",
      " [6.33280673e-04 9.77499228e-04]\n",
      " [4.57305334e-04 6.08833725e-04]\n",
      " [3.33635851e-04 4.11369968e-04]\n",
      " [2.47136154e-04 3.08643241e-04]\n",
      " [1.73946496e-04 1.84420682e-04]\n",
      " [7.69678217e-05 1.12326976e-04]\n",
      " [6.71956295e-05 7.88862845e-05]]\n",
      "Train Epoch26 out_loss 0.0015367459272965789\n",
      "Test Epoch26 layer0 out_loss 0.01040913537144661\n",
      "Test Epoch26 layer1 out_loss 0.0021900939755141735\n",
      "Test Epoch26 layer2 out_loss 0.0012043605092912912\n",
      "Test Epoch26 layer3 out_loss 0.001213600393384695\n",
      "Test Epoch26 layer4 out_loss 0.0013438279274851084\n",
      "Test Epoch26 layer5 out_loss 0.0013189857127144933\n",
      "Test Epoch26 layer6 out_loss 0.0011118896072730422\n",
      "Test Epoch26 layer7 out_loss 0.0012934185797348619\n",
      "Test Epoch26 layer8 out_loss 0.0012938102008774877\n",
      "Test Epoch26 layer9 out_loss 0.0012931243982166052\n",
      "Train 27 | out_loss 0.001222970662638545: 100%|█| 138/138 [00:01<00:00, 105.34it\n",
      "[[2.60559607e-04 3.81780248e-02]\n",
      " [4.61369456e-04 1.44280846e-03]\n",
      " [5.96459284e-04 8.86982925e-04]\n",
      " [4.34233416e-04 6.53359244e-04]\n",
      " [3.86888444e-04 4.99057576e-04]\n",
      " [3.20246911e-04 4.08267639e-04]\n",
      " [2.60300681e-04 3.71308416e-04]\n",
      " [2.08375584e-04 2.51206002e-04]\n",
      " [9.61179192e-05 1.58132018e-04]\n",
      " [8.46843332e-05 1.20710224e-04]]\n",
      "Train Epoch27 out_loss 0.001222970662638545\n",
      "Test Epoch27 layer0 out_loss 0.006526778917759657\n",
      "Test Epoch27 layer1 out_loss 0.0015312101459130645\n",
      "Test Epoch27 layer2 out_loss 0.0015677664196118712\n",
      "Test Epoch27 layer3 out_loss 0.001415648846887052\n",
      "Test Epoch27 layer4 out_loss 0.0019045125227421522\n",
      "Test Epoch27 layer5 out_loss 0.0010413523996248841\n",
      "Test Epoch27 layer6 out_loss 0.001339609269052744\n",
      "Test Epoch27 layer7 out_loss 0.001597402268089354\n",
      "Test Epoch27 layer8 out_loss 0.0015553272096440196\n",
      "Test Epoch27 layer9 out_loss 0.0014820258365944028\n",
      "Train 28 | out_loss 0.0015846656169742346: 100%|█| 138/138 [00:01<00:00, 107.25i\n",
      "[[4.40224690e-04 2.13696363e-01]\n",
      " [4.61444282e-04 2.38333679e-03]\n",
      " [8.42075220e-04 1.37283481e-03]\n",
      " [5.98185475e-04 1.35224373e-03]\n",
      " [4.25402345e-04 7.26227202e-04]\n",
      " [5.62546483e-04 6.33678877e-04]\n",
      " [4.04092025e-04 6.13875222e-04]\n",
      " [3.18120665e-04 4.17464242e-04]\n",
      " [1.44718259e-04 2.57844431e-04]\n",
      " [1.30684195e-04 1.54883206e-04]]\n",
      "Train Epoch28 out_loss 0.0015846656169742346\n",
      "Test Epoch28 layer0 out_loss 0.021107390522956848\n",
      "Test Epoch28 layer1 out_loss 0.002911113668233156\n",
      "Test Epoch28 layer2 out_loss 0.000803071481641382\n",
      "Test Epoch28 layer3 out_loss 0.0007133750477805734\n",
      "Test Epoch28 layer4 out_loss 0.000870261515956372\n",
      "Test Epoch28 layer5 out_loss 0.000955537601839751\n",
      "Test Epoch28 layer6 out_loss 0.0011362677905708551\n",
      "Test Epoch28 layer7 out_loss 0.0010861377231776714\n",
      "Test Epoch28 layer8 out_loss 0.0010741445003077388\n",
      "Test Epoch28 layer9 out_loss 0.00103817880153656\n",
      "Train 29 | out_loss 0.0012218450428918004: 100%|█| 138/138 [00:01<00:00, 109.77i\n",
      "[[2.83190524e-04 3.91351798e-01]\n",
      " [4.51773267e-04 3.08913300e-03]\n",
      " [7.04136716e-04 1.28940217e-03]\n",
      " [6.73408992e-04 1.14851800e-03]\n",
      " [4.30387676e-04 7.57520611e-04]\n",
      " [4.42105743e-04 4.65893041e-04]\n",
      " [3.13641950e-04 4.33593665e-04]\n",
      " [2.17940361e-04 2.82326967e-04]\n",
      " [1.10701678e-04 1.83395362e-04]\n",
      " [1.14533950e-04 2.10878854e-04]]\n",
      "Train Epoch29 out_loss 0.0012218450428918004\n",
      "Test Epoch29 layer0 out_loss 0.03278538957238197\n",
      "Test Epoch29 layer1 out_loss 0.0015826961025595665\n",
      "Test Epoch29 layer2 out_loss 0.0007224882137961686\n",
      "Test Epoch29 layer3 out_loss 0.0006300721433945\n",
      "Test Epoch29 layer4 out_loss 0.0004080433282069862\n",
      "Test Epoch29 layer5 out_loss 0.0005925041623413563\n",
      "Test Epoch29 layer6 out_loss 0.000623323954641819\n",
      "Test Epoch29 layer7 out_loss 0.0004780071903951466\n",
      "Test Epoch29 layer8 out_loss 0.0005742572247982025\n",
      "Test Epoch29 layer9 out_loss 0.0006995807634666562\n",
      "Train 30 | out_loss 0.0015521913301199675: 100%|█| 138/138 [00:01<00:00, 105.24i\n",
      "[[4.05946308e-04 2.24430197e-01]\n",
      " [6.54158867e-04 2.38167201e-03]\n",
      " [9.10470332e-04 1.44038746e-03]\n",
      " [6.10052850e-04 1.19043502e-03]\n",
      " [4.86333774e-04 6.32786706e-04]\n",
      " [6.10441612e-04 5.32209448e-04]\n",
      " [3.64247467e-04 5.22882974e-04]\n",
      " [2.41335412e-04 3.16587271e-04]\n",
      " [1.06799869e-04 1.90372750e-04]\n",
      " [1.04729498e-04 1.38909692e-04]]\n",
      "Train Epoch30 out_loss 0.0015521913301199675\n",
      "Test Epoch30 layer0 out_loss 0.0065633393824100494\n",
      "Test Epoch30 layer1 out_loss 0.0011741023045033216\n",
      "Test Epoch30 layer2 out_loss 0.001174894510768354\n",
      "Test Epoch30 layer3 out_loss 0.0010966757545247674\n",
      "Test Epoch30 layer4 out_loss 0.0006026752525940537\n",
      "Test Epoch30 layer5 out_loss 0.0010820465395227075\n",
      "Test Epoch30 layer6 out_loss 0.0007091729203239083\n",
      "Test Epoch30 layer7 out_loss 0.0007450690027326345\n",
      "Test Epoch30 layer8 out_loss 0.0008587881457060575\n",
      "Test Epoch30 layer9 out_loss 0.0007267851033248007\n",
      "Train 31 | out_loss 0.001494702068157494: 100%|█| 138/138 [00:01<00:00, 104.98it\n",
      "[[4.08862698e-04 6.02546513e-02]\n",
      " [4.67101955e-04 1.67487127e-03]\n",
      " [7.26372050e-04 1.12630426e-03]\n",
      " [5.47055594e-04 9.57226589e-04]\n",
      " [3.49869311e-04 5.33448816e-04]\n",
      " [3.12484742e-04 3.25765077e-04]\n",
      " [2.17429744e-04 2.49541914e-04]\n",
      " [1.46457814e-04 1.69152432e-04]\n",
      " [7.83566514e-05 1.16240281e-04]\n",
      " [7.44171940e-05 1.11700568e-04]]\n",
      "Train Epoch31 out_loss 0.001494702068157494\n",
      "Test Epoch31 layer0 out_loss 0.004001610912382603\n",
      "Test Epoch31 layer1 out_loss 0.0014841407537460327\n",
      "Test Epoch31 layer2 out_loss 0.0009315158240497112\n",
      "Test Epoch31 layer3 out_loss 0.0008239344460889697\n",
      "Test Epoch31 layer4 out_loss 0.0008912743651308119\n",
      "Test Epoch31 layer5 out_loss 0.0008968869806267321\n",
      "Test Epoch31 layer6 out_loss 0.0007507250411435962\n",
      "Test Epoch31 layer7 out_loss 0.0009022385929711163\n",
      "Test Epoch31 layer8 out_loss 0.0008954490185715258\n",
      "Test Epoch31 layer9 out_loss 0.0010677967220544815\n",
      "Train 32 | out_loss 0.0012292005121707916: 100%|█| 138/138 [00:01<00:00, 106.50i\n",
      "[[0.00025012 0.02218047]\n",
      " [0.00041108 0.00116622]\n",
      " [0.00058438 0.00092121]\n",
      " [0.00040215 0.00089953]\n",
      " [0.00036479 0.00050041]\n",
      " [0.00048841 0.00041794]\n",
      " [0.00032086 0.00042281]\n",
      " [0.00021021 0.00028274]\n",
      " [0.00011768 0.0002041 ]\n",
      " [0.00011926 0.00021465]]\n",
      "Train Epoch32 out_loss 0.0012292005121707916\n",
      "Test Epoch32 layer0 out_loss 0.006759729702025652\n",
      "Test Epoch32 layer1 out_loss 0.0005905749858357012\n",
      "Test Epoch32 layer2 out_loss 0.0004428037500474602\n",
      "Test Epoch32 layer3 out_loss 0.00040751631604507565\n",
      "Test Epoch32 layer4 out_loss 0.0005038307863287628\n",
      "Test Epoch32 layer5 out_loss 0.0005141739384271204\n",
      "Test Epoch32 layer6 out_loss 0.0004058786726091057\n",
      "Test Epoch32 layer7 out_loss 0.0004025071393698454\n",
      "Test Epoch32 layer8 out_loss 0.0004036015016026795\n",
      "Test Epoch32 layer9 out_loss 0.00044346231152303517\n",
      "Train 33 | out_loss 0.0014235160779207945: 100%|█| 138/138 [00:01<00:00, 108.61i\n",
      "[[3.94172901e-04 4.30013567e-02]\n",
      " [8.24401650e-04 1.86822435e-03]\n",
      " [1.11493665e-03 1.69152804e-03]\n",
      " [7.54922019e-04 1.36083569e-03]\n",
      " [4.97297861e-04 7.19126528e-04]\n",
      " [3.81612331e-04 4.21261339e-04]\n",
      " [2.55097189e-04 3.17088550e-04]\n",
      " [1.60695082e-04 2.03733650e-04]\n",
      " [9.25939201e-05 1.46841660e-04]\n",
      " [9.08578091e-05 1.96554010e-04]]\n",
      "Train Epoch33 out_loss 0.0014235160779207945\n",
      "Test Epoch33 layer0 out_loss 0.004663336556404829\n",
      "Test Epoch33 layer1 out_loss 0.0007063557277433574\n",
      "Test Epoch33 layer2 out_loss 0.00043291153269819915\n",
      "Test Epoch33 layer3 out_loss 0.0005190614610910416\n",
      "Test Epoch33 layer4 out_loss 0.00043045548954978585\n",
      "Test Epoch33 layer5 out_loss 0.0004161173419561237\n",
      "Test Epoch33 layer6 out_loss 0.0004106085980311036\n",
      "Test Epoch33 layer7 out_loss 0.0004205134464427829\n",
      "Test Epoch33 layer8 out_loss 0.00040460145100951195\n",
      "Test Epoch33 layer9 out_loss 0.0004033008008264005\n",
      "Train 34 | out_loss 0.0013044439256191254: 100%|█| 138/138 [00:01<00:00, 104.57i\n",
      "[[3.48476774e-04 7.80566158e-02]\n",
      " [3.19181388e-04 1.45474935e-03]\n",
      " [4.66708982e-04 8.45244153e-04]\n",
      " [3.89951499e-04 7.25932686e-04]\n",
      " [3.35825070e-04 4.75033451e-04]\n",
      " [2.77332129e-04 4.15962116e-04]\n",
      " [2.29668223e-04 3.18449570e-04]\n",
      " [1.43861305e-04 1.81570814e-04]\n",
      " [9.38350614e-05 1.38132032e-04]\n",
      " [9.20098480e-05 1.82761650e-04]]\n",
      "Train Epoch34 out_loss 0.0013044439256191254\n",
      "Test Epoch34 layer0 out_loss 0.01936311647295952\n",
      "Test Epoch34 layer1 out_loss 0.0018911752849817276\n",
      "Test Epoch34 layer2 out_loss 0.0020081268157809973\n",
      "Test Epoch34 layer3 out_loss 0.0024605290964245796\n",
      "Test Epoch34 layer4 out_loss 0.0021433476358652115\n",
      "Test Epoch34 layer5 out_loss 0.002098908182233572\n",
      "Test Epoch34 layer6 out_loss 0.002121733268722892\n",
      "Test Epoch34 layer7 out_loss 0.001969176111742854\n",
      "Test Epoch34 layer8 out_loss 0.00218055653385818\n",
      "Test Epoch34 layer9 out_loss 0.0022674035280942917\n",
      "Train 35 | out_loss 0.001286288141272962: 100%|█| 138/138 [00:01<00:00, 102.87it\n",
      "[[3.20516455e-04 4.04867899e-01]\n",
      " [6.06025712e-04 3.22816628e-03]\n",
      " [6.71888036e-04 1.42031944e-03]\n",
      " [5.07667346e-04 1.16365900e-03]\n",
      " [3.79410269e-04 6.03893160e-04]\n",
      " [3.59677906e-04 4.01946259e-04]\n",
      " [2.63444195e-04 3.16093704e-04]\n",
      " [1.38641920e-04 1.82661142e-04]\n",
      " [8.46525046e-05 1.27810627e-04]\n",
      " [8.60571305e-05 1.41825960e-04]]\n",
      "Train Epoch35 out_loss 0.001286288141272962\n",
      "Test Epoch35 layer0 out_loss 0.05250841751694679\n",
      "Test Epoch35 layer1 out_loss 0.0023210695944726467\n",
      "Test Epoch35 layer2 out_loss 0.0012557974550873041\n",
      "Test Epoch35 layer3 out_loss 0.0017022972460836172\n",
      "Test Epoch35 layer4 out_loss 0.0020286201033741236\n",
      "Test Epoch35 layer5 out_loss 0.0018504617037251592\n",
      "Test Epoch35 layer6 out_loss 0.002067328430712223\n",
      "Test Epoch35 layer7 out_loss 0.0023188036866486073\n",
      "Test Epoch35 layer8 out_loss 0.001868097111582756\n",
      "Test Epoch35 layer9 out_loss 0.002194178057834506\n",
      "Train 36 | out_loss 0.0015826770104467869: 100%|█| 138/138 [00:01<00:00, 109.56i\n",
      "[[4.74091904e-04 3.99413590e-01]\n",
      " [6.82243088e-04 3.35749973e-03]\n",
      " [8.88242298e-04 1.73368497e-03]\n",
      " [6.89210670e-04 1.66953458e-03]\n",
      " [4.91585429e-04 8.41260125e-04]\n",
      " [4.77318859e-04 5.77048267e-04]\n",
      " [4.63859890e-04 4.86858827e-04]\n",
      " [2.57611163e-04 3.12913200e-04]\n",
      " [1.69330072e-04 2.10346222e-04]\n",
      " [1.44277003e-04 2.43271763e-04]]\n",
      "Train Epoch36 out_loss 0.0015826770104467869\n",
      "Test Epoch36 layer0 out_loss 0.02268563210964203\n",
      "Test Epoch36 layer1 out_loss 0.0011860276572406292\n",
      "Test Epoch36 layer2 out_loss 0.0010631806217133999\n",
      "Test Epoch36 layer3 out_loss 0.00041587723535485566\n",
      "Test Epoch36 layer4 out_loss 0.00041463252273388207\n",
      "Test Epoch36 layer5 out_loss 0.0004205740406177938\n",
      "Test Epoch36 layer6 out_loss 0.00040678473305888474\n",
      "Test Epoch36 layer7 out_loss 0.000472582207294181\n",
      "Test Epoch36 layer8 out_loss 0.0006046267808414996\n",
      "Test Epoch36 layer9 out_loss 0.0004001159395556897\n",
      "Train 37 | out_loss 0.0014338671462610364: 100%|█| 138/138 [00:01<00:00, 102.52i\n",
      "[[3.69281395e-04 1.82673088e-01]\n",
      " [7.01820516e-04 2.39548592e-03]\n",
      " [9.48828663e-04 1.74101007e-03]\n",
      " [8.18907411e-04 1.54990038e-03]\n",
      " [5.97824682e-04 9.17627965e-04]\n",
      " [5.66817032e-04 6.86381021e-04]\n",
      " [4.53066563e-04 4.89513976e-04]\n",
      " [2.88541037e-04 3.27679344e-04]\n",
      " [1.82159519e-04 2.44376767e-04]\n",
      " [1.83838206e-04 3.09341869e-04]]\n",
      "Train Epoch37 out_loss 0.0014338671462610364\n",
      "Test Epoch37 layer0 out_loss 0.004468841943889856\n",
      "Test Epoch37 layer1 out_loss 0.0007109520956873894\n",
      "Test Epoch37 layer2 out_loss 0.0004358318692538887\n",
      "Test Epoch37 layer3 out_loss 0.00041096817585639656\n",
      "Test Epoch37 layer4 out_loss 0.000406109553296119\n",
      "Test Epoch37 layer5 out_loss 0.0004034563316963613\n",
      "Test Epoch37 layer6 out_loss 0.00040815657121129334\n",
      "Test Epoch37 layer7 out_loss 0.0004018254694528878\n",
      "Test Epoch37 layer8 out_loss 0.00043383133015595376\n",
      "Test Epoch37 layer9 out_loss 0.00044348384835757315\n",
      "Train 38 | out_loss 0.0011695318389683962: 100%|█| 138/138 [00:01<00:00, 106.64i\n",
      "[[0.00022399 0.01537289]\n",
      " [0.00051989 0.00121553]\n",
      " [0.00069528 0.00107352]\n",
      " [0.00042362 0.00069117]\n",
      " [0.00033993 0.00049876]\n",
      " [0.00035153 0.00045716]\n",
      " [0.000542   0.00047776]\n",
      " [0.00031436 0.00035278]\n",
      " [0.00021843 0.00024217]\n",
      " [0.00023257 0.00034847]]\n",
      "Train Epoch38 out_loss 0.0011695318389683962\n",
      "Test Epoch38 layer0 out_loss 0.003583465004339814\n",
      "Test Epoch38 layer1 out_loss 0.0009272954775951803\n",
      "Test Epoch38 layer2 out_loss 0.0008319597691297531\n",
      "Test Epoch38 layer3 out_loss 0.0007082864758558571\n",
      "Test Epoch38 layer4 out_loss 0.0007126007694751024\n",
      "Test Epoch38 layer5 out_loss 0.0006953697884455323\n",
      "Test Epoch38 layer6 out_loss 0.0006836709217168391\n",
      "Test Epoch38 layer7 out_loss 0.0007394081330858171\n",
      "Test Epoch38 layer8 out_loss 0.0006799052935093641\n",
      "Test Epoch38 layer9 out_loss 0.0006048929644748569\n",
      "Train 39 | out_loss 0.0013801632449030876: 100%|█| 138/138 [00:01<00:00, 104.85i\n",
      "[[3.42511909e-04 7.61706209e-02]\n",
      " [4.86822223e-04 1.53909876e-03]\n",
      " [5.32194342e-04 1.17064083e-03]\n",
      " [4.41968234e-04 7.59431476e-04]\n",
      " [3.14167178e-04 4.40979856e-04]\n",
      " [2.22023945e-04 2.56083860e-04]\n",
      " [1.72030093e-04 1.94808036e-04]\n",
      " [1.00128600e-04 1.28839465e-04]\n",
      " [8.53084554e-05 1.15518312e-04]\n",
      " [9.69222595e-05 1.47587237e-04]]\n",
      "Train Epoch39 out_loss 0.0013801632449030876\n",
      "Test Epoch39 layer0 out_loss 0.00818601530045271\n",
      "Test Epoch39 layer1 out_loss 0.001065374817699194\n",
      "Test Epoch39 layer2 out_loss 0.0027274589519947767\n",
      "Test Epoch39 layer3 out_loss 0.0022977078333497047\n",
      "Test Epoch39 layer4 out_loss 0.002366455504670739\n",
      "Test Epoch39 layer5 out_loss 0.0024423087015748024\n",
      "Test Epoch39 layer6 out_loss 0.0025122310034930706\n",
      "Test Epoch39 layer7 out_loss 0.0023815154563635588\n",
      "Test Epoch39 layer8 out_loss 0.002519036876037717\n",
      "Test Epoch39 layer9 out_loss 0.0022903375793248415\n",
      "Train 40 | out_loss 0.001299966243095696: 100%|█| 138/138 [00:01<00:00, 103.79it\n",
      "[[3.54234437e-04 1.44427537e-01]\n",
      " [5.01771171e-04 1.91259771e-03]\n",
      " [6.18165856e-04 1.36858298e-03]\n",
      " [4.78747327e-04 8.95571180e-04]\n",
      " [3.63767504e-04 5.71675270e-04]\n",
      " [3.34783826e-04 3.64065794e-04]\n",
      " [2.29843411e-04 2.20835398e-04]\n",
      " [1.24874228e-04 1.48432417e-04]\n",
      " [9.04030622e-05 1.28875925e-04]\n",
      " [1.06690639e-04 2.02287790e-04]]\n",
      "Train Epoch40 out_loss 0.001299966243095696\n",
      "Test Epoch40 layer0 out_loss 0.0034884819760918617\n",
      "Test Epoch40 layer1 out_loss 0.0005624837358482182\n",
      "Test Epoch40 layer2 out_loss 0.0007322327583096921\n",
      "Test Epoch40 layer3 out_loss 0.000442428543465212\n",
      "Test Epoch40 layer4 out_loss 0.00048049259930849075\n",
      "Test Epoch40 layer5 out_loss 0.0004784201446454972\n",
      "Test Epoch40 layer6 out_loss 0.00043066212674602866\n",
      "Test Epoch40 layer7 out_loss 0.0006019086576998234\n",
      "Test Epoch40 layer8 out_loss 0.0004487770493142307\n",
      "Test Epoch40 layer9 out_loss 0.0004922765074297786\n",
      "Train 41 | out_loss 0.0012736705830320716: 100%|█| 138/138 [00:01<00:00, 106.77i\n",
      "[[0.00037815 0.00964187]\n",
      " [0.00075328 0.00150098]\n",
      " [0.00102499 0.00188451]\n",
      " [0.00077476 0.00124075]\n",
      " [0.00059737 0.0007985 ]\n",
      " [0.00062777 0.00063203]\n",
      " [0.00039391 0.00039745]\n",
      " [0.00022728 0.00024862]\n",
      " [0.00015986 0.00022527]\n",
      " [0.00019894 0.00031675]]\n",
      "Train Epoch41 out_loss 0.0012736705830320716\n",
      "Test Epoch41 layer0 out_loss 0.003913498017936945\n",
      "Test Epoch41 layer1 out_loss 0.0016062031500041485\n",
      "Test Epoch41 layer2 out_loss 0.001106176059693098\n",
      "Test Epoch41 layer3 out_loss 0.001374245504848659\n",
      "Test Epoch41 layer4 out_loss 0.0011340955970808864\n",
      "Test Epoch41 layer5 out_loss 0.0010936374310404062\n",
      "Test Epoch41 layer6 out_loss 0.0009264365071430802\n",
      "Test Epoch41 layer7 out_loss 0.0009934207191690803\n",
      "Test Epoch41 layer8 out_loss 0.001089637167751789\n",
      "Test Epoch41 layer9 out_loss 0.0009771385230123997\n",
      "Train 42 | out_loss 0.001506870030425489: 100%|█| 138/138 [00:01<00:00, 102.40it\n",
      "[[0.00048659 0.01165582]\n",
      " [0.00055542 0.00132813]\n",
      " [0.00062125 0.00135422]\n",
      " [0.00044096 0.00072501]\n",
      " [0.00034613 0.00045113]\n",
      " [0.00029184 0.0003074 ]\n",
      " [0.00024015 0.00025483]\n",
      " [0.00015545 0.00019522]\n",
      " [0.00013351 0.00018879]\n",
      " [0.00016849 0.000246  ]]\n",
      "Train Epoch42 out_loss 0.001506870030425489\n",
      "Test Epoch42 layer0 out_loss 0.0056960792280733585\n",
      "Test Epoch42 layer1 out_loss 0.0014315448934212327\n",
      "Test Epoch42 layer2 out_loss 0.0007469780393876135\n",
      "Test Epoch42 layer3 out_loss 0.001028628321364522\n",
      "Test Epoch42 layer4 out_loss 0.0010396626312285662\n",
      "Test Epoch42 layer5 out_loss 0.0010836014989763498\n",
      "Test Epoch42 layer6 out_loss 0.0009651053114794195\n",
      "Test Epoch42 layer7 out_loss 0.001098852721042931\n",
      "Test Epoch42 layer8 out_loss 0.0011485421564429998\n",
      "Test Epoch42 layer9 out_loss 0.0010638219537213445\n",
      "Train 43 | out_loss 0.0012089929077774286: 100%|█| 138/138 [00:01<00:00, 101.60i\n",
      "[[0.0002814  0.02283752]\n",
      " [0.00051533 0.00151992]\n",
      " [0.00071243 0.00143867]\n",
      " [0.00053495 0.00104417]\n",
      " [0.00041196 0.00053596]\n",
      " [0.00035717 0.0003169 ]\n",
      " [0.00024445 0.00026708]\n",
      " [0.00016708 0.00018646]\n",
      " [0.00013539 0.00018339]\n",
      " [0.00016725 0.00023581]]\n",
      "Train Epoch43 out_loss 0.0012089929077774286\n",
      "Test Epoch43 layer0 out_loss 0.004611670039594173\n",
      "Test Epoch43 layer1 out_loss 0.0011093401117250323\n",
      "Test Epoch43 layer2 out_loss 0.0004722828743979335\n",
      "Test Epoch43 layer3 out_loss 0.00043736552470363677\n",
      "Test Epoch43 layer4 out_loss 0.0004681333666667342\n",
      "Test Epoch43 layer5 out_loss 0.00046342465793713927\n",
      "Test Epoch43 layer6 out_loss 0.0004601700056809932\n",
      "Test Epoch43 layer7 out_loss 0.0005044377758167684\n",
      "Test Epoch43 layer8 out_loss 0.00045166999916546047\n",
      "Test Epoch43 layer9 out_loss 0.00043000231380574405\n",
      "Train 44 | out_loss 0.001353480271063745: 100%|█| 138/138 [00:01<00:00, 105.27it\n",
      "[[0.0003577  0.02837065]\n",
      " [0.00068586 0.0018469 ]\n",
      " [0.00072553 0.00168677]\n",
      " [0.00054803 0.00090209]\n",
      " [0.00048582 0.00057187]\n",
      " [0.00036044 0.0003626 ]\n",
      " [0.00024773 0.00024814]\n",
      " [0.00017734 0.00018341]\n",
      " [0.00012823 0.00015473]\n",
      " [0.00014412 0.00017042]]\n",
      "Train Epoch44 out_loss 0.001353480271063745\n",
      "Test Epoch44 layer0 out_loss 0.005678262561559677\n",
      "Test Epoch44 layer1 out_loss 0.0007579026278108358\n",
      "Test Epoch44 layer2 out_loss 0.0009768852032721043\n",
      "Test Epoch44 layer3 out_loss 0.0010767241474241018\n",
      "Test Epoch44 layer4 out_loss 0.001002573873847723\n",
      "Test Epoch44 layer5 out_loss 0.0008773401496000588\n",
      "Test Epoch44 layer6 out_loss 0.0011256396537646651\n",
      "Test Epoch44 layer7 out_loss 0.0010197164956480265\n",
      "Test Epoch44 layer8 out_loss 0.000949015433434397\n",
      "Test Epoch44 layer9 out_loss 0.0008185353362932801\n",
      "Train 45 | out_loss 0.0016805417835712433: 100%|█| 138/138 [00:01<00:00, 108.61i\n",
      "[[0.00055323 0.15843554]\n",
      " [0.00055495 0.00332007]\n",
      " [0.00068209 0.00201927]\n",
      " [0.00070146 0.00148724]\n",
      " [0.00052888 0.00068125]\n",
      " [0.0005347  0.0004206 ]\n",
      " [0.00026719 0.00028958]\n",
      " [0.00019911 0.00023371]\n",
      " [0.00018988 0.00028472]\n",
      " [0.00027343 0.00036918]]\n",
      "Train Epoch45 out_loss 0.0016805417835712433\n",
      "Test Epoch45 layer0 out_loss 0.005109906196594238\n",
      "Test Epoch45 layer1 out_loss 0.0011987178586423397\n",
      "Test Epoch45 layer2 out_loss 0.0005862577818334103\n",
      "Test Epoch45 layer3 out_loss 0.0007330261869356036\n",
      "Test Epoch45 layer4 out_loss 0.0008094143122434616\n",
      "Test Epoch45 layer5 out_loss 0.0006964541971683502\n",
      "Test Epoch45 layer6 out_loss 0.0007324828184209764\n",
      "Test Epoch45 layer7 out_loss 0.0008102099527604878\n",
      "Test Epoch45 layer8 out_loss 0.000837596133351326\n",
      "Test Epoch45 layer9 out_loss 0.0006173624424263835\n",
      "Train 46 | out_loss 0.001069755177013576: 100%|█| 138/138 [00:01<00:00, 106.48it\n",
      "[[0.00018631 0.0530795 ]\n",
      " [0.0005839  0.00188391]\n",
      " [0.00077747 0.00183368]\n",
      " [0.00063146 0.00097276]\n",
      " [0.00046317 0.00047498]\n",
      " [0.00027896 0.00024656]\n",
      " [0.00017386 0.00018444]\n",
      " [0.00015376 0.00019087]\n",
      " [0.00014092 0.00019027]\n",
      " [0.00017219 0.00023238]]\n",
      "Train Epoch46 out_loss 0.001069755177013576\n",
      "Test Epoch46 layer0 out_loss 0.0036684186197817326\n",
      "Test Epoch46 layer1 out_loss 0.0022071190178394318\n",
      "Test Epoch46 layer2 out_loss 0.0012380272382870317\n",
      "Test Epoch46 layer3 out_loss 0.0005896768998354673\n",
      "Test Epoch46 layer4 out_loss 0.0005085509037598968\n",
      "Test Epoch46 layer5 out_loss 0.00047200138214975595\n",
      "Test Epoch46 layer6 out_loss 0.00047285473556257784\n",
      "Test Epoch46 layer7 out_loss 0.00041790204704739153\n",
      "Test Epoch46 layer8 out_loss 0.00045875305659137666\n",
      "Test Epoch46 layer9 out_loss 0.0005657444125972688\n",
      "Train 47 | out_loss 0.0012884074822068214: 100%|█| 138/138 [00:01<00:00, 106.51i\n",
      "[[0.0003739  0.0330249 ]\n",
      " [0.00057607 0.00189703]\n",
      " [0.00077236 0.0014582 ]\n",
      " [0.00057087 0.0009257 ]\n",
      " [0.00032546 0.0004199 ]\n",
      " [0.00028074 0.00026741]\n",
      " [0.00023645 0.00025382]\n",
      " [0.00021865 0.00026133]\n",
      " [0.00021798 0.00026912]\n",
      " [0.00023865 0.00028349]]\n",
      "Train Epoch47 out_loss 0.0012884074822068214\n",
      "Test Epoch47 layer0 out_loss 0.012264221906661987\n",
      "Test Epoch47 layer1 out_loss 0.0011580637656152248\n",
      "Test Epoch47 layer2 out_loss 0.00044654562952928245\n",
      "Test Epoch47 layer3 out_loss 0.0008485061698593199\n",
      "Test Epoch47 layer4 out_loss 0.0006639352068305016\n",
      "Test Epoch47 layer5 out_loss 0.0006266813725233078\n",
      "Test Epoch47 layer6 out_loss 0.0007823759224265814\n",
      "Test Epoch47 layer7 out_loss 0.0006796119268983603\n",
      "Test Epoch47 layer8 out_loss 0.0007273423252627254\n",
      "Test Epoch47 layer9 out_loss 0.000770511687733233\n",
      "Train 48 | out_loss 0.001286424696445465: 100%|█| 138/138 [00:01<00:00, 105.65it\n",
      "[[2.73274662e-04 2.44770828e-01]\n",
      " [5.25112206e-04 2.89740111e-03]\n",
      " [6.10354253e-04 1.42882060e-03]\n",
      " [5.46079373e-04 9.33393748e-04]\n",
      " [2.80794732e-04 3.70953019e-04]\n",
      " [2.08120690e-04 2.13329639e-04]\n",
      " [1.76224221e-04 2.10910982e-04]\n",
      " [1.97538128e-04 2.23273288e-04]\n",
      " [1.70583303e-04 1.91376746e-04]\n",
      " [1.67956583e-04 1.91929960e-04]]\n",
      "Train Epoch48 out_loss 0.001286424696445465\n",
      "Test Epoch48 layer0 out_loss 0.0032245961483567953\n",
      "Test Epoch48 layer1 out_loss 0.0011614419054239988\n",
      "Test Epoch48 layer2 out_loss 0.0005395303596742451\n",
      "Test Epoch48 layer3 out_loss 0.0004486131074372679\n",
      "Test Epoch48 layer4 out_loss 0.0005276240408420563\n",
      "Test Epoch48 layer5 out_loss 0.0005006721476092935\n",
      "Test Epoch48 layer6 out_loss 0.00043492557597346604\n",
      "Test Epoch48 layer7 out_loss 0.0006373804062604904\n",
      "Test Epoch48 layer8 out_loss 0.00043662413372658193\n",
      "Test Epoch48 layer9 out_loss 0.0005087328609079123\n",
      "Train 49 | out_loss 0.0013902663486078382: 100%|█| 138/138 [00:01<00:00, 105.88i\n",
      "[[0.00037402 0.0144177 ]\n",
      " [0.00061616 0.00150911]\n",
      " [0.00062849 0.00145435]\n",
      " [0.0005132  0.00073056]\n",
      " [0.00035902 0.00038914]\n",
      " [0.00034551 0.00033124]\n",
      " [0.00024371 0.00027722]\n",
      " [0.00024228 0.00024965]\n",
      " [0.00029893 0.00034755]\n",
      " [0.00025126 0.00022422]]\n",
      "Train Epoch49 out_loss 0.0013902663486078382\n",
      "Test Epoch49 layer0 out_loss 0.0035018196795135736\n",
      "Test Epoch49 layer1 out_loss 0.0014451282331719995\n",
      "Test Epoch49 layer2 out_loss 0.0007822249899618328\n",
      "Test Epoch49 layer3 out_loss 0.0012533265398815274\n",
      "Test Epoch49 layer4 out_loss 0.001010037143714726\n",
      "Test Epoch49 layer5 out_loss 0.0009579818579368293\n",
      "Test Epoch49 layer6 out_loss 0.0008906172588467598\n",
      "Test Epoch49 layer7 out_loss 0.001319986185990274\n",
      "Test Epoch49 layer8 out_loss 0.0012684696121141315\n",
      "Test Epoch49 layer9 out_loss 0.0009627704857848585\n",
      "Train 50 | out_loss 0.0013231212506070733: 100%|█| 138/138 [00:01<00:00, 106.71i\n",
      "[[0.00036986 0.04667455]\n",
      " [0.00052178 0.00194468]\n",
      " [0.00073693 0.00172037]\n",
      " [0.0005321  0.00112206]\n",
      " [0.00042399 0.00049052]\n",
      " [0.00032035 0.0002857 ]\n",
      " [0.00023298 0.00024842]\n",
      " [0.00017837 0.00020557]\n",
      " [0.00018534 0.00024533]\n",
      " [0.00021553 0.00023002]]\n",
      "Train Epoch50 out_loss 0.0013231212506070733\n",
      "Test Epoch50 layer0 out_loss 0.00334632839076221\n",
      "Test Epoch50 layer1 out_loss 0.0004479694471228868\n",
      "Test Epoch50 layer2 out_loss 0.0010344331385567784\n",
      "Test Epoch50 layer3 out_loss 0.0004752047243528068\n",
      "Test Epoch50 layer4 out_loss 0.0004384822095744312\n",
      "Test Epoch50 layer5 out_loss 0.0004312658857088536\n",
      "Test Epoch50 layer6 out_loss 0.00039640648174099624\n",
      "Test Epoch50 layer7 out_loss 0.00044584600254893303\n",
      "Test Epoch50 layer8 out_loss 0.00040174907189793885\n",
      "Test Epoch50 layer9 out_loss 0.00046091206604614854\n",
      "Train 51 | out_loss 0.0010563149116933346: 100%|█| 138/138 [00:01<00:00, 109.27i\n",
      "[[0.00021817 0.02691088]\n",
      " [0.00057661 0.00185515]\n",
      " [0.00074292 0.00161857]\n",
      " [0.00044776 0.00088954]\n",
      " [0.00034447 0.00038217]\n",
      " [0.00024985 0.00025228]\n",
      " [0.00020682 0.00020191]\n",
      " [0.00019758 0.00019762]\n",
      " [0.000186   0.00021629]\n",
      " [0.00022508 0.00021699]]\n",
      "Train Epoch51 out_loss 0.0010563149116933346\n",
      "Test Epoch51 layer0 out_loss 0.0048214104026556015\n",
      "Test Epoch51 layer1 out_loss 0.001971515594050288\n",
      "Test Epoch51 layer2 out_loss 0.0016135082114487886\n",
      "Test Epoch51 layer3 out_loss 0.0019554097671061754\n",
      "Test Epoch51 layer4 out_loss 0.0016868263483047485\n",
      "Test Epoch51 layer5 out_loss 0.0018780130194500089\n",
      "Test Epoch51 layer6 out_loss 0.0016828281804919243\n",
      "Test Epoch51 layer7 out_loss 0.001791013521142304\n",
      "Test Epoch51 layer8 out_loss 0.0018275190377607942\n",
      "Test Epoch51 layer9 out_loss 0.0018305425764992833\n",
      "Train 52 | out_loss 0.0013050283305346966: 100%|█| 138/138 [00:01<00:00, 110.21i\n",
      "[[0.00034233 0.13522424]\n",
      " [0.00049988 0.00371717]\n",
      " [0.00066407 0.00183435]\n",
      " [0.00042328 0.00098719]\n",
      " [0.00034365 0.00047917]\n",
      " [0.00029514 0.000321  ]\n",
      " [0.00028783 0.00029313]\n",
      " [0.00022603 0.00022803]\n",
      " [0.00018314 0.0001914 ]\n",
      " [0.00017037 0.0001763 ]]\n",
      "Train Epoch52 out_loss 0.0013050283305346966\n",
      "Test Epoch52 layer0 out_loss 0.00899212434887886\n",
      "Test Epoch52 layer1 out_loss 0.004113808739930391\n",
      "Test Epoch52 layer2 out_loss 0.0035279945004731417\n",
      "Test Epoch52 layer3 out_loss 0.003255414078012109\n",
      "Test Epoch52 layer4 out_loss 0.0030297713819891214\n",
      "Test Epoch52 layer5 out_loss 0.0028858103323727846\n",
      "Test Epoch52 layer6 out_loss 0.0031314140651375055\n",
      "Test Epoch52 layer7 out_loss 0.003006621031090617\n",
      "Test Epoch52 layer8 out_loss 0.0030442264396697283\n",
      "Test Epoch52 layer9 out_loss 0.0030538872815668583\n",
      "Train 53 | out_loss 0.0014281996991485357: 100%|█| 138/138 [00:01<00:00, 107.80i\n",
      "[[0.00041236 0.07679329]\n",
      " [0.00045118 0.00202239]\n",
      " [0.00049987 0.00120935]\n",
      " [0.00030631 0.00058178]\n",
      " [0.00022836 0.00028918]\n",
      " [0.00020628 0.00019709]\n",
      " [0.00017685 0.00019093]\n",
      " [0.00012314 0.00012688]\n",
      " [0.00012395 0.00016471]\n",
      " [0.00018961 0.00020537]]\n",
      "Train Epoch53 out_loss 0.0014281996991485357\n",
      "Test Epoch53 layer0 out_loss 0.014653535559773445\n",
      "Test Epoch53 layer1 out_loss 0.0007411810220219195\n",
      "Test Epoch53 layer2 out_loss 0.0011491184122860432\n",
      "Test Epoch53 layer3 out_loss 0.0011674209963530302\n",
      "Test Epoch53 layer4 out_loss 0.0009082125616259873\n",
      "Test Epoch53 layer5 out_loss 0.0009685241966508329\n",
      "Test Epoch53 layer6 out_loss 0.0008663342450745404\n",
      "Test Epoch53 layer7 out_loss 0.0009119227761402726\n",
      "Test Epoch53 layer8 out_loss 0.0009889805223792791\n",
      "Test Epoch53 layer9 out_loss 0.0009682771633379161\n",
      "Train 54 | out_loss 0.0014420442748814821: 100%|█| 138/138 [00:01<00:00, 110.23i\n",
      "[[3.72365026e-04 1.82612565e-01]\n",
      " [6.29382441e-04 3.10111287e-03]\n",
      " [7.55508571e-04 1.93054611e-03]\n",
      " [5.64026024e-04 1.26583482e-03]\n",
      " [4.62482015e-04 5.16917709e-04]\n",
      " [3.29185388e-04 2.96552692e-04]\n",
      " [2.49113906e-04 2.49839475e-04]\n",
      " [1.82724562e-04 1.85275335e-04]\n",
      " [1.41010513e-04 1.69250653e-04]\n",
      " [1.35321538e-04 1.30041455e-04]]\n",
      "Train Epoch54 out_loss 0.0014420442748814821\n",
      "Test Epoch54 layer0 out_loss 0.0158558152616024\n",
      "Test Epoch54 layer1 out_loss 0.0006182817160151899\n",
      "Test Epoch54 layer2 out_loss 0.0004027318791486323\n",
      "Test Epoch54 layer3 out_loss 0.0005528008914552629\n",
      "Test Epoch54 layer4 out_loss 0.00042666171793825924\n",
      "Test Epoch54 layer5 out_loss 0.0004228534235153347\n",
      "Test Epoch54 layer6 out_loss 0.0005519315600395203\n",
      "Test Epoch54 layer7 out_loss 0.0004874558944720775\n",
      "Test Epoch54 layer8 out_loss 0.00045464144204743207\n",
      "Test Epoch54 layer9 out_loss 0.00046683778055012226\n",
      "Train 55 | out_loss 0.001036606845445931: 100%|█| 138/138 [00:01<00:00, 111.31it\n",
      "[[0.0002919  0.02933118]\n",
      " [0.00046504 0.00152868]\n",
      " [0.00061413 0.00140814]\n",
      " [0.00044748 0.00075237]\n",
      " [0.00039155 0.00047765]\n",
      " [0.00033989 0.00035429]\n",
      " [0.00035129 0.00032607]\n",
      " [0.0002539  0.00020513]\n",
      " [0.00015183 0.00019347]\n",
      " [0.00016927 0.00022537]]\n",
      "Train Epoch55 out_loss 0.001036606845445931\n",
      "Test Epoch55 layer0 out_loss 0.0053723398596048355\n",
      "Test Epoch55 layer1 out_loss 0.0008957712561823428\n",
      "Test Epoch55 layer2 out_loss 0.0008018017397262156\n",
      "Test Epoch55 layer3 out_loss 0.0007900246419012547\n",
      "Test Epoch55 layer4 out_loss 0.00073700409848243\n",
      "Test Epoch55 layer5 out_loss 0.0009150162804871798\n",
      "Test Epoch55 layer6 out_loss 0.0009337113006040454\n",
      "Test Epoch55 layer7 out_loss 0.0008296989253722131\n",
      "Test Epoch55 layer8 out_loss 0.0008573330123908818\n",
      "Test Epoch55 layer9 out_loss 0.000923052488360554\n",
      "Train 56 | out_loss 0.001452723634429276: 100%|█| 138/138 [00:01<00:00, 111.24it\n",
      "[[0.00039948 0.0192036 ]\n",
      " [0.00051536 0.00166299]\n",
      " [0.00065349 0.00149421]\n",
      " [0.00046228 0.00087499]\n",
      " [0.00038849 0.00047732]\n",
      " [0.00040121 0.00042052]\n",
      " [0.00047234 0.00049914]\n",
      " [0.00038907 0.00034746]\n",
      " [0.00030251 0.00033569]\n",
      " [0.00025737 0.00027202]]\n",
      "Train Epoch56 out_loss 0.001452723634429276\n",
      "Test Epoch56 layer0 out_loss 0.00675542326644063\n",
      "Test Epoch56 layer1 out_loss 0.006406773813068867\n",
      "Test Epoch56 layer2 out_loss 0.004957508761435747\n",
      "Test Epoch56 layer3 out_loss 0.005552786402404308\n",
      "Test Epoch56 layer4 out_loss 0.005153195932507515\n",
      "Test Epoch56 layer5 out_loss 0.0052272784523665905\n",
      "Test Epoch56 layer6 out_loss 0.0053201699629426\n",
      "Test Epoch56 layer7 out_loss 0.005130878649652004\n",
      "Test Epoch56 layer8 out_loss 0.005216361954808235\n",
      "Test Epoch56 layer9 out_loss 0.005309684667736292\n",
      "Train 57 | out_loss 0.0012118699960410595: 100%|█| 138/138 [00:01<00:00, 110.17i\n",
      "[[0.00039285 0.0068383 ]\n",
      " [0.00055478 0.00177752]\n",
      " [0.00063299 0.00142759]\n",
      " [0.00047542 0.00082733]\n",
      " [0.00041878 0.00044711]\n",
      " [0.00041232 0.00040317]\n",
      " [0.00038055 0.00046268]\n",
      " [0.00026258 0.00021832]\n",
      " [0.00020021 0.00021487]\n",
      " [0.00017912 0.00018845]]\n",
      "Train Epoch57 out_loss 0.0012118699960410595\n",
      "Test Epoch57 layer0 out_loss 0.0058739567175507545\n",
      "Test Epoch57 layer1 out_loss 0.000701438169926405\n",
      "Test Epoch57 layer2 out_loss 0.0004140166856814176\n",
      "Test Epoch57 layer3 out_loss 0.0004862444766331464\n",
      "Test Epoch57 layer4 out_loss 0.00046712058247067034\n",
      "Test Epoch57 layer5 out_loss 0.00044137463555671275\n",
      "Test Epoch57 layer6 out_loss 0.0004149785381741822\n",
      "Test Epoch57 layer7 out_loss 0.0004801694303750992\n",
      "Test Epoch57 layer8 out_loss 0.0004016040184069425\n",
      "Test Epoch57 layer9 out_loss 0.0004396906588226557\n",
      "Train 58 | out_loss 0.0012129555689170957: 100%|█| 138/138 [00:01<00:00, 112.26i\n",
      "[[0.00032689 0.03452321]\n",
      " [0.00042388 0.00181019]\n",
      " [0.00057197 0.00156664]\n",
      " [0.00041286 0.00086948]\n",
      " [0.00058505 0.00057433]\n",
      " [0.00044349 0.00045336]\n",
      " [0.00025541 0.00028176]\n",
      " [0.00019115 0.0001938 ]\n",
      " [0.00016182 0.00020502]\n",
      " [0.00019241 0.00022745]]\n",
      "Train Epoch58 out_loss 0.0012129555689170957\n",
      "Test Epoch58 layer0 out_loss 0.014752613380551338\n",
      "Test Epoch58 layer1 out_loss 0.0022200692910701036\n",
      "Test Epoch58 layer2 out_loss 0.0007337590795941651\n",
      "Test Epoch58 layer3 out_loss 0.00040577547042630613\n",
      "Test Epoch58 layer4 out_loss 0.000403966085286811\n",
      "Test Epoch58 layer5 out_loss 0.0004021107451990247\n",
      "Test Epoch58 layer6 out_loss 0.000399832206312567\n",
      "Test Epoch58 layer7 out_loss 0.00040053846896626055\n",
      "Test Epoch58 layer8 out_loss 0.00041088677244260907\n",
      "Test Epoch58 layer9 out_loss 0.00040987401735037565\n",
      "Train 59 | out_loss 0.0011607315391302109: 100%|█| 138/138 [00:01<00:00, 107.99i\n",
      "[[0.00028435 0.0252877 ]\n",
      " [0.00055546 0.00215454]\n",
      " [0.00077987 0.00178487]\n",
      " [0.00052711 0.00080045]\n",
      " [0.00040108 0.00045391]\n",
      " [0.00028496 0.00031135]\n",
      " [0.00022386 0.00027487]\n",
      " [0.00023267 0.00027332]\n",
      " [0.00022339 0.00028492]\n",
      " [0.00027689 0.00031764]]\n",
      "Train Epoch59 out_loss 0.0011607315391302109\n",
      "Test Epoch59 layer0 out_loss 0.006497336085885763\n",
      "Test Epoch59 layer1 out_loss 0.0019960517529398203\n",
      "Test Epoch59 layer2 out_loss 0.0005588456988334656\n",
      "Test Epoch59 layer3 out_loss 0.0007136178901419044\n",
      "Test Epoch59 layer4 out_loss 0.0006264808471314609\n",
      "Test Epoch59 layer5 out_loss 0.0007065187091939151\n",
      "Test Epoch59 layer6 out_loss 0.0007586983847431839\n",
      "Test Epoch59 layer7 out_loss 0.0007411353290081024\n",
      "Test Epoch59 layer8 out_loss 0.0008271780679933727\n",
      "Test Epoch59 layer9 out_loss 0.0008022654219530523\n",
      "Train 60 | out_loss 0.001358421053737402: 100%|█| 138/138 [00:01<00:00, 109.63it\n",
      "[[3.89249838e-04 2.18345557e-01]\n",
      " [5.42649064e-04 3.52331992e-03]\n",
      " [5.64723301e-04 1.39634455e-03]\n",
      " [4.01752542e-04 6.93680792e-04]\n",
      " [3.00555258e-04 3.91500197e-04]\n",
      " [2.79112492e-04 3.16063402e-04]\n",
      " [2.08361867e-04 2.15688051e-04]\n",
      " [2.07011047e-04 2.54089372e-04]\n",
      " [2.41755776e-04 2.61847642e-04]\n",
      " [2.28787173e-04 2.24857192e-04]]\n",
      "Train Epoch60 out_loss 0.001358421053737402\n",
      "Test Epoch60 layer0 out_loss 0.006608921103179455\n",
      "Test Epoch60 layer1 out_loss 0.0009014899842441082\n",
      "Test Epoch60 layer2 out_loss 0.00039929215563461185\n",
      "Test Epoch60 layer3 out_loss 0.0004987397114746273\n",
      "Test Epoch60 layer4 out_loss 0.00043729052413254976\n",
      "Test Epoch60 layer5 out_loss 0.00041693405364640057\n",
      "Test Epoch60 layer6 out_loss 0.00041920298826880753\n",
      "Test Epoch60 layer7 out_loss 0.0004127916763536632\n",
      "Test Epoch60 layer8 out_loss 0.0004212620260659605\n",
      "Test Epoch60 layer9 out_loss 0.00041190729825757444\n",
      "Train 61 | out_loss 0.0011980204144492745: 100%|█| 138/138 [00:01<00:00, 110.34i\n",
      "[[0.00036852 0.03276504]\n",
      " [0.0004737  0.00185842]\n",
      " [0.00058432 0.00154843]\n",
      " [0.00040823 0.00080987]\n",
      " [0.00039665 0.00052088]\n",
      " [0.00051644 0.00051345]\n",
      " [0.0003343  0.00030091]\n",
      " [0.00025531 0.00021781]\n",
      " [0.00020657 0.00020738]\n",
      " [0.00014867 0.00017748]]\n",
      "Train Epoch61 out_loss 0.0011980204144492745\n",
      "Test Epoch61 layer0 out_loss 0.006457669660449028\n",
      "Test Epoch61 layer1 out_loss 0.0007329382351599634\n",
      "Test Epoch61 layer2 out_loss 0.0003861395816784352\n",
      "Test Epoch61 layer3 out_loss 0.00040300784166902304\n",
      "Test Epoch61 layer4 out_loss 0.000490283127874136\n",
      "Test Epoch61 layer5 out_loss 0.00045802551903761923\n",
      "Test Epoch61 layer6 out_loss 0.00044055748730897903\n",
      "Test Epoch61 layer7 out_loss 0.0004584408306982368\n",
      "Test Epoch61 layer8 out_loss 0.00045409140875563025\n",
      "Test Epoch61 layer9 out_loss 0.0004559338267426938\n",
      "Train 62 | out_loss 0.001315237139351666: 100%|█| 138/138 [00:01<00:00, 110.56it\n",
      "[[0.00034881 0.00581732]\n",
      " [0.00046234 0.00156482]\n",
      " [0.00058047 0.00130334]\n",
      " [0.00039767 0.00055936]\n",
      " [0.00036871 0.00041544]\n",
      " [0.00022394 0.00025276]\n",
      " [0.00019025 0.0001759 ]\n",
      " [0.00014537 0.0001535 ]\n",
      " [0.00011921 0.00014289]\n",
      " [0.00011023 0.00014595]]\n",
      "Train Epoch62 out_loss 0.001315237139351666\n",
      "Test Epoch62 layer0 out_loss 0.005618331488221884\n",
      "Test Epoch62 layer1 out_loss 0.001079415320418775\n",
      "Test Epoch62 layer2 out_loss 0.0004164044512435794\n",
      "Test Epoch62 layer3 out_loss 0.00047892381553538144\n",
      "Test Epoch62 layer4 out_loss 0.00043048191582784057\n",
      "Test Epoch62 layer5 out_loss 0.0004116985364817083\n",
      "Test Epoch62 layer6 out_loss 0.00042067168396897614\n",
      "Test Epoch62 layer7 out_loss 0.000409455707995221\n",
      "Test Epoch62 layer8 out_loss 0.00041911876178346574\n",
      "Test Epoch62 layer9 out_loss 0.00040491169784218073\n",
      "Train 63 | out_loss 0.001481133047491312: 100%|█| 138/138 [00:01<00:00, 108.50it\n",
      "[[0.00049922 0.03190387]\n",
      " [0.00042253 0.00212161]\n",
      " [0.00057369 0.00155833]\n",
      " [0.00049403 0.00091005]\n",
      " [0.0005043  0.00056438]\n",
      " [0.00024369 0.00024993]\n",
      " [0.0001803  0.00017577]\n",
      " [0.0001445  0.0001744 ]\n",
      " [0.0001659  0.00018904]\n",
      " [0.0001457  0.00017431]]\n",
      "Train Epoch63 out_loss 0.001481133047491312\n",
      "Test Epoch63 layer0 out_loss 0.0014370825374498963\n",
      "Test Epoch63 layer1 out_loss 0.000817057560198009\n",
      "Test Epoch63 layer2 out_loss 0.0004983123508282006\n",
      "Test Epoch63 layer3 out_loss 0.0005257405573502183\n",
      "Test Epoch63 layer4 out_loss 0.0005788767011836171\n",
      "Test Epoch63 layer5 out_loss 0.0004896574537269771\n",
      "Test Epoch63 layer6 out_loss 0.0004509144346229732\n",
      "Test Epoch63 layer7 out_loss 0.00044293285463936627\n",
      "Test Epoch63 layer8 out_loss 0.0004759441071655601\n",
      "Test Epoch63 layer9 out_loss 0.0005185333429835737\n",
      "Train 64 | out_loss 0.0013186356518417597: 100%|█| 138/138 [00:01<00:00, 110.50i\n",
      "[[0.00034799 0.03090272]\n",
      " [0.0004874  0.00227171]\n",
      " [0.00055823 0.00153334]\n",
      " [0.00041657 0.0006958 ]\n",
      " [0.00041813 0.00045858]\n",
      " [0.00027466 0.00027227]\n",
      " [0.00017673 0.00017318]\n",
      " [0.00014908 0.00015204]\n",
      " [0.00013211 0.00014514]\n",
      " [0.00010858 0.00013705]]\n",
      "Train Epoch64 out_loss 0.0013186356518417597\n",
      "Test Epoch64 layer0 out_loss 0.011190087534487247\n",
      "Test Epoch64 layer1 out_loss 0.0016067418036982417\n",
      "Test Epoch64 layer2 out_loss 0.0014475317439064384\n",
      "Test Epoch64 layer3 out_loss 0.0007042472716420889\n",
      "Test Epoch64 layer4 out_loss 0.0008419394143857062\n",
      "Test Epoch64 layer5 out_loss 0.0006769775645807385\n",
      "Test Epoch64 layer6 out_loss 0.00073766935383901\n",
      "Test Epoch64 layer7 out_loss 0.0007886577514000237\n",
      "Test Epoch64 layer8 out_loss 0.000806340656708926\n",
      "Test Epoch64 layer9 out_loss 0.0008278161403723061\n",
      "Train 65 | out_loss 0.0016018757596611977: 100%|█| 138/138 [00:01<00:00, 109.71i\n",
      "[[0.00055321 0.03859551]\n",
      " [0.00053575 0.00252144]\n",
      " [0.00068158 0.00174981]\n",
      " [0.00044579 0.00071853]\n",
      " [0.00039746 0.00042899]\n",
      " [0.00028289 0.00028714]\n",
      " [0.000194   0.00017193]\n",
      " [0.00014077 0.00014944]\n",
      " [0.00012688 0.00013984]\n",
      " [0.00010816 0.00012929]]\n",
      "Train Epoch65 out_loss 0.0016018757596611977\n",
      "Test Epoch65 layer0 out_loss 0.004416162613779306\n",
      "Test Epoch65 layer1 out_loss 0.0017380132339894772\n",
      "Test Epoch65 layer2 out_loss 0.0008781010401435196\n",
      "Test Epoch65 layer3 out_loss 0.00040197913767769933\n",
      "Test Epoch65 layer4 out_loss 0.0004241870774421841\n",
      "Test Epoch65 layer5 out_loss 0.00042162605677731335\n",
      "Test Epoch65 layer6 out_loss 0.00041020018397830427\n",
      "Test Epoch65 layer7 out_loss 0.00040938108577392995\n",
      "Test Epoch65 layer8 out_loss 0.00042338864295743406\n",
      "Test Epoch65 layer9 out_loss 0.00040786838508211076\n",
      "Train 66 | out_loss 0.0005199930747039616: 100%|█| 138/138 [00:01<00:00, 108.05i\n",
      "[[1.33338341e-05 7.35923737e-02]\n",
      " [4.26257517e-04 2.59832711e-03]\n",
      " [5.44124061e-04 1.55720696e-03]\n",
      " [3.44145090e-04 6.16919924e-04]\n",
      " [2.27671032e-04 3.05592046e-04]\n",
      " [2.19503671e-04 2.18635197e-04]\n",
      " [1.63648332e-04 1.37809474e-04]\n",
      " [1.17868693e-04 1.19696724e-04]\n",
      " [9.42318938e-05 1.20594453e-04]\n",
      " [9.97513705e-05 1.32818858e-04]]\n",
      "Train Epoch66 out_loss 0.0005199930747039616\n",
      "Test Epoch66 layer0 out_loss 0.00610650097951293\n",
      "Test Epoch66 layer1 out_loss 0.0009585182997398078\n",
      "Test Epoch66 layer2 out_loss 0.0004802780458703637\n",
      "Test Epoch66 layer3 out_loss 0.00044340069871395826\n",
      "Test Epoch66 layer4 out_loss 0.00040816684486344457\n",
      "Test Epoch66 layer5 out_loss 0.00040541295311413705\n",
      "Test Epoch66 layer6 out_loss 0.0004014215664938092\n",
      "Test Epoch66 layer7 out_loss 0.00041359258466400206\n",
      "Test Epoch66 layer8 out_loss 0.00040950882248580456\n",
      "Test Epoch66 layer9 out_loss 0.00040012068348005414\n",
      "Train 67 | out_loss 0.0013441027840599418: 100%|█| 138/138 [00:01<00:00, 106.79i\n",
      "[[0.0003257  0.03163306]\n",
      " [0.00042267 0.00205577]\n",
      " [0.00052423 0.00121443]\n",
      " [0.00043879 0.00056932]\n",
      " [0.00022822 0.00028036]\n",
      " [0.00019765 0.00019721]\n",
      " [0.00018241 0.00018208]\n",
      " [0.0001335  0.00016151]\n",
      " [0.00012339 0.00016634]\n",
      " [0.00014154 0.00018737]]\n",
      "Train Epoch67 out_loss 0.0013441027840599418\n",
      "Test Epoch67 layer0 out_loss 0.0029489118605852127\n",
      "Test Epoch67 layer1 out_loss 0.0005122264265082777\n",
      "Test Epoch67 layer2 out_loss 0.0005187154747545719\n",
      "Test Epoch67 layer3 out_loss 0.0005985264433547854\n",
      "Test Epoch67 layer4 out_loss 0.0004459066258277744\n",
      "Test Epoch67 layer5 out_loss 0.0004549208970274776\n",
      "Test Epoch67 layer6 out_loss 0.0004654587828554213\n",
      "Test Epoch67 layer7 out_loss 0.0004855063743889332\n",
      "Test Epoch67 layer8 out_loss 0.0004923806991428137\n",
      "Test Epoch67 layer9 out_loss 0.00047803044435568154\n",
      "Train 68 | out_loss 0.001225836225785315: 100%|█| 138/138 [00:01<00:00, 106.62it\n",
      "[[2.88169607e-04 1.90728906e-02]\n",
      " [4.82876520e-04 2.13683618e-03]\n",
      " [5.76804466e-04 1.36939064e-03]\n",
      " [3.64716003e-04 6.15467481e-04]\n",
      " [2.74072522e-04 2.90178768e-04]\n",
      " [2.02844440e-04 1.81472553e-04]\n",
      " [1.36973976e-04 1.31568475e-04]\n",
      " [1.03084601e-04 1.10678109e-04]\n",
      " [8.15658167e-05 9.66988952e-05]\n",
      " [9.18648084e-05 1.05362612e-04]]\n",
      "Train Epoch68 out_loss 0.001225836225785315\n",
      "Test Epoch68 layer0 out_loss 0.004728153347969055\n",
      "Test Epoch68 layer1 out_loss 0.0036681664641946554\n",
      "Test Epoch68 layer2 out_loss 0.0028389275539666414\n",
      "Test Epoch68 layer3 out_loss 0.0031789150089025497\n",
      "Test Epoch68 layer4 out_loss 0.003090029349550605\n",
      "Test Epoch68 layer5 out_loss 0.003060102229937911\n",
      "Test Epoch68 layer6 out_loss 0.003162162145599723\n",
      "Test Epoch68 layer7 out_loss 0.003076094901189208\n",
      "Test Epoch68 layer8 out_loss 0.0030984070617705584\n",
      "Test Epoch68 layer9 out_loss 0.003083641640841961\n",
      "Train 69 | out_loss 0.0014170509530231357: 100%|█| 138/138 [00:01<00:00, 104.95i\n",
      "[[0.00048009 0.02050863]\n",
      " [0.00049653 0.00222786]\n",
      " [0.00065117 0.00154245]\n",
      " [0.00047247 0.0007255 ]\n",
      " [0.00029479 0.00029792]\n",
      " [0.00016815 0.00016369]\n",
      " [0.00013471 0.00015783]\n",
      " [0.00013171 0.00016748]\n",
      " [0.00013187 0.00017337]\n",
      " [0.0001533  0.00018694]]\n",
      "Train Epoch69 out_loss 0.0014170509530231357\n",
      "Test Epoch69 layer0 out_loss 0.0016020919429138303\n",
      "Test Epoch69 layer1 out_loss 0.000575276673771441\n",
      "Test Epoch69 layer2 out_loss 0.0005006149876862764\n",
      "Test Epoch69 layer3 out_loss 0.0004995098570361733\n",
      "Test Epoch69 layer4 out_loss 0.00046093814307823777\n",
      "Test Epoch69 layer5 out_loss 0.00040838090353645384\n",
      "Test Epoch69 layer6 out_loss 0.00040349853225052357\n",
      "Test Epoch69 layer7 out_loss 0.00043663184624165297\n",
      "Test Epoch69 layer8 out_loss 0.0004135137132834643\n",
      "Test Epoch69 layer9 out_loss 0.00042506653699092567\n",
      "Train 70 | out_loss 0.0010802666656672955: 100%|█| 138/138 [00:01<00:00, 111.58i\n",
      "[[0.00024997 0.01465545]\n",
      " [0.00031962 0.00170285]\n",
      " [0.00042322 0.00124785]\n",
      " [0.00036595 0.00065434]\n",
      " [0.00031439 0.00041119]\n",
      " [0.00036006 0.0004282 ]\n",
      " [0.0003953  0.00040313]\n",
      " [0.00033704 0.00033746]\n",
      " [0.00025475 0.00023577]\n",
      " [0.00021863 0.00023475]]\n",
      "Train Epoch70 out_loss 0.0010802666656672955\n",
      "Test Epoch70 layer0 out_loss 0.004025207832455635\n",
      "Test Epoch70 layer1 out_loss 0.00058948271907866\n",
      "Test Epoch70 layer2 out_loss 0.0009697937057353556\n",
      "Test Epoch70 layer3 out_loss 0.0010568484431132674\n",
      "Test Epoch70 layer4 out_loss 0.0010566391283646226\n",
      "Test Epoch70 layer5 out_loss 0.0007786634378135204\n",
      "Test Epoch70 layer6 out_loss 0.0009240571525879204\n",
      "Test Epoch70 layer7 out_loss 0.0009019564604386687\n",
      "Test Epoch70 layer8 out_loss 0.0009302634280174971\n",
      "Test Epoch70 layer9 out_loss 0.0008512766216881573\n",
      "Train 71 | out_loss 0.0015549702802672982: 100%|█| 138/138 [00:01<00:00, 106.10i\n",
      "[[0.00051388 0.04642068]\n",
      " [0.00048319 0.00275785]\n",
      " [0.0006232  0.00174596]\n",
      " [0.00047435 0.00072529]\n",
      " [0.00031817 0.00035867]\n",
      " [0.00024181 0.00022435]\n",
      " [0.00017183 0.00015228]\n",
      " [0.00016209 0.00014749]\n",
      " [0.00010626 0.00012332]\n",
      " [0.00012724 0.00015099]]\n",
      "Train Epoch71 out_loss 0.0015549702802672982\n",
      "Test Epoch71 layer0 out_loss 0.00411517359316349\n",
      "Test Epoch71 layer1 out_loss 0.0017109657637774944\n",
      "Test Epoch71 layer2 out_loss 0.0013832113472744823\n",
      "Test Epoch71 layer3 out_loss 0.0017844326794147491\n",
      "Test Epoch71 layer4 out_loss 0.001672105398029089\n",
      "Test Epoch71 layer5 out_loss 0.0016782041639089584\n",
      "Test Epoch71 layer6 out_loss 0.0016838194569572806\n",
      "Test Epoch71 layer7 out_loss 0.0017146790632978082\n",
      "Test Epoch71 layer8 out_loss 0.001719831838272512\n",
      "Test Epoch71 layer9 out_loss 0.0016843335470184684\n",
      "Train 72 | out_loss 0.0013958527706563473: 100%|█| 138/138 [00:01<00:00, 107.22i\n",
      "[[4.77931899e-04 1.31013294e-01]\n",
      " [4.45190284e-04 3.72494636e-03]\n",
      " [5.44627927e-04 1.57234075e-03]\n",
      " [3.64754584e-04 6.01535768e-04]\n",
      " [2.34407857e-04 2.83023023e-04]\n",
      " [4.48516391e-04 4.67503355e-04]\n",
      " [2.08252463e-04 2.11633653e-04]\n",
      " [1.46665284e-04 1.37792051e-04]\n",
      " [9.04438160e-05 1.07976907e-04]\n",
      " [8.69201627e-05 1.05847816e-04]]\n",
      "Train Epoch72 out_loss 0.0013958527706563473\n",
      "Test Epoch72 layer0 out_loss 0.0028813821263611317\n",
      "Test Epoch72 layer1 out_loss 0.0005315553862601519\n",
      "Test Epoch72 layer2 out_loss 0.0007897737086750567\n",
      "Test Epoch72 layer3 out_loss 0.0008913442143239081\n",
      "Test Epoch72 layer4 out_loss 0.0010041475761681795\n",
      "Test Epoch72 layer5 out_loss 0.0009375395602546632\n",
      "Test Epoch72 layer6 out_loss 0.0009033699170686305\n",
      "Test Epoch72 layer7 out_loss 0.0009295148774981499\n",
      "Test Epoch72 layer8 out_loss 0.000897883961442858\n",
      "Test Epoch72 layer9 out_loss 0.0009065503836609423\n",
      "Train 73 | out_loss 0.0005748923285864294: 100%|█| 138/138 [00:01<00:00, 110.19i\n",
      "[[3.43298260e-05 8.17207096e-03]\n",
      " [3.79693267e-04 1.33476857e-03]\n",
      " [4.49045898e-04 1.18980496e-03]\n",
      " [3.05594001e-04 5.13399445e-04]\n",
      " [2.74108569e-04 3.08212465e-04]\n",
      " [4.55343803e-04 4.70084028e-04]\n",
      " [3.67577405e-04 4.47153357e-04]\n",
      " [2.46822884e-04 2.09154062e-04]\n",
      " [1.50399859e-04 1.69785579e-04]\n",
      " [1.37926639e-04 1.77245007e-04]]\n",
      "Train Epoch73 out_loss 0.0005748923285864294\n",
      "Test Epoch73 layer0 out_loss 0.004683655221015215\n",
      "Test Epoch73 layer1 out_loss 0.001263099373318255\n",
      "Test Epoch73 layer2 out_loss 0.0010643796995282173\n",
      "Test Epoch73 layer3 out_loss 0.001331342151388526\n",
      "Test Epoch73 layer4 out_loss 0.0012039401335641742\n",
      "Test Epoch73 layer5 out_loss 0.0014012579340487719\n",
      "Test Epoch73 layer6 out_loss 0.001259827520698309\n",
      "Test Epoch73 layer7 out_loss 0.0012633261503651738\n",
      "Test Epoch73 layer8 out_loss 0.0012717320350930095\n",
      "Test Epoch73 layer9 out_loss 0.0012658423511311412\n",
      "Train 74 | out_loss 0.0012344822753220797: 100%|█| 138/138 [00:01<00:00, 106.61i\n",
      "[[0.00034844 0.00697366]\n",
      " [0.00035562 0.00134236]\n",
      " [0.00045698 0.0011175 ]\n",
      " [0.00028296 0.00042065]\n",
      " [0.0002315  0.00026097]\n",
      " [0.000232   0.00023314]\n",
      " [0.00022399 0.00021295]\n",
      " [0.00019247 0.0002054 ]\n",
      " [0.00010565 0.00015973]\n",
      " [0.00010806 0.00016489]]\n",
      "Train Epoch74 out_loss 0.0012344822753220797\n",
      "Test Epoch74 layer0 out_loss 0.01279600802809\n",
      "Test Epoch74 layer1 out_loss 0.0004519742797128856\n",
      "Test Epoch74 layer2 out_loss 0.0008337406907230616\n",
      "Test Epoch74 layer3 out_loss 0.00041294601396657526\n",
      "Test Epoch74 layer4 out_loss 0.00041058650822378695\n",
      "Test Epoch74 layer5 out_loss 0.00040219107177108526\n",
      "Test Epoch74 layer6 out_loss 0.0004015417071059346\n",
      "Test Epoch74 layer7 out_loss 0.0003997253952547908\n",
      "Test Epoch74 layer8 out_loss 0.000400343764340505\n",
      "Test Epoch74 layer9 out_loss 0.0004012830904684961\n",
      "Train 75 | out_loss 0.001519057434052229: 100%|█| 138/138 [00:01<00:00, 109.05it\n",
      "[[0.00045712 0.01822375]\n",
      " [0.00045376 0.00222549]\n",
      " [0.00068638 0.00187091]\n",
      " [0.00054307 0.0006818 ]\n",
      " [0.00034485 0.00035298]\n",
      " [0.00022381 0.00023168]\n",
      " [0.00019789 0.00020645]\n",
      " [0.00016075 0.00015816]\n",
      " [0.00013173 0.00016324]\n",
      " [0.00015882 0.00018518]]\n",
      "Train Epoch75 out_loss 0.001519057434052229\n",
      "Test Epoch75 layer0 out_loss 0.0030447174794971943\n",
      "Test Epoch75 layer1 out_loss 0.0006496954010799527\n",
      "Test Epoch75 layer2 out_loss 0.00040993752190843225\n",
      "Test Epoch75 layer3 out_loss 0.00044956817873753607\n",
      "Test Epoch75 layer4 out_loss 0.0004310256044846028\n",
      "Test Epoch75 layer5 out_loss 0.00041037931805476546\n",
      "Test Epoch75 layer6 out_loss 0.0004083629173692316\n",
      "Test Epoch75 layer7 out_loss 0.00040183248347602785\n",
      "Test Epoch75 layer8 out_loss 0.0004054162709508091\n",
      "Test Epoch75 layer9 out_loss 0.0004044033703394234\n",
      "Train 76 | out_loss 0.0013728681951761246: 100%|█| 138/138 [00:01<00:00, 104.98i\n",
      "[[0.00034834 0.00515588]\n",
      " [0.00035072 0.00163988]\n",
      " [0.00044466 0.00098646]\n",
      " [0.00030643 0.00042254]\n",
      " [0.00029285 0.00032353]\n",
      " [0.00029726 0.00032889]\n",
      " [0.00019036 0.00017035]\n",
      " [0.00013532 0.00013452]\n",
      " [0.00010977 0.00012652]\n",
      " [0.00011689 0.00013286]]\n",
      "Train Epoch76 out_loss 0.0013728681951761246\n",
      "Test Epoch76 layer0 out_loss 0.0038800255861133337\n",
      "Test Epoch76 layer1 out_loss 0.0007631239132024348\n",
      "Test Epoch76 layer2 out_loss 0.0004657688841689378\n",
      "Test Epoch76 layer3 out_loss 0.0005668840021826327\n",
      "Test Epoch76 layer4 out_loss 0.0005256566219031811\n",
      "Test Epoch76 layer5 out_loss 0.0005135384853929281\n",
      "Test Epoch76 layer6 out_loss 0.0005469939205795527\n",
      "Test Epoch76 layer7 out_loss 0.0005351288709789515\n",
      "Test Epoch76 layer8 out_loss 0.0005348441191017628\n",
      "Test Epoch76 layer9 out_loss 0.0005321998614817858\n",
      "Train 77 | out_loss 0.0018469271017238498: 100%|█| 138/138 [00:01<00:00, 107.84i\n",
      "[[0.00072607 0.0350439 ]\n",
      " [0.00036816 0.00245991]\n",
      " [0.0005104  0.00158381]\n",
      " [0.00036488 0.00057702]\n",
      " [0.00029418 0.00034465]\n",
      " [0.00021212 0.00020545]\n",
      " [0.00016128 0.00017457]\n",
      " [0.00015723 0.00015452]\n",
      " [0.00010565 0.00012011]\n",
      " [0.00010189 0.0001159 ]]\n",
      "Train Epoch77 out_loss 0.0018469271017238498\n",
      "Test Epoch77 layer0 out_loss 0.0036324362736195326\n",
      "Test Epoch77 layer1 out_loss 0.0005773112061433494\n",
      "Test Epoch77 layer2 out_loss 0.00048623207840137184\n",
      "Test Epoch77 layer3 out_loss 0.0004718129930552095\n",
      "Test Epoch77 layer4 out_loss 0.000516357074957341\n",
      "Test Epoch77 layer5 out_loss 0.0005357396439649165\n",
      "Test Epoch77 layer6 out_loss 0.0005157461855560541\n",
      "Test Epoch77 layer7 out_loss 0.0005074343644082546\n",
      "Test Epoch77 layer8 out_loss 0.0005159788415767252\n",
      "Test Epoch77 layer9 out_loss 0.0005263732746243477\n",
      "Train 78 | out_loss 0.00047053612070158124: 100%|█| 138/138 [00:01<00:00, 105.80\n",
      "[[7.34843732e-07 2.41677487e-02]\n",
      " [3.33066916e-04 1.66168239e-03]\n",
      " [3.93505131e-04 1.03826847e-03]\n",
      " [2.60691047e-04 4.04555318e-04]\n",
      " [2.03498029e-04 2.43611731e-04]\n",
      " [1.83266110e-04 1.71530968e-04]\n",
      " [1.47129628e-04 1.44228762e-04]\n",
      " [1.11076348e-04 1.04550871e-04]\n",
      " [8.85221039e-05 1.09586225e-04]\n",
      " [1.00536089e-04 1.27949656e-04]]\n",
      "Train Epoch78 out_loss 0.00047053612070158124\n",
      "Test Epoch78 layer0 out_loss 0.0028471825644373894\n",
      "Test Epoch78 layer1 out_loss 0.0006799347465857863\n",
      "Test Epoch78 layer2 out_loss 0.0004854140861425549\n",
      "Test Epoch78 layer3 out_loss 0.0005377210909500718\n",
      "Test Epoch78 layer4 out_loss 0.0004607821465469897\n",
      "Test Epoch78 layer5 out_loss 0.0005231302930042148\n",
      "Test Epoch78 layer6 out_loss 0.0005500347469933331\n",
      "Test Epoch78 layer7 out_loss 0.0005411307211034\n",
      "Test Epoch78 layer8 out_loss 0.0005201447056606412\n",
      "Test Epoch78 layer9 out_loss 0.000527382711879909\n",
      "Train 79 | out_loss 0.001608853810466826: 100%|█| 138/138 [00:01<00:00, 108.74it\n",
      "[[5.86945389e-04 7.59755396e-02]\n",
      " [4.44132244e-04 3.31124314e-03]\n",
      " [6.00177788e-04 1.42035834e-03]\n",
      " [3.90313491e-04 6.71387226e-04]\n",
      " [2.42602877e-04 3.65849392e-04]\n",
      " [2.03471217e-04 1.83905866e-04]\n",
      " [1.43302890e-04 1.39620916e-04]\n",
      " [1.08835018e-04 1.15223371e-04]\n",
      " [9.49363964e-05 1.27904745e-04]\n",
      " [1.12636206e-04 1.41867661e-04]]\n",
      "Train Epoch79 out_loss 0.001608853810466826\n",
      "Test Epoch79 layer0 out_loss 0.025213729590177536\n",
      "Test Epoch79 layer1 out_loss 0.0005745350499637425\n",
      "Test Epoch79 layer2 out_loss 0.0007544478867202997\n",
      "Test Epoch79 layer3 out_loss 0.00040206106496043503\n",
      "Test Epoch79 layer4 out_loss 0.000423175428295508\n",
      "Test Epoch79 layer5 out_loss 0.00041507245623506606\n",
      "Test Epoch79 layer6 out_loss 0.00041995980427600443\n",
      "Test Epoch79 layer7 out_loss 0.0004117019707337022\n",
      "Test Epoch79 layer8 out_loss 0.0004237621615175158\n",
      "Test Epoch79 layer9 out_loss 0.00041919114300981164\n",
      "Train 80 | out_loss 0.0004604184068739414: 100%|█| 138/138 [00:01<00:00, 104.01i\n",
      "[[1.54294498e-06 4.26633143e-02]\n",
      " [4.09211467e-04 2.63125134e-03]\n",
      " [4.93839422e-04 1.59730743e-03]\n",
      " [3.66214001e-04 5.68771154e-04]\n",
      " [2.45649959e-04 3.11896316e-04]\n",
      " [1.99005957e-04 1.75615868e-04]\n",
      " [1.33089661e-04 1.20420449e-04]\n",
      " [9.96359545e-05 1.04691203e-04]\n",
      " [8.52982396e-05 1.39970971e-04]\n",
      " [1.07015629e-04 1.61998641e-04]]\n",
      "Train Epoch80 out_loss 0.0004604184068739414\n",
      "Test Epoch80 layer0 out_loss 0.004317736253142357\n",
      "Test Epoch80 layer1 out_loss 0.0010539843933656812\n",
      "Test Epoch80 layer2 out_loss 0.0013024567160755396\n",
      "Test Epoch80 layer3 out_loss 0.001030772808007896\n",
      "Test Epoch80 layer4 out_loss 0.0009347726008854806\n",
      "Test Epoch80 layer5 out_loss 0.0009513320401310921\n",
      "Test Epoch80 layer6 out_loss 0.0009213692974299192\n",
      "Test Epoch80 layer7 out_loss 0.0009353231871500611\n",
      "Test Epoch80 layer8 out_loss 0.0009434744133614004\n",
      "Test Epoch80 layer9 out_loss 0.0009381080162711442\n",
      "Train 81 | out_loss 0.0014251441461965442: 100%|█| 138/138 [00:01<00:00, 105.51i\n",
      "[[4.36678852e-04 3.19672443e-03]\n",
      " [4.36021032e-04 1.56060074e-03]\n",
      " [6.80090588e-04 1.19134856e-03]\n",
      " [3.32670027e-04 4.28324122e-04]\n",
      " [2.01932670e-04 2.22937991e-04]\n",
      " [1.53479895e-04 1.27608555e-04]\n",
      " [1.09634676e-04 9.97141407e-05]\n",
      " [9.91745293e-05 1.16973231e-04]\n",
      " [8.96284558e-05 1.23073221e-04]\n",
      " [9.30833405e-05 1.27106632e-04]]\n",
      "Train Epoch81 out_loss 0.0014251441461965442\n",
      "Test Epoch81 layer0 out_loss 0.0011884663254022598\n",
      "Test Epoch81 layer1 out_loss 0.0005366943078115582\n",
      "Test Epoch81 layer2 out_loss 0.0005211339448578656\n",
      "Test Epoch81 layer3 out_loss 0.0004847070958930999\n",
      "Test Epoch81 layer4 out_loss 0.00047648564213886857\n",
      "Test Epoch81 layer5 out_loss 0.0005391844315454364\n",
      "Test Epoch81 layer6 out_loss 0.0005128876655362546\n",
      "Test Epoch81 layer7 out_loss 0.0005309072439558804\n",
      "Test Epoch81 layer8 out_loss 0.000520059431437403\n",
      "Test Epoch81 layer9 out_loss 0.0005517954705283046\n",
      "Train 82 | out_loss 0.0014214407419785857: 100%|█| 138/138 [00:01<00:00, 103.08i\n",
      "[[0.00043484 0.04898233]\n",
      " [0.00053778 0.00324745]\n",
      " [0.00069582 0.00179345]\n",
      " [0.00054797 0.00062822]\n",
      " [0.00025597 0.00030202]\n",
      " [0.00019405 0.00018447]\n",
      " [0.00015513 0.00016412]\n",
      " [0.00018559 0.00018918]\n",
      " [0.0001631  0.00019604]\n",
      " [0.00017995 0.00021895]]\n",
      "Train Epoch82 out_loss 0.0014214407419785857\n",
      "Test Epoch82 layer0 out_loss 0.004574259277433157\n",
      "Test Epoch82 layer1 out_loss 0.0013054433511570096\n",
      "Test Epoch82 layer2 out_loss 0.00047375221038237214\n",
      "Test Epoch82 layer3 out_loss 0.00042372310417704284\n",
      "Test Epoch82 layer4 out_loss 0.0004729677748400718\n",
      "Test Epoch82 layer5 out_loss 0.0004562778340186924\n",
      "Test Epoch82 layer6 out_loss 0.0004373975971248001\n",
      "Test Epoch82 layer7 out_loss 0.0004453373549040407\n",
      "Test Epoch82 layer8 out_loss 0.0004294099926482886\n",
      "Test Epoch82 layer9 out_loss 0.00044866223470307887\n",
      "Train 83 | out_loss 0.0014710924588143826: 100%|█| 138/138 [00:01<00:00, 104.71i\n",
      "[[0.00041469 0.01689485]\n",
      " [0.00019676 0.00150158]\n",
      " [0.00028759 0.00114773]\n",
      " [0.00022401 0.00038896]\n",
      " [0.00022297 0.00022329]\n",
      " [0.00015395 0.00016908]\n",
      " [0.00013404 0.00012918]\n",
      " [0.00010652 0.00013409]\n",
      " [0.00010208 0.00015414]\n",
      " [0.00013528 0.00017075]]\n",
      "Train Epoch83 out_loss 0.0014710924588143826\n",
      "Test Epoch83 layer0 out_loss 0.0032148209866136312\n",
      "Test Epoch83 layer1 out_loss 0.0012255279580131173\n",
      "Test Epoch83 layer2 out_loss 0.0010769156506285071\n",
      "Test Epoch83 layer3 out_loss 0.00106542999856174\n",
      "Test Epoch83 layer4 out_loss 0.0011284996289759874\n",
      "Test Epoch83 layer5 out_loss 0.000987826380878687\n",
      "Test Epoch83 layer6 out_loss 0.0009223170927725732\n",
      "Test Epoch83 layer7 out_loss 0.0009576866868883371\n",
      "Test Epoch83 layer8 out_loss 0.0009624611120671034\n",
      "Test Epoch83 layer9 out_loss 0.0009314283379353583\n",
      "Train 84 | out_loss 0.0016383001348003745: 100%|█| 138/138 [00:01<00:00, 109.14i\n",
      "[[0.00056373 0.0108661 ]\n",
      " [0.00029368 0.00184359]\n",
      " [0.00032932 0.00091234]\n",
      " [0.00019276 0.000372  ]\n",
      " [0.0001699  0.00022534]\n",
      " [0.0001777  0.00021372]\n",
      " [0.00015053 0.00014794]\n",
      " [0.00011834 0.00013155]\n",
      " [0.00011552 0.00014329]\n",
      " [0.000106   0.00011616]]\n",
      "Train Epoch84 out_loss 0.0016383001348003745\n",
      "Test Epoch84 layer0 out_loss 0.0037673127371817827\n",
      "Test Epoch84 layer1 out_loss 0.004091345705091953\n",
      "Test Epoch84 layer2 out_loss 0.0034828982315957546\n",
      "Test Epoch84 layer3 out_loss 0.003399033797904849\n",
      "Test Epoch84 layer4 out_loss 0.003317234804853797\n",
      "Test Epoch84 layer5 out_loss 0.0033354973420500755\n",
      "Test Epoch84 layer6 out_loss 0.003256856231018901\n",
      "Test Epoch84 layer7 out_loss 0.0032893687020987272\n",
      "Test Epoch84 layer8 out_loss 0.003250224981456995\n",
      "Test Epoch84 layer9 out_loss 0.0032809206750243902\n",
      "Train 85 | out_loss 0.0007347253849729896: 100%|█| 138/138 [00:01<00:00, 104.02i\n",
      "[[8.03242868e-05 3.52619371e-03]\n",
      " [3.10586270e-04 1.38820297e-03]\n",
      " [4.15909655e-04 8.85633075e-04]\n",
      " [2.41593051e-04 4.12678120e-04]\n",
      " [2.31568490e-04 2.89769859e-04]\n",
      " [2.41163580e-04 2.41347438e-04]\n",
      " [2.24701015e-04 2.19506183e-04]\n",
      " [1.46386882e-04 1.46561878e-04]\n",
      " [1.16375326e-04 1.44882418e-04]\n",
      " [1.01316105e-04 1.20165304e-04]]\n",
      "Train Epoch85 out_loss 0.0007347253849729896\n",
      "Test Epoch85 layer0 out_loss 0.0014453562907874584\n",
      "Test Epoch85 layer1 out_loss 0.0007201320258900523\n",
      "Test Epoch85 layer2 out_loss 0.00047078257193788886\n",
      "Test Epoch85 layer3 out_loss 0.00048580876318737864\n",
      "Test Epoch85 layer4 out_loss 0.00042616104474291205\n",
      "Test Epoch85 layer5 out_loss 0.0005152224912308156\n",
      "Test Epoch85 layer6 out_loss 0.0004153297049924731\n",
      "Test Epoch85 layer7 out_loss 0.0004476325702853501\n",
      "Test Epoch85 layer8 out_loss 0.00047915088362060487\n",
      "Test Epoch85 layer9 out_loss 0.0004858886240981519\n",
      "Train 86 | out_loss 0.0015513485996052623: 100%|█| 138/138 [00:01<00:00, 103.95i\n",
      "[[5.21889743e-04 5.06379152e-03]\n",
      " [3.95659653e-04 1.75630047e-03]\n",
      " [5.95697905e-04 1.10834944e-03]\n",
      " [3.56977342e-04 4.54279666e-04]\n",
      " [2.25570939e-04 2.55457112e-04]\n",
      " [2.16581059e-04 1.65996460e-04]\n",
      " [1.17266618e-04 1.04942001e-04]\n",
      " [7.29467400e-05 7.35051687e-05]\n",
      " [5.70830523e-05 7.50869880e-05]\n",
      " [5.26251365e-05 7.19184145e-05]]\n",
      "Train Epoch86 out_loss 0.0015513485996052623\n",
      "Test Epoch86 layer0 out_loss 0.0017076574731618166\n",
      "Test Epoch86 layer1 out_loss 0.00043054952402599156\n",
      "Test Epoch86 layer2 out_loss 0.00039498042315244675\n",
      "Test Epoch86 layer3 out_loss 0.0004974997136741877\n",
      "Test Epoch86 layer4 out_loss 0.0004838992317672819\n",
      "Test Epoch86 layer5 out_loss 0.0005209047812968493\n",
      "Test Epoch86 layer6 out_loss 0.0005834362818859518\n",
      "Test Epoch86 layer7 out_loss 0.0005651970277540386\n",
      "Test Epoch86 layer8 out_loss 0.0005921770352870226\n",
      "Test Epoch86 layer9 out_loss 0.0005831198650412261\n",
      "Train 87 | out_loss 0.0004381877661217004: 100%|█| 138/138 [00:01<00:00, 111.14i\n",
      "[[2.31735919e-06 1.29853871e-02]\n",
      " [3.59289687e-04 2.09862028e-03]\n",
      " [3.96021870e-04 8.30457157e-04]\n",
      " [2.26695249e-04 3.20680816e-04]\n",
      " [1.65833037e-04 1.91527243e-04]\n",
      " [1.58825755e-04 1.21755535e-04]\n",
      " [8.39899230e-05 7.80693151e-05]\n",
      " [5.51480780e-05 7.28577255e-05]\n",
      " [4.92146520e-05 6.90036424e-05]\n",
      " [5.74888956e-05 7.66313868e-05]]\n",
      "Train Epoch87 out_loss 0.0004381877661217004\n",
      "Test Epoch87 layer0 out_loss 0.002318721264600754\n",
      "Test Epoch87 layer1 out_loss 0.0010722959414124489\n",
      "Test Epoch87 layer2 out_loss 0.0005070746410638094\n",
      "Test Epoch87 layer3 out_loss 0.0006243440438993275\n",
      "Test Epoch87 layer4 out_loss 0.00046649647993035614\n",
      "Test Epoch87 layer5 out_loss 0.0005129994242452085\n",
      "Test Epoch87 layer6 out_loss 0.0004960497026331723\n",
      "Test Epoch87 layer7 out_loss 0.00048112065996974707\n",
      "Test Epoch87 layer8 out_loss 0.00047966535203158855\n",
      "Test Epoch87 layer9 out_loss 0.0004784367047250271\n",
      "Train 88 | out_loss 0.001532510039396584: 100%|█| 138/138 [00:01<00:00, 102.02it\n",
      "[[4.92950905e-04 4.87929620e-03]\n",
      " [3.52915556e-04 1.67946085e-03]\n",
      " [4.55863557e-04 9.86927556e-04]\n",
      " [2.90995491e-04 3.66826393e-04]\n",
      " [1.73844710e-04 1.62790554e-04]\n",
      " [1.11568211e-04 9.45673644e-05]\n",
      " [8.17184599e-05 8.14743471e-05]\n",
      " [6.55293707e-05 8.57272354e-05]\n",
      " [6.18197444e-05 8.49951792e-05]\n",
      " [7.85573505e-05 1.09108151e-04]]\n",
      "Train Epoch88 out_loss 0.001532510039396584\n",
      "Test Epoch88 layer0 out_loss 0.0033457919489592314\n",
      "Test Epoch88 layer1 out_loss 0.000461005256511271\n",
      "Test Epoch88 layer2 out_loss 0.0004072910232935101\n",
      "Test Epoch88 layer3 out_loss 0.0004037515027448535\n",
      "Test Epoch88 layer4 out_loss 0.00040046716458164155\n",
      "Test Epoch88 layer5 out_loss 0.00040685568819753826\n",
      "Test Epoch88 layer6 out_loss 0.00040265527786687016\n",
      "Test Epoch88 layer7 out_loss 0.0004020753549411893\n",
      "Test Epoch88 layer8 out_loss 0.00040812240331433713\n",
      "Test Epoch88 layer9 out_loss 0.00040428806096315384\n",
      "Train 89 | out_loss 0.0015707125421613455: 100%|█| 138/138 [00:01<00:00, 102.48i\n",
      "[[5.20962942e-04 5.28276404e-02]\n",
      " [2.35480192e-04 3.33905438e-03]\n",
      " [2.98028123e-04 9.76058944e-04]\n",
      " [1.95596785e-04 4.26498508e-04]\n",
      " [1.73315905e-04 2.19828982e-04]\n",
      " [1.33347539e-04 1.04448606e-04]\n",
      " [7.37822015e-05 8.27994350e-05]\n",
      " [6.54999229e-05 8.58241079e-05]\n",
      " [6.34213799e-05 8.76856987e-05]\n",
      " [7.68082583e-05 9.70336943e-05]]\n",
      "Train Epoch89 out_loss 0.0015707125421613455\n",
      "Test Epoch89 layer0 out_loss 0.013497160747647285\n",
      "Test Epoch89 layer1 out_loss 0.001885125762782991\n",
      "Test Epoch89 layer2 out_loss 0.0007165506249293685\n",
      "Test Epoch89 layer3 out_loss 0.0006738018710166216\n",
      "Test Epoch89 layer4 out_loss 0.0008207192877307534\n",
      "Test Epoch89 layer5 out_loss 0.0007107504061423242\n",
      "Test Epoch89 layer6 out_loss 0.0006810319609940052\n",
      "Test Epoch89 layer7 out_loss 0.0007567217689938843\n",
      "Test Epoch89 layer8 out_loss 0.00068268011091277\n",
      "Test Epoch89 layer9 out_loss 0.0007140852394513786\n",
      "Train 90 | out_loss 0.0007962880190461874: 100%|█| 138/138 [00:01<00:00, 109.81i\n",
      "[[6.28458768e-05 1.90335120e-02]\n",
      " [3.51366860e-04 2.25615031e-03]\n",
      " [4.99505714e-04 1.49747842e-03]\n",
      " [4.64123688e-04 5.37660506e-04]\n",
      " [2.44491712e-04 2.72129819e-04]\n",
      " [1.67938857e-04 2.06912358e-04]\n",
      " [1.72514287e-04 2.08766613e-04]\n",
      " [1.58616924e-04 2.03949492e-04]\n",
      " [1.52840457e-04 2.00528105e-04]\n",
      " [1.75992643e-04 2.35787093e-04]]\n",
      "Train Epoch90 out_loss 0.0007962880190461874\n",
      "Test Epoch90 layer0 out_loss 0.004906920716166496\n",
      "Test Epoch90 layer1 out_loss 0.004352984018623829\n",
      "Test Epoch90 layer2 out_loss 0.004328388255089521\n",
      "Test Epoch90 layer3 out_loss 0.004306283313781023\n",
      "Test Epoch90 layer4 out_loss 0.004334243014454842\n",
      "Test Epoch90 layer5 out_loss 0.0042948792688548565\n",
      "Test Epoch90 layer6 out_loss 0.004276600666344166\n",
      "Test Epoch90 layer7 out_loss 0.004304913338273764\n",
      "Test Epoch90 layer8 out_loss 0.004306718707084656\n",
      "Test Epoch90 layer9 out_loss 0.004322371911257505\n",
      "Train 91 | out_loss 0.015300935134291649: 100%|█| 138/138 [00:01<00:00, 110.07it\n",
      "[[3.57633694e-04 1.09042450e-02]\n",
      " [8.32828574e-03 5.30440783e-02]\n",
      " [2.20176810e-02 7.80581908e-02]\n",
      " [4.42503715e-02 9.70960119e-02]\n",
      " [9.57253354e-02 1.86674902e-01]\n",
      " [2.12120324e-01 2.60101381e-01]\n",
      " [2.58771693e-01 3.13684154e-01]\n",
      " [2.45297007e-01 4.09441139e-01]\n",
      " [2.74110407e-01 4.94489379e-01]\n",
      " [2.43790125e-01 4.99916562e-01]]\n",
      "Train Epoch91 out_loss 0.015300935134291649\n",
      "Test Epoch91 layer0 out_loss 0.006114454939961433\n",
      "Test Epoch91 layer1 out_loss 0.002715270733460784\n",
      "Test Epoch91 layer2 out_loss 0.00124772556591779\n",
      "Test Epoch91 layer3 out_loss 0.00445060059428215\n",
      "Test Epoch91 layer4 out_loss 0.002778426744043827\n",
      "Test Epoch91 layer5 out_loss 0.01494270283728838\n",
      "Test Epoch91 layer6 out_loss 0.02733345329761505\n",
      "Test Epoch91 layer7 out_loss 0.008681942708790302\n",
      "Test Epoch91 layer8 out_loss 0.03731884807348251\n",
      "Test Epoch91 layer9 out_loss 0.04340464994311333\n",
      "Train 92 | out_loss 0.015912745147943497: 100%|█| 138/138 [00:01<00:00, 104.44it\n",
      "[[4.82033646e-04 4.85182872e-03]\n",
      " [1.12873603e-04 1.96692068e-03]\n",
      " [2.91211809e-04 2.62481083e-03]\n",
      " [1.31743715e-03 7.67336944e-03]\n",
      " [5.78932618e-03 1.55699086e-02]\n",
      " [5.93893939e-03 6.15389516e-02]\n",
      " [2.10929511e-02 8.18535051e-02]\n",
      " [4.38020896e-02 1.21520231e-01]\n",
      " [9.78016108e-02 1.83197208e-01]\n",
      " [1.25432548e-01 3.44785486e-01]]\n",
      "Train Epoch92 out_loss 0.015912745147943497\n",
      "Test Epoch92 layer0 out_loss 0.0008051323238760233\n",
      "Test Epoch92 layer1 out_loss 0.0006031604716554284\n",
      "Test Epoch92 layer2 out_loss 0.0004606449801940471\n",
      "Test Epoch92 layer3 out_loss 0.00046103153727017343\n",
      "Test Epoch92 layer4 out_loss 0.0003959456516895443\n",
      "Test Epoch92 layer5 out_loss 0.0004711850197054446\n",
      "Test Epoch92 layer6 out_loss 0.0005402177921496332\n",
      "Test Epoch92 layer7 out_loss 0.0005096424138173461\n",
      "Test Epoch92 layer8 out_loss 0.0006226098630577326\n",
      "Test Epoch92 layer9 out_loss 0.0012033376842737198\n",
      "Train 93 | out_loss 0.001888764789327979: 100%|█| 138/138 [00:01<00:00, 108.44it\n",
      "[[5.39667938e-04 4.57928731e-03]\n",
      " [5.10435062e-06 4.24028645e-04]\n",
      " [4.65881656e-06 1.77470494e-04]\n",
      " [8.34325212e-06 1.99537309e-04]\n",
      " [1.14660324e-05 2.43886129e-04]\n",
      " [7.35581960e-06 2.46722878e-04]\n",
      " [8.63734348e-06 3.79944635e-04]\n",
      " [1.37225591e-05 4.94931975e-04]\n",
      " [5.55035140e-05 7.32508385e-04]\n",
      " [1.18023280e-04 1.78642321e-03]]\n",
      "Train Epoch93 out_loss 0.001888764789327979\n",
      "Test Epoch93 layer0 out_loss 0.0012474782997742295\n",
      "Test Epoch93 layer1 out_loss 0.0005728752003051341\n",
      "Test Epoch93 layer2 out_loss 0.0005340088391676545\n",
      "Test Epoch93 layer3 out_loss 0.00045966095058247447\n",
      "Test Epoch93 layer4 out_loss 0.000488427875097841\n",
      "Test Epoch93 layer5 out_loss 0.0005815117037855089\n",
      "Test Epoch93 layer6 out_loss 0.0005963602452538908\n",
      "Test Epoch93 layer7 out_loss 0.0005233754054643214\n",
      "Test Epoch93 layer8 out_loss 0.0005267043015919626\n",
      "Test Epoch93 layer9 out_loss 0.0008166485349647701\n",
      "Train 94 | out_loss 0.0005548731423914433: 100%|█| 138/138 [00:01<00:00, 103.36i\n",
      "[[3.46537067e-06 1.15394108e-02]\n",
      " [5.18865414e-06 1.39102374e-03]\n",
      " [5.19547484e-06 2.53481061e-04]\n",
      " [8.21521514e-06 2.15952762e-04]\n",
      " [7.50768356e-06 1.75304463e-04]\n",
      " [4.79667620e-06 2.02357643e-04]\n",
      " [6.16703066e-06 4.00777105e-04]\n",
      " [9.30317547e-06 4.18761880e-04]\n",
      " [2.44902635e-05 6.67331638e-04]\n",
      " [5.31848014e-05 1.23386540e-03]]\n",
      "Train Epoch94 out_loss 0.0005548731423914433\n",
      "Test Epoch94 layer0 out_loss 0.004744280129671097\n",
      "Test Epoch94 layer1 out_loss 0.0006085181375965476\n",
      "Test Epoch94 layer2 out_loss 0.000423882098402828\n",
      "Test Epoch94 layer3 out_loss 0.0004295725666452199\n",
      "Test Epoch94 layer4 out_loss 0.00038590512122027576\n",
      "Test Epoch94 layer5 out_loss 0.0004282635636627674\n",
      "Test Epoch94 layer6 out_loss 0.0005412205355241895\n",
      "Test Epoch94 layer7 out_loss 0.0004758702125400305\n",
      "Test Epoch94 layer8 out_loss 0.0005442971014417708\n",
      "Test Epoch94 layer9 out_loss 0.0005293221329338849\n",
      "Train 95 | out_loss 0.0022815202828496695: 100%|█| 138/138 [00:01<00:00, 104.29i\n",
      "[[8.45149034e-04 1.16922090e-02]\n",
      " [5.99773262e-06 1.20140712e-03]\n",
      " [6.34125150e-06 2.39935485e-04]\n",
      " [1.64868580e-05 1.64171000e-04]\n",
      " [1.44702524e-05 1.28163243e-04]\n",
      " [9.86887811e-06 1.59400220e-04]\n",
      " [1.16305875e-05 3.43265689e-04]\n",
      " [1.80646258e-05 3.41655144e-04]\n",
      " [5.78821297e-05 5.50188961e-04]\n",
      " [9.24561621e-05 1.01197527e-03]]\n",
      "Train Epoch95 out_loss 0.0022815202828496695\n",
      "Test Epoch95 layer0 out_loss 0.00518947234377265\n",
      "Test Epoch95 layer1 out_loss 0.0008800685754977167\n",
      "Test Epoch95 layer2 out_loss 0.00040703359991312027\n",
      "Test Epoch95 layer3 out_loss 0.0004201784613542259\n",
      "Test Epoch95 layer4 out_loss 0.0003707986616063863\n",
      "Test Epoch95 layer5 out_loss 0.0004253437800798565\n",
      "Test Epoch95 layer6 out_loss 0.0004585144342854619\n",
      "Test Epoch95 layer7 out_loss 0.00041985540883615613\n",
      "Test Epoch95 layer8 out_loss 0.0005087371100671589\n",
      "Test Epoch95 layer9 out_loss 0.0004868605174124241\n",
      "Train 96 | out_loss 0.0004996282514184713: 100%|█| 138/138 [00:01<00:00, 104.19i\n",
      "[[5.30579928e-08 1.19467468e-02]\n",
      " [4.79780913e-06 1.11783917e-03]\n",
      " [4.99958114e-06 2.80870377e-04]\n",
      " [8.12275118e-06 1.49149071e-04]\n",
      " [8.96593095e-06 1.00407193e-04]\n",
      " [5.26363148e-06 1.29905568e-04]\n",
      " [5.98427513e-06 2.76188512e-04]\n",
      " [8.30293969e-06 2.89897846e-04]\n",
      " [3.03566954e-05 4.37306912e-04]\n",
      " [4.34173458e-05 8.47816333e-04]]\n",
      "Train Epoch96 out_loss 0.0004996282514184713\n",
      "Test Epoch96 layer0 out_loss 0.003499580081552267\n",
      "Test Epoch96 layer1 out_loss 0.0004828254459425807\n",
      "Test Epoch96 layer2 out_loss 0.0003936582070309669\n",
      "Test Epoch96 layer3 out_loss 0.00040137534961104393\n",
      "Test Epoch96 layer4 out_loss 0.00042406446300446987\n",
      "Test Epoch96 layer5 out_loss 0.00044282927410677075\n",
      "Test Epoch96 layer6 out_loss 0.0004661179846152663\n",
      "Test Epoch96 layer7 out_loss 0.0004750685184262693\n",
      "Test Epoch96 layer8 out_loss 0.00048496571253053844\n",
      "Test Epoch96 layer9 out_loss 0.0004808316589333117\n",
      "Train 97 | out_loss 0.0018904111348092556: 100%|█| 138/138 [00:01<00:00, 109.96i\n",
      "[[5.82280748e-04 3.14113956e-02]\n",
      " [1.65314198e-05 2.96624432e-03]\n",
      " [1.96597779e-05 5.43074856e-04]\n",
      " [2.04106237e-05 2.80724098e-04]\n",
      " [1.90247252e-05 1.78947552e-04]\n",
      " [1.24895856e-05 2.04334136e-04]\n",
      " [1.35133533e-05 4.75425755e-04]\n",
      " [1.63064226e-05 4.11721529e-04]\n",
      " [5.26976486e-05 6.84468263e-04]\n",
      " [8.29687730e-05 1.14345072e-03]]\n",
      "Train Epoch97 out_loss 0.0018904111348092556\n",
      "Test Epoch97 layer0 out_loss 0.0019635751377791166\n",
      "Test Epoch97 layer1 out_loss 0.000921017664950341\n",
      "Test Epoch97 layer2 out_loss 0.00047399726463481784\n",
      "Test Epoch97 layer3 out_loss 0.0005846004351042211\n",
      "Test Epoch97 layer4 out_loss 0.0008000837988220155\n",
      "Test Epoch97 layer5 out_loss 0.0006203377852216363\n",
      "Test Epoch97 layer6 out_loss 0.0006116779986768961\n",
      "Test Epoch97 layer7 out_loss 0.0006679187645204365\n",
      "Test Epoch97 layer8 out_loss 0.0006368614849634469\n",
      "Test Epoch97 layer9 out_loss 0.0006036402774043381\n",
      "Train 98 | out_loss 0.0004889520932920277: 100%|█| 138/138 [00:01<00:00, 108.39i\n",
      "[[1.21143823e-06 4.02052170e-03]\n",
      " [2.81138273e-05 7.58996728e-04]\n",
      " [2.99955981e-05 2.02098591e-04]\n",
      " [3.64206497e-05 1.42305968e-04]\n",
      " [3.03799021e-05 9.93503202e-05]\n",
      " [2.12997903e-05 1.30604134e-04]\n",
      " [2.59864983e-05 2.40549409e-04]\n",
      " [2.74960986e-05 2.33393654e-04]\n",
      " [8.54552012e-05 3.59805987e-04]\n",
      " [1.68836099e-04 7.04275854e-04]]\n",
      "Train Epoch98 out_loss 0.0004889520932920277\n",
      "Test Epoch98 layer0 out_loss 0.0021781071554869413\n",
      "Test Epoch98 layer1 out_loss 0.00043324241414666176\n",
      "Test Epoch98 layer2 out_loss 0.0003970323014073074\n",
      "Test Epoch98 layer3 out_loss 0.0004145041457377374\n",
      "Test Epoch98 layer4 out_loss 0.00040047045331448317\n",
      "Test Epoch98 layer5 out_loss 0.0004482679651118815\n",
      "Test Epoch98 layer6 out_loss 0.00043228280264884233\n",
      "Test Epoch98 layer7 out_loss 0.000438048446085304\n",
      "Test Epoch98 layer8 out_loss 0.0004861139750573784\n",
      "Test Epoch98 layer9 out_loss 0.0005002175457775593\n",
      "Train 99 | out_loss 0.0017301671905443072: 100%|█| 138/138 [00:01<00:00, 107.81i\n",
      "[[5.20723732e-04 3.82738978e-03]\n",
      " [2.39763379e-05 4.23291966e-04]\n",
      " [2.73807599e-05 1.26218786e-04]\n",
      " [2.98115476e-05 9.98107140e-05]\n",
      " [2.42082686e-05 7.12148021e-05]\n",
      " [1.63994163e-05 9.20671982e-05]\n",
      " [1.99322651e-05 1.65017696e-04]\n",
      " [2.27979188e-05 1.80068314e-04]\n",
      " [7.21746628e-05 2.63176853e-04]\n",
      " [1.27270153e-04 5.37864192e-04]]\n",
      "Train Epoch99 out_loss 0.0017301671905443072\n",
      "Test Epoch99 layer0 out_loss 0.002422187477350235\n",
      "Test Epoch99 layer1 out_loss 0.000489367637783289\n",
      "Test Epoch99 layer2 out_loss 0.0003895609697792679\n",
      "Test Epoch99 layer3 out_loss 0.00041178209357894957\n",
      "Test Epoch99 layer4 out_loss 0.0004143435216974467\n",
      "Test Epoch99 layer5 out_loss 0.00042571566882543266\n",
      "Test Epoch99 layer6 out_loss 0.0004088793939445168\n",
      "Test Epoch99 layer7 out_loss 0.00040832781814970076\n",
      "Test Epoch99 layer8 out_loss 0.0005096547538414598\n",
      "Test Epoch99 layer9 out_loss 0.00045267443056218326\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "# LinearAL ailerons\n",
    "\n",
    "data = \"ailerons\"\n",
    "model =  \"linearal\"\n",
    "for layer in range(1,11):\n",
    "#for layer in [3]:\n",
    "    log = f\"result/{data}_{model}_l{layer}.log\"\n",
    "    !python3 dis_train_al.py --dataset {data} --model {model} --epoch 100 --num-layer {layer} --task regression > {log}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d3mIndex\n",
       "1557   -0.0015\n",
       "3654   -0.0006\n",
       "5071   -0.0007\n",
       "7126   -0.0006\n",
       "7148   -0.0007\n",
       "         ...  \n",
       "211    -0.0008\n",
       "160    -0.0005\n",
       "6095   -0.0006\n",
       "4529   -0.0007\n",
       "3829   -0.0019\n",
       "Name: goal, Length: 8800, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a7f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
