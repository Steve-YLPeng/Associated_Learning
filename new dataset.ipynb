{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bbac891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "  0%|                                                   | 0/258 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 0.6403655409812927: 100%|█| 258/258 [00:01<00:00, 190.26it/s]\n",
      "Train Epoch0 out_loss 0.4100678861141205, R2 0.589984655380249\n",
      "Test Epoch0 layer0 out_loss 0.3176153004169464, R2 0.682165265083313\n",
      "Test Epoch0 layer1 out_loss 0.2983078360557556, R2 0.7014861106872559\n",
      "Test Epoch0 layer2 out_loss 0.2951917052268982, R2 0.7046043872833252\n",
      "Test Epoch0 layer3 out_loss 0.29966121912002563, R2 0.7001317739486694\n",
      "Test Epoch0 layer4 out_loss 0.29881009459495544, R2 0.7009835243225098\n",
      "Best r2 0.7046043872833252 at L2\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Start Testing\n"
     ]
    }
   ],
   "source": [
    "# LinearAL \n",
    "\n",
    "data = \"ca_housing\"\n",
    "#data = \"paint\"\n",
    "model =  \"linearal\"\n",
    "#for layer in range(1,11):\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{data}/\n",
    "    !python3 dis_train_al.py --dataset {data} --model {model} --epoch 100 --num-layer {layer} --lr 0.001 --task regression # > {log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f7a8d985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/12500 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.74409125 (595273/800000): 100%|█| 12500/12500 [01:46<00:00, 116.\n",
      "Train 1 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:51<00:00, 111.\n",
      "Train 2 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:58<00:00, 105.\n",
      "Train 3 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:56<00:00, 106.\n",
      "Train 4 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:44<00:00, 119.\n",
      "Train 5 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:41<00:00, 122.\n",
      "Train 6 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:45<00:00, 118.\n",
      "Train 7 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:57<00:00, 106.\n",
      "Train 8 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:45<00:00, 118.\n",
      "Train 9 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:51<00:00, 111.\n"
     ]
    }
   ],
   "source": [
    "# LinearAL \n",
    "data = \"criteo\"\n",
    "\n",
    "model =  \"linearal\"\n",
    "#for layer in range(1,11):\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{data}/\n",
    "    !python3 dis_train_al.py --dataset {data} --model {model} --epoch 10 --num-layer {layer} --task classification --lr 0.0001 --l1-dim 300 --label-emb 128 > {log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abecc5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ae70865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:408: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.8468271445566609 (334556/395070): 100%|█| 3087/3087 [00:29<00:00\n",
      "Train 1 | Acc 0.9855544587035209 (389363/395070): 100%|█| 3087/3087 [00:28<00:00\n",
      "Train 2 | Acc 0.9941959652719771 (392777/395070): 100%|█| 3087/3087 [00:30<00:00\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/AL_main_new/dis_train_al.py\", line 286, in <module>\n",
      "    main()\n",
      "  File \"/home/AL_main_new/dis_train_al.py\", line 221, in main\n",
      "    train(model, train_loader, epoch, task=args.task)\n",
      "  File \"/home/AL_main_new/dis_train_al.py\", line 84, in train\n",
      "    train_AUC = auroc(y_out,y_tar.view(-1).int(),num_classes=model.class_num,average='macro').item()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torchmetrics/functional/classification/auroc.py\", line 269, in auroc\n",
      "    return _auroc_compute(preds, target, mode, num_classes, pos_label, average, max_fpr, sample_weights)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torchmetrics/functional/classification/auroc.py\", line 150, in _auroc_compute\n",
      "    fpr, tpr, _ = roc(preds, target, num_classes, pos_label, sample_weights)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torchmetrics/functional/classification/roc.py\", line 282, in roc\n",
      "    return _roc_compute(preds, target, num_classes, pos_label, sample_weights)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torchmetrics/functional/classification/roc.py\", line 194, in _roc_compute\n",
      "    return _roc_compute_multi_class(preds, target, num_classes, sample_weights)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torchmetrics/functional/classification/roc.py\", line 122, in _roc_compute_multi_class\n",
      "    res = roc(\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torchmetrics/functional/classification/roc.py\", line 282, in roc\n",
      "    return _roc_compute(preds, target, num_classes, pos_label, sample_weights)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torchmetrics/functional/classification/roc.py\", line 193, in _roc_compute\n",
      "    return _roc_compute_single_class(preds, target, pos_label, sample_weights)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torchmetrics/functional/classification/roc.py\", line 73, in _roc_compute_single_class\n",
      "    thresholds = torch.cat([thresholds[0][None] + 1, thresholds])\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# LinearAL \n",
    "data = \"kdd99\"\n",
    "\n",
    "model =  \"linearal\"\n",
    "for layer in [10]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{data}/\n",
    "    !python3 dis_train_al.py --dataset {data} --model {model} --epoch 10 --num-layer {layer} --batch-size 128 --lr 0.0001 --l1-dim 128 --label-emb 128 --task classification > {log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7675b11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:408: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.855023160452578 (337794/395070): 100%|█| 3087/3087 [00:25<00:00,\n",
      "Train 1 | Acc 0.9883210570278684 (390456/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 2 | Acc 0.9946338623535069 (392950/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 3 | Acc 0.9955248436985851 (393302/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 4 | Acc 0.9958083377629281 (393414/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 5 | Acc 0.9960184271141823 (393497/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 6 | Acc 0.9961728301313691 (393558/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 7 | Acc 0.9964057002556509 (393650/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 8 | Acc 0.9966866631229908 (393761/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 9 | Acc 0.9969701571873338 (393873/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 10 | Acc 0.997134684992533 (393938/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 11 | Acc 0.9972511200546739 (393984/395070): 100%|█| 3087/3087 [00:25<00:0\n",
      "Train 12 | Acc 0.9974156478598729 (394049/395070): 100%|█| 3087/3087 [00:25<00:0\n",
      "Train 13 | Acc 0.9975371453160199 (394097/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 14 | Acc 0.9976409243931456 (394138/395070): 100%|█| 3087/3087 [00:23<00:0\n",
      "Train 15 | Acc 0.9977067355152252 (394164/395070): 100%|█| 3087/3087 [00:23<00:0\n",
      "Train 16 | Acc 0.9978257017743691 (394211/395070): 100%|█| 3087/3087 [00:25<00:0\n",
      "Train 17 | Acc 0.9978839193054395 (394234/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 18 | Acc 0.9979117624724733 (394245/395070): 100%|█| 3087/3087 [00:25<00:0\n",
      "Train 19 | Acc 0.997980104791556 (394272/395070): 100%|█| 3087/3087 [00:23<00:00\n",
      "Train 20 | Acc 0.9980028855645835 (394281/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 21 | Acc 0.9980535095046448 (394301/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 22 | Acc 0.998063634292657 (394305/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 23 | Acc 0.9981167894297213 (394326/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 24 | Acc 0.9981117270357152 (394324/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 25 | Acc 0.9981167894297213 (394326/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 26 | Acc 0.9982053813248285 (394361/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 27 | Acc 0.9982079125218316 (394362/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 28 | Acc 0.9982230997038499 (394368/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 29 | Acc 0.998263598855899 (394384/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 30 | Acc 0.998263598855899 (394384/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 31 | Acc 0.9982863796289265 (394393/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 32 | Acc 0.9982737236439112 (394388/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 33 | Acc 0.9982838484319234 (394392/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 34 | Acc 0.9982939732199357 (394396/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 35 | Acc 0.9982838484319234 (394392/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 36 | Acc 0.9982939732199357 (394396/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 37 | Acc 0.9983015668109448 (394399/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 38 | Acc 0.9982914420229326 (394395/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 39 | Acc 0.9982863796289265 (394393/395070): 100%|█| 3087/3087 [00:23<00:0\n",
      "Train 40 | Acc 0.9983192851899664 (394406/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 41 | Acc 0.9983015668109448 (394399/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 42 | Acc 0.9983066292049511 (394401/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 43 | Acc 0.9983192851899664 (394406/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 44 | Acc 0.9983319411749817 (394411/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 45 | Acc 0.9983294099779786 (394410/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 46 | Acc 0.9983395347659908 (394414/395070): 100%|█| 3087/3087 [00:25<00:0\n",
      "Train 47 | Acc 0.9982863796289265 (394393/395070): 100%|█| 3087/3087 [00:25<00:0\n",
      "Train 48 | Acc 0.9983319411749817 (394411/395070): 100%|█| 3087/3087 [00:26<00:0\n",
      "Train 49 | Acc 0.9983496595540031 (394418/395070): 100%|█| 3087/3087 [00:25<00:0\n"
     ]
    }
   ],
   "source": [
    "# LinearAL side \n",
    "data = \"kdd99\"\n",
    "\n",
    "model =  \"linearalside\"\n",
    "#for layer in range(1,11):\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{data}/\n",
    "    !python3 dis_train_al.py --dataset {data} --model {model} --epoch 10 --num-layer {layer} --batch-size 128 --lr 0.0001 --l1-dim 128 --label-emb 128 --task classification > {log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56678f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformer.encoder import TransformerEncoder\n",
    "from torch.nn import ModuleList\n",
    "from typing import List\n",
    "class AE(nn.Module):\n",
    "\n",
    "    def __init__(self, inp_dim, out_dim, cri='ce', act=None):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        if act == None:\n",
    "            self.g = nn.Sequential(\n",
    "                    nn.Linear(inp_dim, out_dim),\n",
    "                    nn.Tanh()            \n",
    "                )\n",
    "            if cri == 'ce':\n",
    "                self.h = nn.Sequential(\n",
    "                    nn.Linear(out_dim, inp_dim),\n",
    "                    nn.Tanh()            \n",
    "                )\n",
    "                self.cri = nn.CrossEntropyLoss()\n",
    "                \n",
    "            elif cri == 'mse':\n",
    "                self.h = nn.Sequential(\n",
    "                    nn.Linear(out_dim, inp_dim),\n",
    "                )\n",
    "                self.cri = nn.MSELoss()\n",
    "            \n",
    "        else:\n",
    "            if act[0] != None:\n",
    "                self.g = nn.Sequential(\n",
    "                    nn.Linear(inp_dim, out_dim),       \n",
    "                    act[0]    \n",
    "                )\n",
    "            else:\n",
    "                self.g = nn.Sequential(\n",
    "                    nn.Linear(inp_dim, out_dim),         \n",
    "                )\n",
    "            if act[1] != None:\n",
    "                self.h = nn.Sequential(\n",
    "                    nn.Linear(out_dim, inp_dim),\n",
    "                    act[1] \n",
    "                )\n",
    "            else:\n",
    "                self.h = nn.Sequential(\n",
    "                    nn.Linear(out_dim, inp_dim), \n",
    "                )\n",
    "            if cri == 'mse' :\n",
    "                self.cri = nn.MSELoss()\n",
    "            else :\n",
    "                self.cri = nn.CrossEntropyLoss()\n",
    "            \n",
    "        self.mode = cri\n",
    "    \n",
    "    def forward(self, x):\n",
    "        enc_x = self.g(x)\n",
    "        rec_x = self.h(enc_x)\n",
    "        if self.mode == 'ce':\n",
    "            #print(\"ae\",rec_x)\n",
    "            #print(\"lab\",x)\n",
    "            return enc_x, self.cri(rec_x, x.argmax(1))\n",
    "        elif self.mode == 'mse':\n",
    "            return enc_x, self.cri(rec_x, x)\n",
    "\n",
    "class ENC(nn.Module):\n",
    "\n",
    "    def __init__(self, inp_dim, out_dim, lab_dim=128, f='emb', n_heads=4, word_vec=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.b = nn.Sequential(\n",
    "            nn.Linear(out_dim, lab_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.mode = f\n",
    "        if f == 'emb':\n",
    "            self.f = nn.Embedding(inp_dim, out_dim)\n",
    "            if word_vec is not None:\n",
    "                self.f = nn.Embedding.from_pretrained(word_vec, freeze=False)\n",
    "        elif f == 'lstm':\n",
    "            self.f = nn.LSTM(inp_dim, out_dim, bidirectional=True, batch_first=True)\n",
    "        elif f == 'trans':\n",
    "            self.f = TransformerEncoder(d_model=inp_dim, d_ff=out_dim, n_heads=n_heads)\n",
    "            self.b = nn.Sequential(\n",
    "                nn.Linear(inp_dim, lab_dim),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        elif f == 'linear':\n",
    "            self.f = nn.Sequential(\n",
    "                nn.Linear(inp_dim, out_dim),\n",
    "                #nn.BatchNorm1d(out_dim),\n",
    "                nn.ELU(),\n",
    "                #nn.Tanh(),\n",
    "                #nn.Sigmoid(),\n",
    "                \n",
    "            )\n",
    "            self.b = nn.Sequential(\n",
    "                nn.Linear(out_dim, lab_dim),\n",
    "                #nn.BatchNorm1d(out_dim),\n",
    "                #nn.ELU(),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "\n",
    "        self.cri = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, x, tgt, mask=None, h=None):\n",
    "\n",
    "        if self.mode == 'emb' :\n",
    "            enc_x = self.f(x.long())\n",
    "        elif self.mode == 'linear' :\n",
    "            enc_x = self.f(x)\n",
    "        elif self.mode == 'lstm':\n",
    "            enc_x, (h, c) = self.f(x, h)\n",
    "        elif self.mode == 'trans':\n",
    "            enc_x = self.f(x, mask=mask)\n",
    "        \n",
    "        red_x = self.reduction(enc_x, mask, h)\n",
    "        red_x = self.b(red_x)\n",
    "        loss = self.cri(red_x, tgt)\n",
    "        \n",
    "        return enc_x, loss, h, mask\n",
    "\n",
    "    def reduction(self, x, mask=None, h=None):\n",
    "\n",
    "        # to match bridge function\n",
    "        if self.mode == 'emb':\n",
    "            return x.mean(1)\n",
    "\n",
    "        elif self.mode == 'lstm':\n",
    "            _h = h[0] + h[1]\n",
    "            return _h\n",
    "\n",
    "        elif self.mode == 'trans':\n",
    "\n",
    "            denom = torch.sum(mask, -1, keepdim=True)\n",
    "            feat = torch.sum(x * mask.unsqueeze(-1), dim=1) / denom\n",
    "            return feat\n",
    "        \n",
    "        elif self.mode == 'linear':\n",
    "            return x\n",
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, inp_dim, lab_dim, hid_dim, lr, out_dim=None, ae_cri='mse', ae_act=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc = ENC(inp_dim, hid_dim, lab_dim=lab_dim, f='linear')\n",
    "        if out_dim == None:\n",
    "            self.ae = AE(lab_dim, lab_dim, cri=ae_cri, act=ae_act)\n",
    "        else:\n",
    "            self.ae = AE(out_dim, lab_dim, cri=ae_cri, act=ae_act)\n",
    "    \n",
    "        self.ae_opt = torch.optim.Adam(self.ae.parameters(), lr=lr)\n",
    "        self.enc_opt = torch.optim.Adam(self.enc.parameters(), lr=lr)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "\n",
    "        self.ae_opt.zero_grad()\n",
    "        enc_y , ae_loss = self.ae(y)\n",
    "        ae_loss.backward()\n",
    "        #nn.utils.clip_grad_norm_(self.ae.parameters(), 5)\n",
    "        self.ae_opt.step()\n",
    "    \n",
    "        self.enc_opt.zero_grad()\n",
    "        tgt = enc_y.clone().detach()\n",
    "        enc_x, enc_loss, _, _ = self.enc(x, tgt)\n",
    "        enc_loss.backward()\n",
    "        #nn.utils.clip_grad_norm_(self.enc.parameters(), 5)\n",
    "        self.enc_opt.step()\n",
    "        #(h, c) = hidden\n",
    "        #h = h.reshape(2, x.size(0), -1)\n",
    "        #hidden = (h.detach(), c.detach())\n",
    "\n",
    "        return enc_x.detach(), enc_y.detach(), ae_loss, enc_loss \n",
    "class alModel(nn.Module):\n",
    "    def __init__(self, num_layer, l1_dim, class_num, lab_dim, emb_dim=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layer = num_layer\n",
    "        self.history = {\"train_acc\":[],\"valid_acc\":[],\"train_loss\":[],\n",
    "                        \"train_AUC\":[],\"valid_AUC\":[],\n",
    "                        \"train_r2\":[],\"valid_r2\":[],\n",
    "                        \"train_out\":[],\"valid_out\":[],\n",
    "                        } \n",
    "        self.emb_dim = emb_dim\n",
    "        self.l1_dim = l1_dim\n",
    "        self.lab_dim = lab_dim\n",
    "        self.losses = [0.0] * (num_layer*2)\n",
    "        self.class_num = class_num\n",
    "class LinearALRegress(alModel): \n",
    "    \n",
    "    def __init__(self, num_layer, feature_dim, class_num, l1_dim, lr, lab_dim=128):\n",
    "        super().__init__(num_layer, l1_dim, class_num, lab_dim)\n",
    "              \n",
    "        layers = ModuleList([])\n",
    "        for idx in range(self.num_layer):\n",
    "            if idx == 0:\n",
    "                act = [nn.Tanh(),None]\n",
    "                #act = [None,None]\n",
    "                layer = LinearLayer(inp_dim=feature_dim, out_dim=class_num, \n",
    "                                    hid_dim=l1_dim, lab_dim=lab_dim, lr=lr, ae_act=act)\n",
    "            else:\n",
    "                layer = LinearLayer(l1_dim, lab_dim, l1_dim, lr=lr)\n",
    "            layers.append(layer)\n",
    "        \n",
    "        self.layers = layers     \n",
    "model = LinearALRegress(3,20,11,128,0.001,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3689e30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.layers[1].train()\n",
    "print(model.training)\n",
    "print(model.layers[0].training)\n",
    "print(model.layers[0].enc.training)\n",
    "print(model.layers[0].ae.training)\n",
    "print(model.layers[1].training)\n",
    "print(model.layers[1].enc.training)\n",
    "print(model.layers[1].ae.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e40cd61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearALRegress(\n",
       "  (layers): ModuleList(\n",
       "    (0): LinearLayer(\n",
       "      (enc): ENC(\n",
       "        (b): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (f): Sequential(\n",
       "          (0): Linear(in_features=20, out_features=128, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (cri): MSELoss()\n",
       "      )\n",
       "      (ae): AE(\n",
       "        (g): Sequential(\n",
       "          (0): Linear(in_features=11, out_features=128, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (h): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=11, bias=True)\n",
       "        )\n",
       "        (cri): MSELoss()\n",
       "      )\n",
       "    )\n",
       "    (1): LinearLayer(\n",
       "      (enc): ENC(\n",
       "        (b): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (f): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (cri): MSELoss()\n",
       "      )\n",
       "      (ae): AE(\n",
       "        (g): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (h): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (cri): MSELoss()\n",
       "      )\n",
       "    )\n",
       "    (2): LinearLayer(\n",
       "      (enc): ENC(\n",
       "        (b): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (f): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (cri): MSELoss()\n",
       "      )\n",
       "      (ae): AE(\n",
       "        (g): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (h): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (cri): MSELoss()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "model.modules\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5444bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/train_l4//’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/train_l4//kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:408: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.8866529982028502 (350290/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 1 | Acc 0.9892525375249955 (390824/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 2 | Acc 0.9953020983623155 (393214/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 3 | Acc 0.9962538284354672 (393590/395070): 100%|█| 3087/3087 [00:17<00:00\n",
      "Train 4 | Acc 0.9972840256157137 (393997/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 5 | Acc 0.9976383931961424 (394137/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 6 | Acc 0.9978257017743691 (394211/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 7 | Acc 0.9979725112005468 (394269/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 8 | Acc 0.9980914774596907 (394316/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 9 | Acc 0.998144632596755 (394337/395070): 100%|█| 3087/3087 [00:18<00:00,\n",
      "Train 10 | Acc 0.998228162097856 (394370/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 11 | Acc 0.998228162097856 (394370/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 12 | Acc 0.9982737236439112 (394388/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 13 | Acc 0.9982838484319234 (394392/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 14 | Acc 0.9983395347659908 (394414/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 15 | Acc 0.9983496595540031 (394418/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 16 | Acc 0.9983749715240338 (394428/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 17 | Acc 0.9983901587060521 (394434/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 18 | Acc 0.9983800339180399 (394430/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 19 | Acc 0.9984104082820766 (394442/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 20 | Acc 0.9984255954640949 (394448/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 21 | Acc 0.9984458450401195 (394456/395070): 100%|█| 3087/3087 [00:17<00:0\n",
      "Train 22 | Acc 0.9984559698281317 (394460/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 23 | Acc 0.9984762194041562 (394468/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 24 | Acc 0.9984812817981623 (394470/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 25 | Acc 0.9984812817981623 (394470/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 26 | Acc 0.9984711570101501 (394466/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 27 | Acc 0.9984838129951654 (394471/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 28 | Acc 0.9984838129951654 (394471/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 29 | Acc 0.9984838129951654 (394471/395070): 100%|█| 3087/3087 [00:18<00:0\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# layer mask training \n",
    "######################\n",
    "\n",
    "data = \"kdd99\"\n",
    "save = \"train_l4/\"\n",
    "load = \"train_l3/\"\n",
    "model =  \"linearal\"\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{save}/\n",
    "    !mkdir ckpt/{save}/{data}/\n",
    "    !python3 dis_train_side.py --dataset {data} --model {model} --epoch 30 \\\n",
    "    --num-layer {layer} --batch-size 128 --lr 0.0001 --l1-dim 128 --label-emb 128 \\\n",
    "    --task classification > {log}\n",
    "    #--save-dir ./ckpt/{save} \\\n",
    "    #--load-dir ./ckpt/{load} \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccf3594c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/mask1//’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/mask1//kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:408: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.8317184296453793 (328587/395070): 100%|█| 3087/3087 [00:17<00:00\n",
      "Train 1 | Acc 0.9892433234421365 (384048/388224):  98%|▉| 3027/3087 [00:16<00:00^C\n",
      "Train 1 | Acc 0.9892433234421365 (384048/388224):  98%|▉| 3033/3087 [00:16<00:00\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/AL_main_new/dis_train_side.py\", line 322, in <module>\n",
      "    main()\n",
      "  File \"/home/AL_main_new/dis_train_side.py\", line 247, in main\n",
      "    train(model, train_loader, epoch, task=args.task, layer_mask=layer_mask)\n",
      "  File \"/home/AL_main_new/dis_train_side.py\", line 80, in train\n",
      "    losses = model(x, y)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/AL_main_new/distributed_model.py\", line 710, in forward\n",
      "    x_out, y_out, ae_out, as_out = layer(x, y)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/AL_main_new/distributed_model.py\", line 293, in forward\n",
      "    self.ae_opt.step()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 109, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/optim/adam.py\", line 157, in step\n",
      "    adam(params_with_grad,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/optim/adam.py\", line 213, in adam\n",
      "    func(params,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/optim/adam.py\", line 307, in _single_tensor_adam\n",
      "    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# layer mask training \n",
    "######################\n",
    "\n",
    "data = \"kdd99\"\n",
    "model =  \"linearal\"\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{save}/\n",
    "    !mkdir ckpt/{save}/{data}/\n",
    "    !python3 dis_train_side.py --dataset {data} --model {model} --epoch 50 \\\n",
    "    --num-layer {layer} --batch-size 128 --lr 0.0001 --l1-dim 128 --label-emb 128 \\\n",
    "    --lr-schedule ReduceLROnPlateau \\\n",
    "    --task classification > {log}\n",
    "    #--save-dir ./ckpt/{save} \\\n",
    "    #--load-dir ./ckpt/{load} \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "da5b5373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/side_mask4//’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/side_mask4//kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:408: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.8965980712278837 (354219/395070): 100%|█| 3087/3087 [00:19<00:00\n",
      "Train 1 | Acc 0.9885108968030982 (390531/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 2 | Acc 0.9949350747968715 (393069/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 3 | Acc 0.9955450932746096 (393310/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 4 | Acc 0.9958741488850077 (393440/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 5 | Acc 0.9960488014782191 (393509/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 6 | Acc 0.9962437036474548 (393586/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 7 | Acc 0.9963398891335713 (393624/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 8 | Acc 0.9964664489837244 (393674/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 9 | Acc 0.9966765383349786 (393757/395070): 100%|█| 3087/3087 [00:17<00:00\n",
      "Train 10 | Acc 0.9967879110031134 (393801/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 11 | Acc 0.9969549700053155 (393867/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 12 | Acc 0.9970233123243982 (393894/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 13 | Acc 0.9970562178854381 (393907/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 14 | Acc 0.9971017794314931 (393925/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 15 | Acc 0.997134684992533 (393938/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 16 | Acc 0.9971524033715544 (393945/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 17 | Acc 0.9971448097805452 (393942/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 18 | Acc 0.9971625281595666 (393949/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 19 | Acc 0.9971777153415851 (393955/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 20 | Acc 0.9971777153415851 (393955/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 21 | Acc 0.9971903713266004 (393960/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 22 | Acc 0.9971777153415851 (393955/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 23 | Acc 0.9971979649176096 (393963/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 24 | Acc 0.9971929025236034 (393961/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 25 | Acc 0.9971954337206065 (393962/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 26 | Acc 0.9971878401295973 (393959/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 27 | Acc 0.9972055585086187 (393966/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 28 | Acc 0.9972030273116157 (393965/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 29 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 30 | Acc 0.9972106209026248 (393968/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 31 | Acc 0.9972106209026248 (393968/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 32 | Acc 0.9972106209026248 (393968/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 33 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 34 | Acc 0.997215683296631 (393970/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 35 | Acc 0.9972080897056218 (393967/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 36 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 37 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 38 | Acc 0.997215683296631 (393970/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 39 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 40 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 41 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 42 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 43 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 44 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 45 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 46 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 47 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 48 | Acc 0.997215683296631 (393970/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 49 | Acc 0.997215683296631 (393970/395070): 100%|█| 3087/3087 [00:18<00:00\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# layer mask training \n",
    "######################\n",
    "\n",
    "data = \"kdd99\"\n",
    "model =  \"linearalside\"\n",
    "save = \"side_mask4/\"\n",
    "load = \"side_mask3/\"\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{save}/\n",
    "    !mkdir ckpt/{save}/{data}/\n",
    "    !python3 dis_train_side.py --dataset {data} --model {model} --epoch 50 \\\n",
    "    --num-layer {layer} --batch-size 128 --lr 0.0001 --l1-dim 128 --label-emb 128 \\\n",
    "    --lr-schedule ReduceLROnPlateau \\\n",
    "    --task classification > {log}\n",
    "    #--save-dir ./ckpt/{save} \\\n",
    "    #--load-dir ./ckpt/{load} \\\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de8eee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/mask1//’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/mask1//kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:409: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.6033614296200673 (238370/395070): 100%|█| 3087/3087 [00:44<00:00\n",
      "Train 1 | Acc 0.5936441643253094 (234531/395070): 100%|█| 3087/3087 [00:44<00:00\n",
      "Train 2 | Acc 0.5888222340344749 (232626/395070): 100%|█| 3087/3087 [00:42<00:00\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/AL_main_new/dis_train_side.py\", line 337, in <module>\n",
      "    main()\n",
      "  File \"/home/AL_main_new/dis_train_side.py\", line 266, in main\n",
      "    AUC, acc = test(model, test_loader, shortcut=layer+1, task=args.task)\n",
      "  File \"/home/AL_main_new/dis_train_side.py\", line 150, in test\n",
      "    y_out = torch.cat((y_out, pred.cpu()), 0)\n",
      "KeyboardInterrupt\n",
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/mask2//’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/mask2//kdd99/’: File exists\n"
     ]
    }
   ],
   "source": [
    "# training mask try more layer\n",
    "data = \"kdd99\"\n",
    "model =  \"linearal\"\n",
    "layer = 10\n",
    "epoch = 10\n",
    "lr = 0.0001\n",
    "for mask in range(1,layer+1):\n",
    "#for mask in [1]:\n",
    "    save = f\"mask{mask}/\"\n",
    "    load = f\"mask{mask-1}/\"\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}_m{mask}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{save}/\n",
    "    !mkdir ckpt/{save}/{data}/\n",
    "    if mask != 1:\n",
    "        !python3 dis_train_side.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --num-layer {layer} --batch-size 128 --lr {lr} --l1-dim 128 --label-emb 128 \\\n",
    "        --lr-schedule ReduceLROnPlateau \\\n",
    "        --train-mask {mask} \\\n",
    "        --save-dir ./ckpt/{save} \\\n",
    "        --load-dir ./ckpt/{load} \\\n",
    "        --task classification > {log}\n",
    "    else:\n",
    "        !python3 dis_train_side.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --num-layer {layer} --batch-size 128 --lr {lr} --l1-dim 128 --label-emb 128 \\\n",
    "        --lr-schedule ReduceLROnPlateau \\\n",
    "        --train-mask {mask} \\\n",
    "        --save-dir ./ckpt/{save} \\\n",
    "        --task classification > {log}\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65f2af1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06416ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
