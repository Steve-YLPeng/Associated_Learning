{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bbac891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "  0%|                                                   | 0/258 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 0.6403655409812927: 100%|█| 258/258 [00:01<00:00, 190.26it/s]\n",
      "Train Epoch0 out_loss 0.4100678861141205, R2 0.589984655380249\n",
      "Test Epoch0 layer0 out_loss 0.3176153004169464, R2 0.682165265083313\n",
      "Test Epoch0 layer1 out_loss 0.2983078360557556, R2 0.7014861106872559\n",
      "Test Epoch0 layer2 out_loss 0.2951917052268982, R2 0.7046043872833252\n",
      "Test Epoch0 layer3 out_loss 0.29966121912002563, R2 0.7001317739486694\n",
      "Test Epoch0 layer4 out_loss 0.29881009459495544, R2 0.7009835243225098\n",
      "Best r2 0.7046043872833252 at L2\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Start Testing\n"
     ]
    }
   ],
   "source": [
    "# LinearAL \n",
    "\n",
    "data = \"ca_housing\"\n",
    "#data = \"paint\"\n",
    "model =  \"linearal\"\n",
    "#for layer in range(1,11):\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{data}/\n",
    "    !python3 dis_train_al.py --dataset {data} --model {model} --epoch 100 --num-layer {layer} --lr 0.001 --task regression # > {log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f7a8d985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/12500 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.74409125 (595273/800000): 100%|█| 12500/12500 [01:46<00:00, 116.\n",
      "Train 1 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:51<00:00, 111.\n",
      "Train 2 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:58<00:00, 105.\n",
      "Train 3 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:56<00:00, 106.\n",
      "Train 4 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:44<00:00, 119.\n",
      "Train 5 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:41<00:00, 122.\n",
      "Train 6 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:45<00:00, 118.\n",
      "Train 7 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:57<00:00, 106.\n",
      "Train 8 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:45<00:00, 118.\n",
      "Train 9 | Acc 0.74518375 (596147/800000): 100%|█| 12500/12500 [01:51<00:00, 111.\n"
     ]
    }
   ],
   "source": [
    "# LinearAL \n",
    "data = \"criteo\"\n",
    "\n",
    "model =  \"linearal\"\n",
    "#for layer in range(1,11):\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{data}/\n",
    "    !python3 dis_train_al.py --dataset {data} --model {model} --epoch 10 --num-layer {layer} --task classification --lr 0.0001 --l1-dim 300 --label-emb 128 > {log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abecc5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ae70865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:410: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.868939681575417 (343292/395070): 100%|█| 3087/3087 [01:19<00:00,\n",
      "Train 1 | Acc 0.9826696165191741 (42640/43392):  11%| | 335/3087 [00:08<01:12, 3^C\n",
      "Train 1 | Acc 0.9826696165191741 (42640/43392):  11%| | 339/3087 [00:08<01:08, 4\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/AL_main_new/dis_train_al.py\", line 286, in <module>\n",
      "    main()\n",
      "  File \"/home/AL_main_new/dis_train_al.py\", line 221, in main\n",
      "    train(model, train_loader, epoch, task=args.task)\n",
      "  File \"/home/AL_main_new/dis_train_al.py\", line 71, in train\n",
      "    losses = model(x, y)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/AL_main_new/distributed_model.py\", line 713, in forward\n",
      "    x_out, y_out, ae_out, as_out = layer(x_out, y_out)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/AL_main_new/distributed_model.py\", line 299, in forward\n",
      "    enc_loss.backward()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/_tensor.py\", line 396, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 173, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# LinearAL \n",
    "data = \"kdd99\"\n",
    "\n",
    "model =  \"linearal\"\n",
    "for layer in [10]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{data}/\n",
    "    !python3 dis_train_al.py --dataset {data} --model {model} --epoch 2 --num-layer {layer} --batch-size 128 --lr 0.0001 --l1-dim 128 --label-emb 128 --task classification > {log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7675b11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:408: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.855023160452578 (337794/395070): 100%|█| 3087/3087 [00:25<00:00,\n",
      "Train 1 | Acc 0.9883210570278684 (390456/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 2 | Acc 0.9946338623535069 (392950/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 3 | Acc 0.9955248436985851 (393302/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 4 | Acc 0.9958083377629281 (393414/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 5 | Acc 0.9960184271141823 (393497/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 6 | Acc 0.9961728301313691 (393558/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 7 | Acc 0.9964057002556509 (393650/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 8 | Acc 0.9966866631229908 (393761/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 9 | Acc 0.9969701571873338 (393873/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 10 | Acc 0.997134684992533 (393938/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 11 | Acc 0.9972511200546739 (393984/395070): 100%|█| 3087/3087 [00:25<00:0\n",
      "Train 12 | Acc 0.9974156478598729 (394049/395070): 100%|█| 3087/3087 [00:25<00:0\n",
      "Train 13 | Acc 0.9975371453160199 (394097/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 14 | Acc 0.9976409243931456 (394138/395070): 100%|█| 3087/3087 [00:23<00:0\n",
      "Train 15 | Acc 0.9977067355152252 (394164/395070): 100%|█| 3087/3087 [00:23<00:0\n",
      "Train 16 | Acc 0.9978257017743691 (394211/395070): 100%|█| 3087/3087 [00:25<00:0\n",
      "Train 17 | Acc 0.9978839193054395 (394234/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 18 | Acc 0.9979117624724733 (394245/395070): 100%|█| 3087/3087 [00:25<00:0\n",
      "Train 19 | Acc 0.997980104791556 (394272/395070): 100%|█| 3087/3087 [00:23<00:00\n",
      "Train 20 | Acc 0.9980028855645835 (394281/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 21 | Acc 0.9980535095046448 (394301/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 22 | Acc 0.998063634292657 (394305/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 23 | Acc 0.9981167894297213 (394326/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 24 | Acc 0.9981117270357152 (394324/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 25 | Acc 0.9981167894297213 (394326/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 26 | Acc 0.9982053813248285 (394361/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 27 | Acc 0.9982079125218316 (394362/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 28 | Acc 0.9982230997038499 (394368/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 29 | Acc 0.998263598855899 (394384/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 30 | Acc 0.998263598855899 (394384/395070): 100%|█| 3087/3087 [00:24<00:00\n",
      "Train 31 | Acc 0.9982863796289265 (394393/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 32 | Acc 0.9982737236439112 (394388/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 33 | Acc 0.9982838484319234 (394392/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 34 | Acc 0.9982939732199357 (394396/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 35 | Acc 0.9982838484319234 (394392/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 36 | Acc 0.9982939732199357 (394396/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 37 | Acc 0.9983015668109448 (394399/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 38 | Acc 0.9982914420229326 (394395/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 39 | Acc 0.9982863796289265 (394393/395070): 100%|█| 3087/3087 [00:23<00:0\n",
      "Train 40 | Acc 0.9983192851899664 (394406/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 41 | Acc 0.9983015668109448 (394399/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 42 | Acc 0.9983066292049511 (394401/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 43 | Acc 0.9983192851899664 (394406/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 44 | Acc 0.9983319411749817 (394411/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 45 | Acc 0.9983294099779786 (394410/395070): 100%|█| 3087/3087 [00:24<00:0\n",
      "Train 46 | Acc 0.9983395347659908 (394414/395070): 100%|█| 3087/3087 [00:25<00:0\n",
      "Train 47 | Acc 0.9982863796289265 (394393/395070): 100%|█| 3087/3087 [00:25<00:0\n",
      "Train 48 | Acc 0.9983319411749817 (394411/395070): 100%|█| 3087/3087 [00:26<00:0\n",
      "Train 49 | Acc 0.9983496595540031 (394418/395070): 100%|█| 3087/3087 [00:25<00:0\n"
     ]
    }
   ],
   "source": [
    "# LinearAL side \n",
    "data = \"kdd99\"\n",
    "\n",
    "model =  \"linearalside\"\n",
    "#for layer in range(1,11):\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{data}/\n",
    "    !python3 dis_train_al.py --dataset {data} --model {model} --epoch 10 --num-layer {layer} --batch-size 128 --lr 0.0001 --l1-dim 128 --label-emb 128 --task classification > {log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56678f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformer.encoder import TransformerEncoder\n",
    "from torch.nn import ModuleList\n",
    "from typing import List\n",
    "class AE(nn.Module):\n",
    "\n",
    "    def __init__(self, inp_dim, out_dim, cri='ce', act=None):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        if act == None:\n",
    "            self.g = nn.Sequential(\n",
    "                    nn.Linear(inp_dim, out_dim),\n",
    "                    nn.Tanh()            \n",
    "                )\n",
    "            if cri == 'ce':\n",
    "                self.h = nn.Sequential(\n",
    "                    nn.Linear(out_dim, inp_dim),\n",
    "                    nn.Tanh()            \n",
    "                )\n",
    "                self.cri = nn.CrossEntropyLoss()\n",
    "                \n",
    "            elif cri == 'mse':\n",
    "                self.h = nn.Sequential(\n",
    "                    nn.Linear(out_dim, inp_dim),\n",
    "                )\n",
    "                self.cri = nn.MSELoss()\n",
    "            \n",
    "        else:\n",
    "            if act[0] != None:\n",
    "                self.g = nn.Sequential(\n",
    "                    nn.Linear(inp_dim, out_dim),       \n",
    "                    act[0]    \n",
    "                )\n",
    "            else:\n",
    "                self.g = nn.Sequential(\n",
    "                    nn.Linear(inp_dim, out_dim),         \n",
    "                )\n",
    "            if act[1] != None:\n",
    "                self.h = nn.Sequential(\n",
    "                    nn.Linear(out_dim, inp_dim),\n",
    "                    act[1] \n",
    "                )\n",
    "            else:\n",
    "                self.h = nn.Sequential(\n",
    "                    nn.Linear(out_dim, inp_dim), \n",
    "                )\n",
    "            if cri == 'mse' :\n",
    "                self.cri = nn.MSELoss()\n",
    "            else :\n",
    "                self.cri = nn.CrossEntropyLoss()\n",
    "            \n",
    "        self.mode = cri\n",
    "    \n",
    "    def forward(self, x):\n",
    "        enc_x = self.g(x)\n",
    "        rec_x = self.h(enc_x)\n",
    "        if self.mode == 'ce':\n",
    "            #print(\"ae\",rec_x)\n",
    "            #print(\"lab\",x)\n",
    "            return enc_x, self.cri(rec_x, x.argmax(1))\n",
    "        elif self.mode == 'mse':\n",
    "            return enc_x, self.cri(rec_x, x)\n",
    "\n",
    "class ENC(nn.Module):\n",
    "\n",
    "    def __init__(self, inp_dim, out_dim, lab_dim=128, f='emb', n_heads=4, word_vec=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.b = nn.Sequential(\n",
    "            nn.Linear(out_dim, lab_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.mode = f\n",
    "        if f == 'emb':\n",
    "            self.f = nn.Embedding(inp_dim, out_dim)\n",
    "            if word_vec is not None:\n",
    "                self.f = nn.Embedding.from_pretrained(word_vec, freeze=False)\n",
    "        elif f == 'lstm':\n",
    "            self.f = nn.LSTM(inp_dim, out_dim, bidirectional=True, batch_first=True)\n",
    "        elif f == 'trans':\n",
    "            self.f = TransformerEncoder(d_model=inp_dim, d_ff=out_dim, n_heads=n_heads)\n",
    "            self.b = nn.Sequential(\n",
    "                nn.Linear(inp_dim, lab_dim),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        elif f == 'linear':\n",
    "            self.f = nn.Sequential(\n",
    "                nn.Linear(inp_dim, out_dim),\n",
    "                #nn.BatchNorm1d(out_dim),\n",
    "                nn.ELU(),\n",
    "                #nn.Tanh(),\n",
    "                #nn.Sigmoid(),\n",
    "                \n",
    "            )\n",
    "            self.b = nn.Sequential(\n",
    "                nn.Linear(out_dim, lab_dim),\n",
    "                #nn.BatchNorm1d(out_dim),\n",
    "                #nn.ELU(),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "\n",
    "        self.cri = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, x, tgt, mask=None, h=None):\n",
    "\n",
    "        if self.mode == 'emb' :\n",
    "            enc_x = self.f(x.long())\n",
    "        elif self.mode == 'linear' :\n",
    "            enc_x = self.f(x)\n",
    "        elif self.mode == 'lstm':\n",
    "            enc_x, (h, c) = self.f(x, h)\n",
    "        elif self.mode == 'trans':\n",
    "            enc_x = self.f(x, mask=mask)\n",
    "        \n",
    "        red_x = self.reduction(enc_x, mask, h)\n",
    "        red_x = self.b(red_x)\n",
    "        loss = self.cri(red_x, tgt)\n",
    "        \n",
    "        return enc_x, loss, h, mask\n",
    "\n",
    "    def reduction(self, x, mask=None, h=None):\n",
    "\n",
    "        # to match bridge function\n",
    "        if self.mode == 'emb':\n",
    "            return x.mean(1)\n",
    "\n",
    "        elif self.mode == 'lstm':\n",
    "            _h = h[0] + h[1]\n",
    "            return _h\n",
    "\n",
    "        elif self.mode == 'trans':\n",
    "\n",
    "            denom = torch.sum(mask, -1, keepdim=True)\n",
    "            feat = torch.sum(x * mask.unsqueeze(-1), dim=1) / denom\n",
    "            return feat\n",
    "        \n",
    "        elif self.mode == 'linear':\n",
    "            return x\n",
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, inp_dim, lab_dim, hid_dim, lr, out_dim=None, ae_cri='mse', ae_act=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc = ENC(inp_dim, hid_dim, lab_dim=lab_dim, f='linear')\n",
    "        if out_dim == None:\n",
    "            self.ae = AE(lab_dim, lab_dim, cri=ae_cri, act=ae_act)\n",
    "        else:\n",
    "            self.ae = AE(out_dim, lab_dim, cri=ae_cri, act=ae_act)\n",
    "    \n",
    "        self.ae_opt = torch.optim.Adam(self.ae.parameters(), lr=lr)\n",
    "        self.enc_opt = torch.optim.Adam(self.enc.parameters(), lr=lr)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "\n",
    "        self.ae_opt.zero_grad()\n",
    "        enc_y , ae_loss = self.ae(y)\n",
    "        ae_loss.backward()\n",
    "        #nn.utils.clip_grad_norm_(self.ae.parameters(), 5)\n",
    "        self.ae_opt.step()\n",
    "    \n",
    "        self.enc_opt.zero_grad()\n",
    "        tgt = enc_y.clone().detach()\n",
    "        enc_x, enc_loss, _, _ = self.enc(x, tgt)\n",
    "        enc_loss.backward()\n",
    "        #nn.utils.clip_grad_norm_(self.enc.parameters(), 5)\n",
    "        self.enc_opt.step()\n",
    "        #(h, c) = hidden\n",
    "        #h = h.reshape(2, x.size(0), -1)\n",
    "        #hidden = (h.detach(), c.detach())\n",
    "\n",
    "        return enc_x.detach(), enc_y.detach(), ae_loss, enc_loss \n",
    "class alModel(nn.Module):\n",
    "    def __init__(self, num_layer, l1_dim, class_num, lab_dim, emb_dim=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layer = num_layer\n",
    "        self.history = {\"train_acc\":[],\"valid_acc\":[],\"train_loss\":[],\n",
    "                        \"train_AUC\":[],\"valid_AUC\":[],\n",
    "                        \"train_r2\":[],\"valid_r2\":[],\n",
    "                        \"train_out\":[],\"valid_out\":[],\n",
    "                        } \n",
    "        self.emb_dim = emb_dim\n",
    "        self.l1_dim = l1_dim\n",
    "        self.lab_dim = lab_dim\n",
    "        self.losses = [0.0] * (num_layer*2)\n",
    "        self.class_num = class_num\n",
    "class LinearALRegress(alModel): \n",
    "    \n",
    "    def __init__(self, num_layer, feature_dim, class_num, l1_dim, lr, lab_dim=128):\n",
    "        super().__init__(num_layer, l1_dim, class_num, lab_dim)\n",
    "              \n",
    "        layers = ModuleList([])\n",
    "        for idx in range(self.num_layer):\n",
    "            if idx == 0:\n",
    "                act = [nn.Tanh(),None]\n",
    "                #act = [None,None]\n",
    "                layer = LinearLayer(inp_dim=feature_dim, out_dim=class_num, \n",
    "                                    hid_dim=l1_dim, lab_dim=lab_dim, lr=lr, ae_act=act)\n",
    "            else:\n",
    "                layer = LinearLayer(l1_dim, lab_dim, l1_dim, lr=lr)\n",
    "            layers.append(layer)\n",
    "        \n",
    "        self.layers = layers     \n",
    "model = LinearALRegress(3,20,11,128,0.001,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3689e30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "model.layers[1].train()\n",
    "print(model.training)\n",
    "print(model.layers[0].training)\n",
    "print(model.layers[0].enc.training)\n",
    "print(model.layers[0].ae.training)\n",
    "print(model.layers[1].training)\n",
    "print(model.layers[1].enc.training)\n",
    "print(model.layers[1].ae.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e40cd61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearALRegress(\n",
       "  (layers): ModuleList(\n",
       "    (0): LinearLayer(\n",
       "      (enc): ENC(\n",
       "        (b): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (f): Sequential(\n",
       "          (0): Linear(in_features=20, out_features=128, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (cri): MSELoss()\n",
       "      )\n",
       "      (ae): AE(\n",
       "        (g): Sequential(\n",
       "          (0): Linear(in_features=11, out_features=128, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (h): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=11, bias=True)\n",
       "        )\n",
       "        (cri): MSELoss()\n",
       "      )\n",
       "    )\n",
       "    (1): LinearLayer(\n",
       "      (enc): ENC(\n",
       "        (b): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (f): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (cri): MSELoss()\n",
       "      )\n",
       "      (ae): AE(\n",
       "        (g): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (h): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (cri): MSELoss()\n",
       "      )\n",
       "    )\n",
       "    (2): LinearLayer(\n",
       "      (enc): ENC(\n",
       "        (b): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (f): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): ELU(alpha=1.0)\n",
       "        )\n",
       "        (cri): MSELoss()\n",
       "      )\n",
       "      (ae): AE(\n",
       "        (g): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (1): Tanh()\n",
       "        )\n",
       "        (h): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (cri): MSELoss()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "model.modules\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5444bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/train_l4//’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/train_l4//kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:408: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.8866529982028502 (350290/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 1 | Acc 0.9892525375249955 (390824/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 2 | Acc 0.9953020983623155 (393214/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 3 | Acc 0.9962538284354672 (393590/395070): 100%|█| 3087/3087 [00:17<00:00\n",
      "Train 4 | Acc 0.9972840256157137 (393997/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 5 | Acc 0.9976383931961424 (394137/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 6 | Acc 0.9978257017743691 (394211/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 7 | Acc 0.9979725112005468 (394269/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 8 | Acc 0.9980914774596907 (394316/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 9 | Acc 0.998144632596755 (394337/395070): 100%|█| 3087/3087 [00:18<00:00,\n",
      "Train 10 | Acc 0.998228162097856 (394370/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 11 | Acc 0.998228162097856 (394370/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 12 | Acc 0.9982737236439112 (394388/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 13 | Acc 0.9982838484319234 (394392/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 14 | Acc 0.9983395347659908 (394414/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 15 | Acc 0.9983496595540031 (394418/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 16 | Acc 0.9983749715240338 (394428/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 17 | Acc 0.9983901587060521 (394434/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 18 | Acc 0.9983800339180399 (394430/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 19 | Acc 0.9984104082820766 (394442/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 20 | Acc 0.9984255954640949 (394448/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 21 | Acc 0.9984458450401195 (394456/395070): 100%|█| 3087/3087 [00:17<00:0\n",
      "Train 22 | Acc 0.9984559698281317 (394460/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 23 | Acc 0.9984762194041562 (394468/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 24 | Acc 0.9984812817981623 (394470/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 25 | Acc 0.9984812817981623 (394470/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 26 | Acc 0.9984711570101501 (394466/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 27 | Acc 0.9984838129951654 (394471/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 28 | Acc 0.9984838129951654 (394471/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 29 | Acc 0.9984838129951654 (394471/395070): 100%|█| 3087/3087 [00:18<00:0\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# layer mask training \n",
    "######################\n",
    "\n",
    "data = \"kdd99\"\n",
    "save = \"train_l4/\"\n",
    "load = \"train_l3/\"\n",
    "model =  \"linearal\"\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{save}/\n",
    "    !mkdir ckpt/{save}/{data}/\n",
    "    !python3 dis_train_side.py --dataset {data} --model {model} --epoch 30 \\\n",
    "    --num-layer {layer} --batch-size 128 --lr 0.0001 --l1-dim 128 --label-emb 128 \\\n",
    "    --task classification > {log}\n",
    "    #--save-dir ./ckpt/{save} \\\n",
    "    #--load-dir ./ckpt/{load} \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccf3594c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/mask1//’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/mask1//kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:408: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.8317184296453793 (328587/395070): 100%|█| 3087/3087 [00:17<00:00\n",
      "Train 1 | Acc 0.9892433234421365 (384048/388224):  98%|▉| 3027/3087 [00:16<00:00^C\n",
      "Train 1 | Acc 0.9892433234421365 (384048/388224):  98%|▉| 3033/3087 [00:16<00:00\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/AL_main_new/dis_train_side.py\", line 322, in <module>\n",
      "    main()\n",
      "  File \"/home/AL_main_new/dis_train_side.py\", line 247, in main\n",
      "    train(model, train_loader, epoch, task=args.task, layer_mask=layer_mask)\n",
      "  File \"/home/AL_main_new/dis_train_side.py\", line 80, in train\n",
      "    losses = model(x, y)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/AL_main_new/distributed_model.py\", line 710, in forward\n",
      "    x_out, y_out, ae_out, as_out = layer(x, y)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/AL_main_new/distributed_model.py\", line 293, in forward\n",
      "    self.ae_opt.step()\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 109, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/optim/adam.py\", line 157, in step\n",
      "    adam(params_with_grad,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/optim/adam.py\", line 213, in adam\n",
      "    func(params,\n",
      "  File \"/opt/conda/lib/python3.9/site-packages/torch/optim/adam.py\", line 307, in _single_tensor_adam\n",
      "    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# layer mask training \n",
    "######################\n",
    "\n",
    "data = \"kdd99\"\n",
    "model =  \"linearal\"\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{save}/\n",
    "    !mkdir ckpt/{save}/{data}/\n",
    "    !python3 dis_train_side.py --dataset {data} --model {model} --epoch 50 \\\n",
    "    --num-layer {layer} --batch-size 128 --lr 0.0001 --l1-dim 128 --label-emb 128 \\\n",
    "    --lr-schedule ReduceLROnPlateau \\\n",
    "    --task classification > {log}\n",
    "    #--save-dir ./ckpt/{save} \\\n",
    "    #--load-dir ./ckpt/{load} \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "da5b5373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/side_mask4//’: File exists\n",
      "mkdir: cannot create directory ‘ckpt/side_mask4//kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:408: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.8965980712278837 (354219/395070): 100%|█| 3087/3087 [00:19<00:00\n",
      "Train 1 | Acc 0.9885108968030982 (390531/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 2 | Acc 0.9949350747968715 (393069/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 3 | Acc 0.9955450932746096 (393310/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 4 | Acc 0.9958741488850077 (393440/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 5 | Acc 0.9960488014782191 (393509/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 6 | Acc 0.9962437036474548 (393586/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 7 | Acc 0.9963398891335713 (393624/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 8 | Acc 0.9964664489837244 (393674/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 9 | Acc 0.9966765383349786 (393757/395070): 100%|█| 3087/3087 [00:17<00:00\n",
      "Train 10 | Acc 0.9967879110031134 (393801/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 11 | Acc 0.9969549700053155 (393867/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 12 | Acc 0.9970233123243982 (393894/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 13 | Acc 0.9970562178854381 (393907/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 14 | Acc 0.9971017794314931 (393925/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 15 | Acc 0.997134684992533 (393938/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 16 | Acc 0.9971524033715544 (393945/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 17 | Acc 0.9971448097805452 (393942/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 18 | Acc 0.9971625281595666 (393949/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 19 | Acc 0.9971777153415851 (393955/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 20 | Acc 0.9971777153415851 (393955/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 21 | Acc 0.9971903713266004 (393960/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 22 | Acc 0.9971777153415851 (393955/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 23 | Acc 0.9971979649176096 (393963/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 24 | Acc 0.9971929025236034 (393961/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 25 | Acc 0.9971954337206065 (393962/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 26 | Acc 0.9971878401295973 (393959/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 27 | Acc 0.9972055585086187 (393966/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 28 | Acc 0.9972030273116157 (393965/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 29 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 30 | Acc 0.9972106209026248 (393968/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 31 | Acc 0.9972106209026248 (393968/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 32 | Acc 0.9972106209026248 (393968/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 33 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 34 | Acc 0.997215683296631 (393970/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 35 | Acc 0.9972080897056218 (393967/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 36 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 37 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 38 | Acc 0.997215683296631 (393970/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 39 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 40 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 41 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 42 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 43 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 44 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 45 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 46 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 47 | Acc 0.9972131520996279 (393969/395070): 100%|█| 3087/3087 [00:18<00:0\n",
      "Train 48 | Acc 0.997215683296631 (393970/395070): 100%|█| 3087/3087 [00:18<00:00\n",
      "Train 49 | Acc 0.997215683296631 (393970/395070): 100%|█| 3087/3087 [00:18<00:00\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# layer mask training \n",
    "######################\n",
    "\n",
    "data = \"kdd99\"\n",
    "model =  \"linearalside\"\n",
    "save = \"side_mask4/\"\n",
    "load = \"side_mask3/\"\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{save}/\n",
    "    !mkdir ckpt/{save}/{data}/\n",
    "    !python3 dis_train_side.py --dataset {data} --model {model} --epoch 50 \\\n",
    "    --num-layer {layer} --batch-size 128 --lr 0.0001 --l1-dim 128 --label-emb 128 \\\n",
    "    --lr-schedule ReduceLROnPlateau \\\n",
    "    --task classification > {log}\n",
    "    #--save-dir ./ckpt/{save} \\\n",
    "    #--load-dir ./ckpt/{load} \\\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de8eee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:410: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.1541676158655428 (60907/395070): 100%|█| 3087/3087 [00:38<00:00,\n",
      "Train 1 | Acc 0.19224441238261575 (75950/395070): 100%|█| 3087/3087 [00:35<00:00\n",
      "Train 2 | Acc 0.18956640595337534 (74892/395070): 100%|█| 3087/3087 [00:38<00:00\n",
      "Train 3 | Acc 0.1880805933125775 (74305/395070): 100%|█| 3087/3087 [00:38<00:00,\n",
      "Train 4 | Acc 0.18647581441263575 (73671/395070): 100%|█| 3087/3087 [00:37<00:00\n",
      "Train 5 | Acc 0.1850710000759359 (73116/395070): 100%|█| 3087/3087 [00:38<00:00,\n",
      "Train 6 | Acc 0.18412433239679044 (72742/395070): 100%|█| 3087/3087 [00:39<00:00\n",
      "Train 7 | Acc 0.18321563267269092 (72383/395070): 100%|█| 3087/3087 [00:38<00:00\n",
      "Train 8 | Acc 0.18262839496798036 (72151/395070): 100%|█| 3087/3087 [00:39<00:00\n",
      "Train 9 | Acc 0.18239046244969245 (72057/395070): 100%|█| 3087/3087 [00:39<00:00\n",
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:410: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.5774293163236894 (228125/395070): 100%|█| 3087/3087 [00:42<00:00\n",
      "Train 1 | Acc 0.5704609309742578 (225372/395070): 100%|█| 3087/3087 [00:42<00:00\n",
      "Train 2 | Acc 0.5700863138178044 (225224/395070): 100%|█| 3087/3087 [00:45<00:00\n",
      "Train 3 | Acc 0.5704862429442884 (225382/395070): 100%|█| 3087/3087 [00:42<00:00\n",
      "Train 4 | Acc 0.5702179360619637 (225276/395070): 100%|█| 3087/3087 [00:42<00:00\n",
      "Train 5 | Acc 0.5702229984559698 (225278/395070): 100%|█| 3087/3087 [00:44<00:00\n",
      "Train 6 | Acc 0.5702634976080189 (225294/395070): 100%|█| 3087/3087 [00:44<00:00\n",
      "Train 7 | Acc 0.5702837471840433 (225302/395070): 100%|█| 3087/3087 [00:45<00:00\n",
      "Train 8 | Acc 0.5702002176829423 (225269/395070): 100%|█| 3087/3087 [00:45<00:00\n",
      "Train 9 | Acc 0.5701647809248994 (225255/395070): 100%|█| 3087/3087 [00:42<00:00\n",
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:410: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.02044447819373782 (8077/395070): 100%|█| 3087/3087 [00:47<00:00,\n",
      "Train 1 | Acc 0.0013946895486875743 (551/395070): 100%|█| 3087/3087 [00:47<00:00\n",
      "Train 2 | Acc 0.0013491280026324448 (533/395070): 100%|█| 3087/3087 [00:46<00:00\n",
      "Train 3 | Acc 0.0012807856835497507 (506/395070): 100%|█| 3087/3087 [00:47<00:00\n",
      "Train 4 | Acc 0.0011036018933353582 (436/395070): 100%|█| 3087/3087 [00:47<00:00\n",
      "Train 5 | Acc 0.0004935834155972359 (195/395070): 100%|█| 3087/3087 [00:47<00:00\n",
      "Train 6 | Acc 0.000453084263548232 (179/395070): 100%|█| 3087/3087 [00:47<00:00,\n",
      "Train 7 | Acc 0.000392335535474726 (155/395070): 100%|█| 3087/3087 [00:47<00:00,\n",
      "Train 8 | Acc 0.0003594299744349103 (142/395070): 100%|█| 3087/3087 [00:45<00:00\n",
      "Train 9 | Acc 0.0003366492014073455 (133/395070): 100%|█| 3087/3087 [00:47<00:00\n",
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:410: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.0012909104715620016 (510/395070): 100%|█| 3087/3087 [00:50<00:00\n",
      "Train 1 | Acc 0.0021894854076492773 (865/395070): 100%|█| 3087/3087 [00:50<00:00\n",
      "Train 2 | Acc 0.002159111043612524 (853/395070): 100%|█| 3087/3087 [00:53<00:00,\n",
      "Train 3 | Acc 0.0021464550585972107 (848/395070): 100%|█| 3087/3087 [00:51<00:00\n",
      "Train 4 | Acc 0.002012301617434885 (795/395070): 100%|█| 3087/3087 [00:52<00:00,\n",
      "Train 5 | Acc 0.002103424709545144 (831/395070): 100%|█| 3087/3087 [00:52<00:00,\n",
      "Train 6 | Acc 0.002123674285569646 (839/395070): 100%|█| 3087/3087 [00:49<00:00,\n",
      "Train 7 | Acc 0.0020755815425114537 (820/395070): 100%|█| 3087/3087 [00:51<00:00\n",
      "Train 8 | Acc 0.0021084871035512696 (833/395070): 100%|█| 3087/3087 [00:52<00:00\n",
      "Train 9 | Acc 0.0021565798466094614 (852/395070): 100%|█| 3087/3087 [00:51<00:00\n",
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:410: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.12656238135014047 (50001/395070): 100%|█| 3087/3087 [00:56<00:00\n",
      "Train 1 | Acc 0.015738982965044168 (6218/395070): 100%|█| 3087/3087 [00:57<00:00\n",
      "Train 2 | Acc 0.0038575442326676287 (1524/395070): 100%|█| 3087/3087 [00:55<00:0\n",
      "Train 3 | Acc 0.0034778646822082163 (1374/395070): 100%|█| 3087/3087 [00:57<00:0\n",
      "Train 4 | Acc 0.0033842103930948947 (1337/395070): 100%|█| 3087/3087 [00:54<00:0\n",
      "Train 5 | Acc 0.0033361176500367024 (1318/395070): 100%|█| 3087/3087 [00:55<00:0\n",
      "Train 6 | Acc 0.0033133368770091377 (1309/395070): 100%|█| 3087/3087 [00:54<00:0\n",
      "Train 7 | Acc 0.003338648847039765 (1319/395070): 100%|█| 3087/3087 [00:55<00:00\n",
      "Train 8 | Acc 0.0033715544080795807 (1332/395070): 100%|█| 3087/3087 [00:56<00:0\n",
      "Train 9 | Acc 0.003331055256030577 (1316/395070): 100%|█| 3087/3087 [00:55<00:00\n",
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:410: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.0094312400334118 (3726/395070): 100%|█| 3087/3087 [01:00<00:00, \n",
      "Train 1 | Acc 0.003348773635052016 (1323/395070): 100%|█| 3087/3087 [00:59<00:00\n",
      "Train 2 | Acc 0.0033361176500367024 (1318/395070): 100%|█| 3087/3087 [00:57<00:0\n",
      "Train 3 | Acc 0.003381679196091832 (1336/395070): 100%|█| 3087/3087 [00:58<00:00\n",
      "Train 4 | Acc 0.0034044599691193966 (1345/395070): 100%|█| 3087/3087 [00:59<00:0\n",
      "Train 5 | Acc 0.0034145847571316478 (1349/395070): 100%|█| 3087/3087 [01:00<00:0\n",
      "Train 6 | Acc 0.003409522363125522 (1347/395070): 100%|█| 3087/3087 [00:59<00:00\n",
      "Train 7 | Acc 0.0033563672260612043 (1326/395070): 100%|█| 3087/3087 [01:00<00:0\n",
      "Train 8 | Acc 0.0031969018148682513 (1263/395070): 100%|█| 3087/3087 [00:58<00:0\n",
      "Train 9 | Acc 0.0028931581745007214 (1143/395070): 100%|█| 3087/3087 [00:57<00:0\n",
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:410: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.2087250360695573 (82461/395070): 100%|█| 3087/3087 [01:04<00:00,\n",
      "Train 1 | Acc 0.2202622320095173 (87019/395070): 100%|█| 3087/3087 [01:02<00:00,\n",
      "Train 2 | Acc 0.2202622320095173 (87019/395070): 100%|█| 3087/3087 [01:02<00:00,\n",
      "Train 3 | Acc 0.22025463841850812 (87016/395070): 100%|█| 3087/3087 [01:07<00:00\n",
      "Train 4 | Acc 0.22025716961551117 (87017/395070): 100%|█| 3087/3087 [01:09<00:00\n",
      "Train 5 | Acc 0.22025716961551117 (87017/395070): 100%|█| 3087/3087 [01:07<00:00\n",
      "Train 6 | Acc 0.22025970081251423 (87018/395070): 100%|█| 3087/3087 [01:09<00:00\n",
      "Train 7 | Acc 0.22025970081251423 (87018/395070): 100%|█| 3087/3087 [01:04<00:00\n",
      "Train 8 | Acc 0.22025970081251423 (87018/395070): 100%|█| 3087/3087 [01:09<00:00\n",
      "Train 9 | Acc 0.22025970081251423 (87018/395070): 100%|█| 3087/3087 [01:04<00:00\n",
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:410: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.39499582352494494 (156051/395070): 100%|█| 3087/3087 [01:13<00:0\n",
      "Train 1 | Acc 0.4188751360518389 (165485/395070): 100%|█| 3087/3087 [01:11<00:00\n",
      "Train 2 | Acc 0.42066722353000735 (166193/395070): 100%|█| 3087/3087 [01:06<00:0\n",
      "Train 3 | Acc 0.4227630546485433 (167021/395070): 100%|█| 3087/3087 [01:06<00:00\n",
      "Train 4 | Acc 0.42299086237881894 (167111/395070): 100%|█| 3087/3087 [01:05<00:0\n",
      "Train 5 | Acc 0.42305920469790165 (167138/395070): 100%|█| 3087/3087 [01:05<00:0\n",
      "Train 6 | Acc 0.4230667982889108 (167141/395070): 100%|█| 3087/3087 [01:06<00:00\n",
      "Train 7 | Acc 0.4230971726529476 (167153/395070): 100%|█| 3087/3087 [01:06<00:00\n",
      "Train 8 | Acc 0.42309970384995066 (167154/395070): 100%|█| 3087/3087 [01:07<00:0\n",
      "Train 9 | Acc 0.42312501581998124 (167164/395070): 100%|█| 3087/3087 [01:05<00:0\n",
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:410: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.20518895385627864 (81064/395070): 100%|█| 3087/3087 [01:09<00:00\n",
      "Train 1 | Acc 0.2041233199179892 (80643/395070): 100%|█| 3087/3087 [01:08<00:00,\n",
      "Train 2 | Acc 0.20545219834459716 (81168/395070): 100%|█| 3087/3087 [01:09<00:00\n",
      "Train 3 | Acc 0.2056800060748728 (81258/395070): 100%|█| 3087/3087 [01:09<00:00,\n",
      "Train 4 | Acc 0.20579390994001062 (81303/395070): 100%|█| 3087/3087 [01:10<00:00\n",
      "Train 5 | Acc 0.2058015035310198 (81306/395070): 100%|█| 3087/3087 [01:10<00:00,\n",
      "Train 6 | Acc 0.20584200268306882 (81322/395070): 100%|█| 3087/3087 [01:08<00:00\n",
      "Train 7 | Acc 0.20587490824410865 (81335/395070): 100%|█| 3087/3087 [01:10<00:00\n",
      "Train 8 | Acc 0.20589009542612702 (81341/395070): 100%|█| 3087/3087 [01:08<00:00\n",
      "Train 9 | Acc 0.20589262662313007 (81342/395070): 100%|█| 3087/3087 [01:10<00:00\n",
      "mkdir: cannot create directory ‘result/kdd99/’: File exists\n",
      "  0%|                                                  | 0/3087 [00:00<?, ?it/s]/home/AL_main_new/utils.py:410: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.9824790543447997 (388148/395070): 100%|█| 3087/3087 [01:15<00:00\n",
      "Train 1 | Acc 0.9982433492798745 (394376/395070): 100%|█| 3087/3087 [01:14<00:00\n",
      "Train 2 | Acc 0.9982560052648898 (394381/395070): 100%|█| 3087/3087 [01:13<00:00\n",
      "Train 3 | Acc 0.9982458804768776 (394377/395070): 100%|█| 3087/3087 [01:13<00:00\n",
      "Train 4 | Acc 0.9982787860379173 (394390/395070): 100%|█| 3087/3087 [01:13<00:00\n",
      "Train 5 | Acc 0.9982610676588959 (394383/395070): 100%|█| 3087/3087 [01:12<00:00\n",
      "Train 6 | Acc 0.9982838484319234 (394392/395070): 100%|█| 3087/3087 [01:14<00:00\n",
      "Train 7 | Acc 0.9982863796289265 (394393/395070): 100%|█| 3087/3087 [01:14<00:00\n",
      "Train 8 | Acc 0.9983066292049511 (394401/395070): 100%|█| 3087/3087 [01:16<00:00\n",
      "Train 9 | Acc 0.9983294099779786 (394410/395070): 100%|█| 3087/3087 [01:22<00:00\n"
     ]
    }
   ],
   "source": [
    "# training mask try more layer\n",
    "data = \"kdd99\"\n",
    "model =  \"linearal\"\n",
    "layer = 10\n",
    "epoch = 10\n",
    "lr = 0.0001\n",
    "for mask in range(1,layer+1):\n",
    "#for mask in [1]:\n",
    "    save = f\"mask{mask}/\"\n",
    "    load = f\"mask{mask-1}/\"\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}_m{mask}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{save}/\n",
    "    !mkdir ckpt/{save}/{data}/\n",
    "    if mask != 1:\n",
    "        !python3 dis_train_side.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --num-layer {layer} --batch-size 128 --lr {lr} --l1-dim 128 --label-emb 128 \\\n",
    "        --lr-schedule ReduceLROnPlateau \\\n",
    "        --train-mask {mask} \\\n",
    "        --save-dir ./ckpt/{save} \\\n",
    "        --load-dir ./ckpt/{load} \\\n",
    "        --task classification > {log}\n",
    "    else:\n",
    "        !python3 dis_train_side.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --num-layer {layer} --batch-size 128 --lr {lr} --l1-dim 128 --label-emb 128 \\\n",
    "        --lr-schedule ReduceLROnPlateau \\\n",
    "        --train-mask {mask} \\\n",
    "        --save-dir ./ckpt/{save} \\\n",
    "        --task classification > {log}\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f2af1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training mask try more layer\n",
    "data = \"kdd99\"\n",
    "model =  \"linearalside\"\n",
    "layer = 5\n",
    "epoch = 10\n",
    "lr = 0.0001\n",
    "for mask in range(1,layer+1):\n",
    "#for mask in [1]:\n",
    "    save = f\"mask{mask}/\"\n",
    "    load = f\"mask{mask-1}/\"\n",
    "    log = f\"result/{data}/{data}_{model}_l{layer}_m{mask}.log\"\n",
    "    !mkdir result/{data}/\n",
    "    !mkdir ckpt/{save}/\n",
    "    !mkdir ckpt/{save}/{data}/\n",
    "    if mask != 1:\n",
    "        !python3 dis_train_side.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --num-layer {layer} --batch-size 128 --lr {lr} --l1-dim 128 --label-emb 128 \\\n",
    "        --lr-schedule ReduceLROnPlateau \\\n",
    "        --train-mask {mask} \\\n",
    "        --save-dir ./ckpt/{save} \\\n",
    "        --load-dir ./ckpt/{load} \\\n",
    "        --task classification > {log}\n",
    "    else:\n",
    "        !python3 dis_train_side.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --num-layer {layer} --batch-size 128 --lr {lr} --l1-dim 128 --label-emb 128 \\\n",
    "        --lr-schedule ReduceLROnPlateau \\\n",
    "        --train-mask {mask} \\\n",
    "        --save-dir ./ckpt/{save} \\\n",
    "        --task classification > {log}\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06416ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
