{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06dd4036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       42\n",
       "1       37\n",
       "2       35\n",
       "3       37\n",
       "4       57\n",
       "      ... \n",
       "630     97\n",
       "631     92\n",
       "632    100\n",
       "633    100\n",
       "634    104\n",
       "Name: sensor_point5_i_value, Length: 635, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv(\"2022-train-v2.csv\")\n",
    "data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0f28f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['env_rpi05_hum', 'env_rpi05_pm1', 'env_rpi05_pm10', 'env_rpi05_pm25',\n",
       "       'env_rpi05_temp', 'env_rpi07_hum', 'env_rpi07_pm1', 'env_rpi07_pm10',\n",
       "       'env_rpi07_pm25', 'env_rpi07_temp', 'env_rpi09_hum', 'env_rpi09_lux',\n",
       "       'env_rpi09_pm1', 'env_rpi09_pm10', 'env_rpi09_pm25', 'env_rpi09_temp',\n",
       "       'env_rpi14_hum', 'env_rpi14_lux', 'env_rpi14_pm1', 'env_rpi14_pm10',\n",
       "       'env_rpi14_pm25', 'env_rpi14_temp', 'env_rpi15_hum', 'env_rpi15_lux',\n",
       "       'env_rpi15_pm1', 'env_rpi15_pm10', 'env_rpi15_pm25', 'env_rpi15_temp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad319671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(635, 125)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_target = data.columns[:6]\n",
    "col_feature1 = data.columns[6:33].to_list() # 27 cols\n",
    "col_feature2 = data.columns[33:43].to_list() # 10 cols\n",
    "col_feature3 = data.columns[43:103].to_list() # 60 cols\n",
    "col_feature4 = data.columns[103:].to_list() # 28 cols\n",
    "y = data[col_target]\n",
    "x = data[col_feature1 + col_feature2 + col_feature3 + col_feature4]\n",
    "x = x.fillna(0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2f394a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 76, 146, 112,  62,  86, 102])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train, clean_test, train_label, test_label = train_test_split(x, y, test_size=0.2)\n",
    "train_label.to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4e22348e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor_point5_i_value     0\n",
      "sensor_point6_i_value     0\n",
      "sensor_point7_i_value     0\n",
      "sensor_point8_i_value     0\n",
      "sensor_point9_i_value     0\n",
      "sensor_point10_i_value    0\n",
      "dtype: int64\n",
      "sensor_point5_i_value     0\n",
      "sensor_point6_i_value     0\n",
      "sensor_point7_i_value     0\n",
      "sensor_point8_i_value     0\n",
      "sensor_point9_i_value     0\n",
      "sensor_point10_i_value    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((y == 0).sum())\n",
    "print((y.isna()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "57f55723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14      1\n",
      "349     3\n",
      "397     1\n",
      "635    22\n",
      "dtype: int64 \n",
      "\n",
      "635    10\n",
      "dtype: int64 \n",
      "\n",
      "62     10\n",
      "464     1\n",
      "468     1\n",
      "471     3\n",
      "473    10\n",
      "504     5\n",
      "614     5\n",
      "617     3\n",
      "619     2\n",
      "635    20\n",
      "dtype: int64 \n",
      "\n",
      "56      1\n",
      "518     1\n",
      "524     1\n",
      "570     5\n",
      "608     5\n",
      "635    15\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for col in [col_feature1,col_feature2,col_feature3,col_feature4]:\n",
    "    print((x[col]!=0).sum(axis=0).value_counts().sort_index(),\"\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d93b4abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22    210\n",
      "23     62\n",
      "24     14\n",
      "25     28\n",
      "26    321\n",
      "dtype: int64 \n",
      "\n",
      "10    635\n",
      "dtype: int64 \n",
      "\n",
      "20      5\n",
      "22      2\n",
      "30    109\n",
      "35      3\n",
      "40     69\n",
      "45     33\n",
      "48      3\n",
      "49      4\n",
      "50    345\n",
      "60     62\n",
      "dtype: int64 \n",
      "\n",
      "21     88\n",
      "22      4\n",
      "25     25\n",
      "26     86\n",
      "27    380\n",
      "28     52\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [col_feature1,col_feature2,col_feature3,col_feature4]:\n",
    "    print((x[col]!=0).sum(axis=1).value_counts().sort_index(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbac891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 6406.1474609375: 100%|█████████| 8/8 [00:00<00:00, 19.66it/s]\n",
      "[[5.08291475e+04 5.54421422e+00]\n",
      " [4.44919227e+00 1.37897025e+00]\n",
      " [1.54342385e+00 4.90786001e-01]]\n",
      "Train Epoch0 out_loss 6406.1474609375\n",
      "Test Epoch0 layer0 out_loss 6572.89404296875\n",
      "Test Epoch0 layer1 out_loss 6653.1923828125\n",
      "Test Epoch0 layer2 out_loss 6684.71337890625\n",
      "Train 1 | out_loss 6235.0205078125: 100%|████████| 8/8 [00:00<00:00, 329.63it/s]\n",
      "[[4.94694644e+04 7.03004077e-01]\n",
      " [5.36559839e-01 6.36970807e-01]\n",
      " [7.28320777e-01 6.88812330e-01]]\n",
      "Train Epoch1 out_loss 6235.0205078125\n",
      "Test Epoch1 layer0 out_loss 6403.57470703125\n",
      "Test Epoch1 layer1 out_loss 6364.05810546875\n",
      "Test Epoch1 layer2 out_loss 6333.96826171875\n",
      "Train 2 | out_loss 5880.71044921875: 100%|███████| 8/8 [00:00<00:00, 326.33it/s]\n",
      "[[4.81456504e+04 9.96289928e-02]\n",
      " [2.63087660e-01 2.15146130e-01]\n",
      " [2.44019773e-01 3.17598742e-01]]\n",
      "Train Epoch2 out_loss 5880.71044921875\n",
      "Test Epoch2 layer0 out_loss 6231.388671875\n",
      "Test Epoch2 layer1 out_loss 6175.76171875\n",
      "Test Epoch2 layer2 out_loss 6103.45068359375\n",
      "Train 3 | out_loss 5821.8095703125: 100%|████████| 8/8 [00:00<00:00, 323.11it/s]\n",
      "[[4.68595342e+04 4.15565697e-02]\n",
      " [1.37410914e-01 1.49435144e-01]\n",
      " [1.01953626e-01 2.95450587e-01]]\n",
      "Train Epoch3 out_loss 5821.8095703125\n",
      "Test Epoch3 layer0 out_loss 6067.14306640625\n",
      "Test Epoch3 layer1 out_loss 6059.76953125\n",
      "Test Epoch3 layer2 out_loss 6081.5009765625\n",
      "Train 4 | out_loss 5727.9765625: 100%|███████████| 8/8 [00:00<00:00, 326.75it/s]\n",
      "[[4.55439219e+04 1.12316119e-01]\n",
      " [5.25581813e-02 9.10987076e-02]\n",
      " [6.43309518e-02 1.62100816e-01]]\n",
      "Train Epoch4 out_loss 5727.9765625\n",
      "Test Epoch4 layer0 out_loss 5907.81005859375\n",
      "Test Epoch4 layer1 out_loss 5891.0107421875\n",
      "Test Epoch4 layer2 out_loss 5923.67724609375\n",
      "Train 5 | out_loss 5522.30615234375: 100%|███████| 8/8 [00:00<00:00, 331.15it/s]\n",
      "[[4.43019351e+04 2.35531900e-01]\n",
      " [4.02836041e-02 4.71997573e-02]\n",
      " [3.19345440e-02 9.79930563e-02]]\n",
      "Train Epoch5 out_loss 5522.30615234375\n",
      "Test Epoch5 layer0 out_loss 5753.021484375\n",
      "Test Epoch5 layer1 out_loss 5722.2275390625\n",
      "Test Epoch5 layer2 out_loss 5709.76953125\n",
      "Train 6 | out_loss 5361.3681640625: 100%|████████| 8/8 [00:00<00:00, 328.94it/s]\n",
      "[[4.30459321e+04 2.94357099e-01]\n",
      " [1.59074015e-02 3.25112126e-02]\n",
      " [2.19456659e-02 6.73956024e-02]]\n",
      "Train Epoch6 out_loss 5361.3681640625\n",
      "Test Epoch6 layer0 out_loss 5600.2451171875\n",
      "Test Epoch6 layer1 out_loss 5573.2744140625\n",
      "Test Epoch6 layer2 out_loss 5557.91259765625\n",
      "Train 7 | out_loss 5198.49658203125: 100%|███████| 8/8 [00:00<00:00, 329.15it/s]\n",
      "[[4.18315674e+04 2.02637922e-01]\n",
      " [2.36452308e-02 2.07692576e-02]\n",
      " [1.25687608e-02 4.49284657e-02]]\n",
      "Train Epoch7 out_loss 5198.49658203125\n",
      "Test Epoch7 layer0 out_loss 5444.9013671875\n",
      "Test Epoch7 layer1 out_loss 5400.64404296875\n",
      "Test Epoch7 layer2 out_loss 5396.80615234375\n",
      "Train 8 | out_loss 5072.21435546875: 100%|███████| 8/8 [00:00<00:00, 328.66it/s]\n",
      "[[4.06633896e+04 1.73008902e-01]\n",
      " [1.17576295e-02 1.76630650e-02]\n",
      " [8.28851713e-03 2.57588695e-02]]\n",
      "Train Epoch8 out_loss 5072.21435546875\n",
      "Test Epoch8 layer0 out_loss 5293.3525390625\n",
      "Test Epoch8 layer1 out_loss 5256.1953125\n",
      "Test Epoch8 layer2 out_loss 5276.39599609375\n",
      "Train 9 | out_loss 4923.896484375: 100%|█████████| 8/8 [00:00<00:00, 328.70it/s]\n",
      "[[3.94723076e+04 1.89580720e-01]\n",
      " [7.40523328e-03 1.04585150e-02]\n",
      " [4.87497175e-03 1.53431754e-02]]\n",
      "Train Epoch9 out_loss 4923.896484375\n",
      "Test Epoch9 layer0 out_loss 5147.52294921875\n",
      "Test Epoch9 layer1 out_loss 5107.740234375\n",
      "Test Epoch9 layer2 out_loss 5105.64111328125\n",
      "Train 10 | out_loss 4772.76025390625: 100%|██████| 8/8 [00:00<00:00, 324.19it/s]\n",
      "[[3.83196777e+04 1.17929908e-01]\n",
      " [3.05074158e-03 5.69371966e-03]\n",
      " [2.92286408e-03 9.62597027e-03]]\n",
      "Train Epoch10 out_loss 4772.76025390625\n",
      "Test Epoch10 layer0 out_loss 5002.93310546875\n",
      "Test Epoch10 layer1 out_loss 4963.43603515625\n",
      "Test Epoch10 layer2 out_loss 4969.43896484375\n",
      "Train 11 | out_loss 4641.44873046875: 100%|██████| 8/8 [00:00<00:00, 328.29it/s]\n",
      "[[3.71883555e+04 1.09066574e-02]\n",
      " [1.84065958e-03 3.32394519e-03]\n",
      " [1.45824185e-03 5.31023851e-03]]\n",
      "Train Epoch11 out_loss 4641.44873046875\n",
      "Test Epoch11 layer0 out_loss 4859.8779296875\n",
      "Test Epoch11 layer1 out_loss 4820.0087890625\n",
      "Test Epoch11 layer2 out_loss 4824.63671875\n",
      "Train 12 | out_loss 4497.19677734375: 100%|██████| 8/8 [00:00<00:00, 325.93it/s]\n",
      "[[3.60789604e+04 5.39498264e-03]\n",
      " [6.87956865e-04 2.08663259e-03]\n",
      " [7.46862737e-04 3.10271341e-03]]\n",
      "Train Epoch12 out_loss 4497.19677734375\n",
      "Test Epoch12 layer0 out_loss 4719.71240234375\n",
      "Test Epoch12 layer1 out_loss 4679.3076171875\n",
      "Test Epoch12 layer2 out_loss 4679.68115234375\n",
      "Train 13 | out_loss 4357.15576171875: 100%|██████| 8/8 [00:00<00:00, 331.87it/s]\n",
      "[[3.49965896e+04 5.09449549e-03]\n",
      " [4.31521346e-04 1.43368274e-03]\n",
      " [3.68439749e-04 1.74273932e-03]]\n",
      "Train Epoch13 out_loss 4357.15576171875\n",
      "Test Epoch13 layer0 out_loss 4581.82958984375\n",
      "Test Epoch13 layer1 out_loss 4543.994140625\n",
      "Test Epoch13 layer2 out_loss 4537.119140625\n",
      "Train 14 | out_loss 4225.57421875: 100%|█████████| 8/8 [00:00<00:00, 329.22it/s]\n",
      "[[3.38890093e+04 4.87252889e-03]\n",
      " [1.67100057e-04 1.05966104e-03]\n",
      " [1.69294048e-04 1.07110547e-03]]\n",
      "Train Epoch14 out_loss 4225.57421875\n",
      "Test Epoch14 layer0 out_loss 4446.14990234375\n",
      "Test Epoch14 layer1 out_loss 4407.6826171875\n",
      "Test Epoch14 layer2 out_loss 4404.400390625\n",
      "Train 15 | out_loss 4091.825439453125: 100%|█████| 8/8 [00:00<00:00, 328.96it/s]\n",
      "[[3.28460388e+04 4.67733847e-03]\n",
      " [1.35810418e-04 8.21951064e-04]\n",
      " [8.91353679e-05 6.46601420e-04]]\n",
      "Train Epoch15 out_loss 4091.825439453125\n",
      "Test Epoch15 layer0 out_loss 4312.6474609375\n",
      "Test Epoch15 layer1 out_loss 4272.75537109375\n",
      "Test Epoch15 layer2 out_loss 4267.3603515625\n",
      "Train 16 | out_loss 3962.348876953125: 100%|█████| 8/8 [00:00<00:00, 331.83it/s]\n",
      "[[3.17993201e+04 4.49467864e-03]\n",
      " [6.77019414e-05 6.07935985e-04]\n",
      " [4.45052051e-05 3.74351435e-04]]\n",
      "Train Epoch16 out_loss 3962.348876953125\n",
      "Test Epoch16 layer0 out_loss 4181.3046875\n",
      "Test Epoch16 layer1 out_loss 4139.96337890625\n",
      "Test Epoch16 layer2 out_loss 4133.603515625\n",
      "Train 17 | out_loss 3832.61376953125: 100%|██████| 8/8 [00:00<00:00, 328.85it/s]\n",
      "[[3.07767395e+04 4.32531437e-03]\n",
      " [5.57416732e-05 4.51872664e-04]\n",
      " [2.48529520e-05 2.44953724e-04]]\n",
      "Train Epoch17 out_loss 3832.61376953125\n",
      "Test Epoch17 layer0 out_loss 4052.109619140625\n",
      "Test Epoch17 layer1 out_loss 4009.483154296875\n",
      "Test Epoch17 layer2 out_loss 4004.309814453125\n",
      "Train 18 | out_loss 3709.369140625: 100%|████████| 8/8 [00:00<00:00, 328.22it/s]\n",
      "[[2.97877581e+04 4.16547339e-03]\n",
      " [3.83725560e-05 3.47236768e-04]\n",
      " [1.40249041e-05 1.60987476e-04]]\n",
      "Train Epoch18 out_loss 3709.369140625\n",
      "Test Epoch18 layer0 out_loss 3925.054931640625\n",
      "Test Epoch18 layer1 out_loss 3881.47265625\n",
      "Test Epoch18 layer2 out_loss 3875.763427734375\n",
      "Train 19 | out_loss 3584.852294921875: 100%|█████| 8/8 [00:00<00:00, 329.48it/s]\n",
      "[[2.88007898e+04 4.01502510e-03]\n",
      " [3.22313040e-05 2.82257195e-04]\n",
      " [9.82182974e-06 1.14449032e-04]]\n",
      "Train Epoch19 out_loss 3584.852294921875\n",
      "Test Epoch19 layer0 out_loss 3800.1328125\n",
      "Test Epoch19 layer1 out_loss 3755.782958984375\n",
      "Test Epoch19 layer2 out_loss 3749.959228515625\n",
      "Train 20 | out_loss 3463.263427734375: 100%|█████| 8/8 [00:00<00:00, 332.83it/s]\n",
      "[[2.78016230e+04 3.87263217e-03]\n",
      " [2.74051376e-05 2.47863605e-04]\n",
      " [6.82294615e-06 8.75023170e-05]]\n",
      "Train Epoch20 out_loss 3463.263427734375\n",
      "Test Epoch20 layer0 out_loss 3677.337890625\n",
      "Test Epoch20 layer1 out_loss 3632.358154296875\n",
      "Test Epoch20 layer2 out_loss 3624.95849609375\n",
      "Train 21 | out_loss 3345.8994140625: 100%|███████| 8/8 [00:00<00:00, 328.58it/s]\n",
      "[[2.68602437e+04 3.73725890e-03]\n",
      " [2.33227298e-05 2.29671723e-04]\n",
      " [5.08423643e-06 7.10567242e-05]]\n",
      "Train Epoch21 out_loss 3345.8994140625\n",
      "Test Epoch21 layer0 out_loss 3556.667236328125\n",
      "Test Epoch21 layer1 out_loss 3510.93505859375\n",
      "Test Epoch21 layer2 out_loss 3504.607421875\n",
      "Train 22 | out_loss 3228.591064453125: 100%|█████| 8/8 [00:00<00:00, 333.79it/s]\n",
      "[[2.59386819e+04 3.60769025e-03]\n",
      " [1.98923948e-05 2.13733931e-04]\n",
      " [4.08140819e-06 6.18461700e-05]]\n",
      "Train Epoch22 out_loss 3228.591064453125\n",
      "Test Epoch22 layer0 out_loss 3438.1181640625\n",
      "Test Epoch22 layer1 out_loss 3391.4384765625\n",
      "Test Epoch22 layer2 out_loss 3384.540771484375\n",
      "Train 23 | out_loss 3114.664794921875: 100%|█████| 8/8 [00:00<00:00, 333.00it/s]\n",
      "[[2.50165156e+04 3.48510276e-03]\n",
      " [1.78110283e-05 1.99658984e-04]\n",
      " [3.81659081e-06 5.59721216e-05]]\n",
      "Train Epoch23 out_loss 3114.664794921875\n",
      "Test Epoch23 layer0 out_loss 3321.6875\n",
      "Test Epoch23 layer1 out_loss 3274.62451171875\n",
      "Test Epoch23 layer2 out_loss 3267.700439453125\n",
      "Train 24 | out_loss 3002.0283203125: 100%|███████| 8/8 [00:00<00:00, 328.65it/s]\n",
      "[[2.41210518e+04 3.36858371e-03]\n",
      " [1.58072146e-05 1.87085087e-04]\n",
      " [3.07885783e-06 5.19533703e-05]]\n",
      "Train Epoch24 out_loss 3002.0283203125\n",
      "Test Epoch24 layer0 out_loss 3207.37451171875\n",
      "Test Epoch24 layer1 out_loss 3159.56591796875\n",
      "Test Epoch24 layer2 out_loss 3153.87890625\n",
      "Train 25 | out_loss 2892.26123046875: 100%|██████| 8/8 [00:00<00:00, 325.38it/s]\n",
      "[[2.32305015e+04 3.25725265e-03]\n",
      " [1.40550101e-05 1.76803710e-04]\n",
      " [2.69400727e-06 4.82264572e-05]]\n",
      "Train Epoch25 out_loss 2892.26123046875\n",
      "Test Epoch25 layer0 out_loss 3095.177734375\n",
      "Test Epoch25 layer1 out_loss 3046.957763671875\n",
      "Test Epoch25 layer2 out_loss 3042.029541015625\n",
      "Train 26 | out_loss 2785.070556640625: 100%|█████| 8/8 [00:00<00:00, 325.67it/s]\n",
      "[[2.23829922e+04 3.15132551e-03]\n",
      " [1.26543864e-05 1.67203183e-04]\n",
      " [2.35838310e-06 4.57969290e-05]]\n",
      "Train Epoch26 out_loss 2785.070556640625\n",
      "Test Epoch26 layer0 out_loss 2985.096435546875\n",
      "Test Epoch26 layer1 out_loss 2936.3798828125\n",
      "Test Epoch26 layer2 out_loss 2930.417724609375\n",
      "Train 27 | out_loss 2680.5068359375: 100%|███████| 8/8 [00:00<00:00, 312.38it/s]\n",
      "[[2.15273694e+04 3.05014665e-03]\n",
      " [1.15315397e-05 1.58213719e-04]\n",
      " [2.10399283e-06 4.29355496e-05]]\n",
      "Train Epoch27 out_loss 2680.5068359375\n",
      "Test Epoch27 layer0 out_loss 2877.131103515625\n",
      "Test Epoch27 layer1 out_loss 2828.19580078125\n",
      "Test Epoch27 layer2 out_loss 2821.74365234375\n",
      "Train 28 | out_loss 2577.2978515625: 100%|███████| 8/8 [00:00<00:00, 331.47it/s]\n",
      "[[2.07075513e+04 2.95395948e-03]\n",
      " [1.04764664e-05 1.51113336e-04]\n",
      " [1.98688247e-06 4.10806063e-05]]\n",
      "Train Epoch28 out_loss 2577.2978515625\n",
      "Test Epoch28 layer0 out_loss 2771.281982421875\n",
      "Test Epoch28 layer1 out_loss 2722.23291015625\n",
      "Test Epoch28 layer2 out_loss 2716.541259765625\n",
      "Train 29 | out_loss 2475.71337890625: 100%|██████| 8/8 [00:00<00:00, 325.01it/s]\n",
      "[[1.98925547e+04 2.86211903e-03]\n",
      " [9.50344904e-06 1.45019791e-04]\n",
      " [1.88661015e-06 3.99438204e-05]]\n",
      "Train Epoch29 out_loss 2475.71337890625\n",
      "Test Epoch29 layer0 out_loss 2667.546142578125\n",
      "Test Epoch29 layer1 out_loss 2618.606201171875\n",
      "Test Epoch29 layer2 out_loss 2613.0771484375\n",
      "Train 30 | out_loss 2377.32470703125: 100%|██████| 8/8 [00:00<00:00, 325.49it/s]\n",
      "[[1.91156675e+04 2.77403594e-03]\n",
      " [8.62563964e-06 1.36789321e-04]\n",
      " [1.72484062e-06 3.75711716e-05]]\n",
      "Train Epoch30 out_loss 2377.32470703125\n",
      "Test Epoch30 layer0 out_loss 2565.927001953125\n",
      "Test Epoch30 layer1 out_loss 2516.72021484375\n",
      "Test Epoch30 layer2 out_loss 2511.94580078125\n",
      "Train 31 | out_loss 2280.60693359375: 100%|██████| 8/8 [00:00<00:00, 322.62it/s]\n",
      "[[1.83430330e+04 2.69004441e-03]\n",
      " [7.96179070e-06 1.31408759e-04]\n",
      " [1.60233899e-06 3.63301460e-05]]\n",
      "Train Epoch31 out_loss 2280.60693359375\n",
      "Test Epoch31 layer0 out_loss 2466.421630859375\n",
      "Test Epoch31 layer1 out_loss 2417.44384765625\n",
      "Test Epoch31 layer2 out_loss 2412.63818359375\n",
      "Train 32 | out_loss 2186.155517578125: 100%|█████| 8/8 [00:00<00:00, 331.07it/s]\n",
      "[[1.75785731e+04 2.60979278e-03]\n",
      " [7.42951131e-06 1.25398166e-04]\n",
      " [1.41779337e-06 3.48557314e-05]]\n",
      "Train Epoch32 out_loss 2186.155517578125\n",
      "Test Epoch32 layer0 out_loss 2369.03173828125\n",
      "Test Epoch32 layer1 out_loss 2320.1474609375\n",
      "Test Epoch32 layer2 out_loss 2315.219970703125\n",
      "Train 33 | out_loss 2094.963134765625: 100%|█████| 8/8 [00:00<00:00, 332.03it/s]\n",
      "[[1.68407565e+04 2.53285491e-03]\n",
      " [6.87261709e-06 1.20724823e-04]\n",
      " [1.33138341e-06 3.41046534e-05]]\n",
      "Train Epoch33 out_loss 2094.963134765625\n",
      "Test Epoch33 layer0 out_loss 2273.7578125\n",
      "Test Epoch33 layer1 out_loss 2224.923583984375\n",
      "Test Epoch33 layer2 out_loss 2219.31298828125\n",
      "Train 34 | out_loss 2004.467529296875: 100%|█████| 8/8 [00:00<00:00, 332.76it/s]\n",
      "[[1.61308438e+04 2.45964367e-03]\n",
      " [6.35397666e-06 1.16462473e-04]\n",
      " [1.21825535e-06 3.33807565e-05]]\n",
      "Train Epoch34 out_loss 2004.467529296875\n",
      "Test Epoch34 layer0 out_loss 2180.599853515625\n",
      "Test Epoch34 layer1 out_loss 2132.482421875\n",
      "Test Epoch34 layer2 out_loss 2127.7646484375\n",
      "Train 35 | out_loss 1916.44140625: 100%|█████████| 8/8 [00:00<00:00, 331.78it/s]\n",
      "[[1.54148909e+04 2.38910437e-03]\n",
      " [6.00136132e-06 1.12852355e-04]\n",
      " [1.11607355e-06 3.23825166e-05]]\n",
      "Train Epoch35 out_loss 1916.44140625\n",
      "Test Epoch35 layer0 out_loss 2089.558349609375\n",
      "Test Epoch35 layer1 out_loss 2041.5767822265625\n",
      "Test Epoch35 layer2 out_loss 2038.036376953125\n",
      "Train 36 | out_loss 1830.8148193359375: 100%|████| 8/8 [00:00<00:00, 331.33it/s]\n",
      "[[1.47177069e+04 2.32200598e-03]\n",
      " [5.62375734e-06 1.09409749e-04]\n",
      " [1.18132327e-06 3.19027563e-05]]\n",
      "Train Epoch36 out_loss 1830.8148193359375\n",
      "Test Epoch36 layer0 out_loss 2000.6334228515625\n",
      "Test Epoch36 layer1 out_loss 1952.7835693359375\n",
      "Test Epoch36 layer2 out_loss 1948.3292236328125\n",
      "Train 37 | out_loss 1747.6300048828125: 100%|████| 8/8 [00:00<00:00, 329.12it/s]\n",
      "[[1.40634528e+04 2.25734402e-03]\n",
      " [5.20714539e-06 1.05052363e-04]\n",
      " [1.07630088e-06 3.09852306e-05]]\n",
      "Train Epoch37 out_loss 1747.6300048828125\n",
      "Test Epoch37 layer0 out_loss 1913.82568359375\n",
      "Test Epoch37 layer1 out_loss 1866.7265625\n",
      "Test Epoch37 layer2 out_loss 1862.5426025390625\n",
      "Train 38 | out_loss 1666.002197265625: 100%|█████| 8/8 [00:00<00:00, 329.17it/s]\n",
      "[[1.34112144e+04 2.19548473e-03]\n",
      " [5.03473436e-06 1.01448176e-04]\n",
      " [9.94514476e-07 3.02215597e-05]]\n",
      "Train Epoch38 out_loss 1666.002197265625\n",
      "Test Epoch38 layer0 out_loss 1829.1351318359375\n",
      "Test Epoch38 layer1 out_loss 1782.3565673828125\n",
      "Test Epoch38 layer2 out_loss 1778.5731201171875\n",
      "Train 39 | out_loss 1587.2672119140625: 100%|████| 8/8 [00:00<00:00, 327.18it/s]\n",
      "[[1.27735138e+04 2.13587115e-03]\n",
      " [4.72347606e-06 9.70901719e-05]\n",
      " [1.09219848e-06 2.90865283e-05]]\n",
      "Train Epoch39 out_loss 1587.2672119140625\n",
      "Test Epoch39 layer0 out_loss 1746.5614013671875\n",
      "Test Epoch39 layer1 out_loss 1700.558349609375\n",
      "Test Epoch39 layer2 out_loss 1696.850341796875\n",
      "Train 40 | out_loss 1510.1070556640625: 100%|████| 8/8 [00:00<00:00, 328.77it/s]\n",
      "[[1.21442175e+04 2.07897811e-03]\n",
      " [4.53625744e-06 9.43466848e-05]\n",
      " [1.08304414e-06 2.89479547e-05]]\n",
      "Train Epoch40 out_loss 1510.1070556640625\n",
      "Test Epoch40 layer0 out_loss 1666.1065673828125\n",
      "Test Epoch40 layer1 out_loss 1620.6641845703125\n",
      "Test Epoch40 layer2 out_loss 1617.41552734375\n",
      "Train 41 | out_loss 1435.6309814453125: 100%|████| 8/8 [00:00<00:00, 331.04it/s]\n",
      "[[1.15570503e+04 2.02429495e-03]\n",
      " [4.24416182e-06 9.09463761e-05]\n",
      " [9.20357511e-07 2.80847087e-05]]\n",
      "Train Epoch41 out_loss 1435.6309814453125\n",
      "Test Epoch41 layer0 out_loss 1587.77001953125\n",
      "Test Epoch41 layer1 out_loss 1543.046630859375\n",
      "Test Epoch41 layer2 out_loss 1539.8736572265625\n",
      "Train 42 | out_loss 1362.9776611328125: 100%|████| 8/8 [00:00<00:00, 331.31it/s]\n",
      "[[1.09661956e+04 1.97161606e-03]\n",
      " [4.14887956e-06 8.80637026e-05]\n",
      " [8.97835573e-07 2.73384658e-05]]\n",
      "Train Epoch42 out_loss 1362.9776611328125\n",
      "Test Epoch42 layer0 out_loss 1511.5516357421875\n",
      "Test Epoch42 layer1 out_loss 1467.3900146484375\n",
      "Test Epoch42 layer2 out_loss 1464.05029296875\n",
      "Train 43 | out_loss 1292.3564453125: 100%|███████| 8/8 [00:00<00:00, 284.99it/s]\n",
      "[[1.04157043e+04 1.92104276e-03]\n",
      " [3.94263663e-06 8.57089717e-05]\n",
      " [8.25662536e-07 2.69992063e-05]]\n",
      "Train Epoch43 out_loss 1292.3564453125\n",
      "Test Epoch43 layer0 out_loss 1437.4525146484375\n",
      "Test Epoch43 layer1 out_loss 1394.243408203125\n",
      "Test Epoch43 layer2 out_loss 1390.806640625\n",
      "Train 44 | out_loss 1223.892822265625: 100%|█████| 8/8 [00:00<00:00, 322.51it/s]\n",
      "[[9.86109631e+03 1.87226430e-03]\n",
      " [3.78529277e-06 8.29710375e-05]\n",
      " [7.71324411e-07 2.63744680e-05]]\n",
      "Train Epoch44 out_loss 1223.892822265625\n",
      "Test Epoch44 layer0 out_loss 1365.472900390625\n",
      "Test Epoch44 layer1 out_loss 1323.0491943359375\n",
      "Test Epoch44 layer2 out_loss 1319.9285888671875\n",
      "Train 45 | out_loss 1158.0457763671875: 100%|████| 8/8 [00:00<00:00, 320.37it/s]\n",
      "[[9.33106042e+03 1.82564942e-03]\n",
      " [3.69047678e-06 8.11419841e-05]\n",
      " [7.20314171e-07 2.61242034e-05]]\n",
      "Train Epoch45 out_loss 1158.0457763671875\n",
      "Test Epoch45 layer0 out_loss 1295.613037109375\n",
      "Test Epoch45 layer1 out_loss 1254.0489501953125\n",
      "Test Epoch45 layer2 out_loss 1251.344482421875\n",
      "Train 46 | out_loss 1094.156982421875: 100%|█████| 8/8 [00:00<00:00, 312.20it/s]\n",
      "[[8.81082483e+03 1.78042601e-03]\n",
      " [3.64295673e-06 7.86520513e-05]\n",
      " [6.84013521e-07 2.55579041e-05]]\n",
      "Train Epoch46 out_loss 1094.156982421875\n",
      "Test Epoch46 layer0 out_loss 1227.8729248046875\n",
      "Test Epoch46 layer1 out_loss 1187.124267578125\n",
      "Test Epoch46 layer2 out_loss 1184.8592529296875\n",
      "Train 47 | out_loss 1032.3929443359375: 100%|████| 8/8 [00:00<00:00, 325.68it/s]\n",
      "[[8.30438324e+03 1.73705879e-03]\n",
      " [3.57956477e-06 7.70158185e-05]\n",
      " [6.70503900e-07 2.53637609e-05]]\n",
      "Train Epoch47 out_loss 1032.3929443359375\n",
      "Test Epoch47 layer0 out_loss 1162.2537841796875\n",
      "Test Epoch47 layer1 out_loss 1122.298828125\n",
      "Test Epoch47 layer2 out_loss 1120.2955322265625\n",
      "Train 48 | out_loss 972.5465087890625: 100%|█████| 8/8 [00:00<00:00, 332.60it/s]\n",
      "[[7.83351025e+03 1.69524922e-03]\n",
      " [3.56105895e-06 7.47066579e-05]\n",
      " [6.60132940e-07 2.45923684e-05]]\n",
      "Train Epoch48 out_loss 972.5465087890625\n",
      "Test Epoch48 layer0 out_loss 1098.7547607421875\n",
      "Test Epoch48 layer1 out_loss 1059.913818359375\n",
      "Test Epoch48 layer2 out_loss 1057.3084716796875\n",
      "Train 49 | out_loss 914.3787841796875: 100%|█████| 8/8 [00:00<00:00, 333.95it/s]\n",
      "[[7.37148920e+03 1.65470970e-03]\n",
      " [3.55829608e-06 7.24340969e-05]\n",
      " [7.07392983e-07 2.40803754e-05]]\n",
      "Train Epoch49 out_loss 914.3787841796875\n",
      "Test Epoch49 layer0 out_loss 1037.376953125\n",
      "Test Epoch49 layer1 out_loss 999.398681640625\n",
      "Test Epoch49 layer2 out_loss 996.713623046875\n",
      "Train 50 | out_loss 859.2029418945312: 100%|█████| 8/8 [00:00<00:00, 329.79it/s]\n",
      "[[6.92459930e+03 1.61576357e-03]\n",
      " [3.67023037e-06 7.09043675e-05]\n",
      " [7.32210317e-07 2.37961754e-05]]\n",
      "Train Epoch50 out_loss 859.2029418945312\n",
      "Test Epoch50 layer0 out_loss 978.1201782226562\n",
      "Test Epoch50 layer1 out_loss 941.1828002929688\n",
      "Test Epoch50 layer2 out_loss 938.830078125\n",
      "Train 51 | out_loss 806.607666015625: 100%|██████| 8/8 [00:00<00:00, 322.91it/s]\n",
      "[[6.49906879e+03 1.57724849e-03]\n",
      " [3.97955540e-06 6.89402445e-05]\n",
      " [7.71594690e-07 2.34075885e-05]]\n",
      "Train Epoch51 out_loss 806.607666015625\n",
      "Test Epoch51 layer0 out_loss 920.98486328125\n",
      "Test Epoch51 layer1 out_loss 885.2131958007812\n",
      "Test Epoch51 layer2 out_loss 882.9666748046875\n",
      "Train 52 | out_loss 755.0673828125: 100%|████████| 8/8 [00:00<00:00, 327.43it/s]\n",
      "[[6.08526013e+03 1.53928428e-03]\n",
      " [5.82490697e-06 6.74521439e-05]\n",
      " [9.38329210e-07 2.31348649e-05]]\n",
      "Train Epoch52 out_loss 755.0673828125\n",
      "Test Epoch52 layer0 out_loss 865.9713134765625\n",
      "Test Epoch52 layer1 out_loss 831.2147827148438\n",
      "Test Epoch52 layer2 out_loss 829.2440795898438\n",
      "Train 53 | out_loss 706.764892578125: 100%|██████| 8/8 [00:00<00:00, 326.91it/s]\n",
      "[[5.69664716e+03 1.50447285e-03]\n",
      " [1.17681327e-05 6.64697250e-05]\n",
      " [1.39124678e-06 2.27502713e-05]]\n",
      "Train Epoch53 out_loss 706.764892578125\n",
      "Test Epoch53 layer0 out_loss 813.0806274414062\n",
      "Test Epoch53 layer1 out_loss 779.512451171875\n",
      "Test Epoch53 layer2 out_loss 777.611083984375\n",
      "Train 54 | out_loss 659.3536987304688: 100%|█████| 8/8 [00:00<00:00, 327.93it/s]\n",
      "[[5.32336914e+03 1.47065816e-03]\n",
      " [1.74807050e-05 6.51623006e-05]\n",
      " [1.52154113e-06 2.21231926e-05]]\n",
      "Train Epoch54 out_loss 659.3536987304688\n",
      "Test Epoch54 layer0 out_loss 762.3131103515625\n",
      "Test Epoch54 layer1 out_loss 730.0442504882812\n",
      "Test Epoch54 layer2 out_loss 728.185791015625\n",
      "Train 55 | out_loss 615.326904296875: 100%|██████| 8/8 [00:00<00:00, 329.20it/s]\n",
      "[[4.96125885e+03 1.45484666e-03]\n",
      " [5.64998048e-05 6.73384129e-05]\n",
      " [3.78843085e-06 2.22636788e-05]]\n",
      "Train Epoch55 out_loss 615.326904296875\n",
      "Test Epoch55 layer0 out_loss 713.670166015625\n",
      "Test Epoch55 layer1 out_loss 682.6788940429688\n",
      "Test Epoch55 layer2 out_loss 680.6654663085938\n",
      "Train 56 | out_loss 573.211181640625: 100%|██████| 8/8 [00:00<00:00, 328.23it/s]\n",
      "[[4.62027109e+03 1.45312944e-03]\n",
      " [1.01820121e-04 6.97456217e-05]\n",
      " [7.87707859e-06 2.25572919e-05]]\n",
      "Train Epoch56 out_loss 573.211181640625\n",
      "Test Epoch56 layer0 out_loss 667.1525268554688\n",
      "Test Epoch56 layer1 out_loss 637.845947265625\n",
      "Test Epoch56 layer2 out_loss 636.1214599609375\n",
      "Train 57 | out_loss 532.9484252929688: 100%|█████| 8/8 [00:00<00:00, 327.88it/s]\n",
      "[[4.28707257e+03 1.51134418e-03]\n",
      " [2.21629590e-04 8.13787524e-05]\n",
      " [1.94117258e-05 2.40889360e-05]]\n",
      "Train Epoch57 out_loss 532.9484252929688\n",
      "Test Epoch57 layer0 out_loss 622.7601928710938\n",
      "Test Epoch57 layer1 out_loss 595.0318603515625\n",
      "Test Epoch57 layer2 out_loss 593.2069091796875\n",
      "Train 58 | out_loss 494.54071044921875: 100%|████| 8/8 [00:00<00:00, 324.30it/s]\n",
      "[[3.97678497e+03 1.50034872e-03]\n",
      " [2.45979880e-04 8.49562944e-05]\n",
      " [2.19933531e-05 2.66350489e-05]]\n",
      "Train Epoch58 out_loss 494.54071044921875\n",
      "Test Epoch58 layer0 out_loss 580.4986572265625\n",
      "Test Epoch58 layer1 out_loss 554.1119384765625\n",
      "Test Epoch58 layer2 out_loss 551.7136840820312\n",
      "Train 59 | out_loss 459.02618408203125: 100%|████| 8/8 [00:00<00:00, 331.83it/s]\n",
      "[[3.68705356e+03 1.69116812e-03]\n",
      " [4.92087363e-04 1.08241971e-04]\n",
      " [4.22278540e-05 3.10945602e-05]]\n",
      "Train Epoch59 out_loss 459.02618408203125\n",
      "Test Epoch59 layer0 out_loss 540.3740234375\n",
      "Test Epoch59 layer1 out_loss 515.9781494140625\n",
      "Test Epoch59 layer2 out_loss 514.548095703125\n",
      "Train 60 | out_loss 425.2803955078125: 100%|█████| 8/8 [00:00<00:00, 329.49it/s]\n",
      "[[3.41373880e+03 1.66727585e-03]\n",
      " [5.08653692e-04 1.16218261e-04]\n",
      " [5.19341671e-05 3.91595393e-05]]\n",
      "Train Epoch60 out_loss 425.2803955078125\n",
      "Test Epoch60 layer0 out_loss 502.3843688964844\n",
      "Test Epoch60 layer1 out_loss 478.8928527832031\n",
      "Test Epoch60 layer2 out_loss 479.37982177734375\n",
      "Train 61 | out_loss 395.2564697265625: 100%|█████| 8/8 [00:00<00:00, 330.48it/s]\n",
      "[[3.15997534e+03 2.32582919e-03]\n",
      " [1.21240751e-03 1.78360897e-04]\n",
      " [1.08174256e-04 6.12116614e-05]]\n",
      "Train Epoch61 out_loss 395.2564697265625\n",
      "Test Epoch61 layer0 out_loss 466.5815124511719\n",
      "Test Epoch61 layer1 out_loss 446.96282958984375\n",
      "Test Epoch61 layer2 out_loss 446.55340576171875\n",
      "Train 62 | out_loss 366.62054443359375: 100%|████| 8/8 [00:00<00:00, 330.39it/s]\n",
      "[[2.91392047e+03 2.93921030e-03]\n",
      " [1.83106809e-03 2.32073137e-04]\n",
      " [1.62414490e-04 8.41636374e-05]]\n",
      "Train Epoch62 out_loss 366.62054443359375\n",
      "Test Epoch62 layer0 out_loss 432.9533996582031\n",
      "Test Epoch62 layer1 out_loss 414.321533203125\n",
      "Test Epoch62 layer2 out_loss 411.7034912109375\n",
      "Train 63 | out_loss 338.59576416015625: 100%|████| 8/8 [00:00<00:00, 326.95it/s]\n",
      "[[2.69871204e+03 2.66723821e-03]\n",
      " [1.61359351e-03 2.11893135e-04]\n",
      " [1.53473356e-04 9.77891314e-05]]\n",
      "Train Epoch63 out_loss 338.59576416015625\n",
      "Test Epoch63 layer0 out_loss 401.4536437988281\n",
      "Test Epoch63 layer1 out_loss 385.30584716796875\n",
      "Test Epoch63 layer2 out_loss 383.3638000488281\n",
      "Train 64 | out_loss 314.4036865234375: 100%|█████| 8/8 [00:00<00:00, 325.85it/s]\n",
      "[[2.49013783e+03 3.46338289e-03]\n",
      " [2.38454623e-03 3.03316349e-04]\n",
      " [2.35463653e-04 1.28576815e-04]]\n",
      "Train Epoch64 out_loss 314.4036865234375\n",
      "Test Epoch64 layer0 out_loss 372.16162109375\n",
      "Test Epoch64 layer1 out_loss 357.5948486328125\n",
      "Test Epoch64 layer2 out_loss 359.4373779296875\n",
      "Train 65 | out_loss 296.8152160644531: 100%|█████| 8/8 [00:00<00:00, 328.56it/s]\n",
      "[[2.29379135e+03 7.73447825e-03]\n",
      " [5.64032150e-03 5.98227281e-04]\n",
      " [5.12332619e-04 2.27565979e-04]]\n",
      "Train Epoch65 out_loss 296.8152160644531\n",
      "Test Epoch65 layer0 out_loss 345.3536376953125\n",
      "Test Epoch65 layer1 out_loss 338.694580078125\n",
      "Test Epoch65 layer2 out_loss 339.57000732421875\n",
      "Train 66 | out_loss 271.81982421875: 100%|███████| 8/8 [00:00<00:00, 328.25it/s]\n",
      "[[2.12857222e+03 4.11040167e-03]\n",
      " [3.37552598e-03 5.77043429e-04]\n",
      " [5.30820053e-04 4.36093280e-04]]\n",
      "Train Epoch66 out_loss 271.81982421875\n",
      "Test Epoch66 layer0 out_loss 320.6105651855469\n",
      "Test Epoch66 layer1 out_loss 308.3314514160156\n",
      "Test Epoch66 layer2 out_loss 307.1757507324219\n",
      "Train 67 | out_loss 253.75741577148438: 100%|████| 8/8 [00:00<00:00, 328.30it/s]\n",
      "[[1.96181764e+03 6.43140559e-03]\n",
      " [4.70296346e-03 7.84592492e-04]\n",
      " [7.28347492e-04 7.14401598e-04]]\n",
      "Train Epoch67 out_loss 253.75741577148438\n",
      "Test Epoch67 layer0 out_loss 298.328369140625\n",
      "Test Epoch67 layer1 out_loss 292.953857421875\n",
      "Test Epoch67 layer2 out_loss 299.72674560546875\n",
      "Train 68 | out_loss 247.4584503173828: 100%|█████| 8/8 [00:00<00:00, 323.97it/s]\n",
      "[[1.82539095e+03 1.68241966e-02]\n",
      " [1.10370073e-02 1.37488871e-03]\n",
      " [1.26150475e-03 1.00866851e-03]]\n",
      "Train Epoch68 out_loss 247.4584503173828\n",
      "Test Epoch68 layer0 out_loss 278.8251037597656\n",
      "Test Epoch68 layer1 out_loss 276.7431945800781\n",
      "Test Epoch68 layer2 out_loss 279.1911926269531\n",
      "Train 69 | out_loss 224.51669311523438: 100%|████| 8/8 [00:00<00:00, 328.58it/s]\n",
      "[[1.69805782e+03 1.02612910e-02]\n",
      " [8.08624690e-03 1.29689264e-03]\n",
      " [1.24637246e-03 1.51083930e-03]]\n",
      "Train Epoch69 out_loss 224.51669311523438\n",
      "Test Epoch69 layer0 out_loss 261.194580078125\n",
      "Test Epoch69 layer1 out_loss 260.548828125\n",
      "Test Epoch69 layer2 out_loss 253.9829559326172\n",
      "Train 70 | out_loss 223.33079528808594: 100%|████| 8/8 [00:00<00:00, 327.26it/s]\n",
      "[[1.58653659e+03 2.38738412e-02]\n",
      " [1.41521856e-02 1.94427397e-03]\n",
      " [1.75247878e-03 1.74734922e-03]]\n",
      "Train Epoch70 out_loss 223.33079528808594\n",
      "Test Epoch70 layer0 out_loss 245.6610107421875\n",
      "Test Epoch70 layer1 out_loss 251.41908264160156\n",
      "Test Epoch70 layer2 out_loss 248.4545135498047\n",
      "Train 71 | out_loss 209.56961059570312: 100%|████| 8/8 [00:00<00:00, 332.59it/s]\n",
      "[[1.48398247e+03 2.74733144e-02]\n",
      " [1.54710286e-02 2.11084083e-03]\n",
      " [1.99892712e-03 1.79894573e-03]]\n",
      "Train Epoch71 out_loss 209.56961059570312\n",
      "Test Epoch71 layer0 out_loss 232.19667053222656\n",
      "Test Epoch71 layer1 out_loss 241.35574340820312\n",
      "Test Epoch71 layer2 out_loss 234.91366577148438\n",
      "Train 72 | out_loss 201.8344268798828: 100%|█████| 8/8 [00:00<00:00, 326.86it/s]\n",
      "[[1.40097234e+03 2.98745516e-02]\n",
      " [1.62307959e-02 2.20625383e-03]\n",
      " [2.23375607e-03 1.85140550e-03]]\n",
      "Train Epoch72 out_loss 201.8344268798828\n",
      "Test Epoch72 layer0 out_loss 221.11636352539062\n",
      "Test Epoch72 layer1 out_loss 223.09007263183594\n",
      "Test Epoch72 layer2 out_loss 228.70069885253906\n",
      "Train 73 | out_loss 193.16238403320312: 100%|████| 8/8 [00:00<00:00, 331.71it/s]\n",
      "[[1.32911279e+03 3.26865900e-02]\n",
      " [1.67554665e-02 2.51230077e-03]\n",
      " [2.42958723e-03 2.10914438e-03]]\n",
      "Train Epoch73 out_loss 193.16238403320312\n",
      "Test Epoch73 layer0 out_loss 212.7774200439453\n",
      "Test Epoch73 layer1 out_loss 218.39035034179688\n",
      "Test Epoch73 layer2 out_loss 216.81895446777344\n",
      "Train 74 | out_loss 194.08596801757812: 100%|████| 8/8 [00:00<00:00, 308.97it/s]\n",
      "[[1.26213529e+03 5.07041723e-02]\n",
      " [2.15774683e-02 3.21523866e-03]\n",
      " [2.94405449e-03 2.31449906e-03]]\n",
      "Train Epoch74 out_loss 194.08596801757812\n",
      "Test Epoch74 layer0 out_loss 206.75343322753906\n",
      "Test Epoch74 layer1 out_loss 223.78915405273438\n",
      "Test Epoch74 layer2 out_loss 221.18724060058594\n",
      "Train 75 | out_loss 189.71763610839844: 100%|████| 8/8 [00:00<00:00, 323.46it/s]\n",
      "[[1.20381540e+03 5.45604937e-02]\n",
      " [2.31985316e-02 3.83710649e-03]\n",
      " [3.36898438e-03 2.36268737e-03]]\n",
      "Train Epoch75 out_loss 189.71763610839844\n",
      "Test Epoch75 layer0 out_loss 203.04708862304688\n",
      "Test Epoch75 layer1 out_loss 213.02915954589844\n",
      "Test Epoch75 layer2 out_loss 211.80416870117188\n",
      "Train 76 | out_loss 183.09182739257812: 100%|████| 8/8 [00:00<00:00, 329.44it/s]\n",
      "[[1.15587551e+03 4.99453093e-02]\n",
      " [2.28496108e-02 4.27563049e-03]\n",
      " [3.62537877e-03 2.21567515e-03]]\n",
      "Train Epoch76 out_loss 183.09182739257812\n",
      "Test Epoch76 layer0 out_loss 197.93292236328125\n",
      "Test Epoch76 layer1 out_loss 203.96188354492188\n",
      "Test Epoch76 layer2 out_loss 210.33261108398438\n",
      "Train 77 | out_loss 189.62557983398438: 100%|████| 8/8 [00:00<00:00, 315.93it/s]\n",
      "[[1.11316442e+03 8.33972441e-02]\n",
      " [3.21473074e-02 8.25162465e-03]\n",
      " [6.87146449e-03 3.28101960e-03]]\n",
      "Train Epoch77 out_loss 189.62557983398438\n",
      "Test Epoch77 layer0 out_loss 199.9872283935547\n",
      "Test Epoch77 layer1 out_loss 210.1730194091797\n",
      "Test Epoch77 layer2 out_loss 216.6275177001953\n",
      "Train 78 | out_loss 176.97206115722656: 100%|████| 8/8 [00:00<00:00, 321.17it/s]\n",
      "[[1.07491326e+03 4.88314943e-02]\n",
      " [2.76455976e-02 1.06513677e-02]\n",
      " [1.05022156e-02 7.63854611e-03]]\n",
      "Train Epoch78 out_loss 176.97206115722656\n",
      "Test Epoch78 layer0 out_loss 193.67018127441406\n",
      "Test Epoch78 layer1 out_loss 198.19334411621094\n",
      "Test Epoch78 layer2 out_loss 190.2102813720703\n",
      "Train 79 | out_loss 182.0601348876953: 100%|█████| 8/8 [00:00<00:00, 328.10it/s]\n",
      "[[1.04281578e+03 6.27197656e-02]\n",
      " [3.04124432e-02 1.49579286e-02]\n",
      " [1.45005514e-02 1.40908909e-02]]\n",
      "Train Epoch79 out_loss 182.0601348876953\n",
      "Test Epoch79 layer0 out_loss 198.76702880859375\n",
      "Test Epoch79 layer1 out_loss 198.6388397216797\n",
      "Test Epoch79 layer2 out_loss 206.38465881347656\n",
      "Train 80 | out_loss 176.1080322265625: 100%|█████| 8/8 [00:00<00:00, 328.82it/s]\n",
      "[[1.01699452e+03 5.42739569e-02]\n",
      " [2.61998717e-02 1.57427117e-02]\n",
      " [1.58941301e-02 1.69530617e-02]]\n",
      "Train Epoch80 out_loss 176.1080322265625\n",
      "Test Epoch80 layer0 out_loss 193.70184326171875\n",
      "Test Epoch80 layer1 out_loss 198.29437255859375\n",
      "Test Epoch80 layer2 out_loss 190.98931884765625\n",
      "Train 81 | out_loss 179.1499481201172: 100%|█████| 8/8 [00:00<00:00, 328.62it/s]\n",
      "[[9.92217918e+02 5.97377699e-02]\n",
      " [2.46101627e-02 1.87801494e-02]\n",
      " [1.72033360e-02 1.86156771e-02]]\n",
      "Train Epoch81 out_loss 179.1499481201172\n",
      "Test Epoch81 layer0 out_loss 199.11448669433594\n",
      "Test Epoch81 layer1 out_loss 200.25990295410156\n",
      "Test Epoch81 layer2 out_loss 208.0963897705078\n",
      "Train 82 | out_loss 176.44076538085938: 100%|████| 8/8 [00:00<00:00, 323.53it/s]\n",
      "[[9.65277237e+02 6.19601388e-02]\n",
      " [2.03177680e-02 2.03092754e-02]\n",
      " [1.66454751e-02 1.81051190e-02]]\n",
      "Train Epoch82 out_loss 176.44076538085938\n",
      "Test Epoch82 layer0 out_loss 193.89544677734375\n",
      "Test Epoch82 layer1 out_loss 194.36524963378906\n",
      "Test Epoch82 layer2 out_loss 194.47207641601562\n",
      "Train 83 | out_loss 175.08587646484375: 100%|████| 8/8 [00:00<00:00, 321.78it/s]\n",
      "[[9.42834023e+02 6.14435072e-02]\n",
      " [1.62107755e-02 2.40451108e-02]\n",
      " [1.72657872e-02 1.88276020e-02]]\n",
      "Train Epoch83 out_loss 175.08587646484375\n",
      "Test Epoch83 layer0 out_loss 194.08409118652344\n",
      "Test Epoch83 layer1 out_loss 192.1676025390625\n",
      "Test Epoch83 layer2 out_loss 193.8513641357422\n",
      "Train 84 | out_loss 173.0809326171875: 100%|█████| 8/8 [00:00<00:00, 324.52it/s]\n",
      "[[9.23822731e+02 6.18230654e-02]\n",
      " [1.12863384e-02 2.75659701e-02]\n",
      " [1.61459312e-02 1.89614727e-02]]\n",
      "Train Epoch84 out_loss 173.0809326171875\n",
      "Test Epoch84 layer0 out_loss 188.93838500976562\n",
      "Test Epoch84 layer1 out_loss 194.3875732421875\n",
      "Test Epoch84 layer2 out_loss 190.18038940429688\n",
      "Train 85 | out_loss 172.5220184326172: 100%|█████| 8/8 [00:00<00:00, 325.34it/s]\n",
      "[[9.07730545e+02 6.11382290e-02]\n",
      " [7.72859307e-03 3.17776091e-02]\n",
      " [1.39639577e-02 2.18282999e-02]]\n",
      "Train Epoch85 out_loss 172.5220184326172\n",
      "Test Epoch85 layer0 out_loss 192.05084228515625\n",
      "Test Epoch85 layer1 out_loss 191.38018798828125\n",
      "Test Epoch85 layer2 out_loss 196.8260498046875\n",
      "Train 86 | out_loss 173.27304077148438: 100%|████| 8/8 [00:00<00:00, 321.56it/s]\n",
      "[[8.93692764e+02 6.74859025e-02]\n",
      " [4.99492657e-03 3.77859862e-02]\n",
      " [1.05891800e-02 2.76947976e-02]]\n",
      "Train Epoch86 out_loss 173.27304077148438\n",
      "Test Epoch86 layer0 out_loss 191.19346618652344\n",
      "Test Epoch86 layer1 out_loss 193.98114013671875\n",
      "Test Epoch86 layer2 out_loss 192.06460571289062\n",
      "Train 87 | out_loss 172.64337158203125: 100%|████| 8/8 [00:00<00:00, 330.97it/s]\n",
      "[[8.83826561e+02 6.38487241e-02]\n",
      " [3.26867244e-03 4.08228519e-02]\n",
      " [6.91906462e-03 3.40255175e-02]]\n",
      "Train Epoch87 out_loss 172.64337158203125\n",
      "Test Epoch87 layer0 out_loss 189.0313720703125\n",
      "Test Epoch87 layer1 out_loss 187.13706970214844\n",
      "Test Epoch87 layer2 out_loss 185.6083984375\n",
      "Train 88 | out_loss 171.4970703125: 100%|████████| 8/8 [00:00<00:00, 321.50it/s]\n",
      "[[8.66085892e+02 6.66091056e-02]\n",
      " [2.56267616e-03 4.47103428e-02]\n",
      " [4.74332279e-03 4.25537969e-02]]\n",
      "Train Epoch88 out_loss 171.4970703125\n",
      "Test Epoch88 layer0 out_loss 189.84800720214844\n",
      "Test Epoch88 layer1 out_loss 187.4404296875\n",
      "Test Epoch88 layer2 out_loss 187.70440673828125\n",
      "Train 89 | out_loss 171.89004516601562: 100%|████| 8/8 [00:00<00:00, 318.99it/s]\n",
      "[[8.57167542e+02 6.76205768e-02]\n",
      " [1.82267811e-03 4.70482614e-02]\n",
      " [2.99280256e-03 4.93386732e-02]]\n",
      "Train Epoch89 out_loss 171.89004516601562\n",
      "Test Epoch89 layer0 out_loss 192.09451293945312\n",
      "Test Epoch89 layer1 out_loss 193.81570434570312\n",
      "Test Epoch89 layer2 out_loss 199.988037109375\n",
      "Train 90 | out_loss 170.79244995117188: 100%|████| 8/8 [00:00<00:00, 328.18it/s]\n",
      "[[8.41873779e+02 7.43809724e-02]\n",
      " [1.31443568e-03 5.04265754e-02]\n",
      " [1.93927468e-03 5.53218406e-02]]\n",
      "Train Epoch90 out_loss 170.79244995117188\n",
      "Test Epoch90 layer0 out_loss 192.40167236328125\n",
      "Test Epoch90 layer1 out_loss 182.49807739257812\n",
      "Test Epoch90 layer2 out_loss 182.74557495117188\n",
      "Train 91 | out_loss 165.8308563232422: 100%|█████| 8/8 [00:00<00:00, 326.15it/s]\n",
      "[[8.43932884e+02 6.77391612e-02]\n",
      " [1.16754475e-03 4.86902697e-02]\n",
      " [1.57942252e-03 5.50653082e-02]]\n",
      "Train Epoch91 out_loss 165.8308563232422\n",
      "Test Epoch91 layer0 out_loss 181.69248962402344\n",
      "Test Epoch91 layer1 out_loss 186.30691528320312\n",
      "Test Epoch91 layer2 out_loss 180.5929718017578\n",
      "Train 92 | out_loss 177.22084045410156: 100%|████| 8/8 [00:00<00:00, 327.24it/s]\n",
      "[[8.27369789e+02 8.67261793e-02]\n",
      " [1.04804377e-03 5.90098016e-02]\n",
      " [1.49768776e-03 6.40962403e-02]]\n",
      "Train Epoch92 out_loss 177.22084045410156\n",
      "Test Epoch92 layer0 out_loss 202.2011260986328\n",
      "Test Epoch92 layer1 out_loss 193.2100372314453\n",
      "Test Epoch92 layer2 out_loss 189.52183532714844\n",
      "Train 93 | out_loss 173.68780517578125: 100%|████| 8/8 [00:00<00:00, 326.69it/s]\n",
      "[[8.14831970e+02 7.69010242e-02]\n",
      " [6.65090865e-04 5.38122319e-02]\n",
      " [1.18018850e-03 5.87907713e-02]]\n",
      "Train Epoch93 out_loss 173.68780517578125\n",
      "Test Epoch93 layer0 out_loss 186.00682067871094\n",
      "Test Epoch93 layer1 out_loss 184.09202575683594\n",
      "Test Epoch93 layer2 out_loss 188.20437622070312\n",
      "Train 94 | out_loss 175.158447265625: 100%|██████| 8/8 [00:00<00:00, 327.58it/s]\n",
      "[[8.09571457e+02 8.77949777e-02]\n",
      " [9.25379005e-04 5.64378798e-02]\n",
      " [1.14830784e-03 6.18224479e-02]]\n",
      "Train Epoch94 out_loss 175.158447265625\n",
      "Test Epoch94 layer0 out_loss 193.7569580078125\n",
      "Test Epoch94 layer1 out_loss 195.52369689941406\n",
      "Test Epoch94 layer2 out_loss 197.6136474609375\n",
      "Train 95 | out_loss 173.5036163330078: 100%|█████| 8/8 [00:00<00:00, 326.96it/s]\n",
      "[[8.07387589e+02 8.11489224e-02]\n",
      " [1.60648268e-03 5.67356534e-02]\n",
      " [1.77432541e-03 6.28653122e-02]]\n",
      "Train Epoch95 out_loss 173.5036163330078\n",
      "Test Epoch95 layer0 out_loss 189.59054565429688\n",
      "Test Epoch95 layer1 out_loss 182.9842529296875\n",
      "Test Epoch95 layer2 out_loss 183.43331909179688\n",
      "Train 96 | out_loss 173.29953002929688: 100%|████| 8/8 [00:00<00:00, 328.43it/s]\n",
      "[[7.88296394e+02 8.08430151e-02]\n",
      " [1.29724196e-03 5.90754603e-02]\n",
      " [2.21497631e-03 6.56342502e-02]]\n",
      "Train Epoch96 out_loss 173.29953002929688\n",
      "Test Epoch96 layer0 out_loss 190.02053833007812\n",
      "Test Epoch96 layer1 out_loss 190.208251953125\n",
      "Test Epoch96 layer2 out_loss 197.20802307128906\n",
      "Train 97 | out_loss 172.01344299316406: 100%|████| 8/8 [00:00<00:00, 325.00it/s]\n",
      "[[7.76650246e+02 7.65577825e-02]\n",
      " [6.64433614e-04 5.82271870e-02]\n",
      " [1.73180868e-03 6.26439704e-02]]\n",
      "Train Epoch97 out_loss 172.01344299316406\n",
      "Test Epoch97 layer0 out_loss 189.97219848632812\n",
      "Test Epoch97 layer1 out_loss 189.3106231689453\n",
      "Test Epoch97 layer2 out_loss 187.42396545410156\n",
      "Train 98 | out_loss 172.11927795410156: 100%|████| 8/8 [00:00<00:00, 325.99it/s]\n",
      "[[7.68886440e+02 7.69769065e-02]\n",
      " [5.66401726e-04 6.07314105e-02]\n",
      " [1.43993192e-03 6.28587441e-02]]\n",
      "Train Epoch98 out_loss 172.11927795410156\n",
      "Test Epoch98 layer0 out_loss 195.2698211669922\n",
      "Test Epoch98 layer1 out_loss 189.26217651367188\n",
      "Test Epoch98 layer2 out_loss 188.1404571533203\n",
      "Train 99 | out_loss 170.75892639160156: 100%|████| 8/8 [00:00<00:00, 330.20it/s]\n",
      "[[7.66825851e+02 7.57461172e-02]\n",
      " [6.08545284e-04 6.04915884e-02]\n",
      " [1.15687274e-03 6.14914563e-02]]\n",
      "Train Epoch99 out_loss 170.75892639160156\n",
      "Test Epoch99 layer0 out_loss 194.5899658203125\n",
      "Test Epoch99 layer1 out_loss 191.95628356933594\n",
      "Test Epoch99 layer2 out_loss 191.7109375\n"
     ]
    }
   ],
   "source": [
    "# LinearAL \n",
    "\n",
    "data = \"paint\"\n",
    "model =  \"linearal\"\n",
    "#for layer in [2,3,4,5,10]:\n",
    "for layer in [3]:\n",
    "    log = f\"result/{data}_{model}_l{layer}.log\"\n",
    "    !python3 dis_train_al.py --dataset {data} --model {model} --epoch 100 --num-layer {layer} --task regression # > {log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae70865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
