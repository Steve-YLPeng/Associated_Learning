{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06dd4036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7818"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "df = pd.read_csv(\"criteo_small.csv\")\n",
    "\n",
    "col_target = [\"label\"]\n",
    "col_dense = [f\"I{i}\" for i in range(1,14)]\n",
    "col_sparse = [f\"C{i}\" for i in range(1,27)]\n",
    "\n",
    "df[col_sparse] = df[col_sparse].fillna('-1', )\n",
    "df[col_dense] = df[col_dense].fillna(0,)\n",
    "\n",
    "for feat in col_sparse:\n",
    "    lbe = LabelEncoder()\n",
    "    df[feat] = lbe.fit_transform(df[feat])\n",
    "    \n",
    "mms = MinMaxScaler(feature_range=(0,1))\n",
    "df[col_dense] = mms.fit_transform(df[col_dense])\n",
    "\n",
    "y = df[col_target]\n",
    "x = df[col_dense + col_sparse]\n",
    "1-(y.to_numpy().sum() / y.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f28f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "house_dataset = fetch_california_housing()\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    house_dataset.data,\n",
    "    columns=house_dataset.feature_names\n",
    ")\n",
    "df.loc[:,\"Price\"] = house_dataset.target\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df.loc[:,:] = scaler.fit_transform(df)\n",
    "\n",
    "col_feature = house_dataset.feature_names\n",
    "col_target = [\"Price\"]\n",
    "\n",
    "y = df[col_target]\n",
    "x = df[col_feature]\n",
    "x = x.fillna(0)\n",
    "target_num = 1\n",
    "args.feature_dim = 8\n",
    "feature_train, feature_test, train_target, test_target = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f78ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_sparse = ['protocol_type','service','flag']\n",
    "col_dense = ['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate',    'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',  'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate']\n",
    "label = ['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fe67003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.unique(dataset.target).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
       "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
       "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
       "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
       "       'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
       "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
       "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
       "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
       "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
       "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
       "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
       "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
       "       'dst_host_srv_rerror_rate', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18a7e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_sparse = ['protocol_type', 'service', 'flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da3ef581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " duration\n",
      "0        481671\n",
      "1          2476\n",
      "2           870\n",
      "3           625\n",
      "5           554\n",
      "          ...  \n",
      "18185         1\n",
      "4283          1\n",
      "2154          1\n",
      "1007          1\n",
      "120           1\n",
      "Name: duration, Length: 2495, dtype: int64\n",
      "\n",
      " protocol_type\n",
      "b'icmp'    283602\n",
      "b'tcp'     190065\n",
      "b'udp'      20354\n",
      "Name: protocol_type, dtype: int64\n",
      "\n",
      " service\n",
      "b'ecr_i'      281400\n",
      "b'private'    110893\n",
      "b'http'        64293\n",
      "b'smtp'         9723\n",
      "b'other'        7237\n",
      "               ...  \n",
      "b'X11'            11\n",
      "b'tim_i'           7\n",
      "b'pm_dump'         1\n",
      "b'tftp_u'          1\n",
      "b'red_i'           1\n",
      "Name: service, Length: 66, dtype: int64\n",
      "\n",
      " flag\n",
      "b'SF'        378440\n",
      "b'S0'         87007\n",
      "b'REJ'        26875\n",
      "b'RSTR'         903\n",
      "b'RSTO'         579\n",
      "b'SH'           107\n",
      "b'S1'            57\n",
      "b'S2'            24\n",
      "b'RSTOS0'        11\n",
      "b'S3'            10\n",
      "b'OTH'            8\n",
      "Name: flag, dtype: int64\n",
      "\n",
      " src_bytes\n",
      "1032     228035\n",
      "0        115342\n",
      "520       52774\n",
      "105        7370\n",
      "147        2725\n",
      "          ...  \n",
      "6927          1\n",
      "2315          1\n",
      "11898         1\n",
      "12289         1\n",
      "475           1\n",
      "Name: src_bytes, Length: 3300, dtype: int64\n",
      "\n",
      " dst_bytes\n",
      "0        408258\n",
      "105        4451\n",
      "147        2501\n",
      "146        2289\n",
      "8314       2133\n",
      "          ...  \n",
      "11707         1\n",
      "1258          1\n",
      "21324         1\n",
      "53843         1\n",
      "13828         1\n",
      "Name: dst_bytes, Length: 10725, dtype: int64\n",
      "\n",
      " land\n",
      "0    493999\n",
      "1        22\n",
      "Name: land, dtype: int64\n",
      "\n",
      " wrong_fragment\n",
      "0    492783\n",
      "3       970\n",
      "1       268\n",
      "Name: wrong_fragment, dtype: int64\n",
      "\n",
      " urgent\n",
      "0    494017\n",
      "1         2\n",
      "2         1\n",
      "3         1\n",
      "Name: urgent, dtype: int64\n",
      "\n",
      " hot\n",
      "0     490829\n",
      "2       2192\n",
      "28       274\n",
      "1        256\n",
      "4        112\n",
      "6        104\n",
      "5         51\n",
      "3         38\n",
      "14        37\n",
      "30        28\n",
      "22        28\n",
      "19        23\n",
      "24        13\n",
      "18        13\n",
      "20        10\n",
      "7          5\n",
      "17         2\n",
      "12         2\n",
      "16         1\n",
      "10         1\n",
      "15         1\n",
      "9          1\n",
      "Name: hot, dtype: int64\n",
      "\n",
      " num_failed_logins\n",
      "0    493958\n",
      "1        57\n",
      "2         3\n",
      "5         1\n",
      "4         1\n",
      "3         1\n",
      "Name: num_failed_logins, dtype: int64\n",
      "\n",
      " logged_in\n",
      "0    420784\n",
      "1     73237\n",
      "Name: logged_in, dtype: int64\n",
      "\n",
      " num_compromised\n",
      "0      491797\n",
      "1        2151\n",
      "2          24\n",
      "4          16\n",
      "3          11\n",
      "6           3\n",
      "5           2\n",
      "7           2\n",
      "767         1\n",
      "12          1\n",
      "9           1\n",
      "884         1\n",
      "13          1\n",
      "38          1\n",
      "18          1\n",
      "11          1\n",
      "275         1\n",
      "281         1\n",
      "16          1\n",
      "238         1\n",
      "21          1\n",
      "22          1\n",
      "102         1\n",
      "Name: num_compromised, dtype: int64\n",
      "\n",
      " root_shell\n",
      "0    493966\n",
      "1        55\n",
      "Name: root_shell, dtype: int64\n",
      "\n",
      " su_attempted\n",
      "0    494009\n",
      "1         6\n",
      "2         6\n",
      "Name: su_attempted, dtype: int64\n",
      "\n",
      " num_root\n",
      "0      493436\n",
      "1         233\n",
      "9         167\n",
      "6         126\n",
      "2          22\n",
      "5          12\n",
      "4          10\n",
      "3           3\n",
      "7           1\n",
      "993         1\n",
      "54          1\n",
      "306         1\n",
      "14          1\n",
      "39          1\n",
      "278         1\n",
      "268         1\n",
      "12          1\n",
      "857         1\n",
      "16          1\n",
      "119         1\n",
      "Name: num_root, dtype: int64\n",
      "\n",
      " num_file_creations\n",
      "0     493756\n",
      "1        207\n",
      "2         36\n",
      "4          7\n",
      "16         2\n",
      "5          1\n",
      "22         1\n",
      "25         1\n",
      "12         1\n",
      "8          1\n",
      "7          1\n",
      "21         1\n",
      "14         1\n",
      "10         1\n",
      "28         1\n",
      "9          1\n",
      "15         1\n",
      "20         1\n",
      "Name: num_file_creations, dtype: int64\n",
      "\n",
      " num_shells\n",
      "0    493970\n",
      "1        48\n",
      "2         3\n",
      "Name: num_shells, dtype: int64\n",
      "\n",
      " num_access_files\n",
      "0    493567\n",
      "1       424\n",
      "2        25\n",
      "3         2\n",
      "4         1\n",
      "6         1\n",
      "8         1\n",
      "Name: num_access_files, dtype: int64\n",
      "\n",
      " num_outbound_cmds\n",
      "0    494021\n",
      "Name: num_outbound_cmds, dtype: int64\n",
      "\n",
      " is_host_login\n",
      "0    494021\n",
      "Name: is_host_login, dtype: int64\n",
      "\n",
      " is_guest_login\n",
      "0    493336\n",
      "1       685\n",
      "Name: is_guest_login, dtype: int64\n",
      "\n",
      " count\n",
      "511    227895\n",
      "1       39214\n",
      "510     26598\n",
      "2       11219\n",
      "3        5812\n",
      "        ...  \n",
      "354         1\n",
      "422         1\n",
      "333         1\n",
      "415         1\n",
      "407         1\n",
      "Name: count, Length: 490, dtype: int64\n",
      "\n",
      " srv_count\n",
      "511    226559\n",
      "1       37001\n",
      "510     26898\n",
      "2       18857\n",
      "3       11280\n",
      "        ...  \n",
      "414         1\n",
      "370         1\n",
      "288         1\n",
      "362         1\n",
      "407         1\n",
      "Name: srv_count, Length: 470, dtype: int64\n",
      "\n",
      " serror_rate\n",
      "0.00    404787\n",
      "1.00     86537\n",
      "0.99       311\n",
      "0.08       155\n",
      "0.05       150\n",
      "         ...  \n",
      "0.87         1\n",
      "0.80         1\n",
      "0.90         1\n",
      "0.34         1\n",
      "0.89         1\n",
      "Name: serror_rate, Length: 92, dtype: int64\n",
      "\n",
      " srv_serror_rate\n",
      "0.00    405686\n",
      "1.00     87052\n",
      "0.03       139\n",
      "0.04       120\n",
      "0.05       109\n",
      "0.06        98\n",
      "0.02        84\n",
      "0.50        78\n",
      "0.08        73\n",
      "0.07        68\n",
      "0.25        56\n",
      "0.33        55\n",
      "0.17        51\n",
      "0.09        48\n",
      "0.10        46\n",
      "0.20        45\n",
      "0.12        43\n",
      "0.11        43\n",
      "0.14        34\n",
      "0.01        10\n",
      "0.67         9\n",
      "0.18         6\n",
      "0.92         6\n",
      "0.95         5\n",
      "0.94         5\n",
      "0.88         4\n",
      "0.19         4\n",
      "0.58         4\n",
      "0.75         4\n",
      "0.83         3\n",
      "0.76         3\n",
      "0.15         3\n",
      "0.91         3\n",
      "0.40         3\n",
      "0.85         2\n",
      "0.27         2\n",
      "0.22         2\n",
      "0.93         2\n",
      "0.16         1\n",
      "0.38         1\n",
      "0.36         1\n",
      "0.35         1\n",
      "0.45         1\n",
      "0.21         1\n",
      "0.44         1\n",
      "0.23         1\n",
      "0.51         1\n",
      "0.86         1\n",
      "0.90         1\n",
      "0.80         1\n",
      "0.37         1\n",
      "Name: srv_serror_rate, dtype: int64\n",
      "\n",
      " rerror_rate\n",
      "0.00    464948\n",
      "1.00     26979\n",
      "0.86       113\n",
      "0.87       102\n",
      "0.92        97\n",
      "         ...  \n",
      "0.66         1\n",
      "0.31         1\n",
      "0.32         1\n",
      "0.34         1\n",
      "0.24         1\n",
      "Name: rerror_rate, Length: 77, dtype: int64\n",
      "\n",
      " srv_rerror_rate\n",
      "0.00    464320\n",
      "1.00     28116\n",
      "0.33       252\n",
      "0.50       201\n",
      "0.25       173\n",
      "0.20       143\n",
      "0.17       128\n",
      "0.14        73\n",
      "0.04        63\n",
      "0.03        61\n",
      "0.12        57\n",
      "0.06        54\n",
      "0.02        54\n",
      "0.05        41\n",
      "0.07        36\n",
      "0.40        30\n",
      "0.67        28\n",
      "0.08        28\n",
      "0.11        26\n",
      "0.29        25\n",
      "0.09        24\n",
      "0.10        16\n",
      "0.75        11\n",
      "0.60        11\n",
      "0.01         6\n",
      "0.71         4\n",
      "0.22         4\n",
      "0.83         3\n",
      "0.86         3\n",
      "0.18         2\n",
      "0.96         2\n",
      "0.79         2\n",
      "0.43         2\n",
      "0.92         2\n",
      "0.81         2\n",
      "0.88         2\n",
      "0.73         2\n",
      "0.69         1\n",
      "0.94         1\n",
      "0.62         1\n",
      "0.80         1\n",
      "0.85         1\n",
      "0.93         1\n",
      "0.82         1\n",
      "0.27         1\n",
      "0.37         1\n",
      "0.21         1\n",
      "0.38         1\n",
      "0.87         1\n",
      "0.95         1\n",
      "0.13         1\n",
      "Name: srv_rerror_rate, dtype: int64\n",
      "\n",
      " same_srv_rate\n",
      "1.00    382079\n",
      "0.06     11196\n",
      "0.05     10582\n",
      "0.04     10161\n",
      "0.07     10028\n",
      "         ...  \n",
      "0.68         2\n",
      "0.69         2\n",
      "0.87         1\n",
      "0.63         1\n",
      "0.61         1\n",
      "Name: same_srv_rate, Length: 99, dtype: int64\n",
      "\n",
      " diff_srv_rate\n",
      "0.00    382021\n",
      "0.06     52812\n",
      "0.07     28798\n",
      "0.05     19218\n",
      "0.08      3254\n",
      "         ...  \n",
      "0.82         1\n",
      "0.86         1\n",
      "0.64         1\n",
      "0.83         1\n",
      "0.88         1\n",
      "Name: diff_srv_rate, Length: 78, dtype: int64\n",
      "\n",
      " srv_diff_host_rate\n",
      "0.00    459377\n",
      "1.00      8099\n",
      "0.12      1508\n",
      "0.50      1418\n",
      "0.67      1410\n",
      "         ...  \n",
      "0.54         2\n",
      "0.46         2\n",
      "0.88         2\n",
      "0.70         1\n",
      "0.77         1\n",
      "Name: srv_diff_host_rate, Length: 64, dtype: int64\n",
      "\n",
      " dst_host_count\n",
      "255    432829\n",
      "1        2884\n",
      "2        2023\n",
      "3        1434\n",
      "4        1317\n",
      "        ...  \n",
      "254        70\n",
      "226        70\n",
      "236        63\n",
      "246        61\n",
      "0           3\n",
      "Name: dst_host_count, Length: 256, dtype: int64\n",
      "\n",
      " dst_host_srv_count\n",
      "255    337746\n",
      "1       11895\n",
      "2        7243\n",
      "3        5855\n",
      "11       5627\n",
      "        ...  \n",
      "199        66\n",
      "207        65\n",
      "206        62\n",
      "202        56\n",
      "0           3\n",
      "Name: dst_host_srv_count, Length: 256, dtype: int64\n",
      "\n",
      " dst_host_same_srv_rate\n",
      "1.00    347828\n",
      "0.04     16092\n",
      "0.02     15880\n",
      "0.05     15414\n",
      "0.07     15165\n",
      "         ...  \n",
      "0.30       155\n",
      "0.21       151\n",
      "0.34       150\n",
      "0.41       148\n",
      "0.42       144\n",
      "Name: dst_host_same_srv_rate, Length: 101, dtype: int64\n",
      "\n",
      " dst_host_diff_srv_rate\n",
      "0.00    347031\n",
      "0.07     45922\n",
      "0.06     28224\n",
      "0.05     18466\n",
      "0.08     14540\n",
      "         ...  \n",
      "0.97        11\n",
      "0.94        10\n",
      "0.93         8\n",
      "0.92         7\n",
      "0.99         6\n",
      "Name: dst_host_diff_srv_rate, Length: 101, dtype: int64\n",
      "\n",
      " dst_host_same_src_port_rate\n",
      "1.00    288883\n",
      "0.00    142860\n",
      "0.01     21912\n",
      "0.02      7228\n",
      "0.03      4419\n",
      "         ...  \n",
      "0.78        34\n",
      "0.70        32\n",
      "0.72        28\n",
      "0.66        27\n",
      "0.68        27\n",
      "Name: dst_host_same_src_port_rate, Length: 101, dtype: int64\n",
      "\n",
      " dst_host_srv_diff_host_rate\n",
      "0.00    441889\n",
      "0.02     11738\n",
      "0.01     10530\n",
      "0.04      6673\n",
      "0.03      6624\n",
      "         ...  \n",
      "0.80         1\n",
      "0.58         1\n",
      "0.75         1\n",
      "0.70         1\n",
      "0.47         1\n",
      "Name: dst_host_srv_diff_host_rate, Length: 65, dtype: int64\n",
      "\n",
      " dst_host_serror_rate\n",
      "0.00    399810\n",
      "1.00     86759\n",
      "0.01      3670\n",
      "0.02       989\n",
      "0.03       425\n",
      "         ...  \n",
      "0.66         1\n",
      "0.74         1\n",
      "0.78         1\n",
      "0.86         1\n",
      "0.37         1\n",
      "Name: dst_host_serror_rate, Length: 100, dtype: int64\n",
      "\n",
      " dst_host_srv_serror_rate\n",
      "0.00    400945\n",
      "1.00     86997\n",
      "0.01      4868\n",
      "0.02       675\n",
      "0.03       149\n",
      "         ...  \n",
      "0.87         1\n",
      "0.84         1\n",
      "0.55         1\n",
      "0.81         1\n",
      "0.53         1\n",
      "Name: dst_host_srv_serror_rate, Length: 72, dtype: int64\n",
      "\n",
      " dst_host_rerror_rate\n",
      "0.00    458792\n",
      "1.00     26040\n",
      "0.01      1596\n",
      "0.02       932\n",
      "0.04       801\n",
      "         ...  \n",
      "0.63        19\n",
      "0.34        18\n",
      "0.46        15\n",
      "0.39        14\n",
      "0.79        13\n",
      "Name: dst_host_rerror_rate, Length: 101, dtype: int64\n",
      "\n",
      " dst_host_srv_rerror_rate\n",
      "0.00    459805\n",
      "1.00     25695\n",
      "0.01      1851\n",
      "0.04       830\n",
      "0.02       783\n",
      "         ...  \n",
      "0.23         6\n",
      "0.32         5\n",
      "0.28         4\n",
      "0.26         4\n",
      "0.22         4\n",
      "Name: dst_host_srv_rerror_rate, Length: 101, dtype: int64\n",
      "\n",
      " label\n",
      "b'smurf.'              280790\n",
      "b'neptune.'            107201\n",
      "b'normal.'              97278\n",
      "b'back.'                 2203\n",
      "b'satan.'                1589\n",
      "b'ipsweep.'              1247\n",
      "b'portsweep.'            1040\n",
      "b'warezclient.'          1020\n",
      "b'teardrop.'              979\n",
      "b'pod.'                   264\n",
      "b'nmap.'                  231\n",
      "b'guess_passwd.'           53\n",
      "b'buffer_overflow.'        30\n",
      "b'land.'                   21\n",
      "b'warezmaster.'            20\n",
      "b'imap.'                   12\n",
      "b'rootkit.'                10\n",
      "b'loadmodule.'              9\n",
      "b'ftp_write.'               8\n",
      "b'multihop.'                7\n",
      "b'phf.'                     4\n",
      "b'perl.'                    3\n",
      "b'spy.'                     2\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print('\\n',col)\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad319671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(635, 125)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_target = data.columns[:6]\n",
    "col_feature1 = data.columns[6:33].to_list() # 27 cols\n",
    "col_feature2 = data.columns[33:43].to_list() # 10 cols\n",
    "col_feature3 = data.columns[43:103].to_list() # 60 cols\n",
    "col_feature4 = data.columns[103:].to_list() # 28 cols\n",
    "y = data[col_target]\n",
    "x = data[col_feature1 + col_feature2 + col_feature3 + col_feature4]\n",
    "x = x.fillna(0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2f394a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 92, 100,  78,  78,  84,  68])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train, clean_test, train_label, test_label = train_test_split(x, y, test_size=0.2)\n",
    "train_label.to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e22348e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor_point5_i_value     0\n",
      "sensor_point6_i_value     0\n",
      "sensor_point7_i_value     0\n",
      "sensor_point8_i_value     0\n",
      "sensor_point9_i_value     0\n",
      "sensor_point10_i_value    0\n",
      "dtype: int64\n",
      "sensor_point5_i_value     0\n",
      "sensor_point6_i_value     0\n",
      "sensor_point7_i_value     0\n",
      "sensor_point8_i_value     0\n",
      "sensor_point9_i_value     0\n",
      "sensor_point10_i_value    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((y == 0).sum())\n",
    "print((y.isna()).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57f55723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      22\n",
      "238     1\n",
      "286     3\n",
      "621     1\n",
      "dtype: int64 \n",
      "\n",
      "0    10\n",
      "dtype: int64 \n",
      "\n",
      "0      20\n",
      "16      2\n",
      "18      3\n",
      "21      5\n",
      "131     5\n",
      "162    10\n",
      "164     3\n",
      "167     1\n",
      "171     1\n",
      "573    10\n",
      "dtype: int64 \n",
      "\n",
      "0      15\n",
      "27      5\n",
      "65      5\n",
      "111     1\n",
      "117     1\n",
      "579     1\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for col in [col_feature1,col_feature2,col_feature3,col_feature4]:\n",
    "    print((x[col]==0).sum(axis=0).value_counts().sort_index(),\"\\n\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d93b4abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    321\n",
      "2     28\n",
      "3     14\n",
      "4     62\n",
      "5    210\n",
      "dtype: int64 \n",
      "\n",
      "0    635\n",
      "dtype: int64 \n",
      "\n",
      "0      62\n",
      "10    345\n",
      "11      4\n",
      "12      3\n",
      "15     33\n",
      "20     69\n",
      "25      3\n",
      "30    109\n",
      "38      2\n",
      "40      5\n",
      "dtype: int64 \n",
      "\n",
      "0     52\n",
      "1    380\n",
      "2     86\n",
      "3     25\n",
      "6      4\n",
      "7     88\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [col_feature1,col_feature2,col_feature3,col_feature4]:\n",
    "    print((x[col]==0).sum(axis=1).value_counts().sort_index(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbac891a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "  0%|                                                   | 0/258 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | out_loss 0.6337985396385193: 100%|█| 258/258 [00:02<00:00, 121.27it/s]\n",
      "Train Epoch0 out_loss 0.4017006456851959, R2 0.6002315282821655\n",
      "Test Epoch0 layer0 out_loss 0.32252609729766846, R2 0.6710010766983032\n",
      "Test Epoch0 layer1 out_loss 0.297218918800354, R2 0.6968162059783936\n",
      "Test Epoch0 layer2 out_loss 0.2917695939540863, R2 0.7023748159408569\n",
      "Test Epoch0 layer3 out_loss 0.2951323688030243, R2 0.6989445686340332\n",
      "Test Epoch0 layer4 out_loss 0.3012111783027649, R2 0.6927437782287598\n",
      "Train 1 | out_loss 0.5396091938018799: 100%|█| 258/258 [00:01<00:00, 143.97it/s]\n",
      "Train Epoch1 out_loss 0.29117798805236816, R2 0.7102225422859192\n",
      "Test Epoch1 layer0 out_loss 0.30407649278640747, R2 0.6898209452629089\n",
      "Test Epoch1 layer1 out_loss 0.27703142166137695, R2 0.7174087762832642\n",
      "Test Epoch1 layer2 out_loss 0.2743087112903595, R2 0.720186173915863\n",
      "Test Epoch1 layer3 out_loss 0.2808779776096344, R2 0.713485062122345\n",
      "Test Epoch1 layer4 out_loss 0.28432902693748474, R2 0.7099647521972656\n",
      "Train 2 | out_loss 0.5281102657318115: 100%|█| 258/258 [00:01<00:00, 138.28it/s]\n",
      "Train Epoch2 out_loss 0.2789004445075989, R2 0.7224410772323608\n",
      "Test Epoch2 layer0 out_loss 0.2984330654144287, R2 0.6955776214599609\n",
      "Test Epoch2 layer1 out_loss 0.274930477142334, R2 0.7195519208908081\n",
      "Test Epoch2 layer2 out_loss 0.27299928665161133, R2 0.7215218544006348\n",
      "Test Epoch2 layer3 out_loss 0.271695613861084, R2 0.7228517532348633\n",
      "Test Epoch2 layer4 out_loss 0.274619460105896, R2 0.7198691368103027\n",
      "Train 3 | out_loss 0.5204576849937439: 100%|█| 258/258 [00:01<00:00, 141.26it/s]\n",
      "Train Epoch3 out_loss 0.2708762288093567, R2 0.7304266691207886\n",
      "Test Epoch3 layer0 out_loss 0.30189046263694763, R2 0.6920508742332458\n",
      "Test Epoch3 layer1 out_loss 0.27427253127098083, R2 0.720223069190979\n",
      "Test Epoch3 layer2 out_loss 0.271720826625824, R2 0.7228260040283203\n",
      "Test Epoch3 layer3 out_loss 0.2749255299568176, R2 0.7195569276809692\n",
      "Test Epoch3 layer4 out_loss 0.28147023916244507, R2 0.7128809094429016\n",
      "Train 4 | out_loss 0.5175905227661133: 100%|█| 258/258 [00:01<00:00, 138.50it/s]\n",
      "Train Epoch4 out_loss 0.26789987087249756, R2 0.7333887219429016\n",
      "Test Epoch4 layer0 out_loss 0.293897807598114, R2 0.7002038955688477\n",
      "Test Epoch4 layer1 out_loss 0.27449753880500793, R2 0.719993531703949\n",
      "Test Epoch4 layer2 out_loss 0.26785367727279663, R2 0.7267707586288452\n",
      "Test Epoch4 layer3 out_loss 0.2670176923274994, R2 0.727623462677002\n",
      "Test Epoch4 layer4 out_loss 0.26619571447372437, R2 0.7284619808197021\n",
      "Train 5 | out_loss 0.5105181336402893: 100%|█| 258/258 [00:01<00:00, 144.21it/s]\n",
      "Train Epoch5 out_loss 0.2606287896633148, R2 0.7406248450279236\n",
      "Test Epoch5 layer0 out_loss 0.30099090933799744, R2 0.692968487739563\n",
      "Test Epoch5 layer1 out_loss 0.2707691192626953, R2 0.7237968444824219\n",
      "Test Epoch5 layer2 out_loss 0.2619069516658783, R2 0.7328368425369263\n",
      "Test Epoch5 layer3 out_loss 0.25971540808677673, R2 0.7350723743438721\n",
      "Test Epoch5 layer4 out_loss 0.2620857357978821, R2 0.7326544523239136\n",
      "Train 6 | out_loss 0.5071045756340027: 100%|█| 258/258 [00:01<00:00, 135.90it/s]\n",
      "Train Epoch6 out_loss 0.25715500116348267, R2 0.7440819144248962\n",
      "Test Epoch6 layer0 out_loss 0.28865358233451843, R2 0.705553412437439\n",
      "Test Epoch6 layer1 out_loss 0.26313504576683044, R2 0.7315840721130371\n",
      "Test Epoch6 layer2 out_loss 0.2551930248737335, R2 0.7396854758262634\n",
      "Test Epoch6 layer3 out_loss 0.2556779086589813, R2 0.7391908764839172\n",
      "Test Epoch6 layer4 out_loss 0.25632190704345703, R2 0.7385339736938477\n",
      "Train 7 | out_loss 0.5047711133956909: 100%|█| 258/258 [00:02<00:00, 127.55it/s]\n",
      "Train Epoch7 out_loss 0.2547939121723175, R2 0.7464315891265869\n",
      "Test Epoch7 layer0 out_loss 0.29294949769973755, R2 0.7011712789535522\n",
      "Test Epoch7 layer1 out_loss 0.2627035081386566, R2 0.7320243120193481\n",
      "Test Epoch7 layer2 out_loss 0.2581937611103058, R2 0.7366244792938232\n",
      "Test Epoch7 layer3 out_loss 0.2623809576034546, R2 0.7323532700538635\n",
      "Test Epoch7 layer4 out_loss 0.2734127640724182, R2 0.7211000919342041\n",
      "Train 8 | out_loss 0.5000433325767517: 100%|█| 258/258 [00:02<00:00, 128.76it/s]\n",
      "Train Epoch8 out_loss 0.25004324316978455, R2 0.7511594891548157\n",
      "Test Epoch8 layer0 out_loss 0.29500532150268555, R2 0.6990741491317749\n",
      "Test Epoch8 layer1 out_loss 0.2687813937664032, R2 0.7258244156837463\n",
      "Test Epoch8 layer2 out_loss 0.26839444041252136, R2 0.726219117641449\n",
      "Test Epoch8 layer3 out_loss 0.26174166798591614, R2 0.7330054044723511\n",
      "Test Epoch8 layer4 out_loss 0.26199617981910706, R2 0.7327457666397095\n",
      "Train 9 | out_loss 0.4987669885158539: 100%|█| 258/258 [00:01<00:00, 132.76it/s]\n",
      "Train Epoch9 out_loss 0.24876850843429565, R2 0.7524280548095703\n",
      "Test Epoch9 layer0 out_loss 0.28414568305015564, R2 0.7101517915725708\n",
      "Test Epoch9 layer1 out_loss 0.2502094507217407, R2 0.7447690963745117\n",
      "Test Epoch9 layer2 out_loss 0.24451696872711182, R2 0.7505757808685303\n",
      "Test Epoch9 layer3 out_loss 0.24372540414333344, R2 0.7513832449913025\n",
      "Test Epoch9 layer4 out_loss 0.2438701093196869, R2 0.7512356042861938\n",
      "Train 10 | out_loss 0.4937383532524109: 100%|█| 258/258 [00:01<00:00, 138.21it/s\n",
      "Train Epoch10 out_loss 0.2437775731086731, R2 0.7573949694633484\n",
      "Test Epoch10 layer0 out_loss 0.2801015079021454, R2 0.7142771482467651\n",
      "Test Epoch10 layer1 out_loss 0.2495459020137787, R2 0.745445966720581\n",
      "Test Epoch10 layer2 out_loss 0.24764151871204376, R2 0.7473885416984558\n",
      "Test Epoch10 layer3 out_loss 0.2523878812789917, R2 0.7425469160079956\n",
      "Test Epoch10 layer4 out_loss 0.25327423214912415, R2 0.7416428327560425\n",
      "Train 11 | out_loss 0.49159544706344604: 100%|█| 258/258 [00:02<00:00, 127.01it/\n",
      "Train Epoch11 out_loss 0.24166615307331085, R2 0.75949627161026\n",
      "Test Epoch11 layer0 out_loss 0.2930304706096649, R2 0.7010886669158936\n",
      "Test Epoch11 layer1 out_loss 0.25095781683921814, R2 0.7440056800842285\n",
      "Test Epoch11 layer2 out_loss 0.2459975779056549, R2 0.7490654587745667\n",
      "Test Epoch11 layer3 out_loss 0.24353881180286407, R2 0.7515735626220703\n",
      "Test Epoch11 layer4 out_loss 0.24221567809581757, R2 0.7529232501983643\n",
      "Train 12 | out_loss 0.4911682903766632: 100%|█| 258/258 [00:01<00:00, 136.61it/s\n",
      "Train Epoch12 out_loss 0.24124625325202942, R2 0.7599141597747803\n",
      "Test Epoch12 layer0 out_loss 0.28018632531166077, R2 0.7141906023025513\n",
      "Test Epoch12 layer1 out_loss 0.24964018166065216, R2 0.7453497648239136\n",
      "Test Epoch12 layer2 out_loss 0.2458467185497284, R2 0.7492193579673767\n",
      "Test Epoch12 layer3 out_loss 0.2487807720899582, R2 0.74622642993927\n",
      "Test Epoch12 layer4 out_loss 0.24506667256355286, R2 0.7500150203704834\n",
      "Train 13 | out_loss 0.48733311891555786: 100%|█| 258/258 [00:02<00:00, 127.51it/\n",
      "Train Epoch13 out_loss 0.2374935895204544, R2 0.7636487483978271\n",
      "Test Epoch13 layer0 out_loss 0.2887003719806671, R2 0.7055056691169739\n",
      "Test Epoch13 layer1 out_loss 0.24985690414905548, R2 0.7451286911964417\n",
      "Test Epoch13 layer2 out_loss 0.24553172290325165, R2 0.7495406866073608\n",
      "Test Epoch13 layer3 out_loss 0.2425558716058731, R2 0.7525762319564819\n",
      "Test Epoch13 layer4 out_loss 0.24101150035858154, R2 0.7541516423225403\n",
      "Train 14 | out_loss 0.48548978567123413: 100%|█| 258/258 [00:01<00:00, 145.86it/\n",
      "Train Epoch14 out_loss 0.23570038378238678, R2 0.7654333114624023\n",
      "Test Epoch14 layer0 out_loss 0.28362393379211426, R2 0.7106840014457703\n",
      "Test Epoch14 layer1 out_loss 0.2645657956600189, R2 0.7301245927810669\n",
      "Test Epoch14 layer2 out_loss 0.2575241029262543, R2 0.7373076677322388\n",
      "Test Epoch14 layer3 out_loss 0.2502448260784149, R2 0.7447329759597778\n",
      "Test Epoch14 layer4 out_loss 0.2575603723526001, R2 0.7372705936431885\n",
      "Train 15 | out_loss 0.48336783051490784: 100%|█| 258/258 [00:02<00:00, 127.45it/\n",
      "Train Epoch15 out_loss 0.23364447057247162, R2 0.7674793004989624\n",
      "Test Epoch15 layer0 out_loss 0.28499874472618103, R2 0.7092815637588501\n",
      "Test Epoch15 layer1 out_loss 0.24857811629772186, R2 0.7464331388473511\n",
      "Test Epoch15 layer2 out_loss 0.2379426807165146, R2 0.757282018661499\n",
      "Test Epoch15 layer3 out_loss 0.23997792601585388, R2 0.7552059292793274\n",
      "Test Epoch15 layer4 out_loss 0.24443256855010986, R2 0.7506619095802307\n",
      "Train 16 | out_loss 0.4799160063266754: 100%|█| 258/258 [00:01<00:00, 150.55it/s\n",
      "Train Epoch16 out_loss 0.23031942546367645, R2 0.7707884311676025\n",
      "Test Epoch16 layer0 out_loss 0.28006401658058167, R2 0.7143153548240662\n",
      "Test Epoch16 layer1 out_loss 0.23845171928405762, R2 0.7567627429962158\n",
      "Test Epoch16 layer2 out_loss 0.2348242551088333, R2 0.7604629993438721\n",
      "Test Epoch16 layer3 out_loss 0.23617757856845856, R2 0.759082555770874\n",
      "Test Epoch16 layer4 out_loss 0.23680409789085388, R2 0.7584434747695923\n",
      "Train 17 | out_loss 0.47842395305633545: 100%|█| 258/258 [00:01<00:00, 131.71it/\n",
      "Train Epoch17 out_loss 0.2288895845413208, R2 0.7722113132476807\n",
      "Test Epoch17 layer0 out_loss 0.27644112706184387, R2 0.7180109620094299\n",
      "Test Epoch17 layer1 out_loss 0.23871788382530212, R2 0.7564912438392639\n",
      "Test Epoch17 layer2 out_loss 0.234406515955925, R2 0.7608891725540161\n",
      "Test Epoch17 layer3 out_loss 0.2351609170436859, R2 0.760119616985321\n",
      "Test Epoch17 layer4 out_loss 0.23678606748580933, R2 0.7584618330001831\n",
      "Train 18 | out_loss 0.4749927222728729: 100%|█| 258/258 [00:01<00:00, 143.80it/s\n",
      "Train Epoch18 out_loss 0.2256181389093399, R2 0.7754670977592468\n",
      "Test Epoch18 layer0 out_loss 0.27654075622558594, R2 0.7179093360900879\n",
      "Test Epoch18 layer1 out_loss 0.24040062725543976, R2 0.7547747492790222\n",
      "Test Epoch18 layer2 out_loss 0.2326430082321167, R2 0.7626880407333374\n",
      "Test Epoch18 layer3 out_loss 0.23486341536045074, R2 0.7604230642318726\n",
      "Test Epoch18 layer4 out_loss 0.23263561725616455, R2 0.7626956105232239\n",
      "Train 19 | out_loss 0.47098520398139954: 100%|█| 258/258 [00:01<00:00, 142.26it/\n",
      "Train Epoch19 out_loss 0.22182705998420715, R2 0.7792398929595947\n",
      "Test Epoch19 layer0 out_loss 0.2822982370853424, R2 0.7120362520217896\n",
      "Test Epoch19 layer1 out_loss 0.2377876192331314, R2 0.7574402093887329\n",
      "Test Epoch19 layer2 out_loss 0.2320493906736374, R2 0.7632935643196106\n",
      "Test Epoch19 layer3 out_loss 0.2359222024679184, R2 0.7593430280685425\n",
      "Test Epoch19 layer4 out_loss 0.23204109072685242, R2 0.7633020877838135\n",
      "Train 20 | out_loss 0.4725321829319: 100%|███| 258/258 [00:02<00:00, 125.77it/s]\n",
      "Train Epoch20 out_loss 0.22328662872314453, R2 0.7777873277664185\n",
      "Test Epoch20 layer0 out_loss 0.2780081033706665, R2 0.7164125442504883\n",
      "Test Epoch20 layer1 out_loss 0.23431473970413208, R2 0.7609827518463135\n",
      "Test Epoch20 layer2 out_loss 0.23306240141391754, R2 0.7622602581977844\n",
      "Test Epoch20 layer3 out_loss 0.23880885541439056, R2 0.7563984394073486\n",
      "Test Epoch20 layer4 out_loss 0.2294878363609314, R2 0.765906572341919\n",
      "Train 21 | out_loss 0.46909284591674805: 100%|█| 258/258 [00:01<00:00, 138.75it/\n",
      "Train Epoch21 out_loss 0.22004805505275726, R2 0.7810103297233582\n",
      "Test Epoch21 layer0 out_loss 0.2761661112308502, R2 0.7182915210723877\n",
      "Test Epoch21 layer1 out_loss 0.23500946164131165, R2 0.7602741122245789\n",
      "Test Epoch21 layer2 out_loss 0.2296990156173706, R2 0.7656911611557007\n",
      "Test Epoch21 layer3 out_loss 0.23007497191429138, R2 0.765307605266571\n",
      "Test Epoch21 layer4 out_loss 0.2326749712228775, R2 0.7626554369926453\n",
      "Train 22 | out_loss 0.4664929211139679: 100%|█| 258/258 [00:02<00:00, 125.25it/s\n",
      "Train Epoch22 out_loss 0.21761561930179596, R2 0.7834311127662659\n",
      "Test Epoch22 layer0 out_loss 0.27397480607032776, R2 0.7205267548561096\n",
      "Test Epoch22 layer1 out_loss 0.22969749569892883, R2 0.7656927108764648\n",
      "Test Epoch22 layer2 out_loss 0.22831924259662628, R2 0.767098605632782\n",
      "Test Epoch22 layer3 out_loss 0.22641021013259888, R2 0.7690459489822388\n",
      "Test Epoch22 layer4 out_loss 0.2267027497291565, R2 0.7687475085258484\n",
      "Train 23 | out_loss 0.46402591466903687: 100%|█| 258/258 [00:01<00:00, 164.05it/\n",
      "Train Epoch23 out_loss 0.21531997621059418, R2 0.7857156991958618\n",
      "Test Epoch23 layer0 out_loss 0.27368366718292236, R2 0.7208237648010254\n",
      "Test Epoch23 layer1 out_loss 0.2327287346124649, R2 0.7626006007194519\n",
      "Test Epoch23 layer2 out_loss 0.22465991973876953, R2 0.7708313465118408\n",
      "Test Epoch23 layer3 out_loss 0.2254846692085266, R2 0.769990086555481\n",
      "Test Epoch23 layer4 out_loss 0.22875656187534332, R2 0.766652524471283\n",
      "Train 24 | out_loss 0.4626767933368683: 100%|█| 258/258 [00:02<00:00, 117.04it/s\n",
      "Train Epoch24 out_loss 0.21406979858875275, R2 0.7869598865509033\n",
      "Test Epoch24 layer0 out_loss 0.27658095955848694, R2 0.7178683280944824\n",
      "Test Epoch24 layer1 out_loss 0.2334749698638916, R2 0.7618393898010254\n",
      "Test Epoch24 layer2 out_loss 0.22997461259365082, R2 0.7654100060462952\n",
      "Test Epoch24 layer3 out_loss 0.23249481618404388, R2 0.7628391981124878\n",
      "Test Epoch24 layer4 out_loss 0.2375648468732834, R2 0.7576674222946167\n",
      "Train 25 | out_loss 0.4619655907154083: 100%|█| 258/258 [00:01<00:00, 149.71it/s\n",
      "Train Epoch25 out_loss 0.21341222524642944, R2 0.7876142859458923\n",
      "Test Epoch25 layer0 out_loss 0.2800760269165039, R2 0.7143031358718872\n",
      "Test Epoch25 layer1 out_loss 0.24207274615764618, R2 0.7530690431594849\n",
      "Test Epoch25 layer2 out_loss 0.23499348759651184, R2 0.7602903842926025\n",
      "Test Epoch25 layer3 out_loss 0.24054639041423798, R2 0.7546260356903076\n",
      "Test Epoch25 layer4 out_loss 0.23754969239234924, R2 0.7576829195022583\n",
      "Train 26 | out_loss 0.4605017304420471: 100%|█| 258/258 [00:02<00:00, 115.19it/s\n",
      "Train Epoch26 out_loss 0.212061807513237, R2 0.7889581918716431\n",
      "Test Epoch26 layer0 out_loss 0.2803751826286316, R2 0.7139979600906372\n",
      "Test Epoch26 layer1 out_loss 0.23408077657222748, R2 0.7612214088439941\n",
      "Test Epoch26 layer2 out_loss 0.22414082288742065, R2 0.7713608741760254\n",
      "Test Epoch26 layer3 out_loss 0.226457417011261, R2 0.7689977884292603\n",
      "Test Epoch26 layer4 out_loss 0.22196941077709198, R2 0.7735758423805237\n",
      "Train 27 | out_loss 0.4583613872528076: 100%|█| 258/258 [00:01<00:00, 151.73it/s\n",
      "Train Epoch27 out_loss 0.21009515225887299, R2 0.7909154295921326\n",
      "Test Epoch27 layer0 out_loss 0.28137263655662537, R2 0.7129805088043213\n",
      "Test Epoch27 layer1 out_loss 0.23389644920825958, R2 0.7614094614982605\n",
      "Test Epoch27 layer2 out_loss 0.22678416967391968, R2 0.7686644792556763\n",
      "Test Epoch27 layer3 out_loss 0.22946305572986603, R2 0.7659318447113037\n",
      "Test Epoch27 layer4 out_loss 0.2274821400642395, R2 0.7679525017738342\n",
      "Train 28 | out_loss 0.4571309983730316: 100%|█| 258/258 [00:02<00:00, 127.04it/s\n",
      "Train Epoch28 out_loss 0.20896871387958527, R2 0.7920364141464233\n",
      "Test Epoch28 layer0 out_loss 0.27544525265693665, R2 0.7190268039703369\n",
      "Test Epoch28 layer1 out_loss 0.2298608124256134, R2 0.7655260562896729\n",
      "Test Epoch28 layer2 out_loss 0.22514106333255768, R2 0.7703405618667603\n",
      "Test Epoch28 layer3 out_loss 0.22148826718330383, R2 0.774066686630249\n",
      "Test Epoch28 layer4 out_loss 0.21844616532325745, R2 0.7771698236465454\n",
      "Train 29 | out_loss 0.4553520083427429: 100%|█| 258/258 [00:01<00:00, 148.26it/s\n",
      "Train Epoch29 out_loss 0.2073454111814499, R2 0.7936519384384155\n",
      "Test Epoch29 layer0 out_loss 0.27285832166671753, R2 0.721665620803833\n",
      "Test Epoch29 layer1 out_loss 0.22685420513153076, R2 0.7685930132865906\n",
      "Test Epoch29 layer2 out_loss 0.22152049839496613, R2 0.774033784866333\n",
      "Test Epoch29 layer3 out_loss 0.22221821546554565, R2 0.7733221054077148\n",
      "Test Epoch29 layer4 out_loss 0.22421105206012726, R2 0.7712892293930054\n",
      "Train 30 | out_loss 0.4550158679485321: 100%|█| 258/258 [00:02<00:00, 128.34it/s\n",
      "Train Epoch30 out_loss 0.2070394605398178, R2 0.7939563989639282\n",
      "Test Epoch30 layer0 out_loss 0.27130234241485596, R2 0.7232528924942017\n",
      "Test Epoch30 layer1 out_loss 0.22969166934490204, R2 0.7656986117362976\n",
      "Test Epoch30 layer2 out_loss 0.22577475011348724, R2 0.7696941494941711\n",
      "Test Epoch30 layer3 out_loss 0.22518403828144073, R2 0.7702966928482056\n",
      "Test Epoch30 layer4 out_loss 0.22585627436637878, R2 0.7696110010147095\n",
      "Train 31 | out_loss 0.45400258898735046: 100%|█| 258/258 [00:01<00:00, 142.60it/\n",
      "Train Epoch31 out_loss 0.2061183750629425, R2 0.794873058795929\n",
      "Test Epoch31 layer0 out_loss 0.2695867717266083, R2 0.7250028848648071\n",
      "Test Epoch31 layer1 out_loss 0.2266639620065689, R2 0.7687870860099792\n",
      "Test Epoch31 layer2 out_loss 0.22015783190727234, R2 0.7754237651824951\n",
      "Test Epoch31 layer3 out_loss 0.21947389841079712, R2 0.7761214375495911\n",
      "Test Epoch31 layer4 out_loss 0.21997396647930145, R2 0.7756113409996033\n",
      "Train 32 | out_loss 0.45238643884658813: 100%|█| 258/258 [00:01<00:00, 142.40it/\n",
      "Train Epoch32 out_loss 0.20465345680713654, R2 0.7963309288024902\n",
      "Test Epoch32 layer0 out_loss 0.26967480778694153, R2 0.7249130606651306\n",
      "Test Epoch32 layer1 out_loss 0.224660262465477, R2 0.7708309888839722\n",
      "Test Epoch32 layer2 out_loss 0.22207032144069672, R2 0.7734729051589966\n",
      "Test Epoch32 layer3 out_loss 0.220250204205513, R2 0.77532958984375\n",
      "Test Epoch32 layer4 out_loss 0.22424983978271484, R2 0.7712496519088745\n",
      "Train 33 | out_loss 0.45413005352020264: 100%|█| 258/258 [00:01<00:00, 132.54it/\n",
      "Train Epoch33 out_loss 0.2062341868877411, R2 0.7947577834129333\n",
      "Test Epoch33 layer0 out_loss 0.27094393968582153, R2 0.7236185073852539\n",
      "Test Epoch33 layer1 out_loss 0.2297896146774292, R2 0.765598714351654\n",
      "Test Epoch33 layer2 out_loss 0.22469806671142578, R2 0.7707924246788025\n",
      "Test Epoch33 layer3 out_loss 0.2221774309873581, R2 0.7733636498451233\n",
      "Test Epoch33 layer4 out_loss 0.22446821630001068, R2 0.7710269093513489\n",
      "Train 34 | out_loss 0.4542839825153351: 100%|█| 258/258 [00:01<00:00, 154.51it/s\n",
      "Train Epoch34 out_loss 0.2063738852739334, R2 0.7946187257766724\n",
      "Test Epoch34 layer0 out_loss 0.26442286372184753, R2 0.7302703857421875\n",
      "Test Epoch34 layer1 out_loss 0.22638510167598724, R2 0.7690715789794922\n",
      "Test Epoch34 layer2 out_loss 0.22381789982318878, R2 0.7716902494430542\n",
      "Test Epoch34 layer3 out_loss 0.22198638319969177, R2 0.7735585570335388\n",
      "Test Epoch34 layer4 out_loss 0.24069982767105103, R2 0.7544695138931274\n",
      "Train 35 | out_loss 0.45241779088974: 100%|██| 258/258 [00:02<00:00, 122.35it/s]\n",
      "Train Epoch35 out_loss 0.204681858420372, R2 0.7963026762008667\n",
      "Test Epoch35 layer0 out_loss 0.26937729120254517, R2 0.7252165079116821\n",
      "Test Epoch35 layer1 out_loss 0.22460228204727173, R2 0.7708901762962341\n",
      "Test Epoch35 layer2 out_loss 0.21578796207904816, R2 0.7798813581466675\n",
      "Test Epoch35 layer3 out_loss 0.2199351042509079, R2 0.7756509780883789\n",
      "Test Epoch35 layer4 out_loss 0.22750674188137054, R2 0.7679274082183838\n",
      "Train 36 | out_loss 0.4518493413925171: 100%|█| 258/258 [00:01<00:00, 167.51it/s\n",
      "Train Epoch36 out_loss 0.20416778326034546, R2 0.7968142628669739\n",
      "Test Epoch36 layer0 out_loss 0.27131858468055725, R2 0.7232363224029541\n",
      "Test Epoch36 layer1 out_loss 0.22336941957473755, R2 0.7721477746963501\n",
      "Test Epoch36 layer2 out_loss 0.22083275020122528, R2 0.7747353315353394\n",
      "Test Epoch36 layer3 out_loss 0.22190238535404205, R2 0.773644208908081\n",
      "Test Epoch36 layer4 out_loss 0.2206829935312271, R2 0.7748880982398987\n",
      "Train 37 | out_loss 0.4502555727958679: 100%|█| 258/258 [00:02<00:00, 112.18it/s\n",
      "Train Epoch37 out_loss 0.20273004472255707, R2 0.7982450723648071\n",
      "Test Epoch37 layer0 out_loss 0.26521873474121094, R2 0.7294585704803467\n",
      "Test Epoch37 layer1 out_loss 0.22741849720478058, R2 0.7680174112319946\n",
      "Test Epoch37 layer2 out_loss 0.2238408327102661, R2 0.7716668844223022\n",
      "Test Epoch37 layer3 out_loss 0.22304509580135345, R2 0.7724785804748535\n",
      "Test Epoch37 layer4 out_loss 0.2228996455669403, R2 0.7726269364356995\n",
      "Train 38 | out_loss 0.45140400528907776: 100%|█| 258/258 [00:01<00:00, 167.77it/\n",
      "Train Epoch38 out_loss 0.2037656009197235, R2 0.7972145080566406\n",
      "Test Epoch38 layer0 out_loss 0.27279651165008545, R2 0.7217286825180054\n",
      "Test Epoch38 layer1 out_loss 0.22636523842811584, R2 0.7690918445587158\n",
      "Test Epoch38 layer2 out_loss 0.22266890108585358, R2 0.7728623151779175\n",
      "Test Epoch38 layer3 out_loss 0.2272387593984604, R2 0.7682007551193237\n",
      "Test Epoch38 layer4 out_loss 0.22882823646068573, R2 0.7665793895721436\n",
      "Train 39 | out_loss 0.4507881700992584: 100%|█| 258/258 [00:02<00:00, 114.09it/s\n",
      "Train Epoch39 out_loss 0.20321007072925568, R2 0.7977674007415771\n",
      "Test Epoch39 layer0 out_loss 0.2643539309501648, R2 0.7303407192230225\n",
      "Test Epoch39 layer1 out_loss 0.22131766378879547, R2 0.7742406725883484\n",
      "Test Epoch39 layer2 out_loss 0.2184402197599411, R2 0.7771759033203125\n",
      "Test Epoch39 layer3 out_loss 0.21922944486141205, R2 0.7763708233833313\n",
      "Test Epoch39 layer4 out_loss 0.2215886265039444, R2 0.7739642858505249\n",
      "Train 40 | out_loss 0.44846758246421814: 100%|█| 258/258 [00:01<00:00, 158.63it/\n",
      "Train Epoch40 out_loss 0.2011231780052185, R2 0.7998442053794861\n",
      "Test Epoch40 layer0 out_loss 0.2663147747516632, R2 0.7283405065536499\n",
      "Test Epoch40 layer1 out_loss 0.23020005226135254, R2 0.7651800513267517\n",
      "Test Epoch40 layer2 out_loss 0.22395791113376617, R2 0.7715474367141724\n",
      "Test Epoch40 layer3 out_loss 0.22303417325019836, R2 0.7724897265434265\n",
      "Test Epoch40 layer4 out_loss 0.22413285076618195, R2 0.7713689804077148\n",
      "Train 41 | out_loss 0.44787317514419556: 100%|█| 258/258 [00:02<00:00, 127.85it/\n",
      "Train Epoch41 out_loss 0.20059038698673248, R2 0.800374448299408\n",
      "Test Epoch41 layer0 out_loss 0.2594302296638489, R2 0.735363245010376\n",
      "Test Epoch41 layer1 out_loss 0.21928200125694275, R2 0.7763172388076782\n",
      "Test Epoch41 layer2 out_loss 0.21800634264945984, R2 0.7776184678077698\n",
      "Test Epoch41 layer3 out_loss 0.22263725101947784, R2 0.7728946208953857\n",
      "Test Epoch41 layer4 out_loss 0.21616069972515106, R2 0.7795011401176453\n",
      "Train 42 | out_loss 0.4470919370651245: 100%|█| 258/258 [00:01<00:00, 165.47it/s\n",
      "Train Epoch42 out_loss 0.19989119470119476, R2 0.8010702729225159\n",
      "Test Epoch42 layer0 out_loss 0.26541388034820557, R2 0.7292594909667969\n",
      "Test Epoch42 layer1 out_loss 0.22214411199092865, R2 0.77339768409729\n",
      "Test Epoch42 layer2 out_loss 0.21499769389629364, R2 0.7806875109672546\n",
      "Test Epoch42 layer3 out_loss 0.21460580825805664, R2 0.7810872793197632\n",
      "Test Epoch42 layer4 out_loss 0.21356792747974396, R2 0.7821459770202637\n",
      "Train 43 | out_loss 0.4474868178367615: 100%|█| 258/258 [00:01<00:00, 142.17it/s\n",
      "Train Epoch43 out_loss 0.20024442672729492, R2 0.8007187247276306\n",
      "Test Epoch43 layer0 out_loss 0.26375412940979004, R2 0.7309525609016418\n",
      "Test Epoch43 layer1 out_loss 0.22177718579769135, R2 0.7737719416618347\n",
      "Test Epoch43 layer2 out_loss 0.22134248912334442, R2 0.7742153406143188\n",
      "Test Epoch43 layer3 out_loss 0.22676075994968414, R2 0.7686883211135864\n",
      "Test Epoch43 layer4 out_loss 0.22152739763259888, R2 0.7740267515182495\n",
      "Train 44 | out_loss 0.4461934566497803: 100%|█| 258/258 [00:01<00:00, 147.99it/s\n",
      "Train Epoch44 out_loss 0.19908863306045532, R2 0.8018689751625061\n",
      "Test Epoch44 layer0 out_loss 0.26308774948120117, R2 0.7316323518753052\n",
      "Test Epoch44 layer1 out_loss 0.22384484112262726, R2 0.7716628313064575\n",
      "Test Epoch44 layer2 out_loss 0.216161847114563, R2 0.7795000076293945\n",
      "Test Epoch44 layer3 out_loss 0.2132839858531952, R2 0.7824355959892273\n",
      "Test Epoch44 layer4 out_loss 0.2170862853527069, R2 0.7785570025444031\n",
      "Train 45 | out_loss 0.44660109281539917: 100%|█| 258/258 [00:01<00:00, 160.84it/\n",
      "Train Epoch45 out_loss 0.19945263862609863, R2 0.801506757736206\n",
      "Test Epoch45 layer0 out_loss 0.2582723796367645, R2 0.7365443110466003\n",
      "Test Epoch45 layer1 out_loss 0.21975652873516083, R2 0.7758331298828125\n",
      "Test Epoch45 layer2 out_loss 0.21550676226615906, R2 0.7801681756973267\n",
      "Test Epoch45 layer3 out_loss 0.21478328108787537, R2 0.7809062004089355\n",
      "Test Epoch45 layer4 out_loss 0.21278075873851776, R2 0.782948911190033\n",
      "Train 46 | out_loss 0.4445396661758423: 100%|█| 258/258 [00:01<00:00, 135.92it/s\n",
      "Train Epoch46 out_loss 0.19761556386947632, R2 0.8033349514007568\n",
      "Test Epoch46 layer0 out_loss 0.27477744221687317, R2 0.7197080254554749\n",
      "Test Epoch46 layer1 out_loss 0.2288719266653061, R2 0.7665348052978516\n",
      "Test Epoch46 layer2 out_loss 0.22293047606945038, R2 0.7725955247879028\n",
      "Test Epoch46 layer3 out_loss 0.22577933967113495, R2 0.7696894407272339\n",
      "Test Epoch46 layer4 out_loss 0.2263680398464203, R2 0.7690889835357666\n",
      "Train 47 | out_loss 0.4438481032848358: 100%|█| 258/258 [00:01<00:00, 178.77it/s\n",
      "Train Epoch47 out_loss 0.1970011442899704, R2 0.8039464354515076\n",
      "Test Epoch47 layer0 out_loss 0.26406344771385193, R2 0.7306370139122009\n",
      "Test Epoch47 layer1 out_loss 0.21991708874702454, R2 0.7756693363189697\n",
      "Test Epoch47 layer2 out_loss 0.21221303939819336, R2 0.7835280299186707\n",
      "Test Epoch47 layer3 out_loss 0.2109864056110382, R2 0.7847793102264404\n",
      "Test Epoch47 layer4 out_loss 0.21185044944286346, R2 0.783897876739502\n",
      "Train 48 | out_loss 0.44407716393470764: 100%|█| 258/258 [00:02<00:00, 116.56it/\n",
      "Train Epoch48 out_loss 0.19720453023910522, R2 0.8037440180778503\n",
      "Test Epoch48 layer0 out_loss 0.2758488357067108, R2 0.7186151146888733\n",
      "Test Epoch48 layer1 out_loss 0.22938290238380432, R2 0.7660135626792908\n",
      "Test Epoch48 layer2 out_loss 0.22978080809116364, R2 0.7656077146530151\n",
      "Test Epoch48 layer3 out_loss 0.23384308815002441, R2 0.7614638805389404\n",
      "Test Epoch48 layer4 out_loss 0.22496837377548218, R2 0.7705167531967163\n",
      "Train 49 | out_loss 0.4431793689727783: 100%|█| 258/258 [00:01<00:00, 188.70it/s\n",
      "Train Epoch49 out_loss 0.19640782475471497, R2 0.8045368790626526\n",
      "Test Epoch49 layer0 out_loss 0.255877822637558, R2 0.7389869689941406\n",
      "Test Epoch49 layer1 out_loss 0.2158806324005127, R2 0.7797868251800537\n",
      "Test Epoch49 layer2 out_loss 0.2100290060043335, R2 0.7857558727264404\n",
      "Test Epoch49 layer3 out_loss 0.2111322283744812, R2 0.784630537033081\n",
      "Test Epoch49 layer4 out_loss 0.2148357331752777, R2 0.7808526754379272\n",
      "Train 50 | out_loss 0.442859947681427: 100%|█| 258/258 [00:02<00:00, 125.26it/s]\n",
      "Train Epoch50 out_loss 0.19612492620944977, R2 0.8048183917999268\n",
      "Test Epoch50 layer0 out_loss 0.26392075419425964, R2 0.7307826280593872\n",
      "Test Epoch50 layer1 out_loss 0.22674565017223358, R2 0.7687037587165833\n",
      "Test Epoch50 layer2 out_loss 0.2181796282529831, R2 0.777441680431366\n",
      "Test Epoch50 layer3 out_loss 0.21735039353370667, R2 0.7782875895500183\n",
      "Test Epoch50 layer4 out_loss 0.21498481929302216, R2 0.7807006239891052\n",
      "Train 51 | out_loss 0.4419902563095093: 100%|█| 258/258 [00:01<00:00, 152.16it/s\n",
      "Train Epoch51 out_loss 0.19535546004772186, R2 0.805584192276001\n",
      "Test Epoch51 layer0 out_loss 0.26297733187675476, R2 0.7317449450492859\n",
      "Test Epoch51 layer1 out_loss 0.22050562500953674, R2 0.775068998336792\n",
      "Test Epoch51 layer2 out_loss 0.21709156036376953, R2 0.7785515785217285\n",
      "Test Epoch51 layer3 out_loss 0.22365088760852814, R2 0.771860659122467\n",
      "Test Epoch51 layer4 out_loss 0.21893319487571716, R2 0.7766730189323425\n",
      "Train 52 | out_loss 0.44323334097862244: 100%|█| 258/258 [00:02<00:00, 128.36it/\n",
      "Train Epoch52 out_loss 0.19645588099956512, R2 0.8044890761375427\n",
      "Test Epoch52 layer0 out_loss 0.26277801394462585, R2 0.7319482564926147\n",
      "Test Epoch52 layer1 out_loss 0.217582106590271, R2 0.7780511975288391\n",
      "Test Epoch52 layer2 out_loss 0.2114916741847992, R2 0.7842638492584229\n",
      "Test Epoch52 layer3 out_loss 0.2096654772758484, R2 0.7861267328262329\n",
      "Test Epoch52 layer4 out_loss 0.2112847864627838, R2 0.7844749093055725\n",
      "Train 53 | out_loss 0.4422747790813446: 100%|█| 258/258 [00:01<00:00, 136.84it/s\n",
      "Train Epoch53 out_loss 0.19560687243938446, R2 0.8053339719772339\n",
      "Test Epoch53 layer0 out_loss 0.2592025101184845, R2 0.7355955839157104\n",
      "Test Epoch53 layer1 out_loss 0.22010298073291779, R2 0.7754797339439392\n",
      "Test Epoch53 layer2 out_loss 0.2144552320241928, R2 0.7812408208847046\n",
      "Test Epoch53 layer3 out_loss 0.2150566130876541, R2 0.7806273698806763\n",
      "Test Epoch53 layer4 out_loss 0.21514712274074554, R2 0.780535101890564\n",
      "Train 54 | out_loss 0.4420245885848999: 100%|█| 258/258 [00:02<00:00, 128.68it/s\n",
      "Train Epoch54 out_loss 0.19538576900959015, R2 0.8055540323257446\n",
      "Test Epoch54 layer0 out_loss 0.2635974586009979, R2 0.7311123609542847\n",
      "Test Epoch54 layer1 out_loss 0.2182786613702774, R2 0.7773406505584717\n",
      "Test Epoch54 layer2 out_loss 0.21136002242565155, R2 0.7843981981277466\n",
      "Test Epoch54 layer3 out_loss 0.21233803033828735, R2 0.7834005355834961\n",
      "Test Epoch54 layer4 out_loss 0.21168647706508636, R2 0.7840651273727417\n",
      "Train 55 | out_loss 0.4414624273777008: 100%|█| 258/258 [00:02<00:00, 128.78it/s\n",
      "Train Epoch55 out_loss 0.19488906860351562, R2 0.8060483336448669\n",
      "Test Epoch55 layer0 out_loss 0.25863879919052124, R2 0.7361705303192139\n",
      "Test Epoch55 layer1 out_loss 0.21878764033317566, R2 0.776821494102478\n",
      "Test Epoch55 layer2 out_loss 0.21130089461803436, R2 0.7844584584236145\n",
      "Test Epoch55 layer3 out_loss 0.2107643485069275, R2 0.7850058078765869\n",
      "Test Epoch55 layer4 out_loss 0.21226997673511505, R2 0.7834699153900146\n",
      "Train 56 | out_loss 0.440743088722229: 100%|█| 258/258 [00:01<00:00, 142.76it/s]\n",
      "Train Epoch56 out_loss 0.19425451755523682, R2 0.8066798448562622\n",
      "Test Epoch56 layer0 out_loss 0.2553277015686035, R2 0.7395480871200562\n",
      "Test Epoch56 layer1 out_loss 0.2171737551689148, R2 0.7784677743911743\n",
      "Test Epoch56 layer2 out_loss 0.21144790947437286, R2 0.7843084931373596\n",
      "Test Epoch56 layer3 out_loss 0.21199236810207367, R2 0.7837531566619873\n",
      "Test Epoch56 layer4 out_loss 0.21372397243976593, R2 0.7819867730140686\n",
      "Train 57 | out_loss 0.44089066982269287: 100%|█| 258/258 [00:01<00:00, 135.73it/\n",
      "Train Epoch57 out_loss 0.19438457489013672, R2 0.8065503835678101\n",
      "Test Epoch57 layer0 out_loss 0.25883176922798157, R2 0.7359737157821655\n",
      "Test Epoch57 layer1 out_loss 0.21823996305465698, R2 0.7773801684379578\n",
      "Test Epoch57 layer2 out_loss 0.21116934716701508, R2 0.7845926880836487\n",
      "Test Epoch57 layer3 out_loss 0.21028666198253632, R2 0.7854930758476257\n",
      "Test Epoch57 layer4 out_loss 0.21006911993026733, R2 0.7857149839401245\n",
      "Train 58 | out_loss 0.43902891874313354: 100%|█| 258/258 [00:01<00:00, 148.95it/\n",
      "Train Epoch58 out_loss 0.1927463859319687, R2 0.8081806898117065\n",
      "Test Epoch58 layer0 out_loss 0.2517261505126953, R2 0.7432218790054321\n",
      "Test Epoch58 layer1 out_loss 0.21506556868553162, R2 0.7806182503700256\n",
      "Test Epoch58 layer2 out_loss 0.2094588577747345, R2 0.7863374948501587\n",
      "Test Epoch58 layer3 out_loss 0.2109713852405548, R2 0.7847945690155029\n",
      "Test Epoch58 layer4 out_loss 0.21022941172122955, R2 0.7855514883995056\n",
      "Train 59 | out_loss 0.4382430613040924: 100%|█| 258/258 [00:02<00:00, 115.06it/s\n",
      "Train Epoch59 out_loss 0.19205699861049652, R2 0.8088667988777161\n",
      "Test Epoch59 layer0 out_loss 0.25645875930786133, R2 0.7383943796157837\n",
      "Test Epoch59 layer1 out_loss 0.22166825830936432, R2 0.773883044719696\n",
      "Test Epoch59 layer2 out_loss 0.21129226684570312, R2 0.7844672799110413\n",
      "Test Epoch59 layer3 out_loss 0.21178410947322845, R2 0.7839655876159668\n",
      "Test Epoch59 layer4 out_loss 0.2150488942861557, R2 0.7806352376937866\n",
      "Train 60 | out_loss 0.4383799433708191: 100%|█| 258/258 [00:01<00:00, 154.76it/s\n",
      "Train Epoch60 out_loss 0.1921769380569458, R2 0.808747410774231\n",
      "Test Epoch60 layer0 out_loss 0.25650882720947266, R2 0.7383432388305664\n",
      "Test Epoch60 layer1 out_loss 0.2145518958568573, R2 0.7811422348022461\n",
      "Test Epoch60 layer2 out_loss 0.20924070477485657, R2 0.78656005859375\n",
      "Test Epoch60 layer3 out_loss 0.21022078394889832, R2 0.7855602502822876\n",
      "Test Epoch60 layer4 out_loss 0.2100220024585724, R2 0.7857630252838135\n",
      "Train 61 | out_loss 0.4385177195072174: 100%|█| 258/258 [00:02<00:00, 125.71it/s\n",
      "Train Epoch61 out_loss 0.1922978013753891, R2 0.8086271286010742\n",
      "Test Epoch61 layer0 out_loss 0.26124411821365356, R2 0.7335129380226135\n",
      "Test Epoch61 layer1 out_loss 0.21994569897651672, R2 0.7756401896476746\n",
      "Test Epoch61 layer2 out_loss 0.2147102802991867, R2 0.7809807062149048\n",
      "Test Epoch61 layer3 out_loss 0.21241024136543274, R2 0.7833268642425537\n",
      "Test Epoch61 layer4 out_loss 0.21697208285331726, R2 0.7786734700202942\n",
      "Train 62 | out_loss 0.43965351581573486: 100%|█| 258/258 [00:01<00:00, 142.09it/\n",
      "Train Epoch62 out_loss 0.1932951956987381, R2 0.8076345920562744\n",
      "Test Epoch62 layer0 out_loss 0.26476767659187317, R2 0.7299187183380127\n",
      "Test Epoch62 layer1 out_loss 0.21678632497787476, R2 0.7788629531860352\n",
      "Test Epoch62 layer2 out_loss 0.20872612297534943, R2 0.7870849370956421\n",
      "Test Epoch62 layer3 out_loss 0.20967747271060944, R2 0.786114513874054\n",
      "Test Epoch62 layer4 out_loss 0.21115925908088684, R2 0.7846029996871948\n",
      "Train 63 | out_loss 0.4377685785293579: 100%|█| 258/258 [00:02<00:00, 127.62it/s\n",
      "Train Epoch63 out_loss 0.19164127111434937, R2 0.809280514717102\n",
      "Test Epoch63 layer0 out_loss 0.2562294006347656, R2 0.7386282682418823\n",
      "Test Epoch63 layer1 out_loss 0.218735009431839, R2 0.7768751978874207\n",
      "Test Epoch63 layer2 out_loss 0.20843230187892914, R2 0.7873846292495728\n",
      "Test Epoch63 layer3 out_loss 0.20955516397953033, R2 0.7862392663955688\n",
      "Test Epoch63 layer4 out_loss 0.20872299373149872, R2 0.78708815574646\n",
      "Train 64 | out_loss 0.4375323951244354: 100%|█| 258/258 [00:01<00:00, 145.00it/s\n",
      "Train Epoch64 out_loss 0.1914345920085907, R2 0.8094861507415771\n",
      "Test Epoch64 layer0 out_loss 0.25359389185905457, R2 0.7413166761398315\n",
      "Test Epoch64 layer1 out_loss 0.21716642379760742, R2 0.7784752249717712\n",
      "Test Epoch64 layer2 out_loss 0.21117794513702393, R2 0.7845839262008667\n",
      "Test Epoch64 layer3 out_loss 0.21260592341423035, R2 0.7831272482872009\n",
      "Test Epoch64 layer4 out_loss 0.2227052003145218, R2 0.772825300693512\n",
      "Train 65 | out_loss 0.43858715891838074: 100%|█| 258/258 [00:01<00:00, 129.85it/\n",
      "Train Epoch65 out_loss 0.19235871732234955, R2 0.8085665702819824\n",
      "Test Epoch65 layer0 out_loss 0.2562944293022156, R2 0.7385619878768921\n",
      "Test Epoch65 layer1 out_loss 0.220549076795578, R2 0.7750247120857239\n",
      "Test Epoch65 layer2 out_loss 0.21257485449314117, R2 0.7831589579582214\n",
      "Test Epoch65 layer3 out_loss 0.21128959953784943, R2 0.7844700217247009\n",
      "Test Epoch65 layer4 out_loss 0.21367458999156952, R2 0.7820371389389038\n",
      "Train 66 | out_loss 0.43666064739227295: 100%|█| 258/258 [00:01<00:00, 141.46it/\n",
      "Train Epoch66 out_loss 0.19067248702049255, R2 0.8102446794509888\n",
      "Test Epoch66 layer0 out_loss 0.2616531550884247, R2 0.7330957055091858\n",
      "Test Epoch66 layer1 out_loss 0.2184716910123825, R2 0.7771437764167786\n",
      "Test Epoch66 layer2 out_loss 0.20859065651893616, R2 0.7872231006622314\n",
      "Test Epoch66 layer3 out_loss 0.20945316553115845, R2 0.7863432765007019\n",
      "Test Epoch66 layer4 out_loss 0.2170833945274353, R2 0.7785599231719971\n",
      "Train 67 | out_loss 0.43680235743522644: 100%|█| 258/258 [00:01<00:00, 146.84it/\n",
      "Train Epoch67 out_loss 0.19079624116420746, R2 0.810121476650238\n",
      "Test Epoch67 layer0 out_loss 0.2652028501033783, R2 0.7294747829437256\n",
      "Test Epoch67 layer1 out_loss 0.2231728434562683, R2 0.7723482847213745\n",
      "Test Epoch67 layer2 out_loss 0.2205255776643753, R2 0.7750486731529236\n",
      "Test Epoch67 layer3 out_loss 0.2213321328163147, R2 0.7742259502410889\n",
      "Test Epoch67 layer4 out_loss 0.22365351021289825, R2 0.7718579769134521\n",
      "Train 68 | out_loss 0.43614399433135986: 100%|█| 258/258 [00:02<00:00, 124.24it/\n",
      "Train Epoch68 out_loss 0.19022157788276672, R2 0.8106933832168579\n",
      "Test Epoch68 layer0 out_loss 0.2694443166255951, R2 0.7251482009887695\n",
      "Test Epoch68 layer1 out_loss 0.2230578064918518, R2 0.7724655866622925\n",
      "Test Epoch68 layer2 out_loss 0.20856334269046783, R2 0.7872509956359863\n",
      "Test Epoch68 layer3 out_loss 0.20864763855934143, R2 0.7871649861335754\n",
      "Test Epoch68 layer4 out_loss 0.20850351452827454, R2 0.7873120307922363\n",
      "Train 69 | out_loss 0.4349885880947113: 100%|█| 258/258 [00:01<00:00, 144.66it/s\n",
      "Train Epoch69 out_loss 0.1892150193452835, R2 0.8116950988769531\n",
      "Test Epoch69 layer0 out_loss 0.2814725637435913, R2 0.7128785848617554\n",
      "Test Epoch69 layer1 out_loss 0.22198621928691864, R2 0.7735587358474731\n",
      "Test Epoch69 layer2 out_loss 0.20976121723651886, R2 0.7860291004180908\n",
      "Test Epoch69 layer3 out_loss 0.20944122970104218, R2 0.7863554954528809\n",
      "Test Epoch69 layer4 out_loss 0.2091132402420044, R2 0.7866900563240051\n",
      "Train 70 | out_loss 0.43467089533805847: 100%|█| 258/258 [00:01<00:00, 130.79it/\n",
      "Train Epoch70 out_loss 0.18893879652023315, R2 0.8119699954986572\n",
      "Test Epoch70 layer0 out_loss 0.2524838149547577, R2 0.7424490451812744\n",
      "Test Epoch70 layer1 out_loss 0.2182733416557312, R2 0.777346134185791\n",
      "Test Epoch70 layer2 out_loss 0.20902720093727112, R2 0.7867778539657593\n",
      "Test Epoch70 layer3 out_loss 0.21055205166339874, R2 0.7852223515510559\n",
      "Test Epoch70 layer4 out_loss 0.2129310667514801, R2 0.7827956080436707\n",
      "Train 71 | out_loss 0.43614083528518677: 100%|█| 258/258 [00:01<00:00, 140.97it/\n",
      "Train Epoch71 out_loss 0.1902187317609787, R2 0.8106961846351624\n",
      "Test Epoch71 layer0 out_loss 0.262159526348114, R2 0.7325791120529175\n",
      "Test Epoch71 layer1 out_loss 0.22379839420318604, R2 0.7717101573944092\n",
      "Test Epoch71 layer2 out_loss 0.21635785698890686, R2 0.7793000340461731\n",
      "Test Epoch71 layer3 out_loss 0.21531492471694946, R2 0.780363917350769\n",
      "Test Epoch71 layer4 out_loss 0.2146802842617035, R2 0.7810112833976746\n",
      "Train 72 | out_loss 0.43422266840934753: 100%|█| 258/258 [00:01<00:00, 137.46it/\n",
      "Train Epoch72 out_loss 0.18854930996894836, R2 0.8123576045036316\n",
      "Test Epoch72 layer0 out_loss 0.2603551149368286, R2 0.7344197630882263\n",
      "Test Epoch72 layer1 out_loss 0.21831004321575165, R2 0.7773087024688721\n",
      "Test Epoch72 layer2 out_loss 0.21083344519138336, R2 0.7849353551864624\n",
      "Test Epoch72 layer3 out_loss 0.20835857093334198, R2 0.7874598503112793\n",
      "Test Epoch72 layer4 out_loss 0.2071298509836197, R2 0.7887132167816162\n",
      "Train 73 | out_loss 0.43505048751831055: 100%|█| 258/258 [00:01<00:00, 138.94it/\n",
      "Train Epoch73 out_loss 0.18926885724067688, R2 0.8116415143013\n",
      "Test Epoch73 layer0 out_loss 0.2610083520412445, R2 0.7337534427642822\n",
      "Test Epoch73 layer1 out_loss 0.21802470088005066, R2 0.7775997519493103\n",
      "Test Epoch73 layer2 out_loss 0.20790742337703705, R2 0.7879200577735901\n",
      "Test Epoch73 layer3 out_loss 0.20846791565418243, R2 0.7873483300209045\n",
      "Test Epoch73 layer4 out_loss 0.2075822949409485, R2 0.7882516980171204\n",
      "Train 74 | out_loss 0.43438437581062317: 100%|█| 258/258 [00:01<00:00, 130.26it/\n",
      "Train Epoch74 out_loss 0.18868979811668396, R2 0.8122178316116333\n",
      "Test Epoch74 layer0 out_loss 0.25961437821388245, R2 0.735175371170044\n",
      "Test Epoch74 layer1 out_loss 0.21949873864650726, R2 0.7760961055755615\n",
      "Test Epoch74 layer2 out_loss 0.21323373913764954, R2 0.7824868559837341\n",
      "Test Epoch74 layer3 out_loss 0.21590901911258698, R2 0.7797578573226929\n",
      "Test Epoch74 layer4 out_loss 0.2188618928194046, R2 0.7767457365989685\n",
      "Train 75 | out_loss 0.4345245659351349: 100%|█| 258/258 [00:01<00:00, 134.63it/s\n",
      "Train Epoch75 out_loss 0.18881158530712128, R2 0.8120965957641602\n",
      "Test Epoch75 layer0 out_loss 0.2634908854961395, R2 0.731221079826355\n",
      "Test Epoch75 layer1 out_loss 0.22081786394119263, R2 0.7747505307197571\n",
      "Test Epoch75 layer2 out_loss 0.2130448818206787, R2 0.7826794981956482\n",
      "Test Epoch75 layer3 out_loss 0.20840348303318024, R2 0.7874140739440918\n",
      "Test Epoch75 layer4 out_loss 0.209764763712883, R2 0.7860254645347595\n",
      "Train 76 | out_loss 0.43364790081977844: 100%|█| 258/258 [00:01<00:00, 138.87it/\n",
      "Train Epoch76 out_loss 0.1880505234003067, R2 0.812853991985321\n",
      "Test Epoch76 layer0 out_loss 0.2491251677274704, R2 0.7458751201629639\n",
      "Test Epoch76 layer1 out_loss 0.21351715922355652, R2 0.7821977138519287\n",
      "Test Epoch76 layer2 out_loss 0.2052905410528183, R2 0.790589451789856\n",
      "Test Epoch76 layer3 out_loss 0.20474770665168762, R2 0.7911431789398193\n",
      "Test Epoch76 layer4 out_loss 0.20495091378688812, R2 0.7909358739852905\n",
      "Train 77 | out_loss 0.43269091844558716: 100%|█| 258/258 [00:01<00:00, 132.78it/\n",
      "Train Epoch77 out_loss 0.1872214376926422, R2 0.8136790990829468\n",
      "Test Epoch77 layer0 out_loss 0.259894996881485, R2 0.7348891496658325\n",
      "Test Epoch77 layer1 out_loss 0.22776705026626587, R2 0.7676618695259094\n",
      "Test Epoch77 layer2 out_loss 0.2154490202665329, R2 0.7802271246910095\n",
      "Test Epoch77 layer3 out_loss 0.21897578239440918, R2 0.7766295671463013\n",
      "Test Epoch77 layer4 out_loss 0.21962852776050568, R2 0.7759637236595154\n",
      "Train 78 | out_loss 0.43401870131492615: 100%|█| 258/258 [00:01<00:00, 141.38it/\n",
      "Train Epoch78 out_loss 0.18837228417396545, R2 0.8125337362289429\n",
      "Test Epoch78 layer0 out_loss 0.2572961747646332, R2 0.7375401258468628\n",
      "Test Epoch78 layer1 out_loss 0.21730023622512817, R2 0.7783387303352356\n",
      "Test Epoch78 layer2 out_loss 0.2129768431186676, R2 0.7827489376068115\n",
      "Test Epoch78 layer3 out_loss 0.2108464390039444, R2 0.7849220633506775\n",
      "Test Epoch78 layer4 out_loss 0.2106015533208847, R2 0.7851718664169312\n",
      "Train 79 | out_loss 0.4432675540447235: 100%|█| 258/258 [00:01<00:00, 129.08it/s\n",
      "Train Epoch79 out_loss 0.19648604094982147, R2 0.8044590950012207\n",
      "Test Epoch79 layer0 out_loss 0.2505992650985718, R2 0.7443714141845703\n",
      "Test Epoch79 layer1 out_loss 0.2129615694284439, R2 0.7827644944190979\n",
      "Test Epoch79 layer2 out_loss 0.20487961173057556, R2 0.7910086512565613\n",
      "Test Epoch79 layer3 out_loss 0.20538248121738434, R2 0.7904956340789795\n",
      "Test Epoch79 layer4 out_loss 0.20582541823387146, R2 0.790043830871582\n",
      "Train 80 | out_loss 0.43706658482551575: 100%|█| 258/258 [00:01<00:00, 136.55it/\n",
      "Train Epoch80 out_loss 0.1910272091627121, R2 0.8098916411399841\n",
      "Test Epoch80 layer0 out_loss 0.24778896570205688, R2 0.7472381591796875\n",
      "Test Epoch80 layer1 out_loss 0.21342886984348297, R2 0.7822878360748291\n",
      "Test Epoch80 layer2 out_loss 0.20721803605556488, R2 0.7886232733726501\n",
      "Test Epoch80 layer3 out_loss 0.20600487291812897, R2 0.7898607850074768\n",
      "Test Epoch80 layer4 out_loss 0.20588362216949463, R2 0.7899844646453857\n",
      "Train 81 | out_loss 0.43427783250808716: 100%|█| 258/258 [00:01<00:00, 133.84it/\n",
      "Train Epoch81 out_loss 0.18859721720218658, R2 0.8123099207878113\n",
      "Test Epoch81 layer0 out_loss 0.24696677923202515, R2 0.7480767965316772\n",
      "Test Epoch81 layer1 out_loss 0.2140335887670517, R2 0.7816709280014038\n",
      "Test Epoch81 layer2 out_loss 0.20760877430438995, R2 0.7882246971130371\n",
      "Test Epoch81 layer3 out_loss 0.20727023482322693, R2 0.7885700464248657\n",
      "Test Epoch81 layer4 out_loss 0.20816969871520996, R2 0.7876524925231934\n",
      "Train 82 | out_loss 0.4337790906429291: 100%|█| 258/258 [00:01<00:00, 130.43it/s\n",
      "Train Epoch82 out_loss 0.18816432356834412, R2 0.8127407431602478\n",
      "Test Epoch82 layer0 out_loss 0.2577284574508667, R2 0.7370991706848145\n",
      "Test Epoch82 layer1 out_loss 0.22211723029613495, R2 0.7734251022338867\n",
      "Test Epoch82 layer2 out_loss 0.21173638105392456, R2 0.7840142250061035\n",
      "Test Epoch82 layer3 out_loss 0.2134413868188858, R2 0.7822750210762024\n",
      "Test Epoch82 layer4 out_loss 0.21707327663898468, R2 0.7785702347755432\n",
      "Train 83 | out_loss 0.43289434909820557: 100%|█| 258/258 [00:01<00:00, 132.01it/\n",
      "Train Epoch83 out_loss 0.1873975694179535, R2 0.8135038018226624\n",
      "Test Epoch83 layer0 out_loss 0.2530381679534912, R2 0.7418836355209351\n",
      "Test Epoch83 layer1 out_loss 0.22259922325611115, R2 0.7729334235191345\n",
      "Test Epoch83 layer2 out_loss 0.21560896933078766, R2 0.7800639867782593\n",
      "Test Epoch83 layer3 out_loss 0.2136252075433731, R2 0.7820875644683838\n",
      "Test Epoch83 layer4 out_loss 0.21455542743206024, R2 0.7811386585235596\n",
      "Train 84 | out_loss 0.4319368004798889: 100%|█| 258/258 [00:01<00:00, 132.17it/s\n",
      "Train Epoch84 out_loss 0.1865694224834442, R2 0.8143279552459717\n",
      "Test Epoch84 layer0 out_loss 0.25761690735816956, R2 0.7372129559516907\n",
      "Test Epoch84 layer1 out_loss 0.2273339033126831, R2 0.7681037187576294\n",
      "Test Epoch84 layer2 out_loss 0.21304094791412354, R2 0.7826834917068481\n",
      "Test Epoch84 layer3 out_loss 0.2142641842365265, R2 0.7814357280731201\n",
      "Test Epoch84 layer4 out_loss 0.218795046210289, R2 0.7768139243125916\n",
      "Train 85 | out_loss 0.431133896112442: 100%|█| 258/258 [00:01<00:00, 134.18it/s]\n",
      "Train Epoch85 out_loss 0.18587635457515717, R2 0.8150177001953125\n",
      "Test Epoch85 layer0 out_loss 0.24978803098201752, R2 0.7451989650726318\n",
      "Test Epoch85 layer1 out_loss 0.21211528778076172, R2 0.7836277484893799\n",
      "Test Epoch85 layer2 out_loss 0.2057998776435852, R2 0.7900699377059937\n",
      "Test Epoch85 layer3 out_loss 0.20342878997325897, R2 0.7924885749816895\n",
      "Test Epoch85 layer4 out_loss 0.20392367243766785, R2 0.7919837236404419\n",
      "Train 86 | out_loss 0.43196967244148254: 100%|█| 258/258 [00:01<00:00, 129.61it/\n",
      "Train Epoch86 out_loss 0.1865977793931961, R2 0.8142997026443481\n",
      "Test Epoch86 layer0 out_loss 0.2561618983745575, R2 0.7386971712112427\n",
      "Test Epoch86 layer1 out_loss 0.21486468613147736, R2 0.7808231711387634\n",
      "Test Epoch86 layer2 out_loss 0.21055138111114502, R2 0.7852230072021484\n",
      "Test Epoch86 layer3 out_loss 0.20841677486896515, R2 0.787400484085083\n",
      "Test Epoch86 layer4 out_loss 0.21254004538059235, R2 0.7831944823265076\n",
      "Train 87 | out_loss 0.4319544732570648: 100%|█| 258/258 [00:01<00:00, 140.70it/s\n",
      "Train Epoch87 out_loss 0.1865847110748291, R2 0.814312756061554\n",
      "Test Epoch87 layer0 out_loss 0.25572651624679565, R2 0.7391412854194641\n",
      "Test Epoch87 layer1 out_loss 0.21379435062408447, R2 0.7819149494171143\n",
      "Test Epoch87 layer2 out_loss 0.2130783200263977, R2 0.7826454043388367\n",
      "Test Epoch87 layer3 out_loss 0.20980572700500488, R2 0.785983681678772\n",
      "Test Epoch87 layer4 out_loss 0.2102161943912506, R2 0.7855649590492249\n",
      "Train 88 | out_loss 0.4325377345085144: 100%|█| 258/258 [00:02<00:00, 123.97it/s\n",
      "Train Epoch88 out_loss 0.18708892166614532, R2 0.8138110041618347\n",
      "Test Epoch88 layer0 out_loss 0.2573864758014679, R2 0.73744797706604\n",
      "Test Epoch88 layer1 out_loss 0.2145129293203354, R2 0.7811819911003113\n",
      "Test Epoch88 layer2 out_loss 0.20491042733192444, R2 0.7909772396087646\n",
      "Test Epoch88 layer3 out_loss 0.2112605720758438, R2 0.7844996452331543\n",
      "Test Epoch88 layer4 out_loss 0.20986954867839813, R2 0.7859185934066772\n",
      "Train 89 | out_loss 0.429402232170105: 100%|█| 258/258 [00:01<00:00, 153.43it/s]\n",
      "Train Epoch89 out_loss 0.1843862533569336, R2 0.8165006041526794\n",
      "Test Epoch89 layer0 out_loss 0.24704623222351074, R2 0.7479957342147827\n",
      "Test Epoch89 layer1 out_loss 0.21509672701358795, R2 0.7805864810943604\n",
      "Test Epoch89 layer2 out_loss 0.21028245985507965, R2 0.7854973673820496\n",
      "Test Epoch89 layer3 out_loss 0.21360301971435547, R2 0.7821101546287537\n",
      "Test Epoch89 layer4 out_loss 0.21548110246658325, R2 0.7801944017410278\n",
      "Train 90 | out_loss 0.430810809135437: 100%|█| 258/258 [00:02<00:00, 116.99it/s]\n",
      "Train Epoch90 out_loss 0.18559791147708893, R2 0.8152948021888733\n",
      "Test Epoch90 layer0 out_loss 0.2586933672428131, R2 0.7361148595809937\n",
      "Test Epoch90 layer1 out_loss 0.21608860790729523, R2 0.7795746922492981\n",
      "Test Epoch90 layer2 out_loss 0.20407813787460327, R2 0.7918261885643005\n",
      "Test Epoch90 layer3 out_loss 0.20534783601760864, R2 0.7905310392379761\n",
      "Test Epoch90 layer4 out_loss 0.2060425579547882, R2 0.7898223400115967\n",
      "Train 91 | out_loss 0.4304170608520508: 100%|█| 258/258 [00:01<00:00, 159.58it/s\n",
      "Train Epoch91 out_loss 0.18525896966457367, R2 0.8156321048736572\n",
      "Test Epoch91 layer0 out_loss 0.25151070952415466, R2 0.7434417009353638\n",
      "Test Epoch91 layer1 out_loss 0.2211073338985443, R2 0.7744552493095398\n",
      "Test Epoch91 layer2 out_loss 0.21310070157051086, R2 0.7826225757598877\n",
      "Test Epoch91 layer3 out_loss 0.21506890654563904, R2 0.7806148529052734\n",
      "Test Epoch91 layer4 out_loss 0.21050702035427094, R2 0.7852683067321777\n",
      "Train 92 | out_loss 0.4303489029407501: 100%|█| 258/258 [00:02<00:00, 121.46it/s\n",
      "Train Epoch92 out_loss 0.18520011007785797, R2 0.8156906962394714\n",
      "Test Epoch92 layer0 out_loss 0.2501342296600342, R2 0.7448458075523376\n",
      "Test Epoch92 layer1 out_loss 0.2136908918619156, R2 0.7820205092430115\n",
      "Test Epoch92 layer2 out_loss 0.21161244809627533, R2 0.7841407060623169\n",
      "Test Epoch92 layer3 out_loss 0.2094813734292984, R2 0.7863144874572754\n",
      "Test Epoch92 layer4 out_loss 0.21274933218955994, R2 0.7829809784889221\n",
      "Train 93 | out_loss 0.44233617186546326: 100%|█| 258/258 [00:01<00:00, 154.46it/\n",
      "Train Epoch93 out_loss 0.195661261677742, R2 0.8052798509597778\n",
      "Test Epoch93 layer0 out_loss 0.25814181566238403, R2 0.7366775274276733\n",
      "Test Epoch93 layer1 out_loss 0.21935012936592102, R2 0.7762477397918701\n",
      "Test Epoch93 layer2 out_loss 0.2116001397371292, R2 0.7841532230377197\n",
      "Test Epoch93 layer3 out_loss 0.21085980534553528, R2 0.7849084138870239\n",
      "Test Epoch93 layer4 out_loss 0.21119166910648346, R2 0.7845699191093445\n",
      "Train 94 | out_loss 0.42883485555648804: 100%|█| 258/258 [00:02<00:00, 121.08it/\n",
      "Train Epoch94 out_loss 0.18389935791492462, R2 0.8169851899147034\n",
      "Test Epoch94 layer0 out_loss 0.2600371539592743, R2 0.734744131565094\n",
      "Test Epoch94 layer1 out_loss 0.21865317225456238, R2 0.7769586443901062\n",
      "Test Epoch94 layer2 out_loss 0.21076568961143494, R2 0.7850044369697571\n",
      "Test Epoch94 layer3 out_loss 0.20977242290973663, R2 0.786017656326294\n",
      "Test Epoch94 layer4 out_loss 0.2128138691186905, R2 0.7829151153564453\n",
      "Train 95 | out_loss 0.4288528263568878: 100%|█| 258/258 [00:01<00:00, 147.70it/s\n",
      "Train Epoch95 out_loss 0.1839146912097931, R2 0.8169699311256409\n",
      "Test Epoch95 layer0 out_loss 0.24697329103946686, R2 0.7480701804161072\n",
      "Test Epoch95 layer1 out_loss 0.21461252868175507, R2 0.7810803651809692\n",
      "Test Epoch95 layer2 out_loss 0.2073177993297577, R2 0.7885215282440186\n",
      "Test Epoch95 layer3 out_loss 0.2068587839603424, R2 0.7889897227287292\n",
      "Test Epoch95 layer4 out_loss 0.20674380660057068, R2 0.7891070246696472\n",
      "Train 96 | out_loss 0.4300006330013275: 100%|█| 258/258 [00:01<00:00, 134.27it/s\n",
      "Train Epoch96 out_loss 0.18490053713321686, R2 0.8159888386726379\n",
      "Test Epoch96 layer0 out_loss 0.24454152584075928, R2 0.7505507469177246\n",
      "Test Epoch96 layer1 out_loss 0.21508286893367767, R2 0.7806006073951721\n",
      "Test Epoch96 layer2 out_loss 0.20654240250587463, R2 0.789312481880188\n",
      "Test Epoch96 layer3 out_loss 0.21204394102096558, R2 0.7837005257606506\n",
      "Test Epoch96 layer4 out_loss 0.20878519117832184, R2 0.7870246767997742\n",
      "Train 97 | out_loss 0.4279966950416565: 100%|█| 258/258 [00:01<00:00, 136.76it/s\n",
      "Train Epoch97 out_loss 0.18318112194538116, R2 0.8176999688148499\n",
      "Test Epoch97 layer0 out_loss 0.2435537576675415, R2 0.7515583634376526\n",
      "Test Epoch97 layer1 out_loss 0.21175405383110046, R2 0.7839962244033813\n",
      "Test Epoch97 layer2 out_loss 0.20535437762737274, R2 0.7905243635177612\n",
      "Test Epoch97 layer3 out_loss 0.20544135570526123, R2 0.7904356122016907\n",
      "Test Epoch97 layer4 out_loss 0.20621535181999207, R2 0.7896460890769958\n",
      "Train 98 | out_loss 0.4282807409763336: 100%|█| 258/258 [00:01<00:00, 140.13it/s\n",
      "Train Epoch98 out_loss 0.18342441320419312, R2 0.8174578547477722\n",
      "Test Epoch98 layer0 out_loss 0.24465763568878174, R2 0.7504323124885559\n",
      "Test Epoch98 layer1 out_loss 0.21668505668640137, R2 0.7789663076400757\n",
      "Test Epoch98 layer2 out_loss 0.21047964692115784, R2 0.7852962017059326\n",
      "Test Epoch98 layer3 out_loss 0.211003839969635, R2 0.7847614884376526\n",
      "Test Epoch98 layer4 out_loss 0.21387548744678497, R2 0.781832218170166\n",
      "Train 99 | out_loss 0.42811986804008484: 100%|█| 258/258 [00:02<00:00, 124.90it/\n",
      "Train Epoch99 out_loss 0.1832866221666336, R2 0.8175950050354004\n",
      "Test Epoch99 layer0 out_loss 0.25035831332206726, R2 0.744617223739624\n",
      "Test Epoch99 layer1 out_loss 0.21462048590183258, R2 0.7810722589492798\n",
      "Test Epoch99 layer2 out_loss 0.20324058830738068, R2 0.792680561542511\n",
      "Test Epoch99 layer3 out_loss 0.2047959268093109, R2 0.7910940051078796\n",
      "Test Epoch99 layer4 out_loss 0.2046501189470291, R2 0.7912427186965942\n",
      "Best r2 0.792680561542511 at L2\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "# LinearAL \n",
    "\n",
    "data = \"ca_housing\"\n",
    "#data = \"paint\"\n",
    "model =  \"linearal\"\n",
    "#for layer in range(1,11):\n",
    "for layer in [5]:\n",
    "    log = f\"result/{data}_{model}_l{layer}.log\"\n",
    "    !python3 dis_train_al.py --dataset {data} --model {model} --epoch 100 --num-layer {layer} --lr 0.001 --task regression # > {log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ae70865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "Start Training\n",
      "  0%|                                                  | 0/6176 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.9627570746123638 (380497/395216): 100%|█| 6176/6176 [00:15<00:00\n",
      "[[1.39556581e+04 1.79137843e+01]\n",
      " [3.86015957e+00 1.09439019e+01]\n",
      " [3.46772333e+00 9.11350174e+00]]\n",
      "Train Epoch0 Acc 0.9627570746123638 (380497/395216)\n",
      "Test Epoch0 layer0 Acc 0.9949091645159658\n",
      "Test Epoch0 layer1 Acc 0.9950306158595212\n",
      "Test Epoch0 layer2 Acc 0.9955872678508173\n",
      "Best acc 0.9955872678508173\n",
      "train_loss (2, 3, 1)\n",
      "valid_acc (3, 1)\n",
      "train_acc (1,)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Figure(640x480)\n",
      "Start Testing\n",
      "[[  419     0     0     0     0     0     0     0     0     0     0    12\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    1     0     0     0     0     0     0     0     0     0     0     2\n",
      "      0     0     0     0     0     1     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0    11\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     3     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0   213     0     0     0     0     0    23\n",
      "      0     0     0     0     0     0     0     0     4     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     5\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     2\n",
      "      0     0     0     0     0     0     0     0     1     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     2\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0 21462     0     2\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0    11     0     0     0    18     0    17\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [   12     0     0     0     0     2     0     0     0     2     0 19424\n",
      "      0     0     0     0     0     6     0     2    11     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     1     0     0     0     2     0    31\n",
      "      0     0     0     0     0    12     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0    13     0     4\n",
      "      0     0    18     0     0   188     0     0     1     0]\n",
      " [    1     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     1     0    27\n",
      "      0     0     0     0   270     3     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0    13\n",
      "      0     0     0     0     0 56168     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     1     0     2\n",
      "      0     0     0     0     0     0     0   189     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0    43\n",
      "      0     0     0     0     0     0     0     0   139     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     6\n",
      "      0     0     0     0     0     0     0     0     0     0]]\n",
      "Figure(640x480)\n",
      "[[  419     0     0     0     0     0     0     0     0     0     0    12\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    1     0     0     0     0     0     0     0     0     0     0     3\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0    11\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     3     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0   213     0     0     0     0     0    23\n",
      "      0     0     0     0     0     0     0     0     4     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     5\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     2\n",
      "      0     0     0     0     0     0     0     0     1     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     2\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0 21464     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0    11     0     0     0     0     0    18\n",
      "      0     0     0     0     0    17     0     0     0     0]\n",
      " [    8     0     0     0     0     2     0     0     0     2     0 19431\n",
      "      0     0     0     0     0     5     0     0    11     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     3     0     0     0     7     0    12\n",
      "      0     0     0     0     0    24     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0    11     0     6\n",
      "      0     0    14     0     0   192     0     0     1     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     2\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     1     0    26\n",
      "      0     0     0     0   271     3     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0    13\n",
      "      0     0     0     0     0 56168     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     3     0     0\n",
      "      0     0     0     0     0     0     0   189     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0    37\n",
      "      0     0     0     0     0     0     0     0   145     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     6\n",
      "      0     0     0     0     0     0     0     0     0     0]]\n",
      "Figure(640x480)\n",
      "[[  419     0     0     0     0     0     0     0     0     0     0    12\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     3\n",
      "      0     0     0     0     0     1     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0    11\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     2     0     1\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0   213     0     0     0     0     0    20\n",
      "      0     0     0     0     0     0     0     0     7     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     5\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     2\n",
      "      0     0     0     0     0     0     0     0     1     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     2\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0 21461     0     3\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0    11     0     0     0     0     0    17\n",
      "      0     0     0     0     0    18     0     0     0     0]\n",
      " [    7     0     0     0     0     2     0     0     0     1     0 19429\n",
      "      0     0     0     0     0     9     0     0    11     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     3     0     0     0     0     0    15\n",
      "      0     0     0     0     0    28     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     9     0     4\n",
      "      0     0    70     0     0   140     0     0     1     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     2\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0    26\n",
      "      0     0     0     0   271     4     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0    12\n",
      "      0     0     0     0     0 56169     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     1\n",
      "      0     0     0     0     0     2     0   189     0     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0    34\n",
      "      0     0     0     0     0     0     0     0   148     0]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     6\n",
      "      0     0     0     0     0     0     0     0     0     0]]\n",
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "# LinearAL \n",
    "data = \"kdd99\"\n",
    "\n",
    "model =  \"linearal\"\n",
    "#for layer in range(1,11):\n",
    "for layer in [3]:\n",
    "    log = f\"result/{data}_{model}_l{layer}.log\"\n",
    "    !python3 dis_train_al.py --dataset {data} --model {model} --epoch 1 --num-layer {layer} --task classification --lr 0.001 --l1-dim 32 --label-emb 16 #> {log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "833b414e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8800,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7675b11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "  0%|                                                  | 0/6176 [00:00<?, ?it/s]/home/AL_main_new/utils.py:99: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  x = torch.tensor([x for x,y in batch], dtype=torch.float32)\n",
      "Train 0 | Acc 0.9348280433990527 (369459/395216): 100%|█| 6176/6176 [00:36<00:00\n"
     ]
    }
   ],
   "source": [
    "# LinearAL side \n",
    "data = \"kdd99\"\n",
    "\n",
    "model =  \"linearalside\"\n",
    "#for layer in range(1,11):\n",
    "for layer in [8]:\n",
    "    log = f\"result/{data}_{model}_l{layer}.log\"\n",
    "    !python3 dis_train_al.py --dataset {data} --model {model} --epoch 10 --num-layer {layer} --task classification --lr 0.001 --l1-dim 32 --label-emb 16 > {log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.Tensor([[1,2,3],[4,5,6]])\n",
    "\n",
    "x2=torch.split(x,[1,2],-1)\n",
    "torch.cat(x2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea8a7f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0008725115898554677\n",
      "0.0004098966061174112\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(statistics.mean(y))\n",
    "print(statistics.stdev(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d15db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
