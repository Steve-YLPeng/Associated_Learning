{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91685f81",
   "metadata": {},
   "source": [
    "## 0208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e97f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "data = \"dbpedia_14\"\n",
    "text_len = 60\n",
    "model = \"transformeral\"\n",
    "layer = 5\n",
    "epoch = 10\n",
    "lr = 0.0001\n",
    "fix_previous_layer = True\n",
    "#for mask in range(1,1+layer):\n",
    "mask = 5\n",
    "save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}_m{mask}/\"  \n",
    "#load_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}_m{mask-1}/\" \n",
    "out_path = f\"result/0117/fix train adapt/{data}_{model}_l{layer}ad_pad{text_len}_m{mask}/\"\n",
    "log = f\"{out_path}/{data}_{model}_l{layer}.log\"\n",
    "\n",
    "with open(log,mode='r') as log:\n",
    "    buffer = log.readlines()\n",
    "    df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "class history(object):\n",
    "    def __init__(self):\n",
    "        self.auc = {}\n",
    "        self.acc = {}\n",
    "        self.entr = {}\n",
    "        for threshold in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "            self.auc[threshold] = []\n",
    "            self.acc[threshold] = []\n",
    "            self.entr[threshold] = []\n",
    "            \n",
    "result = history()\n",
    "for line in buffer:\n",
    "    match = re.match('Test Epoch(.)*', line)\n",
    "    if match!=None:\n",
    "        print(match.group())\n",
    "        match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "        print(match)\n",
    "        threshold = float(match[0])\n",
    "        result.acc[threshold].append(match[1])\n",
    "        result.auc[threshold].append(match[2])\n",
    "        result.entr[threshold].append(match[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "    print(len(result.acc[threshold]))\n",
    "    print(len(result.auc[threshold]))\n",
    "    print(len(result.entr[threshold]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c6b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2/06 - valid/test 80%:20%\n",
    "###      - prefix\n",
    "###      - plot result\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "data = \"ag_news\"\n",
    "text_len = 175\n",
    "\n",
    "\n",
    "for model in [\"linearal\",\"lstmal\",\"transformeral\"]:\n",
    "    result = [[] for _ in range(4)]\n",
    "    for threshold in [.1,.2,.3,.4,.5,.6,.7,.8,.9]:\n",
    "\n",
    "        layer = 5\n",
    "        epoch = 10\n",
    "        lr = 0.0001\n",
    "        fix_previous_layer = False\n",
    "        \n",
    "        mask = 5\n",
    "        out_path = f\"result/0208/test/prefix/{data}_{model}_l{layer}adp_pad{text_len}_t{threshold}_m{mask}_test/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}.log\"\n",
    "            \n",
    "        with open(log,mode='r') as log:\n",
    "            buffer = log.readlines()\n",
    "            df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "            df\n",
    "            \n",
    "            for line in buffer:\n",
    "                match = re.match('Test threshold(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    #print(match[1])\n",
    "                    result[0].append(float(match[1]))\n",
    "                    result[1].append(float(match[2]))\n",
    "                    result[2].append(float(match[3]))\n",
    "            for line in buffer:\n",
    "                match = re.match('t(.)*_test_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    #print(match[1])\n",
    "                    result[3].append(float(match[1]))\n",
    "    print(\"\\n\",model)\n",
    "    for i in range(4):\n",
    "        print(i)\n",
    "        for v in result[i]:\n",
    "            print(v)                    \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4e2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2/06 - valid/test 80%:20%\n",
    "###      - fix\n",
    "###      - plot result\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "data = \"ag_news\"\n",
    "text_len = 175\n",
    "\n",
    "for model in [\"linearal\",\"lstmal\",\"transformeral\"]:\n",
    "    result = [[] for _ in range(4)]\n",
    "    for threshold in [.1,.2,.3,.4,.5,.6,.7,.8,.9]:\n",
    "\n",
    "        layer = 5\n",
    "        epoch = 10\n",
    "        lr = 0.0001\n",
    "        fix_previous_layer = False\n",
    "        \n",
    "        mask = 5\n",
    "        out_path = f\"result/0208/test/fix/{data}_{model}_l{layer}adf_pad{text_len}_t{threshold}_m{mask}_test/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}.log\"\n",
    "            \n",
    "        with open(log,mode='r') as log:\n",
    "            buffer = log.readlines()\n",
    "            df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "            df\n",
    "            \n",
    "            for line in buffer:\n",
    "                match = re.match('Test threshold(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    #print(match[1])\n",
    "                    result[0].append(float(match[1]))\n",
    "                    result[1].append(float(match[2]))\n",
    "                    result[2].append(float(match[3]))\n",
    "            for line in buffer:\n",
    "                match = re.match('t(.)*_test_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    #print(match[1])\n",
    "                    result[3].append(float(match[1]))\n",
    "    print(\"\\n\",model)\n",
    "    for i in range(4):\n",
    "        print(i)\n",
    "        for v in result[i]:\n",
    "            print(v)                    \n",
    "\n",
    "                    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab581dd2",
   "metadata": {},
   "source": [
    "## 0214\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1418cc62",
   "metadata": {},
   "source": [
    "### base adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc003623",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 0214\n",
    "### pad base adapt \n",
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for model in [\"lstmal\"]:\n",
    "for model in [\"lstmal\",\"linearal\",\"transformeral\"]:\n",
    "    total_result = pd.DataFrame(columns=['padding_size', 'model', 'test_threshold', 'test_acc', 'test_auc',\n",
    "                                        'test_avg_entr', 'test_time'])\n",
    "    #data = \"ag_news\"\n",
    "    #for text_len in [25,50,75,100,125,150,175]:\n",
    "    data = \"dbpedia_14\"\n",
    "    for text_len in [20,40,60]:\n",
    "        layer = 5\n",
    "        epoch = 50\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}ad_pad{text_len}/\"\n",
    "        #out_path = f\"result/0220/ag_news/base adapt/{data}_{model}_l{layer}ad_pad{text_len}/\"\n",
    "        out_path = f\"result/0220/dbpedia_14/base adapt/{data}_{model}_l{layer}ad_pad{text_len}/\"\n",
    "        \"result/0220/dbpedia/base adapt/dbpedia_14_linearal_l5ad_pad20/dbpedia_14_linearal_l5.log\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}.log\"\n",
    "        \n",
    "        result = pd.DataFrame(columns=[\"padding_size\"])\n",
    "        result_ep = pd.DataFrame(columns=[\"epoch\",\"ep_train_time\"])\n",
    "        result_ep[\"epoch\"] = [*range(epoch)]\n",
    "        list_acc = []\n",
    "        list_auc = []\n",
    "        list_entr = []\n",
    "        list_test_time = []\n",
    "        list_ep_train_time = []\n",
    "        list_ep_train_acc = []\n",
    "        list_ep_train_auc = []\n",
    "        list_ep_train_entr = []\n",
    "        list_ep_valid_time = []\n",
    "        list_ep_valid_acc = []\n",
    "        list_ep_valid_auc = []\n",
    "        list_ep_valid_entr = []\n",
    "        train_time = 0\n",
    "        init_time = 0\n",
    "        best_ep = -1\n",
    "        best_th = []\n",
    "        save_th = []\n",
    "        with open(log,mode='r') as log:\n",
    "            buffer = log.readlines()\n",
    "            df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "            df\n",
    "            \n",
    "            for line in buffer:\n",
    "                \n",
    "                \n",
    "                match = re.match('Save ckpt to (.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"ep \\d+\",match.group(0))\n",
    "                    best_ep = match[0]\n",
    "                    best_th.append(current_th)\n",
    "                match = re.match('Test threshold(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    list_acc.append(float(match[1]))\n",
    "                    list_auc.append(float(match[2]))\n",
    "                    list_entr.append(float(match[3]))\n",
    "                    \n",
    "\n",
    "                match = re.match('t(.)*_test_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_test_time.append(float(match[1]))\n",
    "\n",
    "                match = re.match('init_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    init_time = float(match[0])\n",
    "                match = re.match('(.)*valid_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    train_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_train_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_t(.)*_test_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_valid_time.append(float(match[1]))\n",
    "                    \n",
    "                match = re.match('Train Epoch\\d+ Acc(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_acc.append(float(match[0]))\n",
    "                    list_ep_train_auc.append(float(match[1]))\n",
    "                    #print(best_th)\n",
    "                    if len(best_th)>0:\n",
    "                        save_th = best_th\n",
    "                    best_th = []\n",
    "                    \n",
    "                match = re.match('Test Epoch\\d+ threshold(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    #print(line)\n",
    "                    #print(match)\n",
    "                    current_th = int(float(match[0])*10)\n",
    "                    list_ep_valid_acc.append(float(match[1]))\n",
    "                    list_ep_valid_auc.append(float(match[2]))\n",
    "                    list_ep_valid_entr.append(float(match[3]))\n",
    "        print(save_th)    \n",
    "        ep_valid_time = np.array(list_ep_valid_time).reshape((epoch,-1))\n",
    "        ep_valid_acc = np.array(list_ep_valid_acc).reshape((epoch,-1))\n",
    "        ep_valid_auc = np.array(list_ep_valid_auc).reshape((epoch,-1))\n",
    "        ep_valid_entr = np.array(list_ep_valid_entr).reshape((epoch,-1))\n",
    "        \n",
    "        result_ep[\"ep_train_acc\"] = list_ep_train_acc \n",
    "        result_ep[\"ep_train_auc\"] = list_ep_train_auc          \n",
    "        \n",
    "        result_ep[\"ep_valid_time\"] = np.sum(ep_valid_time,-1) \n",
    "        result_ep[[f\"ep_valid.{(i+1)}_time\" for i in range(9)]] = ep_valid_time\n",
    "        result_ep[\"ep_train_time\"] = list_ep_train_time \n",
    "        \n",
    "        para_size = 9\n",
    "        result['model'] = [model]*para_size\n",
    "        result['padding_size'] = [text_len]*para_size\n",
    "        result[\"test_threshold\"] = [(1+i)*0.1 for i in range(para_size)]\n",
    "        result[\"best_ep\"] = [best_ep[2:]]*para_size\n",
    "        result[\"best_th\"] = [save_th]*para_size\n",
    "        result[\"best_acc_setting\"] = [list_acc[save_th[-1]-1]]*para_size\n",
    "        result[\"best_auc_setting\"] = [list_auc[save_th[-1]-1]]*para_size\n",
    "        result[\"test_acc\"] = list_acc\n",
    "        result[\"test_auc\"] = list_auc\n",
    "        result[\"test_avg_entr\"] = list_entr\n",
    "        result[\"test_time\"] = list_test_time\n",
    "        result[\"init_time\"] = [init_time]*para_size\n",
    "        result[\"train+valid_time\"] = [train_time]*para_size\n",
    "        result[\"train_time\"] = [result_ep[\"ep_train_time\"].sum()]*para_size\n",
    "        result[\"valid_time\"] = [result_ep[\"ep_valid_time\"].sum()]*para_size\n",
    "        #print(result)\n",
    "        #print(result_ep)\n",
    "\n",
    "        path = f\"result/_csv/{data}/base_ad/\"\n",
    "        title = f\"{data}_{model}_l{layer}ad_pad{text_len}({best_ep})\"\n",
    "        os.makedirs(path,exist_ok=True)\n",
    "        \"\"\"\n",
    "        t = [0.1*(i+1) for i in range(9)]\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_time\"],\"o-\") \n",
    "        plt.xlabel(\"threshold\")\n",
    "        plt.ylabel(\"test time\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_test_time.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_acc\"],\"o-\") \n",
    "        plt.xlabel(\"threshold\")\n",
    "        plt.ylabel(\"test acc\")\n",
    "        for i in range(9):\n",
    "            if (i+1) in save_th:\n",
    "                plt.plot((i+1)/10,result[\"test_acc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_acc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_auc\"],\"o-\") \n",
    "        plt.xlabel(\"threshold\")\n",
    "        plt.ylabel(\"test auc\")\n",
    "        for i in range(9):\n",
    "            if (i+1) in save_th:\n",
    "                plt.plot((i+1)/10,result[\"test_auc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_auc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_avg_entr\"],\"o-\") \n",
    "        plt.xlabel(\"threshold\")\n",
    "        plt.ylabel(\"test avg entr\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_entr.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        #result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "        #result_ep.to_csv(f\"{path}/{title}_ep.csv\", index=False)\n",
    "        total_result = pd.concat([total_result,result],axis=0,ignore_index=True)            \n",
    "        del result\n",
    "\n",
    "    title = f\"{data}_{model}_l{layer}ad\"\n",
    "    total_result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9494d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25fad4e",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebd86f0b",
   "metadata": {},
   "source": [
    "### base shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 0214\n",
    "### pad base sc\n",
    "### 0220 - ag_news/dbpedia_14 \n",
    "###      - testing log有誤 \"Test Epoch49 layer(.)*\"\n",
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for model in [\"lstmal\",\"linearal\",\"transformeral\"]:\n",
    "    total_result = pd.DataFrame(columns=['padding_size', 'model', 'test_acc', 'test_auc',\n",
    "                                        'test_time'])\n",
    "    #data = \"ag_news\"\n",
    "    #for text_len in [25,50,75,100,125,150,175]:\n",
    "    #data = \"dbpedia_14\"\n",
    "    #for text_len in [20,40,60]:\n",
    "    data = \"imdb\"\n",
    "    for text_len in [100,200,300,400,500]:    \n",
    "        layer = 5\n",
    "        epoch = 50\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        #out_path = f\"result/0220/ag_news/base sc/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        #out_path = f\"result/0220/dbpedia/base sc/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        out_path = f\"result/0220/imdb/base sc/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}.log\"\n",
    "        \n",
    "        result = pd.DataFrame(columns=[\"padding_size\"])\n",
    "        result_ep = pd.DataFrame(columns=[\"epoch\",\"ep_train_time\"])\n",
    "        result_ep[\"epoch\"] = [*range(epoch)]\n",
    "        list_acc = []\n",
    "        list_auc = []\n",
    "        list_entr = []\n",
    "        list_test_time = []\n",
    "        list_ep_train_time = []\n",
    "        list_ep_train_acc = []\n",
    "        list_ep_train_auc = []\n",
    "        list_ep_train_entr = []\n",
    "        list_ep_valid_time = []\n",
    "        list_ep_valid_acc = []\n",
    "        list_ep_valid_auc = []\n",
    "        list_ep_valid_entr = []\n",
    "        train_time = 0\n",
    "        init_time = 0\n",
    "        best_ep = -1\n",
    "        best_th = []\n",
    "        save_th = []\n",
    "        test_part = False\n",
    "        \n",
    "        para_size = 5\n",
    "        with open(log,mode='r') as log:\n",
    "            buffer = log.readlines()\n",
    "            df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "            df\n",
    "            \n",
    "            for line in buffer:\n",
    "                \n",
    "                \n",
    "                match = re.match(\"Start Testing\", line)\n",
    "                if match!=None:\n",
    "                    test_part = True\n",
    "                    \n",
    "                match = re.match('Save ckpt to (.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"ep \\d+\",match.group(0))\n",
    "                    best_ep = match[0]\n",
    "                    best_th.append(current_th)\n",
    "                \n",
    "                if data == \"imdb\":\n",
    "                    match = re.match('Test layer\\d+(.)*', line)    \n",
    "                else:    \n",
    "                    match = re.match('Test Epoch49 layer(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    list_acc.append(float(match[0]))\n",
    "                    list_auc.append(float(match[1]))\n",
    "                    list_entr.append(float(match[2]))\n",
    "                    \n",
    "                if data == \"imdb\":\n",
    "                    match = re.match('l\\d+_test_time(.)*', line)\n",
    "                else:    \n",
    "                    match = re.match('ep49_l\\d_test_time(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_test_time.append(float(match[0]))\n",
    "\n",
    "                match = re.match('init_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    init_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('(.)*valid_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    train_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_train_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_l\\d+_test_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_valid_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('Train Epoch\\d+ Acc(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_acc.append(float(match[0]))\n",
    "                    list_ep_train_auc.append(float(match[1]))\n",
    "                    #print(best_th)\n",
    "                    if len(best_th)>0:\n",
    "                        save_th = best_th\n",
    "                    best_th = []\n",
    "                    \n",
    "                match = re.match('Test Epoch\\d+ layer(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    #print(line)\n",
    "                    #print(match)\n",
    "                    \n",
    "                    list_ep_valid_acc.append(float(match[0]))\n",
    "                    list_ep_valid_auc.append(float(match[1]))\n",
    "                    list_ep_valid_entr.append(float(match[2]))\n",
    "                    \n",
    "                    match = re.findall('\\d+', line)\n",
    "                    current_th = int(match[1])\n",
    "        print(save_th)    \n",
    "        ep_valid_time = np.array(list_ep_valid_time).reshape((epoch,-1))\n",
    "        ep_valid_acc = np.array(list_ep_valid_acc).reshape((epoch,-1))\n",
    "        ep_valid_auc = np.array(list_ep_valid_auc).reshape((epoch,-1))\n",
    "        ep_valid_entr = np.array(list_ep_valid_entr).reshape((epoch,-1))\n",
    "        \n",
    "        result_ep[\"ep_train_acc\"] = list_ep_train_acc \n",
    "        result_ep[\"ep_train_auc\"] = list_ep_train_auc          \n",
    "        \n",
    "        result_ep[\"ep_valid_time\"] = np.sum(ep_valid_time,-1) \n",
    "        result_ep[[f\"ep_valid_l{i}_time\" for i in range(para_size)]] = ep_valid_time\n",
    "        result_ep[\"ep_train_time\"] = list_ep_train_time \n",
    "        \n",
    "        \n",
    "        result['model'] = [model]*para_size\n",
    "        result['padding_size'] = [text_len]*para_size\n",
    "        result[\"test_layer\"] = [(i) for i in range(para_size)]\n",
    "        result[\"best_ep\"] = [best_ep[2:]]*para_size\n",
    "        result[\"best_th\"] = [save_th]*para_size\n",
    "        result[\"best_acc_setting\"] = [list_acc[save_th[-1]-1]]*para_size\n",
    "        result[\"best_auc_setting\"] = [list_auc[save_th[-1]-1]]*para_size\n",
    "        result[\"test_acc\"] = list_acc\n",
    "        result[\"test_auc\"] = list_auc\n",
    "        result[\"test_avg_entr\"] = list_entr\n",
    "        result[\"test_time\"] = list_test_time\n",
    "        result[\"init_time\"] = [init_time]*para_size\n",
    "        result[\"train+valid_time\"] = [train_time]*para_size\n",
    "        result[\"train_time\"] = [result_ep[\"ep_train_time\"].sum()]*para_size\n",
    "        result[\"valid_time\"] = [result_ep[\"ep_valid_time\"].sum()]*para_size\n",
    "        #print(result)\n",
    "        #print(result_ep)\n",
    "\n",
    "        path = f\"result/_csv/{data}/base_sc/\"\n",
    "        title = f\"{data}_{model}_l{layer}_pad{text_len}({best_ep})\"\n",
    "        t = [(i) for i in range(para_size)]\n",
    "        \n",
    "        os.makedirs(path,exist_ok=True)\n",
    "\n",
    "        \"\"\"\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_time\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test time\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_test_time.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_acc\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test acc\")\n",
    "        for i in range(para_size):\n",
    "            if (i) == save_th[-1]:\n",
    "                plt.plot((i),result[\"test_acc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_acc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_auc\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test auc\")\n",
    "        for i in range(para_size):\n",
    "            if (i) == save_th[-1]:\n",
    "                plt.plot((i),result[\"test_auc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_auc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_avg_entr\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test avg entr\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_entr.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        #result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "        #result_ep.to_csv(f\"{path}/{title}_ep.csv\", index=False)\n",
    "        total_result = pd.concat([total_result,result],axis=0,ignore_index=True)            \n",
    "        del result\n",
    "    \n",
    "    title = f\"{data}_{model}_l{layer}\"\n",
    "    total_result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b7ba3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d52e358d",
   "metadata": {},
   "source": [
    "### fix/prefix adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c25b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"ag_news\"\n",
    "for model in [\"lstmal\",\"linearal\",\"transformeral\"]:\n",
    "    total_result = pd.DataFrame(columns=[])\n",
    "    for threshold in [.1,.2,.3,.4,.5,.6,.7,.8,.9]:\n",
    "        for text_len in [175]:\n",
    "            layer = 5\n",
    "            epoch = 10\n",
    "            lr = 0.0001\n",
    "            \n",
    "            result = pd.DataFrame(columns=[\"padding_size\"])\n",
    "            result_ep = pd.DataFrame(columns=[\"epoch\",\"ep_train_time\"])\n",
    "            result_ep[\"epoch\"] = [*range(epoch)]\n",
    "            list_acc = []\n",
    "            list_auc = []\n",
    "            list_entr = []\n",
    "            list_test_time = []\n",
    "            list_init_time = []\n",
    "            list_train_time = []\n",
    "            \n",
    "            for mask in range(1,1+layer):\n",
    "                save_path = f\"ckpt/{data}_{model}_l{layer}adf_pad{text_len}_t{threshold}_m{mask}/\"  \n",
    "                load_path = f\"ckpt/{data}_{model}_l{layer}adf_pad{text_len}_t{threshold}_m{mask-1}/\" \n",
    "                #out_path = f\"result/0220/ag_news/fix adapt/{data}_{model}_l{layer}adf_pad{text_len}_t{threshold}_m{mask}/\"\n",
    "                out_path = f\"result/0214/prefix adapt/{data}_{model}_l{layer}adf_pad{text_len}_t{threshold}_m{mask}/\"\n",
    "                log = f\"{out_path}/{data}_{model}_l{layer}.log\"\n",
    "                \n",
    "                with open(log,mode='r') as log:\n",
    "                    buffer = log.readlines()\n",
    "                    df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "                    df\n",
    "                    \n",
    "                    \n",
    "                    for line in buffer:\n",
    "                        match = re.match('Test threshold(.)*', line)\n",
    "                        if match!=None:\n",
    "                            match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                            list_acc.append(float(match[1]))\n",
    "                            list_auc.append(float(match[2]))\n",
    "                            list_entr.append(float(match[3]))\n",
    "\n",
    "                        match = re.match('t(.)*_test_time(.)*', line)\n",
    "                        if match!=None:\n",
    "                            match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                            list_test_time.append(float(match[1]))\n",
    "                        match = re.match('init_time(.)*', line)\n",
    "                        if match!=None:\n",
    "                            match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                            list_init_time.append(float(match[0]))\n",
    "                        match = re.match('(.)*valid_time(.)*', line)\n",
    "                        if match!=None:\n",
    "                            match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                            list_train_time.append(float(match[0]))\n",
    "                                \n",
    "            result['threshold'] = [threshold]*5\n",
    "            result['model'] = [model]*5\n",
    "            result['padding_size'] = [text_len]*5\n",
    "            result[\"train_mask\"] = [(1+i) for i in range(5)]\n",
    "            \n",
    "            result[\"test_acc\"] = list_acc\n",
    "            result[\"test_auc\"] = list_auc\n",
    "            result[\"test_avg_entr\"] = list_entr\n",
    "            \n",
    "            result[\"init_time\"] = list_init_time\n",
    "            result[\"test_time\"] = list_test_time\n",
    "            result[\"train+valid_time\"] = list_train_time\n",
    "        \n",
    "            #print(result)\n",
    "            total_result = pd.concat([total_result,result],axis=0,ignore_index=True)\n",
    "    \n",
    "    table = total_result[total_result[\"train_mask\"]==5]\n",
    "    #title = f\"{data}_{model}_l{layer}f_pad{text_len}\"\n",
    "    title = f\"{data}_{model}_l{layer}p_pad{text_len}\"\n",
    "    path = f\"result/_csv/{data}\"\n",
    "                   \n",
    "    print(total_result)\n",
    "    total_result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.plot(t,table[\"test_acc\"],\"o-\") \n",
    "    plt.xlabel(\"threshold\")\n",
    "    plt.ylabel(\"test acc\")\n",
    "    plt.savefig(f\"{path}/{title}_plt_acc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.plot(t,table[\"test_auc\"],\"o-\") \n",
    "    plt.xlabel(\"threshold\")\n",
    "    plt.ylabel(\"test auc\")\n",
    "    plt.savefig(f\"{path}/{title}_plt_auc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.plot(t,table[\"test_time\"],\"o-\") \n",
    "    plt.xlabel(\"threshold\")\n",
    "    plt.ylabel(\"test time\")\n",
    "    plt.savefig(f\"{path}/{title}_plt_test_time.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.plot(t,table[\"test_avg_entr\"],\"o-\") \n",
    "    plt.xlabel(\"threshold\")\n",
    "    plt.ylabel(\"test avg entr\")\n",
    "    plt.savefig(f\"{path}/{title}_plt_entr.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "    plt.show()\n",
    "    #break\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbdd66bb",
   "metadata": {},
   "source": [
    "### base fullpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9067b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fullpath baseline\n",
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "### 2/22 - baseline: valid/test with fullpath\n",
    "data = \"ag_news\"\n",
    "total_result = pd.DataFrame(columns=[])\n",
    "for model in [\"linearal\",\"lstmal\",\"transformeral\"]:\n",
    "    for text_len in [25,50,75,100,125,150,175]:\n",
    "### 2/26 - dbpedia\n",
    "#data = \"dbpedia_14\"\n",
    "#for text_len in [20,40,60]:\n",
    "### 2/28 - imdb 8:1:1\n",
    "#data = \"imdb\"\n",
    "#for text_len in [100,200,300,400,500]:\n",
    "    \n",
    "        \n",
    "        layer = 5\n",
    "        epoch = 50\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}base_pad{text_len}/\"\n",
    "        out_path = f\"result/0227/{data}_{model}_l{layer}base_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}base.log\"\n",
    "        \n",
    "        \n",
    "        result = pd.DataFrame(columns=[\"padding_size\"])\n",
    "        result_ep = pd.DataFrame(columns=[\"epoch\",\"ep_train_time\"])\n",
    "        result_ep[\"epoch\"] = [*range(epoch)]\n",
    "        list_acc = []\n",
    "        list_auc = []\n",
    "        list_entr = []\n",
    "        list_test_time = []\n",
    "        list_ep_train_time = []\n",
    "        list_ep_train_acc = []\n",
    "        list_ep_train_auc = []\n",
    "        list_ep_train_entr = []\n",
    "        list_ep_valid_time = []\n",
    "        list_ep_valid_acc = []\n",
    "        list_ep_valid_auc = []\n",
    "        list_ep_valid_entr = []\n",
    "        train_time = 0\n",
    "        init_time = 0\n",
    "        best_ep = -1\n",
    "        best_th = []\n",
    "        save_th = []\n",
    "        test_part = False\n",
    "        \n",
    "        para_size = 1\n",
    "        with open(log,mode='r') as log:\n",
    "            buffer = log.readlines()\n",
    "            df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "            df\n",
    "            \n",
    "            for line in buffer:\n",
    "                \n",
    "                \n",
    "                match = re.match(\"Start Testing\", line)\n",
    "                if match!=None:\n",
    "                    test_part = True\n",
    "                    \n",
    "                match = re.match('Save ckpt to (.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"ep \\d+\",match.group(0))\n",
    "                    best_ep = match[0]\n",
    "                    best_th.append(current_th)\n",
    "                    \n",
    "                match = re.match('Test layer\\d Acc(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    list_acc.append(float(match[0]))\n",
    "                    list_auc.append(float(match[1]))\n",
    "                    list_entr.append(float(match[2]))\n",
    "                    \n",
    "\n",
    "                match = re.match('Test layer\\d Acc(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_test_time.append(float(match[0]))\n",
    "\n",
    "                match = re.match('init_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    init_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('(.)*valid_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    train_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_train_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_l\\d+_test_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_valid_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('Train Epoch\\d+ Acc(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_acc.append(float(match[0]))\n",
    "                    list_ep_train_auc.append(float(match[1]))\n",
    "                    #print(best_th)\n",
    "                    if len(best_th)>0:\n",
    "                        save_th = best_th\n",
    "                    best_th = []\n",
    "                    \n",
    "                match = re.match('Test Epoch\\d+ layer(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    #print(line)\n",
    "                    #print(match)\n",
    "                    \n",
    "                    list_ep_valid_acc.append(float(match[0]))\n",
    "                    list_ep_valid_auc.append(float(match[1]))\n",
    "                    list_ep_valid_entr.append(float(match[2]))\n",
    "                    \n",
    "                    match = re.findall('\\d+', line)\n",
    "                    current_th = int(match[1])\n",
    "        print(save_th)    \n",
    "        ep_valid_time = np.array(list_ep_valid_time).reshape((epoch,-1))\n",
    "        ep_valid_acc = np.array(list_ep_valid_acc).reshape((epoch,-1))\n",
    "        ep_valid_auc = np.array(list_ep_valid_auc).reshape((epoch,-1))\n",
    "        ep_valid_entr = np.array(list_ep_valid_entr).reshape((epoch,-1))\n",
    "        \n",
    "        result_ep[\"ep_train_acc\"] = list_ep_train_acc \n",
    "        result_ep[\"ep_train_auc\"] = list_ep_train_auc          \n",
    "        \n",
    "        result_ep[\"ep_valid_time\"] = np.sum(ep_valid_time,-1) \n",
    "        result_ep[[f\"ep_valid_l{i}_time\" for i in range(para_size)]] = ep_valid_time\n",
    "        result_ep[\"ep_train_time\"] = list_ep_train_time \n",
    "        \n",
    "        \n",
    "        result['model'] = [model]*para_size\n",
    "        result['padding_size'] = [text_len]*para_size\n",
    "        result[\"test_layer\"] = [(i) for i in range(para_size)]\n",
    "        result[\"test_acc\"] = list_acc\n",
    "        result[\"test_auc\"] = list_auc\n",
    "        result[\"test_avg_entr\"] = list_entr\n",
    "        result[\"test_time\"] = list_test_time\n",
    "        result[\"init_time\"] = [init_time]*para_size\n",
    "        result[\"train+valid_time\"] = [train_time]*para_size\n",
    "        result[\"train_time\"] = [result_ep[\"ep_train_time\"].sum()]*para_size\n",
    "        result[\"valid_time\"] = [result_ep[\"ep_valid_time\"].sum()]*para_size\n",
    "        result['best_ep'] = best_ep\n",
    "        #print(result)\n",
    "        #print(result_ep)\n",
    "        \"\"\"\n",
    "        path = f\"result/_csv/{data}\"\n",
    "        title = f\"{data}_{model}_l{layer}_pad{text_len}({best_ep})\"\n",
    "        t = [(i) for i in range(para_size)]\n",
    "        try:\n",
    "            os.mkdir(path)\n",
    "        except:\n",
    "            pass \n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_time\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test time\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_test_time.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_acc\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test acc\")\n",
    "        for i in range(para_size):\n",
    "            if (i) == save_th[-1]:\n",
    "                plt.plot((i),result[\"test_acc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_acc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_auc\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test auc\")\n",
    "        for i in range(para_size):\n",
    "            if (i) == save_th[-1]:\n",
    "                plt.plot((i),result[\"test_auc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_auc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_avg_entr\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test avg entr\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_entr.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        #result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "        #result_ep.to_csv(f\"{path}/{title}_ep.csv\", index=False)\n",
    "        total_result = pd.concat([total_result,result],axis=0,ignore_index=True)            \n",
    "        del result\n",
    "    path = f\"result/_csv/{data}\"\n",
    "    title = f\"{data}_{model}_l{layer}base\"\n",
    "    total_result.to_csv(f\"{path}/{title}_ep.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e68ddd1",
   "metadata": {},
   "source": [
    "## 0308"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1e292bc",
   "metadata": {},
   "source": [
    "\n",
    "### fullpath baseline 多次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0c5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fullpath baseline\n",
    "### 2/22 - baseline: valid/test with fullpath\n",
    "### 2/26 - dbpedia\n",
    "### 2/28 - imdb 8:1:1\n",
    "### 3/08 - read more files\n",
    "### 3/20 - fullpath training now do shortcut/adaptive inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94d8c610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imdb_linearal_l5base512_5.log', 'imdb_linearal_l5base512_1.log', 'imdb_linearal_l5base512_3.log', 'imdb_linearal_l5base512_2.log', 'imdb_linearal_l5base512_0.log', 'imdb_linearal_l5base512_4.log']\n",
      "[4]\n",
      "[4]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 20 into shape (30,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/AL_main_new/result_plot.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B140.115.59.235/home/AL_main_new/result_plot.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=148'>149</a>\u001b[0m             list_test_time_th\u001b[39m.\u001b[39mappend(\u001b[39mfloat\u001b[39m(match[\u001b[39m1\u001b[39m]))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B140.115.59.235/home/AL_main_new/result_plot.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=149'>150</a>\u001b[0m \u001b[39mprint\u001b[39m(save_th)    \n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B140.115.59.235/home/AL_main_new/result_plot.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=150'>151</a>\u001b[0m ep_valid_time \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray(list_ep_valid_time)\u001b[39m.\u001b[39;49mreshape((epoch,\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B140.115.59.235/home/AL_main_new/result_plot.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=151'>152</a>\u001b[0m ep_valid_acc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(list_ep_valid_acc)\u001b[39m.\u001b[39mreshape((epoch,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B140.115.59.235/home/AL_main_new/result_plot.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=152'>153</a>\u001b[0m ep_valid_auc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(list_ep_valid_auc)\u001b[39m.\u001b[39mreshape((epoch,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 20 into shape (30,newaxis)"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "total_result = pd.DataFrame(columns=[])\n",
    "\n",
    "#data = \"ag_news\"\n",
    "#for text_len in [25,50,75,100,125,150,175]:\n",
    "\n",
    "#data = \"dbpedia_14\"\n",
    "#for text_len in [20,40,60]:\n",
    "\n",
    "data = \"imdb\"\n",
    "#for text_len in [100,200,300,400,500]:\n",
    "#for test_count in range(5):\n",
    "text_len = 500\n",
    "#text_len = 80\n",
    "#text_len = 177\n",
    "for model in [\"linearal\",\"lstmal\",\"transformeral\"]:\n",
    "    layer = 5\n",
    "    epoch = 20\n",
    "    lr = 0.0001\n",
    "    out_path = f\"result/0318/fullpath+sc_ad/{data}_{model}_l{layer}base512_pad{text_len}/\"\n",
    "\n",
    "    log_list = os.listdir(out_path)\n",
    "    print(log_list)\n",
    "    for log in log_list:\n",
    "        \n",
    "        result = pd.DataFrame(columns=[\"padding_size\"])\n",
    "        result_ep = pd.DataFrame(columns=[\"epoch\",\"ep_train_time\"])\n",
    "        result_ep[\"epoch\"] = [*range(epoch)]\n",
    "        list_acc = []\n",
    "        list_auc = []\n",
    "        list_f1 = []\n",
    "        list_entr = []\n",
    "        list_acc_th = []\n",
    "        list_auc_th = []\n",
    "        list_f1_th = []\n",
    "        list_entr_th = []\n",
    "        list_test_time = []\n",
    "        list_test_time_th = []\n",
    "        list_ep_train_time = []\n",
    "        list_ep_train_acc = []\n",
    "        list_ep_train_auc = []\n",
    "        list_ep_train_entr = []\n",
    "        list_ep_valid_time = []\n",
    "        list_ep_valid_acc = []\n",
    "        list_ep_valid_auc = []\n",
    "        list_ep_valid_entr = []\n",
    "        list_ep_valid_f1 = []\n",
    "        train_time = 0\n",
    "        init_time = 0\n",
    "        best_ep = -1\n",
    "        best_th = []\n",
    "        save_th = []\n",
    "        test_part = False\n",
    "        \n",
    "        #para_size = 1\n",
    "        para_size = 5+9\n",
    "        with open(out_path+log,mode='r') as log:\n",
    "            buffer = log.readlines()\n",
    "            df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "            df\n",
    "            \n",
    "            for line in buffer:\n",
    "                \n",
    "                \n",
    "                match = re.match(\"Start Testing\", line)\n",
    "                if match!=None:\n",
    "                    test_part = True\n",
    "                    \n",
    "                match = re.match('Save ckpt to (.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"ep \\d+\",match.group(0))\n",
    "                    best_ep = match[0]\n",
    "                    best_th.append(current_th)\n",
    "\n",
    "                match = re.match('init_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    init_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('(.)*valid_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    train_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_train_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_l\\d+_test_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_valid_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('Train Epoch\\d+ Acc(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_acc.append(float(match[0]))\n",
    "                    list_ep_train_auc.append(float(match[1]))\n",
    "                    #print(best_th)\n",
    "                    if len(best_th)>0:\n",
    "                        save_th = best_th\n",
    "                    best_th = []\n",
    "                    \n",
    "                match = re.match('Test Epoch\\d+ layer(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    #print(line)\n",
    "                    #print(match)\n",
    "                    \n",
    "                    list_ep_valid_acc.append(float(match[0]))\n",
    "                    list_ep_valid_auc.append(float(match[1]))\n",
    "                    list_ep_valid_entr.append(float(match[2]))\n",
    "                    list_ep_valid_f1.append(float(match[3]))\n",
    "                    \n",
    "                    match = re.findall('\\d+', line)\n",
    "                    current_th = int(match[1])\n",
    "                \n",
    "                ### testing part\n",
    "                match = re.match('Test layer\\d Acc(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    list_acc.append(float(match[0]))\n",
    "                    list_auc.append(float(match[1]))\n",
    "                    list_entr.append(float(match[2]))\n",
    "                    list_f1.append(float(match[3]))\n",
    "                    \n",
    "                match = re.match('l\\d+_test_time(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_test_time.append(float(match[0]))\n",
    "                \n",
    "                match = re.match('Test threshold(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    list_acc_th.append(float(match[1]))\n",
    "                    list_auc_th.append(float(match[2]))\n",
    "                    list_entr_th.append(float(match[3]))\n",
    "                    list_f1_th.append(float(match[4]))\n",
    "                    \n",
    "                match = re.match('t(.)*_test_time(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_test_time_th.append(float(match[1]))\n",
    "        print(save_th)    \n",
    "        ep_valid_time = np.array(list_ep_valid_time).reshape((epoch,-1))\n",
    "        ep_valid_acc = np.array(list_ep_valid_acc).reshape((epoch,-1))\n",
    "        ep_valid_auc = np.array(list_ep_valid_auc).reshape((epoch,-1))\n",
    "        ep_valid_entr = np.array(list_ep_valid_entr).reshape((epoch,-1))\n",
    "        ep_valid_f1 = np.array(list_ep_valid_entr).reshape((epoch,-1))\n",
    "        \n",
    "        result_ep[\"ep_train_acc\"] = list_ep_train_acc \n",
    "        result_ep[\"ep_train_auc\"] = list_ep_train_auc          \n",
    "        result_ep[\"ep_valid_time\"] = np.sum(ep_valid_time,-1) \n",
    "        result_ep[\"ep_valid_l4_time\"] = ep_valid_time\n",
    "        result_ep[\"ep_train_time\"] = list_ep_train_time \n",
    "        \n",
    "        \n",
    "        result['model'] = [model]*para_size\n",
    "        result['padding_size'] = [text_len]*para_size\n",
    "        #result[\"test_layer\"] = [(i) for i in range(para_size)]\n",
    "        result[\"test_setting\"] = [i for i in range(5)]+[0.1*(i+1) for i in range(9)]\n",
    "        result[\"test_acc\"] = list_acc + list_acc_th\n",
    "        result[\"test_auc\"] = list_auc + list_auc_th\n",
    "        result[\"test_f1\"] = list_f1 + list_f1_th\n",
    "        result[\"test_avg_entr\"] = list_entr + list_entr_th\n",
    "        result[\"test_time\"] = list_test_time + list_test_time_th\n",
    "        result[\"init_time\"] = [init_time]*para_size\n",
    "        result[\"train+valid_time\"] = [train_time]*para_size\n",
    "        result[\"train_time\"] = [result_ep[\"ep_train_time\"].sum()]*para_size\n",
    "        result[\"valid_time\"] = [result_ep[\"ep_valid_time\"].sum()]*para_size\n",
    "        result['best_ep'] = best_ep[3:]\n",
    "        #print(result)\n",
    "        #print(result_ep)\n",
    "        \"\"\"\n",
    "        path = f\"result/_csv/{data}\"\n",
    "        title = f\"{data}_{model}_l{layer}_pad{text_len}({best_ep})\"\n",
    "        t = [(i) for i in range(para_size)]\n",
    "        try:\n",
    "            os.mkdir(path)\n",
    "        except:\n",
    "            pass \n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_time\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test time\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_test_time.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_acc\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test acc\")\n",
    "        for i in range(para_size):\n",
    "            if (i) == save_th[-1]:\n",
    "                plt.plot((i),result[\"test_acc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_acc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_auc\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test auc\")\n",
    "        for i in range(para_size):\n",
    "            if (i) == save_th[-1]:\n",
    "                plt.plot((i),result[\"test_auc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_auc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_avg_entr\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test avg entr\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_entr.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        #result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "        #result_ep.to_csv(f\"{path}/{title}_ep.csv\", index=False)\n",
    "        total_result = pd.concat([total_result,result],axis=0,ignore_index=True)            \n",
    "        del result\n",
    "path = f\"result/_csv/{data}\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "title = f\"{data}_l{layer}base_512\"\n",
    "total_result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a60f5d6",
   "metadata": {},
   "source": [
    "### adapt 多次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e868a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "total_result = pd.DataFrame(columns=[])\n",
    "\n",
    "### 2/04 - valid/test 80%:20%\n",
    "###      - save_path unique for test load\n",
    "###      - \"lstmal\",\"linearal\",\"transformeral\" adapt valid pad save best auc\n",
    "### 2/08 - valid/test 50%:50%\n",
    "#data = \"ag_news\"\n",
    "#for text_len in [25,50,75,100,125,150,175]:\n",
    "#for text_len in [50,75,100,125,150,175]:\n",
    "### 2/18 - dbpedia\n",
    "#data = \"dbpedia_14\"\n",
    "#for text_len in [20,40,60]:\n",
    "data = \"imdb\"\n",
    "\n",
    "text_len = 500\n",
    "#text_len = 177\n",
    "for model in [\"lstmal\",\"linearal\",\"transformeral\"]:\n",
    "    layer = 5\n",
    "    epoch = 30\n",
    "    lr = 0.0001\n",
    "    save_path = f\"ckpt/{data}_{model}_l{layer}ad_pad{text_len}/\"\n",
    "    out_path = f\"result/0315/timer fixed/imdb/{data}_{model}_l{layer}ad_pad{text_len}/\"\n",
    "    log_list = os.listdir(out_path)\n",
    "    print(log_list)\n",
    "    for log in log_list:\n",
    "        \n",
    "        result = pd.DataFrame(columns=[\"padding_size\"])\n",
    "        result_ep = pd.DataFrame(columns=[\"epoch\",\"ep_train_time\"])\n",
    "        result_ep[\"epoch\"] = [*range(epoch)]\n",
    "        list_acc = []\n",
    "        list_auc = []\n",
    "        list_entr = []\n",
    "        list_f1 = []\n",
    "        list_test_time = []\n",
    "        list_ep_train_time = []\n",
    "        list_ep_train_acc = []\n",
    "        list_ep_train_auc = []\n",
    "        list_ep_train_entr = []\n",
    "        list_ep_valid_time = []\n",
    "        list_ep_valid_acc = []\n",
    "        list_ep_valid_auc = []\n",
    "        list_ep_valid_entr = []\n",
    "        train_time = 0\n",
    "        init_time = 0\n",
    "        best_ep = -1\n",
    "        best_th = []\n",
    "        save_th = []\n",
    "        with open(out_path+log,mode='r') as log:\n",
    "            buffer = log.readlines()\n",
    "            df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "            df\n",
    "            \n",
    "            for line in buffer:\n",
    "                \n",
    "                \n",
    "                match = re.match('Save ckpt to (.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"ep \\d+\",match.group(0))\n",
    "                    best_ep = match[0]\n",
    "                    best_th.append(current_th)\n",
    "                match = re.match('Test threshold(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    list_acc.append(float(match[1]))\n",
    "                    list_auc.append(float(match[2]))\n",
    "                    list_entr.append(float(match[3]))\n",
    "                    list_f1.append(float(match[4]))\n",
    "                    \n",
    "\n",
    "                match = re.match('t(.)*_test_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_test_time.append(float(match[1]))\n",
    "\n",
    "                match = re.match('init_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    init_time = float(match[0])\n",
    "                match = re.match('(.)*valid_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    train_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_train_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_t(.)*_test_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_valid_time.append(float(match[1]))\n",
    "                    \n",
    "                match = re.match('Train Epoch\\d+ Acc(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_acc.append(float(match[0]))\n",
    "                    list_ep_train_auc.append(float(match[1]))\n",
    "                    #print(best_th)\n",
    "                    if len(best_th)>0:\n",
    "                        save_th = best_th\n",
    "                    best_th = []\n",
    "                    \n",
    "                match = re.match('Test Epoch\\d+ threshold(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    #print(line)\n",
    "                    #print(match)\n",
    "                    current_th = int(float(match[0])*10)\n",
    "                    list_ep_valid_acc.append(float(match[1]))\n",
    "                    list_ep_valid_auc.append(float(match[2]))\n",
    "                    list_ep_valid_entr.append(float(match[3]))\n",
    "        print(save_th)    \n",
    "        ep_valid_time = np.array(list_ep_valid_time).reshape((epoch,-1))\n",
    "        ep_valid_acc = np.array(list_ep_valid_acc).reshape((epoch,-1))\n",
    "        ep_valid_auc = np.array(list_ep_valid_auc).reshape((epoch,-1))\n",
    "        ep_valid_entr = np.array(list_ep_valid_entr).reshape((epoch,-1))\n",
    "        \n",
    "        result_ep[\"ep_train_acc\"] = list_ep_train_acc \n",
    "        result_ep[\"ep_train_auc\"] = list_ep_train_auc          \n",
    "        \n",
    "        result_ep[\"ep_valid_time\"] = np.sum(ep_valid_time,-1) \n",
    "        result_ep[[f\"ep_valid.{(i+1)}_time\" for i in range(9)]] = ep_valid_time\n",
    "        result_ep[\"ep_train_time\"] = list_ep_train_time \n",
    "        \n",
    "        para_size = 9\n",
    "        result['model'] = [model]*para_size\n",
    "        result['padding_size'] = [text_len]*para_size\n",
    "        result[\"test_threshold\"] = [(1+i)*0.1 for i in range(para_size)]\n",
    "        result[\"best_ep\"] = [best_ep[2:]]*para_size\n",
    "        result[\"best_th\"] = [save_th]*para_size\n",
    "        result[\"best_acc_setting\"] = [list_acc[save_th[-1]-1]]*para_size\n",
    "        result[\"best_auc_setting\"] = [list_auc[save_th[-1]-1]]*para_size\n",
    "        result[\"best_f1_setting\"] = [list_f1[save_th[-1]-1]]*para_size\n",
    "        result[\"best_entr_setting\"] = [list_entr[save_th[-1]-1]]*para_size\n",
    "        result[\"test_time_setting\"] = [list_test_time[save_th[-1]-1]]*para_size\n",
    "        result[\"test_acc\"] = list_acc\n",
    "        result[\"test_auc\"] = list_auc\n",
    "        result[\"test_f1\"] = list_f1\n",
    "        result[\"test_avg_entr\"] = list_entr\n",
    "        result[\"test_time\"] = list_test_time\n",
    "        result[\"init_time\"] = [init_time]*para_size\n",
    "        result[\"train+valid_time\"] = [train_time]*para_size\n",
    "        result[\"train_time\"] = [result_ep[\"ep_train_time\"].sum()]*para_size\n",
    "        result[\"valid_time\"] = [result_ep[\"ep_valid_time\"].sum()]*para_size\n",
    "        #print(result)\n",
    "        #print(result_ep)\n",
    "\n",
    "        path = f\"result/_csv/{data}/base_ad/\"\n",
    "        title = f\"{data}_{model}_l{layer}ad_pad{text_len}({best_ep})\"\n",
    "        os.makedirs(path,exist_ok=True)\n",
    "        \"\"\"\n",
    "        t = [0.1*(i+1) for i in range(9)]\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_time\"],\"o-\") \n",
    "        plt.xlabel(\"threshold\")\n",
    "        plt.ylabel(\"test time\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_test_time.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_acc\"],\"o-\") \n",
    "        plt.xlabel(\"threshold\")\n",
    "        plt.ylabel(\"test acc\")\n",
    "        for i in range(9):\n",
    "            if (i+1) in save_th:\n",
    "                plt.plot((i+1)/10,result[\"test_acc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_acc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_auc\"],\"o-\") \n",
    "        plt.xlabel(\"threshold\")\n",
    "        plt.ylabel(\"test auc\")\n",
    "        for i in range(9):\n",
    "            if (i+1) in save_th:\n",
    "                plt.plot((i+1)/10,result[\"test_auc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_auc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_avg_entr\"],\"o-\") \n",
    "        plt.xlabel(\"threshold\")\n",
    "        plt.ylabel(\"test avg entr\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_entr.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        #result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "        #result_ep.to_csv(f\"{path}/{title}_ep.csv\", index=False)\n",
    "        total_result = pd.concat([total_result,result],axis=0,ignore_index=True)            \n",
    "        del result\n",
    "\n",
    "title = f\"{data}_l{layer}ad\"\n",
    "total_result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a95707a4",
   "metadata": {},
   "source": [
    "### shortcut 多次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5220f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "total_result = pd.DataFrame(columns=[])\n",
    "\n",
    "### baseline shortcut\n",
    "\n",
    "### 2/04 - valid/test 80%:20%\n",
    "###      - baseline\n",
    "### 2/14 - valid/test 50%:50%\n",
    "#data = \"ag_news\"\n",
    "#for text_len in [25,50,75,100,125,150,175]:\n",
    "### 2/18 - dbpedia\n",
    "#data = \"dbpedia_14\"\n",
    "#for text_len in [20,40,60]:\n",
    "### 2/28 - imdb 8:1:1\n",
    "data = \"imdb\"\n",
    "#for text_len in [100,200,300,400,500]:\n",
    "\n",
    "text_len = 500\n",
    "#text_len = 177\n",
    "for model in [\"linearal\",\"lstmal\",\"transformeral\",]:\n",
    "    layer = 5\n",
    "    epoch = 30\n",
    "    lr = 0.0001\n",
    "    save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "    out_path = f\"result/0315/timer fixed/imdb/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "    log_list = os.listdir(out_path)\n",
    "    print(log_list)\n",
    "    for log in log_list:\n",
    "        result = pd.DataFrame(columns=[\"padding_size\"])\n",
    "        result_ep = pd.DataFrame(columns=[\"epoch\",\"ep_train_time\"])\n",
    "        result_ep[\"epoch\"] = [*range(epoch)]\n",
    "        list_acc = []\n",
    "        list_auc = []\n",
    "        list_f1 = []\n",
    "        list_entr = []\n",
    "        list_test_time = []\n",
    "        list_ep_train_time = []\n",
    "        list_ep_train_acc = []\n",
    "        list_ep_train_auc = []\n",
    "        list_ep_train_entr = []\n",
    "        list_ep_valid_time = []\n",
    "        list_ep_valid_acc = []\n",
    "        list_ep_valid_auc = []\n",
    "        list_ep_valid_entr = []\n",
    "        train_time = 0\n",
    "        init_time = 0\n",
    "        best_ep = -1\n",
    "        best_th = []\n",
    "        save_th = []\n",
    "        test_part = False\n",
    "        \n",
    "        para_size = 5\n",
    "        with open(out_path + log,mode='r') as log:\n",
    "            buffer = log.readlines()\n",
    "            df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "            df\n",
    "            \n",
    "            for line in buffer:\n",
    "                \n",
    "                \n",
    "                match = re.match(\"Start Testing\", line)\n",
    "                if match!=None:\n",
    "                    test_part = True\n",
    "                    \n",
    "                match = re.match('Save ckpt to (.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"ep \\d+\",match.group(0))\n",
    "                    best_ep = match[0]\n",
    "                    best_th.append(current_th)\n",
    "                \n",
    "                match = re.match('Test layer\\d+(.)*', line)    \n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    list_acc.append(float(match[0]))\n",
    "                    list_auc.append(float(match[1]))\n",
    "                    list_entr.append(float(match[2]))\n",
    "                    list_f1.append(float(match[3]))\n",
    "                    \n",
    "\n",
    "                match = re.match('l\\d+_test_time(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_test_time.append(float(match[0]))\n",
    "\n",
    "                match = re.match('init_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    init_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('(.)*valid_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    train_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_train_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_l\\d+_test_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_valid_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('Train Epoch\\d+ Acc(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_acc.append(float(match[0]))\n",
    "                    list_ep_train_auc.append(float(match[1]))\n",
    "                    #print(best_th)\n",
    "                    if len(best_th)>0:\n",
    "                        save_th = best_th\n",
    "                    best_th = []\n",
    "                    \n",
    "                match = re.match('Test Epoch\\d+ layer(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    #print(line)\n",
    "                    #print(match)\n",
    "                    \n",
    "                    list_ep_valid_acc.append(float(match[0]))\n",
    "                    list_ep_valid_auc.append(float(match[1]))\n",
    "                    list_ep_valid_entr.append(float(match[2]))\n",
    "                    \n",
    "                    match = re.findall('\\d+', line)\n",
    "                    current_th = int(match[1])\n",
    "        print(save_th)    \n",
    "        ep_valid_time = np.array(list_ep_valid_time).reshape((epoch,-1))\n",
    "        ep_valid_acc = np.array(list_ep_valid_acc).reshape((epoch,-1))\n",
    "        ep_valid_auc = np.array(list_ep_valid_auc).reshape((epoch,-1))\n",
    "        ep_valid_entr = np.array(list_ep_valid_entr).reshape((epoch,-1))\n",
    "        \n",
    "        result_ep[\"ep_train_acc\"] = list_ep_train_acc \n",
    "        result_ep[\"ep_train_auc\"] = list_ep_train_auc          \n",
    "        \n",
    "        result_ep[\"ep_valid_time\"] = np.sum(ep_valid_time,-1) \n",
    "        result_ep[[f\"ep_valid_l{i}_time\" for i in range(para_size)]] = ep_valid_time\n",
    "        result_ep[\"ep_train_time\"] = list_ep_train_time \n",
    "        \n",
    "        \n",
    "        result['model'] = [model]*para_size\n",
    "        result['padding_size'] = [text_len]*para_size\n",
    "        result[\"test_layer\"] = [(i) for i in range(para_size)]\n",
    "        result[\"best_ep\"] = [best_ep[2:]]*para_size\n",
    "        result[\"best_th\"] = [save_th]*para_size\n",
    "        result[\"best_acc_setting\"] = [list_acc[save_th[-1]]]*para_size\n",
    "        result[\"best_auc_setting\"] = [list_auc[save_th[-1]]]*para_size\n",
    "        result[\"best_f1_setting\"] = [list_f1[save_th[-1]]]*para_size\n",
    "        result[\"best_entr_setting\"] = [list_entr[save_th[-1]]]*para_size\n",
    "        result[\"test_time_setting\"] = [list_test_time[save_th[-1]]]*para_size\n",
    "        result[\"test_acc\"] = list_acc\n",
    "        result[\"test_auc\"] = list_auc\n",
    "        result[\"test_f1\"] = list_f1\n",
    "        result[\"test_avg_entr\"] = list_entr\n",
    "        result[\"test_time\"] = list_test_time\n",
    "        result[\"init_time\"] = [init_time]*para_size\n",
    "        result[\"train+valid_time\"] = [train_time]*para_size\n",
    "        result[\"train_time\"] = [result_ep[\"ep_train_time\"].sum()]*para_size\n",
    "        result[\"valid_time\"] = [result_ep[\"ep_valid_time\"].sum()]*para_size\n",
    "        #print(result)\n",
    "        #print(result_ep)\n",
    "\n",
    "        path = f\"result/_csv/{data}/base_sc/\"\n",
    "        title = f\"{data}_{model}_l{layer}_pad{text_len}({best_ep})\"\n",
    "        t = [(i) for i in range(para_size)]\n",
    "        \n",
    "        os.makedirs(path,exist_ok=True)\n",
    "\n",
    "        \"\"\"\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_time\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test time\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_test_time.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_acc\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test acc\")\n",
    "        for i in range(para_size):\n",
    "            if (i) == save_th[-1]:\n",
    "                plt.plot((i),result[\"test_acc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_acc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_auc\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test auc\")\n",
    "        for i in range(para_size):\n",
    "            if (i) == save_th[-1]:\n",
    "                plt.plot((i),result[\"test_auc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_auc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_avg_entr\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test avg entr\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_entr.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        #result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "        #result_ep.to_csv(f\"{path}/{title}_ep.csv\", index=False)\n",
    "        total_result = pd.concat([total_result,result],axis=0,ignore_index=True)            \n",
    "        del result\n",
    "    \n",
    "title = f\"{data}_l{layer}\"\n",
    "total_result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc6dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df82679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e2251b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53db5bde",
   "metadata": {},
   "source": [
    "### side adapt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e968794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imdb_transformeralside_l5_256_sidead_2.log', 'imdb_transformeralside_l5_256_sidead_8.log', 'imdb_transformeralside_l5_256_sidead_0.log', 'imdb_transformeralside_l5_256_sidead_4.log', 'imdb_transformeralside_l5_256_sidead_6.log', 'imdb_transformeralside_l5_256_sidead_5.log', 'imdb_transformeralside_l5_256_sidead_1.log', 'imdb_transformeralside_l5_256_sidead_3.log', 'imdb_transformeralside_l5_256_sidead_7.log']\n",
      "[4]\n",
      "\n",
      "[3, 4]\n",
      "\n",
      "[1, 2, 3, 4]\n",
      "\n",
      "[2, 3, 4]\n",
      "\n",
      "[2, 3, 4]\n",
      "\n",
      "[2, 3, 4]\n",
      "\n",
      "[2, 3]\n",
      "\n",
      "[4]\n",
      "\n",
      "[2, 3]\n",
      "\n",
      "['imdb_linearalside_l5_256_sidead_6.log', 'imdb_linearalside_l5_256_sidead_5.log', 'imdb_linearalside_l5_256_sidead_4.log', 'imdb_linearalside_l5_256_sidead_7.log', 'imdb_linearalside_l5_256_sidead_8.log', 'imdb_linearalside_l5_256_sidead_1.log', 'imdb_linearalside_l5_256_sidead_2.log', 'imdb_linearalside_l5_256_sidead_3.log', 'imdb_linearalside_l5_256_sidead_0.log']\n",
      "[3]\n",
      "\n",
      "[0]\n",
      "\n",
      "[2]\n",
      "\n",
      "[2]\n",
      "\n",
      "[1]\n",
      "\n",
      "[0]\n",
      "\n",
      "[0]\n",
      "\n",
      "[1]\n",
      "\n",
      "[0]\n",
      "\n",
      "['imdb_lstmalside_l5_256_sidead_3.log', 'imdb_lstmalside_l5_256_sidead_8.log', 'imdb_lstmalside_l5_256_sidead_1.log', 'imdb_lstmalside_l5_256_sidead_2.log', 'imdb_lstmalside_l5_256_sidead_7.log', 'imdb_lstmalside_l5_256_sidead_5.log', 'imdb_lstmalside_l5_256_sidead_6.log', 'imdb_lstmalside_l5_256_sidead_0.log', 'imdb_lstmalside_l5_256_sidead_4.log']\n",
      "[2, 3, 4]\n",
      "\n",
      "[2, 3, 4]\n",
      "\n",
      "[2, 3, 4]\n",
      "\n",
      "[2, 3]\n",
      "\n",
      "[2]\n",
      "\n",
      "[2, 3, 4]\n",
      "\n",
      "[2, 3]\n",
      "\n",
      "[2, 3, 4]\n",
      "\n",
      "[3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "total_result = pd.DataFrame(columns=[])\n",
    "\n",
    "#data = \"ag_news\"\n",
    "#for text_len in [25,50,75,100,125,150,175]:\n",
    "\n",
    "#data = \"dbpedia_14\"\n",
    "#for text_len in [20,40,60]:\n",
    "\n",
    "data = \"imdb\"\n",
    "#for text_len in [100,200,300,400,500]:\n",
    "#for test_count in range(5):\n",
    "text_len = 200\n",
    "#text_len = 80\n",
    "#text_len = 175\n",
    "for model in [\"transformeralside\",\"linearalside\",\"lstmalside\"]:\n",
    "    layer = 5\n",
    "    epoch = 50\n",
    "    lr = 0.0005\n",
    "    out_path = f\"result/0328/256 200 0.0005/{data}_{model}_l{layer}_256_sidead/\"\n",
    "    log_list = os.listdir(out_path)\n",
    "    print(log_list)\n",
    "    for log in log_list:\n",
    "        \n",
    "        result = pd.DataFrame(columns=[\"padding_size\"])\n",
    "        result_ep = pd.DataFrame(columns=[\"epoch\",\"ep_train_time\"])\n",
    "        result_ep[\"epoch\"] = [*range(epoch)]\n",
    "        list_acc = []\n",
    "        list_auc = []\n",
    "        list_f1 = []\n",
    "        list_entr = []\n",
    "        list_acc_th = []\n",
    "        list_auc_th = []\n",
    "        list_f1_th = []\n",
    "        list_entr_th = []\n",
    "        list_test_time = []\n",
    "        list_test_time_th = []\n",
    "        list_ep_train_time = []\n",
    "        list_ep_train_acc = []\n",
    "        list_ep_train_auc = []\n",
    "        list_ep_train_entr = []\n",
    "        list_ep_valid_time = []\n",
    "        list_ep_valid_acc = []\n",
    "        list_ep_valid_auc = []\n",
    "        list_ep_valid_entr = []\n",
    "        list_ep_valid_f1 = []\n",
    "        train_time = 0\n",
    "        init_time = 0\n",
    "        best_ep = -1\n",
    "        best_th = []\n",
    "        save_th = []\n",
    "        test_part = False\n",
    "        \n",
    "        #para_size = 1\n",
    "        para_size = 5+9\n",
    "        with open(out_path+log,mode='r') as log:\n",
    "            buffer = log.readlines()\n",
    "            df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "            df\n",
    "            \n",
    "            for line in buffer:\n",
    "                \n",
    "                \n",
    "                match = re.match(\"Start Testing\", line)\n",
    "                if match!=None:\n",
    "                    test_part = True\n",
    "                    \n",
    "                match = re.match('Save ckpt to (.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"ep \\d+\",match.group(0))\n",
    "                    best_ep = match[0]\n",
    "                    best_th.append(current_th)\n",
    "\n",
    "                match = re.match('init_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    init_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('(.)*valid_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    train_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_train_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_l\\d+_test_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_valid_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('Train Epoch\\d+ Acc(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_acc.append(float(match[0]))\n",
    "                    list_ep_train_auc.append(float(match[1]))\n",
    "                    #print(best_th)\n",
    "                    if len(best_th)>0:\n",
    "                        save_th = best_th\n",
    "                    best_th = []\n",
    "                    \n",
    "                match = re.match('Test Epoch\\d+ layer(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    #print(line)\n",
    "                    #print(match)\n",
    "                    \n",
    "                    list_ep_valid_acc.append(float(match[0]))\n",
    "                    list_ep_valid_auc.append(float(match[1]))\n",
    "                    list_ep_valid_entr.append(float(match[2]))\n",
    "                    list_ep_valid_f1.append(float(match[3]))\n",
    "                    \n",
    "                    match = re.findall('\\d+', line)\n",
    "                    current_th = int(match[1])\n",
    "                \n",
    "                ### testing part\n",
    "                match = re.match('Test layer\\d Acc(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    list_acc.append(float(match[0]))\n",
    "                    list_auc.append(float(match[1]))\n",
    "                    list_entr.append(float(match[2]))\n",
    "                    list_f1.append(float(match[3]))\n",
    "                    \n",
    "                match = re.match('l\\d+_test_time(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_test_time.append(float(match[0]))\n",
    "                \n",
    "                match = re.match('Test threshold(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    list_acc_th.append(float(match[1]))\n",
    "                    list_auc_th.append(float(match[2]))\n",
    "                    list_entr_th.append(float(match[3]))\n",
    "                    list_f1_th.append(float(match[4]))\n",
    "                    \n",
    "                match = re.match('t(.)*_test_time(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_test_time_th.append(float(match[1]))\n",
    "        print(save_th)    \n",
    "        \n",
    "        ep_valid_time = np.array(list_ep_valid_time).reshape((epoch,-1))\n",
    "        ep_valid_acc = np.array(list_ep_valid_acc).reshape((epoch,-1))\n",
    "        ep_valid_auc = np.array(list_ep_valid_auc).reshape((epoch,-1))\n",
    "        ep_valid_entr = np.array(list_ep_valid_entr).reshape((epoch,-1))\n",
    "        ep_valid_f1 = np.array(list_ep_valid_entr).reshape((epoch,-1))\n",
    "        print()    \n",
    "        result_ep[\"ep_train_acc\"] = list_ep_train_acc \n",
    "        result_ep[\"ep_train_auc\"] = list_ep_train_auc          \n",
    "        result_ep[\"ep_valid_time\"] = np.sum(ep_valid_time,-1) \n",
    "        #result_ep[\"ep_valid_l4_time\"] = ep_valid_time\n",
    "        result_ep[\"ep_train_time\"] = list_ep_train_time \n",
    "        \n",
    "        \n",
    "        result['model'] = [model]*para_size\n",
    "        result['padding_size'] = [text_len]*para_size\n",
    "        #result[\"test_layer\"] = [(i) for i in range(para_size)]\n",
    "        result[\"test_setting\"] = [i for i in range(5)]+[0.1*(i+1) for i in range(9)]\n",
    "        result[\"test_acc\"] = list_acc + list_acc_th\n",
    "        result[\"test_auc\"] = list_auc + list_auc_th\n",
    "        result[\"test_f1\"] = list_f1 + list_f1_th\n",
    "        result[\"test_avg_entr\"] = list_entr + list_entr_th\n",
    "        result[\"test_time\"] = list_test_time + list_test_time_th\n",
    "        result[\"init_time\"] = [init_time]*para_size\n",
    "        result[\"train+valid_time\"] = [train_time]*para_size\n",
    "        result[\"train_time\"] = [result_ep[\"ep_train_time\"].sum()]*para_size\n",
    "        result[\"valid_time\"] = [result_ep[\"ep_valid_time\"].sum()]*para_size\n",
    "        result['best_ep'] = best_ep[3:]\n",
    "        #print(result)\n",
    "        #print(result_ep)\n",
    "        #result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "        #result_ep.to_csv(f\"{path}/{title}_ep.csv\", index=False)\n",
    "        total_result = pd.concat([total_result,result],axis=0,ignore_index=True)            \n",
    "        del result\n",
    "path = f\"result/_csv/{data}\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "title = f\"{data}_l{layer}side200\"\n",
    "total_result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8bf263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
