{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91685f81",
   "metadata": {},
   "source": [
    "## 0208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e97f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "data = \"dbpedia_14\"\n",
    "text_len = 60\n",
    "model = \"transformeral\"\n",
    "layer = 5\n",
    "epoch = 10\n",
    "lr = 0.0001\n",
    "fix_previous_layer = True\n",
    "#for mask in range(1,1+layer):\n",
    "mask = 5\n",
    "save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}_m{mask}/\"  \n",
    "#load_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}_m{mask-1}/\" \n",
    "out_path = f\"result/0117/fix train adapt/{data}_{model}_l{layer}ad_pad{text_len}_m{mask}/\"\n",
    "log = f\"{out_path}/{data}_{model}_l{layer}.log\"\n",
    "\n",
    "with open(log,mode='r') as log:\n",
    "    buffer = log.readlines()\n",
    "    df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "class history(object):\n",
    "    def __init__(self):\n",
    "        self.auc = {}\n",
    "        self.acc = {}\n",
    "        self.entr = {}\n",
    "        for threshold in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "            self.auc[threshold] = []\n",
    "            self.acc[threshold] = []\n",
    "            self.entr[threshold] = []\n",
    "            \n",
    "result = history()\n",
    "for line in buffer:\n",
    "    match = re.match('Test Epoch(.)*', line)\n",
    "    if match!=None:\n",
    "        print(match.group())\n",
    "        match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "        print(match)\n",
    "        threshold = float(match[0])\n",
    "        result.acc[threshold].append(match[1])\n",
    "        result.auc[threshold].append(match[2])\n",
    "        result.entr[threshold].append(match[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "    print(len(result.acc[threshold]))\n",
    "    print(len(result.auc[threshold]))\n",
    "    print(len(result.entr[threshold]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c6b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2/06 - valid/test 80%:20%\n",
    "###      - prefix\n",
    "###      - plot result\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "data = \"ag_news\"\n",
    "text_len = 175\n",
    "\n",
    "\n",
    "for model in [\"linearal\",\"lstmal\",\"transformeral\"]:\n",
    "    result = [[] for _ in range(4)]\n",
    "    for threshold in [.1,.2,.3,.4,.5,.6,.7,.8,.9]:\n",
    "\n",
    "        layer = 5\n",
    "        epoch = 10\n",
    "        lr = 0.0001\n",
    "        fix_previous_layer = False\n",
    "        \n",
    "        mask = 5\n",
    "        out_path = f\"result/0208/test/prefix/{data}_{model}_l{layer}adp_pad{text_len}_t{threshold}_m{mask}_test/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}.log\"\n",
    "            \n",
    "        with open(log,mode='r') as log:\n",
    "            buffer = log.readlines()\n",
    "            df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "            df\n",
    "            \n",
    "            for line in buffer:\n",
    "                match = re.match('Test threshold(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    #print(match[1])\n",
    "                    result[0].append(float(match[1]))\n",
    "                    result[1].append(float(match[2]))\n",
    "                    result[2].append(float(match[3]))\n",
    "            for line in buffer:\n",
    "                match = re.match('t(.)*_test_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    #print(match[1])\n",
    "                    result[3].append(float(match[1]))\n",
    "    print(\"\\n\",model)\n",
    "    for i in range(4):\n",
    "        print(i)\n",
    "        for v in result[i]:\n",
    "            print(v)                    \n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4e2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2/06 - valid/test 80%:20%\n",
    "###      - fix\n",
    "###      - plot result\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "data = \"ag_news\"\n",
    "text_len = 175\n",
    "\n",
    "for model in [\"linearal\",\"lstmal\",\"transformeral\"]:\n",
    "    result = [[] for _ in range(4)]\n",
    "    for threshold in [.1,.2,.3,.4,.5,.6,.7,.8,.9]:\n",
    "\n",
    "        layer = 5\n",
    "        epoch = 10\n",
    "        lr = 0.0001\n",
    "        fix_previous_layer = False\n",
    "        \n",
    "        mask = 5\n",
    "        out_path = f\"result/0208/test/fix/{data}_{model}_l{layer}adf_pad{text_len}_t{threshold}_m{mask}_test/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}.log\"\n",
    "            \n",
    "        with open(log,mode='r') as log:\n",
    "            buffer = log.readlines()\n",
    "            df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "            df\n",
    "            \n",
    "            for line in buffer:\n",
    "                match = re.match('Test threshold(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    #print(match[1])\n",
    "                    result[0].append(float(match[1]))\n",
    "                    result[1].append(float(match[2]))\n",
    "                    result[2].append(float(match[3]))\n",
    "            for line in buffer:\n",
    "                match = re.match('t(.)*_test_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    #print(match[1])\n",
    "                    result[3].append(float(match[1]))\n",
    "    print(\"\\n\",model)\n",
    "    for i in range(4):\n",
    "        print(i)\n",
    "        for v in result[i]:\n",
    "            print(v)                    \n",
    "\n",
    "                    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab581dd2",
   "metadata": {},
   "source": [
    "## 0214\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1418cc62",
   "metadata": {},
   "source": [
    "### base adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc003623",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 0214\n",
    "### pad base adapt \n",
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for model in [\"lstmal\"]:\n",
    "for model in [\"lstmal\",\"linearal\",\"transformeral\"]:\n",
    "    total_result = pd.DataFrame(columns=['padding_size', 'model', 'test_threshold', 'test_acc', 'test_auc',\n",
    "                                        'test_avg_entr', 'test_time'])\n",
    "    #data = \"ag_news\"\n",
    "    #for text_len in [25,50,75,100,125,150,175]:\n",
    "    data = \"dbpedia_14\"\n",
    "    for text_len in [20,40,60]:\n",
    "        layer = 5\n",
    "        epoch = 50\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}ad_pad{text_len}/\"\n",
    "        #out_path = f\"result/0220/ag_news/base adapt/{data}_{model}_l{layer}ad_pad{text_len}/\"\n",
    "        out_path = f\"result/0220/dbpedia_14/base adapt/{data}_{model}_l{layer}ad_pad{text_len}/\"\n",
    "        \"result/0220/dbpedia/base adapt/dbpedia_14_linearal_l5ad_pad20/dbpedia_14_linearal_l5.log\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}.log\"\n",
    "        \n",
    "        result = pd.DataFrame(columns=[\"padding_size\"])\n",
    "        result_ep = pd.DataFrame(columns=[\"epoch\",\"ep_train_time\"])\n",
    "        result_ep[\"epoch\"] = [*range(epoch)]\n",
    "        list_acc = []\n",
    "        list_auc = []\n",
    "        list_entr = []\n",
    "        list_test_time = []\n",
    "        list_ep_train_time = []\n",
    "        list_ep_train_acc = []\n",
    "        list_ep_train_auc = []\n",
    "        list_ep_train_entr = []\n",
    "        list_ep_valid_time = []\n",
    "        list_ep_valid_acc = []\n",
    "        list_ep_valid_auc = []\n",
    "        list_ep_valid_entr = []\n",
    "        train_time = 0\n",
    "        init_time = 0\n",
    "        best_ep = -1\n",
    "        best_th = []\n",
    "        save_th = []\n",
    "        with open(log,mode='r') as log:\n",
    "            buffer = log.readlines()\n",
    "            df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "            df\n",
    "            \n",
    "            for line in buffer:\n",
    "                \n",
    "                \n",
    "                match = re.match('Save ckpt to (.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"ep \\d+\",match.group(0))\n",
    "                    best_ep = match[0]\n",
    "                    best_th.append(current_th)\n",
    "                match = re.match('Test threshold(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    list_acc.append(float(match[1]))\n",
    "                    list_auc.append(float(match[2]))\n",
    "                    list_entr.append(float(match[3]))\n",
    "                    \n",
    "\n",
    "                match = re.match('t(.)*_test_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_test_time.append(float(match[1]))\n",
    "\n",
    "                match = re.match('init_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    init_time = float(match[0])\n",
    "                match = re.match('(.)*valid_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    train_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_train_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_t(.)*_test_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_valid_time.append(float(match[1]))\n",
    "                    \n",
    "                match = re.match('Train Epoch\\d+ Acc(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_acc.append(float(match[0]))\n",
    "                    list_ep_train_auc.append(float(match[1]))\n",
    "                    #print(best_th)\n",
    "                    if len(best_th)>0:\n",
    "                        save_th = best_th\n",
    "                    best_th = []\n",
    "                    \n",
    "                match = re.match('Test Epoch\\d+ threshold(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    #print(line)\n",
    "                    #print(match)\n",
    "                    current_th = int(float(match[0])*10)\n",
    "                    list_ep_valid_acc.append(float(match[1]))\n",
    "                    list_ep_valid_auc.append(float(match[2]))\n",
    "                    list_ep_valid_entr.append(float(match[3]))\n",
    "        print(save_th)    \n",
    "        ep_valid_time = np.array(list_ep_valid_time).reshape((epoch,-1))\n",
    "        ep_valid_acc = np.array(list_ep_valid_acc).reshape((epoch,-1))\n",
    "        ep_valid_auc = np.array(list_ep_valid_auc).reshape((epoch,-1))\n",
    "        ep_valid_entr = np.array(list_ep_valid_entr).reshape((epoch,-1))\n",
    "        \n",
    "        result_ep[\"ep_train_acc\"] = list_ep_train_acc \n",
    "        result_ep[\"ep_train_auc\"] = list_ep_train_auc          \n",
    "        \n",
    "        result_ep[\"ep_valid_time\"] = np.sum(ep_valid_time,-1) \n",
    "        result_ep[[f\"ep_valid.{(i+1)}_time\" for i in range(9)]] = ep_valid_time\n",
    "        result_ep[\"ep_train_time\"] = list_ep_train_time \n",
    "        \n",
    "        para_size = 9\n",
    "        result['model'] = [model]*para_size\n",
    "        result['padding_size'] = [text_len]*para_size\n",
    "        result[\"test_threshold\"] = [(1+i)*0.1 for i in range(para_size)]\n",
    "        result[\"best_ep\"] = [best_ep[2:]]*para_size\n",
    "        result[\"best_th\"] = [save_th]*para_size\n",
    "        result[\"best_acc_setting\"] = [list_acc[save_th[-1]-1]]*para_size\n",
    "        result[\"best_auc_setting\"] = [list_auc[save_th[-1]-1]]*para_size\n",
    "        result[\"test_acc\"] = list_acc\n",
    "        result[\"test_auc\"] = list_auc\n",
    "        result[\"test_avg_entr\"] = list_entr\n",
    "        result[\"test_time\"] = list_test_time\n",
    "        result[\"init_time\"] = [init_time]*para_size\n",
    "        result[\"train+valid_time\"] = [train_time]*para_size\n",
    "        result[\"train_time\"] = [result_ep[\"ep_train_time\"].sum()]*para_size\n",
    "        result[\"valid_time\"] = [result_ep[\"ep_valid_time\"].sum()]*para_size\n",
    "        #print(result)\n",
    "        #print(result_ep)\n",
    "\n",
    "        path = f\"result/_csv/{data}/base_ad/\"\n",
    "        title = f\"{data}_{model}_l{layer}ad_pad{text_len}({best_ep})\"\n",
    "        os.makedirs(path,exist_ok=True)\n",
    "        \"\"\"\n",
    "        t = [0.1*(i+1) for i in range(9)]\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_time\"],\"o-\") \n",
    "        plt.xlabel(\"threshold\")\n",
    "        plt.ylabel(\"test time\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_test_time.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_acc\"],\"o-\") \n",
    "        plt.xlabel(\"threshold\")\n",
    "        plt.ylabel(\"test acc\")\n",
    "        for i in range(9):\n",
    "            if (i+1) in save_th:\n",
    "                plt.plot((i+1)/10,result[\"test_acc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_acc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_auc\"],\"o-\") \n",
    "        plt.xlabel(\"threshold\")\n",
    "        plt.ylabel(\"test auc\")\n",
    "        for i in range(9):\n",
    "            if (i+1) in save_th:\n",
    "                plt.plot((i+1)/10,result[\"test_auc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_auc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_avg_entr\"],\"o-\") \n",
    "        plt.xlabel(\"threshold\")\n",
    "        plt.ylabel(\"test avg entr\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_entr.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        #result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "        #result_ep.to_csv(f\"{path}/{title}_ep.csv\", index=False)\n",
    "        total_result = pd.concat([total_result,result],axis=0,ignore_index=True)            \n",
    "        del result\n",
    "\n",
    "    title = f\"{data}_{model}_l{layer}ad\"\n",
    "    total_result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9494d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d25fad4e",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebd86f0b",
   "metadata": {},
   "source": [
    "### base shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 0214\n",
    "### pad base sc\n",
    "### 0220 - ag_news/dbpedia_14 \n",
    "###      - testing log有誤 \"Test Epoch49 layer(.)*\"\n",
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for model in [\"lstmal\",\"linearal\",\"transformeral\"]:\n",
    "    total_result = pd.DataFrame(columns=['padding_size', 'model', 'test_acc', 'test_auc',\n",
    "                                        'test_time'])\n",
    "    #data = \"ag_news\"\n",
    "    #for text_len in [25,50,75,100,125,150,175]:\n",
    "    #data = \"dbpedia_14\"\n",
    "    #for text_len in [20,40,60]:\n",
    "    data = \"imdb\"\n",
    "    for text_len in [100,200,300,400,500]:    \n",
    "        layer = 5\n",
    "        epoch = 50\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        #out_path = f\"result/0220/ag_news/base sc/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        #out_path = f\"result/0220/dbpedia/base sc/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        out_path = f\"result/0220/imdb/base sc/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}.log\"\n",
    "        \n",
    "        result = pd.DataFrame(columns=[\"padding_size\"])\n",
    "        result_ep = pd.DataFrame(columns=[\"epoch\",\"ep_train_time\"])\n",
    "        result_ep[\"epoch\"] = [*range(epoch)]\n",
    "        list_acc = []\n",
    "        list_auc = []\n",
    "        list_entr = []\n",
    "        list_test_time = []\n",
    "        list_ep_train_time = []\n",
    "        list_ep_train_acc = []\n",
    "        list_ep_train_auc = []\n",
    "        list_ep_train_entr = []\n",
    "        list_ep_valid_time = []\n",
    "        list_ep_valid_acc = []\n",
    "        list_ep_valid_auc = []\n",
    "        list_ep_valid_entr = []\n",
    "        train_time = 0\n",
    "        init_time = 0\n",
    "        best_ep = -1\n",
    "        best_th = []\n",
    "        save_th = []\n",
    "        test_part = False\n",
    "        \n",
    "        para_size = 5\n",
    "        with open(log,mode='r') as log:\n",
    "            buffer = log.readlines()\n",
    "            df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "            df\n",
    "            \n",
    "            for line in buffer:\n",
    "                \n",
    "                \n",
    "                match = re.match(\"Start Testing\", line)\n",
    "                if match!=None:\n",
    "                    test_part = True\n",
    "                    \n",
    "                match = re.match('Save ckpt to (.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"ep \\d+\",match.group(0))\n",
    "                    best_ep = match[0]\n",
    "                    best_th.append(current_th)\n",
    "                \n",
    "                if data == \"imdb\":\n",
    "                    match = re.match('Test layer\\d+(.)*', line)    \n",
    "                else:    \n",
    "                    match = re.match('Test Epoch49 layer(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    list_acc.append(float(match[0]))\n",
    "                    list_auc.append(float(match[1]))\n",
    "                    list_entr.append(float(match[2]))\n",
    "                    \n",
    "                if data == \"imdb\":\n",
    "                    match = re.match('l\\d+_test_time(.)*', line)\n",
    "                else:    \n",
    "                    match = re.match('ep49_l\\d_test_time(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_test_time.append(float(match[0]))\n",
    "\n",
    "                match = re.match('init_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    init_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('(.)*valid_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    train_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_train_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_l\\d+_test_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_valid_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('Train Epoch\\d+ Acc(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_acc.append(float(match[0]))\n",
    "                    list_ep_train_auc.append(float(match[1]))\n",
    "                    #print(best_th)\n",
    "                    if len(best_th)>0:\n",
    "                        save_th = best_th\n",
    "                    best_th = []\n",
    "                    \n",
    "                match = re.match('Test Epoch\\d+ layer(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    #print(line)\n",
    "                    #print(match)\n",
    "                    \n",
    "                    list_ep_valid_acc.append(float(match[0]))\n",
    "                    list_ep_valid_auc.append(float(match[1]))\n",
    "                    list_ep_valid_entr.append(float(match[2]))\n",
    "                    \n",
    "                    match = re.findall('\\d+', line)\n",
    "                    current_th = int(match[1])\n",
    "        print(save_th)    \n",
    "        ep_valid_time = np.array(list_ep_valid_time).reshape((epoch,-1))\n",
    "        ep_valid_acc = np.array(list_ep_valid_acc).reshape((epoch,-1))\n",
    "        ep_valid_auc = np.array(list_ep_valid_auc).reshape((epoch,-1))\n",
    "        ep_valid_entr = np.array(list_ep_valid_entr).reshape((epoch,-1))\n",
    "        \n",
    "        result_ep[\"ep_train_acc\"] = list_ep_train_acc \n",
    "        result_ep[\"ep_train_auc\"] = list_ep_train_auc          \n",
    "        \n",
    "        result_ep[\"ep_valid_time\"] = np.sum(ep_valid_time,-1) \n",
    "        result_ep[[f\"ep_valid_l{i}_time\" for i in range(para_size)]] = ep_valid_time\n",
    "        result_ep[\"ep_train_time\"] = list_ep_train_time \n",
    "        \n",
    "        \n",
    "        result['model'] = [model]*para_size\n",
    "        result['padding_size'] = [text_len]*para_size\n",
    "        result[\"test_layer\"] = [(i) for i in range(para_size)]\n",
    "        result[\"best_ep\"] = [best_ep[2:]]*para_size\n",
    "        result[\"best_th\"] = [save_th]*para_size\n",
    "        result[\"best_acc_setting\"] = [list_acc[save_th[-1]-1]]*para_size\n",
    "        result[\"best_auc_setting\"] = [list_auc[save_th[-1]-1]]*para_size\n",
    "        result[\"test_acc\"] = list_acc\n",
    "        result[\"test_auc\"] = list_auc\n",
    "        result[\"test_avg_entr\"] = list_entr\n",
    "        result[\"test_time\"] = list_test_time\n",
    "        result[\"init_time\"] = [init_time]*para_size\n",
    "        result[\"train+valid_time\"] = [train_time]*para_size\n",
    "        result[\"train_time\"] = [result_ep[\"ep_train_time\"].sum()]*para_size\n",
    "        result[\"valid_time\"] = [result_ep[\"ep_valid_time\"].sum()]*para_size\n",
    "        #print(result)\n",
    "        #print(result_ep)\n",
    "\n",
    "        path = f\"result/_csv/{data}/base_sc/\"\n",
    "        title = f\"{data}_{model}_l{layer}_pad{text_len}({best_ep})\"\n",
    "        t = [(i) for i in range(para_size)]\n",
    "        \n",
    "        os.makedirs(path,exist_ok=True)\n",
    "\n",
    "        \"\"\"\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_time\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test time\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_test_time.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_acc\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test acc\")\n",
    "        for i in range(para_size):\n",
    "            if (i) == save_th[-1]:\n",
    "                plt.plot((i),result[\"test_acc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_acc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_auc\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test auc\")\n",
    "        for i in range(para_size):\n",
    "            if (i) == save_th[-1]:\n",
    "                plt.plot((i),result[\"test_auc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_auc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_avg_entr\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test avg entr\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_entr.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        #result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "        #result_ep.to_csv(f\"{path}/{title}_ep.csv\", index=False)\n",
    "        total_result = pd.concat([total_result,result],axis=0,ignore_index=True)            \n",
    "        del result\n",
    "    \n",
    "    title = f\"{data}_{model}_l{layer}\"\n",
    "    total_result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b7ba3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d52e358d",
   "metadata": {},
   "source": [
    "### fix/prefix adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c25b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"ag_news\"\n",
    "for model in [\"lstmal\",\"linearal\",\"transformeral\"]:\n",
    "    total_result = pd.DataFrame(columns=[])\n",
    "    for threshold in [.1,.2,.3,.4,.5,.6,.7,.8,.9]:\n",
    "        for text_len in [175]:\n",
    "            layer = 5\n",
    "            epoch = 10\n",
    "            lr = 0.0001\n",
    "            \n",
    "            result = pd.DataFrame(columns=[\"padding_size\"])\n",
    "            result_ep = pd.DataFrame(columns=[\"epoch\",\"ep_train_time\"])\n",
    "            result_ep[\"epoch\"] = [*range(epoch)]\n",
    "            list_acc = []\n",
    "            list_auc = []\n",
    "            list_entr = []\n",
    "            list_test_time = []\n",
    "            list_init_time = []\n",
    "            list_train_time = []\n",
    "            \n",
    "            for mask in range(1,1+layer):\n",
    "                save_path = f\"ckpt/{data}_{model}_l{layer}adf_pad{text_len}_t{threshold}_m{mask}/\"  \n",
    "                load_path = f\"ckpt/{data}_{model}_l{layer}adf_pad{text_len}_t{threshold}_m{mask-1}/\" \n",
    "                #out_path = f\"result/0220/ag_news/fix adapt/{data}_{model}_l{layer}adf_pad{text_len}_t{threshold}_m{mask}/\"\n",
    "                out_path = f\"result/0214/prefix adapt/{data}_{model}_l{layer}adf_pad{text_len}_t{threshold}_m{mask}/\"\n",
    "                log = f\"{out_path}/{data}_{model}_l{layer}.log\"\n",
    "                \n",
    "                with open(log,mode='r') as log:\n",
    "                    buffer = log.readlines()\n",
    "                    df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "                    df\n",
    "                    \n",
    "                    \n",
    "                    for line in buffer:\n",
    "                        match = re.match('Test threshold(.)*', line)\n",
    "                        if match!=None:\n",
    "                            match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                            list_acc.append(float(match[1]))\n",
    "                            list_auc.append(float(match[2]))\n",
    "                            list_entr.append(float(match[3]))\n",
    "\n",
    "                        match = re.match('t(.)*_test_time(.)*', line)\n",
    "                        if match!=None:\n",
    "                            match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                            list_test_time.append(float(match[1]))\n",
    "                        match = re.match('init_time(.)*', line)\n",
    "                        if match!=None:\n",
    "                            match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                            list_init_time.append(float(match[0]))\n",
    "                        match = re.match('(.)*valid_time(.)*', line)\n",
    "                        if match!=None:\n",
    "                            match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                            list_train_time.append(float(match[0]))\n",
    "                                \n",
    "            result['threshold'] = [threshold]*5\n",
    "            result['model'] = [model]*5\n",
    "            result['padding_size'] = [text_len]*5\n",
    "            result[\"train_mask\"] = [(1+i) for i in range(5)]\n",
    "            \n",
    "            result[\"test_acc\"] = list_acc\n",
    "            result[\"test_auc\"] = list_auc\n",
    "            result[\"test_avg_entr\"] = list_entr\n",
    "            \n",
    "            result[\"init_time\"] = list_init_time\n",
    "            result[\"test_time\"] = list_test_time\n",
    "            result[\"train+valid_time\"] = list_train_time\n",
    "        \n",
    "            #print(result)\n",
    "            total_result = pd.concat([total_result,result],axis=0,ignore_index=True)\n",
    "    \n",
    "    table = total_result[total_result[\"train_mask\"]==5]\n",
    "    #title = f\"{data}_{model}_l{layer}f_pad{text_len}\"\n",
    "    title = f\"{data}_{model}_l{layer}p_pad{text_len}\"\n",
    "    path = f\"result/_csv/{data}\"\n",
    "                   \n",
    "    print(total_result)\n",
    "    total_result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.plot(t,table[\"test_acc\"],\"o-\") \n",
    "    plt.xlabel(\"threshold\")\n",
    "    plt.ylabel(\"test acc\")\n",
    "    plt.savefig(f\"{path}/{title}_plt_acc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.plot(t,table[\"test_auc\"],\"o-\") \n",
    "    plt.xlabel(\"threshold\")\n",
    "    plt.ylabel(\"test auc\")\n",
    "    plt.savefig(f\"{path}/{title}_plt_auc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.plot(t,table[\"test_time\"],\"o-\") \n",
    "    plt.xlabel(\"threshold\")\n",
    "    plt.ylabel(\"test time\")\n",
    "    plt.savefig(f\"{path}/{title}_plt_test_time.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.plot(t,table[\"test_avg_entr\"],\"o-\") \n",
    "    plt.xlabel(\"threshold\")\n",
    "    plt.ylabel(\"test avg entr\")\n",
    "    plt.savefig(f\"{path}/{title}_plt_entr.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "    plt.show()\n",
    "    #break\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbdd66bb",
   "metadata": {},
   "source": [
    "### base fullpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9067b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fullpath baseline\n",
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "### 2/22 - baseline: valid/test with fullpath\n",
    "data = \"ag_news\"\n",
    "total_result = pd.DataFrame(columns=[])\n",
    "for model in [\"linearal\",\"lstmal\",\"transformeral\"]:\n",
    "    for text_len in [25,50,75,100,125,150,175]:\n",
    "### 2/26 - dbpedia\n",
    "#data = \"dbpedia_14\"\n",
    "#for text_len in [20,40,60]:\n",
    "### 2/28 - imdb 8:1:1\n",
    "#data = \"imdb\"\n",
    "#for text_len in [100,200,300,400,500]:\n",
    "    \n",
    "        \n",
    "        layer = 5\n",
    "        epoch = 50\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}base_pad{text_len}/\"\n",
    "        out_path = f\"result/0227/{data}_{model}_l{layer}base_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}base.log\"\n",
    "        \n",
    "        \n",
    "        result = pd.DataFrame(columns=[\"padding_size\"])\n",
    "        result_ep = pd.DataFrame(columns=[\"epoch\",\"ep_train_time\"])\n",
    "        result_ep[\"epoch\"] = [*range(epoch)]\n",
    "        list_acc = []\n",
    "        list_auc = []\n",
    "        list_entr = []\n",
    "        list_test_time = []\n",
    "        list_ep_train_time = []\n",
    "        list_ep_train_acc = []\n",
    "        list_ep_train_auc = []\n",
    "        list_ep_train_entr = []\n",
    "        list_ep_valid_time = []\n",
    "        list_ep_valid_acc = []\n",
    "        list_ep_valid_auc = []\n",
    "        list_ep_valid_entr = []\n",
    "        train_time = 0\n",
    "        init_time = 0\n",
    "        best_ep = -1\n",
    "        best_th = []\n",
    "        save_th = []\n",
    "        test_part = False\n",
    "        \n",
    "        para_size = 1\n",
    "        with open(log,mode='r') as log:\n",
    "            buffer = log.readlines()\n",
    "            df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "            df\n",
    "            \n",
    "            for line in buffer:\n",
    "                \n",
    "                \n",
    "                match = re.match(\"Start Testing\", line)\n",
    "                if match!=None:\n",
    "                    test_part = True\n",
    "                    \n",
    "                match = re.match('Save ckpt to (.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"ep \\d+\",match.group(0))\n",
    "                    best_ep = match[0]\n",
    "                    best_th.append(current_th)\n",
    "                    \n",
    "                match = re.match('Test layer\\d Acc(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    list_acc.append(float(match[0]))\n",
    "                    list_auc.append(float(match[1]))\n",
    "                    list_entr.append(float(match[2]))\n",
    "                    \n",
    "\n",
    "                match = re.match('Test layer\\d Acc(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_test_time.append(float(match[0]))\n",
    "\n",
    "                match = re.match('init_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    init_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('(.)*valid_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    train_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_train_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_l\\d+_test_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_valid_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('Train Epoch\\d+ Acc(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_acc.append(float(match[0]))\n",
    "                    list_ep_train_auc.append(float(match[1]))\n",
    "                    #print(best_th)\n",
    "                    if len(best_th)>0:\n",
    "                        save_th = best_th\n",
    "                    best_th = []\n",
    "                    \n",
    "                match = re.match('Test Epoch\\d+ layer(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    #print(line)\n",
    "                    #print(match)\n",
    "                    \n",
    "                    list_ep_valid_acc.append(float(match[0]))\n",
    "                    list_ep_valid_auc.append(float(match[1]))\n",
    "                    list_ep_valid_entr.append(float(match[2]))\n",
    "                    \n",
    "                    match = re.findall('\\d+', line)\n",
    "                    current_th = int(match[1])\n",
    "        print(save_th)    \n",
    "        ep_valid_time = np.array(list_ep_valid_time).reshape((epoch,-1))\n",
    "        ep_valid_acc = np.array(list_ep_valid_acc).reshape((epoch,-1))\n",
    "        ep_valid_auc = np.array(list_ep_valid_auc).reshape((epoch,-1))\n",
    "        ep_valid_entr = np.array(list_ep_valid_entr).reshape((epoch,-1))\n",
    "        \n",
    "        result_ep[\"ep_train_acc\"] = list_ep_train_acc \n",
    "        result_ep[\"ep_train_auc\"] = list_ep_train_auc          \n",
    "        \n",
    "        result_ep[\"ep_valid_time\"] = np.sum(ep_valid_time,-1) \n",
    "        result_ep[[f\"ep_valid_l{i}_time\" for i in range(para_size)]] = ep_valid_time\n",
    "        result_ep[\"ep_train_time\"] = list_ep_train_time \n",
    "        \n",
    "        \n",
    "        result['model'] = [model]*para_size\n",
    "        result['padding_size'] = [text_len]*para_size\n",
    "        result[\"test_layer\"] = [(i) for i in range(para_size)]\n",
    "        result[\"test_acc\"] = list_acc\n",
    "        result[\"test_auc\"] = list_auc\n",
    "        result[\"test_avg_entr\"] = list_entr\n",
    "        result[\"test_time\"] = list_test_time\n",
    "        result[\"init_time\"] = [init_time]*para_size\n",
    "        result[\"train+valid_time\"] = [train_time]*para_size\n",
    "        result[\"train_time\"] = [result_ep[\"ep_train_time\"].sum()]*para_size\n",
    "        result[\"valid_time\"] = [result_ep[\"ep_valid_time\"].sum()]*para_size\n",
    "        result['best_ep'] = best_ep\n",
    "        #print(result)\n",
    "        #print(result_ep)\n",
    "        \"\"\"\n",
    "        path = f\"result/_csv/{data}\"\n",
    "        title = f\"{data}_{model}_l{layer}_pad{text_len}({best_ep})\"\n",
    "        t = [(i) for i in range(para_size)]\n",
    "        try:\n",
    "            os.mkdir(path)\n",
    "        except:\n",
    "            pass \n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_time\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test time\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_test_time.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_acc\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test acc\")\n",
    "        for i in range(para_size):\n",
    "            if (i) == save_th[-1]:\n",
    "                plt.plot((i),result[\"test_acc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_acc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_auc\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test auc\")\n",
    "        for i in range(para_size):\n",
    "            if (i) == save_th[-1]:\n",
    "                plt.plot((i),result[\"test_auc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_auc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_avg_entr\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test avg entr\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_entr.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        #result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "        #result_ep.to_csv(f\"{path}/{title}_ep.csv\", index=False)\n",
    "        total_result = pd.concat([total_result,result],axis=0,ignore_index=True)            \n",
    "        del result\n",
    "    path = f\"result/_csv/{data}\"\n",
    "    title = f\"{data}_{model}_l{layer}base\"\n",
    "    total_result.to_csv(f\"{path}/{title}_ep.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e68ddd1",
   "metadata": {},
   "source": [
    "## 0308"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1e292bc",
   "metadata": {},
   "source": [
    "\n",
    "### fullpath baseline 多次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0c5c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fullpath baseline\n",
    "### 2/22 - baseline: valid/test with fullpath\n",
    "### 2/26 - dbpedia\n",
    "### 2/28 - imdb 8:1:1\n",
    "### 3/08 - read more files\n",
    "### 3/20 - fullpath training now do shortcut/adaptive inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d8c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "total_result = pd.DataFrame(columns=[])\n",
    "\n",
    "#data = \"ag_news\"\n",
    "#for text_len in [25,50,75,100,125,150,175]:\n",
    "\n",
    "#data = \"dbpedia_14\"\n",
    "#for text_len in [20,40,60]:\n",
    "\n",
    "data = \"imdb\"\n",
    "#for text_len in [100,200,300,400,500]:\n",
    "#for test_count in range(5):\n",
    "text_len = 500\n",
    "#text_len = 80\n",
    "#text_len = 177\n",
    "for model in [\"linearal\",\"lstmal\",\"transformeral\"]:\n",
    "    layer = 5\n",
    "    epoch = 20\n",
    "    lr = 0.0001\n",
    "    out_path = f\"result/0318/fullpath+sc_ad/{data}_{model}_l{layer}base512_pad{text_len}/\"\n",
    "\n",
    "    log_list = os.listdir(out_path)\n",
    "    print(log_list)\n",
    "    for log in log_list:\n",
    "        \n",
    "        result = pd.DataFrame(columns=[\"padding_size\"])\n",
    "        result_ep = pd.DataFrame(columns=[\"epoch\",\"ep_train_time\"])\n",
    "        result_ep[\"epoch\"] = [*range(epoch)]\n",
    "        list_acc = []\n",
    "        list_auc = []\n",
    "        list_f1 = []\n",
    "        list_entr = []\n",
    "        list_acc_th = []\n",
    "        list_auc_th = []\n",
    "        list_f1_th = []\n",
    "        list_entr_th = []\n",
    "        list_test_time = []\n",
    "        list_test_time_th = []\n",
    "        list_ep_train_time = []\n",
    "        list_ep_train_acc = []\n",
    "        list_ep_train_auc = []\n",
    "        list_ep_train_entr = []\n",
    "        list_ep_valid_time = []\n",
    "        list_ep_valid_acc = []\n",
    "        list_ep_valid_auc = []\n",
    "        list_ep_valid_entr = []\n",
    "        list_ep_valid_f1 = []\n",
    "        train_time = 0\n",
    "        init_time = 0\n",
    "        best_ep = -1\n",
    "        best_th = []\n",
    "        save_th = []\n",
    "        test_part = False\n",
    "        \n",
    "        #para_size = 1\n",
    "        para_size = 5+9\n",
    "        with open(out_path+log,mode='r') as log:\n",
    "            buffer = log.readlines()\n",
    "            df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "            df\n",
    "            \n",
    "            for line in buffer:\n",
    "                \n",
    "                \n",
    "                match = re.match(\"Start Testing\", line)\n",
    "                if match!=None:\n",
    "                    test_part = True\n",
    "                    \n",
    "                match = re.match('Save ckpt to (.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"ep \\d+\",match.group(0))\n",
    "                    best_ep = match[0]\n",
    "                    best_th.append(current_th)\n",
    "\n",
    "                match = re.match('init_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    init_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('(.)*valid_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    train_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_train_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_l\\d+_test_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_valid_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('Train Epoch\\d+ Acc(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_acc.append(float(match[0]))\n",
    "                    list_ep_train_auc.append(float(match[1]))\n",
    "                    #print(best_th)\n",
    "                    if len(best_th)>0:\n",
    "                        save_th = best_th\n",
    "                    best_th = []\n",
    "                    \n",
    "                match = re.match('Test Epoch\\d+ layer(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    #print(line)\n",
    "                    #print(match)\n",
    "                    \n",
    "                    list_ep_valid_acc.append(float(match[0]))\n",
    "                    list_ep_valid_auc.append(float(match[1]))\n",
    "                    list_ep_valid_entr.append(float(match[2]))\n",
    "                    list_ep_valid_f1.append(float(match[3]))\n",
    "                    \n",
    "                    match = re.findall('\\d+', line)\n",
    "                    current_th = int(match[1])\n",
    "                \n",
    "                ### testing part\n",
    "                match = re.match('Test layer\\d Acc(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    list_acc.append(float(match[0]))\n",
    "                    list_auc.append(float(match[1]))\n",
    "                    list_entr.append(float(match[2]))\n",
    "                    list_f1.append(float(match[3]))\n",
    "                    \n",
    "                match = re.match('l\\d+_test_time(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_test_time.append(float(match[0]))\n",
    "                \n",
    "                match = re.match('Test threshold(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    list_acc_th.append(float(match[1]))\n",
    "                    list_auc_th.append(float(match[2]))\n",
    "                    list_entr_th.append(float(match[3]))\n",
    "                    list_f1_th.append(float(match[4]))\n",
    "                    \n",
    "                match = re.match('t(.)*_test_time(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_test_time_th.append(float(match[1]))\n",
    "        print(save_th)    \n",
    "        ep_valid_time = np.array(list_ep_valid_time).reshape((epoch,-1))\n",
    "        ep_valid_acc = np.array(list_ep_valid_acc).reshape((epoch,-1))\n",
    "        ep_valid_auc = np.array(list_ep_valid_auc).reshape((epoch,-1))\n",
    "        ep_valid_entr = np.array(list_ep_valid_entr).reshape((epoch,-1))\n",
    "        ep_valid_f1 = np.array(list_ep_valid_entr).reshape((epoch,-1))\n",
    "        \n",
    "        result_ep[\"ep_train_acc\"] = list_ep_train_acc \n",
    "        result_ep[\"ep_train_auc\"] = list_ep_train_auc          \n",
    "        result_ep[\"ep_valid_time\"] = np.sum(ep_valid_time,-1) \n",
    "        result_ep[\"ep_valid_l4_time\"] = ep_valid_time\n",
    "        result_ep[\"ep_train_time\"] = list_ep_train_time \n",
    "        \n",
    "        \n",
    "        result['model'] = [model]*para_size\n",
    "        result['padding_size'] = [text_len]*para_size\n",
    "        #result[\"test_layer\"] = [(i) for i in range(para_size)]\n",
    "        result[\"test_setting\"] = [i for i in range(5)]+[0.1*(i+1) for i in range(9)]\n",
    "        result[\"test_acc\"] = list_acc + list_acc_th\n",
    "        result[\"test_auc\"] = list_auc + list_auc_th\n",
    "        result[\"test_f1\"] = list_f1 + list_f1_th\n",
    "        result[\"test_avg_entr\"] = list_entr + list_entr_th\n",
    "        result[\"test_time\"] = list_test_time + list_test_time_th\n",
    "        result[\"init_time\"] = [init_time]*para_size\n",
    "        result[\"train+valid_time\"] = [train_time]*para_size\n",
    "        result[\"train_time\"] = [result_ep[\"ep_train_time\"].sum()]*para_size\n",
    "        result[\"valid_time\"] = [result_ep[\"ep_valid_time\"].sum()]*para_size\n",
    "        result['best_ep'] = best_ep[3:]\n",
    "        #print(result)\n",
    "        #print(result_ep)\n",
    "        \"\"\"\n",
    "        path = f\"result/_csv/{data}\"\n",
    "        title = f\"{data}_{model}_l{layer}_pad{text_len}({best_ep})\"\n",
    "        t = [(i) for i in range(para_size)]\n",
    "        try:\n",
    "            os.mkdir(path)\n",
    "        except:\n",
    "            pass \n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_time\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test time\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_test_time.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_acc\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test acc\")\n",
    "        for i in range(para_size):\n",
    "            if (i) == save_th[-1]:\n",
    "                plt.plot((i),result[\"test_acc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_acc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_auc\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test auc\")\n",
    "        for i in range(para_size):\n",
    "            if (i) == save_th[-1]:\n",
    "                plt.plot((i),result[\"test_auc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_auc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_avg_entr\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test avg entr\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_entr.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        #result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "        #result_ep.to_csv(f\"{path}/{title}_ep.csv\", index=False)\n",
    "        total_result = pd.concat([total_result,result],axis=0,ignore_index=True)            \n",
    "        del result\n",
    "path = f\"result/_csv/{data}\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "title = f\"{data}_l{layer}base_512\"\n",
    "total_result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a60f5d6",
   "metadata": {},
   "source": [
    "### adapt 多次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e868a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "total_result = pd.DataFrame(columns=[])\n",
    "\n",
    "### 2/04 - valid/test 80%:20%\n",
    "###      - save_path unique for test load\n",
    "###      - \"lstmal\",\"linearal\",\"transformeral\" adapt valid pad save best auc\n",
    "### 2/08 - valid/test 50%:50%\n",
    "#data = \"ag_news\"\n",
    "#for text_len in [25,50,75,100,125,150,175]:\n",
    "#for text_len in [50,75,100,125,150,175]:\n",
    "### 2/18 - dbpedia\n",
    "#data = \"dbpedia_14\"\n",
    "#for text_len in [20,40,60]:\n",
    "data = \"imdb\"\n",
    "\n",
    "text_len = 500\n",
    "#text_len = 177\n",
    "for model in [\"lstmal\",\"linearal\",\"transformeral\"]:\n",
    "    layer = 5\n",
    "    epoch = 30\n",
    "    lr = 0.0001\n",
    "    save_path = f\"ckpt/{data}_{model}_l{layer}ad_pad{text_len}/\"\n",
    "    out_path = f\"result/0315/timer fixed/imdb/{data}_{model}_l{layer}ad_pad{text_len}/\"\n",
    "    log_list = os.listdir(out_path)\n",
    "    print(log_list)\n",
    "    for log in log_list:\n",
    "        \n",
    "        result = pd.DataFrame(columns=[\"padding_size\"])\n",
    "        result_ep = pd.DataFrame(columns=[\"epoch\",\"ep_train_time\"])\n",
    "        result_ep[\"epoch\"] = [*range(epoch)]\n",
    "        list_acc = []\n",
    "        list_auc = []\n",
    "        list_entr = []\n",
    "        list_f1 = []\n",
    "        list_test_time = []\n",
    "        list_ep_train_time = []\n",
    "        list_ep_train_acc = []\n",
    "        list_ep_train_auc = []\n",
    "        list_ep_train_entr = []\n",
    "        list_ep_valid_time = []\n",
    "        list_ep_valid_acc = []\n",
    "        list_ep_valid_auc = []\n",
    "        list_ep_valid_entr = []\n",
    "        train_time = 0\n",
    "        init_time = 0\n",
    "        best_ep = -1\n",
    "        best_th = []\n",
    "        save_th = []\n",
    "        with open(out_path+log,mode='r') as log:\n",
    "            buffer = log.readlines()\n",
    "            df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "            df\n",
    "            \n",
    "            for line in buffer:\n",
    "                \n",
    "                \n",
    "                match = re.match('Save ckpt to (.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"ep \\d+\",match.group(0))\n",
    "                    best_ep = match[0]\n",
    "                    best_th.append(current_th)\n",
    "                match = re.match('Test threshold(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    list_acc.append(float(match[1]))\n",
    "                    list_auc.append(float(match[2]))\n",
    "                    list_entr.append(float(match[3]))\n",
    "                    list_f1.append(float(match[4]))\n",
    "                    \n",
    "\n",
    "                match = re.match('t(.)*_test_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_test_time.append(float(match[1]))\n",
    "\n",
    "                match = re.match('init_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    init_time = float(match[0])\n",
    "                match = re.match('(.)*valid_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    train_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_train_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_t(.)*_test_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_valid_time.append(float(match[1]))\n",
    "                    \n",
    "                match = re.match('Train Epoch\\d+ Acc(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_acc.append(float(match[0]))\n",
    "                    list_ep_train_auc.append(float(match[1]))\n",
    "                    #print(best_th)\n",
    "                    if len(best_th)>0:\n",
    "                        save_th = best_th\n",
    "                    best_th = []\n",
    "                    \n",
    "                match = re.match('Test Epoch\\d+ threshold(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    #print(line)\n",
    "                    #print(match)\n",
    "                    current_th = int(float(match[0])*10)\n",
    "                    list_ep_valid_acc.append(float(match[1]))\n",
    "                    list_ep_valid_auc.append(float(match[2]))\n",
    "                    list_ep_valid_entr.append(float(match[3]))\n",
    "        print(save_th)    \n",
    "        ep_valid_time = np.array(list_ep_valid_time).reshape((epoch,-1))\n",
    "        ep_valid_acc = np.array(list_ep_valid_acc).reshape((epoch,-1))\n",
    "        ep_valid_auc = np.array(list_ep_valid_auc).reshape((epoch,-1))\n",
    "        ep_valid_entr = np.array(list_ep_valid_entr).reshape((epoch,-1))\n",
    "        \n",
    "        result_ep[\"ep_train_acc\"] = list_ep_train_acc \n",
    "        result_ep[\"ep_train_auc\"] = list_ep_train_auc          \n",
    "        \n",
    "        result_ep[\"ep_valid_time\"] = np.sum(ep_valid_time,-1) \n",
    "        result_ep[[f\"ep_valid.{(i+1)}_time\" for i in range(9)]] = ep_valid_time\n",
    "        result_ep[\"ep_train_time\"] = list_ep_train_time \n",
    "        \n",
    "        para_size = 9\n",
    "        result['model'] = [model]*para_size\n",
    "        result['padding_size'] = [text_len]*para_size\n",
    "        result[\"test_threshold\"] = [(1+i)*0.1 for i in range(para_size)]\n",
    "        result[\"best_ep\"] = [best_ep[2:]]*para_size\n",
    "        result[\"best_th\"] = [save_th]*para_size\n",
    "        result[\"best_acc_setting\"] = [list_acc[save_th[-1]-1]]*para_size\n",
    "        result[\"best_auc_setting\"] = [list_auc[save_th[-1]-1]]*para_size\n",
    "        result[\"best_f1_setting\"] = [list_f1[save_th[-1]-1]]*para_size\n",
    "        result[\"best_entr_setting\"] = [list_entr[save_th[-1]-1]]*para_size\n",
    "        result[\"test_time_setting\"] = [list_test_time[save_th[-1]-1]]*para_size\n",
    "        result[\"test_acc\"] = list_acc\n",
    "        result[\"test_auc\"] = list_auc\n",
    "        result[\"test_f1\"] = list_f1\n",
    "        result[\"test_avg_entr\"] = list_entr\n",
    "        result[\"test_time\"] = list_test_time\n",
    "        result[\"init_time\"] = [init_time]*para_size\n",
    "        result[\"train+valid_time\"] = [train_time]*para_size\n",
    "        result[\"train_time\"] = [result_ep[\"ep_train_time\"].sum()]*para_size\n",
    "        result[\"valid_time\"] = [result_ep[\"ep_valid_time\"].sum()]*para_size\n",
    "        #print(result)\n",
    "        #print(result_ep)\n",
    "\n",
    "        path = f\"result/_csv/{data}/base_ad/\"\n",
    "        title = f\"{data}_{model}_l{layer}ad_pad{text_len}({best_ep})\"\n",
    "        os.makedirs(path,exist_ok=True)\n",
    "        \"\"\"\n",
    "        t = [0.1*(i+1) for i in range(9)]\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_time\"],\"o-\") \n",
    "        plt.xlabel(\"threshold\")\n",
    "        plt.ylabel(\"test time\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_test_time.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_acc\"],\"o-\") \n",
    "        plt.xlabel(\"threshold\")\n",
    "        plt.ylabel(\"test acc\")\n",
    "        for i in range(9):\n",
    "            if (i+1) in save_th:\n",
    "                plt.plot((i+1)/10,result[\"test_acc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_acc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_auc\"],\"o-\") \n",
    "        plt.xlabel(\"threshold\")\n",
    "        plt.ylabel(\"test auc\")\n",
    "        for i in range(9):\n",
    "            if (i+1) in save_th:\n",
    "                plt.plot((i+1)/10,result[\"test_auc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_auc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_avg_entr\"],\"o-\") \n",
    "        plt.xlabel(\"threshold\")\n",
    "        plt.ylabel(\"test avg entr\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_entr.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        #result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "        #result_ep.to_csv(f\"{path}/{title}_ep.csv\", index=False)\n",
    "        total_result = pd.concat([total_result,result],axis=0,ignore_index=True)            \n",
    "        del result\n",
    "\n",
    "title = f\"{data}_l{layer}ad\"\n",
    "total_result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a95707a4",
   "metadata": {},
   "source": [
    "### shortcut 多次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5220f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "total_result = pd.DataFrame(columns=[])\n",
    "\n",
    "### baseline shortcut\n",
    "\n",
    "### 2/04 - valid/test 80%:20%\n",
    "###      - baseline\n",
    "### 2/14 - valid/test 50%:50%\n",
    "#data = \"ag_news\"\n",
    "#for text_len in [25,50,75,100,125,150,175]:\n",
    "### 2/18 - dbpedia\n",
    "#data = \"dbpedia_14\"\n",
    "#for text_len in [20,40,60]:\n",
    "### 2/28 - imdb 8:1:1\n",
    "data = \"imdb\"\n",
    "#for text_len in [100,200,300,400,500]:\n",
    "\n",
    "text_len = 500\n",
    "#text_len = 177\n",
    "for model in [\"linearal\",\"lstmal\",\"transformeral\",]:\n",
    "    layer = 5\n",
    "    epoch = 30\n",
    "    lr = 0.0001\n",
    "    save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "    out_path = f\"result/0315/timer fixed/imdb/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "    log_list = os.listdir(out_path)\n",
    "    print(log_list)\n",
    "    for log in log_list:\n",
    "        result = pd.DataFrame(columns=[\"padding_size\"])\n",
    "        result_ep = pd.DataFrame(columns=[\"epoch\",\"ep_train_time\"])\n",
    "        result_ep[\"epoch\"] = [*range(epoch)]\n",
    "        list_acc = []\n",
    "        list_auc = []\n",
    "        list_f1 = []\n",
    "        list_entr = []\n",
    "        list_test_time = []\n",
    "        list_ep_train_time = []\n",
    "        list_ep_train_acc = []\n",
    "        list_ep_train_auc = []\n",
    "        list_ep_train_entr = []\n",
    "        list_ep_valid_time = []\n",
    "        list_ep_valid_acc = []\n",
    "        list_ep_valid_auc = []\n",
    "        list_ep_valid_entr = []\n",
    "        train_time = 0\n",
    "        init_time = 0\n",
    "        best_ep = -1\n",
    "        best_th = []\n",
    "        save_th = []\n",
    "        test_part = False\n",
    "        \n",
    "        para_size = 5\n",
    "        with open(out_path + log,mode='r') as log:\n",
    "            buffer = log.readlines()\n",
    "            df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "            df\n",
    "            \n",
    "            for line in buffer:\n",
    "                \n",
    "                \n",
    "                match = re.match(\"Start Testing\", line)\n",
    "                if match!=None:\n",
    "                    test_part = True\n",
    "                    \n",
    "                match = re.match('Save ckpt to (.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"ep \\d+\",match.group(0))\n",
    "                    best_ep = match[0]\n",
    "                    best_th.append(current_th)\n",
    "                \n",
    "                match = re.match('Test layer\\d+(.)*', line)    \n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    list_acc.append(float(match[0]))\n",
    "                    list_auc.append(float(match[1]))\n",
    "                    list_entr.append(float(match[2]))\n",
    "                    list_f1.append(float(match[3]))\n",
    "                    \n",
    "\n",
    "                match = re.match('l\\d+_test_time(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_test_time.append(float(match[0]))\n",
    "\n",
    "                match = re.match('init_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    init_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('(.)*valid_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    train_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_train_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_l\\d+_test_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_valid_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('Train Epoch\\d+ Acc(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_acc.append(float(match[0]))\n",
    "                    list_ep_train_auc.append(float(match[1]))\n",
    "                    #print(best_th)\n",
    "                    if len(best_th)>0:\n",
    "                        save_th = best_th\n",
    "                    best_th = []\n",
    "                    \n",
    "                match = re.match('Test Epoch\\d+ layer(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    #print(line)\n",
    "                    #print(match)\n",
    "                    \n",
    "                    list_ep_valid_acc.append(float(match[0]))\n",
    "                    list_ep_valid_auc.append(float(match[1]))\n",
    "                    list_ep_valid_entr.append(float(match[2]))\n",
    "                    \n",
    "                    match = re.findall('\\d+', line)\n",
    "                    current_th = int(match[1])\n",
    "        print(save_th)    \n",
    "        ep_valid_time = np.array(list_ep_valid_time).reshape((epoch,-1))\n",
    "        ep_valid_acc = np.array(list_ep_valid_acc).reshape((epoch,-1))\n",
    "        ep_valid_auc = np.array(list_ep_valid_auc).reshape((epoch,-1))\n",
    "        ep_valid_entr = np.array(list_ep_valid_entr).reshape((epoch,-1))\n",
    "        \n",
    "        result_ep[\"ep_train_acc\"] = list_ep_train_acc \n",
    "        result_ep[\"ep_train_auc\"] = list_ep_train_auc          \n",
    "        \n",
    "        result_ep[\"ep_valid_time\"] = np.sum(ep_valid_time,-1) \n",
    "        result_ep[[f\"ep_valid_l{i}_time\" for i in range(para_size)]] = ep_valid_time\n",
    "        result_ep[\"ep_train_time\"] = list_ep_train_time \n",
    "        \n",
    "        \n",
    "        result['model'] = [model]*para_size\n",
    "        result['padding_size'] = [text_len]*para_size\n",
    "        result[\"test_layer\"] = [(i) for i in range(para_size)]\n",
    "        result[\"best_ep\"] = [best_ep[2:]]*para_size\n",
    "        result[\"best_th\"] = [save_th]*para_size\n",
    "        result[\"best_acc_setting\"] = [list_acc[save_th[-1]]]*para_size\n",
    "        result[\"best_auc_setting\"] = [list_auc[save_th[-1]]]*para_size\n",
    "        result[\"best_f1_setting\"] = [list_f1[save_th[-1]]]*para_size\n",
    "        result[\"best_entr_setting\"] = [list_entr[save_th[-1]]]*para_size\n",
    "        result[\"test_time_setting\"] = [list_test_time[save_th[-1]]]*para_size\n",
    "        result[\"test_acc\"] = list_acc\n",
    "        result[\"test_auc\"] = list_auc\n",
    "        result[\"test_f1\"] = list_f1\n",
    "        result[\"test_avg_entr\"] = list_entr\n",
    "        result[\"test_time\"] = list_test_time\n",
    "        result[\"init_time\"] = [init_time]*para_size\n",
    "        result[\"train+valid_time\"] = [train_time]*para_size\n",
    "        result[\"train_time\"] = [result_ep[\"ep_train_time\"].sum()]*para_size\n",
    "        result[\"valid_time\"] = [result_ep[\"ep_valid_time\"].sum()]*para_size\n",
    "        #print(result)\n",
    "        #print(result_ep)\n",
    "\n",
    "        path = f\"result/_csv/{data}/base_sc/\"\n",
    "        title = f\"{data}_{model}_l{layer}_pad{text_len}({best_ep})\"\n",
    "        t = [(i) for i in range(para_size)]\n",
    "        \n",
    "        os.makedirs(path,exist_ok=True)\n",
    "\n",
    "        \"\"\"\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_time\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test time\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_test_time.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_acc\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test acc\")\n",
    "        for i in range(para_size):\n",
    "            if (i) == save_th[-1]:\n",
    "                plt.plot((i),result[\"test_acc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_acc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_auc\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test auc\")\n",
    "        for i in range(para_size):\n",
    "            if (i) == save_th[-1]:\n",
    "                plt.plot((i),result[\"test_auc\"][i],\"ro\") \n",
    "        plt.savefig(f\"{path}/{title}_plt_auc.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.plot(t,result[\"test_avg_entr\"],\"o-\") \n",
    "        plt.xlabel(\"shortcut\")\n",
    "        plt.ylabel(\"test avg entr\")\n",
    "        plt.savefig(f\"{path}/{title}_plt_entr.png\", bbox_inches = \"tight\",facecolor='white', transparent=False)\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        #result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "        #result_ep.to_csv(f\"{path}/{title}_ep.csv\", index=False)\n",
    "        total_result = pd.concat([total_result,result],axis=0,ignore_index=True)            \n",
    "        del result\n",
    "    \n",
    "title = f\"{data}_l{layer}\"\n",
    "total_result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53db5bde",
   "metadata": {},
   "source": [
    "### side adapt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e968794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "total_result = pd.DataFrame(columns=[])\n",
    "\n",
    "#data = \"ag_news\"\n",
    "#for text_len in [25,50,75,100,125,150,175]:\n",
    "\n",
    "#data = \"dbpedia_14\"\n",
    "#for text_len in [20,40,60]:\n",
    "\n",
    "data = \"imdb\"\n",
    "#for text_len in [100,200,300,400,500]:\n",
    "#for test_count in range(5):\n",
    "text_len = 200\n",
    "#text_len = 80\n",
    "#text_len = 175\n",
    "for model in [\"transformeralside\",\"linearalside\",\"lstmalside\"]:\n",
    "    layer = 5\n",
    "    epoch = 50\n",
    "    lr = 0.0005\n",
    "    out_path = f\"result/0328/256 200 0.0005/{data}_{model}_l{layer}_256_sidead/\"\n",
    "    log_list = os.listdir(out_path)\n",
    "    print(log_list)\n",
    "    for log in log_list:\n",
    "        \n",
    "        result = pd.DataFrame(columns=[\"padding_size\"])\n",
    "        result_ep = pd.DataFrame(columns=[\"epoch\",\"ep_train_time\"])\n",
    "        result_ep[\"epoch\"] = [*range(epoch)]\n",
    "        list_acc = []\n",
    "        list_auc = []\n",
    "        list_f1 = []\n",
    "        list_entr = []\n",
    "        list_acc_th = []\n",
    "        list_auc_th = []\n",
    "        list_f1_th = []\n",
    "        list_entr_th = []\n",
    "        list_test_time = []\n",
    "        list_test_time_th = []\n",
    "        list_ep_train_time = []\n",
    "        list_ep_train_acc = []\n",
    "        list_ep_train_auc = []\n",
    "        list_ep_train_entr = []\n",
    "        list_ep_valid_time = []\n",
    "        list_ep_valid_acc = []\n",
    "        list_ep_valid_auc = []\n",
    "        list_ep_valid_entr = []\n",
    "        list_ep_valid_f1 = []\n",
    "        train_time = 0\n",
    "        init_time = 0\n",
    "        best_ep = -1\n",
    "        best_th = []\n",
    "        save_th = []\n",
    "        test_part = False\n",
    "        \n",
    "        #para_size = 1\n",
    "        para_size = 5+9\n",
    "        with open(out_path+log,mode='r') as log:\n",
    "            buffer = log.readlines()\n",
    "            df = pd.DataFrame(buffer,columns=[\"log\"])\n",
    "            df\n",
    "            \n",
    "            for line in buffer:\n",
    "                \n",
    "                \n",
    "                match = re.match(\"Start Testing\", line)\n",
    "                if match!=None:\n",
    "                    test_part = True\n",
    "                    \n",
    "                match = re.match('Save ckpt to (.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"ep \\d+\",match.group(0))\n",
    "                    best_ep = match[0]\n",
    "                    best_th.append(current_th)\n",
    "\n",
    "                match = re.match('init_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    init_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('(.)*valid_time(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    train_time = float(match[0])\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_train_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('ep(\\d)+_l\\d+_test_time(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_valid_time.append(float(match[0]))\n",
    "                    \n",
    "                match = re.match('Train Epoch\\d+ Acc(.)*', line)\n",
    "                if match!=None:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_ep_train_acc.append(float(match[0]))\n",
    "                    list_ep_train_auc.append(float(match[1]))\n",
    "                    #print(best_th)\n",
    "                    if len(best_th)>0:\n",
    "                        save_th = best_th\n",
    "                    best_th = []\n",
    "                    \n",
    "                match = re.match('Test Epoch\\d+ layer(.)*', line)\n",
    "                if match!=None and test_part==False:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    #print(line)\n",
    "                    #print(match)\n",
    "                    \n",
    "                    list_ep_valid_acc.append(float(match[0]))\n",
    "                    list_ep_valid_auc.append(float(match[1]))\n",
    "                    list_ep_valid_entr.append(float(match[2]))\n",
    "                    list_ep_valid_f1.append(float(match[3]))\n",
    "                    \n",
    "                    match = re.findall('\\d+', line)\n",
    "                    current_th = int(match[1])\n",
    "                \n",
    "                ### testing part\n",
    "                match = re.match('Test layer\\d Acc(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    list_acc.append(float(match[0]))\n",
    "                    list_auc.append(float(match[1]))\n",
    "                    list_entr.append(float(match[2]))\n",
    "                    list_f1.append(float(match[3]))\n",
    "                    \n",
    "                match = re.match('l\\d+_test_time(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_test_time.append(float(match[0]))\n",
    "                \n",
    "                match = re.match('Test threshold(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d?\\.\\d+\",match.group(0))\n",
    "                    list_acc_th.append(float(match[1]))\n",
    "                    list_auc_th.append(float(match[2]))\n",
    "                    list_entr_th.append(float(match[3]))\n",
    "                    list_f1_th.append(float(match[4]))\n",
    "                    \n",
    "                match = re.match('t(.)*_test_time(.)*', line)\n",
    "                if match!=None and test_part==True:\n",
    "                    match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                    list_test_time_th.append(float(match[1]))\n",
    "        print(save_th)    \n",
    "        \n",
    "        ep_valid_time = np.array(list_ep_valid_time).reshape((epoch,-1))\n",
    "        ep_valid_acc = np.array(list_ep_valid_acc).reshape((epoch,-1))\n",
    "        ep_valid_auc = np.array(list_ep_valid_auc).reshape((epoch,-1))\n",
    "        ep_valid_entr = np.array(list_ep_valid_entr).reshape((epoch,-1))\n",
    "        ep_valid_f1 = np.array(list_ep_valid_entr).reshape((epoch,-1))\n",
    "        print()    \n",
    "        result_ep[\"ep_train_acc\"] = list_ep_train_acc \n",
    "        result_ep[\"ep_train_auc\"] = list_ep_train_auc          \n",
    "        result_ep[\"ep_valid_time\"] = np.sum(ep_valid_time,-1) \n",
    "        #result_ep[\"ep_valid_l4_time\"] = ep_valid_time\n",
    "        result_ep[\"ep_train_time\"] = list_ep_train_time \n",
    "        \n",
    "        \n",
    "        result['model'] = [model]*para_size\n",
    "        result['padding_size'] = [text_len]*para_size\n",
    "        #result[\"test_layer\"] = [(i) for i in range(para_size)]\n",
    "        result[\"test_setting\"] = [i for i in range(5)]+[0.1*(i+1) for i in range(9)]\n",
    "        result[\"test_acc\"] = list_acc + list_acc_th\n",
    "        result[\"test_auc\"] = list_auc + list_auc_th\n",
    "        result[\"test_f1\"] = list_f1 + list_f1_th\n",
    "        result[\"test_avg_entr\"] = list_entr + list_entr_th\n",
    "        result[\"test_time\"] = list_test_time + list_test_time_th\n",
    "        result[\"init_time\"] = [init_time]*para_size\n",
    "        result[\"train+valid_time\"] = [train_time]*para_size\n",
    "        result[\"train_time\"] = [result_ep[\"ep_train_time\"].sum()]*para_size\n",
    "        result[\"valid_time\"] = [result_ep[\"ep_valid_time\"].sum()]*para_size\n",
    "        result['best_ep'] = best_ep[3:]\n",
    "        #print(result)\n",
    "        #print(result_ep)\n",
    "        #result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "        #result_ep.to_csv(f\"{path}/{title}_ep.csv\", index=False)\n",
    "        total_result = pd.concat([total_result,result],axis=0,ignore_index=True)            \n",
    "        del result\n",
    "path = f\"result/_csv/{data}\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "title = f\"{data}_l{layer}side200\"\n",
    "total_result.to_csv(f\"{path}/{title}.csv\", index=False)\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "751652b6",
   "metadata": {},
   "source": [
    "## 0426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8bf263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datalist = [\"cifar10\", \"cifar100\", \"tinyImageNet\"]\n",
    "model_list = [\"CNN_AL\",\"VGG_AL\",\"resnet_AL\",]\n",
    "for data in datalist:\n",
    "    for model in model_list:\n",
    "        layer = 4\n",
    "        epoch = 200\n",
    "        lr = 0.001\n",
    "        aug_type = \"strong\"\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_{aug_type}/\"\n",
    "        \n",
    "        #out_path = f\"result/0501/adapt rewrite/conf max/{data}_{model}_l{layer}_{aug_type}_max/\"\n",
    "        out_path = f\"result/0418/strong b128/{data}_{model}_l{layer}_{aug_type}/\"\n",
    "\n",
    "        \n",
    "        log_list = os.listdir(out_path)\n",
    "        #print(\"files: \",log_list)\n",
    "        avg_acc = []\n",
    "        avg_time = []\n",
    "        for log in log_list:\n",
    "            para_size = 5+9\n",
    "            with open(out_path+log,mode='r') as log:\n",
    "                buffer = log.readlines()\n",
    "                list_ep_train_acc=[]\n",
    "                list_ep_valid_acc=[]\n",
    "                list_ep_valid_time=[]\n",
    "                for line in buffer:\n",
    "                    match = re.match('Train Epoch\\d+ Acc(.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_train_acc.append(float(match[0]))\n",
    "\n",
    "                        \n",
    "                    match = re.match('Test Epoch\\d+ layer(.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_valid_acc.append(float(match[0]))\n",
    "                    \n",
    "                    match = re.match(\"Test threshold \\d+\\.\\d+ Acc(.)*\", line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_valid_acc.append(float(match[1]))\n",
    "                    \n",
    "                    match = re.match('ep\\d+_l\\d+_test_time(.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_valid_time.append(float(match[0]))\n",
    "                        \n",
    "                    match = re.match('t\\d+\\.\\d+_test_time(.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_valid_time.append(float(match[1]))    \n",
    "                    match = re.match('Best AUC tensor(.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"[0-9]+\\.?[0-9]+\",match.group(0))\n",
    "                        best_ep = int(match[1])\n",
    "                        best_acc = float(match[0])\n",
    "                #print(len(list_ep_train_acc))\n",
    "                #print(len(list_ep_valid_acc))\n",
    "                #print(len(list_ep_valid_time))\n",
    "                list_ep_train_acc = np.array(list_ep_train_acc)\n",
    "                list_ep_valid_acc = np.array(list_ep_valid_acc).reshape((-1, 13))\n",
    "                list_ep_valid_time = np.array(list_ep_valid_time).reshape((-1, 13))\n",
    "                \n",
    "                #print(list_ep_valid_acc[best_ep,:])\n",
    "                #print(list_ep_valid_time[best_ep,:])\n",
    "                avg_acc.append(list_ep_valid_acc[best_ep,:])\n",
    "                avg_time.append(list_ep_valid_time[best_ep,:]) \n",
    "        avg_acc = np.array(avg_acc)\n",
    "        avg_time = np.array(avg_time)\n",
    "        avg_acc = (np.mean(avg_acc, axis=0))\n",
    "        avg_time = (np.mean(avg_time, axis=0))\n",
    "        print(best_acc)\n",
    "        #print(f\"best_ep: {best_ep}\")\n",
    "        #print(\" \".join([str(v) for v in avg_acc]))\n",
    "        #print(avg_time)\n",
    "        \"\"\"\n",
    "        print((f\"{data} {model}\"))\n",
    "        print((\"shortcut/adaptive inference\"))\n",
    "        print((\"confidence type: Max yi\"))\n",
    "        plt.title(f\"{model} testing ACC vs Time\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.plot(avg_time[:4],avg_acc[:4],\"bo-\", label='shortcut inference')\n",
    "        plt.plot(avg_time[4:],avg_acc[4:],\"ro-\", label='adaptive inference')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        print((\"shortcut inference\"))\n",
    "        plt.title(f\"{model} testing ACC vs shortcut depth\")\n",
    "        plt.xlabel(\"shortcut depth\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        x = [f\"L{i}\" for i in range(4)]\n",
    "        plt.plot(x,avg_acc[:4],\"bo-\", label='shortcut inference')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        print((\"adaptive inference\"))\n",
    "        plt.title(f\"{model} testing ACC vs threshold\")\n",
    "        plt.xlabel(\"threshold\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        x = [0.1*(i+1) for i in reversed(range(9))]\n",
    "        plt.plot(x,avg_acc[4:],\"ro-\", label='adaptive inference')\n",
    "        plt.legend()\n",
    "        plt.show()      \n",
    "        \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d97cb7a2",
   "metadata": {},
   "source": [
    "### layer-by-layer training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae75e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for data in [\"cifar100\",]:\n",
    "    for model in [\"CNN_AL\",\"VGG_AL\",\"resnet_AL\",]:\n",
    "        layer = 4\n",
    "        epoch = 400\n",
    "        lr = 0.0001\n",
    "        aug_type = \"strong\"\n",
    "        out_path = f\"result/0509/prefix/300/{data}_{model}_l{layer}_{aug_type}_lbl_pre/\"\n",
    "\n",
    "        \n",
    "        log_list = os.listdir(out_path)\n",
    "        print(\"files: \",log_list)\n",
    "        avg_acc = []\n",
    "        avg_time = []\n",
    "        for log in log_list:\n",
    "            para_size = 5+9\n",
    "            with open(out_path+log,mode='r') as log:\n",
    "                buffer = log.readlines()\n",
    "                list_ep_train_acc=[]\n",
    "                list_ep_valid_acc=[]\n",
    "                list_ep_valid_time=[]\n",
    "                best_ep = []\n",
    "                best_acc = []\n",
    "                for line in buffer:\n",
    "                    \n",
    "                    match = re.match('Test Epoch\\d+ layer(.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_valid_acc.append(float(match[0]))\n",
    "                    \n",
    "                    match = re.match(\"Test threshold \\d+\\.\\d+ Acc(.)*\", line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_valid_acc.append(float(match[1]))\n",
    "                        \n",
    "                    match = re.match('Best AUC tensor(.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"[0-9]+\\.?[0-9]+\",match.group(0))\n",
    "                        best_ep.append(int(match[1]))\n",
    "                        best_acc.append(float(match[0]))\n",
    "                list_ep_valid_acc = np.array(list_ep_valid_acc).reshape((4,-1, 13))\n",
    "                print(list_ep_valid_acc.shape)\n",
    "                for i in range(layer):\n",
    "                    #print(list_ep_valid_acc[i,best_ep[i],:])\n",
    "                    print(best_acc[i],best_ep[i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbcdd291",
   "metadata": {},
   "source": [
    "### bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e05b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datalist = [\"cifar10\", \"cifar100\", \"tinyImageNet\"]\n",
    "model_list = [\"CNN\",\"VGG\",\"resnet\",]\n",
    "[\"CNN_AL\",\"VGG_AL\",\"resnet_AL\",]\n",
    "for data in datalist:\n",
    "    for model in model_list:\n",
    "        layer = 4\n",
    "        epoch = 300\n",
    "        lr = 0.001\n",
    "        aug_type = \"strong\"\n",
    "        #save_path = f\"ckpt/{data}_{model}_l{layer}_{aug_type}/\"\n",
    "        save_path = f\"ckpt/{data}_{model}_{aug_type}/\"\n",
    "        \n",
    "        #out_path = f\"result/0501/adapt rewrite/conf max/{data}_{model}_l{layer}_{aug_type}_max/\"\n",
    "        out_path = f\"result/0515/image_bp/{data}_{model}_{aug_type}/\"\n",
    "\n",
    "        \n",
    "        log_list = os.listdir(out_path)\n",
    "        #print(\"files: \",log_list)\n",
    "        avg_acc = []\n",
    "        avg_time = []\n",
    "        for log in log_list:\n",
    "            para_size = 5+9\n",
    "            with open(out_path+log,mode='r') as log:\n",
    "                buffer = log.readlines()\n",
    "                list_ep_train_acc=[]\n",
    "                list_ep_valid_acc=[]\n",
    "                list_ep_valid_time=[]\n",
    "                for line in buffer:\n",
    "                    match = re.match('Train Epoch\\d+ Acc(.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_train_acc.append(float(match[0]))\n",
    "\n",
    "                        \n",
    "                    match = re.match('Test Epoch\\d+(.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_valid_acc.append(float(match[0]))\n",
    "                    \n",
    "                    \n",
    "                    match = re.match('ep\\d+_test_time(.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_valid_time.append(float(match[0]))\n",
    "                        \n",
    "                    match = re.match('t\\d+\\.\\d+_test_time(.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_valid_time.append(float(match[1]))    \n",
    "                    match = re.match('Best AUC tensor(.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"[0-9]+\\.?[0-9]+\",match.group(0))\n",
    "                        best_ep = int(match[1])\n",
    "                        best_acc = float(match[0])\n",
    "\n",
    "                list_ep_train_acc = np.array(list_ep_train_acc)\n",
    "                list_ep_valid_acc = np.array(list_ep_valid_acc)\n",
    "                list_ep_valid_time = np.array(list_ep_valid_time)\n",
    "                \n",
    "                #print(list_ep_valid_acc[best_ep,:])\n",
    "                #print(list_ep_valid_time[best_ep,:])\n",
    "                avg_acc.append(list_ep_valid_acc[best_ep])\n",
    "                avg_time.append(list_ep_valid_time[best_ep]) \n",
    "        avg_acc = np.array(avg_acc)\n",
    "        avg_time = np.array(avg_time)\n",
    "        avg_acc = (np.mean(avg_acc, axis=0))\n",
    "        avg_time = (np.mean(avg_time, axis=0))\n",
    "        print(best_ep)\n",
    "        #print(f\"best_ep: {best_ep}\")\n",
    "        #print(\" \".join([str(v) for v in avg_acc]))\n",
    "        #print(avg_time)\n",
    "        \"\"\"\n",
    "        print((f\"{data} {model}\"))\n",
    "        print((\"shortcut/adaptive inference\"))\n",
    "        print((\"confidence type: Max yi\"))\n",
    "        plt.title(f\"{model} testing ACC vs Time\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.plot(avg_time[:4],avg_acc[:4],\"bo-\", label='shortcut inference')\n",
    "        plt.plot(avg_time[4:],avg_acc[4:],\"ro-\", label='adaptive inference')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        print((\"shortcut inference\"))\n",
    "        plt.title(f\"{model} testing ACC vs shortcut depth\")\n",
    "        plt.xlabel(\"shortcut depth\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        x = [f\"L{i}\" for i in range(4)]\n",
    "        plt.plot(x,avg_acc[:4],\"bo-\", label='shortcut inference')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        print((\"adaptive inference\"))\n",
    "        plt.title(f\"{model} testing ACC vs threshold\")\n",
    "        plt.xlabel(\"threshold\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        x = [0.1*(i+1) for i in reversed(range(9))]\n",
    "        plt.plot(x,avg_acc[4:],\"ro-\", label='adaptive inference')\n",
    "        plt.legend()\n",
    "        plt.show()      \n",
    "        \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54f634bc",
   "metadata": {},
   "source": [
    "# Final exp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d883fa3",
   "metadata": {},
   "source": [
    "#### FLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32682b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "L0 f 10569.64608m 10144.0\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "L0 b 34359.738368m 33555456.0\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "L0 ae 10.48576m 10250.0\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "L1 f 12079.59552m 18496.0\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "L1 b 8589.934592m 8389632.0\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "L1 ae 1073.741824m 1049600.0\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "L2 f 14495.514624m 55424.0\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "L2 b 17179.869184m 16778240.0\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "L2 ae 1073.741824m 1049600.0\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "L3 f 12079.59552m 73856.0\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "L3 b 4294.967296m 4195328.0\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "L3 ae 1073.741824m 1049600.0\n",
      "[[10569646080.0, 34359738368.0, 10485760.0], [12079595520.0, 8589934592.0, 1073741824.0], [14495514624.0, 17179869184.0, 1073741824.0], [12079595520.0, 4294967296.0, 1073741824.0]]\n",
      "44.939870208\n",
      "32.323403776\n",
      "56.482594816\n",
      "56.751030272\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import mse_loss\n",
    "from torchmetrics.functional import r2_score, auroc, f1_score\n",
    "from utils import *\n",
    "# from model import Model\n",
    "from distributed_model import *\n",
    "from distributed_model_cnn import*\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy\n",
    "import gc\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "model = CNN_AL(num_layer=4, l1_dim=300, lr=0.0001, class_num=10, lab_dim=1024)\n",
    "layers_flop = []\n",
    "input = torch.randn(1024, 3, 32, 32)\n",
    "for layer in range(model.num_layer):\n",
    "    layer_flop = []\n",
    "    m = model.layers[layer].enc.f\n",
    "    flops, params = profile(m, inputs=(input, )) \n",
    "    layer_flop.append(flops)\n",
    "    print(f\"L{layer} f {flops/1e6}m {params}\")\n",
    "    \n",
    "    input = m(input)\n",
    "    m = model.layers[layer].enc.b\n",
    "    flops, params = profile(m, inputs=(input, )) \n",
    "    layer_flop.append(flops)\n",
    "    print(f\"L{layer} b {flops/1e6}m {params}\")\n",
    "    \n",
    "    forward = m(input)\n",
    "    m = model.layers[layer].ae.h\n",
    "    flops, params = profile(m, inputs=(forward, )) \n",
    "    layer_flop.append(flops)\n",
    "    print(f\"L{layer} ae {flops/1e6}m {params}\")\n",
    "    \n",
    "    layers_flop.append(layer_flop)\n",
    "    \n",
    "print(layers_flop)\n",
    "layers_flop_accumulate = layers_flop\n",
    "\n",
    "for i in range(1,model.num_layer):\n",
    "    layers_flop_accumulate[i][0] = layers_flop_accumulate[i][0] + layers_flop_accumulate[i-1][0]\n",
    "    layers_flop_accumulate[i][2] = layers_flop_accumulate[i][2] + layers_flop_accumulate[i-1][2]\n",
    "\n",
    "for count in layers_flop_accumulate:\n",
    "    print(sum(count)/1e9)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fac5c2a",
   "metadata": {},
   "source": [
    "from thop import profile\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import mse_loss\n",
    "from torchmetrics.functional import r2_score, auroc, f1_score\n",
    "from utils import *\n",
    "# from model import Model\n",
    "from distributed_model import *\n",
    "from distributed_model_cnn import*\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy\n",
    "import gc\n",
    "import time\n",
    "\n",
    "class_num = 2\n",
    "df = pd.read_csv('./IMDB_Dataset.csv')\n",
    "df['cleaned_reviews'] = df['review'].apply(data_preprocessing, True)\n",
    "corpus = [word for text in df['cleaned_reviews'] for word in text.split()]\n",
    "vocab = create_vocab(corpus)\n",
    "\n",
    "\n",
    "#model = LSTMModelML(vocab_size=len(vocab), num_layer=4, emb_dim=300, l1_dim=300, lab_dim=128, class_num=class_num, word_vec=word_vec, lr=0.0001)\n",
    "\n",
    "model = LinearModelML(vocab_size=len(vocab), num_layer=4, emb_dim=300, l1_dim=300, lab_dim=128, class_num=class_num, word_vec=word_vec, lr=0.0001)\n",
    "\n",
    "#model = TransformerModelML(vocab_size=len(vocab), num_layer=4, emb_dim=300, l1_dim=300, lab_dim=128, class_num=class_num, word_vec=word_vec, lr=0.0001)\n",
    "        \n",
    "\n",
    "layers_flop = []\n",
    "input = torch.randn(1024, 3, 32, 32)\n",
    "for layer in range(model.num_layer):\n",
    "    layer_flop = []\n",
    "    m = model.layers[layer].enc.f\n",
    "    flops, params = profile(m, inputs=(input, )) \n",
    "    layer_flop.append(flops)\n",
    "    print(f\"L{layer} f {flops/1e6}m {params}\")\n",
    "    \n",
    "    input = m(input)\n",
    "    m = model.layers[layer].enc.b\n",
    "    flops, params = profile(m, inputs=(input, )) \n",
    "    layer_flop.append(flops)\n",
    "    print(f\"L{layer} b {flops/1e6}m {params}\")\n",
    "    \n",
    "    forward = m(input)\n",
    "    m = model.layers[layer].ae.h\n",
    "    flops, params = profile(m, inputs=(forward, )) \n",
    "    layer_flop.append(flops)\n",
    "    print(f\"L{layer} ae {flops/1e6}m {params}\")\n",
    "    \n",
    "    layers_flop.append(layer_flop)\n",
    "    \n",
    "print(layers_flop)\n",
    "layers_flop_accumulate = layers_flop\n",
    "\n",
    "for i in range(1,model.num_layer):\n",
    "    layers_flop_accumulate[i][0] = layers_flop_accumulate[i][0] + layers_flop_accumulate[i-1][0]\n",
    "    layers_flop_accumulate[i][2] = layers_flop_accumulate[i][2] + layers_flop_accumulate[i-1][2]\n",
    "\n",
    "for count in layers_flop_accumulate:\n",
    "    print(sum(count)/1e9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a9b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thop import profile\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import mse_loss\n",
    "from torchmetrics.functional import r2_score, auroc, f1_score\n",
    "from utils import *\n",
    "# from model import Model\n",
    "from distributed_model import *\n",
    "from distributed_model_cnn import*\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy\n",
    "import gc\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "model = CNN_AL(num_layer=4, l1_dim=300, lr=0.0001, class_num=10, lab_dim=128)\n",
    "\n",
    "input = torch.randn(1024, 3, 32, 32)\n",
    "for layer in range(model.num_layer):\n",
    "    \n",
    "    m = model.layers[layer].enc.f\n",
    "    flops, params = profile(m, inputs=(input, )) \n",
    "    print(f\"L{layer} f {flops/1e6}m {params}\")\n",
    "    \n",
    "    input = m(input)\n",
    "    m = model.layers[layer].enc.b\n",
    "    flops, params = profile(m, inputs=(input, )) \n",
    "    print(f\"L{layer} b {flops/1e6}m {params}\")\n",
    "    \n",
    "    forward = m(input)\n",
    "    m = model.layers[layer].ae.h\n",
    "    flops, params = profile(m, inputs=(forward, )) \n",
    "    print(f\"L{layer} ae {flops/1e6}m {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df2873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_AL dim500, act=sig+sig, cri=ce\n",
    "data = \"tinyImageNet\"\n",
    "for model in [\"resnet_AL\",]:\n",
    "    for aug_type in [\"strong\",]:\n",
    "        layer = 4\n",
    "        epoch = 1\n",
    "        lr = 0.0001\n",
    "        \n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_{aug_type}/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_{aug_type}/\"\n",
    "\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_cnn.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-train 128 --batch-test 1024\\\n",
    "        --lr {lr} --l1-dim 300 --label-emb 500 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --aug-type {aug_type} \\\n",
    "        --task image\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f01ce02",
   "metadata": {},
   "source": [
    "#### image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ee3663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from adjustText import adjust_text  \n",
    "total_result = pd.DataFrame(columns=[])\n",
    "fig, axs = plt.subplots(3, 2)\n",
    "fig.set_size_inches(10, 10)\n",
    "r = -1\n",
    "a=96\n",
    "for data in [\"cifar10\", \"cifar100\", \"tinyImageNet\"]:\n",
    "    r+=1\n",
    "    c = -1\n",
    "    for model in [\"VGG_AL\",\"resnet_AL\",]:\n",
    "        c+=1\n",
    "        aug_type = \"strong\"\n",
    "        layer = 4\n",
    "        epoch = 200\n",
    "        lr = 0.0001\n",
    "        \n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_{aug_type}/\"\n",
    "        out_path = f\"result/0518/maxP/{data}_{model}_l{layer}_{aug_type}/\"\n",
    "        #out_path = f\"result/0621/image//{data}_{model}_l{layer}_{aug_type}_1024/\"\n",
    "        \n",
    "        \n",
    "        log_list = os.listdir(out_path)\n",
    "        #print(\"files: \",log_list)\n",
    "        avg_acc = []\n",
    "        avg_time = []\n",
    "        avg_best_acc = []\n",
    "        avg_best_ep = []\n",
    "        for log in log_list:\n",
    "            para_layer = 4\n",
    "            para_thres = 9\n",
    "            para_size = para_layer+para_thres\n",
    "            with open(out_path+log,mode='r') as log:\n",
    "                buffer = log.readlines()\n",
    "\n",
    "                list_ep_valid_acc=[]\n",
    "                list_ep_valid_time=[]\n",
    "                for line in buffer:\n",
    "                    match = re.match('Test Epoch\\d+ layer\\d+ Acc (.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_valid_acc.append(float(match[0]))\n",
    "                    match = re.match('ep\\d+_l\\d+_test_time(.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_valid_time.append(float(match[0]))      \n",
    "                          \n",
    "                    match = re.match(\"Test threshold \\d+\\.\\d+ Acc(.)*\", line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_valid_acc.append(float(match[1]))\n",
    "                    match = re.match('t\\d+\\.\\d+_test_time(.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_valid_time.append(float(match[1]))   \n",
    "                    match = re.match('Best Acc(.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"[0-9]+\\.?[0-9]+\",match.group(0))\n",
    "                        best_ep = int(match[1])\n",
    "                        best_acc = float(match[0])\n",
    "                       \n",
    "                list_ep_valid_acc = np.array(list_ep_valid_acc).reshape((200,13))\n",
    "                list_ep_valid_time = np.array(list_ep_valid_time).reshape((200,13))\n",
    "\n",
    "                avg_acc.append(list_ep_valid_acc[best_ep])\n",
    "                avg_time.append(list_ep_valid_time[best_ep])\n",
    "                avg_best_acc.append(best_acc)\n",
    "                avg_best_ep.append(best_ep)\n",
    "        if data==\"cifar100\" and model==\"resnet_AL\":\n",
    "            print(np.array(avg_time)[:,4:])\n",
    "        std_acc = np.std(avg_acc, axis=0)\n",
    "        std_time = np.std(avg_time, axis=0)        \n",
    "        avg_acc = (np.mean(avg_acc, axis=0))\n",
    "        avg_time = (np.mean(avg_time, axis=0))\n",
    "        avg_best_acc = np.mean(avg_best_acc, axis=0)\n",
    "        avg_best_ep = np.mean(avg_best_ep, axis=0)\n",
    "        \n",
    "        result = pd.DataFrame(columns=[\"dataset\",\"model\",\"best_ep\",\"best_acc\",\"val_type\"]\n",
    "                                    +[f'L{i}_acc' for i in range(para_layer)]\n",
    "                                    +[f't0.{i}_acc' for i in range(1,10)]\n",
    "                                    +[f'L{i}_time' for i in range(para_layer)]\n",
    "                                    +[f't0.{i}_time' for i in range(1,10)])\n",
    "        result.loc[0,[f'L{i}_acc' for i in range(para_layer)]+[f't0.{i}_acc' for i in range(1,10)]] = avg_acc\n",
    "        result.loc[0,[f'L{i}_time' for i in range(para_layer)]+[f't0.{i}_time' for i in range(1,10)]] = avg_time\n",
    "        result.loc[0,[\"dataset\",\"model\",\"best_ep\",\"best_acc\",\"val_type\"]] = [data,model,avg_best_ep, avg_best_acc, \"avg\"]\n",
    "        result.loc[1,[f'L{i}_acc' for i in range(para_layer)]+[f't0.{i}_acc' for i in range(1,10)]] = std_acc\n",
    "        result.loc[1,[f'L{i}_time' for i in range(para_layer)]+[f't0.{i}_time' for i in range(1,10)]] = std_time\n",
    "        result.loc[1,[\"dataset\",\"model\",\"best_ep\",\"best_acc\",\"val_type\"]] = [data,model,avg_best_ep, avg_best_acc, \"std\"]\n",
    "        #print(result)\n",
    "        x = avg_time[:para_layer]\n",
    "        y = avg_acc[:para_layer]\n",
    "        yerr = std_acc[:para_layer]\n",
    "        xerr = std_time[:para_layer]\n",
    "        \n",
    "        #x = avg_time[para_layer:][[0,2,4,6,8]]\n",
    "        #y = avg_acc[para_layer:][[0,2,4,6,8]]\n",
    "        #yerr = std_acc[para_layer:][[0,2,4,6,8]]\n",
    "        #xerr = std_time[para_layer:][[0,2,4,6,8]]\n",
    "        \n",
    "        #axs[r,c].plot(x,y,'--c')\n",
    "        axs[r,c].errorbar(x, y, xerr=yerr, yerr=yerr, marker='o', mfc='royalblue', ecolor='#FF7000', linestyle='--',ms=4,)\n",
    "\n",
    "        texts = [axs[r,c].text(x[i], y[i], f\"L{i+1}\", fontdict=None) for i in range(4)]\n",
    "        \n",
    "        a+=1\n",
    "        axs[r,c].set_title(f\"({chr(a)}) \"+ model+\" in \"+data)\n",
    "        axs[r,c].set(xlabel='inference time (sec)', ylabel='Accuracy')\n",
    "        #plt.fill_between(x, y-yerr, y+yerr)\n",
    "        \n",
    "\n",
    "\n",
    "        adjust_text(texts, ax=axs[r,c])\n",
    "        total_result = pd.concat([total_result,result],axis=0,ignore_index=True)   \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"result/_csv/image_layer.pdf\", format=\"pdf\")\n",
    "plt.show()\n",
    "total_result\n",
    "total_result.to_csv(\"result/_csv/image_adaptive_infrence.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bb00c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = total_result.iloc[:,5:5+para_size].columns\n",
    "pd_acc_avg = total_result[total_result[\"val_type\"]==\"avg\"].iloc[:,5:5+para_size].copy()\n",
    "pd_acc_std = total_result[total_result[\"val_type\"]==\"std\"].iloc[:,5:5+para_size].copy()\n",
    "\n",
    "for c in cols:\n",
    "    pd_acc_avg[cols] = total_result[total_result[\"val_type\"]==\"avg\"][cols].applymap(lambda x: '${0:.2f}\\\\pm'.format(x*100))\n",
    "    pd_acc_std[cols] = total_result[total_result[\"val_type\"]==\"std\"][cols].applymap(lambda x: '{0:.2f}$'.format(x*100))\n",
    "n,m = pd_acc_avg.shape\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        pd_acc_avg.iloc[i,j] = pd_acc_avg.iloc[i,j]+pd_acc_std.iloc[i,j]\n",
    "pd_acc_avg.to_csv(\"result/_csv/image_acc.csv\", index=False)\n",
    "pd_acc_avg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b40422c3",
   "metadata": {},
   "source": [
    "#### text adaptive/shortcut baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa4eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "total_result = pd.DataFrame(columns=[])\n",
    "fig, axs = plt.subplots(3, 2)\n",
    "fig.set_size_inches(10, 10)\n",
    "r = -1\n",
    "a = 96\n",
    "for data,text_len in [\n",
    "    (\"imdb\",500),\n",
    "    (\"ag_news\",177),\n",
    "    (\"dbpedia_14\",80),\n",
    "]:\n",
    "    \n",
    "    r+=1\n",
    "    c=-1\n",
    "    for model in [\"lstmal\",\"transformeral\"]:\n",
    "        c+=1\n",
    "        layer = 5\n",
    "        epoch = 20\n",
    "        lr = 0.0001\n",
    "\n",
    "        out_path = f\"result/0621/text/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        \n",
    "        log_list = os.listdir(out_path)\n",
    "        #print(\"files: \",log_list)\n",
    "        avg_acc = []\n",
    "        avg_time = []\n",
    "        avg_best_acc = []\n",
    "        avg_best_ep = []\n",
    "        for log in log_list:\n",
    "            para_layer = 5\n",
    "            para_thres = 9\n",
    "            para_size = para_layer+para_thres\n",
    "            with open(out_path+log,mode='r') as log:\n",
    "                buffer = log.readlines()\n",
    "\n",
    "                list_ep_valid_acc=[]\n",
    "                list_ep_valid_time=[]\n",
    "                for line in buffer:\n",
    "                    match = re.match('Test Epoch\\d+ layer\\d+ Acc (.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_valid_acc.append(float(match[0]))\n",
    "                    match = re.match('ep\\d+_l\\d+_test_time(.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_valid_time.append(float(match[0]))      \n",
    "                          \n",
    "                    match = re.match(\"Test threshold \\d+\\.\\d+ Acc(.)*\", line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_valid_acc.append(float(match[1]))\n",
    "                    match = re.match('t\\d+\\.\\d+_test_time(.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"\\d+\\.\\d+\",match.group(0))\n",
    "                        list_ep_valid_time.append(float(match[1]))   \n",
    "                    match = re.match('Best Acc(.)*', line)\n",
    "                    if match!=None:\n",
    "                        match = re.findall(\"[0-9]?\\.?[0-9]+\",match.group(0))\n",
    "                        \n",
    "                        best_ep = int(match[1])\n",
    "                        best_acc = float(match[0])\n",
    "                       \n",
    "                list_ep_valid_acc = np.array(list_ep_valid_acc).reshape((-1,para_size))\n",
    "                list_ep_valid_time = np.array(list_ep_valid_time).reshape((-1,para_size))\n",
    "                #print(list_ep_valid_acc[best_ep])\n",
    "                #print(list_ep_valid_time[best_ep])\n",
    "                avg_acc.append(list_ep_valid_acc[best_ep])\n",
    "                avg_time.append(list_ep_valid_time[best_ep])\n",
    "                avg_best_acc.append(best_acc)\n",
    "                avg_best_ep.append(best_ep)\n",
    "        \n",
    "        std_acc = np.std(avg_acc, axis=0)\n",
    "        std_time = np.std(avg_time, axis=0)        \n",
    "        avg_acc = (np.mean(avg_acc, axis=0))\n",
    "        avg_time = (np.mean(avg_time, axis=0))\n",
    "        avg_best_acc = np.mean(avg_best_acc, axis=0)\n",
    "        avg_best_ep = np.mean(avg_best_ep, axis=0)\n",
    "        \n",
    "        result = pd.DataFrame(columns=[\"dataset\",\"model\",\"best_ep\",\"best_acc\",\"val_type\"]\n",
    "                                    +[f'L{i}_acc' for i in range(para_layer)]\n",
    "                                    +[f't0.{i}_acc' for i in range(1,10)]\n",
    "                                    +[f'L{i}_time' for i in range(para_layer)]\n",
    "                                    +[f't0.{i}_time' for i in range(1,10)])\n",
    "        result.loc[0,[f'L{i}_acc' for i in range(para_layer)]+[f't0.{i}_acc' for i in range(1,10)]] = avg_acc\n",
    "        result.loc[0,[f'L{i}_time' for i in range(para_layer)]+[f't0.{i}_time' for i in range(1,10)]] = avg_time\n",
    "        result.loc[0,[\"dataset\",\"model\",\"best_ep\",\"best_acc\",\"val_type\"]] = [data,model,avg_best_ep, avg_best_acc, \"avg\"]\n",
    "        result.loc[1,[f'L{i}_acc' for i in range(para_layer)]+[f't0.{i}_acc' for i in range(1,10)]] = std_acc\n",
    "        result.loc[1,[f'L{i}_time' for i in range(para_layer)]+[f't0.{i}_time' for i in range(1,10)]] = std_time\n",
    "        result.loc[1,[\"dataset\",\"model\",\"best_ep\",\"best_acc\",\"val_type\"]] = [data,model,avg_best_ep, avg_best_acc, \"std\"]\n",
    "        #print(result)\n",
    "        x = avg_time[:para_layer]\n",
    "        y = avg_acc[:para_layer]\n",
    "        yerr = std_acc[:para_layer]\n",
    "        xerr = std_time[:para_layer]\n",
    "        \n",
    "        x = avg_time[para_layer:][[0,2,4,6,8]]\n",
    "        y = avg_acc[para_layer:][[0,2,4,6,8]]\n",
    "        yerr = std_acc[para_layer:][[0,2,4,6,8]]\n",
    "        xerr = std_time[para_layer:][[0,2,4,6,8]]\n",
    "        \n",
    "        axs[r,c].errorbar(x, y, xerr=yerr, yerr=yerr, marker='o', mfc='royalblue', ecolor='#FF7000', linestyle='--',ms=4,)\n",
    "\n",
    "        texts = [axs[r,c].text(x[i], y[i], f\"L{i*2+1}\", fontdict=None) for i in range(5)]\n",
    "        \n",
    "        a+=1\n",
    "        axs[r,c].set_title(f\"({chr(a)}) \"+ model+\" in \"+data)\n",
    "        axs[r,c].set(xlabel='inference time (sec)', ylabel='Accuracy')\n",
    "        #plt.fill_between(x, y-yerr, y+yerr)\n",
    "        \n",
    "\n",
    "\n",
    "        adjust_text(texts, ax=axs[r,c])\n",
    "        total_result = pd.concat([total_result,result],axis=0,ignore_index=True)   \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"result/_csv/text_adapt.pdf\", format=\"pdf\")\n",
    "plt.show()\n",
    "total_result\n",
    "total_result.to_csv(\"result/_csv/text_baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bb1ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = total_result.iloc[:,5:19].columns\n",
    "pd_acc_avg = total_result[total_result[\"val_type\"]==\"avg\"].iloc[:,5:19].copy()\n",
    "pd_acc_std = total_result[total_result[\"val_type\"]==\"std\"].iloc[:,5:19].copy()\n",
    "\n",
    "for c in cols:\n",
    "    pd_acc_avg[cols] = total_result[total_result[\"val_type\"]==\"avg\"][cols].applymap(lambda x: '${0:.2f}\\\\pm'.format(x*100))\n",
    "    pd_acc_std[cols] = total_result[total_result[\"val_type\"]==\"std\"][cols].applymap(lambda x: '{0:.2f}$'.format(x*100))\n",
    "n,m = pd_acc_avg.shape\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        pd_acc_avg.iloc[i,j] = pd_acc_avg.iloc[i,j]+pd_acc_std.iloc[i,j]\n",
    "pd_acc_avg.to_csv(\"result/_csv/text_acc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8192bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a3160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2156294a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
