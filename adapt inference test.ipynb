{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31355eb1",
   "metadata": {},
   "source": [
    "# adapt agnews transformerAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24be13aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘ckpt/ag_news_transformeral_l5_pad50/’: File exists\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/home/user/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "Using custom data configuration default\n",
      "Reusing dataset ag_news (/home/user/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n",
      "loading glove vocabs...: 100%|██████| 400000/400000 [00:03<00:00, 110115.27it/s]\n",
      "Train 0 | Acc 0.6322083333333334 (75865/120000): 100%|█| 938/938 [00:28<00:00, 3\n",
      "Train 1 | Acc 0.9286916666666667 (111443/120000): 100%|█| 938/938 [00:28<00:00, \n",
      "Train 2 | Acc 0.940275 (112833/120000): 100%|█| 938/938 [00:28<00:00, 33.30it/s]\n",
      "Train 3 | Acc 0.9475333333333333 (113704/120000): 100%|█| 938/938 [00:28<00:00, \n",
      "Train 4 | Acc 0.9542 (114504/120000): 100%|███| 938/938 [00:28<00:00, 33.39it/s]\n",
      "Train 5 | Acc 0.9581833333333334 (114982/120000): 100%|█| 938/938 [00:28<00:00, \n",
      "Train 6 | Acc 0.9597916666666667 (115175/120000): 100%|█| 938/938 [00:28<00:00, \n",
      "Train 7 | Acc 0.9608916666666667 (115307/120000): 100%|█| 938/938 [00:28<00:00, \n",
      "Train 8 | Acc 0.9612083333333333 (115345/120000): 100%|█| 938/938 [00:28<00:00, \n",
      "Train 9 | Acc 0.9613583333333333 (115363/120000): 100%|█| 938/938 [00:28<00:00, \n",
      "Train 10 | Acc 0.9614416666666666 (115373/120000): 100%|█| 938/938 [00:28<00:00,\n",
      "Train 11 | Acc 0.9617333333333333 (115408/120000): 100%|█| 938/938 [00:28<00:00,\n",
      "Train 12 | Acc 0.9616916666666666 (115403/120000): 100%|█| 938/938 [00:28<00:00,\n",
      "Train 13 | Acc 0.9615833333333333 (115390/120000): 100%|█| 938/938 [00:28<00:00,\n",
      "Train 14 | Acc 0.9618 (115416/120000): 100%|██| 938/938 [00:28<00:00, 33.37it/s]\n",
      "Train 15 | Acc 0.9615583333333333 (115387/120000): 100%|█| 938/938 [00:28<00:00,\n",
      "Train 16 | Acc 0.9617 (115404/120000): 100%|██| 938/938 [00:28<00:00, 33.01it/s]\n",
      "Train 17 | Acc 0.961525 (115383/120000): 100%|█| 938/938 [00:28<00:00, 33.20it/s\n",
      "Train 18 | Acc 0.96484375 (1482/1536):   1%|   | 12/938 [00:00<00:27, 33.89it/s]"
     ]
    }
   ],
   "source": [
    "data = \"ag_news\"\n",
    "for text_len in [50,100,150,200,250]:\n",
    "    for model in [\"transformeral\"]:\n",
    "        layer = 5\n",
    "        epoch = 30\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}ad_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_adapt.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-size 128 --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ca0cd7b",
   "metadata": {},
   "source": [
    "# adapt imdb transformerAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a895478c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"imdb\"\n",
    "for text_len in [100,200,300,400,500,600,700]:\n",
    "    for model in [\"transformeral\"]:\n",
    "        layer = 5\n",
    "        epoch = 30\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}ad_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_adapt.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-size 128 --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c74eaf0",
   "metadata": {},
   "source": [
    "# imdb transformerAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9546e2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.6'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"imdb\"\n",
    "for text_len in [100,200,300,400,500,600,700]:\n",
    "    for model in [\"transformeral\"]:\n",
    "        layer = 5\n",
    "        epoch = 30\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_side.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-size 128 --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7fe57a05",
   "metadata": {},
   "source": [
    "# adapt dbpedia transformerAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac3e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_len in [20,40,60]:\n",
    "    data = \"dbpedia_14\"\n",
    "    for model in [\"transformeral\"]:\n",
    "        layer = 5\n",
    "        epoch = 30\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}ad_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_adapt.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-size 128 --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bd2a77c",
   "metadata": {},
   "source": [
    "# dbpedia transformerAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b9d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_len in [20,40,60]:\n",
    "    data = \"dbpedia_14\"\n",
    "    for model in [\"transformeral\"]:\n",
    "        layer = 5\n",
    "        epoch = 30\n",
    "        lr = 0.0001\n",
    "        save_path = f\"ckpt/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        out_path = f\"result/{data}_{model}_l{layer}_pad{text_len}/\"\n",
    "        log = f\"{out_path}/{data}_{model}_l{layer}.log\"\n",
    "        !mkdir {save_path}\n",
    "        !mkdir {out_path}\n",
    "        !python3 dis_train_side.py --dataset {data} --model {model} --epoch {epoch} \\\n",
    "        --max-len {text_len} \\\n",
    "        --num-layer {layer}\\\n",
    "        --batch-size 128 --lr {lr} --l1-dim 300 --label-emb 128 \\\n",
    "        --lr-schedule plateau \\\n",
    "        --save-dir {save_path} \\\n",
    "        --out-dir {out_path} \\\n",
    "        --task text > {log}\n",
    "\n",
    "        import gc\n",
    "        gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
